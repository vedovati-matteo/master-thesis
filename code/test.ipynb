{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PINN import PINNS\n",
    "from ODE_systems import ODE_systems\n",
    "\n",
    "from test_PINN_models import test_pinn_models\n",
    "\n",
    "from compute_error import compute_error_norms, compare_error_norms, solve, plot_results\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'net_size': [(2, 50), (3, 50), (4, 50)],\n",
    "    'lr': [1e-2, 1e-3],\n",
    "    'batch_size': [512, 2048],\n",
    "    'stopping_loss': [1e-3, 1e-4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Van der Pol Oscillator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   0%|          | 0/24 [00:00<?, ?it/s]/home/vedo/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.889734148979187\n",
      "Iteration 10, Loss: 0.044277265667915344\n",
      "Iteration 20, Loss: 0.029081782326102257\n",
      "Iteration 30, Loss: 0.00826952513307333\n",
      "Iteration 40, Loss: 0.005044757388532162\n",
      "Iteration 50, Loss: 0.0027233159635215998\n",
      "Iteration 60, Loss: 0.0022342747543007135\n",
      "Iteration 70, Loss: 0.0017856250051409006\n",
      "Iteration 80, Loss: 0.0016178879886865616\n",
      "Iteration 90, Loss: 0.001414948608726263\n",
      "Iteration 100, Loss: 0.0015819271793588996\n",
      "Iteration 110, Loss: 0.0014814393362030387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   4%|▍         | 1/24 [00:02<01:07,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 120, Loss: 0.0013581225648522377\n",
      "Iteration 130, Loss: 0.001269224681891501\n",
      "Stopping early at iteration 134\n",
      "{'Model': 'PINN base', 'Total_Iterations': 135, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.03960907249669317, 'L2_avg': 0.05767953037948207, 'End_point_L1_avg': 0.009499200126326672, 'End_point_L2_avg': 0.009676604339663964}\n",
      "Iteration 0, Loss: 1.248059630393982\n",
      "Iteration 10, Loss: 0.12644517421722412\n",
      "Iteration 20, Loss: 0.044885918498039246\n",
      "Iteration 30, Loss: 0.015050004236400127\n",
      "Iteration 40, Loss: 0.009324105456471443\n",
      "Iteration 50, Loss: 0.004085651133209467\n",
      "Iteration 60, Loss: 0.0026963406708091497\n",
      "Iteration 70, Loss: 0.0021853018552064896\n",
      "Iteration 80, Loss: 0.0018007324542850256\n",
      "Iteration 90, Loss: 0.0018191460985690355\n",
      "Iteration 100, Loss: 0.001752456184476614\n",
      "Iteration 110, Loss: 0.0016429467359557748\n",
      "Iteration 120, Loss: 0.001460959087125957\n",
      "Iteration 130, Loss: 0.0013053970178589225\n",
      "Iteration 140, Loss: 0.001305358367972076\n",
      "Iteration 150, Loss: 0.0010358062572777271\n",
      "Iteration 160, Loss: 0.000826339703053236\n",
      "Iteration 170, Loss: 0.0007082038791850209\n",
      "Iteration 180, Loss: 0.000726258906070143\n",
      "Iteration 190, Loss: 0.0008429104927927256\n",
      "Iteration 200, Loss: 0.0006358458194881678\n",
      "Iteration 210, Loss: 0.0005366217810660601\n",
      "Iteration 220, Loss: 0.0004934114404022694\n",
      "Iteration 230, Loss: 0.0004767801729030907\n",
      "Iteration 240, Loss: 0.0005191262462176383\n",
      "Iteration 250, Loss: 0.0003448468341957778\n",
      "Iteration 260, Loss: 0.00038569315802305937\n",
      "Iteration 270, Loss: 0.00035094787017442286\n",
      "Iteration 280, Loss: 0.0003530865360517055\n",
      "Iteration 290, Loss: 0.00027492502704262733\n",
      "Iteration 300, Loss: 0.0002479290124028921\n",
      "Iteration 310, Loss: 0.0003030062362086028\n",
      "Iteration 320, Loss: 0.00024520629085600376\n",
      "Iteration 330, Loss: 0.0002225773932877928\n",
      "Iteration 340, Loss: 0.0001898185582831502\n",
      "Iteration 350, Loss: 0.000202368653845042\n",
      "Iteration 360, Loss: 0.0001563640107633546\n",
      "Iteration 370, Loss: 0.0001817507145460695\n",
      "Iteration 380, Loss: 0.00016367320495191962\n",
      "Iteration 390, Loss: 0.0004351060197222978\n",
      "Iteration 400, Loss: 0.00024996610591188073\n",
      "Iteration 410, Loss: 0.000334335258230567\n",
      "Iteration 420, Loss: 0.00024639646289870143\n",
      "Iteration 430, Loss: 0.00035978900268673897\n",
      "Iteration 440, Loss: 0.0005696010193787515\n",
      "Iteration 450, Loss: 0.0001365055504720658\n",
      "Iteration 460, Loss: 0.0007075837929733098\n",
      "Iteration 470, Loss: 0.00022882461780682206\n",
      "Iteration 480, Loss: 0.0002507035678718239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   8%|▊         | 2/24 [00:06<01:19,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 490, Loss: 0.0002005845308303833\n",
      "Stopping early at iteration 495\n",
      "{'Model': 'PINN base', 'Total_Iterations': 496, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013629201726388537, 'L2_avg': 0.01724838800564984, 'End_point_L1_avg': 0.011471367934548268, 'End_point_L2_avg': 0.011482185416308096}\n",
      "Iteration 0, Loss: 0.7547629475593567\n",
      "Iteration 10, Loss: 0.08486475050449371\n",
      "Iteration 20, Loss: 0.025416603311896324\n",
      "Iteration 30, Loss: 0.010138331912457943\n",
      "Iteration 40, Loss: 0.006901497952640057\n",
      "Iteration 50, Loss: 0.0036828177981078625\n",
      "Iteration 60, Loss: 0.002714643720537424\n",
      "Iteration 70, Loss: 0.0022281117271631956\n",
      "Iteration 80, Loss: 0.0019180553499609232\n",
      "Iteration 90, Loss: 0.0019011192489415407\n",
      "Iteration 100, Loss: 0.0017423981335014105\n",
      "Iteration 110, Loss: 0.0014748782850801945\n",
      "Iteration 120, Loss: 0.0014259973540902138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  12%|█▎        | 3/24 [00:08<00:54,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130, Loss: 0.0012551620602607727\n",
      "Iteration 140, Loss: 0.0011334617156535387\n",
      "Stopping early at iteration 145\n",
      "{'Model': 'PINN base', 'Total_Iterations': 146, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04004464053956102, 'L2_avg': 0.05787824110014035, 'End_point_L1_avg': 0.00874147235432922, 'End_point_L2_avg': 0.009245450029487732}\n",
      "Iteration 0, Loss: 1.017380714416504\n",
      "Iteration 10, Loss: 0.0520201101899147\n",
      "Iteration 20, Loss: 0.022598206996917725\n",
      "Iteration 30, Loss: 0.015368676744401455\n",
      "Iteration 40, Loss: 0.005516104865819216\n",
      "Iteration 50, Loss: 0.00349837401881814\n",
      "Iteration 60, Loss: 0.0023739305324852467\n",
      "Iteration 70, Loss: 0.001606286852620542\n",
      "Iteration 80, Loss: 0.0013567372225224972\n",
      "Iteration 90, Loss: 0.0009801456471905112\n",
      "Iteration 100, Loss: 0.0007785919005982578\n",
      "Iteration 110, Loss: 0.0006820217240601778\n",
      "Iteration 120, Loss: 0.0005673494888469577\n",
      "Iteration 130, Loss: 0.0004713009111583233\n",
      "Iteration 140, Loss: 0.0004393497365526855\n",
      "Iteration 150, Loss: 0.00037640900700353086\n",
      "Iteration 160, Loss: 0.0003238399513065815\n",
      "Iteration 170, Loss: 0.00030321977101266384\n",
      "Iteration 180, Loss: 0.0002769927668850869\n",
      "Iteration 190, Loss: 0.00024406130251009017\n",
      "Iteration 200, Loss: 0.0002571755030658096\n",
      "Iteration 210, Loss: 0.00021417309471871704\n",
      "Iteration 220, Loss: 0.00019788547069765627\n",
      "Iteration 230, Loss: 0.00019095568859484047\n",
      "Iteration 240, Loss: 0.00018466477922629565\n",
      "Iteration 250, Loss: 0.0001674728118814528\n",
      "Iteration 260, Loss: 0.00015748698206152767\n",
      "Iteration 270, Loss: 0.00018299685325473547\n",
      "Iteration 280, Loss: 0.0001702424488030374\n",
      "Iteration 290, Loss: 0.00014592769730370492\n",
      "Iteration 300, Loss: 0.00014526965969707817\n",
      "Iteration 310, Loss: 0.0001370069949189201\n",
      "Iteration 320, Loss: 0.0002293600409757346\n",
      "Iteration 330, Loss: 0.0003378897672519088\n",
      "Iteration 340, Loss: 0.00013097547343932092\n",
      "Iteration 350, Loss: 0.00013516702165361494\n",
      "Iteration 360, Loss: 0.00011826077388832346\n",
      "Iteration 370, Loss: 0.00016943260561674833\n",
      "Iteration 380, Loss: 0.00032119720708578825\n",
      "Iteration 390, Loss: 0.00010674059012671933\n",
      "Iteration 400, Loss: 0.0001541747769806534\n",
      "Iteration 410, Loss: 0.00015930850349832326\n",
      "Stopping early at iteration 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  17%|█▋        | 4/24 [00:12<01:01,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 419, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.01342835863160621, 'L2_avg': 0.01754511156144124, 'End_point_L1_avg': 0.008774058842676492, 'End_point_L2_avg': 0.008945246441855913}\n",
      "Iteration 0, Loss: 1.0820237398147583\n",
      "Iteration 10, Loss: 0.31596606969833374\n",
      "Iteration 20, Loss: 0.10088042169809341\n",
      "Iteration 30, Loss: 0.06494657695293427\n",
      "Iteration 40, Loss: 0.038440730422735214\n",
      "Iteration 50, Loss: 0.027548465877771378\n",
      "Iteration 60, Loss: 0.018611788749694824\n",
      "Iteration 70, Loss: 0.01822132244706154\n",
      "Iteration 80, Loss: 0.01260464359074831\n",
      "Iteration 90, Loss: 0.01350842323154211\n",
      "Iteration 100, Loss: 0.009834394790232182\n",
      "Iteration 110, Loss: 0.009490570053458214\n",
      "Iteration 120, Loss: 0.008513202890753746\n",
      "Iteration 130, Loss: 0.00518059590831399\n",
      "Iteration 140, Loss: 0.005646090488880873\n",
      "Iteration 150, Loss: 0.004362413194030523\n",
      "Iteration 160, Loss: 0.004977429751306772\n",
      "Iteration 170, Loss: 0.004333737306296825\n",
      "Iteration 180, Loss: 0.0039580161683261395\n",
      "Iteration 190, Loss: 0.003915218636393547\n",
      "Iteration 200, Loss: 0.0036383257247507572\n",
      "Iteration 210, Loss: 0.0035083023831248283\n",
      "Iteration 220, Loss: 0.0026741877663880587\n",
      "Iteration 230, Loss: 0.0026185321621596813\n",
      "Iteration 240, Loss: 0.0024624564684927464\n",
      "Iteration 250, Loss: 0.0024531702511012554\n",
      "Iteration 260, Loss: 0.001888961298391223\n",
      "Iteration 270, Loss: 0.0016260299598798156\n",
      "Iteration 280, Loss: 0.002070621121674776\n",
      "Iteration 290, Loss: 0.0016926550306379795\n",
      "Iteration 300, Loss: 0.0017926994478330016\n",
      "Iteration 310, Loss: 0.0016443189233541489\n",
      "Iteration 320, Loss: 0.0011911781039088964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  21%|██        | 5/24 [00:14<00:56,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 330, Loss: 0.001275923103094101\n",
      "Stopping early at iteration 335\n",
      "{'Model': 'PINN base', 'Total_Iterations': 336, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04666734730790144, 'L2_avg': 0.06288113549575183, 'End_point_L1_avg': 0.01748938760312161, 'End_point_L2_avg': 0.019804231697281554}\n",
      "Iteration 0, Loss: 1.005354404449463\n",
      "Iteration 10, Loss: 0.41327881813049316\n",
      "Iteration 20, Loss: 0.08695399761199951\n",
      "Iteration 30, Loss: 0.06309936195611954\n",
      "Iteration 40, Loss: 0.034058354794979095\n",
      "Iteration 50, Loss: 0.022672493010759354\n",
      "Iteration 60, Loss: 0.015462015755474567\n",
      "Iteration 70, Loss: 0.012941060587763786\n",
      "Iteration 80, Loss: 0.008015194907784462\n",
      "Iteration 90, Loss: 0.005989158060401678\n",
      "Iteration 100, Loss: 0.0073450482450425625\n",
      "Iteration 110, Loss: 0.004631267860531807\n",
      "Iteration 120, Loss: 0.00492738327011466\n",
      "Iteration 130, Loss: 0.003729746676981449\n",
      "Iteration 140, Loss: 0.004143159370869398\n",
      "Iteration 150, Loss: 0.0038157450035214424\n",
      "Iteration 160, Loss: 0.0034378471318632364\n",
      "Iteration 170, Loss: 0.0032399198971688747\n",
      "Iteration 180, Loss: 0.002993933390825987\n",
      "Iteration 190, Loss: 0.002747451886534691\n",
      "Iteration 200, Loss: 0.002605423564091325\n",
      "Iteration 210, Loss: 0.0025251777842640877\n",
      "Iteration 220, Loss: 0.002346753142774105\n",
      "Iteration 230, Loss: 0.0026213701348751783\n",
      "Iteration 240, Loss: 0.0021640220656991005\n",
      "Iteration 250, Loss: 0.0021746628917753696\n",
      "Iteration 260, Loss: 0.0021118964068591595\n",
      "Iteration 270, Loss: 0.0019031277624890208\n",
      "Iteration 280, Loss: 0.0016988926799967885\n",
      "Iteration 290, Loss: 0.0019454288994893432\n",
      "Iteration 300, Loss: 0.0018026885809376836\n",
      "Iteration 310, Loss: 0.001725496375001967\n",
      "Iteration 320, Loss: 0.0018412078497931361\n",
      "Iteration 330, Loss: 0.0014651473611593246\n",
      "Iteration 340, Loss: 0.0015354988863691688\n",
      "Iteration 350, Loss: 0.0015371113549917936\n",
      "Iteration 360, Loss: 0.0014948229072615504\n",
      "Iteration 370, Loss: 0.001337819849140942\n",
      "Iteration 380, Loss: 0.0014167451299726963\n",
      "Iteration 390, Loss: 0.0011774365557357669\n",
      "Iteration 400, Loss: 0.0013642070116475224\n",
      "Iteration 410, Loss: 0.0011616316623985767\n",
      "Iteration 420, Loss: 0.0013054205337539315\n",
      "Iteration 430, Loss: 0.0010885728988796473\n",
      "Iteration 440, Loss: 0.001225650659762323\n",
      "Iteration 450, Loss: 0.0012370753102004528\n",
      "Iteration 460, Loss: 0.0010479566408321261\n",
      "Iteration 470, Loss: 0.001037579495459795\n",
      "Iteration 480, Loss: 0.0011037252843379974\n",
      "Iteration 490, Loss: 0.0009606581879779696\n",
      "Iteration 500, Loss: 0.000986505183391273\n",
      "Iteration 510, Loss: 0.0011384774697944522\n",
      "Iteration 520, Loss: 0.0010077861370518804\n",
      "Iteration 530, Loss: 0.000960817385930568\n",
      "Iteration 540, Loss: 0.0009248189744539559\n",
      "Iteration 550, Loss: 0.0009860341669991612\n",
      "Iteration 560, Loss: 0.0009844162268564105\n",
      "Iteration 570, Loss: 0.000927753746509552\n",
      "Iteration 580, Loss: 0.0007477696053683758\n",
      "Iteration 590, Loss: 0.0008963345317170024\n",
      "Iteration 600, Loss: 0.0008552891667932272\n",
      "Iteration 610, Loss: 0.0007908508996479213\n",
      "Iteration 620, Loss: 0.0009054834954440594\n",
      "Iteration 630, Loss: 0.000847435905598104\n",
      "Iteration 640, Loss: 0.0007585103739984334\n",
      "Iteration 650, Loss: 0.0007893719593994319\n",
      "Iteration 660, Loss: 0.0007921908982098103\n",
      "Iteration 670, Loss: 0.0008972589857876301\n",
      "Iteration 680, Loss: 0.0008850035374052823\n",
      "Iteration 690, Loss: 0.0008809698047116399\n",
      "Iteration 700, Loss: 0.0007470124401152134\n",
      "Iteration 710, Loss: 0.0006840727292001247\n",
      "Iteration 720, Loss: 0.0006405531894415617\n",
      "Iteration 730, Loss: 0.0007474870071746409\n",
      "Iteration 740, Loss: 0.0007332581444643438\n",
      "Iteration 750, Loss: 0.0006163300713524222\n",
      "Iteration 760, Loss: 0.0007130521698854864\n",
      "Iteration 770, Loss: 0.0006058550789020956\n",
      "Iteration 780, Loss: 0.0006246762350201607\n",
      "Iteration 790, Loss: 0.0005912279593758285\n",
      "Iteration 800, Loss: 0.0007791845710016787\n",
      "Iteration 810, Loss: 0.0005470188334584236\n",
      "Iteration 820, Loss: 0.0006067492067813873\n",
      "Iteration 830, Loss: 0.0005924555007368326\n",
      "Iteration 840, Loss: 0.0005154483951628208\n",
      "Iteration 850, Loss: 0.0004874338337685913\n",
      "Iteration 860, Loss: 0.0005300430348142982\n",
      "Iteration 870, Loss: 0.0005595016991719604\n",
      "Iteration 880, Loss: 0.0005465347785502672\n",
      "Iteration 890, Loss: 0.0004996023490093648\n",
      "Iteration 900, Loss: 0.000482077564811334\n",
      "Iteration 910, Loss: 0.0005066423327662051\n",
      "Iteration 920, Loss: 0.0005020458484068513\n",
      "Iteration 930, Loss: 0.0005278880707919598\n",
      "Iteration 940, Loss: 0.0005045558209531009\n",
      "Iteration 950, Loss: 0.00047586712753400207\n",
      "Iteration 960, Loss: 0.000532666512299329\n",
      "Iteration 970, Loss: 0.0004761956515721977\n",
      "Iteration 980, Loss: 0.0006393116782419384\n",
      "Iteration 990, Loss: 0.0005161234294064343\n",
      "Iteration 1000, Loss: 0.0005429775337688625\n",
      "Iteration 1010, Loss: 0.00042985918116755784\n",
      "Iteration 1020, Loss: 0.000515615742187947\n",
      "Iteration 1030, Loss: 0.00044999195961281657\n",
      "Iteration 1040, Loss: 0.0006355565274134278\n",
      "Iteration 1050, Loss: 0.0005628534127026796\n",
      "Iteration 1060, Loss: 0.0004980152589268982\n",
      "Iteration 1070, Loss: 0.00039083603769540787\n",
      "Iteration 1080, Loss: 0.0005708245444111526\n",
      "Iteration 1090, Loss: 0.0005277229938656092\n",
      "Iteration 1100, Loss: 0.0003717738436535001\n",
      "Iteration 1110, Loss: 0.0003788829781115055\n",
      "Iteration 1120, Loss: 0.0003945561475120485\n",
      "Iteration 1130, Loss: 0.0003869707870762795\n",
      "Iteration 1140, Loss: 0.00038886471884325147\n",
      "Iteration 1150, Loss: 0.00040671086753718555\n",
      "Iteration 1160, Loss: 0.00040570725104771554\n",
      "Iteration 1170, Loss: 0.00035303880576975644\n",
      "Iteration 1180, Loss: 0.000405513565056026\n",
      "Iteration 1190, Loss: 0.0003831969224847853\n",
      "Iteration 1200, Loss: 0.0003633587039075792\n",
      "Iteration 1210, Loss: 0.00036678111064247787\n",
      "Iteration 1220, Loss: 0.00033579982118681073\n",
      "Iteration 1230, Loss: 0.0003253327158745378\n",
      "Iteration 1240, Loss: 0.00032525259302929044\n",
      "Iteration 1250, Loss: 0.00032396166352555156\n",
      "Iteration 1260, Loss: 0.0003335151995997876\n",
      "Iteration 1270, Loss: 0.00036531061050482094\n",
      "Iteration 1280, Loss: 0.00031494375434704125\n",
      "Iteration 1290, Loss: 0.00041168712778016925\n",
      "Iteration 1300, Loss: 0.0003198412014171481\n",
      "Iteration 1310, Loss: 0.00032886219560168684\n",
      "Iteration 1320, Loss: 0.0003258308279328048\n",
      "Iteration 1330, Loss: 0.00028443374321796\n",
      "Iteration 1340, Loss: 0.00029540815739892423\n",
      "Iteration 1350, Loss: 0.0003101719485130161\n",
      "Iteration 1360, Loss: 0.00027957919519394636\n",
      "Iteration 1370, Loss: 0.00028707864112220705\n",
      "Iteration 1380, Loss: 0.00028164972900412977\n",
      "Iteration 1390, Loss: 0.00026539686950854957\n",
      "Iteration 1400, Loss: 0.00023569354380015284\n",
      "Iteration 1410, Loss: 0.00028416013810783625\n",
      "Iteration 1420, Loss: 0.00028559486963786185\n",
      "Iteration 1430, Loss: 0.00030777804204262793\n",
      "Iteration 1440, Loss: 0.0003124962095171213\n",
      "Iteration 1450, Loss: 0.00027341285021975636\n",
      "Iteration 1460, Loss: 0.0002955326926894486\n",
      "Iteration 1470, Loss: 0.00023740909819025546\n",
      "Iteration 1480, Loss: 0.0002890171599574387\n",
      "Iteration 1490, Loss: 0.0002749700506683439\n",
      "Iteration 1500, Loss: 0.0006868629134260118\n",
      "Iteration 1510, Loss: 0.0002564520691521466\n",
      "Iteration 1520, Loss: 0.0003283652476966381\n",
      "Iteration 1530, Loss: 0.00034699475509114563\n",
      "Iteration 1540, Loss: 0.00024502817541360855\n",
      "Iteration 1550, Loss: 0.00027953405515290797\n",
      "Iteration 1560, Loss: 0.0002564242167863995\n",
      "Iteration 1570, Loss: 0.00022968475241214037\n",
      "Iteration 1580, Loss: 0.0002220754831796512\n",
      "Iteration 1590, Loss: 0.0002640890597831458\n",
      "Iteration 1600, Loss: 0.00022566404368262738\n",
      "Iteration 1610, Loss: 0.00024273172311950475\n",
      "Iteration 1620, Loss: 0.0002395805495325476\n",
      "Iteration 1630, Loss: 0.0002241131296614185\n",
      "Iteration 1640, Loss: 0.0002902816340792924\n",
      "Iteration 1650, Loss: 0.00103780347853899\n",
      "Iteration 1660, Loss: 0.000312538119032979\n",
      "Iteration 1670, Loss: 0.00020275988208595663\n",
      "Iteration 1680, Loss: 0.00025829419610090554\n",
      "Iteration 1690, Loss: 0.00024668211699463427\n",
      "Iteration 1700, Loss: 0.0003454366815276444\n",
      "Iteration 1710, Loss: 0.00020480029343161732\n",
      "Iteration 1720, Loss: 0.00020564782607834786\n",
      "Iteration 1730, Loss: 0.0002815993211697787\n",
      "Iteration 1740, Loss: 0.00019825302297249436\n",
      "Iteration 1750, Loss: 0.00029843911761417985\n",
      "Iteration 1760, Loss: 0.0002138269046554342\n",
      "Iteration 1770, Loss: 0.00021013402147218585\n",
      "Iteration 1780, Loss: 0.0002240197209175676\n",
      "Iteration 1790, Loss: 0.00023652444360777736\n",
      "Iteration 1800, Loss: 0.0003801575512625277\n",
      "Iteration 1810, Loss: 0.00035385540104471147\n",
      "Iteration 1820, Loss: 0.0004982321988791227\n",
      "Iteration 1830, Loss: 0.0003730029275175184\n",
      "Iteration 1840, Loss: 0.0003502323816064745\n",
      "Iteration 1850, Loss: 0.00027105314075015485\n",
      "Iteration 1860, Loss: 0.000175913650309667\n",
      "Iteration 1870, Loss: 0.00019647757289931178\n",
      "Iteration 1880, Loss: 0.00020715298887807876\n",
      "Iteration 1890, Loss: 0.00018630344129633158\n",
      "Iteration 1900, Loss: 0.00019532200531102717\n",
      "Iteration 1910, Loss: 0.00019569002324715257\n",
      "Iteration 1920, Loss: 0.00017614485113881528\n",
      "Iteration 1930, Loss: 0.0001812158152461052\n",
      "Iteration 1940, Loss: 0.00025013365666382015\n",
      "Iteration 1950, Loss: 0.00017203149036504328\n",
      "Iteration 1960, Loss: 0.0003548229287844151\n",
      "Iteration 1970, Loss: 0.00017575107631273568\n",
      "Iteration 1980, Loss: 0.00020676430722232908\n",
      "Iteration 1990, Loss: 0.00015953704132698476\n",
      "Iteration 2000, Loss: 0.00020078000670764595\n",
      "Iteration 2010, Loss: 0.00018204546358902007\n",
      "Iteration 2020, Loss: 0.00021765903511550277\n",
      "Iteration 2030, Loss: 0.00020161802240181714\n",
      "Iteration 2040, Loss: 0.00023900110682006925\n",
      "Iteration 2050, Loss: 0.00019035791046917439\n",
      "Iteration 2060, Loss: 0.00015761223039589822\n",
      "Iteration 2070, Loss: 0.0001446679962100461\n",
      "Iteration 2080, Loss: 0.00014598197594750673\n",
      "Iteration 2090, Loss: 0.0001374127168674022\n",
      "Iteration 2100, Loss: 0.0001613166241440922\n",
      "Iteration 2110, Loss: 0.00016216389485634863\n",
      "Iteration 2120, Loss: 0.00019345208420418203\n",
      "Iteration 2130, Loss: 0.00028595098410733044\n",
      "Iteration 2140, Loss: 0.00015186490782070905\n",
      "Iteration 2150, Loss: 0.0001638393005123362\n",
      "Iteration 2160, Loss: 0.00014030920283403248\n",
      "Iteration 2170, Loss: 0.0003836305986624211\n",
      "Iteration 2180, Loss: 0.0005336505710147321\n",
      "Iteration 2190, Loss: 0.00014739870675839484\n",
      "Iteration 2200, Loss: 0.00020414621394593269\n",
      "Iteration 2210, Loss: 0.0001868762483354658\n",
      "Iteration 2220, Loss: 0.0001456019381294027\n",
      "Iteration 2230, Loss: 0.00015619266196154058\n",
      "Iteration 2240, Loss: 0.00015543389599770308\n",
      "Iteration 2250, Loss: 0.00014381307119037956\n",
      "Iteration 2260, Loss: 0.00014968993491493165\n",
      "Iteration 2270, Loss: 0.0001699298300081864\n",
      "Iteration 2280, Loss: 0.00012934663391206414\n",
      "Iteration 2290, Loss: 0.00017729065439198166\n",
      "Iteration 2300, Loss: 0.0001390933321090415\n",
      "Iteration 2310, Loss: 0.00012175348092569038\n",
      "Iteration 2320, Loss: 0.00023116204829420894\n",
      "Iteration 2330, Loss: 0.000626974506303668\n",
      "Iteration 2340, Loss: 0.0005652992986142635\n",
      "Iteration 2350, Loss: 0.0001442841748939827\n",
      "Iteration 2360, Loss: 0.0001633711945032701\n",
      "Iteration 2370, Loss: 0.0001595004287082702\n",
      "Iteration 2380, Loss: 0.00011317020107526332\n",
      "Iteration 2390, Loss: 0.00011201767483726144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  25%|██▌       | 6/24 [00:36<02:49,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2400, Loss: 0.00010359752195654437\n",
      "Stopping early at iteration 2403\n",
      "{'Model': 'PINN base', 'Total_Iterations': 2404, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.014141610744773582, 'L2_avg': 0.01858188225663676, 'End_point_L1_avg': 0.008133902707898029, 'End_point_L2_avg': 0.008144548996110782}\n",
      "Iteration 0, Loss: 1.0163707733154297\n",
      "Iteration 10, Loss: 0.3856314718723297\n",
      "Iteration 20, Loss: 0.10986661911010742\n",
      "Iteration 30, Loss: 0.06842786818742752\n",
      "Iteration 40, Loss: 0.037210773676633835\n",
      "Iteration 50, Loss: 0.022555306553840637\n",
      "Iteration 60, Loss: 0.01709071174263954\n",
      "Iteration 70, Loss: 0.013556024059653282\n",
      "Iteration 80, Loss: 0.009363967925310135\n",
      "Iteration 90, Loss: 0.007119355723261833\n",
      "Iteration 100, Loss: 0.006676366552710533\n",
      "Iteration 110, Loss: 0.00589909590780735\n",
      "Iteration 120, Loss: 0.005162893794476986\n",
      "Iteration 130, Loss: 0.004536603577435017\n",
      "Iteration 140, Loss: 0.0044535077176988125\n",
      "Iteration 150, Loss: 0.004045899026095867\n",
      "Iteration 160, Loss: 0.0040694596245884895\n",
      "Iteration 170, Loss: 0.0037385993637144566\n",
      "Iteration 180, Loss: 0.0034028254449367523\n",
      "Iteration 190, Loss: 0.0030040950514376163\n",
      "Iteration 200, Loss: 0.0028061100747436285\n",
      "Iteration 210, Loss: 0.0028531313873827457\n",
      "Iteration 220, Loss: 0.0026965641882270575\n",
      "Iteration 230, Loss: 0.002519694622606039\n",
      "Iteration 240, Loss: 0.0022900747135281563\n",
      "Iteration 250, Loss: 0.002225152449682355\n",
      "Iteration 260, Loss: 0.002256354782730341\n",
      "Iteration 270, Loss: 0.0021256213076412678\n",
      "Iteration 280, Loss: 0.002077290788292885\n",
      "Iteration 290, Loss: 0.0019273326033726335\n",
      "Iteration 300, Loss: 0.0019627572037279606\n",
      "Iteration 310, Loss: 0.0018778638914227486\n",
      "Iteration 320, Loss: 0.0018360898829996586\n",
      "Iteration 330, Loss: 0.001698781969025731\n",
      "Iteration 340, Loss: 0.0015984511701390147\n",
      "Iteration 350, Loss: 0.0015977772418409586\n",
      "Iteration 360, Loss: 0.0015521610621362925\n",
      "Iteration 370, Loss: 0.001586859580129385\n",
      "Iteration 380, Loss: 0.0013968650018796325\n",
      "Iteration 390, Loss: 0.0015105969505384564\n",
      "Iteration 400, Loss: 0.0013267050962895155\n",
      "Iteration 410, Loss: 0.0013827222865074873\n",
      "Iteration 420, Loss: 0.0012827618047595024\n",
      "Iteration 430, Loss: 0.001301399664953351\n",
      "Iteration 440, Loss: 0.0012121984036639333\n",
      "Iteration 450, Loss: 0.0011750058038160205\n",
      "Iteration 460, Loss: 0.0011952643981203437\n",
      "Iteration 470, Loss: 0.0011258412851020694\n",
      "Iteration 480, Loss: 0.00113638152834028\n",
      "Iteration 490, Loss: 0.001097227563150227\n",
      "Iteration 500, Loss: 0.0010583758121356368\n",
      "Iteration 510, Loss: 0.0010564689291641116\n",
      "Iteration 520, Loss: 0.0010207718005403876\n",
      "Iteration 530, Loss: 0.001048458507284522\n",
      "Stopping early at iteration 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  29%|██▉       | 7/24 [00:42<02:18,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 537, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.045067538916487376, 'L2_avg': 0.05899270549142807, 'End_point_L1_avg': 0.026920925775187822, 'End_point_L2_avg': 0.027561713616969973}\n",
      "Iteration 0, Loss: 1.7854527235031128\n",
      "Iteration 10, Loss: 0.6373894810676575\n",
      "Iteration 20, Loss: 0.23766352236270905\n",
      "Iteration 30, Loss: 0.11115317046642303\n",
      "Iteration 40, Loss: 0.08646556735038757\n",
      "Iteration 50, Loss: 0.05656852945685387\n",
      "Iteration 60, Loss: 0.042130548506975174\n",
      "Iteration 70, Loss: 0.03265024721622467\n",
      "Iteration 80, Loss: 0.0246355589479208\n",
      "Iteration 90, Loss: 0.019196800887584686\n",
      "Iteration 100, Loss: 0.013055696152150631\n",
      "Iteration 110, Loss: 0.013566586188971996\n",
      "Iteration 120, Loss: 0.01156750600785017\n",
      "Iteration 130, Loss: 0.010359089821577072\n",
      "Iteration 140, Loss: 0.010592286475002766\n",
      "Iteration 150, Loss: 0.00899816770106554\n",
      "Iteration 160, Loss: 0.008975923992693424\n",
      "Iteration 170, Loss: 0.007554624695330858\n",
      "Iteration 180, Loss: 0.007208756636828184\n",
      "Iteration 190, Loss: 0.006702927406877279\n",
      "Iteration 200, Loss: 0.006286913529038429\n",
      "Iteration 210, Loss: 0.0055933501571416855\n",
      "Iteration 220, Loss: 0.005656447261571884\n",
      "Iteration 230, Loss: 0.005279815290123224\n",
      "Iteration 240, Loss: 0.004867770709097385\n",
      "Iteration 250, Loss: 0.005028935149312019\n",
      "Iteration 260, Loss: 0.004508994985371828\n",
      "Iteration 270, Loss: 0.004267219919711351\n",
      "Iteration 280, Loss: 0.004286836367100477\n",
      "Iteration 290, Loss: 0.004031337331980467\n",
      "Iteration 300, Loss: 0.0035585681907832623\n",
      "Iteration 310, Loss: 0.00374959921464324\n",
      "Iteration 320, Loss: 0.0035181741695851088\n",
      "Iteration 330, Loss: 0.003445635549724102\n",
      "Iteration 340, Loss: 0.0035517013166099787\n",
      "Iteration 350, Loss: 0.0033662565983831882\n",
      "Iteration 360, Loss: 0.0032429106067866087\n",
      "Iteration 370, Loss: 0.002919729333370924\n",
      "Iteration 380, Loss: 0.003000753466039896\n",
      "Iteration 390, Loss: 0.0030091803055256605\n",
      "Iteration 400, Loss: 0.0028878641314804554\n",
      "Iteration 410, Loss: 0.0027288494165986776\n",
      "Iteration 420, Loss: 0.0028867197688668966\n",
      "Iteration 430, Loss: 0.0026686477940529585\n",
      "Iteration 440, Loss: 0.002667302032932639\n",
      "Iteration 450, Loss: 0.00241422513499856\n",
      "Iteration 460, Loss: 0.00232303561642766\n",
      "Iteration 470, Loss: 0.0023255248088389635\n",
      "Iteration 480, Loss: 0.0025035033468157053\n",
      "Iteration 490, Loss: 0.002251571277156472\n",
      "Iteration 500, Loss: 0.002204379765316844\n",
      "Iteration 510, Loss: 0.002154731657356024\n",
      "Iteration 520, Loss: 0.0020541599951684475\n",
      "Iteration 530, Loss: 0.0021315792109817266\n",
      "Iteration 540, Loss: 0.002133262576535344\n",
      "Iteration 550, Loss: 0.0020255260169506073\n",
      "Iteration 560, Loss: 0.0020071540493518114\n",
      "Iteration 570, Loss: 0.0019317064434289932\n",
      "Iteration 580, Loss: 0.0017491653561592102\n",
      "Iteration 590, Loss: 0.0018029640195891261\n",
      "Iteration 600, Loss: 0.0018292282475158572\n",
      "Iteration 610, Loss: 0.0018005028832703829\n",
      "Iteration 620, Loss: 0.0017576200189068913\n",
      "Iteration 630, Loss: 0.0016356721753254533\n",
      "Iteration 640, Loss: 0.0015990223037078977\n",
      "Iteration 650, Loss: 0.0016471592243760824\n",
      "Iteration 660, Loss: 0.0016314814565703273\n",
      "Iteration 670, Loss: 0.0015444118762388825\n",
      "Iteration 680, Loss: 0.0015660363715142012\n",
      "Iteration 690, Loss: 0.0016206396976485848\n",
      "Iteration 700, Loss: 0.001400637673214078\n",
      "Iteration 710, Loss: 0.0014656218700110912\n",
      "Iteration 720, Loss: 0.0014402235392481089\n",
      "Iteration 730, Loss: 0.0014454189222306013\n",
      "Iteration 740, Loss: 0.0013467271346598864\n",
      "Iteration 750, Loss: 0.0012858177069574594\n",
      "Iteration 760, Loss: 0.0012600531335920095\n",
      "Iteration 770, Loss: 0.0012262690579518676\n",
      "Iteration 780, Loss: 0.00123463268391788\n",
      "Iteration 790, Loss: 0.0012822068529203534\n",
      "Iteration 800, Loss: 0.0012414823286235332\n",
      "Iteration 810, Loss: 0.0011754644801840186\n",
      "Iteration 820, Loss: 0.0011897297808900476\n",
      "Iteration 830, Loss: 0.001096904743462801\n",
      "Iteration 840, Loss: 0.0010930862044915557\n",
      "Iteration 850, Loss: 0.0011533020297065377\n",
      "Iteration 860, Loss: 0.0010809223167598248\n",
      "Iteration 870, Loss: 0.0010546826524659991\n",
      "Iteration 880, Loss: 0.0010218502720817924\n",
      "Iteration 890, Loss: 0.000990383792668581\n",
      "Iteration 900, Loss: 0.0010011125123128295\n",
      "Iteration 910, Loss: 0.0009245512192137539\n",
      "Iteration 920, Loss: 0.0009449420031160116\n",
      "Iteration 930, Loss: 0.0009127040975727141\n",
      "Iteration 940, Loss: 0.0008920849650166929\n",
      "Iteration 950, Loss: 0.000943385879509151\n",
      "Iteration 960, Loss: 0.0008847992867231369\n",
      "Iteration 970, Loss: 0.0008916778024286032\n",
      "Iteration 980, Loss: 0.0008538118563592434\n",
      "Iteration 990, Loss: 0.0008518710965290666\n",
      "Iteration 1000, Loss: 0.0008471949258819222\n",
      "Iteration 1010, Loss: 0.0007562628597952425\n",
      "Iteration 1020, Loss: 0.000793242419604212\n",
      "Iteration 1030, Loss: 0.0007740404107607901\n",
      "Iteration 1040, Loss: 0.0006942238542251289\n",
      "Iteration 1050, Loss: 0.0007505664834752679\n",
      "Iteration 1060, Loss: 0.0007577181677334011\n",
      "Iteration 1070, Loss: 0.00078344572102651\n",
      "Iteration 1080, Loss: 0.00070519297150895\n",
      "Iteration 1090, Loss: 0.0007344455225393176\n",
      "Iteration 1100, Loss: 0.0007261569262482226\n",
      "Iteration 1110, Loss: 0.0007035015150904655\n",
      "Iteration 1120, Loss: 0.0006802855059504509\n",
      "Iteration 1130, Loss: 0.0006786973681300879\n",
      "Iteration 1140, Loss: 0.0006433189264498651\n",
      "Iteration 1150, Loss: 0.0005988256307318807\n",
      "Iteration 1160, Loss: 0.0006132663111202419\n",
      "Iteration 1170, Loss: 0.0005832487950101495\n",
      "Iteration 1180, Loss: 0.0006026529590599239\n",
      "Iteration 1190, Loss: 0.0005625232006423175\n",
      "Iteration 1200, Loss: 0.000602562096901238\n",
      "Iteration 1210, Loss: 0.0005964181036688387\n",
      "Iteration 1220, Loss: 0.0005637885187752545\n",
      "Iteration 1230, Loss: 0.0005487420130521059\n",
      "Iteration 1240, Loss: 0.0005876872455701232\n",
      "Iteration 1250, Loss: 0.0005389455473050475\n",
      "Iteration 1260, Loss: 0.000557263265363872\n",
      "Iteration 1270, Loss: 0.0005295040318742394\n",
      "Iteration 1280, Loss: 0.0005186593043617904\n",
      "Iteration 1290, Loss: 0.0005163890309631824\n",
      "Iteration 1300, Loss: 0.0005174020770937204\n",
      "Iteration 1310, Loss: 0.0004892405122518539\n",
      "Iteration 1320, Loss: 0.0004898387705907226\n",
      "Iteration 1330, Loss: 0.00046997470781207085\n",
      "Iteration 1340, Loss: 0.00046461913734674454\n",
      "Iteration 1350, Loss: 0.0004900271305814385\n",
      "Iteration 1360, Loss: 0.0004329876392148435\n",
      "Iteration 1370, Loss: 0.00044023373629897833\n",
      "Iteration 1380, Loss: 0.0004322148161008954\n",
      "Iteration 1390, Loss: 0.00041111442260444164\n",
      "Iteration 1400, Loss: 0.0004011807614006102\n",
      "Iteration 1410, Loss: 0.0004086375702172518\n",
      "Iteration 1420, Loss: 0.0004214620857965201\n",
      "Iteration 1430, Loss: 0.00041562545811757445\n",
      "Iteration 1440, Loss: 0.0003741352120414376\n",
      "Iteration 1450, Loss: 0.00037683662958443165\n",
      "Iteration 1460, Loss: 0.00036844779970124364\n",
      "Iteration 1470, Loss: 0.0003759472456295043\n",
      "Iteration 1480, Loss: 0.0003591629792936146\n",
      "Iteration 1490, Loss: 0.00036786095006391406\n",
      "Iteration 1500, Loss: 0.00035037737688980997\n",
      "Iteration 1510, Loss: 0.0003393546212464571\n",
      "Iteration 1520, Loss: 0.00034013137337751687\n",
      "Iteration 1530, Loss: 0.0003278455405961722\n",
      "Iteration 1540, Loss: 0.000317835045279935\n",
      "Iteration 1550, Loss: 0.00031578767811879516\n",
      "Iteration 1560, Loss: 0.00030424032593145967\n",
      "Iteration 1570, Loss: 0.0003015673137269914\n",
      "Iteration 1580, Loss: 0.0003003644524142146\n",
      "Iteration 1590, Loss: 0.00030861690174788237\n",
      "Iteration 1600, Loss: 0.00029580495902337134\n",
      "Iteration 1610, Loss: 0.00028626288985833526\n",
      "Iteration 1620, Loss: 0.00028221492539159954\n",
      "Iteration 1630, Loss: 0.00027483279700390995\n",
      "Iteration 1640, Loss: 0.0002745656529441476\n",
      "Iteration 1650, Loss: 0.0002677856246009469\n",
      "Iteration 1660, Loss: 0.0002626498171593994\n",
      "Iteration 1670, Loss: 0.0002539187262300402\n",
      "Iteration 1680, Loss: 0.0002500128757674247\n",
      "Iteration 1690, Loss: 0.00024403721909038723\n",
      "Iteration 1700, Loss: 0.00025376654230058193\n",
      "Iteration 1710, Loss: 0.0002299188490724191\n",
      "Iteration 1720, Loss: 0.00024001988640520722\n",
      "Iteration 1730, Loss: 0.00022814572730567306\n",
      "Iteration 1740, Loss: 0.0002322069340152666\n",
      "Iteration 1750, Loss: 0.00023499860253650695\n",
      "Iteration 1760, Loss: 0.00022514950251206756\n",
      "Iteration 1770, Loss: 0.00021366047440096736\n",
      "Iteration 1780, Loss: 0.00021979556186124682\n",
      "Iteration 1790, Loss: 0.00020338082686066628\n",
      "Iteration 1800, Loss: 0.00020604483142960817\n",
      "Iteration 1810, Loss: 0.00019963692466262728\n",
      "Iteration 1820, Loss: 0.0002084209700115025\n",
      "Iteration 1830, Loss: 0.00019924924708902836\n",
      "Iteration 1840, Loss: 0.00019092556613031775\n",
      "Iteration 1850, Loss: 0.00018320833623874933\n",
      "Iteration 1860, Loss: 0.00018917056149803102\n",
      "Iteration 1870, Loss: 0.00017786877288017422\n",
      "Iteration 1880, Loss: 0.0001786527718650177\n",
      "Iteration 1890, Loss: 0.00018209034169558436\n",
      "Iteration 1900, Loss: 0.0001818952732719481\n",
      "Iteration 1910, Loss: 0.00016694188525434583\n",
      "Iteration 1920, Loss: 0.0001710106444079429\n",
      "Iteration 1930, Loss: 0.0001733305980451405\n",
      "Iteration 1940, Loss: 0.00015678406634833664\n",
      "Iteration 1950, Loss: 0.00016023535863496363\n",
      "Iteration 1960, Loss: 0.00015918334247544408\n",
      "Iteration 1970, Loss: 0.00015639010234735906\n",
      "Iteration 1980, Loss: 0.00016478719771839678\n",
      "Iteration 1990, Loss: 0.00016820552991703153\n",
      "Iteration 2000, Loss: 0.00015412023640237749\n",
      "Iteration 2010, Loss: 0.00015823377179913223\n",
      "Iteration 2020, Loss: 0.0001562766992719844\n",
      "Iteration 2030, Loss: 0.0001466850226279348\n",
      "Iteration 2040, Loss: 0.00014136273239273578\n",
      "Iteration 2050, Loss: 0.00015055062249302864\n",
      "Iteration 2060, Loss: 0.00014336864114739\n",
      "Iteration 2070, Loss: 0.00014300849579740316\n",
      "Iteration 2080, Loss: 0.00014291011029854417\n",
      "Iteration 2090, Loss: 0.00014011742314323783\n",
      "Iteration 2100, Loss: 0.0001383959606755525\n",
      "Iteration 2110, Loss: 0.00013555301120504737\n",
      "Iteration 2120, Loss: 0.00013412082626018673\n",
      "Iteration 2130, Loss: 0.00013903348008170724\n",
      "Iteration 2140, Loss: 0.0001243798906216398\n",
      "Iteration 2150, Loss: 0.00012272162712179124\n",
      "Iteration 2160, Loss: 0.00012317106302361935\n",
      "Iteration 2170, Loss: 0.00012318463996052742\n",
      "Iteration 2180, Loss: 0.00012156427692389116\n",
      "Iteration 2190, Loss: 0.00012112442345824093\n",
      "Iteration 2200, Loss: 0.00012179101759102196\n",
      "Iteration 2210, Loss: 0.0001229859481099993\n",
      "Iteration 2220, Loss: 0.00011956221715081483\n",
      "Iteration 2230, Loss: 0.00011733348219422624\n",
      "Iteration 2240, Loss: 0.00011369300773367286\n",
      "Iteration 2250, Loss: 0.00011368785635568202\n",
      "Iteration 2260, Loss: 0.00011625162733253092\n",
      "Iteration 2270, Loss: 0.00011084185098297894\n",
      "Iteration 2280, Loss: 0.0001143167755799368\n",
      "Iteration 2290, Loss: 0.00010711975482990965\n",
      "Iteration 2300, Loss: 0.00011493742204038426\n",
      "Iteration 2310, Loss: 0.0001047936239046976\n",
      "Iteration 2320, Loss: 0.00010498354822630063\n",
      "Iteration 2330, Loss: 0.00010716128599597141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  33%|███▎      | 8/24 [01:02<03:12, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2340, Loss: 0.00011233310215175152\n",
      "Stopping early at iteration 2344\n",
      "{'Model': 'PINN base', 'Total_Iterations': 2345, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014506305064556073, 'L2_avg': 0.01906633325929345, 'End_point_L1_avg': 0.009907251173275324, 'End_point_L2_avg': 0.01003090089997715}\n",
      "Iteration 0, Loss: 1.0737236738204956\n",
      "Iteration 10, Loss: 0.1660182625055313\n",
      "Iteration 20, Loss: 0.07119546830654144\n",
      "Iteration 30, Loss: 0.027853481471538544\n",
      "Iteration 40, Loss: 0.014628816395998001\n",
      "Iteration 50, Loss: 0.006178813520818949\n",
      "Iteration 60, Loss: 0.004810551647096872\n",
      "Iteration 70, Loss: 0.00524519570171833\n",
      "Iteration 80, Loss: 0.0023536698427051306\n",
      "Iteration 90, Loss: 0.0026224867906421423\n",
      "Iteration 100, Loss: 0.0022621555253863335\n",
      "Iteration 110, Loss: 0.004350977949798107\n",
      "Iteration 120, Loss: 0.004538714420050383\n",
      "Iteration 130, Loss: 0.0020066227298229933\n",
      "Iteration 140, Loss: 0.002038612961769104\n",
      "Iteration 150, Loss: 0.0026006170082837343\n",
      "Iteration 160, Loss: 0.0013736269902437925\n",
      "Iteration 170, Loss: 0.003006727434694767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  38%|███▊      | 9/24 [01:04<02:12,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 180, Loss: 0.002197924070060253\n",
      "Stopping early at iteration 189\n",
      "{'Model': 'PINN base', 'Total_Iterations': 190, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.03533359652537642, 'L2_avg': 0.052624339784256506, 'End_point_L1_avg': 0.003464318374001392, 'End_point_L2_avg': 0.004290874012087601}\n",
      "Iteration 0, Loss: 0.8752716183662415\n",
      "Iteration 10, Loss: 0.08491405844688416\n",
      "Iteration 20, Loss: 0.024479255080223083\n",
      "Iteration 30, Loss: 0.013820161111652851\n",
      "Iteration 40, Loss: 0.007727036252617836\n",
      "Iteration 50, Loss: 0.0031207138672471046\n",
      "Iteration 60, Loss: 0.002429292071610689\n",
      "Iteration 70, Loss: 0.0021714854519814253\n",
      "Iteration 80, Loss: 0.001750434166751802\n",
      "Iteration 90, Loss: 0.002235728083178401\n",
      "Iteration 100, Loss: 0.001516655320301652\n",
      "Iteration 110, Loss: 0.001942671719007194\n",
      "Iteration 120, Loss: 0.0015873758820816875\n",
      "Iteration 130, Loss: 0.0015439629787579179\n",
      "Iteration 140, Loss: 0.0013841136824339628\n",
      "Iteration 150, Loss: 0.0011902321130037308\n",
      "Iteration 160, Loss: 0.000993769383057952\n",
      "Iteration 170, Loss: 0.0007313696551136672\n",
      "Iteration 180, Loss: 0.0006839397829025984\n",
      "Iteration 190, Loss: 0.0004938238998875022\n",
      "Iteration 200, Loss: 0.00042365980334579945\n",
      "Iteration 210, Loss: 0.0004000656772404909\n",
      "Iteration 220, Loss: 0.0003380289999768138\n",
      "Iteration 230, Loss: 0.0014669765951111913\n",
      "Iteration 240, Loss: 0.00047522762906737626\n",
      "Iteration 250, Loss: 0.0005260961479507387\n",
      "Iteration 260, Loss: 0.00035748688969761133\n",
      "Iteration 270, Loss: 0.0003225614200346172\n",
      "Iteration 280, Loss: 0.00023267020878847688\n",
      "Iteration 290, Loss: 0.0012453282251954079\n",
      "Iteration 300, Loss: 0.0003594972367864102\n",
      "Iteration 310, Loss: 0.00028113904409110546\n",
      "Iteration 320, Loss: 0.00032993292552419007\n",
      "Iteration 330, Loss: 0.00028367291088216007\n",
      "Iteration 340, Loss: 0.00022635924688074738\n",
      "Iteration 350, Loss: 0.00018132761761080474\n",
      "Iteration 360, Loss: 0.00016077453619800508\n",
      "Iteration 370, Loss: 0.00015213940059766173\n",
      "Iteration 380, Loss: 0.0001599270908627659\n",
      "Iteration 390, Loss: 0.00015602214261889458\n",
      "Iteration 400, Loss: 0.0001598691160324961\n",
      "Iteration 410, Loss: 0.00028477891464717686\n",
      "Iteration 420, Loss: 0.0009318067459389567\n",
      "Iteration 430, Loss: 0.0007782061584293842\n",
      "Iteration 440, Loss: 0.0003306229773443192\n",
      "Iteration 450, Loss: 0.0001937693596119061\n",
      "Iteration 460, Loss: 0.00016408809460699558\n",
      "Iteration 470, Loss: 0.00022545333195012063\n",
      "Iteration 480, Loss: 0.00012397172395139933\n",
      "Iteration 490, Loss: 0.00013198978558648378\n",
      "Stopping early at iteration 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  42%|████▏     | 10/24 [01:10<01:49,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 499, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013703602386741839, 'L2_avg': 0.018559303925798673, 'End_point_L1_avg': 0.0061265658080752825, 'End_point_L2_avg': 0.006313764061370483}\n",
      "Iteration 0, Loss: 0.9336608052253723\n",
      "Iteration 10, Loss: 0.1020667776465416\n",
      "Iteration 20, Loss: 0.03527749329805374\n",
      "Iteration 30, Loss: 0.01201532781124115\n",
      "Iteration 40, Loss: 0.006605195812880993\n",
      "Iteration 50, Loss: 0.003675902495160699\n",
      "Iteration 60, Loss: 0.0024786258582025766\n",
      "Iteration 70, Loss: 0.0019949476700276136\n",
      "Iteration 80, Loss: 0.0016784588806331158\n",
      "Iteration 90, Loss: 0.0014290817780420184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  46%|████▌     | 11/24 [01:11<01:15,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Loss: 0.001182801672257483\n",
      "Stopping early at iteration 106\n",
      "{'Model': 'PINN base', 'Total_Iterations': 107, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0379965326865053, 'L2_avg': 0.057121152414333694, 'End_point_L1_avg': 0.004851313745773427, 'End_point_L2_avg': 0.005531164945587016}\n",
      "Iteration 0, Loss: 1.0432181358337402\n",
      "Iteration 10, Loss: 0.11876054108142853\n",
      "Iteration 20, Loss: 0.02387993223965168\n",
      "Iteration 30, Loss: 0.01258641853928566\n",
      "Iteration 40, Loss: 0.0057089985348284245\n",
      "Iteration 50, Loss: 0.0033643448259681463\n",
      "Iteration 60, Loss: 0.0026698322035372257\n",
      "Iteration 70, Loss: 0.002076101489365101\n",
      "Iteration 80, Loss: 0.002046062145382166\n",
      "Iteration 90, Loss: 0.0017745991935953498\n",
      "Iteration 100, Loss: 0.0017641837475821376\n",
      "Iteration 110, Loss: 0.0017109280452132225\n",
      "Iteration 120, Loss: 0.001624111202545464\n",
      "Iteration 130, Loss: 0.0016102032968774438\n",
      "Iteration 140, Loss: 0.001436305814422667\n",
      "Iteration 150, Loss: 0.0014555620728060603\n",
      "Iteration 160, Loss: 0.0014738369500264525\n",
      "Iteration 170, Loss: 0.0011709036771208048\n",
      "Iteration 180, Loss: 0.0011421011295169592\n",
      "Iteration 190, Loss: 0.0007827886729501188\n",
      "Iteration 200, Loss: 0.0008452085894532502\n",
      "Iteration 210, Loss: 0.0009447568445466459\n",
      "Iteration 220, Loss: 0.004623535554856062\n",
      "Iteration 230, Loss: 0.0013092224253341556\n",
      "Iteration 240, Loss: 0.0008392640738748014\n",
      "Iteration 250, Loss: 0.0006250583101063967\n",
      "Iteration 260, Loss: 0.000466575293103233\n",
      "Iteration 270, Loss: 0.0004098740464542061\n",
      "Iteration 280, Loss: 0.0013583124382421374\n",
      "Iteration 290, Loss: 0.0014673140831291676\n",
      "Iteration 300, Loss: 0.0008890655590221286\n",
      "Iteration 310, Loss: 0.00045073567889630795\n",
      "Iteration 320, Loss: 0.0003209209826309234\n",
      "Iteration 330, Loss: 0.0002851848548743874\n",
      "Iteration 340, Loss: 0.00030204333597794175\n",
      "Iteration 350, Loss: 0.000616118311882019\n",
      "Iteration 360, Loss: 0.00040027842624112964\n",
      "Iteration 370, Loss: 0.0003267686115577817\n",
      "Iteration 380, Loss: 0.0004977486678399146\n",
      "Iteration 390, Loss: 0.0003189686103723943\n",
      "Iteration 400, Loss: 0.00026213997625745833\n",
      "Iteration 410, Loss: 0.00024019277771003544\n",
      "Iteration 420, Loss: 0.0002066577144432813\n",
      "Iteration 430, Loss: 0.00018066051416099072\n",
      "Iteration 440, Loss: 0.00016082801448646933\n",
      "Iteration 450, Loss: 0.0001543184625916183\n",
      "Iteration 460, Loss: 0.0036506534088402987\n",
      "Iteration 470, Loss: 0.003550516441464424\n",
      "Iteration 480, Loss: 0.0013031740672886372\n",
      "Iteration 490, Loss: 0.0007633404457010329\n",
      "Iteration 500, Loss: 0.0006559309549629688\n",
      "Iteration 510, Loss: 0.0003591711283661425\n",
      "Iteration 520, Loss: 0.0002292828430654481\n",
      "Iteration 530, Loss: 0.00017419588402844965\n",
      "Iteration 540, Loss: 0.0001402838242938742\n",
      "Iteration 550, Loss: 0.00012696678459178656\n",
      "Iteration 560, Loss: 0.00011342492507537827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  50%|█████     | 12/24 [01:18<01:13,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 570, Loss: 0.00010574811312835664\n",
      "Stopping early at iteration 576\n",
      "{'Model': 'PINN base', 'Total_Iterations': 577, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014056215667262674, 'L2_avg': 0.01832148052153719, 'End_point_L1_avg': 0.00893332524748406, 'End_point_L2_avg': 0.009011475098055435}\n",
      "Iteration 0, Loss: 1.0068985223770142\n",
      "Iteration 10, Loss: 0.34083494544029236\n",
      "Iteration 20, Loss: 0.13617871701717377\n",
      "Iteration 30, Loss: 0.06936916708946228\n",
      "Iteration 40, Loss: 0.0440305657684803\n",
      "Iteration 50, Loss: 0.02720908634364605\n",
      "Iteration 60, Loss: 0.007946217432618141\n",
      "Iteration 70, Loss: 0.005795799195766449\n",
      "Iteration 80, Loss: 0.005675924941897392\n",
      "Iteration 90, Loss: 0.005803594831377268\n",
      "Iteration 100, Loss: 0.004355012904852629\n",
      "Iteration 110, Loss: 0.003474464872851968\n",
      "Iteration 120, Loss: 0.0033154920674860477\n",
      "Iteration 130, Loss: 0.0027324450202286243\n",
      "Iteration 140, Loss: 0.0034328841138631105\n",
      "Iteration 150, Loss: 0.0026109188329428434\n",
      "Iteration 160, Loss: 0.0028783243615180254\n",
      "Iteration 170, Loss: 0.0024043540470302105\n",
      "Iteration 180, Loss: 0.0022873373236507177\n",
      "Iteration 190, Loss: 0.0019965474493801594\n",
      "Iteration 200, Loss: 0.0019468576647341251\n",
      "Iteration 210, Loss: 0.001740813720971346\n",
      "Iteration 220, Loss: 0.0020731305703520775\n",
      "Iteration 230, Loss: 0.0014101199340075254\n",
      "Iteration 240, Loss: 0.0016472581773996353\n",
      "Iteration 250, Loss: 0.0015850825002416968\n",
      "Iteration 260, Loss: 0.0015075941337272525\n",
      "Iteration 270, Loss: 0.0016118024941533804\n",
      "Iteration 280, Loss: 0.001511132693849504\n",
      "Iteration 290, Loss: 0.001294549205340445\n",
      "Iteration 300, Loss: 0.0014522752026095986\n",
      "Iteration 310, Loss: 0.0013206735020503402\n",
      "Iteration 320, Loss: 0.0012173578143119812\n",
      "Iteration 330, Loss: 0.00122020673006773\n",
      "Iteration 340, Loss: 0.0012910718796774745\n",
      "Iteration 350, Loss: 0.0011733642313629389\n",
      "Iteration 360, Loss: 0.0011378469644114375\n",
      "Iteration 370, Loss: 0.0012863113079220057\n",
      "Stopping early at iteration 375\n",
      "{'Model': 'PINN base', 'Total_Iterations': 376, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.045997170260260435, 'L2_avg': 0.060214902980236296, 'End_point_L1_avg': 0.019312543743866296, 'End_point_L2_avg': 0.022524604749090713}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  54%|█████▍    | 13/24 [01:22<01:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.8869455456733704\n",
      "Iteration 10, Loss: 0.31784743070602417\n",
      "Iteration 20, Loss: 0.13978509604930878\n",
      "Iteration 30, Loss: 0.07419048994779587\n",
      "Iteration 40, Loss: 0.04392869025468826\n",
      "Iteration 50, Loss: 0.019809873774647713\n",
      "Iteration 60, Loss: 0.006983479950577021\n",
      "Iteration 70, Loss: 0.0068142288364470005\n",
      "Iteration 80, Loss: 0.006324567832052708\n",
      "Iteration 90, Loss: 0.005792202427983284\n",
      "Iteration 100, Loss: 0.004689724184572697\n",
      "Iteration 110, Loss: 0.0042568836361169815\n",
      "Iteration 120, Loss: 0.004102958831936121\n",
      "Iteration 130, Loss: 0.003909719176590443\n",
      "Iteration 140, Loss: 0.004041615873575211\n",
      "Iteration 150, Loss: 0.003482147352769971\n",
      "Iteration 160, Loss: 0.003215145319700241\n",
      "Iteration 170, Loss: 0.003548914100974798\n",
      "Iteration 180, Loss: 0.0034503366332501173\n",
      "Iteration 190, Loss: 0.0029437532648444176\n",
      "Iteration 200, Loss: 0.0030677393078804016\n",
      "Iteration 210, Loss: 0.002811129204928875\n",
      "Iteration 220, Loss: 0.0029777297750115395\n",
      "Iteration 230, Loss: 0.0034736772067844868\n",
      "Iteration 240, Loss: 0.0029334721621125937\n",
      "Iteration 250, Loss: 0.0027220735792070627\n",
      "Iteration 260, Loss: 0.0024371054023504257\n",
      "Iteration 270, Loss: 0.003034233348444104\n",
      "Iteration 280, Loss: 0.002637325320392847\n",
      "Iteration 290, Loss: 0.0025830825325101614\n",
      "Iteration 300, Loss: 0.002677812473848462\n",
      "Iteration 310, Loss: 0.002449012128636241\n",
      "Iteration 320, Loss: 0.00242028059437871\n",
      "Iteration 330, Loss: 0.002144341357052326\n",
      "Iteration 340, Loss: 0.0023669421207159758\n",
      "Iteration 350, Loss: 0.002167710103094578\n",
      "Iteration 360, Loss: 0.001668028999119997\n",
      "Iteration 370, Loss: 0.001963923452422023\n",
      "Iteration 380, Loss: 0.0018599849427118897\n",
      "Iteration 390, Loss: 0.001954917563125491\n",
      "Iteration 400, Loss: 0.0017696889117360115\n",
      "Iteration 410, Loss: 0.0017201736336573958\n",
      "Iteration 420, Loss: 0.00185834476724267\n",
      "Iteration 430, Loss: 0.0015999177703633904\n",
      "Iteration 440, Loss: 0.001582980272360146\n",
      "Iteration 450, Loss: 0.001341944676823914\n",
      "Iteration 460, Loss: 0.001347562181763351\n",
      "Iteration 470, Loss: 0.0013814544072374701\n",
      "Iteration 480, Loss: 0.0014299254398792982\n",
      "Iteration 490, Loss: 0.001329833292402327\n",
      "Iteration 500, Loss: 0.0012163978535681963\n",
      "Iteration 510, Loss: 0.0012848472688347101\n",
      "Iteration 520, Loss: 0.0011214191326871514\n",
      "Iteration 530, Loss: 0.001182338921353221\n",
      "Iteration 540, Loss: 0.0010939115891233087\n",
      "Iteration 550, Loss: 0.0011645283084362745\n",
      "Iteration 560, Loss: 0.0009851707145571709\n",
      "Iteration 570, Loss: 0.000986733939498663\n",
      "Iteration 580, Loss: 0.0010535907931625843\n",
      "Iteration 590, Loss: 0.0009388703037984669\n",
      "Iteration 600, Loss: 0.001165479072369635\n",
      "Iteration 610, Loss: 0.0014190804213285446\n",
      "Iteration 620, Loss: 0.0010677394457161427\n",
      "Iteration 630, Loss: 0.0008170672226697206\n",
      "Iteration 640, Loss: 0.0007372054969891906\n",
      "Iteration 650, Loss: 0.0008647526265121996\n",
      "Iteration 660, Loss: 0.0008230417734012008\n",
      "Iteration 670, Loss: 0.0008346674731001258\n",
      "Iteration 680, Loss: 0.0008495434303767979\n",
      "Iteration 690, Loss: 0.0007850427646189928\n",
      "Iteration 700, Loss: 0.0007013907306827605\n",
      "Iteration 710, Loss: 0.001384153962135315\n",
      "Iteration 720, Loss: 0.0009288842556998134\n",
      "Iteration 730, Loss: 0.0007739845314063132\n",
      "Iteration 740, Loss: 0.0006913027609698474\n",
      "Iteration 750, Loss: 0.000617109180893749\n",
      "Iteration 760, Loss: 0.0006297664367593825\n",
      "Iteration 770, Loss: 0.0007352166576310992\n",
      "Iteration 780, Loss: 0.0010487919207662344\n",
      "Iteration 790, Loss: 0.0009907294297590852\n",
      "Iteration 800, Loss: 0.0006574164726771414\n",
      "Iteration 810, Loss: 0.0006118821911513805\n",
      "Iteration 820, Loss: 0.0006531080580316484\n",
      "Iteration 830, Loss: 0.0005871378816664219\n",
      "Iteration 840, Loss: 0.0005865758284926414\n",
      "Iteration 850, Loss: 0.0005892959306947887\n",
      "Iteration 860, Loss: 0.0005352786392904818\n",
      "Iteration 870, Loss: 0.0005411680322140455\n",
      "Iteration 880, Loss: 0.0005572965601459146\n",
      "Iteration 890, Loss: 0.0007085598772391677\n",
      "Iteration 900, Loss: 0.0006195828900672495\n",
      "Iteration 910, Loss: 0.00047704920871183276\n",
      "Iteration 920, Loss: 0.0006179339252412319\n",
      "Iteration 930, Loss: 0.0005399271030910313\n",
      "Iteration 940, Loss: 0.0005989331984892488\n",
      "Iteration 950, Loss: 0.000459316506749019\n",
      "Iteration 960, Loss: 0.0006746228318661451\n",
      "Iteration 970, Loss: 0.0007226915913634002\n",
      "Iteration 980, Loss: 0.0005815736949443817\n",
      "Iteration 990, Loss: 0.0004604915447998792\n",
      "Iteration 1000, Loss: 0.0004191905027255416\n",
      "Iteration 1010, Loss: 0.00045352475717663765\n",
      "Iteration 1020, Loss: 0.0005789427668787539\n",
      "Iteration 1030, Loss: 0.00041620369302108884\n",
      "Iteration 1040, Loss: 0.0005586979677900672\n",
      "Iteration 1050, Loss: 0.0004231728089507669\n",
      "Iteration 1060, Loss: 0.00047278773854486644\n",
      "Iteration 1070, Loss: 0.000764043303206563\n",
      "Iteration 1080, Loss: 0.0005417932406999171\n",
      "Iteration 1090, Loss: 0.0004335741978138685\n",
      "Iteration 1100, Loss: 0.00046769148320890963\n",
      "Iteration 1110, Loss: 0.0004799470189027488\n",
      "Iteration 1120, Loss: 0.000417030300013721\n",
      "Iteration 1130, Loss: 0.0003549277607817203\n",
      "Iteration 1140, Loss: 0.00035177808604203165\n",
      "Iteration 1150, Loss: 0.0005629507941193879\n",
      "Iteration 1160, Loss: 0.0004679453559219837\n",
      "Iteration 1170, Loss: 0.000405546190449968\n",
      "Iteration 1180, Loss: 0.0004536464693956077\n",
      "Iteration 1190, Loss: 0.0004141704412177205\n",
      "Iteration 1200, Loss: 0.000325275439536199\n",
      "Iteration 1210, Loss: 0.0004698132979683578\n",
      "Iteration 1220, Loss: 0.0005451242905110121\n",
      "Iteration 1230, Loss: 0.0003441265143919736\n",
      "Iteration 1240, Loss: 0.00029797496972605586\n",
      "Iteration 1250, Loss: 0.0003237330529373139\n",
      "Iteration 1260, Loss: 0.00032399644260294735\n",
      "Iteration 1270, Loss: 0.0003361032286193222\n",
      "Iteration 1280, Loss: 0.0003560712793841958\n",
      "Iteration 1290, Loss: 0.0003663376846816391\n",
      "Iteration 1300, Loss: 0.0003059878363274038\n",
      "Iteration 1310, Loss: 0.0006598234176635742\n",
      "Iteration 1320, Loss: 0.00031854890403337777\n",
      "Iteration 1330, Loss: 0.0004301802546251565\n",
      "Iteration 1340, Loss: 0.0002831696765497327\n",
      "Iteration 1350, Loss: 0.000509173609316349\n",
      "Iteration 1360, Loss: 0.00036411421024240553\n",
      "Iteration 1370, Loss: 0.0002925022563431412\n",
      "Iteration 1380, Loss: 0.00044325372437015176\n",
      "Iteration 1390, Loss: 0.00034618782228790224\n",
      "Iteration 1400, Loss: 0.0003480880695860833\n",
      "Iteration 1410, Loss: 0.0006123695056885481\n",
      "Iteration 1420, Loss: 0.00037975655868649483\n",
      "Iteration 1430, Loss: 0.000328887312207371\n",
      "Iteration 1440, Loss: 0.0003865516046062112\n",
      "Iteration 1450, Loss: 0.00026406123652122915\n",
      "Iteration 1460, Loss: 0.0002930844493675977\n",
      "Iteration 1470, Loss: 0.000249008386163041\n",
      "Iteration 1480, Loss: 0.00024498740094713867\n",
      "Iteration 1490, Loss: 0.00028077044407837093\n",
      "Iteration 1500, Loss: 0.00023472614702768624\n",
      "Iteration 1510, Loss: 0.0002890171599574387\n",
      "Iteration 1520, Loss: 0.00024323219258803874\n",
      "Iteration 1530, Loss: 0.00028512050630524755\n",
      "Iteration 1540, Loss: 0.0003386557218618691\n",
      "Iteration 1550, Loss: 0.0003086270298808813\n",
      "Iteration 1560, Loss: 0.0006298919906839728\n",
      "Iteration 1570, Loss: 0.00026150469784624875\n",
      "Iteration 1580, Loss: 0.00030180509202182293\n",
      "Iteration 1590, Loss: 0.00042046300950460136\n",
      "Iteration 1600, Loss: 0.000259287073276937\n",
      "Iteration 1610, Loss: 0.0002675386785995215\n",
      "Iteration 1620, Loss: 0.0005581044824793935\n",
      "Iteration 1630, Loss: 0.0004190532199572772\n",
      "Iteration 1640, Loss: 0.0002723892976064235\n",
      "Iteration 1650, Loss: 0.00022396509302780032\n",
      "Iteration 1660, Loss: 0.0002907326852437109\n",
      "Iteration 1670, Loss: 0.0003166791284456849\n",
      "Iteration 1680, Loss: 0.0002727376704569906\n",
      "Iteration 1690, Loss: 0.00023150820925366133\n",
      "Iteration 1700, Loss: 0.0002489692997187376\n",
      "Iteration 1710, Loss: 0.00021664396626874804\n",
      "Iteration 1720, Loss: 0.0002886759175453335\n",
      "Iteration 1730, Loss: 0.00020706627401523292\n",
      "Iteration 1740, Loss: 0.00023070073802955449\n",
      "Iteration 1750, Loss: 0.0002504786243662238\n",
      "Iteration 1760, Loss: 0.00020047673024237156\n",
      "Iteration 1770, Loss: 0.00024326426500920206\n",
      "Iteration 1780, Loss: 0.00022554075985681266\n",
      "Iteration 1790, Loss: 0.0010115575278177857\n",
      "Iteration 1800, Loss: 0.0003973417333327234\n",
      "Iteration 1810, Loss: 0.00021751328313257545\n",
      "Iteration 1820, Loss: 0.0002161491574952379\n",
      "Iteration 1830, Loss: 0.00018995048594661057\n",
      "Iteration 1840, Loss: 0.0002046843437710777\n",
      "Iteration 1850, Loss: 0.00018290943989995867\n",
      "Iteration 1860, Loss: 0.0002325903478777036\n",
      "Iteration 1870, Loss: 0.0005054246867075562\n",
      "Iteration 1880, Loss: 0.0002986443287227303\n",
      "Iteration 1890, Loss: 0.0001769375376170501\n",
      "Iteration 1900, Loss: 0.0002221374015789479\n",
      "Iteration 1910, Loss: 0.00019378491560928524\n",
      "Iteration 1920, Loss: 0.00033966547925956547\n",
      "Iteration 1930, Loss: 0.00020972009224351496\n",
      "Iteration 1940, Loss: 0.0001748129288898781\n",
      "Iteration 1950, Loss: 0.00018300152441952378\n",
      "Iteration 1960, Loss: 0.0002219815069111064\n",
      "Iteration 1970, Loss: 0.00022119942877907306\n",
      "Iteration 1980, Loss: 0.00016330012294929475\n",
      "Iteration 1990, Loss: 0.0002265020302729681\n",
      "Iteration 2000, Loss: 0.00018989613454323262\n",
      "Iteration 2010, Loss: 0.00019828071526717395\n",
      "Iteration 2020, Loss: 0.0001766135246725753\n",
      "Iteration 2030, Loss: 0.00019321625586599112\n",
      "Iteration 2040, Loss: 0.0002555950195528567\n",
      "Iteration 2050, Loss: 0.00021394126815721393\n",
      "Iteration 2060, Loss: 0.00016261405835393816\n",
      "Iteration 2070, Loss: 0.0001626608573133126\n",
      "Iteration 2080, Loss: 0.00019774874090217054\n",
      "Iteration 2090, Loss: 0.00016143031825777143\n",
      "Iteration 2100, Loss: 0.00021337888028938323\n",
      "Iteration 2110, Loss: 0.0009446330368518829\n",
      "Iteration 2120, Loss: 0.00018434169760439545\n",
      "Iteration 2130, Loss: 0.00020614525419659913\n",
      "Iteration 2140, Loss: 0.00014947772433515638\n",
      "Iteration 2150, Loss: 0.00023040529049467295\n",
      "Iteration 2160, Loss: 0.00020814931485801935\n",
      "Iteration 2170, Loss: 0.000253796752076596\n",
      "Iteration 2180, Loss: 0.00028103316435590386\n",
      "Iteration 2190, Loss: 0.0001637312670936808\n",
      "Iteration 2200, Loss: 0.00015644190716557205\n",
      "Iteration 2210, Loss: 0.00019368231005501002\n",
      "Iteration 2220, Loss: 0.0002602656022645533\n",
      "Iteration 2230, Loss: 0.00018272041052114218\n",
      "Iteration 2240, Loss: 0.00025072903372347355\n",
      "Iteration 2250, Loss: 0.00016922794748097658\n",
      "Iteration 2260, Loss: 0.000202564726350829\n",
      "Iteration 2270, Loss: 0.00014101901615504175\n",
      "Iteration 2280, Loss: 0.0002442880650050938\n",
      "Iteration 2290, Loss: 0.00014265278878156096\n",
      "Iteration 2300, Loss: 0.0003040770534425974\n",
      "Iteration 2310, Loss: 0.00021035376994404942\n",
      "Iteration 2320, Loss: 0.00023214529210235924\n",
      "Iteration 2330, Loss: 0.00018035792163573205\n",
      "Iteration 2340, Loss: 0.0001739032013574615\n",
      "Iteration 2350, Loss: 0.00016303987649735063\n",
      "Iteration 2360, Loss: 0.00014103026478551328\n",
      "Iteration 2370, Loss: 0.00023636719561181962\n",
      "Iteration 2380, Loss: 0.00017309471149928868\n",
      "Iteration 2390, Loss: 0.0001556220668135211\n",
      "Iteration 2400, Loss: 0.00016471052367705852\n",
      "Iteration 2410, Loss: 0.00017675975686870515\n",
      "Iteration 2420, Loss: 0.00014806140097789466\n",
      "Iteration 2430, Loss: 0.00024344833218492568\n",
      "Iteration 2440, Loss: 0.00021820730762556195\n",
      "Iteration 2450, Loss: 0.00022982114751357585\n",
      "Iteration 2460, Loss: 0.00041331566171720624\n",
      "Iteration 2470, Loss: 0.00017298941384069622\n",
      "Iteration 2480, Loss: 0.00014629853831138462\n",
      "Iteration 2490, Loss: 0.0001435843005310744\n",
      "Iteration 2500, Loss: 0.00012954307021573186\n",
      "Iteration 2510, Loss: 0.00013717431284021586\n",
      "Iteration 2520, Loss: 0.00016223275451920927\n",
      "Iteration 2530, Loss: 0.00021448284678626806\n",
      "Iteration 2540, Loss: 0.00014254111738409847\n",
      "Iteration 2550, Loss: 0.00013596794451586902\n",
      "Iteration 2560, Loss: 0.00014381087385118008\n",
      "Iteration 2570, Loss: 0.0001367920485790819\n",
      "Iteration 2580, Loss: 0.00015578462625853717\n",
      "Iteration 2590, Loss: 0.0001375693827867508\n",
      "Iteration 2600, Loss: 0.00027882406720891595\n",
      "Iteration 2610, Loss: 0.00016327555931638926\n",
      "Iteration 2620, Loss: 0.00013345733168534935\n",
      "Iteration 2630, Loss: 0.00013152603060007095\n",
      "Iteration 2640, Loss: 0.0002503800787962973\n",
      "Iteration 2650, Loss: 0.00017453670443501323\n",
      "Iteration 2660, Loss: 0.0002117362746503204\n",
      "Iteration 2670, Loss: 0.0001633161009522155\n",
      "Iteration 2680, Loss: 0.00022700692352373153\n",
      "Iteration 2690, Loss: 0.00013792765093967319\n",
      "Iteration 2700, Loss: 0.00013761162699665874\n",
      "Iteration 2710, Loss: 0.00014234734408091754\n",
      "Iteration 2720, Loss: 0.00020921438408549875\n",
      "Iteration 2730, Loss: 0.0001098745851777494\n",
      "Iteration 2740, Loss: 0.0001280905125895515\n",
      "Iteration 2750, Loss: 0.00014670711243525147\n",
      "Iteration 2760, Loss: 0.0001291259250137955\n",
      "Iteration 2770, Loss: 0.00013899225450586528\n",
      "Iteration 2780, Loss: 0.00013598124496638775\n",
      "Iteration 2790, Loss: 0.00016440756735391915\n",
      "Iteration 2800, Loss: 0.00013510941062122583\n",
      "Iteration 2810, Loss: 0.000269506563199684\n",
      "Iteration 2820, Loss: 0.0002441879187244922\n",
      "Iteration 2830, Loss: 0.00018525414634495974\n",
      "Iteration 2840, Loss: 0.0001391061960021034\n",
      "Iteration 2850, Loss: 0.0001250954665010795\n",
      "Iteration 2860, Loss: 0.00011726524098776281\n",
      "Iteration 2870, Loss: 0.0001366156357107684\n",
      "Iteration 2880, Loss: 0.0005420512752607465\n",
      "Iteration 2890, Loss: 0.00012678219354711473\n",
      "Iteration 2900, Loss: 0.00011996933608315885\n",
      "Iteration 2910, Loss: 0.00014584527525585145\n",
      "Iteration 2920, Loss: 0.00013293213851284236\n",
      "Iteration 2930, Loss: 0.00012004464224446565\n",
      "Iteration 2940, Loss: 0.00010761566227301955\n",
      "Iteration 2950, Loss: 0.00018403037392999977\n",
      "Iteration 2960, Loss: 0.00012718491780105978\n",
      "Iteration 2970, Loss: 0.00011567562614800408\n",
      "Iteration 2980, Loss: 0.0001251468202099204\n",
      "Iteration 2990, Loss: 0.00013156259956303984\n",
      "Iteration 3000, Loss: 0.00013194054190535098\n",
      "Iteration 3010, Loss: 0.0002688877284526825\n",
      "Iteration 3020, Loss: 0.00018607258971314877\n",
      "Iteration 3030, Loss: 0.00011649170482996851\n",
      "Iteration 3040, Loss: 0.00020763323118444532\n",
      "Iteration 3050, Loss: 0.0001252626971108839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  58%|█████▊    | 14/24 [01:52<02:09, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3060, Loss: 0.00014848003047518432\n",
      "Iteration 3070, Loss: 0.00017199960711877793\n",
      "Stopping early at iteration 3073\n",
      "{'Model': 'PINN base', 'Total_Iterations': 3074, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.014039687751893178, 'L2_avg': 0.020160943662283916, 'End_point_L1_avg': 0.006084173867123935, 'End_point_L2_avg': 0.006208058089692518}\n",
      "Iteration 0, Loss: 0.9223606586456299\n",
      "Iteration 10, Loss: 0.31296834349632263\n",
      "Iteration 20, Loss: 0.12392761558294296\n",
      "Iteration 30, Loss: 0.06712165474891663\n",
      "Iteration 40, Loss: 0.03325413912534714\n",
      "Iteration 50, Loss: 0.015403542667627335\n",
      "Iteration 60, Loss: 0.0074226148426532745\n",
      "Iteration 70, Loss: 0.00633311877027154\n",
      "Iteration 80, Loss: 0.004805744159966707\n",
      "Iteration 90, Loss: 0.003836805233731866\n",
      "Iteration 100, Loss: 0.0034480157773941755\n",
      "Iteration 110, Loss: 0.0031470858957618475\n",
      "Iteration 120, Loss: 0.0027516812551766634\n",
      "Iteration 130, Loss: 0.0027243925724178553\n",
      "Iteration 140, Loss: 0.0024977840948849916\n",
      "Iteration 150, Loss: 0.002251861384138465\n",
      "Iteration 160, Loss: 0.0020384546369314194\n",
      "Iteration 170, Loss: 0.0018990430980920792\n",
      "Iteration 180, Loss: 0.001949072116985917\n",
      "Iteration 190, Loss: 0.0016935983439907432\n",
      "Iteration 200, Loss: 0.0018441202118992805\n",
      "Iteration 210, Loss: 0.0015944705810397863\n",
      "Iteration 220, Loss: 0.0015675571048632264\n",
      "Iteration 230, Loss: 0.001512981136329472\n",
      "Iteration 240, Loss: 0.0013742967275902629\n",
      "Iteration 250, Loss: 0.0013927955878898501\n",
      "Iteration 260, Loss: 0.001418223837390542\n",
      "Iteration 270, Loss: 0.0012807240709662437\n",
      "Iteration 280, Loss: 0.001182104810141027\n",
      "Iteration 290, Loss: 0.0011976256500929594\n",
      "Iteration 300, Loss: 0.0011086559388786554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  62%|██████▎   | 15/24 [01:56<01:31, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310, Loss: 0.001077095279470086\n",
      "Stopping early at iteration 318\n",
      "{'Model': 'PINN base', 'Total_Iterations': 319, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04362103103161312, 'L2_avg': 0.05735985687887651, 'End_point_L1_avg': 0.02244109841586909, 'End_point_L2_avg': 0.023747747603048496}\n",
      "Iteration 0, Loss: 1.1029342412948608\n",
      "Iteration 10, Loss: 0.3993379473686218\n",
      "Iteration 20, Loss: 0.1451781988143921\n",
      "Iteration 30, Loss: 0.07607603073120117\n",
      "Iteration 40, Loss: 0.04643559455871582\n",
      "Iteration 50, Loss: 0.017420880496501923\n",
      "Iteration 60, Loss: 0.011506645940244198\n",
      "Iteration 70, Loss: 0.0065798331052064896\n",
      "Iteration 80, Loss: 0.005511840805411339\n",
      "Iteration 90, Loss: 0.004489248618483543\n",
      "Iteration 100, Loss: 0.003724884008988738\n",
      "Iteration 110, Loss: 0.003416267689317465\n",
      "Iteration 120, Loss: 0.0029744072817265987\n",
      "Iteration 130, Loss: 0.0028026208747178316\n",
      "Iteration 140, Loss: 0.0025284206494688988\n",
      "Iteration 150, Loss: 0.002373224589973688\n",
      "Iteration 160, Loss: 0.0022588942665606737\n",
      "Iteration 170, Loss: 0.002088027773424983\n",
      "Iteration 180, Loss: 0.0022000866010785103\n",
      "Iteration 190, Loss: 0.0018728028517216444\n",
      "Iteration 200, Loss: 0.0018411726923659444\n",
      "Iteration 210, Loss: 0.0016232504276558757\n",
      "Iteration 220, Loss: 0.0016822147881612182\n",
      "Iteration 230, Loss: 0.001575347501784563\n",
      "Iteration 240, Loss: 0.0015121527248993516\n",
      "Iteration 250, Loss: 0.0013989227591082454\n",
      "Iteration 260, Loss: 0.0011854942422360182\n",
      "Iteration 270, Loss: 0.0012156906304880977\n",
      "Iteration 280, Loss: 0.0013599572703242302\n",
      "Iteration 290, Loss: 0.0011532058706507087\n",
      "Iteration 300, Loss: 0.0012905779294669628\n",
      "Iteration 310, Loss: 0.0010669809998944402\n",
      "Iteration 320, Loss: 0.0010548298014327884\n",
      "Iteration 330, Loss: 0.0010303233284503222\n",
      "Iteration 340, Loss: 0.0009737964137457311\n",
      "Iteration 350, Loss: 0.000994711765088141\n",
      "Iteration 360, Loss: 0.0009030551300384104\n",
      "Iteration 370, Loss: 0.0009200340718962252\n",
      "Iteration 380, Loss: 0.001111463876441121\n",
      "Iteration 390, Loss: 0.000800682173576206\n",
      "Iteration 400, Loss: 0.0008458935772068799\n",
      "Iteration 410, Loss: 0.0007953755557537079\n",
      "Iteration 420, Loss: 0.0007948247948661447\n",
      "Iteration 430, Loss: 0.0007028596010059118\n",
      "Iteration 440, Loss: 0.0010359607404097915\n",
      "Iteration 450, Loss: 0.0008267267257906497\n",
      "Iteration 460, Loss: 0.0007767527713440359\n",
      "Iteration 470, Loss: 0.0006481503369286656\n",
      "Iteration 480, Loss: 0.0006430893554352224\n",
      "Iteration 490, Loss: 0.0006930807139724493\n",
      "Iteration 500, Loss: 0.0006544615025632083\n",
      "Iteration 510, Loss: 0.0005585954640991986\n",
      "Iteration 520, Loss: 0.0006063322653062642\n",
      "Iteration 530, Loss: 0.0005554397357627749\n",
      "Iteration 540, Loss: 0.0004996550269424915\n",
      "Iteration 550, Loss: 0.0004969954607076943\n",
      "Iteration 560, Loss: 0.0005681714974343777\n",
      "Iteration 570, Loss: 0.0005007851868867874\n",
      "Iteration 580, Loss: 0.00046780414413660765\n",
      "Iteration 590, Loss: 0.0004515970649663359\n",
      "Iteration 600, Loss: 0.0004661641432903707\n",
      "Iteration 610, Loss: 0.00043842796003445983\n",
      "Iteration 620, Loss: 0.0004138757358305156\n",
      "Iteration 630, Loss: 0.0003865427279379219\n",
      "Iteration 640, Loss: 0.0005148019408807158\n",
      "Iteration 650, Loss: 0.00037741687265224755\n",
      "Iteration 660, Loss: 0.0003676194464787841\n",
      "Iteration 670, Loss: 0.00037052444531582296\n",
      "Iteration 680, Loss: 0.0004049153649248183\n",
      "Iteration 690, Loss: 0.0003349950129631907\n",
      "Iteration 700, Loss: 0.00038954155752435327\n",
      "Iteration 710, Loss: 0.00032281960011459887\n",
      "Iteration 720, Loss: 0.0003609930572565645\n",
      "Iteration 730, Loss: 0.00031417611171491444\n",
      "Iteration 740, Loss: 0.00033744837855920196\n",
      "Iteration 750, Loss: 0.00028371589723974466\n",
      "Iteration 760, Loss: 0.00046205331454984844\n",
      "Iteration 770, Loss: 0.0004458247567526996\n",
      "Iteration 780, Loss: 0.00044396662269718945\n",
      "Iteration 790, Loss: 0.0002778677735477686\n",
      "Iteration 800, Loss: 0.0002718399919103831\n",
      "Iteration 810, Loss: 0.0003178090846631676\n",
      "Iteration 820, Loss: 0.00024699544883333147\n",
      "Iteration 830, Loss: 0.00040342030115425587\n",
      "Iteration 840, Loss: 0.00025260730762965977\n",
      "Iteration 850, Loss: 0.0002645256754476577\n",
      "Iteration 860, Loss: 0.00024523373576812446\n",
      "Iteration 870, Loss: 0.00023189072089735419\n",
      "Iteration 880, Loss: 0.00023081275867298245\n",
      "Iteration 890, Loss: 0.0002307989343535155\n",
      "Iteration 900, Loss: 0.00039199096499942243\n",
      "Iteration 910, Loss: 0.00027057528495788574\n",
      "Iteration 920, Loss: 0.00026243028696626425\n",
      "Iteration 930, Loss: 0.0002245523064630106\n",
      "Iteration 940, Loss: 0.0001997090148506686\n",
      "Iteration 950, Loss: 0.0002457145892549306\n",
      "Iteration 960, Loss: 0.00022299980628304183\n",
      "Iteration 970, Loss: 0.0002192559913964942\n",
      "Iteration 980, Loss: 0.00046622470836155117\n",
      "Iteration 990, Loss: 0.0001994964841287583\n",
      "Iteration 1000, Loss: 0.0002063139108940959\n",
      "Iteration 1010, Loss: 0.0002116487012244761\n",
      "Iteration 1020, Loss: 0.00018550798995420337\n",
      "Iteration 1030, Loss: 0.00017378876509610564\n",
      "Iteration 1040, Loss: 0.0006522960611619055\n",
      "Iteration 1050, Loss: 0.00026723937480710447\n",
      "Iteration 1060, Loss: 0.00019452245032880455\n",
      "Iteration 1070, Loss: 0.00017438713985029608\n",
      "Iteration 1080, Loss: 0.00020220497390255332\n",
      "Iteration 1090, Loss: 0.0001667939213803038\n",
      "Iteration 1100, Loss: 0.0001654958468861878\n",
      "Iteration 1110, Loss: 0.00017327391833532602\n",
      "Iteration 1120, Loss: 0.00021176267182454467\n",
      "Iteration 1130, Loss: 0.0009067545179277658\n",
      "Iteration 1140, Loss: 0.000294026656774804\n",
      "Iteration 1150, Loss: 0.0001933391613420099\n",
      "Iteration 1160, Loss: 0.00015764545241836458\n",
      "Iteration 1170, Loss: 0.00014763740182388574\n",
      "Iteration 1180, Loss: 0.0001450370909878984\n",
      "Iteration 1190, Loss: 0.0001548715663375333\n",
      "Iteration 1200, Loss: 0.00013482414942700416\n",
      "Iteration 1210, Loss: 0.0001851468114182353\n",
      "Iteration 1220, Loss: 0.00014415245095733553\n",
      "Iteration 1230, Loss: 0.00013883435167372227\n",
      "Iteration 1240, Loss: 0.00041289758519269526\n",
      "Iteration 1250, Loss: 0.00012871921353507787\n",
      "Iteration 1260, Loss: 0.00012909775250591338\n",
      "Iteration 1270, Loss: 0.0001247273467015475\n",
      "Iteration 1280, Loss: 0.00012720974336843938\n",
      "Iteration 1290, Loss: 0.00016051596321631223\n",
      "Iteration 1300, Loss: 0.00011625027400441468\n",
      "Iteration 1310, Loss: 0.0002439402014715597\n",
      "Iteration 1320, Loss: 0.00044473446905612946\n",
      "Iteration 1330, Loss: 0.0001693276863079518\n",
      "Iteration 1340, Loss: 0.0001333530235569924\n",
      "Iteration 1350, Loss: 0.00014245542115531862\n",
      "Iteration 1360, Loss: 0.00011245772475376725\n",
      "Iteration 1370, Loss: 0.00011827053094748408\n",
      "Iteration 1380, Loss: 0.00014856683264952153\n",
      "Iteration 1390, Loss: 0.0006368050235323608\n",
      "Iteration 1400, Loss: 0.000292025477392599\n",
      "Iteration 1410, Loss: 0.00013107007544022053\n",
      "Iteration 1420, Loss: 0.00011181490117451176\n",
      "Iteration 1430, Loss: 0.00012375398364383727\n",
      "Iteration 1440, Loss: 0.0001546491839690134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  67%|██████▋   | 16/24 [02:12<01:35, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1450, Loss: 0.0001185299115604721\n",
      "Stopping early at iteration 1459\n",
      "{'Model': 'PINN base', 'Total_Iterations': 1460, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.013336002832071259, 'L2_avg': 0.016985480706446808, 'End_point_L1_avg': 0.008242430658840547, 'End_point_L2_avg': 0.009164752800138315}\n",
      "Iteration 0, Loss: 0.8480257391929626\n",
      "Iteration 10, Loss: 0.1188659593462944\n",
      "Iteration 20, Loss: 0.02105659805238247\n",
      "Iteration 30, Loss: 0.011682936921715736\n",
      "Iteration 40, Loss: 0.00625803554430604\n",
      "Iteration 50, Loss: 0.003189314156770706\n",
      "Iteration 60, Loss: 0.002482958370819688\n",
      "Iteration 70, Loss: 0.0022225347347557545\n",
      "Iteration 80, Loss: 0.0022740422282367945\n",
      "Iteration 90, Loss: 0.003657738910987973\n",
      "Iteration 100, Loss: 0.0014380551874637604\n",
      "Iteration 110, Loss: 0.0010737382108345628\n",
      "Stopping early at iteration 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  71%|███████   | 17/24 [02:13<01:01,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 113, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.036545220494533, 'L2_avg': 0.0506480405475636, 'End_point_L1_avg': 0.01216431192139446, 'End_point_L2_avg': 0.01418362982631145}\n",
      "Iteration 0, Loss: 1.1268287897109985\n",
      "Iteration 10, Loss: 0.12608517706394196\n",
      "Iteration 20, Loss: 0.04808434098958969\n",
      "Iteration 30, Loss: 0.013688476756215096\n",
      "Iteration 40, Loss: 0.0057247052900493145\n",
      "Iteration 50, Loss: 0.0030752853490412235\n",
      "Iteration 60, Loss: 0.002055591205134988\n",
      "Iteration 70, Loss: 0.004258433356881142\n",
      "Iteration 80, Loss: 0.003570079104974866\n",
      "Iteration 90, Loss: 0.0016123342793434858\n",
      "Iteration 100, Loss: 0.0012284936383366585\n",
      "Iteration 110, Loss: 0.0009753720369189978\n",
      "Iteration 120, Loss: 0.0007843099883757532\n",
      "Iteration 130, Loss: 0.0005298159085214138\n",
      "Iteration 140, Loss: 0.003654438303783536\n",
      "Iteration 150, Loss: 0.0015074772527441382\n",
      "Iteration 160, Loss: 0.00044057692866772413\n",
      "Iteration 170, Loss: 0.0006103257182985544\n",
      "Iteration 180, Loss: 0.00048443450941704214\n",
      "Iteration 190, Loss: 0.002113745780661702\n",
      "Iteration 200, Loss: 0.0004974910407327116\n",
      "Iteration 210, Loss: 0.00035568661405704916\n",
      "Iteration 220, Loss: 0.0006085504428483546\n",
      "Iteration 230, Loss: 0.00042245452641509473\n",
      "Iteration 240, Loss: 0.0006580005283467472\n",
      "Iteration 250, Loss: 0.0003740706597454846\n",
      "Iteration 260, Loss: 0.00025912781711667776\n",
      "Iteration 270, Loss: 0.0005845716223120689\n",
      "Iteration 280, Loss: 0.00021519861184060574\n",
      "Iteration 290, Loss: 0.0002874086203519255\n",
      "Iteration 300, Loss: 0.000184396660188213\n",
      "Iteration 310, Loss: 0.00037920736940577626\n",
      "Iteration 320, Loss: 0.0021895754616707563\n",
      "Iteration 330, Loss: 0.0009452727972529829\n",
      "Iteration 340, Loss: 0.0004101120575796813\n",
      "Iteration 350, Loss: 0.00025442882906645536\n",
      "Iteration 360, Loss: 0.0004068674170412123\n",
      "Iteration 370, Loss: 0.0001497709017712623\n",
      "Iteration 380, Loss: 0.0001694351522019133\n",
      "Iteration 390, Loss: 0.00010767623462015763\n",
      "Stopping early at iteration 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  75%|███████▌  | 18/24 [02:18<00:44,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 394, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013897552414401467, 'L2_avg': 0.018201749996725573, 'End_point_L1_avg': 0.0073514254257257905, 'End_point_L2_avg': 0.008006604507429661}\n",
      "Iteration 0, Loss: 1.0153157711029053\n",
      "Iteration 10, Loss: 0.13706770539283752\n",
      "Iteration 20, Loss: 0.03040597029030323\n",
      "Iteration 30, Loss: 0.00986047089099884\n",
      "Iteration 40, Loss: 0.004996926989406347\n",
      "Iteration 50, Loss: 0.0028202137909829617\n",
      "Iteration 60, Loss: 0.0024490919895470142\n",
      "Iteration 70, Loss: 0.001910285442136228\n",
      "Iteration 80, Loss: 0.0017195340478792787\n",
      "Iteration 90, Loss: 0.0019299848936498165\n",
      "Iteration 100, Loss: 0.0011485576396808028\n",
      "Iteration 110, Loss: 0.003770385403186083\n",
      "Stopping early at iteration 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  79%|███████▉  | 19/24 [02:19<00:28,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 116, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.036410130775533595, 'L2_avg': 0.053240161795272106, 'End_point_L1_avg': 0.007505669751965411, 'End_point_L2_avg': 0.007549116296908318}\n",
      "Iteration 0, Loss: 1.1139147281646729\n",
      "Iteration 10, Loss: 0.14394937455654144\n",
      "Iteration 20, Loss: 0.025288203731179237\n",
      "Iteration 30, Loss: 0.007630638778209686\n",
      "Iteration 40, Loss: 0.012693304568529129\n",
      "Iteration 50, Loss: 0.003321973141282797\n",
      "Iteration 60, Loss: 0.003331393003463745\n",
      "Iteration 70, Loss: 0.001344277523458004\n",
      "Iteration 80, Loss: 0.0008964302251115441\n",
      "Iteration 90, Loss: 0.0009256731136702001\n",
      "Iteration 100, Loss: 0.0005306760431267321\n",
      "Iteration 110, Loss: 0.010855055414140224\n",
      "Iteration 120, Loss: 0.002135468414053321\n",
      "Iteration 130, Loss: 0.0007660018163733184\n",
      "Iteration 140, Loss: 0.0009032075759023428\n",
      "Iteration 150, Loss: 0.00043758240644820035\n",
      "Iteration 160, Loss: 0.0003248425491619855\n",
      "Iteration 170, Loss: 0.0003421188739594072\n",
      "Iteration 180, Loss: 0.0002599948493298143\n",
      "Iteration 190, Loss: 0.0003631899890024215\n",
      "Iteration 200, Loss: 0.0005533149233087897\n",
      "Iteration 210, Loss: 0.001143968547694385\n",
      "Iteration 220, Loss: 0.0003594159206841141\n",
      "Iteration 230, Loss: 0.00024418195243924856\n",
      "Iteration 240, Loss: 0.0002242975024273619\n",
      "Iteration 250, Loss: 0.00016592921747360379\n",
      "Iteration 260, Loss: 0.00019077544857282192\n",
      "Iteration 270, Loss: 0.004644707310944796\n",
      "Iteration 280, Loss: 0.0002369561407249421\n",
      "Iteration 290, Loss: 0.00035529190790839493\n",
      "Iteration 300, Loss: 0.0003134007565677166\n",
      "Iteration 310, Loss: 0.00014730473048985004\n",
      "Iteration 320, Loss: 0.00017075157666113228\n",
      "Iteration 330, Loss: 0.0015371966874226928\n",
      "Iteration 340, Loss: 0.00023885325936134905\n",
      "Iteration 350, Loss: 0.0004834660794585943\n",
      "Iteration 360, Loss: 0.00028421790921129286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  83%|████████▎ | 20/24 [02:24<00:21,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 370, Loss: 0.00011033274495275691\n",
      "Stopping early at iteration 374\n",
      "{'Model': 'PINN base', 'Total_Iterations': 375, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.015225206892519626, 'L2_avg': 0.018126869938485668, 'End_point_L1_avg': 0.013753462532180164, 'End_point_L2_avg': 0.01419404937035584}\n",
      "Iteration 0, Loss: 1.1550471782684326\n",
      "Iteration 10, Loss: 0.4337703585624695\n",
      "Iteration 20, Loss: 0.14183777570724487\n",
      "Iteration 30, Loss: 0.08273079991340637\n",
      "Iteration 40, Loss: 0.051553983241319656\n",
      "Iteration 50, Loss: 0.02798297069966793\n",
      "Iteration 60, Loss: 0.013205510564148426\n",
      "Iteration 70, Loss: 0.009295428171753883\n",
      "Iteration 80, Loss: 0.00756691163405776\n",
      "Iteration 90, Loss: 0.006045439280569553\n",
      "Iteration 100, Loss: 0.005551775451749563\n",
      "Iteration 110, Loss: 0.005458371248096228\n",
      "Iteration 120, Loss: 0.004044636618345976\n",
      "Iteration 130, Loss: 0.0035515010822564363\n",
      "Iteration 140, Loss: 0.003359977388754487\n",
      "Iteration 150, Loss: 0.002639103913679719\n",
      "Iteration 160, Loss: 0.0023434956092387438\n",
      "Iteration 170, Loss: 0.002461794763803482\n",
      "Iteration 180, Loss: 0.0025527598336338997\n",
      "Iteration 190, Loss: 0.0021459036506712437\n",
      "Iteration 200, Loss: 0.002164700534194708\n",
      "Iteration 210, Loss: 0.0018078316934406757\n",
      "Iteration 220, Loss: 0.001940082642249763\n",
      "Iteration 230, Loss: 0.0019097519107162952\n",
      "Iteration 240, Loss: 0.002456231974065304\n",
      "Iteration 250, Loss: 0.0019459109753370285\n",
      "Iteration 260, Loss: 0.001999711152166128\n",
      "Iteration 270, Loss: 0.0017427263082936406\n",
      "Iteration 280, Loss: 0.0015753513434901834\n",
      "Iteration 290, Loss: 0.0013610144378617406\n",
      "Iteration 300, Loss: 0.0017404682002961636\n",
      "Iteration 310, Loss: 0.0014859151560813189\n",
      "Iteration 320, Loss: 0.0013040588237345219\n",
      "Iteration 330, Loss: 0.0012978335143998265\n",
      "Iteration 340, Loss: 0.001418291823938489\n",
      "Iteration 350, Loss: 0.001233249786309898\n",
      "Iteration 360, Loss: 0.0013756441185250878\n",
      "Iteration 370, Loss: 0.0011735454900190234\n",
      "Iteration 380, Loss: 0.0011937512317672372\n",
      "Iteration 390, Loss: 0.001154641155153513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  88%|████████▊ | 21/24 [02:28<00:14,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 399\n",
      "{'Model': 'PINN base', 'Total_Iterations': 400, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.043223934479193364, 'L2_avg': 0.05892234043109964, 'End_point_L1_avg': 0.02364964033068976, 'End_point_L2_avg': 0.024698892406654422}\n",
      "Iteration 0, Loss: 0.8773914575576782\n",
      "Iteration 10, Loss: 0.3590408265590668\n",
      "Iteration 20, Loss: 0.1501871794462204\n",
      "Iteration 30, Loss: 0.09328331053256989\n",
      "Iteration 40, Loss: 0.06760339438915253\n",
      "Iteration 50, Loss: 0.03238951414823532\n",
      "Iteration 60, Loss: 0.026014741510152817\n",
      "Iteration 70, Loss: 0.016076987609267235\n",
      "Iteration 80, Loss: 0.009863754734396935\n",
      "Iteration 90, Loss: 0.009505699388682842\n",
      "Iteration 100, Loss: 0.006138381082564592\n",
      "Iteration 110, Loss: 0.0060755847953259945\n",
      "Iteration 120, Loss: 0.0037107071839272976\n",
      "Iteration 130, Loss: 0.004751408938318491\n",
      "Iteration 140, Loss: 0.003488413756713271\n",
      "Iteration 150, Loss: 0.0035775150172412395\n",
      "Iteration 160, Loss: 0.0032455981709063053\n",
      "Iteration 170, Loss: 0.0034257392399013042\n",
      "Iteration 180, Loss: 0.0035794649738818407\n",
      "Iteration 190, Loss: 0.0027861646376550198\n",
      "Iteration 200, Loss: 0.0026878584176301956\n",
      "Iteration 210, Loss: 0.0023659844882786274\n",
      "Iteration 220, Loss: 0.0026926016435027122\n",
      "Iteration 230, Loss: 0.0025530573911964893\n",
      "Iteration 240, Loss: 0.0020783126819878817\n",
      "Iteration 250, Loss: 0.002177454764023423\n",
      "Iteration 260, Loss: 0.0020550377666950226\n",
      "Iteration 270, Loss: 0.002062608255073428\n",
      "Iteration 280, Loss: 0.0021604893263429403\n",
      "Iteration 290, Loss: 0.0019111557630822062\n",
      "Iteration 300, Loss: 0.0013363988837227225\n",
      "Iteration 310, Loss: 0.0015111756511032581\n",
      "Iteration 320, Loss: 0.001510533969849348\n",
      "Iteration 330, Loss: 0.0014005927368998528\n",
      "Iteration 340, Loss: 0.001462128828279674\n",
      "Iteration 350, Loss: 0.0012210154673084617\n",
      "Iteration 360, Loss: 0.0011317573953419924\n",
      "Iteration 370, Loss: 0.0012437300756573677\n",
      "Iteration 380, Loss: 0.0010443802457302809\n",
      "Iteration 390, Loss: 0.0012012951774522662\n",
      "Iteration 400, Loss: 0.0014144200831651688\n",
      "Iteration 410, Loss: 0.0009374144719913602\n",
      "Iteration 420, Loss: 0.0009855518583208323\n",
      "Iteration 430, Loss: 0.0013186585856601596\n",
      "Iteration 440, Loss: 0.0008240414899773896\n",
      "Iteration 450, Loss: 0.0009698883513920009\n",
      "Iteration 460, Loss: 0.0010349358199164271\n",
      "Iteration 470, Loss: 0.0007869637338444591\n",
      "Iteration 480, Loss: 0.0009517305297777057\n",
      "Iteration 490, Loss: 0.0010065532987937331\n",
      "Iteration 500, Loss: 0.0007428621756844223\n",
      "Iteration 510, Loss: 0.0006283053662627935\n",
      "Iteration 520, Loss: 0.0005707156960852444\n",
      "Iteration 530, Loss: 0.0006355432560667396\n",
      "Iteration 540, Loss: 0.0006417706026695669\n",
      "Iteration 550, Loss: 0.0005999088753014803\n",
      "Iteration 560, Loss: 0.0005931095220148563\n",
      "Iteration 570, Loss: 0.000567494542337954\n",
      "Iteration 580, Loss: 0.001210266724228859\n",
      "Iteration 590, Loss: 0.0005713529535569251\n",
      "Iteration 600, Loss: 0.0007586374413222075\n",
      "Iteration 610, Loss: 0.0008267444791272283\n",
      "Iteration 620, Loss: 0.0004996818606741726\n",
      "Iteration 630, Loss: 0.0005172189557924867\n",
      "Iteration 640, Loss: 0.0005162787274457514\n",
      "Iteration 650, Loss: 0.00044042032095603645\n",
      "Iteration 660, Loss: 0.0004323394678067416\n",
      "Iteration 670, Loss: 0.00045981319271959364\n",
      "Iteration 680, Loss: 0.0005926127196289599\n",
      "Iteration 690, Loss: 0.0005740199121646583\n",
      "Iteration 700, Loss: 0.000566934235394001\n",
      "Iteration 710, Loss: 0.0005647170473821461\n",
      "Iteration 720, Loss: 0.0004785332712344825\n",
      "Iteration 730, Loss: 0.0004489652637857944\n",
      "Iteration 740, Loss: 0.0003677309141494334\n",
      "Iteration 750, Loss: 0.0004999882658012211\n",
      "Iteration 760, Loss: 0.0005085740704089403\n",
      "Iteration 770, Loss: 0.0006303897243924439\n",
      "Iteration 780, Loss: 0.0006476477137766778\n",
      "Iteration 790, Loss: 0.00044556628563441336\n",
      "Iteration 800, Loss: 0.0004710980283562094\n",
      "Iteration 810, Loss: 0.0005177604034543037\n",
      "Iteration 820, Loss: 0.0003539655590429902\n",
      "Iteration 830, Loss: 0.00033171006361953914\n",
      "Iteration 840, Loss: 0.00041101325768977404\n",
      "Iteration 850, Loss: 0.0005995636456646025\n",
      "Iteration 860, Loss: 0.00027395287179388106\n",
      "Iteration 870, Loss: 0.0003631047438830137\n",
      "Iteration 880, Loss: 0.0002899573592003435\n",
      "Iteration 890, Loss: 0.00029268956859596074\n",
      "Iteration 900, Loss: 0.00027601589681580663\n",
      "Iteration 910, Loss: 0.00033643926144577563\n",
      "Iteration 920, Loss: 0.0009742389083839953\n",
      "Iteration 930, Loss: 0.0006212536245584488\n",
      "Iteration 940, Loss: 0.00037525882362388074\n",
      "Iteration 950, Loss: 0.00026758923195302486\n",
      "Iteration 960, Loss: 0.00023678889556322247\n",
      "Iteration 970, Loss: 0.00028354243841022253\n",
      "Iteration 980, Loss: 0.0002380389196332544\n",
      "Iteration 990, Loss: 0.00022213374904822558\n",
      "Iteration 1000, Loss: 0.00021232981816865504\n",
      "Iteration 1010, Loss: 0.00029109945171512663\n",
      "Iteration 1020, Loss: 0.0002279885666212067\n",
      "Iteration 1030, Loss: 0.00045025747385807335\n",
      "Iteration 1040, Loss: 0.00023995473748072982\n",
      "Iteration 1050, Loss: 0.00021360420214477926\n",
      "Iteration 1060, Loss: 0.0002307466056663543\n",
      "Iteration 1070, Loss: 0.00022191197786014527\n",
      "Iteration 1080, Loss: 0.00022574236209038645\n",
      "Iteration 1090, Loss: 0.0010927215917035937\n",
      "Iteration 1100, Loss: 0.00022077349422033876\n",
      "Iteration 1110, Loss: 0.00034230516757816076\n",
      "Iteration 1120, Loss: 0.00026755424914881587\n",
      "Iteration 1130, Loss: 0.00020641642913687974\n",
      "Iteration 1140, Loss: 0.0001886405807454139\n",
      "Iteration 1150, Loss: 0.0001865599915618077\n",
      "Iteration 1160, Loss: 0.00022940716007724404\n",
      "Iteration 1170, Loss: 0.00018315027409698814\n",
      "Iteration 1180, Loss: 0.00022562008234672248\n",
      "Iteration 1190, Loss: 0.00020514012430794537\n",
      "Iteration 1200, Loss: 0.0006594903534278274\n",
      "Iteration 1210, Loss: 0.00041181358392350376\n",
      "Iteration 1220, Loss: 0.00021289958385750651\n",
      "Iteration 1230, Loss: 0.0002982030273415148\n",
      "Iteration 1240, Loss: 0.0001889896666398272\n",
      "Iteration 1250, Loss: 0.00016627366130705923\n",
      "Iteration 1260, Loss: 0.0002064558066194877\n",
      "Iteration 1270, Loss: 0.00020247937936801463\n",
      "Iteration 1280, Loss: 0.00018063696916215122\n",
      "Iteration 1290, Loss: 0.00017794017912819982\n",
      "Iteration 1300, Loss: 0.0001829924003686756\n",
      "Iteration 1310, Loss: 0.0003739151288755238\n",
      "Iteration 1320, Loss: 0.00016324847820214927\n",
      "Iteration 1330, Loss: 0.0002937314857263118\n",
      "Iteration 1340, Loss: 0.00019998918287456036\n",
      "Iteration 1350, Loss: 0.00015008154150564224\n",
      "Iteration 1360, Loss: 0.00016985110414680094\n",
      "Iteration 1370, Loss: 0.00017200114962179214\n",
      "Iteration 1380, Loss: 0.0003183887165505439\n",
      "Iteration 1390, Loss: 0.0001501257938798517\n",
      "Iteration 1400, Loss: 0.00013674980436917394\n",
      "Iteration 1410, Loss: 0.0001811367692425847\n",
      "Iteration 1420, Loss: 0.0002217592264059931\n",
      "Iteration 1430, Loss: 0.0001487998233642429\n",
      "Iteration 1440, Loss: 0.00023284649068955332\n",
      "Iteration 1450, Loss: 0.00021485076285898685\n",
      "Iteration 1460, Loss: 0.0001442581560695544\n",
      "Iteration 1470, Loss: 0.00020084720745217055\n",
      "Iteration 1480, Loss: 0.00038394200964830816\n",
      "Iteration 1490, Loss: 0.0001455856254324317\n",
      "Iteration 1500, Loss: 0.00012575264554470778\n",
      "Iteration 1510, Loss: 0.00019247019372414798\n",
      "Iteration 1520, Loss: 0.00026859031640924513\n",
      "Iteration 1530, Loss: 0.00014233130787033588\n",
      "Iteration 1540, Loss: 0.0002105558232869953\n",
      "Iteration 1550, Loss: 0.00020374594896566123\n",
      "Iteration 1560, Loss: 0.0001809538807719946\n",
      "Iteration 1570, Loss: 0.00013595135533250868\n",
      "Iteration 1580, Loss: 0.0002846477145794779\n",
      "Iteration 1590, Loss: 0.00033040984999388456\n",
      "Iteration 1600, Loss: 0.0002134484820999205\n",
      "Iteration 1610, Loss: 0.00012367071758490056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  92%|█████████▏| 22/24 [02:45<00:17,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1620, Loss: 9.287037391914055e-05\n",
      "Stopping early at iteration 1620\n",
      "{'Model': 'PINN base', 'Total_Iterations': 1621, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.012850183257220885, 'L2_avg': 0.017534908227602005, 'End_point_L1_avg': 0.0047574523182743874, 'End_point_L2_avg': 0.006162237557794547}\n",
      "Iteration 0, Loss: 1.0092601776123047\n",
      "Iteration 10, Loss: 0.3526291251182556\n",
      "Iteration 20, Loss: 0.15231189131736755\n",
      "Iteration 30, Loss: 0.07389258593320847\n",
      "Iteration 40, Loss: 0.04222983494400978\n",
      "Iteration 50, Loss: 0.020623615011572838\n",
      "Iteration 60, Loss: 0.011641998775303364\n",
      "Iteration 70, Loss: 0.007567984517663717\n",
      "Iteration 80, Loss: 0.00654617790132761\n",
      "Iteration 90, Loss: 0.004870154894888401\n",
      "Iteration 100, Loss: 0.004103368613868952\n",
      "Iteration 110, Loss: 0.003477983409538865\n",
      "Iteration 120, Loss: 0.0030475682578980923\n",
      "Iteration 130, Loss: 0.0029567559249699116\n",
      "Iteration 140, Loss: 0.002693387446925044\n",
      "Iteration 150, Loss: 0.0023220893926918507\n",
      "Iteration 160, Loss: 0.0020936636719852686\n",
      "Iteration 170, Loss: 0.0024264520034193993\n",
      "Iteration 180, Loss: 0.0019487919053062797\n",
      "Iteration 190, Loss: 0.0017965214792639017\n",
      "Iteration 200, Loss: 0.001744336448609829\n",
      "Iteration 210, Loss: 0.001698793494142592\n",
      "Iteration 220, Loss: 0.0023511748295277357\n",
      "Iteration 230, Loss: 0.0020743785426020622\n",
      "Iteration 240, Loss: 0.0014382327208295465\n",
      "Iteration 250, Loss: 0.0016475084703415632\n",
      "Iteration 260, Loss: 0.0014010609593242407\n",
      "Iteration 270, Loss: 0.001379848225042224\n",
      "Iteration 280, Loss: 0.0014003139222040772\n",
      "Iteration 290, Loss: 0.0012831400381401181\n",
      "Iteration 300, Loss: 0.0013738786801695824\n",
      "Iteration 310, Loss: 0.0012166266096755862\n",
      "Iteration 320, Loss: 0.0012366054579615593\n",
      "Iteration 330, Loss: 0.0012162902858108282\n",
      "Iteration 340, Loss: 0.0012649225536733866\n",
      "Iteration 350, Loss: 0.0012002099538221955\n",
      "Iteration 360, Loss: 0.0012681428343057632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  96%|█████████▌| 23/24 [02:50<00:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 370, Loss: 0.001172393560409546\n",
      "Stopping early at iteration 374\n",
      "{'Model': 'PINN base', 'Total_Iterations': 375, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04403195670782756, 'L2_avg': 0.057484999300478165, 'End_point_L1_avg': 0.024679278904217096, 'End_point_L2_avg': 0.02662843087536406}\n",
      "Iteration 0, Loss: 1.0265185832977295\n",
      "Iteration 10, Loss: 0.3727834224700928\n",
      "Iteration 20, Loss: 0.16481170058250427\n",
      "Iteration 30, Loss: 0.06958366185426712\n",
      "Iteration 40, Loss: 0.0398314893245697\n",
      "Iteration 50, Loss: 0.013506503775715828\n",
      "Iteration 60, Loss: 0.008944735862314701\n",
      "Iteration 70, Loss: 0.006029210053384304\n",
      "Iteration 80, Loss: 0.004659382160753012\n",
      "Iteration 90, Loss: 0.0035035305190831423\n",
      "Iteration 100, Loss: 0.0029216576367616653\n",
      "Iteration 110, Loss: 0.0028420526068657637\n",
      "Iteration 120, Loss: 0.0024233972653746605\n",
      "Iteration 130, Loss: 0.0023228945210576057\n",
      "Iteration 140, Loss: 0.0020368462428450584\n",
      "Iteration 150, Loss: 0.0019080637721344829\n",
      "Iteration 160, Loss: 0.001788526657037437\n",
      "Iteration 170, Loss: 0.0016965089598670602\n",
      "Iteration 180, Loss: 0.0016390708042308688\n",
      "Iteration 190, Loss: 0.0014071089681237936\n",
      "Iteration 200, Loss: 0.0013538651401177049\n",
      "Iteration 210, Loss: 0.001336801564320922\n",
      "Iteration 220, Loss: 0.001220629084855318\n",
      "Iteration 230, Loss: 0.0011559901759028435\n",
      "Iteration 240, Loss: 0.001150468597188592\n",
      "Iteration 250, Loss: 0.001024623867124319\n",
      "Iteration 260, Loss: 0.0011809001443907619\n",
      "Iteration 270, Loss: 0.0009620267082937062\n",
      "Iteration 280, Loss: 0.0009490381344221532\n",
      "Iteration 290, Loss: 0.000896934827324003\n",
      "Iteration 300, Loss: 0.0008910339674912393\n",
      "Iteration 310, Loss: 0.0008330852724611759\n",
      "Iteration 320, Loss: 0.0010614070342853665\n",
      "Iteration 330, Loss: 0.0007896122988313437\n",
      "Iteration 340, Loss: 0.0010340757435187697\n",
      "Iteration 350, Loss: 0.000793098472058773\n",
      "Iteration 360, Loss: 0.000790142104960978\n",
      "Iteration 370, Loss: 0.0009482195600867271\n",
      "Iteration 380, Loss: 0.0008081953856162727\n",
      "Iteration 390, Loss: 0.0007461448549292982\n",
      "Iteration 400, Loss: 0.0007344885380007327\n",
      "Iteration 410, Loss: 0.0007086424739100039\n",
      "Iteration 420, Loss: 0.0006753355846740305\n",
      "Iteration 430, Loss: 0.0006279459339566529\n",
      "Iteration 440, Loss: 0.0006218882044777274\n",
      "Iteration 450, Loss: 0.0008185843471437693\n",
      "Iteration 460, Loss: 0.000576504273340106\n",
      "Iteration 470, Loss: 0.0005929074250161648\n",
      "Iteration 480, Loss: 0.0006333155324682593\n",
      "Iteration 490, Loss: 0.0005218777223490179\n",
      "Iteration 500, Loss: 0.0005764627130702138\n",
      "Iteration 510, Loss: 0.0005463751149363816\n",
      "Iteration 520, Loss: 0.001459601684473455\n",
      "Iteration 530, Loss: 0.0006043857429176569\n",
      "Iteration 540, Loss: 0.0005217136931605637\n",
      "Iteration 550, Loss: 0.0005297254538163543\n",
      "Iteration 560, Loss: 0.0005135602550581098\n",
      "Iteration 570, Loss: 0.0005116357933729887\n",
      "Iteration 580, Loss: 0.00045839924132451415\n",
      "Iteration 590, Loss: 0.0005110686179250479\n",
      "Iteration 600, Loss: 0.0004824408970307559\n",
      "Iteration 610, Loss: 0.0005622786702588201\n",
      "Iteration 620, Loss: 0.00047504378017038107\n",
      "Iteration 630, Loss: 0.0005468501476570964\n",
      "Iteration 640, Loss: 0.0004539310175459832\n",
      "Iteration 650, Loss: 0.0004061151994392276\n",
      "Iteration 660, Loss: 0.00040054888813756406\n",
      "Iteration 670, Loss: 0.0003923575859516859\n",
      "Iteration 680, Loss: 0.0003964620700571686\n",
      "Iteration 690, Loss: 0.000542051566299051\n",
      "Iteration 700, Loss: 0.0004034058947581798\n",
      "Iteration 710, Loss: 0.0004303395398892462\n",
      "Iteration 720, Loss: 0.0004838363383896649\n",
      "Iteration 730, Loss: 0.0003766754816751927\n",
      "Iteration 740, Loss: 0.00034828344359993935\n",
      "Iteration 750, Loss: 0.00043518911115825176\n",
      "Iteration 760, Loss: 0.00044097055797465146\n",
      "Iteration 770, Loss: 0.0006774533540010452\n",
      "Iteration 780, Loss: 0.00037169165443629026\n",
      "Iteration 790, Loss: 0.0003367639728821814\n",
      "Iteration 800, Loss: 0.0003004461177624762\n",
      "Iteration 810, Loss: 0.0002775611646939069\n",
      "Iteration 820, Loss: 0.0002812567399814725\n",
      "Iteration 830, Loss: 0.00027598164160735905\n",
      "Iteration 840, Loss: 0.0002789620775729418\n",
      "Iteration 850, Loss: 0.00027202049386687577\n",
      "Iteration 860, Loss: 0.00031721050618216395\n",
      "Iteration 870, Loss: 0.00023758264433126897\n",
      "Iteration 880, Loss: 0.00026582455029711127\n",
      "Iteration 890, Loss: 0.0002267332747578621\n",
      "Iteration 900, Loss: 0.00030910669011063874\n",
      "Iteration 910, Loss: 0.00036786808050237596\n",
      "Iteration 920, Loss: 0.0002821862290147692\n",
      "Iteration 930, Loss: 0.00020153445075266063\n",
      "Iteration 940, Loss: 0.00021435802045743912\n",
      "Iteration 950, Loss: 0.00022660927788820118\n",
      "Iteration 960, Loss: 0.00017678037693258375\n",
      "Iteration 970, Loss: 0.00023687670181971043\n",
      "Iteration 980, Loss: 0.00037585379322990775\n",
      "Iteration 990, Loss: 0.00019666209118440747\n",
      "Iteration 1000, Loss: 0.00026612041983753443\n",
      "Iteration 1010, Loss: 0.00015267464914359152\n",
      "Iteration 1020, Loss: 0.00019081711070612073\n",
      "Iteration 1030, Loss: 0.0001494606549385935\n",
      "Iteration 1040, Loss: 0.0006376092205755413\n",
      "Iteration 1050, Loss: 0.000506550190038979\n",
      "Iteration 1060, Loss: 0.00014716207806486636\n",
      "Iteration 1070, Loss: 0.00017609102360438555\n",
      "Iteration 1080, Loss: 0.00013375528214965016\n",
      "Iteration 1090, Loss: 0.00012428328045643866\n",
      "Iteration 1100, Loss: 0.0001223424478666857\n",
      "Iteration 1110, Loss: 0.00011219974112464115\n",
      "Iteration 1120, Loss: 0.00014602838200517\n",
      "Iteration 1130, Loss: 0.00019932906434405595\n",
      "Iteration 1140, Loss: 0.00011027111031580716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base: 100%|██████████| 24/24 [03:02<00:00,  7.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1150, Loss: 0.00016194772615563124\n",
      "Stopping early at iteration 1153\n",
      "{'Model': 'PINN base', 'Total_Iterations': 1154, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.013902065826052062, 'L2_avg': 0.018059174724269086, 'End_point_L1_avg': 0.005844256402754196, 'End_point_L2_avg': 0.0069815843394306085}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.6202582120895386\n",
      "Iteration 10, Loss: 0.12709134817123413\n",
      "Iteration 20, Loss: 0.12411971390247345\n",
      "Iteration 30, Loss: 0.05842207744717598\n",
      "Iteration 40, Loss: 0.03864390030503273\n",
      "Iteration 50, Loss: 0.024912606924772263\n",
      "Iteration 60, Loss: 0.019063733518123627\n",
      "Iteration 70, Loss: 0.01397179439663887\n",
      "Iteration 80, Loss: 0.013184207491576672\n",
      "Iteration 90, Loss: 0.009293933399021626\n",
      "Iteration 100, Loss: 0.009778344072401524\n",
      "Iteration 110, Loss: 0.006725405342876911\n",
      "Iteration 120, Loss: 0.006859033368527889\n",
      "Iteration 130, Loss: 0.006041479296982288\n",
      "Iteration 140, Loss: 0.005477198399603367\n",
      "Iteration 150, Loss: 0.005035756155848503\n",
      "Iteration 160, Loss: 0.003917470574378967\n",
      "Iteration 170, Loss: 0.0038396872114390135\n",
      "Iteration 180, Loss: 0.003868868574500084\n",
      "Iteration 190, Loss: 0.0037090328987687826\n",
      "Iteration 200, Loss: 0.0033628297969698906\n",
      "Iteration 210, Loss: 0.003177788108587265\n",
      "Iteration 220, Loss: 0.002951462985947728\n",
      "Iteration 230, Loss: 0.0032751017715781927\n",
      "Iteration 240, Loss: 0.0024847628083080053\n",
      "Iteration 250, Loss: 0.002493962412700057\n",
      "Iteration 260, Loss: 0.0025856385473161936\n",
      "Iteration 270, Loss: 0.002385030733421445\n",
      "Iteration 280, Loss: 0.0025414200499653816\n",
      "Iteration 290, Loss: 0.0023681267630308867\n",
      "Iteration 300, Loss: 0.002354844706133008\n",
      "Iteration 310, Loss: 0.002224578754976392\n",
      "Iteration 320, Loss: 0.002110052853822708\n",
      "Iteration 330, Loss: 0.0020560743287205696\n",
      "Iteration 340, Loss: 0.0022930835839360952\n",
      "Iteration 350, Loss: 0.0019416615832597017\n",
      "Iteration 360, Loss: 0.001981937326490879\n",
      "Iteration 370, Loss: 0.0020102025009691715\n",
      "Iteration 380, Loss: 0.001778734615072608\n",
      "Iteration 390, Loss: 0.00207402091473341\n",
      "Iteration 400, Loss: 0.0017825720133259892\n",
      "Iteration 410, Loss: 0.001839298871345818\n",
      "Iteration 420, Loss: 0.0015632950235158205\n",
      "Iteration 430, Loss: 0.0017067993758246303\n",
      "Iteration 440, Loss: 0.0016027004458010197\n",
      "Iteration 450, Loss: 0.0016383026959374547\n",
      "Iteration 460, Loss: 0.001576044363901019\n",
      "Iteration 470, Loss: 0.0013843480264768004\n",
      "Iteration 480, Loss: 0.0014513516798615456\n",
      "Iteration 490, Loss: 0.00154741364531219\n",
      "Iteration 500, Loss: 0.0014564021257683635\n",
      "Iteration 510, Loss: 0.0015947967767715454\n",
      "Iteration 520, Loss: 0.0014595375396311283\n",
      "Iteration 530, Loss: 0.0013440492330119014\n",
      "Iteration 540, Loss: 0.001436426187865436\n",
      "Iteration 550, Loss: 0.0013773533282801509\n",
      "Iteration 560, Loss: 0.0013478114269673824\n",
      "Iteration 570, Loss: 0.001205493463203311\n",
      "Iteration 580, Loss: 0.0011475610081106424\n",
      "Iteration 590, Loss: 0.0012157476739957929\n",
      "Iteration 600, Loss: 0.0012254909379407763\n",
      "Iteration 610, Loss: 0.0012383672874420881\n",
      "Iteration 620, Loss: 0.0012757641961798072\n",
      "Iteration 630, Loss: 0.0012270534643903375\n",
      "Iteration 640, Loss: 0.0011677445145323873\n",
      "Iteration 650, Loss: 0.0010805311612784863\n",
      "Iteration 660, Loss: 0.0011639785952866077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   4%|▍         | 1/24 [00:09<03:33,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 666\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 667, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04751717419792198, 'L2_avg': 0.05997298423231836, 'End_point_L1_avg': 0.032400133037584634, 'End_point_L2_avg': 0.03274544712826213}\n",
      "Iteration 0, Loss: 0.9877692461013794\n",
      "Iteration 10, Loss: 0.1892196387052536\n",
      "Iteration 20, Loss: 0.0868382677435875\n",
      "Iteration 30, Loss: 0.05835265666246414\n",
      "Iteration 40, Loss: 0.026713130995631218\n",
      "Iteration 50, Loss: 0.021463600918650627\n",
      "Iteration 60, Loss: 0.01546446979045868\n",
      "Iteration 70, Loss: 0.01682971976697445\n",
      "Iteration 80, Loss: 0.011568723246455193\n",
      "Iteration 90, Loss: 0.008507125079631805\n",
      "Iteration 100, Loss: 0.007704540155827999\n",
      "Iteration 110, Loss: 0.007430327590554953\n",
      "Iteration 120, Loss: 0.006067286245524883\n",
      "Iteration 130, Loss: 0.005285702180117369\n",
      "Iteration 140, Loss: 0.004789953585714102\n",
      "Iteration 150, Loss: 0.00419542845338583\n",
      "Iteration 160, Loss: 0.0039545767940580845\n",
      "Iteration 170, Loss: 0.003746786853298545\n",
      "Iteration 180, Loss: 0.0034956070594489574\n",
      "Iteration 190, Loss: 0.0036337077617645264\n",
      "Iteration 200, Loss: 0.002639996586367488\n",
      "Iteration 210, Loss: 0.0031050117686390877\n",
      "Iteration 220, Loss: 0.002700351644307375\n",
      "Iteration 230, Loss: 0.002864493988454342\n",
      "Iteration 240, Loss: 0.0030700971838086843\n",
      "Iteration 250, Loss: 0.002403452293947339\n",
      "Iteration 260, Loss: 0.002545167226344347\n",
      "Iteration 270, Loss: 0.00255705532617867\n",
      "Iteration 280, Loss: 0.002520780311897397\n",
      "Iteration 290, Loss: 0.002227206714451313\n",
      "Iteration 300, Loss: 0.0022127358242869377\n",
      "Iteration 310, Loss: 0.0021543726325035095\n",
      "Iteration 320, Loss: 0.002302527893334627\n",
      "Iteration 330, Loss: 0.002217588946223259\n",
      "Iteration 340, Loss: 0.001972632249817252\n",
      "Iteration 350, Loss: 0.0020916215144097805\n",
      "Iteration 360, Loss: 0.002064112341031432\n",
      "Iteration 370, Loss: 0.0020616380497813225\n",
      "Iteration 380, Loss: 0.0018279158975929022\n",
      "Iteration 390, Loss: 0.0019921744242310524\n",
      "Iteration 400, Loss: 0.0016330649377778172\n",
      "Iteration 410, Loss: 0.0016705375164747238\n",
      "Iteration 420, Loss: 0.0016298206755891442\n",
      "Iteration 430, Loss: 0.0015833609504625201\n",
      "Iteration 440, Loss: 0.0015752131585031748\n",
      "Iteration 450, Loss: 0.0016047268873080611\n",
      "Iteration 460, Loss: 0.0016364397015422583\n",
      "Iteration 470, Loss: 0.0014662106987088919\n",
      "Iteration 480, Loss: 0.0015730030136182904\n",
      "Iteration 490, Loss: 0.0013157243374735117\n",
      "Iteration 500, Loss: 0.0013683093711733818\n",
      "Iteration 510, Loss: 0.0014584935270249844\n",
      "Iteration 520, Loss: 0.0014309851685538888\n",
      "Iteration 530, Loss: 0.0013638739474117756\n",
      "Iteration 540, Loss: 0.0012562545016407967\n",
      "Iteration 550, Loss: 0.001147730858065188\n",
      "Iteration 560, Loss: 0.0012561719631776214\n",
      "Iteration 570, Loss: 0.0013966441620141268\n",
      "Iteration 580, Loss: 0.001229155226610601\n",
      "Iteration 590, Loss: 0.0012313025072216988\n",
      "Iteration 600, Loss: 0.0011826164554804564\n",
      "Iteration 610, Loss: 0.0011260313913226128\n",
      "Iteration 620, Loss: 0.00115411845035851\n",
      "Iteration 630, Loss: 0.001068984274752438\n",
      "Iteration 640, Loss: 0.0011338801123201847\n",
      "Iteration 650, Loss: 0.001131304888986051\n",
      "Iteration 660, Loss: 0.0010593327460810542\n",
      "Iteration 670, Loss: 0.0010667979950085282\n",
      "Iteration 680, Loss: 0.0010514558525756001\n",
      "Iteration 690, Loss: 0.000991534092463553\n",
      "Iteration 700, Loss: 0.0010334375547245145\n",
      "Iteration 710, Loss: 0.0010387708898633718\n",
      "Iteration 720, Loss: 0.0009254428441636264\n",
      "Iteration 730, Loss: 0.0009641256765462458\n",
      "Iteration 740, Loss: 0.0008896766812540591\n",
      "Iteration 750, Loss: 0.0008903619600459933\n",
      "Iteration 760, Loss: 0.0009255692712031305\n",
      "Iteration 770, Loss: 0.0009699086658656597\n",
      "Iteration 780, Loss: 0.0008777515031397343\n",
      "Iteration 790, Loss: 0.0008536702953279018\n",
      "Iteration 800, Loss: 0.000867606489919126\n",
      "Iteration 810, Loss: 0.0008391602314077318\n",
      "Iteration 820, Loss: 0.0007816659635864198\n",
      "Iteration 830, Loss: 0.0008387156995013356\n",
      "Iteration 840, Loss: 0.0008635639096610248\n",
      "Iteration 850, Loss: 0.0007803488988429308\n",
      "Iteration 860, Loss: 0.0007502553635276854\n",
      "Iteration 870, Loss: 0.0007769257063046098\n",
      "Iteration 880, Loss: 0.0007468007388524711\n",
      "Iteration 890, Loss: 0.000740923685953021\n",
      "Iteration 900, Loss: 0.0008040862157940865\n",
      "Iteration 910, Loss: 0.0007024458609521389\n",
      "Iteration 920, Loss: 0.0007081006187945604\n",
      "Iteration 930, Loss: 0.0006251594168134034\n",
      "Iteration 940, Loss: 0.0007430758560076356\n",
      "Iteration 950, Loss: 0.0005995351821184158\n",
      "Iteration 960, Loss: 0.0008292403654195368\n",
      "Iteration 970, Loss: 0.0007186041329987347\n",
      "Iteration 980, Loss: 0.0006233028834685683\n",
      "Iteration 990, Loss: 0.0006475881673395634\n",
      "Iteration 1000, Loss: 0.0006325938738882542\n",
      "Iteration 1010, Loss: 0.0005978206172585487\n",
      "Iteration 1020, Loss: 0.0006004708120599389\n",
      "Iteration 1030, Loss: 0.0006655862089246511\n",
      "Iteration 1040, Loss: 0.0005665540229529142\n",
      "Iteration 1050, Loss: 0.0006650193827226758\n",
      "Iteration 1060, Loss: 0.0005966943572275341\n",
      "Iteration 1070, Loss: 0.0005803098902106285\n",
      "Iteration 1080, Loss: 0.0005738019826821983\n",
      "Iteration 1090, Loss: 0.0005232847761362791\n",
      "Iteration 1100, Loss: 0.0006620856001973152\n",
      "Iteration 1110, Loss: 0.0005643630283884704\n",
      "Iteration 1120, Loss: 0.0005404764669947326\n",
      "Iteration 1130, Loss: 0.0008474299684166908\n",
      "Iteration 1140, Loss: 0.0008182540768757463\n",
      "Iteration 1150, Loss: 0.0005317567847669125\n",
      "Iteration 1160, Loss: 0.0005202958709560335\n",
      "Iteration 1170, Loss: 0.000623549974989146\n",
      "Iteration 1180, Loss: 0.0006827866309322417\n",
      "Iteration 1190, Loss: 0.0009507726645097136\n",
      "Iteration 1200, Loss: 0.0004718416021205485\n",
      "Iteration 1210, Loss: 0.0005167569615878165\n",
      "Iteration 1220, Loss: 0.0007093769963830709\n",
      "Iteration 1230, Loss: 0.0005371897132135928\n",
      "Iteration 1240, Loss: 0.00040022359462454915\n",
      "Iteration 1250, Loss: 0.00042507171747274697\n",
      "Iteration 1260, Loss: 0.0005300300545059144\n",
      "Iteration 1270, Loss: 0.0009148127282969654\n",
      "Iteration 1280, Loss: 0.0005017670919187367\n",
      "Iteration 1290, Loss: 0.0003978160093538463\n",
      "Iteration 1300, Loss: 0.0004357450525276363\n",
      "Iteration 1310, Loss: 0.0003926768549717963\n",
      "Iteration 1320, Loss: 0.0005314305890351534\n",
      "Iteration 1330, Loss: 0.00040191604057326913\n",
      "Iteration 1340, Loss: 0.0007190416217781603\n",
      "Iteration 1350, Loss: 0.00044283532770350575\n",
      "Iteration 1360, Loss: 0.0005596982082352042\n",
      "Iteration 1370, Loss: 0.00034714574576355517\n",
      "Iteration 1380, Loss: 0.00035108145675621927\n",
      "Iteration 1390, Loss: 0.0003534254210535437\n",
      "Iteration 1400, Loss: 0.00034518211032263935\n",
      "Iteration 1410, Loss: 0.00029976366204209626\n",
      "Iteration 1420, Loss: 0.000877166457939893\n",
      "Iteration 1430, Loss: 0.0003030686639249325\n",
      "Iteration 1440, Loss: 0.0010725414613261819\n",
      "Iteration 1450, Loss: 0.0005919974646531045\n",
      "Iteration 1460, Loss: 0.00033967517083510756\n",
      "Iteration 1470, Loss: 0.001084913033992052\n",
      "Iteration 1480, Loss: 0.0004279886488802731\n",
      "Iteration 1490, Loss: 0.0004265189927536994\n",
      "Iteration 1500, Loss: 0.0011984470766037703\n",
      "Iteration 1510, Loss: 0.0005793006275780499\n",
      "Iteration 1520, Loss: 0.0002973129157908261\n",
      "Iteration 1530, Loss: 0.0003524739877320826\n",
      "Iteration 1540, Loss: 0.0009084354969672859\n",
      "Iteration 1550, Loss: 0.00030046605388633907\n",
      "Iteration 1560, Loss: 0.0007154233171604574\n",
      "Iteration 1570, Loss: 0.0002467434969730675\n",
      "Iteration 1580, Loss: 0.0018345026765018702\n",
      "Iteration 1590, Loss: 0.00047254996025003493\n",
      "Iteration 1600, Loss: 0.0002866353315766901\n",
      "Iteration 1610, Loss: 0.0010807818034663796\n",
      "Iteration 1620, Loss: 0.00025986990658566356\n",
      "Iteration 1630, Loss: 0.000280410167761147\n",
      "Iteration 1640, Loss: 0.0002358661440666765\n",
      "Iteration 1650, Loss: 0.002277580788359046\n",
      "Iteration 1660, Loss: 0.0008493681089021266\n",
      "Iteration 1670, Loss: 0.0004713601665571332\n",
      "Iteration 1680, Loss: 0.0004235212691128254\n",
      "Iteration 1690, Loss: 0.0002824160910677165\n",
      "Iteration 1700, Loss: 0.0002821124217007309\n",
      "Iteration 1710, Loss: 0.00036985226324759424\n",
      "Iteration 1720, Loss: 0.004278108011931181\n",
      "Iteration 1730, Loss: 0.0029575310181826353\n",
      "Iteration 1740, Loss: 0.0004076639888808131\n",
      "Iteration 1750, Loss: 0.0002317042526556179\n",
      "Iteration 1760, Loss: 0.00029015258769504726\n",
      "Iteration 1770, Loss: 0.00024055448011495173\n",
      "Iteration 1780, Loss: 0.0003177493344992399\n",
      "Iteration 1790, Loss: 0.0003670367004815489\n",
      "Iteration 1800, Loss: 0.00020746731024701148\n",
      "Iteration 1810, Loss: 0.0002540777495596558\n",
      "Iteration 1820, Loss: 0.00022353198437485844\n",
      "Iteration 1830, Loss: 0.0002875282953027636\n",
      "Iteration 1840, Loss: 0.002710785251110792\n",
      "Iteration 1850, Loss: 0.0023286649957299232\n",
      "Iteration 1860, Loss: 0.0007136311614885926\n",
      "Iteration 1870, Loss: 0.0005213888362050056\n",
      "Iteration 1880, Loss: 0.0002193779218941927\n",
      "Iteration 1890, Loss: 0.0002242726186523214\n",
      "Iteration 1900, Loss: 0.000256460189120844\n",
      "Iteration 1910, Loss: 0.00017784569354262203\n",
      "Iteration 1920, Loss: 0.00021804243442602456\n",
      "Iteration 1930, Loss: 0.00020351095008663833\n",
      "Iteration 1940, Loss: 0.00019360087753739208\n",
      "Iteration 1950, Loss: 0.0002058553945971653\n",
      "Iteration 1960, Loss: 0.00018050038488581777\n",
      "Iteration 1970, Loss: 0.00027025124290958047\n",
      "Iteration 1980, Loss: 0.00066086690640077\n",
      "Iteration 1990, Loss: 0.00044232685468159616\n",
      "Iteration 2000, Loss: 0.000561630935408175\n",
      "Iteration 2010, Loss: 0.0009657962364144623\n",
      "Iteration 2020, Loss: 0.00023123715072870255\n",
      "Iteration 2030, Loss: 0.00033871145569719374\n",
      "Iteration 2040, Loss: 0.0003251488960813731\n",
      "Iteration 2050, Loss: 0.00027613030397333205\n",
      "Iteration 2060, Loss: 0.0004220981791149825\n",
      "Iteration 2070, Loss: 0.004856089595705271\n",
      "Iteration 2080, Loss: 0.0016322571318596601\n",
      "Iteration 2090, Loss: 0.0001814350252971053\n",
      "Iteration 2100, Loss: 0.00039757409831508994\n",
      "Iteration 2110, Loss: 0.0003453717799857259\n",
      "Iteration 2120, Loss: 0.00016472778224851936\n",
      "Iteration 2130, Loss: 0.0001674134109634906\n",
      "Iteration 2140, Loss: 0.00019538994820322841\n",
      "Iteration 2150, Loss: 0.00017857193597592413\n",
      "Iteration 2160, Loss: 0.0002469961764290929\n",
      "Iteration 2170, Loss: 0.0003153863945044577\n",
      "Iteration 2180, Loss: 0.00027006020536646247\n",
      "Iteration 2190, Loss: 0.0001827585365390405\n",
      "Iteration 2200, Loss: 0.00018549228843767196\n",
      "Iteration 2210, Loss: 0.0007414832361973822\n",
      "Iteration 2220, Loss: 0.002701386110857129\n",
      "Iteration 2230, Loss: 0.0006890507065691054\n",
      "Iteration 2240, Loss: 0.00019853372941724956\n",
      "Iteration 2250, Loss: 0.0002038852690020576\n",
      "Iteration 2260, Loss: 0.00015422439901158214\n",
      "Iteration 2270, Loss: 0.00019456862355582416\n",
      "Iteration 2280, Loss: 0.00014319914043881\n",
      "Iteration 2290, Loss: 0.0003848024061881006\n",
      "Iteration 2300, Loss: 0.00015189558325801045\n",
      "Iteration 2310, Loss: 0.000263503025053069\n",
      "Iteration 2320, Loss: 0.0007275808602571487\n",
      "Iteration 2330, Loss: 0.0010972952004522085\n",
      "Iteration 2340, Loss: 0.001268938067369163\n",
      "Iteration 2350, Loss: 0.0001508628047304228\n",
      "Iteration 2360, Loss: 0.00030601982143707573\n",
      "Iteration 2370, Loss: 0.00081317697186023\n",
      "Iteration 2380, Loss: 0.00038618105463683605\n",
      "Iteration 2390, Loss: 0.00024105327611323446\n",
      "Iteration 2400, Loss: 0.00021178627503104508\n",
      "Iteration 2410, Loss: 0.00019213031919207424\n",
      "Iteration 2420, Loss: 0.00030541152227669954\n",
      "Iteration 2430, Loss: 0.00030615771538577974\n",
      "Iteration 2440, Loss: 0.00048326406977139413\n",
      "Iteration 2450, Loss: 0.00032647670013830066\n",
      "Iteration 2460, Loss: 0.0013532539596781135\n",
      "Iteration 2470, Loss: 0.0003243561659473926\n",
      "Iteration 2480, Loss: 0.00020690668316092342\n",
      "Iteration 2490, Loss: 0.000469404854811728\n",
      "Iteration 2500, Loss: 0.0008081073756329715\n",
      "Iteration 2510, Loss: 0.00018083500617649406\n",
      "Iteration 2520, Loss: 0.0007382574840448797\n",
      "Iteration 2530, Loss: 0.00016363638860639185\n",
      "Iteration 2540, Loss: 0.00033436331432312727\n",
      "Iteration 2550, Loss: 0.0016172927571460605\n",
      "Iteration 2560, Loss: 0.00015241492656059563\n",
      "Iteration 2570, Loss: 0.0009432883816771209\n",
      "Iteration 2580, Loss: 0.0003338669484946877\n",
      "Iteration 2590, Loss: 0.00013070648128632456\n",
      "Iteration 2600, Loss: 0.0018164932262152433\n",
      "Iteration 2610, Loss: 0.0009096122812479734\n",
      "Iteration 2620, Loss: 0.00030625108047388494\n",
      "Iteration 2630, Loss: 0.00038280404987744987\n",
      "Iteration 2640, Loss: 0.00020664276962634176\n",
      "Iteration 2650, Loss: 0.0002520293346606195\n",
      "Iteration 2660, Loss: 0.0002821285161189735\n",
      "Iteration 2670, Loss: 0.0011842264793813229\n",
      "Iteration 2680, Loss: 0.0008058496750891209\n",
      "Iteration 2690, Loss: 0.0004029802803415805\n",
      "Iteration 2700, Loss: 0.000210473794140853\n",
      "Iteration 2710, Loss: 0.0009093359112739563\n",
      "Iteration 2720, Loss: 0.0007920495700091124\n",
      "Iteration 2730, Loss: 0.00013016589218750596\n",
      "Iteration 2740, Loss: 0.00029781321063637733\n",
      "Iteration 2750, Loss: 0.00044572408660314977\n",
      "Iteration 2760, Loss: 0.0003109186654910445\n",
      "Iteration 2770, Loss: 0.00046076587750576437\n",
      "Iteration 2780, Loss: 0.00013763245078735054\n",
      "Iteration 2790, Loss: 0.0007898265030235052\n",
      "Iteration 2800, Loss: 0.00012330064782872796\n",
      "Iteration 2810, Loss: 0.0016430439427495003\n",
      "Iteration 2820, Loss: 0.00012411635543685406\n",
      "Iteration 2830, Loss: 0.00017244844639208168\n",
      "Iteration 2840, Loss: 0.00011632395762717351\n",
      "Iteration 2850, Loss: 0.0006250502774491906\n",
      "Iteration 2860, Loss: 0.0011611806694418192\n",
      "Iteration 2870, Loss: 0.000176350207766518\n",
      "Iteration 2880, Loss: 0.0015364026185125113\n",
      "Iteration 2890, Loss: 0.00022233696654438972\n",
      "Iteration 2900, Loss: 0.0002892084594350308\n",
      "Iteration 2910, Loss: 0.00035516280331648886\n",
      "Iteration 2920, Loss: 0.00011877884389832616\n",
      "Iteration 2930, Loss: 0.00013979712093714625\n",
      "Iteration 2940, Loss: 0.00047969832667149603\n",
      "Iteration 2950, Loss: 0.002501103328540921\n",
      "Iteration 2960, Loss: 0.00016189087182283401\n",
      "Iteration 2970, Loss: 0.00023742795747239143\n",
      "Iteration 2980, Loss: 0.000316295976517722\n",
      "Iteration 2990, Loss: 0.00022616784553974867\n",
      "Iteration 3000, Loss: 0.00011043294216506183\n",
      "Iteration 3010, Loss: 0.00011177261330885813\n",
      "Stopping early at iteration 3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   8%|▊         | 2/24 [00:56<11:39, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 3012, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.014646862766352908, 'L2_avg': 0.018591224860546495, 'End_point_L1_avg': 0.00934949100931824, 'End_point_L2_avg': 0.01272279334798662}\n",
      "Iteration 0, Loss: 1.2511966228485107\n",
      "Iteration 10, Loss: 0.14346005022525787\n",
      "Iteration 20, Loss: 0.09390982985496521\n",
      "Iteration 30, Loss: 0.0481577068567276\n",
      "Iteration 40, Loss: 0.0286068357527256\n",
      "Iteration 50, Loss: 0.02032686024904251\n",
      "Iteration 60, Loss: 0.013480502180755138\n",
      "Iteration 70, Loss: 0.011045457795262337\n",
      "Iteration 80, Loss: 0.008545024320483208\n",
      "Iteration 90, Loss: 0.007620776537805796\n",
      "Iteration 100, Loss: 0.006105322390794754\n",
      "Iteration 110, Loss: 0.004932749550789595\n",
      "Iteration 120, Loss: 0.00479085510596633\n",
      "Iteration 130, Loss: 0.003758382983505726\n",
      "Iteration 140, Loss: 0.003753975033760071\n",
      "Iteration 150, Loss: 0.0035554056521505117\n",
      "Iteration 160, Loss: 0.0029150338377803564\n",
      "Iteration 170, Loss: 0.002885941183194518\n",
      "Iteration 180, Loss: 0.0027553464751690626\n",
      "Iteration 190, Loss: 0.0026082417462021112\n",
      "Iteration 200, Loss: 0.0025959217455238104\n",
      "Iteration 210, Loss: 0.0024332597386091948\n",
      "Iteration 220, Loss: 0.00232951482757926\n",
      "Iteration 230, Loss: 0.0023000023793429136\n",
      "Iteration 240, Loss: 0.002292742719873786\n",
      "Iteration 250, Loss: 0.002139516407623887\n",
      "Iteration 260, Loss: 0.0020554403308779\n",
      "Iteration 270, Loss: 0.0020374548621475697\n",
      "Iteration 280, Loss: 0.0019565331749618053\n",
      "Iteration 290, Loss: 0.0018543403130024672\n",
      "Iteration 300, Loss: 0.001857174327597022\n",
      "Iteration 310, Loss: 0.0018154914723709226\n",
      "Iteration 320, Loss: 0.0017086605075746775\n",
      "Iteration 330, Loss: 0.0017253458499908447\n",
      "Iteration 340, Loss: 0.0017223096219822764\n",
      "Iteration 350, Loss: 0.0016389002557843924\n",
      "Iteration 360, Loss: 0.0016243787249550223\n",
      "Iteration 370, Loss: 0.0016578291542828083\n",
      "Iteration 380, Loss: 0.0015646778047084808\n",
      "Iteration 390, Loss: 0.0015155195724219084\n",
      "Iteration 400, Loss: 0.0015067211352288723\n",
      "Iteration 410, Loss: 0.0015063682803884149\n",
      "Iteration 420, Loss: 0.0014286740915849805\n",
      "Iteration 430, Loss: 0.0013984056422486901\n",
      "Iteration 440, Loss: 0.0013805895578116179\n",
      "Iteration 450, Loss: 0.0013299542479217052\n",
      "Iteration 460, Loss: 0.0013000400504097342\n",
      "Iteration 470, Loss: 0.0012770722387358546\n",
      "Iteration 480, Loss: 0.0012271888554096222\n",
      "Iteration 490, Loss: 0.0012478036805987358\n",
      "Iteration 500, Loss: 0.0011853276519104838\n",
      "Iteration 510, Loss: 0.0012051959056407213\n",
      "Iteration 520, Loss: 0.0011473818449303508\n",
      "Iteration 530, Loss: 0.0011523514986038208\n",
      "Iteration 540, Loss: 0.0010735767427831888\n",
      "Iteration 550, Loss: 0.001091024954803288\n",
      "Iteration 560, Loss: 0.001072572311386466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  12%|█▎        | 3/24 [01:06<07:36, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 570, Loss: 0.0010423269122838974\n",
      "Stopping early at iteration 578\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 579, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.046151116973788806, 'L2_avg': 0.058827276494061206, 'End_point_L1_avg': 0.029029772566276403, 'End_point_L2_avg': 0.02913095063197149}\n",
      "Iteration 0, Loss: 1.8233585357666016\n",
      "Iteration 10, Loss: 0.1425105631351471\n",
      "Iteration 20, Loss: 0.14965125918388367\n",
      "Iteration 30, Loss: 0.043467458337545395\n",
      "Iteration 40, Loss: 0.031287603080272675\n",
      "Iteration 50, Loss: 0.01950201205909252\n",
      "Iteration 60, Loss: 0.01438174583017826\n",
      "Iteration 70, Loss: 0.01008452195674181\n",
      "Iteration 80, Loss: 0.008268972858786583\n",
      "Iteration 90, Loss: 0.006389128044247627\n",
      "Iteration 100, Loss: 0.0060474323108792305\n",
      "Iteration 110, Loss: 0.004834206774830818\n",
      "Iteration 120, Loss: 0.004432477988302708\n",
      "Iteration 130, Loss: 0.004108607303351164\n",
      "Iteration 140, Loss: 0.0036403280682861805\n",
      "Iteration 150, Loss: 0.0037097050808370113\n",
      "Iteration 160, Loss: 0.0033756245393306017\n",
      "Iteration 170, Loss: 0.003255828283727169\n",
      "Iteration 180, Loss: 0.0028794149402529\n",
      "Iteration 190, Loss: 0.0027227457612752914\n",
      "Iteration 200, Loss: 0.0027440355625003576\n",
      "Iteration 210, Loss: 0.0024127548094838858\n",
      "Iteration 220, Loss: 0.0023816083557903767\n",
      "Iteration 230, Loss: 0.0023545417934656143\n",
      "Iteration 240, Loss: 0.0022503111977130175\n",
      "Iteration 250, Loss: 0.0020257369615137577\n",
      "Iteration 260, Loss: 0.002070588991045952\n",
      "Iteration 270, Loss: 0.0019227582961320877\n",
      "Iteration 280, Loss: 0.0018484934698790312\n",
      "Iteration 290, Loss: 0.0018675158498808742\n",
      "Iteration 300, Loss: 0.0019111388828605413\n",
      "Iteration 310, Loss: 0.001788323512300849\n",
      "Iteration 320, Loss: 0.0017839900683611631\n",
      "Iteration 330, Loss: 0.0017504498828202486\n",
      "Iteration 340, Loss: 0.0016821578610688448\n",
      "Iteration 350, Loss: 0.001558444695547223\n",
      "Iteration 360, Loss: 0.0015962282195687294\n",
      "Iteration 370, Loss: 0.0015311696333810687\n",
      "Iteration 380, Loss: 0.0015456443652510643\n",
      "Iteration 390, Loss: 0.0014932932099327445\n",
      "Iteration 400, Loss: 0.0015054445248097181\n",
      "Iteration 410, Loss: 0.001419789856299758\n",
      "Iteration 420, Loss: 0.0013750602956861258\n",
      "Iteration 430, Loss: 0.001360223046503961\n",
      "Iteration 440, Loss: 0.0013264270965009928\n",
      "Iteration 450, Loss: 0.0012829562183469534\n",
      "Iteration 460, Loss: 0.0012879723217338324\n",
      "Iteration 470, Loss: 0.001203067833557725\n",
      "Iteration 480, Loss: 0.0012289638398215175\n",
      "Iteration 490, Loss: 0.0011719601461663842\n",
      "Iteration 500, Loss: 0.0011238927254453301\n",
      "Iteration 510, Loss: 0.00110961077734828\n",
      "Iteration 520, Loss: 0.0011452008038759232\n",
      "Iteration 530, Loss: 0.0010784947080537677\n",
      "Iteration 540, Loss: 0.001067984034307301\n",
      "Iteration 550, Loss: 0.0010422499617561698\n",
      "Iteration 560, Loss: 0.0010346828494220972\n",
      "Iteration 570, Loss: 0.0010189710883423686\n",
      "Iteration 580, Loss: 0.0009678624919615686\n",
      "Iteration 590, Loss: 0.001029007718898356\n",
      "Iteration 600, Loss: 0.0009446243639104068\n",
      "Iteration 610, Loss: 0.0009338515810668468\n",
      "Iteration 620, Loss: 0.0009064251789823174\n",
      "Iteration 630, Loss: 0.0008613026002421975\n",
      "Iteration 640, Loss: 0.0008690092945471406\n",
      "Iteration 650, Loss: 0.0008602872840128839\n",
      "Iteration 660, Loss: 0.0008709791582077742\n",
      "Iteration 670, Loss: 0.0008439147495664656\n",
      "Iteration 680, Loss: 0.0008668664959259331\n",
      "Iteration 690, Loss: 0.0008081096457317472\n",
      "Iteration 700, Loss: 0.0008131967042572796\n",
      "Iteration 710, Loss: 0.0008056185324676335\n",
      "Iteration 720, Loss: 0.0007741180597804487\n",
      "Iteration 730, Loss: 0.0007630025502294302\n",
      "Iteration 740, Loss: 0.0008185444166883826\n",
      "Iteration 750, Loss: 0.0007297344855032861\n",
      "Iteration 760, Loss: 0.0007651979685761034\n",
      "Iteration 770, Loss: 0.0007220041006803513\n",
      "Iteration 780, Loss: 0.000747723737731576\n",
      "Iteration 790, Loss: 0.000721330929081887\n",
      "Iteration 800, Loss: 0.0007468057447113097\n",
      "Iteration 810, Loss: 0.0007126374985091388\n",
      "Iteration 820, Loss: 0.0007040429627522826\n",
      "Iteration 830, Loss: 0.0007110408623702824\n",
      "Iteration 840, Loss: 0.000679996854159981\n",
      "Iteration 850, Loss: 0.0006796691450290382\n",
      "Iteration 860, Loss: 0.0006740413373336196\n",
      "Iteration 870, Loss: 0.0006558115128427744\n",
      "Iteration 880, Loss: 0.0006511890096589923\n",
      "Iteration 890, Loss: 0.0006606962415389717\n",
      "Iteration 900, Loss: 0.0006293177139014006\n",
      "Iteration 910, Loss: 0.0006483771139755845\n",
      "Iteration 920, Loss: 0.0006262988899834454\n",
      "Iteration 930, Loss: 0.0006240242510102689\n",
      "Iteration 940, Loss: 0.0006073251133784652\n",
      "Iteration 950, Loss: 0.0006223833188414574\n",
      "Iteration 960, Loss: 0.0006079540471546352\n",
      "Iteration 970, Loss: 0.0006016827537678182\n",
      "Iteration 980, Loss: 0.0005656984285451472\n",
      "Iteration 990, Loss: 0.0006107979570515454\n",
      "Iteration 1000, Loss: 0.0006096328143030405\n",
      "Iteration 1010, Loss: 0.0006116756703704596\n",
      "Iteration 1020, Loss: 0.0005783555679954588\n",
      "Iteration 1030, Loss: 0.000546752184163779\n",
      "Iteration 1040, Loss: 0.0005548179033212364\n",
      "Iteration 1050, Loss: 0.0005915697547607124\n",
      "Iteration 1060, Loss: 0.0007840486359782517\n",
      "Iteration 1070, Loss: 0.0010510397842153907\n",
      "Iteration 1080, Loss: 0.0006242808303795755\n",
      "Iteration 1090, Loss: 0.001028357888571918\n",
      "Iteration 1100, Loss: 0.0006587346433661878\n",
      "Iteration 1110, Loss: 0.0006935153505764902\n",
      "Iteration 1120, Loss: 0.0011263432679697871\n",
      "Iteration 1130, Loss: 0.0007474684389308095\n",
      "Iteration 1140, Loss: 0.0007609787862747908\n",
      "Iteration 1150, Loss: 0.0004822073387913406\n",
      "Iteration 1160, Loss: 0.0006228337297216058\n",
      "Iteration 1170, Loss: 0.0005300581105984747\n",
      "Iteration 1180, Loss: 0.0006167514366097748\n",
      "Iteration 1190, Loss: 0.000502370938193053\n",
      "Iteration 1200, Loss: 0.0005444626440294087\n",
      "Iteration 1210, Loss: 0.0008440701058134437\n",
      "Iteration 1220, Loss: 0.0010483646765351295\n",
      "Iteration 1230, Loss: 0.0005132560036145151\n",
      "Iteration 1240, Loss: 0.0008861286914907396\n",
      "Iteration 1250, Loss: 0.0006395296659320593\n",
      "Iteration 1260, Loss: 0.0007856736774556339\n",
      "Iteration 1270, Loss: 0.00048026154399849474\n",
      "Iteration 1280, Loss: 0.0005559318233281374\n",
      "Iteration 1290, Loss: 0.0015916537959128618\n",
      "Iteration 1300, Loss: 0.0010229360777884722\n",
      "Iteration 1310, Loss: 0.0005590167129412293\n",
      "Iteration 1320, Loss: 0.0006573030259460211\n",
      "Iteration 1330, Loss: 0.0005938918911851943\n",
      "Iteration 1340, Loss: 0.0008512300555594265\n",
      "Iteration 1350, Loss: 0.0015717471251264215\n",
      "Iteration 1360, Loss: 0.0011467871954664588\n",
      "Iteration 1370, Loss: 0.0007248109322972596\n",
      "Iteration 1380, Loss: 0.0004957073251716793\n",
      "Iteration 1390, Loss: 0.001561310258693993\n",
      "Iteration 1400, Loss: 0.0005453202757053077\n",
      "Iteration 1410, Loss: 0.0004739012510981411\n",
      "Iteration 1420, Loss: 0.0007644410361535847\n",
      "Iteration 1430, Loss: 0.0004360511084087193\n",
      "Iteration 1440, Loss: 0.00046012751408852637\n",
      "Iteration 1450, Loss: 0.0005816221819259226\n",
      "Iteration 1460, Loss: 0.002702593570575118\n",
      "Iteration 1470, Loss: 0.00043217098573222756\n",
      "Iteration 1480, Loss: 0.0003994634316768497\n",
      "Iteration 1490, Loss: 0.00042868650052696466\n",
      "Iteration 1500, Loss: 0.00044771929970011115\n",
      "Iteration 1510, Loss: 0.00047411341802217066\n",
      "Iteration 1520, Loss: 0.00046364718582481146\n",
      "Iteration 1530, Loss: 0.00040993973379954696\n",
      "Iteration 1540, Loss: 0.0006741316174156964\n",
      "Iteration 1550, Loss: 0.003574369242414832\n",
      "Iteration 1560, Loss: 0.0016372192185372114\n",
      "Iteration 1570, Loss: 0.0006680072983726859\n",
      "Iteration 1580, Loss: 0.00039737997576594353\n",
      "Iteration 1590, Loss: 0.00047861936036497355\n",
      "Iteration 1600, Loss: 0.0004489905550144613\n",
      "Iteration 1610, Loss: 0.00039163234760053456\n",
      "Iteration 1620, Loss: 0.000577752769459039\n",
      "Iteration 1630, Loss: 0.0006021170411258936\n",
      "Iteration 1640, Loss: 0.0008412004681304097\n",
      "Iteration 1650, Loss: 0.00040112773422151804\n",
      "Iteration 1660, Loss: 0.0008839408401399851\n",
      "Iteration 1670, Loss: 0.0013864281354472041\n",
      "Iteration 1680, Loss: 0.0008105956367217004\n",
      "Iteration 1690, Loss: 0.00044851747225038707\n",
      "Iteration 1700, Loss: 0.0004276888503227383\n",
      "Iteration 1710, Loss: 0.00041875027818605304\n",
      "Iteration 1720, Loss: 0.00045897444942966104\n",
      "Iteration 1730, Loss: 0.00066454365151003\n",
      "Iteration 1740, Loss: 0.0042747496627271175\n",
      "Iteration 1750, Loss: 0.001997534651309252\n",
      "Iteration 1760, Loss: 0.0004836645966861397\n",
      "Iteration 1770, Loss: 0.00036247711977921426\n",
      "Iteration 1780, Loss: 0.00047791091492399573\n",
      "Iteration 1790, Loss: 0.0004087790730409324\n",
      "Iteration 1800, Loss: 0.00038698725984431803\n",
      "Iteration 1810, Loss: 0.0003506526700221002\n",
      "Iteration 1820, Loss: 0.0004332710523158312\n",
      "Iteration 1830, Loss: 0.0004600778338499367\n",
      "Iteration 1840, Loss: 0.0005226298235356808\n",
      "Iteration 1850, Loss: 0.0005400654627010226\n",
      "Iteration 1860, Loss: 0.0007161666289903224\n",
      "Iteration 1870, Loss: 0.0017367871478199959\n",
      "Iteration 1880, Loss: 0.000693906971719116\n",
      "Iteration 1890, Loss: 0.0004956062766723335\n",
      "Iteration 1900, Loss: 0.00042373075848445296\n",
      "Iteration 1910, Loss: 0.00036049727350473404\n",
      "Iteration 1920, Loss: 0.0009611020213924348\n",
      "Iteration 1930, Loss: 0.00037114156293682754\n",
      "Iteration 1940, Loss: 0.0013698986731469631\n",
      "Iteration 1950, Loss: 0.0004310415533836931\n",
      "Iteration 1960, Loss: 0.0006755279027856886\n",
      "Iteration 1970, Loss: 0.00036894954973831773\n",
      "Iteration 1980, Loss: 0.0004060218052472919\n",
      "Iteration 1990, Loss: 0.0008235074928961694\n",
      "Iteration 2000, Loss: 0.0022077455651015043\n",
      "Iteration 2010, Loss: 0.0005648784572258592\n",
      "Iteration 2020, Loss: 0.00032335109426639974\n",
      "Iteration 2030, Loss: 0.0006945497589185834\n",
      "Iteration 2040, Loss: 0.00048266962403431535\n",
      "Iteration 2050, Loss: 0.0008519597467966378\n",
      "Iteration 2060, Loss: 0.00047962457756511867\n",
      "Iteration 2070, Loss: 0.0004412484122440219\n",
      "Iteration 2080, Loss: 0.0011361564975231886\n",
      "Iteration 2090, Loss: 0.0010955153265967965\n",
      "Iteration 2100, Loss: 0.0005146823241375387\n",
      "Iteration 2110, Loss: 0.0003927001671399921\n",
      "Iteration 2120, Loss: 0.0004175493377260864\n",
      "Iteration 2130, Loss: 0.0012175505980849266\n",
      "Iteration 2140, Loss: 0.0003460260631982237\n",
      "Iteration 2150, Loss: 0.0003156341554131359\n",
      "Iteration 2160, Loss: 0.0006871931254863739\n",
      "Iteration 2170, Loss: 0.0012743626721203327\n",
      "Iteration 2180, Loss: 0.0018033976666629314\n",
      "Iteration 2190, Loss: 0.000641099875792861\n",
      "Iteration 2200, Loss: 0.0003229973081033677\n",
      "Iteration 2210, Loss: 0.00034507602686062455\n",
      "Iteration 2220, Loss: 0.0003182317886967212\n",
      "Iteration 2230, Loss: 0.00046850621583871543\n",
      "Iteration 2240, Loss: 0.00047955772606655955\n",
      "Iteration 2250, Loss: 0.0014660218730568886\n",
      "Iteration 2260, Loss: 0.0014961168635636568\n",
      "Iteration 2270, Loss: 0.0011497973464429379\n",
      "Iteration 2280, Loss: 0.0005451601464301348\n",
      "Iteration 2290, Loss: 0.0003364608564879745\n",
      "Iteration 2300, Loss: 0.00029601514688692987\n",
      "Iteration 2310, Loss: 0.00030705201788805425\n",
      "Iteration 2320, Loss: 0.0003448653151281178\n",
      "Iteration 2330, Loss: 0.0007699120906181633\n",
      "Iteration 2340, Loss: 0.0011810013093054295\n",
      "Iteration 2350, Loss: 0.000449101731646806\n",
      "Iteration 2360, Loss: 0.00034744752338156104\n",
      "Iteration 2370, Loss: 0.00031271661282517016\n",
      "Iteration 2380, Loss: 0.00041245768079534173\n",
      "Iteration 2390, Loss: 0.0014404788380488753\n",
      "Iteration 2400, Loss: 0.0011126152239739895\n",
      "Iteration 2410, Loss: 0.00044694452662952244\n",
      "Iteration 2420, Loss: 0.0005616266862489283\n",
      "Iteration 2430, Loss: 0.0006478982977569103\n",
      "Iteration 2440, Loss: 0.0008512765634804964\n",
      "Iteration 2450, Loss: 0.0005267906817607582\n",
      "Iteration 2460, Loss: 0.00029613677179440856\n",
      "Iteration 2470, Loss: 0.0009669370483607054\n",
      "Iteration 2480, Loss: 0.0008310374687425792\n",
      "Iteration 2490, Loss: 0.00039079628186300397\n",
      "Iteration 2500, Loss: 0.0005435386556200683\n",
      "Iteration 2510, Loss: 0.0002919948019552976\n",
      "Iteration 2520, Loss: 0.00031025087810121477\n",
      "Iteration 2530, Loss: 0.000551147386431694\n",
      "Iteration 2540, Loss: 0.004770378116518259\n",
      "Iteration 2550, Loss: 0.002015481237322092\n",
      "Iteration 2560, Loss: 0.000808966695331037\n",
      "Iteration 2570, Loss: 0.00033004715805873275\n",
      "Iteration 2580, Loss: 0.0003382497525308281\n",
      "Iteration 2590, Loss: 0.00028058516909368336\n",
      "Iteration 2600, Loss: 0.0002762054791674018\n",
      "Iteration 2610, Loss: 0.0003138250613119453\n",
      "Iteration 2620, Loss: 0.00040878032450564206\n",
      "Iteration 2630, Loss: 0.0006712198373861611\n",
      "Iteration 2640, Loss: 0.0004355567798484117\n",
      "Iteration 2650, Loss: 0.0014992087380960584\n",
      "Iteration 2660, Loss: 0.0004598000377882272\n",
      "Iteration 2670, Loss: 0.0004493453598115593\n",
      "Iteration 2680, Loss: 0.00026714784326031804\n",
      "Iteration 2690, Loss: 0.0002817309577949345\n",
      "Iteration 2700, Loss: 0.0003637156041804701\n",
      "Iteration 2710, Loss: 0.001433105207979679\n",
      "Iteration 2720, Loss: 0.0026107316371053457\n",
      "Iteration 2730, Loss: 0.0013796569546684623\n",
      "Iteration 2740, Loss: 0.0005968077457509935\n",
      "Iteration 2750, Loss: 0.0004902257351204753\n",
      "Iteration 2760, Loss: 0.00042185073834843934\n",
      "Iteration 2770, Loss: 0.0002861233660951257\n",
      "Iteration 2780, Loss: 0.0002630501985549927\n",
      "Iteration 2790, Loss: 0.00026832844014279544\n",
      "Iteration 2800, Loss: 0.00029965300927869976\n",
      "Iteration 2810, Loss: 0.0005132016376592219\n",
      "Iteration 2820, Loss: 0.002539091743528843\n",
      "Iteration 2830, Loss: 0.0017147492617368698\n",
      "Iteration 2840, Loss: 0.00046359162661246955\n",
      "Iteration 2850, Loss: 0.000273521727649495\n",
      "Iteration 2860, Loss: 0.00026979565154761076\n",
      "Iteration 2870, Loss: 0.0004380150930956006\n",
      "Iteration 2880, Loss: 0.0002594867837615311\n",
      "Iteration 2890, Loss: 0.0005112545331940055\n",
      "Iteration 2900, Loss: 0.0002660214086063206\n",
      "Iteration 2910, Loss: 0.0004820175818167627\n",
      "Iteration 2920, Loss: 0.00265585002489388\n",
      "Iteration 2930, Loss: 0.00026241797604598105\n",
      "Iteration 2940, Loss: 0.00046146009117364883\n",
      "Iteration 2950, Loss: 0.00035924886469729245\n",
      "Iteration 2960, Loss: 0.00048674887511879206\n",
      "Iteration 2970, Loss: 0.0007989013101905584\n",
      "Iteration 2980, Loss: 0.00039326338446699083\n",
      "Iteration 2990, Loss: 0.0004982744576409459\n",
      "Iteration 3000, Loss: 0.0004773667606059462\n",
      "Iteration 3010, Loss: 0.00022924004588276148\n",
      "Iteration 3020, Loss: 0.0006215876783244312\n",
      "Iteration 3030, Loss: 0.004745090380311012\n",
      "Iteration 3040, Loss: 0.0016761416336521506\n",
      "Iteration 3050, Loss: 0.0008124307496473193\n",
      "Iteration 3060, Loss: 0.0003178690676577389\n",
      "Iteration 3070, Loss: 0.0002650303940754384\n",
      "Iteration 3080, Loss: 0.0002424257982056588\n",
      "Iteration 3090, Loss: 0.00023925461573526263\n",
      "Iteration 3100, Loss: 0.0003038350841961801\n",
      "Iteration 3110, Loss: 0.00024872348876670003\n",
      "Iteration 3120, Loss: 0.00031330093042925\n",
      "Iteration 3130, Loss: 0.0004249798657838255\n",
      "Iteration 3140, Loss: 0.0004803895717486739\n",
      "Iteration 3150, Loss: 0.0006758089293725789\n",
      "Iteration 3160, Loss: 0.0007273348164744675\n",
      "Iteration 3170, Loss: 0.0006980780744925141\n",
      "Iteration 3180, Loss: 0.0027451866772025824\n",
      "Iteration 3190, Loss: 0.0016140869120135903\n",
      "Iteration 3200, Loss: 0.00041702474118210375\n",
      "Iteration 3210, Loss: 0.0003098713932558894\n",
      "Iteration 3220, Loss: 0.000310890085529536\n",
      "Iteration 3230, Loss: 0.0002980784047394991\n",
      "Iteration 3240, Loss: 0.00024525256594642997\n",
      "Iteration 3250, Loss: 0.00030240591149777174\n",
      "Iteration 3260, Loss: 0.00045755613246001303\n",
      "Iteration 3270, Loss: 0.0006877541891299188\n",
      "Iteration 3280, Loss: 0.0014541514683514833\n",
      "Iteration 3290, Loss: 0.0002788262499962002\n",
      "Iteration 3300, Loss: 0.0006297152140177786\n",
      "Iteration 3310, Loss: 0.0004596936923917383\n",
      "Iteration 3320, Loss: 0.00023006234550848603\n",
      "Iteration 3330, Loss: 0.00033914533560164273\n",
      "Iteration 3340, Loss: 0.00044846569653600454\n",
      "Iteration 3350, Loss: 0.0013674416113644838\n",
      "Iteration 3360, Loss: 0.00207011797465384\n",
      "Iteration 3370, Loss: 0.0011339591583237052\n",
      "Iteration 3380, Loss: 0.0002810416917782277\n",
      "Iteration 3390, Loss: 0.0002269042015541345\n",
      "Iteration 3400, Loss: 0.0002333825104869902\n",
      "Iteration 3410, Loss: 0.0002476779918652028\n",
      "Iteration 3420, Loss: 0.002611484844237566\n",
      "Iteration 3430, Loss: 0.0004028680268675089\n",
      "Iteration 3440, Loss: 0.00028685887809842825\n",
      "Iteration 3450, Loss: 0.00025544458185322583\n",
      "Iteration 3460, Loss: 0.00031378239509649575\n",
      "Iteration 3470, Loss: 0.00023404552484862506\n",
      "Iteration 3480, Loss: 0.0002240910253021866\n",
      "Iteration 3490, Loss: 0.00026223910390399396\n",
      "Iteration 3500, Loss: 0.00024100689915940166\n",
      "Iteration 3510, Loss: 0.00021760910749435425\n",
      "Iteration 3520, Loss: 0.0002580564469099045\n",
      "Iteration 3530, Loss: 0.00228888844139874\n",
      "Iteration 3540, Loss: 0.00040623117820359766\n",
      "Iteration 3550, Loss: 0.0018519120058044791\n",
      "Iteration 3560, Loss: 0.00022415675630327314\n",
      "Iteration 3570, Loss: 0.0003613739099819213\n",
      "Iteration 3580, Loss: 0.00024970551021397114\n",
      "Iteration 3590, Loss: 0.0002698231546673924\n",
      "Iteration 3600, Loss: 0.00029217684641480446\n",
      "Iteration 3610, Loss: 0.00021267373813316226\n",
      "Iteration 3620, Loss: 0.00020410804427228868\n",
      "Iteration 3630, Loss: 0.0002453571942169219\n",
      "Iteration 3640, Loss: 0.0002668576780706644\n",
      "Iteration 3650, Loss: 0.00020845684048254043\n",
      "Iteration 3660, Loss: 0.00020759552717208862\n",
      "Iteration 3670, Loss: 0.00021235567692201585\n",
      "Iteration 3680, Loss: 0.0004830490506719798\n",
      "Iteration 3690, Loss: 0.00020689099619630724\n",
      "Iteration 3700, Loss: 0.0006006240146234632\n",
      "Iteration 3710, Loss: 0.00216334848664701\n",
      "Iteration 3720, Loss: 0.00021817242668475956\n",
      "Iteration 3730, Loss: 0.0007225803565233946\n",
      "Iteration 3740, Loss: 0.0002095848467433825\n",
      "Iteration 3750, Loss: 0.00020297009905334562\n",
      "Iteration 3760, Loss: 0.00028913465212099254\n",
      "Iteration 3770, Loss: 0.0005527378525584936\n",
      "Iteration 3780, Loss: 0.0017318051541224122\n",
      "Iteration 3790, Loss: 0.0004956689663231373\n",
      "Iteration 3800, Loss: 0.0009310252498835325\n",
      "Iteration 3810, Loss: 0.0004410075198393315\n",
      "Iteration 3820, Loss: 0.0004860271292272955\n",
      "Iteration 3830, Loss: 0.00018879162962548435\n",
      "Iteration 3840, Loss: 0.0002719145850278437\n",
      "Iteration 3850, Loss: 0.000290050869807601\n",
      "Iteration 3860, Loss: 0.0006180931231938303\n",
      "Iteration 3870, Loss: 0.0009907905478030443\n",
      "Iteration 3880, Loss: 0.00039243430364876986\n",
      "Iteration 3890, Loss: 0.0002225223433924839\n",
      "Iteration 3900, Loss: 0.00020934028725605458\n",
      "Iteration 3910, Loss: 0.0012188841355964541\n",
      "Iteration 3920, Loss: 0.0015259420033544302\n",
      "Iteration 3930, Loss: 0.000738777918741107\n",
      "Iteration 3940, Loss: 0.0003019025025423616\n",
      "Iteration 3950, Loss: 0.00030060045537538826\n",
      "Iteration 3960, Loss: 0.00022066771634854376\n",
      "Iteration 3970, Loss: 0.0004623769491445273\n",
      "Iteration 3980, Loss: 0.00019359721045475453\n",
      "Iteration 3990, Loss: 0.0004451946879271418\n",
      "Iteration 4000, Loss: 0.00021079080761410296\n",
      "Iteration 4010, Loss: 0.00020819988276343793\n",
      "Iteration 4020, Loss: 0.0002114302769768983\n",
      "Iteration 4030, Loss: 0.00031789083732292056\n",
      "Iteration 4040, Loss: 0.006255319807678461\n",
      "Iteration 4050, Loss: 0.002845519920811057\n",
      "Iteration 4060, Loss: 0.00018813999486155808\n",
      "Iteration 4070, Loss: 0.0004602273111231625\n",
      "Iteration 4080, Loss: 0.00017431967717129737\n",
      "Iteration 4090, Loss: 0.00017782974464353174\n",
      "Iteration 4100, Loss: 0.00017270000535063446\n",
      "Iteration 4110, Loss: 0.00017860348452813923\n",
      "Iteration 4120, Loss: 0.00018341201939620078\n",
      "Iteration 4130, Loss: 0.00018319558876100928\n",
      "Iteration 4140, Loss: 0.00017208344070240855\n",
      "Iteration 4150, Loss: 0.00018418492982164025\n",
      "Iteration 4160, Loss: 0.00022593274479731917\n",
      "Iteration 4170, Loss: 0.0006562882917933166\n",
      "Iteration 4180, Loss: 0.0001647752505959943\n",
      "Iteration 4190, Loss: 0.0002132250665454194\n",
      "Iteration 4200, Loss: 0.0002914133365266025\n",
      "Iteration 4210, Loss: 0.002374780597165227\n",
      "Iteration 4220, Loss: 0.00017720111645758152\n",
      "Iteration 4230, Loss: 0.00026128458557650447\n",
      "Iteration 4240, Loss: 0.00022246286971494555\n",
      "Iteration 4250, Loss: 0.00016798388969618827\n",
      "Iteration 4260, Loss: 0.00016664230497553945\n",
      "Iteration 4270, Loss: 0.00028969618142582476\n",
      "Iteration 4280, Loss: 0.0001691424404270947\n",
      "Iteration 4290, Loss: 0.00029816385358572006\n",
      "Iteration 4300, Loss: 0.00019832684483844787\n",
      "Iteration 4310, Loss: 0.0007018628530204296\n",
      "Iteration 4320, Loss: 0.0002839617372956127\n",
      "Iteration 4330, Loss: 0.00037789077032357454\n",
      "Iteration 4340, Loss: 0.0010736668482422829\n",
      "Iteration 4350, Loss: 0.000491467653773725\n",
      "Iteration 4360, Loss: 0.000288566603558138\n",
      "Iteration 4370, Loss: 0.00016468239482492208\n",
      "Iteration 4380, Loss: 0.0002993415400851518\n",
      "Iteration 4390, Loss: 0.0038250871002674103\n",
      "Iteration 4400, Loss: 0.0008435827330686152\n",
      "Iteration 4410, Loss: 0.0005996671970933676\n",
      "Iteration 4420, Loss: 0.00039209716487675905\n",
      "Iteration 4430, Loss: 0.0001722144370432943\n",
      "Iteration 4440, Loss: 0.0001538118376629427\n",
      "Iteration 4450, Loss: 0.00017144170124083757\n",
      "Iteration 4460, Loss: 0.00015409180196002126\n",
      "Iteration 4470, Loss: 0.0003369686601217836\n",
      "Iteration 4480, Loss: 0.0010101470397785306\n",
      "Iteration 4490, Loss: 0.0007137623615562916\n",
      "Iteration 4500, Loss: 0.00044810198596678674\n",
      "Iteration 4510, Loss: 0.0007194795762188733\n",
      "Iteration 4520, Loss: 0.00016616519133094698\n",
      "Iteration 4530, Loss: 0.000197219371329993\n",
      "Iteration 4540, Loss: 0.0004865841765422374\n",
      "Iteration 4550, Loss: 0.0006224338430911303\n",
      "Iteration 4560, Loss: 0.00037816097028553486\n",
      "Iteration 4570, Loss: 0.00016104985843412578\n",
      "Iteration 4580, Loss: 0.00020631485676858574\n",
      "Iteration 4590, Loss: 0.0013671255437657237\n",
      "Iteration 4600, Loss: 0.0010513821616768837\n",
      "Iteration 4610, Loss: 0.0009972546249628067\n",
      "Iteration 4620, Loss: 0.00039806615677662194\n",
      "Iteration 4630, Loss: 0.00017944099090527743\n",
      "Iteration 4640, Loss: 0.00020016892813146114\n",
      "Iteration 4650, Loss: 0.00013237426173873246\n",
      "Iteration 4660, Loss: 0.0001396793668391183\n",
      "Iteration 4670, Loss: 0.0001464363740524277\n",
      "Iteration 4680, Loss: 0.00012118637096136808\n",
      "Iteration 4690, Loss: 0.00012219812197145075\n",
      "Iteration 4700, Loss: 0.0002503924770280719\n",
      "Iteration 4710, Loss: 0.00018345624266657978\n",
      "Iteration 4720, Loss: 0.0002009142335737124\n",
      "Iteration 4730, Loss: 0.00012467836495488882\n",
      "Iteration 4740, Loss: 0.00029352842830121517\n",
      "Iteration 4750, Loss: 0.00013382297765929252\n",
      "Iteration 4760, Loss: 0.00011747523967642337\n",
      "Iteration 4770, Loss: 0.0013415561988949776\n",
      "Iteration 4780, Loss: 0.0014452538453042507\n",
      "Iteration 4790, Loss: 0.00014359562192112207\n",
      "Iteration 4800, Loss: 0.0002655943389981985\n",
      "Iteration 4810, Loss: 0.00014687562361359596\n",
      "Iteration 4820, Loss: 0.00011400935909477994\n",
      "Iteration 4830, Loss: 0.00011083667777711526\n",
      "Iteration 4840, Loss: 0.00012145704386057332\n",
      "Iteration 4850, Loss: 0.00013484164082910866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  17%|█▋        | 4/24 [02:16<13:36, 40.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4860, Loss: 0.00011584313324419782\n",
      "Stopping early at iteration 4863\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 4864, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014306728539306885, 'L2_avg': 0.019071992516010838, 'End_point_L1_avg': 0.006490992177107342, 'End_point_L2_avg': 0.00653498256016762}\n",
      "Iteration 0, Loss: 0.982367753982544\n",
      "Iteration 10, Loss: 0.7456194162368774\n",
      "Iteration 20, Loss: 0.5649545192718506\n",
      "Iteration 30, Loss: 0.4321728050708771\n",
      "Iteration 40, Loss: 0.3274509310722351\n",
      "Iteration 50, Loss: 0.2547001242637634\n",
      "Iteration 60, Loss: 0.18385134637355804\n",
      "Iteration 70, Loss: 0.16150441765785217\n",
      "Iteration 80, Loss: 0.11753492802381516\n",
      "Iteration 90, Loss: 0.08970631659030914\n",
      "Iteration 100, Loss: 0.08180307596921921\n",
      "Iteration 110, Loss: 0.0585513636469841\n",
      "Iteration 120, Loss: 0.05540384724736214\n",
      "Iteration 130, Loss: 0.04470246285200119\n",
      "Iteration 140, Loss: 0.042638733983039856\n",
      "Iteration 150, Loss: 0.03809034451842308\n",
      "Iteration 160, Loss: 0.04215696081519127\n",
      "Iteration 170, Loss: 0.03971273452043533\n",
      "Iteration 180, Loss: 0.032441169023513794\n",
      "Iteration 190, Loss: 0.027813732624053955\n",
      "Iteration 200, Loss: 0.02417103387415409\n",
      "Iteration 210, Loss: 0.021567104384303093\n",
      "Iteration 220, Loss: 0.018988139927387238\n",
      "Iteration 230, Loss: 0.020001692697405815\n",
      "Iteration 240, Loss: 0.017750602215528488\n",
      "Iteration 250, Loss: 0.01675044372677803\n",
      "Iteration 260, Loss: 0.016012419015169144\n",
      "Iteration 270, Loss: 0.012887842021882534\n",
      "Iteration 280, Loss: 0.012727112509310246\n",
      "Iteration 290, Loss: 0.012776244431734085\n",
      "Iteration 300, Loss: 0.013959945179522038\n",
      "Iteration 310, Loss: 0.012688085436820984\n",
      "Iteration 320, Loss: 0.00898551195859909\n",
      "Iteration 330, Loss: 0.010041451081633568\n",
      "Iteration 340, Loss: 0.009857888333499432\n",
      "Iteration 350, Loss: 0.009676030836999416\n",
      "Iteration 360, Loss: 0.009970986284315586\n",
      "Iteration 370, Loss: 0.008211683481931686\n",
      "Iteration 380, Loss: 0.008666310459375381\n",
      "Iteration 390, Loss: 0.009892594069242477\n",
      "Iteration 400, Loss: 0.008760611526668072\n",
      "Iteration 410, Loss: 0.007916057482361794\n",
      "Iteration 420, Loss: 0.008120379410684109\n",
      "Iteration 430, Loss: 0.007674654945731163\n",
      "Iteration 440, Loss: 0.008558584377169609\n",
      "Iteration 450, Loss: 0.007400920614600182\n",
      "Iteration 460, Loss: 0.007712526246905327\n",
      "Iteration 470, Loss: 0.006969185546040535\n",
      "Iteration 480, Loss: 0.007000274490565062\n",
      "Iteration 490, Loss: 0.005203049164265394\n",
      "Iteration 500, Loss: 0.0058027515187859535\n",
      "Iteration 510, Loss: 0.006334776524454355\n",
      "Iteration 520, Loss: 0.00609007989987731\n",
      "Iteration 530, Loss: 0.005606189835816622\n",
      "Iteration 540, Loss: 0.004859028849750757\n",
      "Iteration 550, Loss: 0.006172963883727789\n",
      "Iteration 560, Loss: 0.00490593770518899\n",
      "Iteration 570, Loss: 0.005167006514966488\n",
      "Iteration 580, Loss: 0.0050515830516815186\n",
      "Iteration 590, Loss: 0.0048058065585792065\n",
      "Iteration 600, Loss: 0.004738564603030682\n",
      "Iteration 610, Loss: 0.004686237312853336\n",
      "Iteration 620, Loss: 0.004799413960427046\n",
      "Iteration 630, Loss: 0.004506814293563366\n",
      "Iteration 640, Loss: 0.004389623645693064\n",
      "Iteration 650, Loss: 0.004307313356548548\n",
      "Iteration 660, Loss: 0.004499031696468592\n",
      "Iteration 670, Loss: 0.004295965190976858\n",
      "Iteration 680, Loss: 0.0037713723722845316\n",
      "Iteration 690, Loss: 0.004248989280313253\n",
      "Iteration 700, Loss: 0.004286108072847128\n",
      "Iteration 710, Loss: 0.003954084124416113\n",
      "Iteration 720, Loss: 0.004277651663869619\n",
      "Iteration 730, Loss: 0.004288429394364357\n",
      "Iteration 740, Loss: 0.0038698266725987196\n",
      "Iteration 750, Loss: 0.0034398299176245928\n",
      "Iteration 760, Loss: 0.0038636557292193174\n",
      "Iteration 770, Loss: 0.0037611257284879684\n",
      "Iteration 780, Loss: 0.003663246985524893\n",
      "Iteration 790, Loss: 0.004090920556336641\n",
      "Iteration 800, Loss: 0.003346873912960291\n",
      "Iteration 810, Loss: 0.0036505344323813915\n",
      "Iteration 820, Loss: 0.0036197593435645103\n",
      "Iteration 830, Loss: 0.0035161813721060753\n",
      "Iteration 840, Loss: 0.003471939591690898\n",
      "Iteration 850, Loss: 0.0035235676914453506\n",
      "Iteration 860, Loss: 0.003651016391813755\n",
      "Iteration 870, Loss: 0.003661073511466384\n",
      "Iteration 880, Loss: 0.0035985324066132307\n",
      "Iteration 890, Loss: 0.003364273812621832\n",
      "Iteration 900, Loss: 0.0029604854062199593\n",
      "Iteration 910, Loss: 0.002747897757217288\n",
      "Iteration 920, Loss: 0.003280129050835967\n",
      "Iteration 930, Loss: 0.003203310538083315\n",
      "Iteration 940, Loss: 0.003346669487655163\n",
      "Iteration 950, Loss: 0.003275589318946004\n",
      "Iteration 960, Loss: 0.0030657544266432524\n",
      "Iteration 970, Loss: 0.0027444164734333754\n",
      "Iteration 980, Loss: 0.0027909288182854652\n",
      "Iteration 990, Loss: 0.0028531234711408615\n",
      "Iteration 1000, Loss: 0.003156539285555482\n",
      "Iteration 1010, Loss: 0.003115178318694234\n",
      "Iteration 1020, Loss: 0.003094194922596216\n",
      "Iteration 1030, Loss: 0.002552644582465291\n",
      "Iteration 1040, Loss: 0.0030571084935218096\n",
      "Iteration 1050, Loss: 0.0026332412380725145\n",
      "Iteration 1060, Loss: 0.0029371939599514008\n",
      "Iteration 1070, Loss: 0.0028560806531459093\n",
      "Iteration 1080, Loss: 0.002831454388797283\n",
      "Iteration 1090, Loss: 0.002571315038949251\n",
      "Iteration 1100, Loss: 0.0024136255960911512\n",
      "Iteration 1110, Loss: 0.002822937211021781\n",
      "Iteration 1120, Loss: 0.00264371233060956\n",
      "Iteration 1130, Loss: 0.0024907123297452927\n",
      "Iteration 1140, Loss: 0.0027523809112608433\n",
      "Iteration 1150, Loss: 0.0025345783215016127\n",
      "Iteration 1160, Loss: 0.0024263018276542425\n",
      "Iteration 1170, Loss: 0.0024654476437717676\n",
      "Iteration 1180, Loss: 0.0026457554195076227\n",
      "Iteration 1190, Loss: 0.00219121971167624\n",
      "Iteration 1200, Loss: 0.002326943911612034\n",
      "Iteration 1210, Loss: 0.0023853403981775045\n",
      "Iteration 1220, Loss: 0.0027123766485601664\n",
      "Iteration 1230, Loss: 0.0023898379877209663\n",
      "Iteration 1240, Loss: 0.0025185931008309126\n",
      "Iteration 1250, Loss: 0.0025215386413037777\n",
      "Iteration 1260, Loss: 0.0020899337250739336\n",
      "Iteration 1270, Loss: 0.002150279935449362\n",
      "Iteration 1280, Loss: 0.0023339109029620886\n",
      "Iteration 1290, Loss: 0.0020461103413254023\n",
      "Iteration 1300, Loss: 0.0021795015782117844\n",
      "Iteration 1310, Loss: 0.0021489590872079134\n",
      "Iteration 1320, Loss: 0.002258154796436429\n",
      "Iteration 1330, Loss: 0.002233226550742984\n",
      "Iteration 1340, Loss: 0.0023142725694924593\n",
      "Iteration 1350, Loss: 0.0021799239329993725\n",
      "Iteration 1360, Loss: 0.0023050783202052116\n",
      "Iteration 1370, Loss: 0.002024935558438301\n",
      "Iteration 1380, Loss: 0.0020882633980363607\n",
      "Iteration 1390, Loss: 0.0020856354385614395\n",
      "Iteration 1400, Loss: 0.0021419955883175135\n",
      "Iteration 1410, Loss: 0.0020524845458567142\n",
      "Iteration 1420, Loss: 0.0019655688665807247\n",
      "Iteration 1430, Loss: 0.0017903897678479552\n",
      "Iteration 1440, Loss: 0.0018431521020829678\n",
      "Iteration 1450, Loss: 0.0022250062320381403\n",
      "Iteration 1460, Loss: 0.0018646444659680128\n",
      "Iteration 1470, Loss: 0.0018142738845199347\n",
      "Iteration 1480, Loss: 0.0016915411688387394\n",
      "Iteration 1490, Loss: 0.0017735091969370842\n",
      "Iteration 1500, Loss: 0.0018430890049785376\n",
      "Iteration 1510, Loss: 0.0020316217560321093\n",
      "Iteration 1520, Loss: 0.0017587196780368686\n",
      "Iteration 1530, Loss: 0.0021496624685823917\n",
      "Iteration 1540, Loss: 0.0016695745289325714\n",
      "Iteration 1550, Loss: 0.002010704018175602\n",
      "Iteration 1560, Loss: 0.001936069573275745\n",
      "Iteration 1570, Loss: 0.0020108562894165516\n",
      "Iteration 1580, Loss: 0.0020128728356212378\n",
      "Iteration 1590, Loss: 0.001774498145096004\n",
      "Iteration 1600, Loss: 0.0018602476920932531\n",
      "Iteration 1610, Loss: 0.0019314278615638614\n",
      "Iteration 1620, Loss: 0.0019294931553304195\n",
      "Iteration 1630, Loss: 0.0016496311873197556\n",
      "Iteration 1640, Loss: 0.0017274493584409356\n",
      "Iteration 1650, Loss: 0.0018390982877463102\n",
      "Iteration 1660, Loss: 0.0017241514287889004\n",
      "Iteration 1670, Loss: 0.0016940877540037036\n",
      "Iteration 1680, Loss: 0.001884863362647593\n",
      "Iteration 1690, Loss: 0.0018502477323636413\n",
      "Iteration 1700, Loss: 0.0016435374272987247\n",
      "Iteration 1710, Loss: 0.0016855135327205062\n",
      "Iteration 1720, Loss: 0.0016683446010574698\n",
      "Iteration 1730, Loss: 0.001603438169695437\n",
      "Iteration 1740, Loss: 0.0017351475544273853\n",
      "Iteration 1750, Loss: 0.001695809536613524\n",
      "Iteration 1760, Loss: 0.0018288899445906281\n",
      "Iteration 1770, Loss: 0.001609798171557486\n",
      "Iteration 1780, Loss: 0.0017045775894075632\n",
      "Iteration 1790, Loss: 0.0016476642340421677\n",
      "Iteration 1800, Loss: 0.0016754883108660579\n",
      "Iteration 1810, Loss: 0.0016588032012805343\n",
      "Iteration 1820, Loss: 0.0018095336854457855\n",
      "Iteration 1830, Loss: 0.0015641964273527265\n",
      "Iteration 1840, Loss: 0.0016120981890708208\n",
      "Iteration 1850, Loss: 0.0016510222340002656\n",
      "Iteration 1860, Loss: 0.0015217999462038279\n",
      "Iteration 1870, Loss: 0.0017099403776228428\n",
      "Iteration 1880, Loss: 0.0014342310605570674\n",
      "Iteration 1890, Loss: 0.0015476547414436936\n",
      "Iteration 1900, Loss: 0.0015280517982318997\n",
      "Iteration 1910, Loss: 0.0015044528990983963\n",
      "Iteration 1920, Loss: 0.001590039348229766\n",
      "Iteration 1930, Loss: 0.0017075866926461458\n",
      "Iteration 1940, Loss: 0.0015179278561845422\n",
      "Iteration 1950, Loss: 0.0015725892735645175\n",
      "Iteration 1960, Loss: 0.0015595502918586135\n",
      "Iteration 1970, Loss: 0.0014038106892257929\n",
      "Iteration 1980, Loss: 0.0015541642205789685\n",
      "Iteration 1990, Loss: 0.001618904760107398\n",
      "Iteration 2000, Loss: 0.0014354309532791376\n",
      "Iteration 2010, Loss: 0.0013040357735008001\n",
      "Iteration 2020, Loss: 0.0013751598307862878\n",
      "Iteration 2030, Loss: 0.0014226650819182396\n",
      "Iteration 2040, Loss: 0.0012872739462181926\n",
      "Iteration 2050, Loss: 0.0014088436728343368\n",
      "Iteration 2060, Loss: 0.0016425580251961946\n",
      "Iteration 2070, Loss: 0.0015904040774330497\n",
      "Iteration 2080, Loss: 0.0016180804232135415\n",
      "Iteration 2090, Loss: 0.0013964871177449822\n",
      "Iteration 2100, Loss: 0.001439326093532145\n",
      "Iteration 2110, Loss: 0.0014799333875998855\n",
      "Iteration 2120, Loss: 0.0014160877326503396\n",
      "Iteration 2130, Loss: 0.001310883555561304\n",
      "Iteration 2140, Loss: 0.001370004378259182\n",
      "Iteration 2150, Loss: 0.0014950059121474624\n",
      "Iteration 2160, Loss: 0.0016128427814692259\n",
      "Iteration 2170, Loss: 0.001548372907564044\n",
      "Iteration 2180, Loss: 0.001314816065132618\n",
      "Iteration 2190, Loss: 0.0014200164005160332\n",
      "Iteration 2200, Loss: 0.0014456437202170491\n",
      "Iteration 2210, Loss: 0.0013433628482744098\n",
      "Iteration 2220, Loss: 0.001263928133994341\n",
      "Iteration 2230, Loss: 0.0014202481834217906\n",
      "Iteration 2240, Loss: 0.0013841638574376702\n",
      "Iteration 2250, Loss: 0.001355996006168425\n",
      "Iteration 2260, Loss: 0.0013012629933655262\n",
      "Iteration 2270, Loss: 0.001326367724686861\n",
      "Iteration 2280, Loss: 0.0012087628711014986\n",
      "Iteration 2290, Loss: 0.001260970951989293\n",
      "Iteration 2300, Loss: 0.0013744173338636756\n",
      "Iteration 2310, Loss: 0.0014935994986444712\n",
      "Iteration 2320, Loss: 0.0014113698853179812\n",
      "Iteration 2330, Loss: 0.0014515024377033114\n",
      "Iteration 2340, Loss: 0.001345716998912394\n",
      "Iteration 2350, Loss: 0.00129901769105345\n",
      "Iteration 2360, Loss: 0.0012314034393057227\n",
      "Iteration 2370, Loss: 0.0012892752420157194\n",
      "Iteration 2380, Loss: 0.001325158984400332\n",
      "Iteration 2390, Loss: 0.0013372879475355148\n",
      "Iteration 2400, Loss: 0.0013703173026442528\n",
      "Iteration 2410, Loss: 0.0012859920971095562\n",
      "Iteration 2420, Loss: 0.0012669343268498778\n",
      "Iteration 2430, Loss: 0.0012204707600176334\n",
      "Iteration 2440, Loss: 0.0012693984899669886\n",
      "Iteration 2450, Loss: 0.001239488716237247\n",
      "Iteration 2460, Loss: 0.0011680829338729382\n",
      "Iteration 2470, Loss: 0.0013517026090994477\n",
      "Iteration 2480, Loss: 0.001305816462263465\n",
      "Iteration 2490, Loss: 0.0011986190220341086\n",
      "Iteration 2500, Loss: 0.00128728908021003\n",
      "Iteration 2510, Loss: 0.0012638792395591736\n",
      "Iteration 2520, Loss: 0.001325253746472299\n",
      "Iteration 2530, Loss: 0.0011719404719769955\n",
      "Iteration 2540, Loss: 0.001162204658612609\n",
      "Iteration 2550, Loss: 0.0012247436679899693\n",
      "Iteration 2560, Loss: 0.001270938548259437\n",
      "Iteration 2570, Loss: 0.0012309676967561245\n",
      "Iteration 2580, Loss: 0.0012366223381832242\n",
      "Iteration 2590, Loss: 0.0012746690772473812\n",
      "Iteration 2600, Loss: 0.0011687445221468806\n",
      "Iteration 2610, Loss: 0.0011928182793781161\n",
      "Iteration 2620, Loss: 0.00116473319940269\n",
      "Iteration 2630, Loss: 0.001091385493054986\n",
      "Iteration 2640, Loss: 0.0011985789751634002\n",
      "Iteration 2650, Loss: 0.0011782448273152113\n",
      "Iteration 2660, Loss: 0.0010849348036572337\n",
      "Iteration 2670, Loss: 0.0010757078416645527\n",
      "Iteration 2680, Loss: 0.001216880395077169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  21%|██        | 5/24 [02:57<12:58, 41.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2690, Loss: 0.0011621591402217746\n",
      "Stopping early at iteration 2694\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 2695, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0481469112452197, 'L2_avg': 0.06242498096786903, 'End_point_L1_avg': 0.028318207660334917, 'End_point_L2_avg': 0.028417712752699047}\n",
      "Iteration 0, Loss: 1.46030592918396\n",
      "Iteration 10, Loss: 1.1040533781051636\n",
      "Iteration 20, Loss: 0.8566445708274841\n",
      "Iteration 30, Loss: 0.666770339012146\n",
      "Iteration 40, Loss: 0.5137699246406555\n",
      "Iteration 50, Loss: 0.3935956358909607\n",
      "Iteration 60, Loss: 0.3010382652282715\n",
      "Iteration 70, Loss: 0.2322084754705429\n",
      "Iteration 80, Loss: 0.18010872602462769\n",
      "Iteration 90, Loss: 0.13888335227966309\n",
      "Iteration 100, Loss: 0.10958448052406311\n",
      "Iteration 110, Loss: 0.09276589006185532\n",
      "Iteration 120, Loss: 0.06890811026096344\n",
      "Iteration 130, Loss: 0.06247285380959511\n",
      "Iteration 140, Loss: 0.06200812757015228\n",
      "Iteration 150, Loss: 0.05320866405963898\n",
      "Iteration 160, Loss: 0.04040747508406639\n",
      "Iteration 170, Loss: 0.0419146865606308\n",
      "Iteration 180, Loss: 0.038405612111091614\n",
      "Iteration 190, Loss: 0.0369446724653244\n",
      "Iteration 200, Loss: 0.03502918779850006\n",
      "Iteration 210, Loss: 0.03008042275905609\n",
      "Iteration 220, Loss: 0.032728131860494614\n",
      "Iteration 230, Loss: 0.030675511807203293\n",
      "Iteration 240, Loss: 0.031789328902959824\n",
      "Iteration 250, Loss: 0.030065838247537613\n",
      "Iteration 260, Loss: 0.022450745105743408\n",
      "Iteration 270, Loss: 0.027706749737262726\n",
      "Iteration 280, Loss: 0.025253070518374443\n",
      "Iteration 290, Loss: 0.023019939661026\n",
      "Iteration 300, Loss: 0.018492067232728004\n",
      "Iteration 310, Loss: 0.016752639785408974\n",
      "Iteration 320, Loss: 0.02053067833185196\n",
      "Iteration 330, Loss: 0.016689810901880264\n",
      "Iteration 340, Loss: 0.014808174222707748\n",
      "Iteration 350, Loss: 0.015685277059674263\n",
      "Iteration 360, Loss: 0.013622894883155823\n",
      "Iteration 370, Loss: 0.012887893244624138\n",
      "Iteration 380, Loss: 0.01348646730184555\n",
      "Iteration 390, Loss: 0.011333984322845936\n",
      "Iteration 400, Loss: 0.010481635108590126\n",
      "Iteration 410, Loss: 0.009144684299826622\n",
      "Iteration 420, Loss: 0.0101274773478508\n",
      "Iteration 430, Loss: 0.0097316550090909\n",
      "Iteration 440, Loss: 0.009059341624379158\n",
      "Iteration 450, Loss: 0.008978458121418953\n",
      "Iteration 460, Loss: 0.010873997583985329\n",
      "Iteration 470, Loss: 0.011304590851068497\n",
      "Iteration 480, Loss: 0.008129495196044445\n",
      "Iteration 490, Loss: 0.008822939358651638\n",
      "Iteration 500, Loss: 0.008235689252614975\n",
      "Iteration 510, Loss: 0.007200990803539753\n",
      "Iteration 520, Loss: 0.007920742966234684\n",
      "Iteration 530, Loss: 0.007159298751503229\n",
      "Iteration 540, Loss: 0.007742249872535467\n",
      "Iteration 550, Loss: 0.0066046519204974174\n",
      "Iteration 560, Loss: 0.006287797819823027\n",
      "Iteration 570, Loss: 0.005941187031567097\n",
      "Iteration 580, Loss: 0.0059889210388064384\n",
      "Iteration 590, Loss: 0.0051510753110051155\n",
      "Iteration 600, Loss: 0.006367859430611134\n",
      "Iteration 610, Loss: 0.0056317951530218124\n",
      "Iteration 620, Loss: 0.0054625170305371284\n",
      "Iteration 630, Loss: 0.004576423205435276\n",
      "Iteration 640, Loss: 0.00518537312746048\n",
      "Iteration 650, Loss: 0.00552759924903512\n",
      "Iteration 660, Loss: 0.004563414491713047\n",
      "Iteration 670, Loss: 0.005687097553163767\n",
      "Iteration 680, Loss: 0.004130160436034203\n",
      "Iteration 690, Loss: 0.004941137507557869\n",
      "Iteration 700, Loss: 0.00436124624684453\n",
      "Iteration 710, Loss: 0.0047111609019339085\n",
      "Iteration 720, Loss: 0.0038036981131881475\n",
      "Iteration 730, Loss: 0.0038867429830133915\n",
      "Iteration 740, Loss: 0.0037528653629124165\n",
      "Iteration 750, Loss: 0.00397441815584898\n",
      "Iteration 760, Loss: 0.004118846729397774\n",
      "Iteration 770, Loss: 0.0034958235919475555\n",
      "Iteration 780, Loss: 0.003609543200582266\n",
      "Iteration 790, Loss: 0.003586316015571356\n",
      "Iteration 800, Loss: 0.0033595003187656403\n",
      "Iteration 810, Loss: 0.0036214429419487715\n",
      "Iteration 820, Loss: 0.003336310386657715\n",
      "Iteration 830, Loss: 0.0027902452275156975\n",
      "Iteration 840, Loss: 0.0029140678234398365\n",
      "Iteration 850, Loss: 0.0029730212409049273\n",
      "Iteration 860, Loss: 0.002400950063019991\n",
      "Iteration 870, Loss: 0.0029466035775840282\n",
      "Iteration 880, Loss: 0.002924717031419277\n",
      "Iteration 890, Loss: 0.0027796512003988028\n",
      "Iteration 900, Loss: 0.00282677891664207\n",
      "Iteration 910, Loss: 0.003056694520637393\n",
      "Iteration 920, Loss: 0.00281696580350399\n",
      "Iteration 930, Loss: 0.002771122846752405\n",
      "Iteration 940, Loss: 0.0025480587501078844\n",
      "Iteration 950, Loss: 0.0024930431973189116\n",
      "Iteration 960, Loss: 0.0024884201120585203\n",
      "Iteration 970, Loss: 0.0027243311051279306\n",
      "Iteration 980, Loss: 0.0022436650469899178\n",
      "Iteration 990, Loss: 0.0024013074580579996\n",
      "Iteration 1000, Loss: 0.0024651873391121626\n",
      "Iteration 1010, Loss: 0.0026053087785840034\n",
      "Iteration 1020, Loss: 0.002408407861366868\n",
      "Iteration 1030, Loss: 0.0027572347316890955\n",
      "Iteration 1040, Loss: 0.002432690467685461\n",
      "Iteration 1050, Loss: 0.0024011656641960144\n",
      "Iteration 1060, Loss: 0.002285953611135483\n",
      "Iteration 1070, Loss: 0.0023793147411197424\n",
      "Iteration 1080, Loss: 0.002458859235048294\n",
      "Iteration 1090, Loss: 0.002360757440328598\n",
      "Iteration 1100, Loss: 0.002095390809699893\n",
      "Iteration 1110, Loss: 0.002212143735960126\n",
      "Iteration 1120, Loss: 0.0022278649266809225\n",
      "Iteration 1130, Loss: 0.002164857927709818\n",
      "Iteration 1140, Loss: 0.0022869743406772614\n",
      "Iteration 1150, Loss: 0.0018659934867173433\n",
      "Iteration 1160, Loss: 0.0023169275373220444\n",
      "Iteration 1170, Loss: 0.0018629853148013353\n",
      "Iteration 1180, Loss: 0.0021419976837933064\n",
      "Iteration 1190, Loss: 0.0022241235710680485\n",
      "Iteration 1200, Loss: 0.002228230470791459\n",
      "Iteration 1210, Loss: 0.0020208475179970264\n",
      "Iteration 1220, Loss: 0.002171566942706704\n",
      "Iteration 1230, Loss: 0.0018268165877088904\n",
      "Iteration 1240, Loss: 0.001929225865751505\n",
      "Iteration 1250, Loss: 0.0019153361208736897\n",
      "Iteration 1260, Loss: 0.0020198184065520763\n",
      "Iteration 1270, Loss: 0.0019927516113966703\n",
      "Iteration 1280, Loss: 0.0020514719653874636\n",
      "Iteration 1290, Loss: 0.0019024992361664772\n",
      "Iteration 1300, Loss: 0.00199741474352777\n",
      "Iteration 1310, Loss: 0.0019261082634329796\n",
      "Iteration 1320, Loss: 0.0018603868084028363\n",
      "Iteration 1330, Loss: 0.0017657165881246328\n",
      "Iteration 1340, Loss: 0.0017761315684765577\n",
      "Iteration 1350, Loss: 0.0018328274600207806\n",
      "Iteration 1360, Loss: 0.001954697770997882\n",
      "Iteration 1370, Loss: 0.0018904563039541245\n",
      "Iteration 1380, Loss: 0.0020940385293215513\n",
      "Iteration 1390, Loss: 0.0019983118399977684\n",
      "Iteration 1400, Loss: 0.0018457910045981407\n",
      "Iteration 1410, Loss: 0.0018047904595732689\n",
      "Iteration 1420, Loss: 0.0019070219714194536\n",
      "Iteration 1430, Loss: 0.0017515431391075253\n",
      "Iteration 1440, Loss: 0.0017114466754719615\n",
      "Iteration 1450, Loss: 0.002072960138320923\n",
      "Iteration 1460, Loss: 0.0019962722435593605\n",
      "Iteration 1470, Loss: 0.0016357895219698548\n",
      "Iteration 1480, Loss: 0.001753156422637403\n",
      "Iteration 1490, Loss: 0.0017171980580314994\n",
      "Iteration 1500, Loss: 0.0018249443965032697\n",
      "Iteration 1510, Loss: 0.0017511703772470355\n",
      "Iteration 1520, Loss: 0.0014434645418077707\n",
      "Iteration 1530, Loss: 0.0016425182111561298\n",
      "Iteration 1540, Loss: 0.0017042424296960235\n",
      "Iteration 1550, Loss: 0.001699027605354786\n",
      "Iteration 1560, Loss: 0.0017214578110724688\n",
      "Iteration 1570, Loss: 0.0016118558123707771\n",
      "Iteration 1580, Loss: 0.0017531815683469176\n",
      "Iteration 1590, Loss: 0.001758618513122201\n",
      "Iteration 1600, Loss: 0.001681819441728294\n",
      "Iteration 1610, Loss: 0.0016315254615619779\n",
      "Iteration 1620, Loss: 0.0016877567395567894\n",
      "Iteration 1630, Loss: 0.001636295928619802\n",
      "Iteration 1640, Loss: 0.0016251640627160668\n",
      "Iteration 1650, Loss: 0.0017808317206799984\n",
      "Iteration 1660, Loss: 0.0017269852105528116\n",
      "Iteration 1670, Loss: 0.001741645741276443\n",
      "Iteration 1680, Loss: 0.0017569676274433732\n",
      "Iteration 1690, Loss: 0.0016748516354709864\n",
      "Iteration 1700, Loss: 0.0015113212866708636\n",
      "Iteration 1710, Loss: 0.0016570333391427994\n",
      "Iteration 1720, Loss: 0.001655540312640369\n",
      "Iteration 1730, Loss: 0.0015548949595540762\n",
      "Iteration 1740, Loss: 0.0015402076533064246\n",
      "Iteration 1750, Loss: 0.0016660289838910103\n",
      "Iteration 1760, Loss: 0.0015326160937547684\n",
      "Iteration 1770, Loss: 0.00144378119148314\n",
      "Iteration 1780, Loss: 0.0015225437236949801\n",
      "Iteration 1790, Loss: 0.0015051518566906452\n",
      "Iteration 1800, Loss: 0.0017381585203111172\n",
      "Iteration 1810, Loss: 0.001676129992119968\n",
      "Iteration 1820, Loss: 0.0016176626086235046\n",
      "Iteration 1830, Loss: 0.0015077338321134448\n",
      "Iteration 1840, Loss: 0.0015275697223842144\n",
      "Iteration 1850, Loss: 0.0014588168123736978\n",
      "Iteration 1860, Loss: 0.0014711052644997835\n",
      "Iteration 1870, Loss: 0.0014731985284015536\n",
      "Iteration 1880, Loss: 0.0014908972661942244\n",
      "Iteration 1890, Loss: 0.0014161808649078012\n",
      "Iteration 1900, Loss: 0.001263837912119925\n",
      "Iteration 1910, Loss: 0.001426425646059215\n",
      "Iteration 1920, Loss: 0.0012750810710713267\n",
      "Iteration 1930, Loss: 0.001452938187867403\n",
      "Iteration 1940, Loss: 0.0014334029983729124\n",
      "Iteration 1950, Loss: 0.0012874561361968517\n",
      "Iteration 1960, Loss: 0.0013742055743932724\n",
      "Iteration 1970, Loss: 0.0014224557671695948\n",
      "Iteration 1980, Loss: 0.0013962724478915334\n",
      "Iteration 1990, Loss: 0.001400969224050641\n",
      "Iteration 2000, Loss: 0.0014143558219075203\n",
      "Iteration 2010, Loss: 0.0015710522420704365\n",
      "Iteration 2020, Loss: 0.00142148497980088\n",
      "Iteration 2030, Loss: 0.0013972896849736571\n",
      "Iteration 2040, Loss: 0.0014500088291242719\n",
      "Iteration 2050, Loss: 0.0013725722674280405\n",
      "Iteration 2060, Loss: 0.001312336535193026\n",
      "Iteration 2070, Loss: 0.001427177689038217\n",
      "Iteration 2080, Loss: 0.001376327476464212\n",
      "Iteration 2090, Loss: 0.0012595055159181356\n",
      "Iteration 2100, Loss: 0.001299662166275084\n",
      "Iteration 2110, Loss: 0.001363249379210174\n",
      "Iteration 2120, Loss: 0.0012510605156421661\n",
      "Iteration 2130, Loss: 0.0012606510426849127\n",
      "Iteration 2140, Loss: 0.0012785575818270445\n",
      "Iteration 2150, Loss: 0.0012193245347589254\n",
      "Iteration 2160, Loss: 0.001188791124150157\n",
      "Iteration 2170, Loss: 0.0013949007261544466\n",
      "Iteration 2180, Loss: 0.0012663435190916061\n",
      "Iteration 2190, Loss: 0.0013076945906504989\n",
      "Iteration 2200, Loss: 0.0012012349907308817\n",
      "Iteration 2210, Loss: 0.0012025474570691586\n",
      "Iteration 2220, Loss: 0.0013256752863526344\n",
      "Iteration 2230, Loss: 0.0012741544051095843\n",
      "Iteration 2240, Loss: 0.0012015774846076965\n",
      "Iteration 2250, Loss: 0.001177340978756547\n",
      "Iteration 2260, Loss: 0.0013412988046184182\n",
      "Iteration 2270, Loss: 0.001260800869204104\n",
      "Iteration 2280, Loss: 0.0011777635663747787\n",
      "Iteration 2290, Loss: 0.0012193010188639164\n",
      "Iteration 2300, Loss: 0.0011374057503417134\n",
      "Iteration 2310, Loss: 0.0011525440495461226\n",
      "Iteration 2320, Loss: 0.0011279708705842495\n",
      "Iteration 2330, Loss: 0.0011073804926127195\n",
      "Iteration 2340, Loss: 0.0012089252704754472\n",
      "Iteration 2350, Loss: 0.0011261837789788842\n",
      "Iteration 2360, Loss: 0.0011849608272314072\n",
      "Iteration 2370, Loss: 0.0011231658281758428\n",
      "Iteration 2380, Loss: 0.0012030754005536437\n",
      "Iteration 2390, Loss: 0.0011221420718356967\n",
      "Iteration 2400, Loss: 0.001182285137474537\n",
      "Iteration 2410, Loss: 0.0012537535512819886\n",
      "Iteration 2420, Loss: 0.0011197235435247421\n",
      "Iteration 2430, Loss: 0.0011204155161976814\n",
      "Iteration 2440, Loss: 0.0011113834334537387\n",
      "Iteration 2450, Loss: 0.0012039877474308014\n",
      "Iteration 2460, Loss: 0.0010226273443549871\n",
      "Iteration 2470, Loss: 0.0010577342472970486\n",
      "Iteration 2480, Loss: 0.0011552730575203896\n",
      "Iteration 2490, Loss: 0.0011323064099997282\n",
      "Iteration 2500, Loss: 0.0011393544264137745\n",
      "Iteration 2510, Loss: 0.0011154741514474154\n",
      "Iteration 2520, Loss: 0.0010040294146165252\n",
      "Iteration 2530, Loss: 0.0011201560264453292\n",
      "Iteration 2540, Loss: 0.000960258417762816\n",
      "Iteration 2550, Loss: 0.0010133259929716587\n",
      "Iteration 2560, Loss: 0.0010218987008556724\n",
      "Iteration 2570, Loss: 0.0010517602786421776\n",
      "Iteration 2580, Loss: 0.001147242495790124\n",
      "Iteration 2590, Loss: 0.0009722916292957962\n",
      "Iteration 2600, Loss: 0.0010497575858607888\n",
      "Iteration 2610, Loss: 0.001065360731445253\n",
      "Iteration 2620, Loss: 0.0009891216177493334\n",
      "Iteration 2630, Loss: 0.0010304164607077837\n",
      "Iteration 2640, Loss: 0.0010249691549688578\n",
      "Iteration 2650, Loss: 0.0010040812194347382\n",
      "Iteration 2660, Loss: 0.0010233664652332664\n",
      "Iteration 2670, Loss: 0.0010446166852489114\n",
      "Iteration 2680, Loss: 0.000958826916757971\n",
      "Iteration 2690, Loss: 0.0010829985840246081\n",
      "Iteration 2700, Loss: 0.0010222801938652992\n",
      "Iteration 2710, Loss: 0.001013300265185535\n",
      "Iteration 2720, Loss: 0.0009648949489928782\n",
      "Iteration 2730, Loss: 0.0009476476116105914\n",
      "Iteration 2740, Loss: 0.0009997604647651315\n",
      "Iteration 2750, Loss: 0.0009533189004287124\n",
      "Iteration 2760, Loss: 0.000957815907895565\n",
      "Iteration 2770, Loss: 0.0009446216281503439\n",
      "Iteration 2780, Loss: 0.0008914701757021248\n",
      "Iteration 2790, Loss: 0.0009388088365085423\n",
      "Iteration 2800, Loss: 0.0010023096110671759\n",
      "Iteration 2810, Loss: 0.0009004405583254993\n",
      "Iteration 2820, Loss: 0.001026263809762895\n",
      "Iteration 2830, Loss: 0.0009107640944421291\n",
      "Iteration 2840, Loss: 0.0009140147594735026\n",
      "Iteration 2850, Loss: 0.0008985237800516188\n",
      "Iteration 2860, Loss: 0.0008535674423910677\n",
      "Iteration 2870, Loss: 0.0008883179980330169\n",
      "Iteration 2880, Loss: 0.0008930318872444332\n",
      "Iteration 2890, Loss: 0.0009426621836610138\n",
      "Iteration 2900, Loss: 0.0009411711362190545\n",
      "Iteration 2910, Loss: 0.0009136137086898088\n",
      "Iteration 2920, Loss: 0.0009113719570450485\n",
      "Iteration 2930, Loss: 0.0008897657389752567\n",
      "Iteration 2940, Loss: 0.0009579199249856174\n",
      "Iteration 2950, Loss: 0.0008888041484169662\n",
      "Iteration 2960, Loss: 0.0008246657671406865\n",
      "Iteration 2970, Loss: 0.0007837183657102287\n",
      "Iteration 2980, Loss: 0.0008796958718448877\n",
      "Iteration 2990, Loss: 0.0010105924447998405\n",
      "Iteration 3000, Loss: 0.0007729876087978482\n",
      "Iteration 3010, Loss: 0.0007732136873528361\n",
      "Iteration 3020, Loss: 0.0007903180085122585\n",
      "Iteration 3030, Loss: 0.0008154926472343504\n",
      "Iteration 3040, Loss: 0.000860534724779427\n",
      "Iteration 3050, Loss: 0.0007898312760517001\n",
      "Iteration 3060, Loss: 0.0008031142060644925\n",
      "Iteration 3070, Loss: 0.0007387630175799131\n",
      "Iteration 3080, Loss: 0.0008341767825186253\n",
      "Iteration 3090, Loss: 0.0007521331426687539\n",
      "Iteration 3100, Loss: 0.0008148621418513358\n",
      "Iteration 3110, Loss: 0.0007999284425750375\n",
      "Iteration 3120, Loss: 0.0007938083726912737\n",
      "Iteration 3130, Loss: 0.0007209524046629667\n",
      "Iteration 3140, Loss: 0.0008269880199804902\n",
      "Iteration 3150, Loss: 0.0007248219335451722\n",
      "Iteration 3160, Loss: 0.0007244136068038642\n",
      "Iteration 3170, Loss: 0.0007381791947409511\n",
      "Iteration 3180, Loss: 0.0006945516797713935\n",
      "Iteration 3190, Loss: 0.0007703084265813231\n",
      "Iteration 3200, Loss: 0.0006636444013565779\n",
      "Iteration 3210, Loss: 0.0007497026235796511\n",
      "Iteration 3220, Loss: 0.0007178017986007035\n",
      "Iteration 3230, Loss: 0.0007106648990884423\n",
      "Iteration 3240, Loss: 0.0007983451359905303\n",
      "Iteration 3250, Loss: 0.0007610323955304921\n",
      "Iteration 3260, Loss: 0.0007872931892052293\n",
      "Iteration 3270, Loss: 0.0007388998055830598\n",
      "Iteration 3280, Loss: 0.0007520241197198629\n",
      "Iteration 3290, Loss: 0.0006245668046176434\n",
      "Iteration 3300, Loss: 0.0007631998741999269\n",
      "Iteration 3310, Loss: 0.0007855187868699431\n",
      "Iteration 3320, Loss: 0.0007291320362128317\n",
      "Iteration 3330, Loss: 0.0006849447381682694\n",
      "Iteration 3340, Loss: 0.0007619933458045125\n",
      "Iteration 3350, Loss: 0.0007815302815288305\n",
      "Iteration 3360, Loss: 0.000744436401873827\n",
      "Iteration 3370, Loss: 0.0007178185624070466\n",
      "Iteration 3380, Loss: 0.0006628952687606215\n",
      "Iteration 3390, Loss: 0.0006453116657212377\n",
      "Iteration 3400, Loss: 0.0007309923530556262\n",
      "Iteration 3410, Loss: 0.0006864661118015647\n",
      "Iteration 3420, Loss: 0.0006822195718996227\n",
      "Iteration 3430, Loss: 0.0006989015964791179\n",
      "Iteration 3440, Loss: 0.0006837972323410213\n",
      "Iteration 3450, Loss: 0.0006950461538508534\n",
      "Iteration 3460, Loss: 0.0006250997539609671\n",
      "Iteration 3470, Loss: 0.0005715166917070746\n",
      "Iteration 3480, Loss: 0.0006205724203027785\n",
      "Iteration 3490, Loss: 0.0007296426338143647\n",
      "Iteration 3500, Loss: 0.0006148650427348912\n",
      "Iteration 3510, Loss: 0.0006473271641880274\n",
      "Iteration 3520, Loss: 0.0006156121962703764\n",
      "Iteration 3530, Loss: 0.0006201167707331479\n",
      "Iteration 3540, Loss: 0.0006384372827596962\n",
      "Iteration 3550, Loss: 0.000586853304412216\n",
      "Iteration 3560, Loss: 0.0006851793150417507\n",
      "Iteration 3570, Loss: 0.0005822962848469615\n",
      "Iteration 3580, Loss: 0.0006191249703988433\n",
      "Iteration 3590, Loss: 0.0005506908637471497\n",
      "Iteration 3600, Loss: 0.0006116839358583093\n",
      "Iteration 3610, Loss: 0.0006260362570174038\n",
      "Iteration 3620, Loss: 0.0006300655077211559\n",
      "Iteration 3630, Loss: 0.0006011647055856884\n",
      "Iteration 3640, Loss: 0.0005232029361650348\n",
      "Iteration 3650, Loss: 0.000562815461307764\n",
      "Iteration 3660, Loss: 0.0005890012253075838\n",
      "Iteration 3670, Loss: 0.0005986640462651849\n",
      "Iteration 3680, Loss: 0.0005243218620307744\n",
      "Iteration 3690, Loss: 0.000577254337258637\n",
      "Iteration 3700, Loss: 0.0006219807546585798\n",
      "Iteration 3710, Loss: 0.0005563574959523976\n",
      "Iteration 3720, Loss: 0.0005955561064183712\n",
      "Iteration 3730, Loss: 0.0006031984812580049\n",
      "Iteration 3740, Loss: 0.0005007147556170821\n",
      "Iteration 3750, Loss: 0.0005074883811175823\n",
      "Iteration 3760, Loss: 0.0005212586256675422\n",
      "Iteration 3770, Loss: 0.0005633351975120604\n",
      "Iteration 3780, Loss: 0.0005512204370461404\n",
      "Iteration 3790, Loss: 0.0005246876389719546\n",
      "Iteration 3800, Loss: 0.0005215949495323002\n",
      "Iteration 3810, Loss: 0.0005837243515998125\n",
      "Iteration 3820, Loss: 0.0005288590909913182\n",
      "Iteration 3830, Loss: 0.0005333192530088127\n",
      "Iteration 3840, Loss: 0.0005561875295825303\n",
      "Iteration 3850, Loss: 0.000508107477799058\n",
      "Iteration 3860, Loss: 0.0005301663186401129\n",
      "Iteration 3870, Loss: 0.0005398002685979009\n",
      "Iteration 3880, Loss: 0.0005691104452125728\n",
      "Iteration 3890, Loss: 0.0005253783310763538\n",
      "Iteration 3900, Loss: 0.0005582197918556631\n",
      "Iteration 3910, Loss: 0.0005536164971999824\n",
      "Iteration 3920, Loss: 0.0005349441198632121\n",
      "Iteration 3930, Loss: 0.0004926474648527801\n",
      "Iteration 3940, Loss: 0.000529610610101372\n",
      "Iteration 3950, Loss: 0.0004940618528053164\n",
      "Iteration 3960, Loss: 0.0005086896126158535\n",
      "Iteration 3970, Loss: 0.0005265034851618111\n",
      "Iteration 3980, Loss: 0.0004731570661533624\n",
      "Iteration 3990, Loss: 0.0005499434191733599\n",
      "Iteration 4000, Loss: 0.00047460629139095545\n",
      "Iteration 4010, Loss: 0.0005159147549420595\n",
      "Iteration 4020, Loss: 0.00046744022984057665\n",
      "Iteration 4030, Loss: 0.0004589351883623749\n",
      "Iteration 4040, Loss: 0.00043888294021598995\n",
      "Iteration 4050, Loss: 0.00046809096238575876\n",
      "Iteration 4060, Loss: 0.0005002006073482335\n",
      "Iteration 4070, Loss: 0.00045878655510023236\n",
      "Iteration 4080, Loss: 0.0004665809974540025\n",
      "Iteration 4090, Loss: 0.00045429941383190453\n",
      "Iteration 4100, Loss: 0.0004386423097457737\n",
      "Iteration 4110, Loss: 0.0005111795617267489\n",
      "Iteration 4120, Loss: 0.00048426780267618597\n",
      "Iteration 4130, Loss: 0.0004735719703603536\n",
      "Iteration 4140, Loss: 0.0004741483717225492\n",
      "Iteration 4150, Loss: 0.0004405068466439843\n",
      "Iteration 4160, Loss: 0.0004770189116243273\n",
      "Iteration 4170, Loss: 0.0004778690345119685\n",
      "Iteration 4180, Loss: 0.0004811474645975977\n",
      "Iteration 4190, Loss: 0.00044169105240143836\n",
      "Iteration 4200, Loss: 0.00045870995381847024\n",
      "Iteration 4210, Loss: 0.0004299500724300742\n",
      "Iteration 4220, Loss: 0.0004882943467237055\n",
      "Iteration 4230, Loss: 0.0004367353394627571\n",
      "Iteration 4240, Loss: 0.00045122363371774554\n",
      "Iteration 4250, Loss: 0.00045066120219416916\n",
      "Iteration 4260, Loss: 0.00047803475172258914\n",
      "Iteration 4270, Loss: 0.0003976635343860835\n",
      "Iteration 4280, Loss: 0.0003976011648774147\n",
      "Iteration 4290, Loss: 0.0004933599266223609\n",
      "Iteration 4300, Loss: 0.00041710742516443133\n",
      "Iteration 4310, Loss: 0.0004487558617256582\n",
      "Iteration 4320, Loss: 0.00044496331247501075\n",
      "Iteration 4330, Loss: 0.0004451315908227116\n",
      "Iteration 4340, Loss: 0.00045360703370533884\n",
      "Iteration 4350, Loss: 0.00042728721746243536\n",
      "Iteration 4360, Loss: 0.00045473838690668344\n",
      "Iteration 4370, Loss: 0.0003785591688938439\n",
      "Iteration 4380, Loss: 0.0004402997437864542\n",
      "Iteration 4390, Loss: 0.0003919792943634093\n",
      "Iteration 4400, Loss: 0.00038800822221674025\n",
      "Iteration 4410, Loss: 0.00036980706499889493\n",
      "Iteration 4420, Loss: 0.0004060258506797254\n",
      "Iteration 4430, Loss: 0.0004034997837152332\n",
      "Iteration 4440, Loss: 0.0003976967709604651\n",
      "Iteration 4450, Loss: 0.000392732210457325\n",
      "Iteration 4460, Loss: 0.00038509294972755015\n",
      "Iteration 4470, Loss: 0.00042160702287219465\n",
      "Iteration 4480, Loss: 0.00041424238588660955\n",
      "Iteration 4490, Loss: 0.00038713746471330523\n",
      "Iteration 4500, Loss: 0.00041421165224164724\n",
      "Iteration 4510, Loss: 0.0003828293993137777\n",
      "Iteration 4520, Loss: 0.0003899368457496166\n",
      "Iteration 4530, Loss: 0.00040634904871694744\n",
      "Iteration 4540, Loss: 0.0003663396055344492\n",
      "Iteration 4550, Loss: 0.0003749223833438009\n",
      "Iteration 4560, Loss: 0.0004194910288788378\n",
      "Iteration 4570, Loss: 0.00039970746729522943\n",
      "Iteration 4580, Loss: 0.00036901768180541694\n",
      "Iteration 4590, Loss: 0.0003744295099750161\n",
      "Iteration 4600, Loss: 0.0003906884230673313\n",
      "Iteration 4610, Loss: 0.00034884337219409645\n",
      "Iteration 4620, Loss: 0.0003516924334689975\n",
      "Iteration 4630, Loss: 0.00038659112760797143\n",
      "Iteration 4640, Loss: 0.000343091698596254\n",
      "Iteration 4650, Loss: 0.0003615766763687134\n",
      "Iteration 4660, Loss: 0.00034059074823744595\n",
      "Iteration 4670, Loss: 0.00035766023211181164\n",
      "Iteration 4680, Loss: 0.00037054475978948176\n",
      "Iteration 4690, Loss: 0.00034277880331501365\n",
      "Iteration 4700, Loss: 0.0003721006796695292\n",
      "Iteration 4710, Loss: 0.0003305265854578465\n",
      "Iteration 4720, Loss: 0.00036754683242179453\n",
      "Iteration 4730, Loss: 0.0003080121532548219\n",
      "Iteration 4740, Loss: 0.0003617658221628517\n",
      "Iteration 4750, Loss: 0.0003510517126414925\n",
      "Iteration 4760, Loss: 0.0003653808089438826\n",
      "Iteration 4770, Loss: 0.00035621103597804904\n",
      "Iteration 4780, Loss: 0.00033630846883170307\n",
      "Iteration 4790, Loss: 0.00032663793535903096\n",
      "Iteration 4800, Loss: 0.0003264135157223791\n",
      "Iteration 4810, Loss: 0.0003503084590192884\n",
      "Iteration 4820, Loss: 0.0003416779509279877\n",
      "Iteration 4830, Loss: 0.00034233124461025\n",
      "Iteration 4840, Loss: 0.00030624240753240883\n",
      "Iteration 4850, Loss: 0.00032077269861474633\n",
      "Iteration 4860, Loss: 0.0003212440060451627\n",
      "Iteration 4870, Loss: 0.00031591797596774995\n",
      "Iteration 4880, Loss: 0.00036067984183318913\n",
      "Iteration 4890, Loss: 0.0003340436960570514\n",
      "Iteration 4900, Loss: 0.00033925625029951334\n",
      "Iteration 4910, Loss: 0.0003332245396450162\n",
      "Iteration 4920, Loss: 0.00032224098686128855\n",
      "Iteration 4930, Loss: 0.00032531929900869727\n",
      "Iteration 4940, Loss: 0.0003584662335924804\n",
      "Iteration 4950, Loss: 0.0003295375208836049\n",
      "Iteration 4960, Loss: 0.0003115153522230685\n",
      "Iteration 4970, Loss: 0.00031335343373939395\n",
      "Iteration 4980, Loss: 0.00031317456159740686\n",
      "Iteration 4990, Loss: 0.000329927250277251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  25%|██▌       | 6/24 [04:11<15:36, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.026338078141919276, 'L2_avg': 0.033275935797778045, 'End_point_L1_avg': 0.009333025226199039, 'End_point_L2_avg': 0.011876261173909513}\n",
      "Iteration 0, Loss: 1.9321037530899048\n",
      "Iteration 10, Loss: 1.1170779466629028\n",
      "Iteration 20, Loss: 0.839663028717041\n",
      "Iteration 30, Loss: 0.6505253314971924\n",
      "Iteration 40, Loss: 0.4994349777698517\n",
      "Iteration 50, Loss: 0.3986765146255493\n",
      "Iteration 60, Loss: 0.3114367723464966\n",
      "Iteration 70, Loss: 0.24768124520778656\n",
      "Iteration 80, Loss: 0.20359180867671967\n",
      "Iteration 90, Loss: 0.1677808165550232\n",
      "Iteration 100, Loss: 0.13991093635559082\n",
      "Iteration 110, Loss: 0.12732388079166412\n",
      "Iteration 120, Loss: 0.1059035062789917\n",
      "Iteration 130, Loss: 0.09746874868869781\n",
      "Iteration 140, Loss: 0.0864434689283371\n",
      "Iteration 150, Loss: 0.08232448250055313\n",
      "Iteration 160, Loss: 0.07738300412893295\n",
      "Iteration 170, Loss: 0.07446889579296112\n",
      "Iteration 180, Loss: 0.06413374841213226\n",
      "Iteration 190, Loss: 0.06215319037437439\n",
      "Iteration 200, Loss: 0.06225264072418213\n",
      "Iteration 210, Loss: 0.05778138339519501\n",
      "Iteration 220, Loss: 0.053086601197719574\n",
      "Iteration 230, Loss: 0.05032078176736832\n",
      "Iteration 240, Loss: 0.05302086099982262\n",
      "Iteration 250, Loss: 0.048273295164108276\n",
      "Iteration 260, Loss: 0.0481010302901268\n",
      "Iteration 270, Loss: 0.04577947035431862\n",
      "Iteration 280, Loss: 0.03860791400074959\n",
      "Iteration 290, Loss: 0.04060105234384537\n",
      "Iteration 300, Loss: 0.046569935977458954\n",
      "Iteration 310, Loss: 0.042514652013778687\n",
      "Iteration 320, Loss: 0.03594778850674629\n",
      "Iteration 330, Loss: 0.03794819116592407\n",
      "Iteration 340, Loss: 0.03526395186781883\n",
      "Iteration 350, Loss: 0.03258027881383896\n",
      "Iteration 360, Loss: 0.034676577895879745\n",
      "Iteration 370, Loss: 0.034498054534196854\n",
      "Iteration 380, Loss: 0.03150711581110954\n",
      "Iteration 390, Loss: 0.029375459998846054\n",
      "Iteration 400, Loss: 0.028428757563233376\n",
      "Iteration 410, Loss: 0.02994135022163391\n",
      "Iteration 420, Loss: 0.026938604190945625\n",
      "Iteration 430, Loss: 0.031031843274831772\n",
      "Iteration 440, Loss: 0.024572817608714104\n",
      "Iteration 450, Loss: 0.0237586610019207\n",
      "Iteration 460, Loss: 0.026738936081528664\n",
      "Iteration 470, Loss: 0.024508299306035042\n",
      "Iteration 480, Loss: 0.022853020578622818\n",
      "Iteration 490, Loss: 0.024620994925498962\n",
      "Iteration 500, Loss: 0.021929729729890823\n",
      "Iteration 510, Loss: 0.02173728495836258\n",
      "Iteration 520, Loss: 0.025122445076704025\n",
      "Iteration 530, Loss: 0.018961695954203606\n",
      "Iteration 540, Loss: 0.02056916430592537\n",
      "Iteration 550, Loss: 0.0213649682700634\n",
      "Iteration 560, Loss: 0.019439706578850746\n",
      "Iteration 570, Loss: 0.020801251754164696\n",
      "Iteration 580, Loss: 0.019343718886375427\n",
      "Iteration 590, Loss: 0.017811698839068413\n",
      "Iteration 600, Loss: 0.017821703106164932\n",
      "Iteration 610, Loss: 0.017717700451612473\n",
      "Iteration 620, Loss: 0.017132017761468887\n",
      "Iteration 630, Loss: 0.015889927744865417\n",
      "Iteration 640, Loss: 0.015949444845318794\n",
      "Iteration 650, Loss: 0.01457893755286932\n",
      "Iteration 660, Loss: 0.014372032135725021\n",
      "Iteration 670, Loss: 0.013828138820827007\n",
      "Iteration 680, Loss: 0.014389126561582088\n",
      "Iteration 690, Loss: 0.014656802639365196\n",
      "Iteration 700, Loss: 0.013062410987913609\n",
      "Iteration 710, Loss: 0.01386136282235384\n",
      "Iteration 720, Loss: 0.012749999761581421\n",
      "Iteration 730, Loss: 0.012968984432518482\n",
      "Iteration 740, Loss: 0.013462851755321026\n",
      "Iteration 750, Loss: 0.011272457428276539\n",
      "Iteration 760, Loss: 0.011123806238174438\n",
      "Iteration 770, Loss: 0.010820938274264336\n",
      "Iteration 780, Loss: 0.011575581505894661\n",
      "Iteration 790, Loss: 0.011530906893312931\n",
      "Iteration 800, Loss: 0.011206998489797115\n",
      "Iteration 810, Loss: 0.00993824191391468\n",
      "Iteration 820, Loss: 0.010377073660492897\n",
      "Iteration 830, Loss: 0.01072017289698124\n",
      "Iteration 840, Loss: 0.009864493273198605\n",
      "Iteration 850, Loss: 0.009325772523880005\n",
      "Iteration 860, Loss: 0.009463544003665447\n",
      "Iteration 870, Loss: 0.009152386337518692\n",
      "Iteration 880, Loss: 0.008738333359360695\n",
      "Iteration 890, Loss: 0.007889374159276485\n",
      "Iteration 900, Loss: 0.008742457255721092\n",
      "Iteration 910, Loss: 0.007819613441824913\n",
      "Iteration 920, Loss: 0.008282942697405815\n",
      "Iteration 930, Loss: 0.008039873093366623\n",
      "Iteration 940, Loss: 0.007589130196720362\n",
      "Iteration 950, Loss: 0.007928282953798771\n",
      "Iteration 960, Loss: 0.0074648428708314896\n",
      "Iteration 970, Loss: 0.0073501719161868095\n",
      "Iteration 980, Loss: 0.006421586498618126\n",
      "Iteration 990, Loss: 0.006768569815903902\n",
      "Iteration 1000, Loss: 0.006749202497303486\n",
      "Iteration 1010, Loss: 0.006450823042541742\n",
      "Iteration 1020, Loss: 0.006554032675921917\n",
      "Iteration 1030, Loss: 0.006378679536283016\n",
      "Iteration 1040, Loss: 0.006242901552468538\n",
      "Iteration 1050, Loss: 0.006039380095899105\n",
      "Iteration 1060, Loss: 0.005843707360327244\n",
      "Iteration 1070, Loss: 0.005866146646440029\n",
      "Iteration 1080, Loss: 0.005500243976712227\n",
      "Iteration 1090, Loss: 0.005498032085597515\n",
      "Iteration 1100, Loss: 0.005056123714894056\n",
      "Iteration 1110, Loss: 0.00546302879229188\n",
      "Iteration 1120, Loss: 0.005192204844206572\n",
      "Iteration 1130, Loss: 0.005240707192569971\n",
      "Iteration 1140, Loss: 0.005112698767334223\n",
      "Iteration 1150, Loss: 0.005030588712543249\n",
      "Iteration 1160, Loss: 0.004789615515619516\n",
      "Iteration 1170, Loss: 0.004420929588377476\n",
      "Iteration 1180, Loss: 0.0046250117011368275\n",
      "Iteration 1190, Loss: 0.004580245818942785\n",
      "Iteration 1200, Loss: 0.004644531290978193\n",
      "Iteration 1210, Loss: 0.004476696252822876\n",
      "Iteration 1220, Loss: 0.0045327721163630486\n",
      "Iteration 1230, Loss: 0.004224175121635199\n",
      "Iteration 1240, Loss: 0.004385332576930523\n",
      "Iteration 1250, Loss: 0.004060383886098862\n",
      "Iteration 1260, Loss: 0.0039578890427947044\n",
      "Iteration 1270, Loss: 0.004450898617506027\n",
      "Iteration 1280, Loss: 0.004041776526719332\n",
      "Iteration 1290, Loss: 0.003824719926342368\n",
      "Iteration 1300, Loss: 0.004089377820491791\n",
      "Iteration 1310, Loss: 0.00408954406157136\n",
      "Iteration 1320, Loss: 0.003837179159745574\n",
      "Iteration 1330, Loss: 0.003840529592707753\n",
      "Iteration 1340, Loss: 0.003860145341604948\n",
      "Iteration 1350, Loss: 0.003789368085563183\n",
      "Iteration 1360, Loss: 0.003649964462965727\n",
      "Iteration 1370, Loss: 0.0036829232703894377\n",
      "Iteration 1380, Loss: 0.0034637877251952887\n",
      "Iteration 1390, Loss: 0.0033489258494228125\n",
      "Iteration 1400, Loss: 0.003644537879154086\n",
      "Iteration 1410, Loss: 0.0034279366955161095\n",
      "Iteration 1420, Loss: 0.00350953359156847\n",
      "Iteration 1430, Loss: 0.0033863363787531853\n",
      "Iteration 1440, Loss: 0.003237387863919139\n",
      "Iteration 1450, Loss: 0.0032224967144429684\n",
      "Iteration 1460, Loss: 0.0030893906950950623\n",
      "Iteration 1470, Loss: 0.0034717388916760683\n",
      "Iteration 1480, Loss: 0.0033449577167630196\n",
      "Iteration 1490, Loss: 0.0031493795104324818\n",
      "Iteration 1500, Loss: 0.0033149418886750937\n",
      "Iteration 1510, Loss: 0.003024083562195301\n",
      "Iteration 1520, Loss: 0.003249924397096038\n",
      "Iteration 1530, Loss: 0.0031467978842556477\n",
      "Iteration 1540, Loss: 0.0030535287223756313\n",
      "Iteration 1550, Loss: 0.0030440017580986023\n",
      "Iteration 1560, Loss: 0.003192988922819495\n",
      "Iteration 1570, Loss: 0.0030856167431920767\n",
      "Iteration 1580, Loss: 0.0028441487811505795\n",
      "Iteration 1590, Loss: 0.002969162305817008\n",
      "Iteration 1600, Loss: 0.002969976980239153\n",
      "Iteration 1610, Loss: 0.00288203451782465\n",
      "Iteration 1620, Loss: 0.0029811004642397165\n",
      "Iteration 1630, Loss: 0.002994425827637315\n",
      "Iteration 1640, Loss: 0.002848505275323987\n",
      "Iteration 1650, Loss: 0.0029099343810230494\n",
      "Iteration 1660, Loss: 0.0027980725280940533\n",
      "Iteration 1670, Loss: 0.0028491884004324675\n",
      "Iteration 1680, Loss: 0.002663240535184741\n",
      "Iteration 1690, Loss: 0.0028696279041469097\n",
      "Iteration 1700, Loss: 0.0028286222368478775\n",
      "Iteration 1710, Loss: 0.002710189903154969\n",
      "Iteration 1720, Loss: 0.0027256496250629425\n",
      "Iteration 1730, Loss: 0.0026136119849979877\n",
      "Iteration 1740, Loss: 0.0027444607112556696\n",
      "Iteration 1750, Loss: 0.002605320420116186\n",
      "Iteration 1760, Loss: 0.0026290134992450476\n",
      "Iteration 1770, Loss: 0.0026860146317631006\n",
      "Iteration 1780, Loss: 0.002582266926765442\n",
      "Iteration 1790, Loss: 0.0025982102379202843\n",
      "Iteration 1800, Loss: 0.0025471276603639126\n",
      "Iteration 1810, Loss: 0.0025444147177040577\n",
      "Iteration 1820, Loss: 0.0025727024767547846\n",
      "Iteration 1830, Loss: 0.0023385074455291033\n",
      "Iteration 1840, Loss: 0.002616140991449356\n",
      "Iteration 1850, Loss: 0.002630507340654731\n",
      "Iteration 1860, Loss: 0.0025255640503019094\n",
      "Iteration 1870, Loss: 0.0025088211987167597\n",
      "Iteration 1880, Loss: 0.0024595095310360193\n",
      "Iteration 1890, Loss: 0.002552942605689168\n",
      "Iteration 1900, Loss: 0.0024575903080403805\n",
      "Iteration 1910, Loss: 0.0024910327047109604\n",
      "Iteration 1920, Loss: 0.002259434899315238\n",
      "Iteration 1930, Loss: 0.0023662468884140253\n",
      "Iteration 1940, Loss: 0.002409914741292596\n",
      "Iteration 1950, Loss: 0.0024077147245407104\n",
      "Iteration 1960, Loss: 0.0024273761082440615\n",
      "Iteration 1970, Loss: 0.0024169341195374727\n",
      "Iteration 1980, Loss: 0.002326524816453457\n",
      "Iteration 1990, Loss: 0.002339453436434269\n",
      "Iteration 2000, Loss: 0.00228894897736609\n",
      "Iteration 2010, Loss: 0.0023321101907640696\n",
      "Iteration 2020, Loss: 0.002380785532295704\n",
      "Iteration 2030, Loss: 0.0022430592216551304\n",
      "Iteration 2040, Loss: 0.0022102452348917723\n",
      "Iteration 2050, Loss: 0.0023565366864204407\n",
      "Iteration 2060, Loss: 0.002352715004235506\n",
      "Iteration 2070, Loss: 0.002195631619542837\n",
      "Iteration 2080, Loss: 0.002242292044684291\n",
      "Iteration 2090, Loss: 0.002225457224994898\n",
      "Iteration 2100, Loss: 0.002221029484644532\n",
      "Iteration 2110, Loss: 0.0022570653818547726\n",
      "Iteration 2120, Loss: 0.002289281925186515\n",
      "Iteration 2130, Loss: 0.002127474406734109\n",
      "Iteration 2140, Loss: 0.002183829667046666\n",
      "Iteration 2150, Loss: 0.002202007221058011\n",
      "Iteration 2160, Loss: 0.002118930919095874\n",
      "Iteration 2170, Loss: 0.0022821053862571716\n",
      "Iteration 2180, Loss: 0.0020857984200119972\n",
      "Iteration 2190, Loss: 0.0020532512571662664\n",
      "Iteration 2200, Loss: 0.0019966978579759598\n",
      "Iteration 2210, Loss: 0.0021440330892801285\n",
      "Iteration 2220, Loss: 0.002105840714648366\n",
      "Iteration 2230, Loss: 0.0021691059228032827\n",
      "Iteration 2240, Loss: 0.0021323433611541986\n",
      "Iteration 2250, Loss: 0.0020881176460534334\n",
      "Iteration 2260, Loss: 0.002003521891310811\n",
      "Iteration 2270, Loss: 0.0019311293726786971\n",
      "Iteration 2280, Loss: 0.002083407947793603\n",
      "Iteration 2290, Loss: 0.0021312381140887737\n",
      "Iteration 2300, Loss: 0.002000640146434307\n",
      "Iteration 2310, Loss: 0.001913166488520801\n",
      "Iteration 2320, Loss: 0.001934228464961052\n",
      "Iteration 2330, Loss: 0.0019208755111321807\n",
      "Iteration 2340, Loss: 0.0018945502815768123\n",
      "Iteration 2350, Loss: 0.0019823964685201645\n",
      "Iteration 2360, Loss: 0.0019641334656625986\n",
      "Iteration 2370, Loss: 0.0018754249904304743\n",
      "Iteration 2380, Loss: 0.001968453638255596\n",
      "Iteration 2390, Loss: 0.001988897565752268\n",
      "Iteration 2400, Loss: 0.001934027997776866\n",
      "Iteration 2410, Loss: 0.0018791740294545889\n",
      "Iteration 2420, Loss: 0.0019191574538126588\n",
      "Iteration 2430, Loss: 0.0019920356571674347\n",
      "Iteration 2440, Loss: 0.0019590656738728285\n",
      "Iteration 2450, Loss: 0.0019256600644439459\n",
      "Iteration 2460, Loss: 0.0018279723590239882\n",
      "Iteration 2470, Loss: 0.0018785397987812757\n",
      "Iteration 2480, Loss: 0.0017006566049531102\n",
      "Iteration 2490, Loss: 0.0018621983472257853\n",
      "Iteration 2500, Loss: 0.0019088301341980696\n",
      "Iteration 2510, Loss: 0.0018026628531515598\n",
      "Iteration 2520, Loss: 0.0018811506452038884\n",
      "Iteration 2530, Loss: 0.0018591893604025245\n",
      "Iteration 2540, Loss: 0.0018456852994859219\n",
      "Iteration 2550, Loss: 0.0017614072421565652\n",
      "Iteration 2560, Loss: 0.0018176216399297118\n",
      "Iteration 2570, Loss: 0.0017562976572662592\n",
      "Iteration 2580, Loss: 0.001765757566317916\n",
      "Iteration 2590, Loss: 0.0017636321717873216\n",
      "Iteration 2600, Loss: 0.0017716445727273822\n",
      "Iteration 2610, Loss: 0.0017377918120473623\n",
      "Iteration 2620, Loss: 0.0018207114189863205\n",
      "Iteration 2630, Loss: 0.0016769834328442812\n",
      "Iteration 2640, Loss: 0.0017364509403705597\n",
      "Iteration 2650, Loss: 0.0018206347012892365\n",
      "Iteration 2660, Loss: 0.0017178496345877647\n",
      "Iteration 2670, Loss: 0.001685878960415721\n",
      "Iteration 2680, Loss: 0.0017151802312582731\n",
      "Iteration 2690, Loss: 0.0017056218348443508\n",
      "Iteration 2700, Loss: 0.0016242063138633966\n",
      "Iteration 2710, Loss: 0.0017160355346277356\n",
      "Iteration 2720, Loss: 0.0017436548369005322\n",
      "Iteration 2730, Loss: 0.0016150986775755882\n",
      "Iteration 2740, Loss: 0.0016587317222729325\n",
      "Iteration 2750, Loss: 0.0016628843732178211\n",
      "Iteration 2760, Loss: 0.0016101303044706583\n",
      "Iteration 2770, Loss: 0.0016729666385799646\n",
      "Iteration 2780, Loss: 0.0015809008618816733\n",
      "Iteration 2790, Loss: 0.001597361988388002\n",
      "Iteration 2800, Loss: 0.0016462343046441674\n",
      "Iteration 2810, Loss: 0.0016040272312238812\n",
      "Iteration 2820, Loss: 0.0015297261998057365\n",
      "Iteration 2830, Loss: 0.0015247485134750605\n",
      "Iteration 2840, Loss: 0.001545724575407803\n",
      "Iteration 2850, Loss: 0.0015806916635483503\n",
      "Iteration 2860, Loss: 0.0015793433412909508\n",
      "Iteration 2870, Loss: 0.0015634738374501467\n",
      "Iteration 2880, Loss: 0.001511555165052414\n",
      "Iteration 2890, Loss: 0.0016264161095023155\n",
      "Iteration 2900, Loss: 0.0016200602985918522\n",
      "Iteration 2910, Loss: 0.0015441938303411007\n",
      "Iteration 2920, Loss: 0.0014865701086819172\n",
      "Iteration 2930, Loss: 0.0014283659402281046\n",
      "Iteration 2940, Loss: 0.0014570571947842836\n",
      "Iteration 2950, Loss: 0.001449689851142466\n",
      "Iteration 2960, Loss: 0.001459829625673592\n",
      "Iteration 2970, Loss: 0.001407695235684514\n",
      "Iteration 2980, Loss: 0.0014472147449851036\n",
      "Iteration 2990, Loss: 0.001441613887436688\n",
      "Iteration 3000, Loss: 0.0014213990652933717\n",
      "Iteration 3010, Loss: 0.0014447205467149615\n",
      "Iteration 3020, Loss: 0.0014096464728936553\n",
      "Iteration 3030, Loss: 0.0014510907931253314\n",
      "Iteration 3040, Loss: 0.0014717575395479798\n",
      "Iteration 3050, Loss: 0.001478157239034772\n",
      "Iteration 3060, Loss: 0.001400801818817854\n",
      "Iteration 3070, Loss: 0.001374729792587459\n",
      "Iteration 3080, Loss: 0.001369086210615933\n",
      "Iteration 3090, Loss: 0.0014383516972884536\n",
      "Iteration 3100, Loss: 0.0013543183449655771\n",
      "Iteration 3110, Loss: 0.0013538266066461802\n",
      "Iteration 3120, Loss: 0.00141822244040668\n",
      "Iteration 3130, Loss: 0.0014278031885623932\n",
      "Iteration 3140, Loss: 0.0013574681943282485\n",
      "Iteration 3150, Loss: 0.00139170594047755\n",
      "Iteration 3160, Loss: 0.001356673426926136\n",
      "Iteration 3170, Loss: 0.0013620330719277263\n",
      "Iteration 3180, Loss: 0.0013649981701746583\n",
      "Iteration 3190, Loss: 0.0012815330410376191\n",
      "Iteration 3200, Loss: 0.0013307242188602686\n",
      "Iteration 3210, Loss: 0.001389161217957735\n",
      "Iteration 3220, Loss: 0.0013015251606702805\n",
      "Iteration 3230, Loss: 0.0013067986583337188\n",
      "Iteration 3240, Loss: 0.001277985516935587\n",
      "Iteration 3250, Loss: 0.0012608440592885017\n",
      "Iteration 3260, Loss: 0.001330136670731008\n",
      "Iteration 3270, Loss: 0.0013041766360402107\n",
      "Iteration 3280, Loss: 0.0012513709953054786\n",
      "Iteration 3290, Loss: 0.0012348582968115807\n",
      "Iteration 3300, Loss: 0.0011810435680672526\n",
      "Iteration 3310, Loss: 0.0012475796975195408\n",
      "Iteration 3320, Loss: 0.001261373283341527\n",
      "Iteration 3330, Loss: 0.0012012366205453873\n",
      "Iteration 3340, Loss: 0.0012912474339827895\n",
      "Iteration 3350, Loss: 0.0012206691317260265\n",
      "Iteration 3360, Loss: 0.0012124759377911687\n",
      "Iteration 3370, Loss: 0.0012676886981353164\n",
      "Iteration 3380, Loss: 0.0011908982414752245\n",
      "Iteration 3390, Loss: 0.0011433338513597846\n",
      "Iteration 3400, Loss: 0.0012298955116420984\n",
      "Iteration 3410, Loss: 0.0012426619650796056\n",
      "Iteration 3420, Loss: 0.0011247146176174283\n",
      "Iteration 3430, Loss: 0.0011587518965825438\n",
      "Iteration 3440, Loss: 0.001168638002127409\n",
      "Iteration 3450, Loss: 0.0011530081974342465\n",
      "Iteration 3460, Loss: 0.0010975846089422703\n",
      "Iteration 3470, Loss: 0.0011812754673883319\n",
      "Iteration 3480, Loss: 0.0011463009286671877\n",
      "Iteration 3490, Loss: 0.0011677742004394531\n",
      "Iteration 3500, Loss: 0.0010714929085224867\n",
      "Iteration 3510, Loss: 0.001169756636954844\n",
      "Iteration 3520, Loss: 0.0011526071466505527\n",
      "Iteration 3530, Loss: 0.0011300257174298167\n",
      "Iteration 3540, Loss: 0.001157343853265047\n",
      "Iteration 3550, Loss: 0.0011461912654340267\n",
      "Iteration 3560, Loss: 0.0010756263509392738\n",
      "Iteration 3570, Loss: 0.0011066347360610962\n",
      "Iteration 3580, Loss: 0.001119535882025957\n",
      "Iteration 3590, Loss: 0.001113712671212852\n",
      "Iteration 3600, Loss: 0.0010805170750245452\n",
      "Iteration 3610, Loss: 0.0011332087451592088\n",
      "Iteration 3620, Loss: 0.0010453350841999054\n",
      "Iteration 3630, Loss: 0.001049891929142177\n",
      "Iteration 3640, Loss: 0.001069868914783001\n",
      "Iteration 3650, Loss: 0.001075182342901826\n",
      "Iteration 3660, Loss: 0.0010639042593538761\n",
      "Iteration 3670, Loss: 0.001030760700814426\n",
      "Iteration 3680, Loss: 0.0010525520192459226\n",
      "Stopping early at iteration 3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  29%|██▉       | 7/24 [05:05<14:54, 52.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 3682, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04578076066354342, 'L2_avg': 0.05818845749099544, 'End_point_L1_avg': 0.025118270838278146, 'End_point_L2_avg': 0.025307443355360292}\n",
      "Iteration 0, Loss: 1.3630094528198242\n",
      "Iteration 10, Loss: 1.058366298675537\n",
      "Iteration 20, Loss: 0.8261777758598328\n",
      "Iteration 30, Loss: 0.637204110622406\n",
      "Iteration 40, Loss: 0.48695191740989685\n",
      "Iteration 50, Loss: 0.3691498637199402\n",
      "Iteration 60, Loss: 0.27650216221809387\n",
      "Iteration 70, Loss: 0.20814546942710876\n",
      "Iteration 80, Loss: 0.1564364731311798\n",
      "Iteration 90, Loss: 0.12245500087738037\n",
      "Iteration 100, Loss: 0.09691337496042252\n",
      "Iteration 110, Loss: 0.07609555125236511\n",
      "Iteration 120, Loss: 0.06233398616313934\n",
      "Iteration 130, Loss: 0.052763983607292175\n",
      "Iteration 140, Loss: 0.056313879787921906\n",
      "Iteration 150, Loss: 0.046423353254795074\n",
      "Iteration 160, Loss: 0.04203559085726738\n",
      "Iteration 170, Loss: 0.038251444697380066\n",
      "Iteration 180, Loss: 0.03723875433206558\n",
      "Iteration 190, Loss: 0.03239956125617027\n",
      "Iteration 200, Loss: 0.03068641573190689\n",
      "Iteration 210, Loss: 0.02682182937860489\n",
      "Iteration 220, Loss: 0.028191206976771355\n",
      "Iteration 230, Loss: 0.026133595034480095\n",
      "Iteration 240, Loss: 0.025903550907969475\n",
      "Iteration 250, Loss: 0.02314385212957859\n",
      "Iteration 260, Loss: 0.021037915721535683\n",
      "Iteration 270, Loss: 0.01889977604150772\n",
      "Iteration 280, Loss: 0.019528046250343323\n",
      "Iteration 290, Loss: 0.016376128420233727\n",
      "Iteration 300, Loss: 0.01695321686565876\n",
      "Iteration 310, Loss: 0.015639647841453552\n",
      "Iteration 320, Loss: 0.014935512095689774\n",
      "Iteration 330, Loss: 0.014370696619153023\n",
      "Iteration 340, Loss: 0.0130384536460042\n",
      "Iteration 350, Loss: 0.012293761596083641\n",
      "Iteration 360, Loss: 0.012760300189256668\n",
      "Iteration 370, Loss: 0.013051077723503113\n",
      "Iteration 380, Loss: 0.011882693506777287\n",
      "Iteration 390, Loss: 0.011514374054968357\n",
      "Iteration 400, Loss: 0.01132607739418745\n",
      "Iteration 410, Loss: 0.010607578791677952\n",
      "Iteration 420, Loss: 0.01039046049118042\n",
      "Iteration 430, Loss: 0.009997028857469559\n",
      "Iteration 440, Loss: 0.008744889870285988\n",
      "Iteration 450, Loss: 0.008476787246763706\n",
      "Iteration 460, Loss: 0.009138657711446285\n",
      "Iteration 470, Loss: 0.008244604803621769\n",
      "Iteration 480, Loss: 0.007953975349664688\n",
      "Iteration 490, Loss: 0.007582199294120073\n",
      "Iteration 500, Loss: 0.007701501250267029\n",
      "Iteration 510, Loss: 0.007456800900399685\n",
      "Iteration 520, Loss: 0.006426407489925623\n",
      "Iteration 530, Loss: 0.006957925856113434\n",
      "Iteration 540, Loss: 0.006314270198345184\n",
      "Iteration 550, Loss: 0.0066655706614255905\n",
      "Iteration 560, Loss: 0.0064286161214113235\n",
      "Iteration 570, Loss: 0.005631502252072096\n",
      "Iteration 580, Loss: 0.0054595619440078735\n",
      "Iteration 590, Loss: 0.006325546186417341\n",
      "Iteration 600, Loss: 0.005372909363359213\n",
      "Iteration 610, Loss: 0.005852159112691879\n",
      "Iteration 620, Loss: 0.005096923094242811\n",
      "Iteration 630, Loss: 0.005209991242736578\n",
      "Iteration 640, Loss: 0.004500020295381546\n",
      "Iteration 650, Loss: 0.004955857060849667\n",
      "Iteration 660, Loss: 0.004580772947520018\n",
      "Iteration 670, Loss: 0.004947783891111612\n",
      "Iteration 680, Loss: 0.004410996101796627\n",
      "Iteration 690, Loss: 0.004852477926760912\n",
      "Iteration 700, Loss: 0.003848632797598839\n",
      "Iteration 710, Loss: 0.004423314705491066\n",
      "Iteration 720, Loss: 0.003936294466257095\n",
      "Iteration 730, Loss: 0.004298706538975239\n",
      "Iteration 740, Loss: 0.003997590858489275\n",
      "Iteration 750, Loss: 0.003810731926932931\n",
      "Iteration 760, Loss: 0.004384562838822603\n",
      "Iteration 770, Loss: 0.003409359836950898\n",
      "Iteration 780, Loss: 0.0036438321694731712\n",
      "Iteration 790, Loss: 0.003415757091715932\n",
      "Iteration 800, Loss: 0.003701502690091729\n",
      "Iteration 810, Loss: 0.003629731247201562\n",
      "Iteration 820, Loss: 0.0033021015115082264\n",
      "Iteration 830, Loss: 0.003536500968039036\n",
      "Iteration 840, Loss: 0.003608035622164607\n",
      "Iteration 850, Loss: 0.0031748756300657988\n",
      "Iteration 860, Loss: 0.003304422600194812\n",
      "Iteration 870, Loss: 0.003443557769060135\n",
      "Iteration 880, Loss: 0.00316271698102355\n",
      "Iteration 890, Loss: 0.0033322572708129883\n",
      "Iteration 900, Loss: 0.002977917902171612\n",
      "Iteration 910, Loss: 0.0031131827272474766\n",
      "Iteration 920, Loss: 0.0030901296995580196\n",
      "Iteration 930, Loss: 0.0029263594187796116\n",
      "Iteration 940, Loss: 0.002849351381883025\n",
      "Iteration 950, Loss: 0.0028070646803826094\n",
      "Iteration 960, Loss: 0.0029125462751835585\n",
      "Iteration 970, Loss: 0.0028216924984008074\n",
      "Iteration 980, Loss: 0.0028138651978224516\n",
      "Iteration 990, Loss: 0.0026725525967776775\n",
      "Iteration 1000, Loss: 0.002702455734834075\n",
      "Iteration 1010, Loss: 0.002667694352567196\n",
      "Iteration 1020, Loss: 0.0027807028964161873\n",
      "Iteration 1030, Loss: 0.002806322416290641\n",
      "Iteration 1040, Loss: 0.002641727915033698\n",
      "Iteration 1050, Loss: 0.0025109194684773684\n",
      "Iteration 1060, Loss: 0.0026556928642094135\n",
      "Iteration 1070, Loss: 0.0024813220370560884\n",
      "Iteration 1080, Loss: 0.0025239570531994104\n",
      "Iteration 1090, Loss: 0.0023174395319074392\n",
      "Iteration 1100, Loss: 0.002758456626906991\n",
      "Iteration 1110, Loss: 0.0025047073140740395\n",
      "Iteration 1120, Loss: 0.002435649512335658\n",
      "Iteration 1130, Loss: 0.0025409806985408068\n",
      "Iteration 1140, Loss: 0.002399250864982605\n",
      "Iteration 1150, Loss: 0.0024654101580381393\n",
      "Iteration 1160, Loss: 0.0023287758231163025\n",
      "Iteration 1170, Loss: 0.002202713629230857\n",
      "Iteration 1180, Loss: 0.0022738983388990164\n",
      "Iteration 1190, Loss: 0.0022933760192245245\n",
      "Iteration 1200, Loss: 0.0023933006450533867\n",
      "Iteration 1210, Loss: 0.00231485185213387\n",
      "Iteration 1220, Loss: 0.0022186473943293095\n",
      "Iteration 1230, Loss: 0.0023024315014481544\n",
      "Iteration 1240, Loss: 0.0021129557862877846\n",
      "Iteration 1250, Loss: 0.0020861956290900707\n",
      "Iteration 1260, Loss: 0.002220744965597987\n",
      "Iteration 1270, Loss: 0.0021172985434532166\n",
      "Iteration 1280, Loss: 0.0021526727359741926\n",
      "Iteration 1290, Loss: 0.00211733253672719\n",
      "Iteration 1300, Loss: 0.002143287565559149\n",
      "Iteration 1310, Loss: 0.002051716670393944\n",
      "Iteration 1320, Loss: 0.0019165138946846128\n",
      "Iteration 1330, Loss: 0.0019606188870966434\n",
      "Iteration 1340, Loss: 0.001996812876313925\n",
      "Iteration 1350, Loss: 0.001907219528220594\n",
      "Iteration 1360, Loss: 0.0021228312980383635\n",
      "Iteration 1370, Loss: 0.002011365257203579\n",
      "Iteration 1380, Loss: 0.0019114555325359106\n",
      "Iteration 1390, Loss: 0.0020446337293833494\n",
      "Iteration 1400, Loss: 0.0019753514789044857\n",
      "Iteration 1410, Loss: 0.0018711676821112633\n",
      "Iteration 1420, Loss: 0.001838327618315816\n",
      "Iteration 1430, Loss: 0.0017455711495131254\n",
      "Iteration 1440, Loss: 0.0018378080567345023\n",
      "Iteration 1450, Loss: 0.0018028848571702838\n",
      "Iteration 1460, Loss: 0.001821699202992022\n",
      "Iteration 1470, Loss: 0.0018507734639570117\n",
      "Iteration 1480, Loss: 0.0018066249322146177\n",
      "Iteration 1490, Loss: 0.001713364850729704\n",
      "Iteration 1500, Loss: 0.0017772656865417957\n",
      "Iteration 1510, Loss: 0.0017165394965559244\n",
      "Iteration 1520, Loss: 0.0018073595128953457\n",
      "Iteration 1530, Loss: 0.0017759018810465932\n",
      "Iteration 1540, Loss: 0.0018557155271992087\n",
      "Iteration 1550, Loss: 0.0017196768894791603\n",
      "Iteration 1560, Loss: 0.0017283260822296143\n",
      "Iteration 1570, Loss: 0.001725961803458631\n",
      "Iteration 1580, Loss: 0.0016662559937685728\n",
      "Iteration 1590, Loss: 0.0017659451114013791\n",
      "Iteration 1600, Loss: 0.0017003867542371154\n",
      "Iteration 1610, Loss: 0.0016232033958658576\n",
      "Iteration 1620, Loss: 0.0017365919193252921\n",
      "Iteration 1630, Loss: 0.0016798482974991202\n",
      "Iteration 1640, Loss: 0.0016522671794518828\n",
      "Iteration 1650, Loss: 0.0016294188098981977\n",
      "Iteration 1660, Loss: 0.0016083018854260445\n",
      "Iteration 1670, Loss: 0.0016470736591145396\n",
      "Iteration 1680, Loss: 0.0016196288634091616\n",
      "Iteration 1690, Loss: 0.0015497613931074739\n",
      "Iteration 1700, Loss: 0.001563665340654552\n",
      "Iteration 1710, Loss: 0.0015624695224687457\n",
      "Iteration 1720, Loss: 0.001524000777862966\n",
      "Iteration 1730, Loss: 0.0015799234388396144\n",
      "Iteration 1740, Loss: 0.0015618252800777555\n",
      "Iteration 1750, Loss: 0.0016168492147698998\n",
      "Iteration 1760, Loss: 0.001542678801342845\n",
      "Iteration 1770, Loss: 0.001566538354381919\n",
      "Iteration 1780, Loss: 0.0015668682754039764\n",
      "Iteration 1790, Loss: 0.001533998060040176\n",
      "Iteration 1800, Loss: 0.001502468716353178\n",
      "Iteration 1810, Loss: 0.0014481213875114918\n",
      "Iteration 1820, Loss: 0.0015024417079985142\n",
      "Iteration 1830, Loss: 0.0015113279223442078\n",
      "Iteration 1840, Loss: 0.001559425494633615\n",
      "Iteration 1850, Loss: 0.001399915898218751\n",
      "Iteration 1860, Loss: 0.001422398374415934\n",
      "Iteration 1870, Loss: 0.0013972894521430135\n",
      "Iteration 1880, Loss: 0.001456606318242848\n",
      "Iteration 1890, Loss: 0.001507426262833178\n",
      "Iteration 1900, Loss: 0.0014009694568812847\n",
      "Iteration 1910, Loss: 0.001364382216706872\n",
      "Iteration 1920, Loss: 0.0014160512946546078\n",
      "Iteration 1930, Loss: 0.0014083512360230088\n",
      "Iteration 1940, Loss: 0.0014795251190662384\n",
      "Iteration 1950, Loss: 0.001385105773806572\n",
      "Iteration 1960, Loss: 0.001332842162810266\n",
      "Iteration 1970, Loss: 0.001362909679301083\n",
      "Iteration 1980, Loss: 0.0013600074453279376\n",
      "Iteration 1990, Loss: 0.0013986654812470078\n",
      "Iteration 2000, Loss: 0.0013849838869646192\n",
      "Iteration 2010, Loss: 0.0013719925191253424\n",
      "Iteration 2020, Loss: 0.0014574690721929073\n",
      "Iteration 2030, Loss: 0.0013511278666555882\n",
      "Iteration 2040, Loss: 0.00136314716655761\n",
      "Iteration 2050, Loss: 0.001336476649157703\n",
      "Iteration 2060, Loss: 0.0013083235826343298\n",
      "Iteration 2070, Loss: 0.0013343911850824952\n",
      "Iteration 2080, Loss: 0.0013549881987273693\n",
      "Iteration 2090, Loss: 0.0012727915309369564\n",
      "Iteration 2100, Loss: 0.0013609667075797915\n",
      "Iteration 2110, Loss: 0.0014120537089183927\n",
      "Iteration 2120, Loss: 0.0011840895749628544\n",
      "Iteration 2130, Loss: 0.001286619110032916\n",
      "Iteration 2140, Loss: 0.0013584333937615156\n",
      "Iteration 2150, Loss: 0.00129086640663445\n",
      "Iteration 2160, Loss: 0.0013515755999833345\n",
      "Iteration 2170, Loss: 0.001260348130017519\n",
      "Iteration 2180, Loss: 0.001249736174941063\n",
      "Iteration 2190, Loss: 0.0012277995701879263\n",
      "Iteration 2200, Loss: 0.001243388862349093\n",
      "Iteration 2210, Loss: 0.0012502199970185757\n",
      "Iteration 2220, Loss: 0.0012490084627643228\n",
      "Iteration 2230, Loss: 0.0013024689396843314\n",
      "Iteration 2240, Loss: 0.0011892766924574971\n",
      "Iteration 2250, Loss: 0.001187245361506939\n",
      "Iteration 2260, Loss: 0.0012159571051597595\n",
      "Iteration 2270, Loss: 0.0012150537222623825\n",
      "Iteration 2280, Loss: 0.0011999214766547084\n",
      "Iteration 2290, Loss: 0.0011404067045077682\n",
      "Iteration 2300, Loss: 0.0011744741350412369\n",
      "Iteration 2310, Loss: 0.0011658439179882407\n",
      "Iteration 2320, Loss: 0.0012177122989669442\n",
      "Iteration 2330, Loss: 0.00113489362411201\n",
      "Iteration 2340, Loss: 0.0011656536953523755\n",
      "Iteration 2350, Loss: 0.001132758567109704\n",
      "Iteration 2360, Loss: 0.0011291245464235544\n",
      "Iteration 2370, Loss: 0.0011366301914677024\n",
      "Iteration 2380, Loss: 0.0012020430294796824\n",
      "Iteration 2390, Loss: 0.0011123268632218242\n",
      "Iteration 2400, Loss: 0.001155413337983191\n",
      "Iteration 2410, Loss: 0.0010331944795325398\n",
      "Iteration 2420, Loss: 0.001079881563782692\n",
      "Iteration 2430, Loss: 0.0010934642050415277\n",
      "Iteration 2440, Loss: 0.0011638241121545434\n",
      "Iteration 2450, Loss: 0.0010647387243807316\n",
      "Iteration 2460, Loss: 0.0010424199281260371\n",
      "Iteration 2470, Loss: 0.0010696136159822345\n",
      "Iteration 2480, Loss: 0.0010676422389224172\n",
      "Iteration 2490, Loss: 0.0010510067222639918\n",
      "Iteration 2500, Loss: 0.0011545881861820817\n",
      "Iteration 2510, Loss: 0.0010654362849891186\n",
      "Iteration 2520, Loss: 0.001079448964446783\n",
      "Iteration 2530, Loss: 0.001127784256823361\n",
      "Iteration 2540, Loss: 0.0010814759880304337\n",
      "Iteration 2550, Loss: 0.0010683207074180245\n",
      "Iteration 2560, Loss: 0.0010071344440802932\n",
      "Iteration 2570, Loss: 0.0010720640420913696\n",
      "Iteration 2580, Loss: 0.0010835463181138039\n",
      "Iteration 2590, Loss: 0.001029272098094225\n",
      "Iteration 2600, Loss: 0.0009855855023488402\n",
      "Iteration 2610, Loss: 0.0010342779569327831\n",
      "Iteration 2620, Loss: 0.0010200298856943846\n",
      "Iteration 2630, Loss: 0.0010200876276940107\n",
      "Iteration 2640, Loss: 0.0009571787086315453\n",
      "Iteration 2650, Loss: 0.0010228799656033516\n",
      "Iteration 2660, Loss: 0.0010079604107886553\n",
      "Iteration 2670, Loss: 0.0010002978378906846\n",
      "Iteration 2680, Loss: 0.0009543512715026736\n",
      "Iteration 2690, Loss: 0.0010168777080252767\n",
      "Iteration 2700, Loss: 0.001010310254059732\n",
      "Iteration 2710, Loss: 0.0009556075092405081\n",
      "Iteration 2720, Loss: 0.001002976088784635\n",
      "Iteration 2730, Loss: 0.0009888488566502929\n",
      "Iteration 2740, Loss: 0.000940996571443975\n",
      "Iteration 2750, Loss: 0.0009617728646844625\n",
      "Iteration 2760, Loss: 0.0009414998930878937\n",
      "Iteration 2770, Loss: 0.0009289691806770861\n",
      "Iteration 2780, Loss: 0.0009911170927807689\n",
      "Iteration 2790, Loss: 0.0009534353157505393\n",
      "Iteration 2800, Loss: 0.000923160114325583\n",
      "Iteration 2810, Loss: 0.0009135259315371513\n",
      "Iteration 2820, Loss: 0.0009310003370046616\n",
      "Iteration 2830, Loss: 0.0009318187949247658\n",
      "Iteration 2840, Loss: 0.0009592855349183083\n",
      "Iteration 2850, Loss: 0.0009438079432584345\n",
      "Iteration 2860, Loss: 0.0009161992929875851\n",
      "Iteration 2870, Loss: 0.0008977379184216261\n",
      "Iteration 2880, Loss: 0.0009105619392357767\n",
      "Iteration 2890, Loss: 0.0008494957583025098\n",
      "Iteration 2900, Loss: 0.0008931683842092752\n",
      "Iteration 2910, Loss: 0.0008982475847005844\n",
      "Iteration 2920, Loss: 0.0009148029494099319\n",
      "Iteration 2930, Loss: 0.0008768094703555107\n",
      "Iteration 2940, Loss: 0.0008551611681468785\n",
      "Iteration 2950, Loss: 0.000873862998560071\n",
      "Iteration 2960, Loss: 0.0009060985175892711\n",
      "Iteration 2970, Loss: 0.0008445832063443959\n",
      "Iteration 2980, Loss: 0.0008495014044456184\n",
      "Iteration 2990, Loss: 0.0008378950878977776\n",
      "Iteration 3000, Loss: 0.0008312740828841925\n",
      "Iteration 3010, Loss: 0.000852371915243566\n",
      "Iteration 3020, Loss: 0.000886350404471159\n",
      "Iteration 3030, Loss: 0.0008589595090597868\n",
      "Iteration 3040, Loss: 0.0008110462804324925\n",
      "Iteration 3050, Loss: 0.0008211696404032409\n",
      "Iteration 3060, Loss: 0.0008131572394631803\n",
      "Iteration 3070, Loss: 0.0008004948031157255\n",
      "Iteration 3080, Loss: 0.000893767224624753\n",
      "Iteration 3090, Loss: 0.0008277687011286616\n",
      "Iteration 3100, Loss: 0.0008301094057969749\n",
      "Iteration 3110, Loss: 0.000816524843685329\n",
      "Iteration 3120, Loss: 0.0008260242757387459\n",
      "Iteration 3130, Loss: 0.0007584472768940032\n",
      "Iteration 3140, Loss: 0.0007945282268337905\n",
      "Iteration 3150, Loss: 0.0007991014863364398\n",
      "Iteration 3160, Loss: 0.0008110918570309877\n",
      "Iteration 3170, Loss: 0.0007940347422845662\n",
      "Iteration 3180, Loss: 0.0008009534794837236\n",
      "Iteration 3190, Loss: 0.0008103656000457704\n",
      "Iteration 3200, Loss: 0.0007428650860674679\n",
      "Iteration 3210, Loss: 0.0007868584943935275\n",
      "Iteration 3220, Loss: 0.0007131951279006898\n",
      "Iteration 3230, Loss: 0.0007413146086037159\n",
      "Iteration 3240, Loss: 0.0007660042028874159\n",
      "Iteration 3250, Loss: 0.000778420187998563\n",
      "Iteration 3260, Loss: 0.000751376268453896\n",
      "Iteration 3270, Loss: 0.0007224184810183942\n",
      "Iteration 3280, Loss: 0.0007738703861832619\n",
      "Iteration 3290, Loss: 0.0007289234199561179\n",
      "Iteration 3300, Loss: 0.0007325757178477943\n",
      "Iteration 3310, Loss: 0.0006878420244902372\n",
      "Iteration 3320, Loss: 0.0007082183728925884\n",
      "Iteration 3330, Loss: 0.0006854183739051223\n",
      "Iteration 3340, Loss: 0.0007204638095572591\n",
      "Iteration 3350, Loss: 0.0007097359048202634\n",
      "Iteration 3360, Loss: 0.000713391462340951\n",
      "Iteration 3370, Loss: 0.0007082244264893234\n",
      "Iteration 3380, Loss: 0.0007371064275503159\n",
      "Iteration 3390, Loss: 0.0006794232758693397\n",
      "Iteration 3400, Loss: 0.0006782902055419981\n",
      "Iteration 3410, Loss: 0.0006928603979758918\n",
      "Iteration 3420, Loss: 0.000678220356348902\n",
      "Iteration 3430, Loss: 0.0006662590312771499\n",
      "Iteration 3440, Loss: 0.000682204554323107\n",
      "Iteration 3450, Loss: 0.0006702604005113244\n",
      "Iteration 3460, Loss: 0.0006678052013739944\n",
      "Iteration 3470, Loss: 0.0006635044701397419\n",
      "Iteration 3480, Loss: 0.0006482707103714347\n",
      "Iteration 3490, Loss: 0.0006341875996440649\n",
      "Iteration 3500, Loss: 0.0006896443665027618\n",
      "Iteration 3510, Loss: 0.0006741744582541287\n",
      "Iteration 3520, Loss: 0.0006141985068097711\n",
      "Iteration 3530, Loss: 0.0006409060442820191\n",
      "Iteration 3540, Loss: 0.0006316536455415189\n",
      "Iteration 3550, Loss: 0.000645435880869627\n",
      "Iteration 3560, Loss: 0.0006510626990348101\n",
      "Iteration 3570, Loss: 0.0006427037878893316\n",
      "Iteration 3580, Loss: 0.0006010241340845823\n",
      "Iteration 3590, Loss: 0.0006275781779550016\n",
      "Iteration 3600, Loss: 0.0006162970094010234\n",
      "Iteration 3610, Loss: 0.000613069103565067\n",
      "Iteration 3620, Loss: 0.0005676427390426397\n",
      "Iteration 3630, Loss: 0.0006193507579155266\n",
      "Iteration 3640, Loss: 0.0006019555148668587\n",
      "Iteration 3650, Loss: 0.0005987221957184374\n",
      "Iteration 3660, Loss: 0.0005972581566311419\n",
      "Iteration 3670, Loss: 0.0006022627931088209\n",
      "Iteration 3680, Loss: 0.0005562572041526437\n",
      "Iteration 3690, Loss: 0.000560910499189049\n",
      "Iteration 3700, Loss: 0.0005802757805213332\n",
      "Iteration 3710, Loss: 0.0005797421326860785\n",
      "Iteration 3720, Loss: 0.0005950744962319732\n",
      "Iteration 3730, Loss: 0.0005586921470239758\n",
      "Iteration 3740, Loss: 0.0005735318991355598\n",
      "Iteration 3750, Loss: 0.000570761039853096\n",
      "Iteration 3760, Loss: 0.0005433493643067777\n",
      "Iteration 3770, Loss: 0.0005689180688932538\n",
      "Iteration 3780, Loss: 0.0005185234476812184\n",
      "Iteration 3790, Loss: 0.0005440023960545659\n",
      "Iteration 3800, Loss: 0.000534850696567446\n",
      "Iteration 3810, Loss: 0.0005322990473359823\n",
      "Iteration 3820, Loss: 0.0005602195742540061\n",
      "Iteration 3830, Loss: 0.0005277619929984212\n",
      "Iteration 3840, Loss: 0.0005300212651491165\n",
      "Iteration 3850, Loss: 0.0005447986768558621\n",
      "Iteration 3860, Loss: 0.0005410531302914023\n",
      "Iteration 3870, Loss: 0.0005333118606358767\n",
      "Iteration 3880, Loss: 0.0005272141424939036\n",
      "Iteration 3890, Loss: 0.0005408962606452405\n",
      "Iteration 3900, Loss: 0.0005221591563895345\n",
      "Iteration 3910, Loss: 0.0005252329865470529\n",
      "Iteration 3920, Loss: 0.0005058764945715666\n",
      "Iteration 3930, Loss: 0.0005129799828864634\n",
      "Iteration 3940, Loss: 0.0005168407806195319\n",
      "Iteration 3950, Loss: 0.0004901287611573935\n",
      "Iteration 3960, Loss: 0.00051732431165874\n",
      "Iteration 3970, Loss: 0.0005097093526273966\n",
      "Iteration 3980, Loss: 0.0004902235232293606\n",
      "Iteration 3990, Loss: 0.0004967226996086538\n",
      "Iteration 4000, Loss: 0.0004839394532609731\n",
      "Iteration 4010, Loss: 0.000496399006806314\n",
      "Iteration 4020, Loss: 0.0004943692474626005\n",
      "Iteration 4030, Loss: 0.0004941839724779129\n",
      "Iteration 4040, Loss: 0.0004496660258155316\n",
      "Iteration 4050, Loss: 0.0004808449011761695\n",
      "Iteration 4060, Loss: 0.0005008263979107141\n",
      "Iteration 4070, Loss: 0.0004665156302507967\n",
      "Iteration 4080, Loss: 0.00046863529132679105\n",
      "Iteration 4090, Loss: 0.00045317094190977514\n",
      "Iteration 4100, Loss: 0.00045834481716156006\n",
      "Iteration 4110, Loss: 0.0004449970438145101\n",
      "Iteration 4120, Loss: 0.0004545630363281816\n",
      "Iteration 4130, Loss: 0.0004650407354347408\n",
      "Iteration 4140, Loss: 0.0004469522391445935\n",
      "Iteration 4150, Loss: 0.0004483417433220893\n",
      "Iteration 4160, Loss: 0.0004297833365853876\n",
      "Iteration 4170, Loss: 0.0004201465053483844\n",
      "Iteration 4180, Loss: 0.00041601687553338706\n",
      "Iteration 4190, Loss: 0.0004465534002520144\n",
      "Iteration 4200, Loss: 0.00044185243314132094\n",
      "Iteration 4210, Loss: 0.0004430472617968917\n",
      "Iteration 4220, Loss: 0.0004382383485790342\n",
      "Iteration 4230, Loss: 0.00041867225081659853\n",
      "Iteration 4240, Loss: 0.000421500182710588\n",
      "Iteration 4250, Loss: 0.0004191617190372199\n",
      "Iteration 4260, Loss: 0.0004241990973241627\n",
      "Iteration 4270, Loss: 0.0004183918354101479\n",
      "Iteration 4280, Loss: 0.00040576630271971226\n",
      "Iteration 4290, Loss: 0.00039466944872401655\n",
      "Iteration 4300, Loss: 0.0004170614993199706\n",
      "Iteration 4310, Loss: 0.0004050610587000847\n",
      "Iteration 4320, Loss: 0.0004035774036310613\n",
      "Iteration 4330, Loss: 0.0003890141670126468\n",
      "Iteration 4340, Loss: 0.0003981837653554976\n",
      "Iteration 4350, Loss: 0.00040361189167015254\n",
      "Iteration 4360, Loss: 0.0003957162844017148\n",
      "Iteration 4370, Loss: 0.00040896463906392455\n",
      "Iteration 4380, Loss: 0.0003948387166019529\n",
      "Iteration 4390, Loss: 0.0004020130727440119\n",
      "Iteration 4400, Loss: 0.00038217753171920776\n",
      "Iteration 4410, Loss: 0.0003646148252300918\n",
      "Iteration 4420, Loss: 0.00037045928183943033\n",
      "Iteration 4430, Loss: 0.0003911806852556765\n",
      "Iteration 4440, Loss: 0.00038809009129181504\n",
      "Iteration 4450, Loss: 0.00034564058296382427\n",
      "Iteration 4460, Loss: 0.000374528462998569\n",
      "Iteration 4470, Loss: 0.0003850426583085209\n",
      "Iteration 4480, Loss: 0.00036536031984724104\n",
      "Iteration 4490, Loss: 0.00036855138023383915\n",
      "Iteration 4500, Loss: 0.00036426508449949324\n",
      "Iteration 4510, Loss: 0.000356096716132015\n",
      "Iteration 4520, Loss: 0.0003615342720877379\n",
      "Iteration 4530, Loss: 0.0003688290889840573\n",
      "Iteration 4540, Loss: 0.00034568781848065555\n",
      "Iteration 4550, Loss: 0.00037620626972056925\n",
      "Iteration 4560, Loss: 0.000349802547134459\n",
      "Iteration 4570, Loss: 0.00036192641709931195\n",
      "Iteration 4580, Loss: 0.00036044156877323985\n",
      "Iteration 4590, Loss: 0.00035094530903734267\n",
      "Iteration 4600, Loss: 0.00035343252238817513\n",
      "Iteration 4610, Loss: 0.0003267348511144519\n",
      "Iteration 4620, Loss: 0.00034975717426277697\n",
      "Iteration 4630, Loss: 0.0003495705022942275\n",
      "Iteration 4640, Loss: 0.0003378452965989709\n",
      "Iteration 4650, Loss: 0.00032139348331838846\n",
      "Iteration 4660, Loss: 0.0003407015174161643\n",
      "Iteration 4670, Loss: 0.00032398418989032507\n",
      "Iteration 4680, Loss: 0.0003381504211574793\n",
      "Iteration 4690, Loss: 0.0003229899157304317\n",
      "Iteration 4700, Loss: 0.0003404244489502162\n",
      "Iteration 4710, Loss: 0.0003290213644504547\n",
      "Iteration 4720, Loss: 0.0003249899309594184\n",
      "Iteration 4730, Loss: 0.00032666491460986435\n",
      "Iteration 4740, Loss: 0.0003213304444216192\n",
      "Iteration 4750, Loss: 0.00032401183852925897\n",
      "Iteration 4760, Loss: 0.0003077767032664269\n",
      "Iteration 4770, Loss: 0.000310953997541219\n",
      "Iteration 4780, Loss: 0.00031888799276202917\n",
      "Iteration 4790, Loss: 0.000308143236907199\n",
      "Iteration 4800, Loss: 0.00030350658926181495\n",
      "Iteration 4810, Loss: 0.00030036282259970903\n",
      "Iteration 4820, Loss: 0.0002849872980732471\n",
      "Iteration 4830, Loss: 0.0002886003057938069\n",
      "Iteration 4840, Loss: 0.00029835925670340657\n",
      "Iteration 4850, Loss: 0.0003046414640266448\n",
      "Iteration 4860, Loss: 0.000298980507068336\n",
      "Iteration 4870, Loss: 0.0003064429620280862\n",
      "Iteration 4880, Loss: 0.0002838049840647727\n",
      "Iteration 4890, Loss: 0.00031094043515622616\n",
      "Iteration 4900, Loss: 0.0002917610399890691\n",
      "Iteration 4910, Loss: 0.00029706076020374894\n",
      "Iteration 4920, Loss: 0.0002923141000792384\n",
      "Iteration 4930, Loss: 0.00028751380159519613\n",
      "Iteration 4940, Loss: 0.00029233068926259875\n",
      "Iteration 4950, Loss: 0.0002938711259048432\n",
      "Iteration 4960, Loss: 0.0002832479076460004\n",
      "Iteration 4970, Loss: 0.00029434324824251235\n",
      "Iteration 4980, Loss: 0.00029030448058620095\n",
      "Iteration 4990, Loss: 0.00028505860245786607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  33%|███▎      | 8/24 [06:17<15:40, 58.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.024819435464491356, 'L2_avg': 0.03125727887288779, 'End_point_L1_avg': 0.010326287271284469, 'End_point_L2_avg': 0.01178448120416911}\n",
      "Iteration 0, Loss: 1.3592119216918945\n",
      "Iteration 10, Loss: 0.1573406606912613\n",
      "Iteration 20, Loss: 0.10960811376571655\n",
      "Iteration 30, Loss: 0.047697409987449646\n",
      "Iteration 40, Loss: 0.044157207012176514\n",
      "Iteration 50, Loss: 0.030232513323426247\n",
      "Iteration 60, Loss: 0.024403298273682594\n",
      "Iteration 70, Loss: 0.015383320860564709\n",
      "Iteration 80, Loss: 0.010929861105978489\n",
      "Iteration 90, Loss: 0.012902684509754181\n",
      "Iteration 100, Loss: 0.00921139307320118\n",
      "Iteration 110, Loss: 0.006220510229468346\n",
      "Iteration 120, Loss: 0.006713527254760265\n",
      "Iteration 130, Loss: 0.00516579719260335\n",
      "Iteration 140, Loss: 0.0056099798530340195\n",
      "Iteration 150, Loss: 0.004723056219518185\n",
      "Iteration 160, Loss: 0.004373448900878429\n",
      "Iteration 170, Loss: 0.004017582628875971\n",
      "Iteration 180, Loss: 0.0032785749062895775\n",
      "Iteration 190, Loss: 0.0029703390318900347\n",
      "Iteration 200, Loss: 0.003217135788872838\n",
      "Iteration 210, Loss: 0.0028971571009606123\n",
      "Iteration 220, Loss: 0.0027468048501759768\n",
      "Iteration 230, Loss: 0.002904337365180254\n",
      "Iteration 240, Loss: 0.002495169872418046\n",
      "Iteration 250, Loss: 0.002420550910755992\n",
      "Iteration 260, Loss: 0.0027825103607028723\n",
      "Iteration 270, Loss: 0.0027040818240493536\n",
      "Iteration 280, Loss: 0.0022779738064855337\n",
      "Iteration 290, Loss: 0.002419593045488\n",
      "Iteration 300, Loss: 0.0020355696324259043\n",
      "Iteration 310, Loss: 0.0020895141642540693\n",
      "Iteration 320, Loss: 0.001938424538820982\n",
      "Iteration 330, Loss: 0.002050381386652589\n",
      "Iteration 340, Loss: 0.0019030423136427999\n",
      "Iteration 350, Loss: 0.0019513553706929088\n",
      "Iteration 360, Loss: 0.0018231362337246537\n",
      "Iteration 370, Loss: 0.0019541350193321705\n",
      "Iteration 380, Loss: 0.00195591663941741\n",
      "Iteration 390, Loss: 0.001895805587992072\n",
      "Iteration 400, Loss: 0.00162347755394876\n",
      "Iteration 410, Loss: 0.0016788792563602328\n",
      "Iteration 420, Loss: 0.001774936681613326\n",
      "Iteration 430, Loss: 0.001614295062609017\n",
      "Iteration 440, Loss: 0.0016353698447346687\n",
      "Iteration 450, Loss: 0.0015487207565456629\n",
      "Iteration 460, Loss: 0.001732420758344233\n",
      "Iteration 470, Loss: 0.0015968892257660627\n",
      "Iteration 480, Loss: 0.0016126107657328248\n",
      "Iteration 490, Loss: 0.0015127351507544518\n",
      "Iteration 500, Loss: 0.0014774349983781576\n",
      "Iteration 510, Loss: 0.00141300936229527\n",
      "Iteration 520, Loss: 0.0014685806818306446\n",
      "Iteration 530, Loss: 0.0013188079465180635\n",
      "Iteration 540, Loss: 0.0013339469442144036\n",
      "Iteration 550, Loss: 0.0012866019969806075\n",
      "Iteration 560, Loss: 0.0012603778159245849\n",
      "Iteration 570, Loss: 0.0012742700055241585\n",
      "Iteration 580, Loss: 0.0013264564331620932\n",
      "Iteration 590, Loss: 0.0012936186976730824\n",
      "Iteration 600, Loss: 0.0011304821819067001\n",
      "Iteration 610, Loss: 0.0011941196862608194\n",
      "Iteration 620, Loss: 0.001102454261854291\n",
      "Iteration 630, Loss: 0.0011430573649704456\n",
      "Iteration 640, Loss: 0.0010332036763429642\n",
      "Iteration 650, Loss: 0.001133646466769278\n",
      "Iteration 660, Loss: 0.0012379211839288473\n",
      "Iteration 670, Loss: 0.0010371532989665866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  38%|███▊      | 9/24 [06:28<10:59, 43.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 680, Loss: 0.0010168077424168587\n",
      "Stopping early at iteration 683\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 684, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.045637148065621816, 'L2_avg': 0.058403313315971796, 'End_point_L1_avg': 0.029379079999047132, 'End_point_L2_avg': 0.030798994136612936}\n",
      "Iteration 0, Loss: 1.8379496335983276\n",
      "Iteration 10, Loss: 0.13658981025218964\n",
      "Iteration 20, Loss: 0.16090519726276398\n",
      "Iteration 30, Loss: 0.05389978736639023\n",
      "Iteration 40, Loss: 0.04311341047286987\n",
      "Iteration 50, Loss: 0.02588081918656826\n",
      "Iteration 60, Loss: 0.018263742327690125\n",
      "Iteration 70, Loss: 0.01273881085216999\n",
      "Iteration 80, Loss: 0.00920372735708952\n",
      "Iteration 90, Loss: 0.007496265694499016\n",
      "Iteration 100, Loss: 0.005966012366116047\n",
      "Iteration 110, Loss: 0.006168925203382969\n",
      "Iteration 120, Loss: 0.005817847792059183\n",
      "Iteration 130, Loss: 0.004101910162717104\n",
      "Iteration 140, Loss: 0.004629355855286121\n",
      "Iteration 150, Loss: 0.0035631898790597916\n",
      "Iteration 160, Loss: 0.0032730079255998135\n",
      "Iteration 170, Loss: 0.003010915359482169\n",
      "Iteration 180, Loss: 0.003274890361353755\n",
      "Iteration 190, Loss: 0.0026605825405567884\n",
      "Iteration 200, Loss: 0.002664069412276149\n",
      "Iteration 210, Loss: 0.00264974613673985\n",
      "Iteration 220, Loss: 0.002577191684395075\n",
      "Iteration 230, Loss: 0.002194805536419153\n",
      "Iteration 240, Loss: 0.002204093150794506\n",
      "Iteration 250, Loss: 0.002430916763842106\n",
      "Iteration 260, Loss: 0.0019148691790178418\n",
      "Iteration 270, Loss: 0.00202184054069221\n",
      "Iteration 280, Loss: 0.0021506077609956264\n",
      "Iteration 290, Loss: 0.001933748833835125\n",
      "Iteration 300, Loss: 0.001971439691260457\n",
      "Iteration 310, Loss: 0.0019992964807897806\n",
      "Iteration 320, Loss: 0.0018997853621840477\n",
      "Iteration 330, Loss: 0.0017371107824146748\n",
      "Iteration 340, Loss: 0.0018144105561077595\n",
      "Iteration 350, Loss: 0.0018769896123558283\n",
      "Iteration 360, Loss: 0.0016471089329570532\n",
      "Iteration 370, Loss: 0.0017366394167765975\n",
      "Iteration 380, Loss: 0.0015001596184447408\n",
      "Iteration 390, Loss: 0.0015386305749416351\n",
      "Iteration 400, Loss: 0.0015715652843937278\n",
      "Iteration 410, Loss: 0.0014049112796783447\n",
      "Iteration 420, Loss: 0.0014460980892181396\n",
      "Iteration 430, Loss: 0.0013275406090542674\n",
      "Iteration 440, Loss: 0.0014309465186670423\n",
      "Iteration 450, Loss: 0.0014108252944424748\n",
      "Iteration 460, Loss: 0.00144870241638273\n",
      "Iteration 470, Loss: 0.0012938636355102062\n",
      "Iteration 480, Loss: 0.0013722332660108805\n",
      "Iteration 490, Loss: 0.0012557384325191379\n",
      "Iteration 500, Loss: 0.0012826750753447413\n",
      "Iteration 510, Loss: 0.001252308371476829\n",
      "Iteration 520, Loss: 0.0013413368724286556\n",
      "Iteration 530, Loss: 0.0012541803298518062\n",
      "Iteration 540, Loss: 0.0012145574437454343\n",
      "Iteration 550, Loss: 0.0010691494680941105\n",
      "Iteration 560, Loss: 0.0011136698303744197\n",
      "Iteration 570, Loss: 0.0011199796572327614\n",
      "Iteration 580, Loss: 0.000998952891677618\n",
      "Iteration 590, Loss: 0.0011490269098430872\n",
      "Iteration 600, Loss: 0.0011587104527279735\n",
      "Iteration 610, Loss: 0.0010583513649180532\n",
      "Iteration 620, Loss: 0.0009439393179491162\n",
      "Iteration 630, Loss: 0.000917037483304739\n",
      "Iteration 640, Loss: 0.0010055724997073412\n",
      "Iteration 650, Loss: 0.0009873394155874848\n",
      "Iteration 660, Loss: 0.0009353000205010176\n",
      "Iteration 670, Loss: 0.0009443247690796852\n",
      "Iteration 680, Loss: 0.0009004390449263155\n",
      "Iteration 690, Loss: 0.0009197673061862588\n",
      "Iteration 700, Loss: 0.0008677607984282076\n",
      "Iteration 710, Loss: 0.0008847604622133076\n",
      "Iteration 720, Loss: 0.0009561838814988732\n",
      "Iteration 730, Loss: 0.0008177753770723939\n",
      "Iteration 740, Loss: 0.0008226954378187656\n",
      "Iteration 750, Loss: 0.0007427976815961301\n",
      "Iteration 760, Loss: 0.0007262966246344149\n",
      "Iteration 770, Loss: 0.00078032590681687\n",
      "Iteration 780, Loss: 0.0007765304180793464\n",
      "Iteration 790, Loss: 0.0007906727842055261\n",
      "Iteration 800, Loss: 0.0007562962709926069\n",
      "Iteration 810, Loss: 0.0007951506995595992\n",
      "Iteration 820, Loss: 0.0007970881997607648\n",
      "Iteration 830, Loss: 0.0006723660044372082\n",
      "Iteration 840, Loss: 0.0007201790576800704\n",
      "Iteration 850, Loss: 0.0007197252125479281\n",
      "Iteration 860, Loss: 0.0006993349525146186\n",
      "Iteration 870, Loss: 0.000712195411324501\n",
      "Iteration 880, Loss: 0.0006851223879493773\n",
      "Iteration 890, Loss: 0.0006026991177350283\n",
      "Iteration 900, Loss: 0.0006482639000751078\n",
      "Iteration 910, Loss: 0.0006271405727602541\n",
      "Iteration 920, Loss: 0.0006667826673947275\n",
      "Iteration 930, Loss: 0.0006260083173401654\n",
      "Iteration 940, Loss: 0.0006401262362487614\n",
      "Iteration 950, Loss: 0.0006107620429247618\n",
      "Iteration 960, Loss: 0.0005685195210389793\n",
      "Iteration 970, Loss: 0.0005585947656072676\n",
      "Iteration 980, Loss: 0.0006012984667904675\n",
      "Iteration 990, Loss: 0.0006106644868850708\n",
      "Iteration 1000, Loss: 0.0006291412864811718\n",
      "Iteration 1010, Loss: 0.0005164397298358381\n",
      "Iteration 1020, Loss: 0.0005974492523819208\n",
      "Iteration 1030, Loss: 0.0005610103253275156\n",
      "Iteration 1040, Loss: 0.000538643158506602\n",
      "Iteration 1050, Loss: 0.0005857472424395382\n",
      "Iteration 1060, Loss: 0.0005738582112826407\n",
      "Iteration 1070, Loss: 0.0005778849008493125\n",
      "Iteration 1080, Loss: 0.0005252169212326407\n",
      "Iteration 1090, Loss: 0.00047545411507599056\n",
      "Iteration 1100, Loss: 0.00044518554932437837\n",
      "Iteration 1110, Loss: 0.0004305252805352211\n",
      "Iteration 1120, Loss: 0.00043698676745407283\n",
      "Iteration 1130, Loss: 0.0004122922837268561\n",
      "Iteration 1140, Loss: 0.00048427912406623363\n",
      "Iteration 1150, Loss: 0.0004929564893245697\n",
      "Iteration 1160, Loss: 0.0004938743077218533\n",
      "Iteration 1170, Loss: 0.0004840190813411027\n",
      "Iteration 1180, Loss: 0.00047167757293209434\n",
      "Iteration 1190, Loss: 0.0004521154041867703\n",
      "Iteration 1200, Loss: 0.0004108463763259351\n",
      "Iteration 1210, Loss: 0.0004148098232690245\n",
      "Iteration 1220, Loss: 0.00047585435095243156\n",
      "Iteration 1230, Loss: 0.0003890881489496678\n",
      "Iteration 1240, Loss: 0.0005484563298523426\n",
      "Iteration 1250, Loss: 0.0003807455359492451\n",
      "Iteration 1260, Loss: 0.0004152572655584663\n",
      "Iteration 1270, Loss: 0.00043574415030889213\n",
      "Iteration 1280, Loss: 0.0004200568073429167\n",
      "Iteration 1290, Loss: 0.00038580200634896755\n",
      "Iteration 1300, Loss: 0.00034841414890252054\n",
      "Iteration 1310, Loss: 0.0003757164813578129\n",
      "Iteration 1320, Loss: 0.00034944454091601074\n",
      "Iteration 1330, Loss: 0.0005084739532321692\n",
      "Iteration 1340, Loss: 0.0004082932136952877\n",
      "Iteration 1350, Loss: 0.0003905745397787541\n",
      "Iteration 1360, Loss: 0.000392719084629789\n",
      "Iteration 1370, Loss: 0.00032533641206100583\n",
      "Iteration 1380, Loss: 0.0004233944055158645\n",
      "Iteration 1390, Loss: 0.0003967771481256932\n",
      "Iteration 1400, Loss: 0.00033059457200579345\n",
      "Iteration 1410, Loss: 0.0004249794874340296\n",
      "Iteration 1420, Loss: 0.00041126913856714964\n",
      "Iteration 1430, Loss: 0.00030340434750542045\n",
      "Iteration 1440, Loss: 0.0003886048507411033\n",
      "Iteration 1450, Loss: 0.0004019767220597714\n",
      "Iteration 1460, Loss: 0.00029090113821439445\n",
      "Iteration 1470, Loss: 0.0003652007435448468\n",
      "Iteration 1480, Loss: 0.0004195001965854317\n",
      "Iteration 1490, Loss: 0.0005860365927219391\n",
      "Iteration 1500, Loss: 0.0004025460220873356\n",
      "Iteration 1510, Loss: 0.0005755096790380776\n",
      "Iteration 1520, Loss: 0.0003411282959859818\n",
      "Iteration 1530, Loss: 0.000367446627933532\n",
      "Iteration 1540, Loss: 0.0002977233089040965\n",
      "Iteration 1550, Loss: 0.0003314933564979583\n",
      "Iteration 1560, Loss: 0.00027911056531593204\n",
      "Iteration 1570, Loss: 0.00023758124734740704\n",
      "Iteration 1580, Loss: 0.0004124388506170362\n",
      "Iteration 1590, Loss: 0.00026548642199486494\n",
      "Iteration 1600, Loss: 0.0003680741065181792\n",
      "Iteration 1610, Loss: 0.0006360945990309119\n",
      "Iteration 1620, Loss: 0.00028416054556146264\n",
      "Iteration 1630, Loss: 0.0002911027113441378\n",
      "Iteration 1640, Loss: 0.00044348303345032036\n",
      "Iteration 1650, Loss: 0.0004086965636815876\n",
      "Iteration 1660, Loss: 0.0023736353032290936\n",
      "Iteration 1670, Loss: 0.0005785851972177625\n",
      "Iteration 1680, Loss: 0.0003871052176691592\n",
      "Iteration 1690, Loss: 0.00029773268033750355\n",
      "Iteration 1700, Loss: 0.0006112478440627456\n",
      "Iteration 1710, Loss: 0.0002461876720190048\n",
      "Iteration 1720, Loss: 0.0002236941654700786\n",
      "Iteration 1730, Loss: 0.0003840269346255809\n",
      "Iteration 1740, Loss: 0.001241991645656526\n",
      "Iteration 1750, Loss: 0.0011523929424583912\n",
      "Iteration 1760, Loss: 0.000891747185960412\n",
      "Iteration 1770, Loss: 0.00022370803344529122\n",
      "Iteration 1780, Loss: 0.00020755907462444156\n",
      "Iteration 1790, Loss: 0.0017336200689896941\n",
      "Iteration 1800, Loss: 0.0003523834457155317\n",
      "Iteration 1810, Loss: 0.00021317995560821146\n",
      "Iteration 1820, Loss: 0.00045245912042446434\n",
      "Iteration 1830, Loss: 0.0001982058020075783\n",
      "Iteration 1840, Loss: 0.00019445325597189367\n",
      "Iteration 1850, Loss: 0.0005366253899410367\n",
      "Iteration 1860, Loss: 0.00038248702185228467\n",
      "Iteration 1870, Loss: 0.00020525393483694643\n",
      "Iteration 1880, Loss: 0.0013742533046752214\n",
      "Iteration 1890, Loss: 0.0010686706518754363\n",
      "Iteration 1900, Loss: 0.00032558146631345153\n",
      "Iteration 1910, Loss: 0.0006442336016334593\n",
      "Iteration 1920, Loss: 0.00017821320216171443\n",
      "Iteration 1930, Loss: 0.00018597871530801058\n",
      "Iteration 1940, Loss: 0.0005710073746740818\n",
      "Iteration 1950, Loss: 0.0007586958236061037\n",
      "Iteration 1960, Loss: 0.00018394007929600775\n",
      "Iteration 1970, Loss: 0.0003779362887144089\n",
      "Iteration 1980, Loss: 0.0006485746707767248\n",
      "Iteration 1990, Loss: 0.00034853661782108247\n",
      "Iteration 2000, Loss: 0.00017214514082297683\n",
      "Iteration 2010, Loss: 0.0005045803263783455\n",
      "Iteration 2020, Loss: 0.005031888838857412\n",
      "Iteration 2030, Loss: 0.00232005026191473\n",
      "Iteration 2040, Loss: 0.0001617654343135655\n",
      "Iteration 2050, Loss: 0.0003266724816057831\n",
      "Iteration 2060, Loss: 0.00016491931455675513\n",
      "Iteration 2070, Loss: 0.00021883966110181063\n",
      "Iteration 2080, Loss: 0.00014588539488613605\n",
      "Iteration 2090, Loss: 0.00018086438649334013\n",
      "Iteration 2100, Loss: 0.00015904194151517004\n",
      "Iteration 2110, Loss: 0.00021288826246745884\n",
      "Iteration 2120, Loss: 0.0001965460687642917\n",
      "Iteration 2130, Loss: 0.00017176620895043015\n",
      "Iteration 2140, Loss: 0.00018850919150281698\n",
      "Iteration 2150, Loss: 0.00017675719573162496\n",
      "Iteration 2160, Loss: 0.000153207583935\n",
      "Iteration 2170, Loss: 0.0009610224515199661\n",
      "Iteration 2180, Loss: 0.00016225679428316653\n",
      "Iteration 2190, Loss: 0.0008865101262927055\n",
      "Iteration 2200, Loss: 0.00020656564447563142\n",
      "Iteration 2210, Loss: 0.00028287473833188415\n",
      "Iteration 2220, Loss: 0.0001435754238627851\n",
      "Iteration 2230, Loss: 0.00028789101634174585\n",
      "Iteration 2240, Loss: 0.00021325566922314465\n",
      "Iteration 2250, Loss: 0.000397123716538772\n",
      "Iteration 2260, Loss: 0.006751948036253452\n",
      "Iteration 2270, Loss: 0.0014673015102744102\n",
      "Iteration 2280, Loss: 0.0001759362203301862\n",
      "Iteration 2290, Loss: 0.0003116859297733754\n",
      "Iteration 2300, Loss: 0.00014532550994772464\n",
      "Iteration 2310, Loss: 0.00021426568855531514\n",
      "Iteration 2320, Loss: 0.00016915799642447382\n",
      "Iteration 2330, Loss: 0.0001494323369115591\n",
      "Iteration 2340, Loss: 0.00019720832642633468\n",
      "Iteration 2350, Loss: 0.00018760604143608361\n",
      "Iteration 2360, Loss: 0.00014300689508672804\n",
      "Iteration 2370, Loss: 0.00016611067985650152\n",
      "Iteration 2380, Loss: 0.0003463918110355735\n",
      "Iteration 2390, Loss: 0.0003507132059894502\n",
      "Iteration 2400, Loss: 0.00016358478751499206\n",
      "Iteration 2410, Loss: 0.0001718350249575451\n",
      "Iteration 2420, Loss: 0.0002707467065192759\n",
      "Iteration 2430, Loss: 0.0008774185553193092\n",
      "Iteration 2440, Loss: 0.000865525973495096\n",
      "Iteration 2450, Loss: 0.0011595382820814848\n",
      "Iteration 2460, Loss: 0.0006210702704265714\n",
      "Iteration 2470, Loss: 0.0003712207544595003\n",
      "Iteration 2480, Loss: 0.00038902615779079497\n",
      "Iteration 2490, Loss: 0.0006145288934931159\n",
      "Iteration 2500, Loss: 0.0006956732249818742\n",
      "Iteration 2510, Loss: 0.0003724577836692333\n",
      "Iteration 2520, Loss: 0.0006817758549004793\n",
      "Iteration 2530, Loss: 0.00013090863649267703\n",
      "Iteration 2540, Loss: 0.0001274765090784058\n",
      "Iteration 2550, Loss: 0.0003643313539214432\n",
      "Iteration 2560, Loss: 0.0004448177060112357\n",
      "Iteration 2570, Loss: 0.0008012540056370199\n",
      "Iteration 2580, Loss: 0.0007659411639906466\n",
      "Iteration 2590, Loss: 0.0003385371237527579\n",
      "Iteration 2600, Loss: 0.00045395977213047445\n",
      "Iteration 2610, Loss: 0.0007972584571689367\n",
      "Iteration 2620, Loss: 0.0001139591695391573\n",
      "Iteration 2630, Loss: 0.0003769155009649694\n",
      "Iteration 2640, Loss: 0.0002657945442479104\n",
      "Iteration 2650, Loss: 0.00017109418695326895\n",
      "Iteration 2660, Loss: 0.0006226338446140289\n",
      "Iteration 2670, Loss: 0.0020156842656433582\n",
      "Iteration 2680, Loss: 0.0015688081039115787\n",
      "Iteration 2690, Loss: 0.00040628801798447967\n",
      "Iteration 2700, Loss: 0.00029097599326632917\n",
      "Iteration 2710, Loss: 0.0001512681192252785\n",
      "Iteration 2720, Loss: 0.00011315954907331616\n",
      "Iteration 2730, Loss: 0.00013269539340399206\n",
      "Iteration 2740, Loss: 0.000280562206171453\n",
      "Iteration 2750, Loss: 0.0001358836016152054\n",
      "Iteration 2760, Loss: 0.00015746671124361455\n",
      "Iteration 2770, Loss: 0.0007082688389346004\n",
      "Iteration 2780, Loss: 0.006831496953964233\n",
      "Iteration 2790, Loss: 0.002358103636652231\n",
      "Iteration 2800, Loss: 0.0003147161041852087\n",
      "Iteration 2810, Loss: 0.00040197715861722827\n",
      "Iteration 2820, Loss: 0.0003669081488624215\n",
      "Iteration 2830, Loss: 0.0001129958254750818\n",
      "Iteration 2840, Loss: 0.0001840111508499831\n",
      "Iteration 2850, Loss: 0.00013731411308981478\n",
      "Stopping early at iteration 2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  42%|████▏     | 10/24 [07:15<10:29, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 2860, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.014700024804639892, 'L2_avg': 0.018552556668039184, 'End_point_L1_avg': 0.01062218521704615, 'End_point_L2_avg': 0.013931318755445763}\n",
      "Iteration 0, Loss: 1.495229959487915\n",
      "Iteration 10, Loss: 0.18169088661670685\n",
      "Iteration 20, Loss: 0.12301033735275269\n",
      "Iteration 30, Loss: 0.042470768094062805\n",
      "Iteration 40, Loss: 0.033652033656835556\n",
      "Iteration 50, Loss: 0.019778262823820114\n",
      "Iteration 60, Loss: 0.015850039198994637\n",
      "Iteration 70, Loss: 0.011958859860897064\n",
      "Iteration 80, Loss: 0.008127495646476746\n",
      "Iteration 90, Loss: 0.007001728285104036\n",
      "Iteration 100, Loss: 0.006987732835114002\n",
      "Iteration 110, Loss: 0.0062522063963115215\n",
      "Iteration 120, Loss: 0.005697180051356554\n",
      "Iteration 130, Loss: 0.005028735380619764\n",
      "Iteration 140, Loss: 0.004797312431037426\n",
      "Iteration 150, Loss: 0.004714619368314743\n",
      "Iteration 160, Loss: 0.004520328715443611\n",
      "Iteration 170, Loss: 0.004020834341645241\n",
      "Iteration 180, Loss: 0.0040570395067334175\n",
      "Iteration 190, Loss: 0.003724002279341221\n",
      "Iteration 200, Loss: 0.0038617353420704603\n",
      "Iteration 210, Loss: 0.003661257913336158\n",
      "Iteration 220, Loss: 0.0033355311024934053\n",
      "Iteration 230, Loss: 0.0034487794619053602\n",
      "Iteration 240, Loss: 0.003336027730256319\n",
      "Iteration 250, Loss: 0.003376948880031705\n",
      "Iteration 260, Loss: 0.003093524370342493\n",
      "Iteration 270, Loss: 0.003078392008319497\n",
      "Iteration 280, Loss: 0.0032495511695742607\n",
      "Iteration 290, Loss: 0.0030994624830782413\n",
      "Iteration 300, Loss: 0.0028858771547675133\n",
      "Iteration 310, Loss: 0.002693838905543089\n",
      "Iteration 320, Loss: 0.002686035120859742\n",
      "Iteration 330, Loss: 0.0025751825887709856\n",
      "Iteration 340, Loss: 0.0024533027317374945\n",
      "Iteration 350, Loss: 0.0024214317090809345\n",
      "Iteration 360, Loss: 0.0024668436963111162\n",
      "Iteration 370, Loss: 0.002346476074308157\n",
      "Iteration 380, Loss: 0.0023767477832734585\n",
      "Iteration 390, Loss: 0.0021959540899842978\n",
      "Iteration 400, Loss: 0.0023290140088647604\n",
      "Iteration 410, Loss: 0.0022037404123693705\n",
      "Iteration 420, Loss: 0.00214075343683362\n",
      "Iteration 430, Loss: 0.002044612541794777\n",
      "Iteration 440, Loss: 0.0020172884687781334\n",
      "Iteration 450, Loss: 0.0018814658978953958\n",
      "Iteration 460, Loss: 0.001819857396185398\n",
      "Iteration 470, Loss: 0.001871019136160612\n",
      "Iteration 480, Loss: 0.0016622428083792329\n",
      "Iteration 490, Loss: 0.0018110602395609021\n",
      "Iteration 500, Loss: 0.0016430866671726108\n",
      "Iteration 510, Loss: 0.001602447242476046\n",
      "Iteration 520, Loss: 0.0015703918179497123\n",
      "Iteration 530, Loss: 0.0016260710544884205\n",
      "Iteration 540, Loss: 0.001646069809794426\n",
      "Iteration 550, Loss: 0.001451537711545825\n",
      "Iteration 560, Loss: 0.0015021137660369277\n",
      "Iteration 570, Loss: 0.001443370245397091\n",
      "Iteration 580, Loss: 0.0014226710190996528\n",
      "Iteration 590, Loss: 0.0013241394190117717\n",
      "Iteration 600, Loss: 0.0013440758921205997\n",
      "Iteration 610, Loss: 0.0013483031652867794\n",
      "Iteration 620, Loss: 0.0012761170510202646\n",
      "Iteration 630, Loss: 0.001256468240171671\n",
      "Iteration 640, Loss: 0.0012747807195410132\n",
      "Iteration 650, Loss: 0.0012712188763543963\n",
      "Iteration 660, Loss: 0.0011704288190230727\n",
      "Iteration 670, Loss: 0.001184087828733027\n",
      "Iteration 680, Loss: 0.0011327594984322786\n",
      "Iteration 690, Loss: 0.001205716049298644\n",
      "Iteration 700, Loss: 0.0011723830830305815\n",
      "Iteration 710, Loss: 0.0011664931662380695\n",
      "Iteration 720, Loss: 0.001176629331894219\n",
      "Iteration 730, Loss: 0.001067252946086228\n",
      "Iteration 740, Loss: 0.0011483412235975266\n",
      "Iteration 750, Loss: 0.00111207680311054\n",
      "Iteration 760, Loss: 0.0010732131777331233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  46%|████▌     | 11/24 [07:28<07:36, 35.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 770, Loss: 0.0010347679490223527\n",
      "Stopping early at iteration 778\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 779, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04537624447739083, 'L2_avg': 0.05872963576339347, 'End_point_L1_avg': 0.028117188201862188, 'End_point_L2_avg': 0.02811779842931987}\n",
      "Iteration 0, Loss: 0.8100842237472534\n",
      "Iteration 10, Loss: 0.12452097982168198\n",
      "Iteration 20, Loss: 0.07891866564750671\n",
      "Iteration 30, Loss: 0.05108792334794998\n",
      "Iteration 40, Loss: 0.0349670946598053\n",
      "Iteration 50, Loss: 0.026905301958322525\n",
      "Iteration 60, Loss: 0.0197430606931448\n",
      "Iteration 70, Loss: 0.015209631063044071\n",
      "Iteration 80, Loss: 0.011117740534245968\n",
      "Iteration 90, Loss: 0.00939631462097168\n",
      "Iteration 100, Loss: 0.007004997227340937\n",
      "Iteration 110, Loss: 0.005880944896489382\n",
      "Iteration 120, Loss: 0.005168817471712828\n",
      "Iteration 130, Loss: 0.004765114281326532\n",
      "Iteration 140, Loss: 0.0038712986279278994\n",
      "Iteration 150, Loss: 0.003597422270104289\n",
      "Iteration 160, Loss: 0.003358474001288414\n",
      "Iteration 170, Loss: 0.002968447981402278\n",
      "Iteration 180, Loss: 0.002923973137512803\n",
      "Iteration 190, Loss: 0.0027588894590735435\n",
      "Iteration 200, Loss: 0.002677708864212036\n",
      "Iteration 210, Loss: 0.002501346170902252\n",
      "Iteration 220, Loss: 0.0024414188228547573\n",
      "Iteration 230, Loss: 0.0022386556956917048\n",
      "Iteration 240, Loss: 0.0022446145303547382\n",
      "Iteration 250, Loss: 0.002101034624502063\n",
      "Iteration 260, Loss: 0.0021123408805578947\n",
      "Iteration 270, Loss: 0.0020352352876216173\n",
      "Iteration 280, Loss: 0.001929718884639442\n",
      "Iteration 290, Loss: 0.0019033463904634118\n",
      "Iteration 300, Loss: 0.001849544234573841\n",
      "Iteration 310, Loss: 0.0017741273622959852\n",
      "Iteration 320, Loss: 0.001756845973432064\n",
      "Iteration 330, Loss: 0.0017088769236579537\n",
      "Iteration 340, Loss: 0.0016507101245224476\n",
      "Iteration 350, Loss: 0.0015987169463187456\n",
      "Iteration 360, Loss: 0.001571291359141469\n",
      "Iteration 370, Loss: 0.0015206212410703301\n",
      "Iteration 380, Loss: 0.001475334051065147\n",
      "Iteration 390, Loss: 0.001514552510343492\n",
      "Iteration 400, Loss: 0.0014441338134929538\n",
      "Iteration 410, Loss: 0.0013557130005210638\n",
      "Iteration 420, Loss: 0.0013912222348153591\n",
      "Iteration 430, Loss: 0.0013329812791198492\n",
      "Iteration 440, Loss: 0.001308711594901979\n",
      "Iteration 450, Loss: 0.0012801123084500432\n",
      "Iteration 460, Loss: 0.0012210016138851643\n",
      "Iteration 470, Loss: 0.0012630984419956803\n",
      "Iteration 480, Loss: 0.0011967397294938564\n",
      "Iteration 490, Loss: 0.0011554199736565351\n",
      "Iteration 500, Loss: 0.0011306371307000518\n",
      "Iteration 510, Loss: 0.001137384446337819\n",
      "Iteration 520, Loss: 0.0011260566534474492\n",
      "Iteration 530, Loss: 0.001073587452992797\n",
      "Iteration 540, Loss: 0.0010636337101459503\n",
      "Iteration 550, Loss: 0.0010430878028273582\n",
      "Iteration 560, Loss: 0.001003342098556459\n",
      "Iteration 570, Loss: 0.0009432041551917791\n",
      "Iteration 580, Loss: 0.0009822995634749532\n",
      "Iteration 590, Loss: 0.0009142112685367465\n",
      "Iteration 600, Loss: 0.0009155361913144588\n",
      "Iteration 610, Loss: 0.0009062605677172542\n",
      "Iteration 620, Loss: 0.0008493990171700716\n",
      "Iteration 630, Loss: 0.0008291019476018846\n",
      "Iteration 640, Loss: 0.0008298561442643404\n",
      "Iteration 650, Loss: 0.0008189908694475889\n",
      "Iteration 660, Loss: 0.0008397235651500523\n",
      "Iteration 670, Loss: 0.0008708194363862276\n",
      "Iteration 680, Loss: 0.0008972102077677846\n",
      "Iteration 690, Loss: 0.0007383707561530173\n",
      "Iteration 700, Loss: 0.0007642627460882068\n",
      "Iteration 710, Loss: 0.0007781734457239509\n",
      "Iteration 720, Loss: 0.0006902749883010983\n",
      "Iteration 730, Loss: 0.0008529641199856997\n",
      "Iteration 740, Loss: 0.0017332661664113402\n",
      "Iteration 750, Loss: 0.0009403020376339555\n",
      "Iteration 760, Loss: 0.0006542215123772621\n",
      "Iteration 770, Loss: 0.000686885614413768\n",
      "Iteration 780, Loss: 0.0006702178507111967\n",
      "Iteration 790, Loss: 0.0011855841148644686\n",
      "Iteration 800, Loss: 0.0012022379087284207\n",
      "Iteration 810, Loss: 0.0005543699371628463\n",
      "Iteration 820, Loss: 0.00070071907248348\n",
      "Iteration 830, Loss: 0.0007143525872379541\n",
      "Iteration 840, Loss: 0.0012360522523522377\n",
      "Iteration 850, Loss: 0.0008155014947988093\n",
      "Iteration 860, Loss: 0.001074162544682622\n",
      "Iteration 870, Loss: 0.0007615681388415396\n",
      "Iteration 880, Loss: 0.0004937216290272772\n",
      "Iteration 890, Loss: 0.00191206275485456\n",
      "Iteration 900, Loss: 0.0009699033107608557\n",
      "Iteration 910, Loss: 0.0007300482830032706\n",
      "Iteration 920, Loss: 0.0004471635038498789\n",
      "Iteration 930, Loss: 0.000481833063531667\n",
      "Iteration 940, Loss: 0.0004985210252925754\n",
      "Iteration 950, Loss: 0.0004443011712282896\n",
      "Iteration 960, Loss: 0.0004271906800568104\n",
      "Iteration 970, Loss: 0.0014289329992607236\n",
      "Iteration 980, Loss: 0.00040521868504583836\n",
      "Iteration 990, Loss: 0.0017584596062079072\n",
      "Iteration 1000, Loss: 0.0004924194072373211\n",
      "Iteration 1010, Loss: 0.00046236664638854563\n",
      "Iteration 1020, Loss: 0.00037989456905052066\n",
      "Iteration 1030, Loss: 0.0003862902522087097\n",
      "Iteration 1040, Loss: 0.00036439026007428765\n",
      "Iteration 1050, Loss: 0.00037884246557950974\n",
      "Iteration 1060, Loss: 0.0003568736428860575\n",
      "Iteration 1070, Loss: 0.0004192699561826885\n",
      "Iteration 1080, Loss: 0.0003989829565398395\n",
      "Iteration 1090, Loss: 0.0003448164206929505\n",
      "Iteration 1100, Loss: 0.0003540866600815207\n",
      "Iteration 1110, Loss: 0.001237213145941496\n",
      "Iteration 1120, Loss: 0.0010317388223484159\n",
      "Iteration 1130, Loss: 0.00047920062206685543\n",
      "Iteration 1140, Loss: 0.00031507518724538386\n",
      "Iteration 1150, Loss: 0.00047879270277917385\n",
      "Iteration 1160, Loss: 0.00081586220767349\n",
      "Iteration 1170, Loss: 0.0010835204739123583\n",
      "Iteration 1180, Loss: 0.00045266494271345437\n",
      "Iteration 1190, Loss: 0.0003118583408650011\n",
      "Iteration 1200, Loss: 0.0003153698053210974\n",
      "Iteration 1210, Loss: 0.0004322892928030342\n",
      "Iteration 1220, Loss: 0.003982446156442165\n",
      "Iteration 1230, Loss: 0.0018013560911640525\n",
      "Iteration 1240, Loss: 0.0005806052940897644\n",
      "Iteration 1250, Loss: 0.00035358720924705267\n",
      "Iteration 1260, Loss: 0.0004381581675261259\n",
      "Iteration 1270, Loss: 0.0002613273973111063\n",
      "Iteration 1280, Loss: 0.000246016017626971\n",
      "Iteration 1290, Loss: 0.00026714563136920333\n",
      "Iteration 1300, Loss: 0.0002767614205367863\n",
      "Iteration 1310, Loss: 0.0004158460069447756\n",
      "Iteration 1320, Loss: 0.00024242294603027403\n",
      "Iteration 1330, Loss: 0.0010409848764538765\n",
      "Iteration 1340, Loss: 0.0003054247936233878\n",
      "Iteration 1350, Loss: 0.0007786804926581681\n",
      "Iteration 1360, Loss: 0.0002423122787149623\n",
      "Iteration 1370, Loss: 0.0003836402320303023\n",
      "Iteration 1380, Loss: 0.00034562702057883143\n",
      "Iteration 1390, Loss: 0.00022734227241016924\n",
      "Iteration 1400, Loss: 0.0015128720551729202\n",
      "Iteration 1410, Loss: 0.0008397922501899302\n",
      "Iteration 1420, Loss: 0.00022965666721574962\n",
      "Iteration 1430, Loss: 0.0002976776158902794\n",
      "Iteration 1440, Loss: 0.00028590753208845854\n",
      "Iteration 1450, Loss: 0.00020675643463619053\n",
      "Iteration 1460, Loss: 0.00020119403779972345\n",
      "Iteration 1470, Loss: 0.00019751134095713496\n",
      "Iteration 1480, Loss: 0.00021886746981181204\n",
      "Iteration 1490, Loss: 0.00021891723736189306\n",
      "Iteration 1500, Loss: 0.0007988365250639617\n",
      "Iteration 1510, Loss: 0.0021657347679138184\n",
      "Iteration 1520, Loss: 0.001100078341551125\n",
      "Iteration 1530, Loss: 0.00033260355121456087\n",
      "Iteration 1540, Loss: 0.00024909659987315536\n",
      "Iteration 1550, Loss: 0.00025566195836290717\n",
      "Iteration 1560, Loss: 0.0002568253839854151\n",
      "Iteration 1570, Loss: 0.0002933249925263226\n",
      "Iteration 1580, Loss: 0.0002951961650978774\n",
      "Iteration 1590, Loss: 0.0024266280233860016\n",
      "Iteration 1600, Loss: 0.0012479642173275352\n",
      "Iteration 1610, Loss: 0.0015346782747656107\n",
      "Iteration 1620, Loss: 0.0001793658157112077\n",
      "Iteration 1630, Loss: 0.00026754310238175094\n",
      "Iteration 1640, Loss: 0.00017282158660236746\n",
      "Iteration 1650, Loss: 0.00019547595002222806\n",
      "Iteration 1660, Loss: 0.00016717977996449918\n",
      "Iteration 1670, Loss: 0.00016432178381364793\n",
      "Iteration 1680, Loss: 0.00017802997899707407\n",
      "Iteration 1690, Loss: 0.00016605954442638904\n",
      "Iteration 1700, Loss: 0.0002011329197557643\n",
      "Iteration 1710, Loss: 0.00016925811360124499\n",
      "Iteration 1720, Loss: 0.00015990597603376955\n",
      "Iteration 1730, Loss: 0.00018977477157022804\n",
      "Iteration 1740, Loss: 0.0016713390359655023\n",
      "Iteration 1750, Loss: 0.00015244839596562088\n",
      "Iteration 1760, Loss: 0.0010490630520507693\n",
      "Iteration 1770, Loss: 0.0003139137988910079\n",
      "Iteration 1780, Loss: 0.000172788932104595\n",
      "Iteration 1790, Loss: 0.00015956618881318718\n",
      "Iteration 1800, Loss: 0.00015126590733416378\n",
      "Iteration 1810, Loss: 0.00015581985644530505\n",
      "Iteration 1820, Loss: 0.0001474708697060123\n",
      "Iteration 1830, Loss: 0.00015096666174940765\n",
      "Iteration 1840, Loss: 0.00015438326227013022\n",
      "Iteration 1850, Loss: 0.0001554582267999649\n",
      "Iteration 1860, Loss: 0.0001446212554583326\n",
      "Iteration 1870, Loss: 0.00032490259036421776\n",
      "Iteration 1880, Loss: 0.0017746638040989637\n",
      "Iteration 1890, Loss: 0.00021376677614171058\n",
      "Iteration 1900, Loss: 0.00029491845634765923\n",
      "Iteration 1910, Loss: 0.0007244973676279187\n",
      "Iteration 1920, Loss: 0.00032223539892584085\n",
      "Iteration 1930, Loss: 0.00013558920181822032\n",
      "Iteration 1940, Loss: 0.0001281486329389736\n",
      "Iteration 1950, Loss: 0.00021628927788697183\n",
      "Iteration 1960, Loss: 0.0007335880654864013\n",
      "Iteration 1970, Loss: 0.001377170905470848\n",
      "Iteration 1980, Loss: 0.00013274366210680455\n",
      "Iteration 1990, Loss: 0.00017480542010162026\n",
      "Iteration 2000, Loss: 0.00012870802311226726\n",
      "Iteration 2010, Loss: 0.0004564870032481849\n",
      "Iteration 2020, Loss: 0.0027000585105270147\n",
      "Iteration 2030, Loss: 0.00017156505782622844\n",
      "Iteration 2040, Loss: 0.00013760000001639128\n",
      "Iteration 2050, Loss: 0.0001500874204793945\n",
      "Iteration 2060, Loss: 0.0002483032876625657\n",
      "Iteration 2070, Loss: 0.00032889030990190804\n",
      "Iteration 2080, Loss: 0.0004628683382179588\n",
      "Iteration 2090, Loss: 0.00017009256407618523\n",
      "Iteration 2100, Loss: 0.0009691970190033317\n",
      "Iteration 2110, Loss: 0.0011329002445563674\n",
      "Iteration 2120, Loss: 0.00047882861690595746\n",
      "Iteration 2130, Loss: 0.00021291353914421052\n",
      "Iteration 2140, Loss: 0.00017653884424362332\n",
      "Iteration 2150, Loss: 0.0002348378620808944\n",
      "Iteration 2160, Loss: 0.0003060965391341597\n",
      "Iteration 2170, Loss: 0.0003680834488477558\n",
      "Iteration 2180, Loss: 0.0005434771301224828\n",
      "Iteration 2190, Loss: 0.0007913038716651499\n",
      "Iteration 2200, Loss: 0.0006850976496934891\n",
      "Iteration 2210, Loss: 0.00013327143096830696\n",
      "Iteration 2220, Loss: 0.00012321230315137655\n",
      "Iteration 2230, Loss: 0.00025874527636915445\n",
      "Iteration 2240, Loss: 0.0023711100220680237\n",
      "Iteration 2250, Loss: 0.00014238967560231686\n",
      "Iteration 2260, Loss: 0.0002450966858305037\n",
      "Iteration 2270, Loss: 0.00026697420980781317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  50%|█████     | 12/24 [08:06<07:10, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2280, Loss: 0.00018082262249663472\n",
      "Stopping early at iteration 2285\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 2286, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.013625136905822276, 'L2_avg': 0.017328789468504704, 'End_point_L1_avg': 0.01169334799459317, 'End_point_L2_avg': 0.014499897894485489}\n",
      "Iteration 0, Loss: 1.3054453134536743\n",
      "Iteration 10, Loss: 0.9582411646842957\n",
      "Iteration 20, Loss: 0.7040930390357971\n",
      "Iteration 30, Loss: 0.523019015789032\n",
      "Iteration 40, Loss: 0.3866763412952423\n",
      "Iteration 50, Loss: 0.30173102021217346\n",
      "Iteration 60, Loss: 0.23314544558525085\n",
      "Iteration 70, Loss: 0.1730516254901886\n",
      "Iteration 80, Loss: 0.141778826713562\n",
      "Iteration 90, Loss: 0.11044606566429138\n",
      "Iteration 100, Loss: 0.08524176478385925\n",
      "Iteration 110, Loss: 0.07751019299030304\n",
      "Iteration 120, Loss: 0.06892215460538864\n",
      "Iteration 130, Loss: 0.06415746361017227\n",
      "Iteration 140, Loss: 0.062130123376846313\n",
      "Iteration 150, Loss: 0.05647292733192444\n",
      "Iteration 160, Loss: 0.056961752474308014\n",
      "Iteration 170, Loss: 0.04474693909287453\n",
      "Iteration 180, Loss: 0.04541939124464989\n",
      "Iteration 190, Loss: 0.05093112587928772\n",
      "Iteration 200, Loss: 0.03827999532222748\n",
      "Iteration 210, Loss: 0.03748588636517525\n",
      "Iteration 220, Loss: 0.034978948533535004\n",
      "Iteration 230, Loss: 0.03314727917313576\n",
      "Iteration 240, Loss: 0.032418735325336456\n",
      "Iteration 250, Loss: 0.03168902173638344\n",
      "Iteration 260, Loss: 0.030923744663596153\n",
      "Iteration 270, Loss: 0.03075507842004299\n",
      "Iteration 280, Loss: 0.027970777824521065\n",
      "Iteration 290, Loss: 0.02360534481704235\n",
      "Iteration 300, Loss: 0.027750717476010323\n",
      "Iteration 310, Loss: 0.024420669302344322\n",
      "Iteration 320, Loss: 0.025271620601415634\n",
      "Iteration 330, Loss: 0.029648862779140472\n",
      "Iteration 340, Loss: 0.01773516647517681\n",
      "Iteration 350, Loss: 0.017077820375561714\n",
      "Iteration 360, Loss: 0.018144214525818825\n",
      "Iteration 370, Loss: 0.025672681629657745\n",
      "Iteration 380, Loss: 0.019633613526821136\n",
      "Iteration 390, Loss: 0.02033780701458454\n",
      "Iteration 400, Loss: 0.019816948100924492\n",
      "Iteration 410, Loss: 0.012977387756109238\n",
      "Iteration 420, Loss: 0.01200774870812893\n",
      "Iteration 430, Loss: 0.014413663186132908\n",
      "Iteration 440, Loss: 0.012084448710083961\n",
      "Iteration 450, Loss: 0.010894153267145157\n",
      "Iteration 460, Loss: 0.013544430956244469\n",
      "Iteration 470, Loss: 0.011092361994087696\n",
      "Iteration 480, Loss: 0.012179016135632992\n",
      "Iteration 490, Loss: 0.008008759468793869\n",
      "Iteration 500, Loss: 0.008854664862155914\n",
      "Iteration 510, Loss: 0.008245504461228848\n",
      "Iteration 520, Loss: 0.007888722233474255\n",
      "Iteration 530, Loss: 0.006063117180019617\n",
      "Iteration 540, Loss: 0.008896436542272568\n",
      "Iteration 550, Loss: 0.007546096574515104\n",
      "Iteration 560, Loss: 0.007273915223777294\n",
      "Iteration 570, Loss: 0.005698705092072487\n",
      "Iteration 580, Loss: 0.005585809238255024\n",
      "Iteration 590, Loss: 0.006485975347459316\n",
      "Iteration 600, Loss: 0.005982961505651474\n",
      "Iteration 610, Loss: 0.0058472673408687115\n",
      "Iteration 620, Loss: 0.0050856187008321285\n",
      "Iteration 630, Loss: 0.004328371491283178\n",
      "Iteration 640, Loss: 0.0044286977499723434\n",
      "Iteration 650, Loss: 0.004710266832262278\n",
      "Iteration 660, Loss: 0.005449269898235798\n",
      "Iteration 670, Loss: 0.0038880794309079647\n",
      "Iteration 680, Loss: 0.004204754251986742\n",
      "Iteration 690, Loss: 0.004424524959176779\n",
      "Iteration 700, Loss: 0.004780161194503307\n",
      "Iteration 710, Loss: 0.003620938630774617\n",
      "Iteration 720, Loss: 0.0039648874662816525\n",
      "Iteration 730, Loss: 0.004271731711924076\n",
      "Iteration 740, Loss: 0.003931508399546146\n",
      "Iteration 750, Loss: 0.0030998759903013706\n",
      "Iteration 760, Loss: 0.0027789657469838858\n",
      "Iteration 770, Loss: 0.003050954081118107\n",
      "Iteration 780, Loss: 0.004008372314274311\n",
      "Iteration 790, Loss: 0.002540547400712967\n",
      "Iteration 800, Loss: 0.0032048807479441166\n",
      "Iteration 810, Loss: 0.0027012149803340435\n",
      "Iteration 820, Loss: 0.002911642659455538\n",
      "Iteration 830, Loss: 0.0030735423788428307\n",
      "Iteration 840, Loss: 0.003049013204872608\n",
      "Iteration 850, Loss: 0.0026015345938503742\n",
      "Iteration 860, Loss: 0.0029648044146597385\n",
      "Iteration 870, Loss: 0.003294280730187893\n",
      "Iteration 880, Loss: 0.003100789850577712\n",
      "Iteration 890, Loss: 0.002967172535136342\n",
      "Iteration 900, Loss: 0.002952764043584466\n",
      "Iteration 910, Loss: 0.002806279342621565\n",
      "Iteration 920, Loss: 0.0030541622545570135\n",
      "Iteration 930, Loss: 0.002588059287518263\n",
      "Iteration 940, Loss: 0.002821587258949876\n",
      "Iteration 950, Loss: 0.0026192336808890104\n",
      "Iteration 960, Loss: 0.0024888638872653246\n",
      "Iteration 970, Loss: 0.002403364982455969\n",
      "Iteration 980, Loss: 0.002781879622489214\n",
      "Iteration 990, Loss: 0.002241661539301276\n",
      "Iteration 1000, Loss: 0.0025395196862518787\n",
      "Iteration 1010, Loss: 0.0027790621388703585\n",
      "Iteration 1020, Loss: 0.002838319865986705\n",
      "Iteration 1030, Loss: 0.002757712733000517\n",
      "Iteration 1040, Loss: 0.0026359916664659977\n",
      "Iteration 1050, Loss: 0.002766110934317112\n",
      "Iteration 1060, Loss: 0.002534134080633521\n",
      "Iteration 1070, Loss: 0.0025674442294985056\n",
      "Iteration 1080, Loss: 0.002108290558680892\n",
      "Iteration 1090, Loss: 0.0023686641361564398\n",
      "Iteration 1100, Loss: 0.0023042450193315744\n",
      "Iteration 1110, Loss: 0.002347984816879034\n",
      "Iteration 1120, Loss: 0.0020072099287062883\n",
      "Iteration 1130, Loss: 0.002181921387091279\n",
      "Iteration 1140, Loss: 0.002581138862296939\n",
      "Iteration 1150, Loss: 0.0027198565658181906\n",
      "Iteration 1160, Loss: 0.002120452933013439\n",
      "Iteration 1170, Loss: 0.002173755085095763\n",
      "Iteration 1180, Loss: 0.0021281077060848475\n",
      "Iteration 1190, Loss: 0.002360674785450101\n",
      "Iteration 1200, Loss: 0.0022343348246067762\n",
      "Iteration 1210, Loss: 0.0020641754381358624\n",
      "Iteration 1220, Loss: 0.002032139105722308\n",
      "Iteration 1230, Loss: 0.0020604522433131933\n",
      "Iteration 1240, Loss: 0.0021952535025775433\n",
      "Iteration 1250, Loss: 0.002090248977765441\n",
      "Iteration 1260, Loss: 0.0019176892237737775\n",
      "Iteration 1270, Loss: 0.002054353943094611\n",
      "Iteration 1280, Loss: 0.0021241751965135336\n",
      "Iteration 1290, Loss: 0.0022306893952190876\n",
      "Iteration 1300, Loss: 0.002200608141720295\n",
      "Iteration 1310, Loss: 0.0018804939463734627\n",
      "Iteration 1320, Loss: 0.0019994403701275587\n",
      "Iteration 1330, Loss: 0.0022020002361387014\n",
      "Iteration 1340, Loss: 0.0021089520305395126\n",
      "Iteration 1350, Loss: 0.0020193348173052073\n",
      "Iteration 1360, Loss: 0.00199366407468915\n",
      "Iteration 1370, Loss: 0.0019948137924075127\n",
      "Iteration 1380, Loss: 0.0019119810312986374\n",
      "Iteration 1390, Loss: 0.0018588302191346884\n",
      "Iteration 1400, Loss: 0.0020905728451907635\n",
      "Iteration 1410, Loss: 0.00209594564512372\n",
      "Iteration 1420, Loss: 0.0019030380062758923\n",
      "Iteration 1430, Loss: 0.0019490886479616165\n",
      "Iteration 1440, Loss: 0.001785077154636383\n",
      "Iteration 1450, Loss: 0.0018867894541472197\n",
      "Iteration 1460, Loss: 0.0018727112328633666\n",
      "Iteration 1470, Loss: 0.0017425335245206952\n",
      "Iteration 1480, Loss: 0.001776352641172707\n",
      "Iteration 1490, Loss: 0.001744030974805355\n",
      "Iteration 1500, Loss: 0.0017346428940072656\n",
      "Iteration 1510, Loss: 0.0019771733786910772\n",
      "Iteration 1520, Loss: 0.0018989742966368794\n",
      "Iteration 1530, Loss: 0.0017877017380669713\n",
      "Iteration 1540, Loss: 0.001863280194811523\n",
      "Iteration 1550, Loss: 0.0017430696170777082\n",
      "Iteration 1560, Loss: 0.0016959732165560126\n",
      "Iteration 1570, Loss: 0.0017788405530154705\n",
      "Iteration 1580, Loss: 0.0018321116222068667\n",
      "Iteration 1590, Loss: 0.0015867820475250483\n",
      "Iteration 1600, Loss: 0.0017110061598941684\n",
      "Iteration 1610, Loss: 0.0017210541991516948\n",
      "Iteration 1620, Loss: 0.0014155986718833447\n",
      "Iteration 1630, Loss: 0.001747608301229775\n",
      "Iteration 1640, Loss: 0.0014619147405028343\n",
      "Iteration 1650, Loss: 0.0017124911537393928\n",
      "Iteration 1660, Loss: 0.0017010846640914679\n",
      "Iteration 1670, Loss: 0.0016321440925821662\n",
      "Iteration 1680, Loss: 0.0015916635747998953\n",
      "Iteration 1690, Loss: 0.0016194726340472698\n",
      "Iteration 1700, Loss: 0.0017792077269405127\n",
      "Iteration 1710, Loss: 0.0017856934573501348\n",
      "Iteration 1720, Loss: 0.001628655823878944\n",
      "Iteration 1730, Loss: 0.0016299078706651926\n",
      "Iteration 1740, Loss: 0.001523990067653358\n",
      "Iteration 1750, Loss: 0.0016046959208324552\n",
      "Iteration 1760, Loss: 0.0015202900394797325\n",
      "Iteration 1770, Loss: 0.0016318632988259196\n",
      "Iteration 1780, Loss: 0.0016030510887503624\n",
      "Iteration 1790, Loss: 0.0015493335667997599\n",
      "Iteration 1800, Loss: 0.0016433547716587782\n",
      "Iteration 1810, Loss: 0.0016358140856027603\n",
      "Iteration 1820, Loss: 0.0014624965842813253\n",
      "Iteration 1830, Loss: 0.0013596642529591918\n",
      "Iteration 1840, Loss: 0.0015907172346487641\n",
      "Iteration 1850, Loss: 0.0014701191103085876\n",
      "Iteration 1860, Loss: 0.001540124649181962\n",
      "Iteration 1870, Loss: 0.0014310231199488044\n",
      "Iteration 1880, Loss: 0.001658341265283525\n",
      "Iteration 1890, Loss: 0.001461533596739173\n",
      "Iteration 1900, Loss: 0.0015101957833394408\n",
      "Iteration 1910, Loss: 0.0015975030837580562\n",
      "Iteration 1920, Loss: 0.0016170918243005872\n",
      "Iteration 1930, Loss: 0.0015421629650518298\n",
      "Iteration 1940, Loss: 0.0015658107586205006\n",
      "Iteration 1950, Loss: 0.001616445486433804\n",
      "Iteration 1960, Loss: 0.0015035169199109077\n",
      "Iteration 1970, Loss: 0.0013866615481674671\n",
      "Iteration 1980, Loss: 0.0013730652863159776\n",
      "Iteration 1990, Loss: 0.0015305608976632357\n",
      "Iteration 2000, Loss: 0.0014467728324234486\n",
      "Iteration 2010, Loss: 0.001409110496751964\n",
      "Iteration 2020, Loss: 0.0013658975949510932\n",
      "Iteration 2030, Loss: 0.0013815013226121664\n",
      "Iteration 2040, Loss: 0.00135423697065562\n",
      "Iteration 2050, Loss: 0.0013998326612636447\n",
      "Iteration 2060, Loss: 0.0014338467735797167\n",
      "Iteration 2070, Loss: 0.0013247312745079398\n",
      "Iteration 2080, Loss: 0.001283810706809163\n",
      "Iteration 2090, Loss: 0.0014181940350681543\n",
      "Iteration 2100, Loss: 0.0012916534906253219\n",
      "Iteration 2110, Loss: 0.0012829244369640946\n",
      "Iteration 2120, Loss: 0.0013797751162201166\n",
      "Iteration 2130, Loss: 0.0013716344255954027\n",
      "Iteration 2140, Loss: 0.0012297724606469274\n",
      "Iteration 2150, Loss: 0.0013765781186521053\n",
      "Iteration 2160, Loss: 0.0013036662712693214\n",
      "Iteration 2170, Loss: 0.0012941446620970964\n",
      "Iteration 2180, Loss: 0.0013188422890380025\n",
      "Iteration 2190, Loss: 0.0013771848753094673\n",
      "Iteration 2200, Loss: 0.00118792534340173\n",
      "Iteration 2210, Loss: 0.0012651683064177632\n",
      "Iteration 2220, Loss: 0.0013249160256236792\n",
      "Iteration 2230, Loss: 0.0013618671800941229\n",
      "Iteration 2240, Loss: 0.0011615349212661386\n",
      "Iteration 2250, Loss: 0.0011775774182751775\n",
      "Iteration 2260, Loss: 0.0012789793545380235\n",
      "Iteration 2270, Loss: 0.0012929968070238829\n",
      "Iteration 2280, Loss: 0.0013527253177016973\n",
      "Iteration 2290, Loss: 0.001192335388623178\n",
      "Iteration 2300, Loss: 0.0012811265187337995\n",
      "Iteration 2310, Loss: 0.0012300764210522175\n",
      "Iteration 2320, Loss: 0.0010300650028511882\n",
      "Iteration 2330, Loss: 0.0011650500819087029\n",
      "Iteration 2340, Loss: 0.0013328480999916792\n",
      "Iteration 2350, Loss: 0.0012114348355680704\n",
      "Iteration 2360, Loss: 0.0012388871982693672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  54%|█████▍    | 13/24 [08:45<06:45, 36.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 2366\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 2367, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04862147303084931, 'L2_avg': 0.06270484789649455, 'End_point_L1_avg': 0.027258833819645258, 'End_point_L2_avg': 0.02733605220131108}\n",
      "Iteration 0, Loss: 1.3605725765228271\n",
      "Iteration 10, Loss: 1.0607407093048096\n",
      "Iteration 20, Loss: 0.8376069068908691\n",
      "Iteration 30, Loss: 0.6584450006484985\n",
      "Iteration 40, Loss: 0.5146694183349609\n",
      "Iteration 50, Loss: 0.3909870386123657\n",
      "Iteration 60, Loss: 0.29649269580841064\n",
      "Iteration 70, Loss: 0.22800053656101227\n",
      "Iteration 80, Loss: 0.16786432266235352\n",
      "Iteration 90, Loss: 0.1286897212266922\n",
      "Iteration 100, Loss: 0.093608558177948\n",
      "Iteration 110, Loss: 0.07167041301727295\n",
      "Iteration 120, Loss: 0.06605499237775803\n",
      "Iteration 130, Loss: 0.04201473295688629\n",
      "Iteration 140, Loss: 0.047209225594997406\n",
      "Iteration 150, Loss: 0.040100451558828354\n",
      "Iteration 160, Loss: 0.03719937801361084\n",
      "Iteration 170, Loss: 0.037365660071372986\n",
      "Iteration 180, Loss: 0.026609789580106735\n",
      "Iteration 190, Loss: 0.03381205350160599\n",
      "Iteration 200, Loss: 0.027154874056577682\n",
      "Iteration 210, Loss: 0.0209062322974205\n",
      "Iteration 220, Loss: 0.02168002910912037\n",
      "Iteration 230, Loss: 0.018386878073215485\n",
      "Iteration 240, Loss: 0.020341407507658005\n",
      "Iteration 250, Loss: 0.02022312581539154\n",
      "Iteration 260, Loss: 0.018949341028928757\n",
      "Iteration 270, Loss: 0.01821918599307537\n",
      "Iteration 280, Loss: 0.01792042702436447\n",
      "Iteration 290, Loss: 0.014427351765334606\n",
      "Iteration 300, Loss: 0.017431896179914474\n",
      "Iteration 310, Loss: 0.013139543123543262\n",
      "Iteration 320, Loss: 0.014465466141700745\n",
      "Iteration 330, Loss: 0.012110300362110138\n",
      "Iteration 340, Loss: 0.009680437855422497\n",
      "Iteration 350, Loss: 0.012232246808707714\n",
      "Iteration 360, Loss: 0.008854057639837265\n",
      "Iteration 370, Loss: 0.010290613397955894\n",
      "Iteration 380, Loss: 0.009654884226620197\n",
      "Iteration 390, Loss: 0.009834911674261093\n",
      "Iteration 400, Loss: 0.007327411789447069\n",
      "Iteration 410, Loss: 0.010540003888309002\n",
      "Iteration 420, Loss: 0.007117172237485647\n",
      "Iteration 430, Loss: 0.008226552046835423\n",
      "Iteration 440, Loss: 0.006360729690641165\n",
      "Iteration 450, Loss: 0.009664522483944893\n",
      "Iteration 460, Loss: 0.00538673484697938\n",
      "Iteration 470, Loss: 0.0070596905425190926\n",
      "Iteration 480, Loss: 0.0064765168353915215\n",
      "Iteration 490, Loss: 0.0061562564224004745\n",
      "Iteration 500, Loss: 0.005104708485305309\n",
      "Iteration 510, Loss: 0.004923729691654444\n",
      "Iteration 520, Loss: 0.004993156995624304\n",
      "Iteration 530, Loss: 0.004436961840838194\n",
      "Iteration 540, Loss: 0.005733289755880833\n",
      "Iteration 550, Loss: 0.004157013259828091\n",
      "Iteration 560, Loss: 0.003971044905483723\n",
      "Iteration 570, Loss: 0.003542916849255562\n",
      "Iteration 580, Loss: 0.003819820936769247\n",
      "Iteration 590, Loss: 0.004283346701413393\n",
      "Iteration 600, Loss: 0.004555226303637028\n",
      "Iteration 610, Loss: 0.002941118087619543\n",
      "Iteration 620, Loss: 0.004435780458152294\n",
      "Iteration 630, Loss: 0.003930941689759493\n",
      "Iteration 640, Loss: 0.0037518362514674664\n",
      "Iteration 650, Loss: 0.002504076110199094\n",
      "Iteration 660, Loss: 0.003181930398568511\n",
      "Iteration 670, Loss: 0.003327996702864766\n",
      "Iteration 680, Loss: 0.0035245849285274744\n",
      "Iteration 690, Loss: 0.003035420086234808\n",
      "Iteration 700, Loss: 0.0029504892881959677\n",
      "Iteration 710, Loss: 0.0031693836208432913\n",
      "Iteration 720, Loss: 0.0028644592966884375\n",
      "Iteration 730, Loss: 0.0027398543898016214\n",
      "Iteration 740, Loss: 0.002812364138662815\n",
      "Iteration 750, Loss: 0.0031484593637287617\n",
      "Iteration 760, Loss: 0.0035187480971217155\n",
      "Iteration 770, Loss: 0.003268938045948744\n",
      "Iteration 780, Loss: 0.0032214296516031027\n",
      "Iteration 790, Loss: 0.0028149590361863375\n",
      "Iteration 800, Loss: 0.002647135639563203\n",
      "Iteration 810, Loss: 0.002589514246210456\n",
      "Iteration 820, Loss: 0.0024766705464571714\n",
      "Iteration 830, Loss: 0.002479822374880314\n",
      "Iteration 840, Loss: 0.0023466418497264385\n",
      "Iteration 850, Loss: 0.002810841426253319\n",
      "Iteration 860, Loss: 0.0022730487398803234\n",
      "Iteration 870, Loss: 0.0025807346682995558\n",
      "Iteration 880, Loss: 0.0021901139989495277\n",
      "Iteration 890, Loss: 0.0023282128386199474\n",
      "Iteration 900, Loss: 0.0024866568855941296\n",
      "Iteration 910, Loss: 0.002612764248624444\n",
      "Iteration 920, Loss: 0.002517146058380604\n",
      "Iteration 930, Loss: 0.002698402851819992\n",
      "Iteration 940, Loss: 0.0022605732083320618\n",
      "Iteration 950, Loss: 0.0026090883184224367\n",
      "Iteration 960, Loss: 0.002298838458955288\n",
      "Iteration 970, Loss: 0.0027165054343640804\n",
      "Iteration 980, Loss: 0.0025784680619835854\n",
      "Iteration 990, Loss: 0.0022448627278208733\n",
      "Iteration 1000, Loss: 0.002317641396075487\n",
      "Iteration 1010, Loss: 0.001988771138712764\n",
      "Iteration 1020, Loss: 0.0021310467272996902\n",
      "Iteration 1030, Loss: 0.002149090636521578\n",
      "Iteration 1040, Loss: 0.0023647332563996315\n",
      "Iteration 1050, Loss: 0.0023035285994410515\n",
      "Iteration 1060, Loss: 0.0020202714949846268\n",
      "Iteration 1070, Loss: 0.0021289032883942127\n",
      "Iteration 1080, Loss: 0.0017131816130131483\n",
      "Iteration 1090, Loss: 0.0020203562453389168\n",
      "Iteration 1100, Loss: 0.002191911917179823\n",
      "Iteration 1110, Loss: 0.002047999994829297\n",
      "Iteration 1120, Loss: 0.0018641767092049122\n",
      "Iteration 1130, Loss: 0.002071854891255498\n",
      "Iteration 1140, Loss: 0.0019641751423478127\n",
      "Iteration 1150, Loss: 0.0019011677941307425\n",
      "Iteration 1160, Loss: 0.002172771841287613\n",
      "Iteration 1170, Loss: 0.0020618652924895287\n",
      "Iteration 1180, Loss: 0.0020859972573816776\n",
      "Iteration 1190, Loss: 0.0020441915839910507\n",
      "Iteration 1200, Loss: 0.002057224279269576\n",
      "Iteration 1210, Loss: 0.002187232719734311\n",
      "Iteration 1220, Loss: 0.0019623402040451765\n",
      "Iteration 1230, Loss: 0.0021144719794392586\n",
      "Iteration 1240, Loss: 0.0019513549050316215\n",
      "Iteration 1250, Loss: 0.001988072646781802\n",
      "Iteration 1260, Loss: 0.0021948949433863163\n",
      "Iteration 1270, Loss: 0.0021489663049578667\n",
      "Iteration 1280, Loss: 0.0019925825763493776\n",
      "Iteration 1290, Loss: 0.0018614461878314614\n",
      "Iteration 1300, Loss: 0.0017016221536323428\n",
      "Iteration 1310, Loss: 0.002168804407119751\n",
      "Iteration 1320, Loss: 0.0018430796917527914\n",
      "Iteration 1330, Loss: 0.00197932799346745\n",
      "Iteration 1340, Loss: 0.001969063188880682\n",
      "Iteration 1350, Loss: 0.0018319250084459782\n",
      "Iteration 1360, Loss: 0.001825704355724156\n",
      "Iteration 1370, Loss: 0.0020038888324052095\n",
      "Iteration 1380, Loss: 0.0017635690746828914\n",
      "Iteration 1390, Loss: 0.0016961598303169012\n",
      "Iteration 1400, Loss: 0.0017351118149235845\n",
      "Iteration 1410, Loss: 0.0018959364388138056\n",
      "Iteration 1420, Loss: 0.0016505056992173195\n",
      "Iteration 1430, Loss: 0.0016428985400125384\n",
      "Iteration 1440, Loss: 0.001711338642053306\n",
      "Iteration 1450, Loss: 0.0017492241458967328\n",
      "Iteration 1460, Loss: 0.0018411201890558004\n",
      "Iteration 1470, Loss: 0.0018992109689861536\n",
      "Iteration 1480, Loss: 0.0018070696387439966\n",
      "Iteration 1490, Loss: 0.0016586885321885347\n",
      "Iteration 1500, Loss: 0.0018088534707203507\n",
      "Iteration 1510, Loss: 0.0016363413305953145\n",
      "Iteration 1520, Loss: 0.0018129086820408702\n",
      "Iteration 1530, Loss: 0.0016687476309016347\n",
      "Iteration 1540, Loss: 0.001890702871605754\n",
      "Iteration 1550, Loss: 0.0016748463967815042\n",
      "Iteration 1560, Loss: 0.001563061261549592\n",
      "Iteration 1570, Loss: 0.0017161003779619932\n",
      "Iteration 1580, Loss: 0.0016870900290086865\n",
      "Iteration 1590, Loss: 0.0015776376239955425\n",
      "Iteration 1600, Loss: 0.0015853089280426502\n",
      "Iteration 1610, Loss: 0.0019222444389015436\n",
      "Iteration 1620, Loss: 0.0016188096487894654\n",
      "Iteration 1630, Loss: 0.0016922233626246452\n",
      "Iteration 1640, Loss: 0.0015949738444760442\n",
      "Iteration 1650, Loss: 0.001670266967266798\n",
      "Iteration 1660, Loss: 0.0016397730214521289\n",
      "Iteration 1670, Loss: 0.001670206431299448\n",
      "Iteration 1680, Loss: 0.0015251218574121594\n",
      "Iteration 1690, Loss: 0.0016949692508205771\n",
      "Iteration 1700, Loss: 0.0016926218522712588\n",
      "Iteration 1710, Loss: 0.0016012737760320306\n",
      "Iteration 1720, Loss: 0.0018753272015601397\n",
      "Iteration 1730, Loss: 0.0015295993071049452\n",
      "Iteration 1740, Loss: 0.0015327244764193892\n",
      "Iteration 1750, Loss: 0.0017980901757255197\n",
      "Iteration 1760, Loss: 0.0015307932626456022\n",
      "Iteration 1770, Loss: 0.0016319031128659844\n",
      "Iteration 1780, Loss: 0.0016316231340169907\n",
      "Iteration 1790, Loss: 0.001478524412959814\n",
      "Iteration 1800, Loss: 0.0015545857604593039\n",
      "Iteration 1810, Loss: 0.0017178443958982825\n",
      "Iteration 1820, Loss: 0.001750670955516398\n",
      "Iteration 1830, Loss: 0.0015418230323120952\n",
      "Iteration 1840, Loss: 0.001569058164022863\n",
      "Iteration 1850, Loss: 0.0015383203281089664\n",
      "Iteration 1860, Loss: 0.0015954709379002452\n",
      "Iteration 1870, Loss: 0.0015761068789288402\n",
      "Iteration 1880, Loss: 0.0014553258661180735\n",
      "Iteration 1890, Loss: 0.0017072372138500214\n",
      "Iteration 1900, Loss: 0.0015188406687229872\n",
      "Iteration 1910, Loss: 0.0015039582503959537\n",
      "Iteration 1920, Loss: 0.001601246651262045\n",
      "Iteration 1930, Loss: 0.0015829490730538964\n",
      "Iteration 1940, Loss: 0.0015592762501910329\n",
      "Iteration 1950, Loss: 0.0014248071238398552\n",
      "Iteration 1960, Loss: 0.0015423722798004746\n",
      "Iteration 1970, Loss: 0.0013844408094882965\n",
      "Iteration 1980, Loss: 0.001523863640613854\n",
      "Iteration 1990, Loss: 0.0016001390758901834\n",
      "Iteration 2000, Loss: 0.0014066110597923398\n",
      "Iteration 2010, Loss: 0.0014285726938396692\n",
      "Iteration 2020, Loss: 0.0014045265270397067\n",
      "Iteration 2030, Loss: 0.0014447156572714448\n",
      "Iteration 2040, Loss: 0.0014573035296052694\n",
      "Iteration 2050, Loss: 0.0014628844801336527\n",
      "Iteration 2060, Loss: 0.0013836538419127464\n",
      "Iteration 2070, Loss: 0.0013688209000974894\n",
      "Iteration 2080, Loss: 0.0014124722220003605\n",
      "Iteration 2090, Loss: 0.0015049050562083721\n",
      "Iteration 2100, Loss: 0.001339819049462676\n",
      "Iteration 2110, Loss: 0.0014565952587872744\n",
      "Iteration 2120, Loss: 0.0014232801040634513\n",
      "Iteration 2130, Loss: 0.0013179826783016324\n",
      "Iteration 2140, Loss: 0.0014031360624358058\n",
      "Iteration 2150, Loss: 0.0013545287074521184\n",
      "Iteration 2160, Loss: 0.0013549292925745249\n",
      "Iteration 2170, Loss: 0.0012922914465889335\n",
      "Iteration 2180, Loss: 0.0013471118872985244\n",
      "Iteration 2190, Loss: 0.0012456325348466635\n",
      "Iteration 2200, Loss: 0.0013655917719006538\n",
      "Iteration 2210, Loss: 0.0015297167701646686\n",
      "Iteration 2220, Loss: 0.0013304367894306779\n",
      "Iteration 2230, Loss: 0.0013075459282845259\n",
      "Iteration 2240, Loss: 0.0013296654215082526\n",
      "Iteration 2250, Loss: 0.0013610041933134198\n",
      "Iteration 2260, Loss: 0.001360325957648456\n",
      "Iteration 2270, Loss: 0.0012351616751402617\n",
      "Iteration 2280, Loss: 0.0011488435557112098\n",
      "Iteration 2290, Loss: 0.0012892093509435654\n",
      "Iteration 2300, Loss: 0.0012241459917277098\n",
      "Iteration 2310, Loss: 0.0013437080197036266\n",
      "Iteration 2320, Loss: 0.0013939749915152788\n",
      "Iteration 2330, Loss: 0.0012633829610422254\n",
      "Iteration 2340, Loss: 0.001320243114605546\n",
      "Iteration 2350, Loss: 0.0013955434551462531\n",
      "Iteration 2360, Loss: 0.0012879703426733613\n",
      "Iteration 2370, Loss: 0.0012310564052313566\n",
      "Iteration 2380, Loss: 0.0013317400589585304\n",
      "Iteration 2390, Loss: 0.001243449980393052\n",
      "Iteration 2400, Loss: 0.0011738961329683661\n",
      "Iteration 2410, Loss: 0.0012261585798114538\n",
      "Iteration 2420, Loss: 0.0013041433412581682\n",
      "Iteration 2430, Loss: 0.0011943666031584144\n",
      "Iteration 2440, Loss: 0.0012238469207659364\n",
      "Iteration 2450, Loss: 0.001179901068098843\n",
      "Iteration 2460, Loss: 0.0012228257255628705\n",
      "Iteration 2470, Loss: 0.0011408001882955432\n",
      "Iteration 2480, Loss: 0.0012176526943221688\n",
      "Iteration 2490, Loss: 0.0011819793144240975\n",
      "Iteration 2500, Loss: 0.0013129990547895432\n",
      "Iteration 2510, Loss: 0.0012876708060503006\n",
      "Iteration 2520, Loss: 0.0012442541774362326\n",
      "Iteration 2530, Loss: 0.0012348010204732418\n",
      "Iteration 2540, Loss: 0.0011293812422081828\n",
      "Iteration 2550, Loss: 0.0011420806404203176\n",
      "Iteration 2560, Loss: 0.0011234122794121504\n",
      "Iteration 2570, Loss: 0.0012308578006923199\n",
      "Iteration 2580, Loss: 0.001049263752065599\n",
      "Iteration 2590, Loss: 0.0012806945014744997\n",
      "Iteration 2600, Loss: 0.0012228891719132662\n",
      "Iteration 2610, Loss: 0.0011809103889390826\n",
      "Iteration 2620, Loss: 0.0011863555992022157\n",
      "Iteration 2630, Loss: 0.0011919604148715734\n",
      "Iteration 2640, Loss: 0.0012144636129960418\n",
      "Iteration 2650, Loss: 0.0010530856670811772\n",
      "Iteration 2660, Loss: 0.0011625700863078237\n",
      "Iteration 2670, Loss: 0.0011544162407517433\n",
      "Iteration 2680, Loss: 0.0010770922526717186\n",
      "Iteration 2690, Loss: 0.0010931548895314336\n",
      "Iteration 2700, Loss: 0.0011685923673212528\n",
      "Iteration 2710, Loss: 0.0010337322019040585\n",
      "Iteration 2720, Loss: 0.0012452206574380398\n",
      "Iteration 2730, Loss: 0.0011318012839183211\n",
      "Iteration 2740, Loss: 0.0012892992235720158\n",
      "Iteration 2750, Loss: 0.0011529343901202083\n",
      "Iteration 2760, Loss: 0.0010297688422724605\n",
      "Iteration 2770, Loss: 0.0011612591333687305\n",
      "Iteration 2780, Loss: 0.00108348298817873\n",
      "Iteration 2790, Loss: 0.0010288400808349252\n",
      "Iteration 2800, Loss: 0.00105616869404912\n",
      "Iteration 2810, Loss: 0.0010873728897422552\n",
      "Iteration 2820, Loss: 0.001022070413455367\n",
      "Iteration 2830, Loss: 0.001149020972661674\n",
      "Iteration 2840, Loss: 0.001181627158075571\n",
      "Iteration 2850, Loss: 0.0011377717601135373\n",
      "Iteration 2860, Loss: 0.0010654182406142354\n",
      "Iteration 2870, Loss: 0.001012221910059452\n",
      "Iteration 2880, Loss: 0.0012405059533193707\n",
      "Iteration 2890, Loss: 0.0010294386884197593\n",
      "Iteration 2900, Loss: 0.0010327905183658004\n",
      "Iteration 2910, Loss: 0.0010031467536464334\n",
      "Iteration 2920, Loss: 0.001104889321140945\n",
      "Iteration 2930, Loss: 0.0010603287955746055\n",
      "Iteration 2940, Loss: 0.0009433844825252891\n",
      "Iteration 2950, Loss: 0.0011113565415143967\n",
      "Iteration 2960, Loss: 0.001049934420734644\n",
      "Iteration 2970, Loss: 0.0010013529099524021\n",
      "Iteration 2980, Loss: 0.0010096515761688352\n",
      "Iteration 2990, Loss: 0.0011470408644527197\n",
      "Iteration 3000, Loss: 0.0010938711930066347\n",
      "Iteration 3010, Loss: 0.0009871246293187141\n",
      "Iteration 3020, Loss: 0.001126553164795041\n",
      "Iteration 3030, Loss: 0.0010905625531449914\n",
      "Iteration 3040, Loss: 0.0009690108709037304\n",
      "Iteration 3050, Loss: 0.0009198257466778159\n",
      "Iteration 3060, Loss: 0.000990970991551876\n",
      "Iteration 3070, Loss: 0.0010304901516065001\n",
      "Iteration 3080, Loss: 0.0009598214528523386\n",
      "Iteration 3090, Loss: 0.0009009767090901732\n",
      "Iteration 3100, Loss: 0.0009761739638634026\n",
      "Iteration 3110, Loss: 0.0009573161951266229\n",
      "Iteration 3120, Loss: 0.0009668631246313453\n",
      "Iteration 3130, Loss: 0.0008977587567642331\n",
      "Iteration 3140, Loss: 0.000968779728282243\n",
      "Iteration 3150, Loss: 0.0010019858600571752\n",
      "Iteration 3160, Loss: 0.0009337522787973285\n",
      "Iteration 3170, Loss: 0.0008667558431625366\n",
      "Iteration 3180, Loss: 0.0008994520758278668\n",
      "Iteration 3190, Loss: 0.0010088114067912102\n",
      "Iteration 3200, Loss: 0.0008816785993985832\n",
      "Iteration 3210, Loss: 0.0009813157375901937\n",
      "Iteration 3220, Loss: 0.0008474828209728003\n",
      "Iteration 3230, Loss: 0.0009152918355539441\n",
      "Iteration 3240, Loss: 0.0008810515864752233\n",
      "Iteration 3250, Loss: 0.0008750565466471016\n",
      "Iteration 3260, Loss: 0.000793825660366565\n",
      "Iteration 3270, Loss: 0.0008893974008969963\n",
      "Iteration 3280, Loss: 0.0007962424424476922\n",
      "Iteration 3290, Loss: 0.0009056917624548078\n",
      "Iteration 3300, Loss: 0.0009604315273463726\n",
      "Iteration 3310, Loss: 0.0008958136895671487\n",
      "Iteration 3320, Loss: 0.0009506620117463171\n",
      "Iteration 3330, Loss: 0.0009111560648307204\n",
      "Iteration 3340, Loss: 0.0008530676714144647\n",
      "Iteration 3350, Loss: 0.0007696442771703005\n",
      "Iteration 3360, Loss: 0.0008382387459278107\n",
      "Iteration 3370, Loss: 0.0009350154432468116\n",
      "Iteration 3380, Loss: 0.0009179458720609546\n",
      "Iteration 3390, Loss: 0.0008443727274425328\n",
      "Iteration 3400, Loss: 0.0008926513837650418\n",
      "Iteration 3410, Loss: 0.0008778655319474638\n",
      "Iteration 3420, Loss: 0.0008448689477518201\n",
      "Iteration 3430, Loss: 0.0008598603308200836\n",
      "Iteration 3440, Loss: 0.0008385317050851882\n",
      "Iteration 3450, Loss: 0.0008504085708409548\n",
      "Iteration 3460, Loss: 0.0007689666235819459\n",
      "Iteration 3470, Loss: 0.000760686700232327\n",
      "Iteration 3480, Loss: 0.0008267736993730068\n",
      "Iteration 3490, Loss: 0.0008568632183596492\n",
      "Iteration 3500, Loss: 0.0008078620303422213\n",
      "Iteration 3510, Loss: 0.0008850102312862873\n",
      "Iteration 3520, Loss: 0.0007049493724480271\n",
      "Iteration 3530, Loss: 0.0008324639638885856\n",
      "Iteration 3540, Loss: 0.000787719152867794\n",
      "Iteration 3550, Loss: 0.0008768298430368304\n",
      "Iteration 3560, Loss: 0.0007893774891272187\n",
      "Iteration 3570, Loss: 0.0007887450628913939\n",
      "Iteration 3580, Loss: 0.000709390442352742\n",
      "Iteration 3590, Loss: 0.0007794629200361669\n",
      "Iteration 3600, Loss: 0.0007768892683088779\n",
      "Iteration 3610, Loss: 0.000814019818790257\n",
      "Iteration 3620, Loss: 0.0008075062069110572\n",
      "Iteration 3630, Loss: 0.0007761450833640993\n",
      "Iteration 3640, Loss: 0.0008137782569974661\n",
      "Iteration 3650, Loss: 0.0008182407473213971\n",
      "Iteration 3660, Loss: 0.0008595767430961132\n",
      "Iteration 3670, Loss: 0.0006367345340549946\n",
      "Iteration 3680, Loss: 0.0007855320000089705\n",
      "Iteration 3690, Loss: 0.0007683297735638916\n",
      "Iteration 3700, Loss: 0.000749764556530863\n",
      "Iteration 3710, Loss: 0.0007769957301206887\n",
      "Iteration 3720, Loss: 0.0007092829328030348\n",
      "Iteration 3730, Loss: 0.0008162963204085827\n",
      "Iteration 3740, Loss: 0.0007151902536861598\n",
      "Iteration 3750, Loss: 0.0007341933087445796\n",
      "Iteration 3760, Loss: 0.0007653514039702713\n",
      "Iteration 3770, Loss: 0.000728884304407984\n",
      "Iteration 3780, Loss: 0.0006890008226037025\n",
      "Iteration 3790, Loss: 0.0006497942958958447\n",
      "Iteration 3800, Loss: 0.0006795335793867707\n",
      "Iteration 3810, Loss: 0.0006882160669192672\n",
      "Iteration 3820, Loss: 0.0006965764914639294\n",
      "Iteration 3830, Loss: 0.0007123177638277411\n",
      "Iteration 3840, Loss: 0.0007253672229126096\n",
      "Iteration 3850, Loss: 0.0006557109882123768\n",
      "Iteration 3860, Loss: 0.000618112098891288\n",
      "Iteration 3870, Loss: 0.0006895430851727724\n",
      "Iteration 3880, Loss: 0.0006759356474503875\n",
      "Iteration 3890, Loss: 0.0006925983470864594\n",
      "Iteration 3900, Loss: 0.0006658936617895961\n",
      "Iteration 3910, Loss: 0.0007005440420471132\n",
      "Iteration 3920, Loss: 0.0005831359885632992\n",
      "Iteration 3930, Loss: 0.000647244683932513\n",
      "Iteration 3940, Loss: 0.0005980022251605988\n",
      "Iteration 3950, Loss: 0.0006900027510710061\n",
      "Iteration 3960, Loss: 0.0006856965483166277\n",
      "Iteration 3970, Loss: 0.0006616480532102287\n",
      "Iteration 3980, Loss: 0.0006647175177931786\n",
      "Iteration 3990, Loss: 0.0006105635548010468\n",
      "Iteration 4000, Loss: 0.0006251242593862116\n",
      "Iteration 4010, Loss: 0.0006296639912761748\n",
      "Iteration 4020, Loss: 0.0006931236712262034\n",
      "Iteration 4030, Loss: 0.000623989209998399\n",
      "Iteration 4040, Loss: 0.0006751366308890283\n",
      "Iteration 4050, Loss: 0.0006090890965424478\n",
      "Iteration 4060, Loss: 0.0006026161136105657\n",
      "Iteration 4070, Loss: 0.0005918865790590644\n",
      "Iteration 4080, Loss: 0.0005998443812131882\n",
      "Iteration 4090, Loss: 0.0006202792865224183\n",
      "Iteration 4100, Loss: 0.000615652825217694\n",
      "Iteration 4110, Loss: 0.0006137452437542379\n",
      "Iteration 4120, Loss: 0.0006248686113394797\n",
      "Iteration 4130, Loss: 0.0006074776756577194\n",
      "Iteration 4140, Loss: 0.0006892390083521605\n",
      "Iteration 4150, Loss: 0.0007066171965561807\n",
      "Iteration 4160, Loss: 0.0005910053150728345\n",
      "Iteration 4170, Loss: 0.0005949795013293624\n",
      "Iteration 4180, Loss: 0.0005815629265271127\n",
      "Iteration 4190, Loss: 0.0005834810435771942\n",
      "Iteration 4200, Loss: 0.0005740353954024613\n",
      "Iteration 4210, Loss: 0.000627133238594979\n",
      "Iteration 4220, Loss: 0.0006364908767864108\n",
      "Iteration 4230, Loss: 0.0005502082058228552\n",
      "Iteration 4240, Loss: 0.0005719203618355095\n",
      "Iteration 4250, Loss: 0.000519047724083066\n",
      "Iteration 4260, Loss: 0.0005492907366715372\n",
      "Iteration 4270, Loss: 0.0005350401625037193\n",
      "Iteration 4280, Loss: 0.0005386212142184377\n",
      "Iteration 4290, Loss: 0.0005817257915623486\n",
      "Iteration 4300, Loss: 0.0005803389358334243\n",
      "Iteration 4310, Loss: 0.0005170676158741117\n",
      "Iteration 4320, Loss: 0.0005812516319565475\n",
      "Iteration 4330, Loss: 0.0005362026276998222\n",
      "Iteration 4340, Loss: 0.0005286987288855016\n",
      "Iteration 4350, Loss: 0.0005971465725451708\n",
      "Iteration 4360, Loss: 0.0005671260878443718\n",
      "Iteration 4370, Loss: 0.0005456567159853876\n",
      "Iteration 4380, Loss: 0.0005414115148596466\n",
      "Iteration 4390, Loss: 0.0005137479747645557\n",
      "Iteration 4400, Loss: 0.0005194564000703394\n",
      "Iteration 4410, Loss: 0.0005849680746905506\n",
      "Iteration 4420, Loss: 0.0004707648477051407\n",
      "Iteration 4430, Loss: 0.0005138411652296782\n",
      "Iteration 4440, Loss: 0.00048774777678772807\n",
      "Iteration 4450, Loss: 0.0005224730703048408\n",
      "Iteration 4460, Loss: 0.0005396935157477856\n",
      "Iteration 4470, Loss: 0.0005066730664111674\n",
      "Iteration 4480, Loss: 0.0005583596066571772\n",
      "Iteration 4490, Loss: 0.0004918033955618739\n",
      "Iteration 4500, Loss: 0.0004913277225568891\n",
      "Iteration 4510, Loss: 0.0005287544918246567\n",
      "Iteration 4520, Loss: 0.0004985306295566261\n",
      "Iteration 4530, Loss: 0.00048148538917303085\n",
      "Iteration 4540, Loss: 0.0005547598702833056\n",
      "Iteration 4550, Loss: 0.00045771367149427533\n",
      "Iteration 4560, Loss: 0.000466796918772161\n",
      "Iteration 4570, Loss: 0.0005370569415390491\n",
      "Iteration 4580, Loss: 0.0004681014397647232\n",
      "Iteration 4590, Loss: 0.0005304142250679433\n",
      "Iteration 4600, Loss: 0.00044497536146081984\n",
      "Iteration 4610, Loss: 0.0005063498974777758\n",
      "Iteration 4620, Loss: 0.0004771451058331877\n",
      "Iteration 4630, Loss: 0.000503059069160372\n",
      "Iteration 4640, Loss: 0.00045069537009112537\n",
      "Iteration 4650, Loss: 0.0004775064007844776\n",
      "Iteration 4660, Loss: 0.00044755099224857986\n",
      "Iteration 4670, Loss: 0.000452975305961445\n",
      "Iteration 4680, Loss: 0.0005308801773935556\n",
      "Iteration 4690, Loss: 0.00041448173578828573\n",
      "Iteration 4700, Loss: 0.0004864509974140674\n",
      "Iteration 4710, Loss: 0.00046138736070133746\n",
      "Iteration 4720, Loss: 0.00045806929119862616\n",
      "Iteration 4730, Loss: 0.00046534609282389283\n",
      "Iteration 4740, Loss: 0.0005032324115745723\n",
      "Iteration 4750, Loss: 0.00041727814823389053\n",
      "Iteration 4760, Loss: 0.00043674325570464134\n",
      "Iteration 4770, Loss: 0.00048490948393009603\n",
      "Iteration 4780, Loss: 0.0004698263364844024\n",
      "Iteration 4790, Loss: 0.00046753164497204125\n",
      "Iteration 4800, Loss: 0.00043025289778597653\n",
      "Iteration 4810, Loss: 0.00043213850585743785\n",
      "Iteration 4820, Loss: 0.00044429933768697083\n",
      "Iteration 4830, Loss: 0.0004271992656867951\n",
      "Iteration 4840, Loss: 0.00040987267857417464\n",
      "Iteration 4850, Loss: 0.0004222302231937647\n",
      "Iteration 4860, Loss: 0.00041806508670561016\n",
      "Iteration 4870, Loss: 0.000438576505985111\n",
      "Iteration 4880, Loss: 0.00039260703488253057\n",
      "Iteration 4890, Loss: 0.00042512593790888786\n",
      "Iteration 4900, Loss: 0.0004485865356400609\n",
      "Iteration 4910, Loss: 0.0004610269679687917\n",
      "Iteration 4920, Loss: 0.00045155640691518784\n",
      "Iteration 4930, Loss: 0.0004073526943102479\n",
      "Iteration 4940, Loss: 0.00043660993105731905\n",
      "Iteration 4950, Loss: 0.0003896585258189589\n",
      "Iteration 4960, Loss: 0.00037675388739444315\n",
      "Iteration 4970, Loss: 0.00040658365469425917\n",
      "Iteration 4980, Loss: 0.00040289488970302045\n",
      "Iteration 4990, Loss: 0.00039096592809073627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  58%|█████▊    | 14/24 [10:09<08:32, 51.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.02897928455477713, 'L2_avg': 0.0368531819512499, 'End_point_L1_avg': 0.00856172622164429, 'End_point_L2_avg': 0.01067250651165746}\n",
      "Iteration 0, Loss: 1.7842302322387695\n",
      "Iteration 10, Loss: 0.9583548307418823\n",
      "Iteration 20, Loss: 0.7878099679946899\n",
      "Iteration 30, Loss: 0.6319335103034973\n",
      "Iteration 40, Loss: 0.4975806176662445\n",
      "Iteration 50, Loss: 0.3965545892715454\n",
      "Iteration 60, Loss: 0.3110377788543701\n",
      "Iteration 70, Loss: 0.2480253279209137\n",
      "Iteration 80, Loss: 0.19471243023872375\n",
      "Iteration 90, Loss: 0.15152283012866974\n",
      "Iteration 100, Loss: 0.12484714388847351\n",
      "Iteration 110, Loss: 0.1013702005147934\n",
      "Iteration 120, Loss: 0.08798873424530029\n",
      "Iteration 130, Loss: 0.07628700137138367\n",
      "Iteration 140, Loss: 0.061756111681461334\n",
      "Iteration 150, Loss: 0.060111626982688904\n",
      "Iteration 160, Loss: 0.053535811603069305\n",
      "Iteration 170, Loss: 0.05421584099531174\n",
      "Iteration 180, Loss: 0.0514245331287384\n",
      "Iteration 190, Loss: 0.04540169984102249\n",
      "Iteration 200, Loss: 0.04908967390656471\n",
      "Iteration 210, Loss: 0.03877705708146095\n",
      "Iteration 220, Loss: 0.03571886196732521\n",
      "Iteration 230, Loss: 0.03660132363438606\n",
      "Iteration 240, Loss: 0.03430680185556412\n",
      "Iteration 250, Loss: 0.03317048028111458\n",
      "Iteration 260, Loss: 0.031118256971240044\n",
      "Iteration 270, Loss: 0.03365606814622879\n",
      "Iteration 280, Loss: 0.029293088242411613\n",
      "Iteration 290, Loss: 0.02928033284842968\n",
      "Iteration 300, Loss: 0.02958977222442627\n",
      "Iteration 310, Loss: 0.025080997496843338\n",
      "Iteration 320, Loss: 0.02643582969903946\n",
      "Iteration 330, Loss: 0.024133261293172836\n",
      "Iteration 340, Loss: 0.021331505849957466\n",
      "Iteration 350, Loss: 0.024536218494176865\n",
      "Iteration 360, Loss: 0.023078206926584244\n",
      "Iteration 370, Loss: 0.020682215690612793\n",
      "Iteration 380, Loss: 0.019748028367757797\n",
      "Iteration 390, Loss: 0.01895241066813469\n",
      "Iteration 400, Loss: 0.019890442490577698\n",
      "Iteration 410, Loss: 0.017748184502124786\n",
      "Iteration 420, Loss: 0.01924363151192665\n",
      "Iteration 430, Loss: 0.01805199682712555\n",
      "Iteration 440, Loss: 0.017242765054106712\n",
      "Iteration 450, Loss: 0.01686980575323105\n",
      "Iteration 460, Loss: 0.014874656684696674\n",
      "Iteration 470, Loss: 0.015267019160091877\n",
      "Iteration 480, Loss: 0.015497487038373947\n",
      "Iteration 490, Loss: 0.013892531394958496\n",
      "Iteration 500, Loss: 0.013102111406624317\n",
      "Iteration 510, Loss: 0.013549791648983955\n",
      "Iteration 520, Loss: 0.012690777890384197\n",
      "Iteration 530, Loss: 0.013214855454862118\n",
      "Iteration 540, Loss: 0.012461347505450249\n",
      "Iteration 550, Loss: 0.012844890356063843\n",
      "Iteration 560, Loss: 0.012463460676372051\n",
      "Iteration 570, Loss: 0.012268362566828728\n",
      "Iteration 580, Loss: 0.012132931500673294\n",
      "Iteration 590, Loss: 0.011470349505543709\n",
      "Iteration 600, Loss: 0.011533010751008987\n",
      "Iteration 610, Loss: 0.010080061852931976\n",
      "Iteration 620, Loss: 0.0100710429251194\n",
      "Iteration 630, Loss: 0.010092698037624359\n",
      "Iteration 640, Loss: 0.009508508257567883\n",
      "Iteration 650, Loss: 0.009565265849232674\n",
      "Iteration 660, Loss: 0.008979002013802528\n",
      "Iteration 670, Loss: 0.009168142452836037\n",
      "Iteration 680, Loss: 0.008603105321526527\n",
      "Iteration 690, Loss: 0.009289488196372986\n",
      "Iteration 700, Loss: 0.008746503852307796\n",
      "Iteration 710, Loss: 0.008752090856432915\n",
      "Iteration 720, Loss: 0.007267828099429607\n",
      "Iteration 730, Loss: 0.007191558834165335\n",
      "Iteration 740, Loss: 0.007677304092794657\n",
      "Iteration 750, Loss: 0.007726515177637339\n",
      "Iteration 760, Loss: 0.007408600300550461\n",
      "Iteration 770, Loss: 0.006803909316658974\n",
      "Iteration 780, Loss: 0.007533031981438398\n",
      "Iteration 790, Loss: 0.00697664450854063\n",
      "Iteration 800, Loss: 0.006882417015731335\n",
      "Iteration 810, Loss: 0.00650368258357048\n",
      "Iteration 820, Loss: 0.006455983966588974\n",
      "Iteration 830, Loss: 0.006215529982000589\n",
      "Iteration 840, Loss: 0.005903911776840687\n",
      "Iteration 850, Loss: 0.006296131759881973\n",
      "Iteration 860, Loss: 0.007098943926393986\n",
      "Iteration 870, Loss: 0.005948266014456749\n",
      "Iteration 880, Loss: 0.005687565077096224\n",
      "Iteration 890, Loss: 0.005894337315112352\n",
      "Iteration 900, Loss: 0.005725836381316185\n",
      "Iteration 910, Loss: 0.005564464721828699\n",
      "Iteration 920, Loss: 0.005411163438111544\n",
      "Iteration 930, Loss: 0.0053445762023329735\n",
      "Iteration 940, Loss: 0.00507174851372838\n",
      "Iteration 950, Loss: 0.0052330647595226765\n",
      "Iteration 960, Loss: 0.005934910383075476\n",
      "Iteration 970, Loss: 0.004833991173654795\n",
      "Iteration 980, Loss: 0.0051653021946549416\n",
      "Iteration 990, Loss: 0.004971522372215986\n",
      "Iteration 1000, Loss: 0.004881992004811764\n",
      "Iteration 1010, Loss: 0.005219873506575823\n",
      "Iteration 1020, Loss: 0.004607141483575106\n",
      "Iteration 1030, Loss: 0.004688103683292866\n",
      "Iteration 1040, Loss: 0.004579978995025158\n",
      "Iteration 1050, Loss: 0.004535366781055927\n",
      "Iteration 1060, Loss: 0.004450441803783178\n",
      "Iteration 1070, Loss: 0.004543978720903397\n",
      "Iteration 1080, Loss: 0.004142369143664837\n",
      "Iteration 1090, Loss: 0.004410929512232542\n",
      "Iteration 1100, Loss: 0.003948122728615999\n",
      "Iteration 1110, Loss: 0.00426818011328578\n",
      "Iteration 1120, Loss: 0.004134343005716801\n",
      "Iteration 1130, Loss: 0.004133356735110283\n",
      "Iteration 1140, Loss: 0.004258159082382917\n",
      "Iteration 1150, Loss: 0.004008361604064703\n",
      "Iteration 1160, Loss: 0.003615670371800661\n",
      "Iteration 1170, Loss: 0.0038910016883164644\n",
      "Iteration 1180, Loss: 0.003836736548691988\n",
      "Iteration 1190, Loss: 0.0037772415671497583\n",
      "Iteration 1200, Loss: 0.003855066141113639\n",
      "Iteration 1210, Loss: 0.0036915657110512257\n",
      "Iteration 1220, Loss: 0.0034908761736005545\n",
      "Iteration 1230, Loss: 0.0036646868102252483\n",
      "Iteration 1240, Loss: 0.003811591537669301\n",
      "Iteration 1250, Loss: 0.003629289334639907\n",
      "Iteration 1260, Loss: 0.003630079096183181\n",
      "Iteration 1270, Loss: 0.0036132200621068478\n",
      "Iteration 1280, Loss: 0.003490947652608156\n",
      "Iteration 1290, Loss: 0.003291851142421365\n",
      "Iteration 1300, Loss: 0.0033387376461178064\n",
      "Iteration 1310, Loss: 0.0034122238866984844\n",
      "Iteration 1320, Loss: 0.003592253429815173\n",
      "Iteration 1330, Loss: 0.0035210628993809223\n",
      "Iteration 1340, Loss: 0.003352685598656535\n",
      "Iteration 1350, Loss: 0.0032224729657173157\n",
      "Iteration 1360, Loss: 0.0031938054598867893\n",
      "Iteration 1370, Loss: 0.0031704744324088097\n",
      "Iteration 1380, Loss: 0.003306531347334385\n",
      "Iteration 1390, Loss: 0.003240886377170682\n",
      "Iteration 1400, Loss: 0.003321590833365917\n",
      "Iteration 1410, Loss: 0.0031773936934769154\n",
      "Iteration 1420, Loss: 0.003267668653279543\n",
      "Iteration 1430, Loss: 0.003061385126784444\n",
      "Iteration 1440, Loss: 0.0032387454994022846\n",
      "Iteration 1450, Loss: 0.0031691468320786953\n",
      "Iteration 1460, Loss: 0.0031003509648144245\n",
      "Iteration 1470, Loss: 0.0030178925953805447\n",
      "Iteration 1480, Loss: 0.003083463292568922\n",
      "Iteration 1490, Loss: 0.0029310884419828653\n",
      "Iteration 1500, Loss: 0.0030788348522037268\n",
      "Iteration 1510, Loss: 0.0027790169697254896\n",
      "Iteration 1520, Loss: 0.0030373134650290012\n",
      "Iteration 1530, Loss: 0.0030897881370037794\n",
      "Iteration 1540, Loss: 0.0028141627553850412\n",
      "Iteration 1550, Loss: 0.00276538310572505\n",
      "Iteration 1560, Loss: 0.0028508584946393967\n",
      "Iteration 1570, Loss: 0.0028228878509253263\n",
      "Iteration 1580, Loss: 0.0028363633900880814\n",
      "Iteration 1590, Loss: 0.0028826447669416666\n",
      "Iteration 1600, Loss: 0.0027134804986417294\n",
      "Iteration 1610, Loss: 0.002836901228874922\n",
      "Iteration 1620, Loss: 0.0027080532163381577\n",
      "Iteration 1630, Loss: 0.00270395097322762\n",
      "Iteration 1640, Loss: 0.002652751514688134\n",
      "Iteration 1650, Loss: 0.0027812113985419273\n",
      "Iteration 1660, Loss: 0.0027364646084606647\n",
      "Iteration 1670, Loss: 0.0026855955366045237\n",
      "Iteration 1680, Loss: 0.002763347467407584\n",
      "Iteration 1690, Loss: 0.002544916234910488\n",
      "Iteration 1700, Loss: 0.0027599113527685404\n",
      "Iteration 1710, Loss: 0.002642687177285552\n",
      "Iteration 1720, Loss: 0.0026195314712822437\n",
      "Iteration 1730, Loss: 0.0026859829667955637\n",
      "Iteration 1740, Loss: 0.0027533788233995438\n",
      "Iteration 1750, Loss: 0.0026552763301879168\n",
      "Iteration 1760, Loss: 0.00258458498865366\n",
      "Iteration 1770, Loss: 0.0025528736878186464\n",
      "Iteration 1780, Loss: 0.002536820713430643\n",
      "Iteration 1790, Loss: 0.00248522637411952\n",
      "Iteration 1800, Loss: 0.00269039673730731\n",
      "Iteration 1810, Loss: 0.0025506759993731976\n",
      "Iteration 1820, Loss: 0.0024413198698312044\n",
      "Iteration 1830, Loss: 0.0023413794115185738\n",
      "Iteration 1840, Loss: 0.0024704814422875643\n",
      "Iteration 1850, Loss: 0.0024210945703089237\n",
      "Iteration 1860, Loss: 0.002438867464661598\n",
      "Iteration 1870, Loss: 0.0024705894757062197\n",
      "Iteration 1880, Loss: 0.0024682844523340464\n",
      "Iteration 1890, Loss: 0.002523822709918022\n",
      "Iteration 1900, Loss: 0.0023772965651005507\n",
      "Iteration 1910, Loss: 0.0023190428037196398\n",
      "Iteration 1920, Loss: 0.002360985614359379\n",
      "Iteration 1930, Loss: 0.0021662565413862467\n",
      "Iteration 1940, Loss: 0.002235350664705038\n",
      "Iteration 1950, Loss: 0.0022747660987079144\n",
      "Iteration 1960, Loss: 0.002185309072956443\n",
      "Iteration 1970, Loss: 0.002239143941551447\n",
      "Iteration 1980, Loss: 0.0023814847227185965\n",
      "Iteration 1990, Loss: 0.0022219843231141567\n",
      "Iteration 2000, Loss: 0.002167211612686515\n",
      "Iteration 2010, Loss: 0.0022994736209511757\n",
      "Iteration 2020, Loss: 0.002233097329735756\n",
      "Iteration 2030, Loss: 0.0022039469331502914\n",
      "Iteration 2040, Loss: 0.0022046901285648346\n",
      "Iteration 2050, Loss: 0.0022114450111985207\n",
      "Iteration 2060, Loss: 0.0020758642349392176\n",
      "Iteration 2070, Loss: 0.002206929726526141\n",
      "Iteration 2080, Loss: 0.0021756840869784355\n",
      "Iteration 2090, Loss: 0.002214792650192976\n",
      "Iteration 2100, Loss: 0.002185497200116515\n",
      "Iteration 2110, Loss: 0.0022097183391451836\n",
      "Iteration 2120, Loss: 0.0021241335198283195\n",
      "Iteration 2130, Loss: 0.0021711287554353476\n",
      "Iteration 2140, Loss: 0.002095660660415888\n",
      "Iteration 2150, Loss: 0.0021805071737617254\n",
      "Iteration 2160, Loss: 0.002177647314965725\n",
      "Iteration 2170, Loss: 0.002206098288297653\n",
      "Iteration 2180, Loss: 0.0020945630967617035\n",
      "Iteration 2190, Loss: 0.0021625161170959473\n",
      "Iteration 2200, Loss: 0.0021844657603651285\n",
      "Iteration 2210, Loss: 0.0019788588397204876\n",
      "Iteration 2220, Loss: 0.0019580209627747536\n",
      "Iteration 2230, Loss: 0.002080559730529785\n",
      "Iteration 2240, Loss: 0.002037235302850604\n",
      "Iteration 2250, Loss: 0.0019509533885866404\n",
      "Iteration 2260, Loss: 0.0019733060616999865\n",
      "Iteration 2270, Loss: 0.0020367600955069065\n",
      "Iteration 2280, Loss: 0.001981389708817005\n",
      "Iteration 2290, Loss: 0.001980389002710581\n",
      "Iteration 2300, Loss: 0.001997553976252675\n",
      "Iteration 2310, Loss: 0.0019528631819412112\n",
      "Iteration 2320, Loss: 0.0019413159461691976\n",
      "Iteration 2330, Loss: 0.0019746446050703526\n",
      "Iteration 2340, Loss: 0.0018960234010592103\n",
      "Iteration 2350, Loss: 0.0020268040243536234\n",
      "Iteration 2360, Loss: 0.0019055248703807592\n",
      "Iteration 2370, Loss: 0.0019231068436056376\n",
      "Iteration 2380, Loss: 0.0019169559236615896\n",
      "Iteration 2390, Loss: 0.0018429113551974297\n",
      "Iteration 2400, Loss: 0.001924585667438805\n",
      "Iteration 2410, Loss: 0.0018454354722052813\n",
      "Iteration 2420, Loss: 0.0018991278484463692\n",
      "Iteration 2430, Loss: 0.0018843839643523097\n",
      "Iteration 2440, Loss: 0.0019097243202850223\n",
      "Iteration 2450, Loss: 0.0019076521275565028\n",
      "Iteration 2460, Loss: 0.0018755559576675296\n",
      "Iteration 2470, Loss: 0.0017744714859873056\n",
      "Iteration 2480, Loss: 0.0017633734969422221\n",
      "Iteration 2490, Loss: 0.001868927269242704\n",
      "Iteration 2500, Loss: 0.0019033238058909774\n",
      "Iteration 2510, Loss: 0.0017986290622502565\n",
      "Iteration 2520, Loss: 0.0017633381066843867\n",
      "Iteration 2530, Loss: 0.0018304241821169853\n",
      "Iteration 2540, Loss: 0.0017803418450057507\n",
      "Iteration 2550, Loss: 0.0017908673034980893\n",
      "Iteration 2560, Loss: 0.001706236507743597\n",
      "Iteration 2570, Loss: 0.001822453923523426\n",
      "Iteration 2580, Loss: 0.0018392183119431138\n",
      "Iteration 2590, Loss: 0.0017236609710380435\n",
      "Iteration 2600, Loss: 0.0016572714084759355\n",
      "Iteration 2610, Loss: 0.0017071430338546634\n",
      "Iteration 2620, Loss: 0.0017053772462531924\n",
      "Iteration 2630, Loss: 0.0018124444177374244\n",
      "Iteration 2640, Loss: 0.0015922882594168186\n",
      "Iteration 2650, Loss: 0.001737707294523716\n",
      "Iteration 2660, Loss: 0.0017275083810091019\n",
      "Iteration 2670, Loss: 0.0017060087993741035\n",
      "Iteration 2680, Loss: 0.0016553967725485563\n",
      "Iteration 2690, Loss: 0.0015915654366835952\n",
      "Iteration 2700, Loss: 0.0015933493850752711\n",
      "Iteration 2710, Loss: 0.0016419609310105443\n",
      "Iteration 2720, Loss: 0.0017427586717531085\n",
      "Iteration 2730, Loss: 0.0016593474429100752\n",
      "Iteration 2740, Loss: 0.0016549652209505439\n",
      "Iteration 2750, Loss: 0.0016004877397790551\n",
      "Iteration 2760, Loss: 0.0016814280534163117\n",
      "Iteration 2770, Loss: 0.0016050559934228659\n",
      "Iteration 2780, Loss: 0.0016084893140941858\n",
      "Iteration 2790, Loss: 0.0015634073643013835\n",
      "Iteration 2800, Loss: 0.0015642590587958694\n",
      "Iteration 2810, Loss: 0.0015735271153971553\n",
      "Iteration 2820, Loss: 0.0016558128409087658\n",
      "Iteration 2830, Loss: 0.001527708605863154\n",
      "Iteration 2840, Loss: 0.0014805898535996675\n",
      "Iteration 2850, Loss: 0.0014789990382269025\n",
      "Iteration 2860, Loss: 0.001537349889986217\n",
      "Iteration 2870, Loss: 0.0015893602976575494\n",
      "Iteration 2880, Loss: 0.001495048520155251\n",
      "Iteration 2890, Loss: 0.0015066739870235324\n",
      "Iteration 2900, Loss: 0.0014973495854064822\n",
      "Iteration 2910, Loss: 0.001468965201638639\n",
      "Iteration 2920, Loss: 0.0014112042263150215\n",
      "Iteration 2930, Loss: 0.0014745690859854221\n",
      "Iteration 2940, Loss: 0.0015024264575913548\n",
      "Iteration 2950, Loss: 0.0014689944218844175\n",
      "Iteration 2960, Loss: 0.0014468863373622298\n",
      "Iteration 2970, Loss: 0.0014435710618272424\n",
      "Iteration 2980, Loss: 0.0013785635819658637\n",
      "Iteration 2990, Loss: 0.001471861032769084\n",
      "Iteration 3000, Loss: 0.0013790333177894354\n",
      "Iteration 3010, Loss: 0.0015057176351547241\n",
      "Iteration 3020, Loss: 0.0014045560965314507\n",
      "Iteration 3030, Loss: 0.0014250434469431639\n",
      "Iteration 3040, Loss: 0.0014664968475699425\n",
      "Iteration 3050, Loss: 0.00142201641574502\n",
      "Iteration 3060, Loss: 0.0013684763107448816\n",
      "Iteration 3070, Loss: 0.0013440140755847096\n",
      "Iteration 3080, Loss: 0.0013789645163342357\n",
      "Iteration 3090, Loss: 0.0013317962875589728\n",
      "Iteration 3100, Loss: 0.0013393391855061054\n",
      "Iteration 3110, Loss: 0.0013784491457045078\n",
      "Iteration 3120, Loss: 0.0013644888531416655\n",
      "Iteration 3130, Loss: 0.0013605005806311965\n",
      "Iteration 3140, Loss: 0.0013596751959994435\n",
      "Iteration 3150, Loss: 0.0013775803381577134\n",
      "Iteration 3160, Loss: 0.0012923991307616234\n",
      "Iteration 3170, Loss: 0.0013049455592408776\n",
      "Iteration 3180, Loss: 0.0013047736138105392\n",
      "Iteration 3190, Loss: 0.001341500086709857\n",
      "Iteration 3200, Loss: 0.0013060441706329584\n",
      "Iteration 3210, Loss: 0.0013114415341988206\n",
      "Iteration 3220, Loss: 0.0012834002263844013\n",
      "Iteration 3230, Loss: 0.0013153073377907276\n",
      "Iteration 3240, Loss: 0.0012300037778913975\n",
      "Iteration 3250, Loss: 0.0012727250577881932\n",
      "Iteration 3260, Loss: 0.0012962962500751019\n",
      "Iteration 3270, Loss: 0.001293759560212493\n",
      "Iteration 3280, Loss: 0.0013010345865041018\n",
      "Iteration 3290, Loss: 0.0012269680155441165\n",
      "Iteration 3300, Loss: 0.0012256067711859941\n",
      "Iteration 3310, Loss: 0.0012028638739138842\n",
      "Iteration 3320, Loss: 0.0012641935609281063\n",
      "Iteration 3330, Loss: 0.0011882178951054811\n",
      "Iteration 3340, Loss: 0.001227059168741107\n",
      "Iteration 3350, Loss: 0.0011949925683438778\n",
      "Iteration 3360, Loss: 0.0011688893428072333\n",
      "Iteration 3370, Loss: 0.0011113937944173813\n",
      "Iteration 3380, Loss: 0.001184858032502234\n",
      "Iteration 3390, Loss: 0.0011858879588544369\n",
      "Iteration 3400, Loss: 0.0011590671492740512\n",
      "Iteration 3410, Loss: 0.001196176279336214\n",
      "Iteration 3420, Loss: 0.0011774355079978704\n",
      "Iteration 3430, Loss: 0.0011448374716565013\n",
      "Iteration 3440, Loss: 0.0012092404067516327\n",
      "Iteration 3450, Loss: 0.0011750595876947045\n",
      "Iteration 3460, Loss: 0.0011696849251165986\n",
      "Iteration 3470, Loss: 0.0011174014071002603\n",
      "Iteration 3480, Loss: 0.0011935816146433353\n",
      "Iteration 3490, Loss: 0.0011874957708641887\n",
      "Iteration 3500, Loss: 0.0011687000514939427\n",
      "Iteration 3510, Loss: 0.0011618523858487606\n",
      "Iteration 3520, Loss: 0.0011002450482919812\n",
      "Iteration 3530, Loss: 0.0011218348518013954\n",
      "Iteration 3540, Loss: 0.0011404220713302493\n",
      "Iteration 3550, Loss: 0.0010685002198442817\n",
      "Iteration 3560, Loss: 0.0011194497346878052\n",
      "Iteration 3570, Loss: 0.0010677976533770561\n",
      "Iteration 3580, Loss: 0.0010905456729233265\n",
      "Iteration 3590, Loss: 0.001001435797661543\n",
      "Iteration 3600, Loss: 0.0011058395029976964\n",
      "Iteration 3610, Loss: 0.0010732286609709263\n",
      "Iteration 3620, Loss: 0.0010648589814081788\n",
      "Iteration 3630, Loss: 0.0010499574709683657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  62%|██████▎   | 15/24 [11:08<08:00, 53.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3640, Loss: 0.001040500937961042\n",
      "Stopping early at iteration 3646\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 3647, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04616632847979525, 'L2_avg': 0.05897468331470282, 'End_point_L1_avg': 0.028059158423560472, 'End_point_L2_avg': 0.028935594255683095}\n",
      "Iteration 0, Loss: 1.1241490840911865\n",
      "Iteration 10, Loss: 0.811556339263916\n",
      "Iteration 20, Loss: 0.5800798535346985\n",
      "Iteration 30, Loss: 0.4155014753341675\n",
      "Iteration 40, Loss: 0.2971568703651428\n",
      "Iteration 50, Loss: 0.21654632687568665\n",
      "Iteration 60, Loss: 0.16159865260124207\n",
      "Iteration 70, Loss: 0.11981460452079773\n",
      "Iteration 80, Loss: 0.09332382678985596\n",
      "Iteration 90, Loss: 0.07289770245552063\n",
      "Iteration 100, Loss: 0.06274184584617615\n",
      "Iteration 110, Loss: 0.05553709343075752\n",
      "Iteration 120, Loss: 0.04836677387356758\n",
      "Iteration 130, Loss: 0.04798653721809387\n",
      "Iteration 140, Loss: 0.03944224491715431\n",
      "Iteration 150, Loss: 0.04183683916926384\n",
      "Iteration 160, Loss: 0.03616771101951599\n",
      "Iteration 170, Loss: 0.03560998663306236\n",
      "Iteration 180, Loss: 0.03457355871796608\n",
      "Iteration 190, Loss: 0.030165348201990128\n",
      "Iteration 200, Loss: 0.027705775573849678\n",
      "Iteration 210, Loss: 0.02565261349081993\n",
      "Iteration 220, Loss: 0.025406837463378906\n",
      "Iteration 230, Loss: 0.024846145883202553\n",
      "Iteration 240, Loss: 0.02074361778795719\n",
      "Iteration 250, Loss: 0.020230989903211594\n",
      "Iteration 260, Loss: 0.022922232747077942\n",
      "Iteration 270, Loss: 0.02097148448228836\n",
      "Iteration 280, Loss: 0.02008919045329094\n",
      "Iteration 290, Loss: 0.018859265372157097\n",
      "Iteration 300, Loss: 0.017399612814188004\n",
      "Iteration 310, Loss: 0.01648098975419998\n",
      "Iteration 320, Loss: 0.016066594049334526\n",
      "Iteration 330, Loss: 0.015181779861450195\n",
      "Iteration 340, Loss: 0.013856654986739159\n",
      "Iteration 350, Loss: 0.013129333965480328\n",
      "Iteration 360, Loss: 0.012485193088650703\n",
      "Iteration 370, Loss: 0.011277958750724792\n",
      "Iteration 380, Loss: 0.013012278825044632\n",
      "Iteration 390, Loss: 0.011774509213864803\n",
      "Iteration 400, Loss: 0.011986998841166496\n",
      "Iteration 410, Loss: 0.011163858696818352\n",
      "Iteration 420, Loss: 0.010622454807162285\n",
      "Iteration 430, Loss: 0.010237458162009716\n",
      "Iteration 440, Loss: 0.00983388815075159\n",
      "Iteration 450, Loss: 0.009643361903727055\n",
      "Iteration 460, Loss: 0.008782774209976196\n",
      "Iteration 470, Loss: 0.008833721280097961\n",
      "Iteration 480, Loss: 0.008111326023936272\n",
      "Iteration 490, Loss: 0.00785902887582779\n",
      "Iteration 500, Loss: 0.0075838747434318066\n",
      "Iteration 510, Loss: 0.008631770499050617\n",
      "Iteration 520, Loss: 0.006318533793091774\n",
      "Iteration 530, Loss: 0.007539685815572739\n",
      "Iteration 540, Loss: 0.007159677799791098\n",
      "Iteration 550, Loss: 0.007732532452791929\n",
      "Iteration 560, Loss: 0.00725466338917613\n",
      "Iteration 570, Loss: 0.007204121444374323\n",
      "Iteration 580, Loss: 0.0068071624264121056\n",
      "Iteration 590, Loss: 0.0059832497499883175\n",
      "Iteration 600, Loss: 0.006267164368182421\n",
      "Iteration 610, Loss: 0.006720850709825754\n",
      "Iteration 620, Loss: 0.005308602005243301\n",
      "Iteration 630, Loss: 0.005406539887189865\n",
      "Iteration 640, Loss: 0.00565042020753026\n",
      "Iteration 650, Loss: 0.006109058856964111\n",
      "Iteration 660, Loss: 0.005438217893242836\n",
      "Iteration 670, Loss: 0.006492993328720331\n",
      "Iteration 680, Loss: 0.005621824413537979\n",
      "Iteration 690, Loss: 0.005563448183238506\n",
      "Iteration 700, Loss: 0.005010188091546297\n",
      "Iteration 710, Loss: 0.005003707949072123\n",
      "Iteration 720, Loss: 0.004869952332228422\n",
      "Iteration 730, Loss: 0.004733210429549217\n",
      "Iteration 740, Loss: 0.004652768839150667\n",
      "Iteration 750, Loss: 0.004576458595693111\n",
      "Iteration 760, Loss: 0.004292465280741453\n",
      "Iteration 770, Loss: 0.0046743303537368774\n",
      "Iteration 780, Loss: 0.00462723895907402\n",
      "Iteration 790, Loss: 0.004146233666688204\n",
      "Iteration 800, Loss: 0.004059420898556709\n",
      "Iteration 810, Loss: 0.00392585014924407\n",
      "Iteration 820, Loss: 0.0042139082215726376\n",
      "Iteration 830, Loss: 0.00427470775321126\n",
      "Iteration 840, Loss: 0.004020568914711475\n",
      "Iteration 850, Loss: 0.0034638899378478527\n",
      "Iteration 860, Loss: 0.003699233755469322\n",
      "Iteration 870, Loss: 0.0035881148651242256\n",
      "Iteration 880, Loss: 0.003930462058633566\n",
      "Iteration 890, Loss: 0.0035149604082107544\n",
      "Iteration 900, Loss: 0.0034362415317445993\n",
      "Iteration 910, Loss: 0.0036836201325058937\n",
      "Iteration 920, Loss: 0.003701134817674756\n",
      "Iteration 930, Loss: 0.003214360447600484\n",
      "Iteration 940, Loss: 0.0033964728936553\n",
      "Iteration 950, Loss: 0.0031477685552090406\n",
      "Iteration 960, Loss: 0.003244182327762246\n",
      "Iteration 970, Loss: 0.0028706989251077175\n",
      "Iteration 980, Loss: 0.003300118027254939\n",
      "Iteration 990, Loss: 0.003327554790303111\n",
      "Iteration 1000, Loss: 0.003176620928570628\n",
      "Iteration 1010, Loss: 0.002823054092004895\n",
      "Iteration 1020, Loss: 0.0031544684898108244\n",
      "Iteration 1030, Loss: 0.0029899568762630224\n",
      "Iteration 1040, Loss: 0.0029556569643318653\n",
      "Iteration 1050, Loss: 0.002806237433105707\n",
      "Iteration 1060, Loss: 0.00281541864387691\n",
      "Iteration 1070, Loss: 0.0027146469801664352\n",
      "Iteration 1080, Loss: 0.0028768135234713554\n",
      "Iteration 1090, Loss: 0.0027780095115303993\n",
      "Iteration 1100, Loss: 0.002910659881308675\n",
      "Iteration 1110, Loss: 0.0025753427762538195\n",
      "Iteration 1120, Loss: 0.0024665382225066423\n",
      "Iteration 1130, Loss: 0.0025362400338053703\n",
      "Iteration 1140, Loss: 0.0026444606482982635\n",
      "Iteration 1150, Loss: 0.002521566580981016\n",
      "Iteration 1160, Loss: 0.002430760534480214\n",
      "Iteration 1170, Loss: 0.002477793488651514\n",
      "Iteration 1180, Loss: 0.002385033294558525\n",
      "Iteration 1190, Loss: 0.0025128875859081745\n",
      "Iteration 1200, Loss: 0.0025189081206917763\n",
      "Iteration 1210, Loss: 0.002447327831760049\n",
      "Iteration 1220, Loss: 0.002418362768366933\n",
      "Iteration 1230, Loss: 0.0023712944239377975\n",
      "Iteration 1240, Loss: 0.0022937082685530186\n",
      "Iteration 1250, Loss: 0.002043083542957902\n",
      "Iteration 1260, Loss: 0.0025222592521458864\n",
      "Iteration 1270, Loss: 0.0022435965947806835\n",
      "Iteration 1280, Loss: 0.0021549281664192677\n",
      "Iteration 1290, Loss: 0.0021072549279779196\n",
      "Iteration 1300, Loss: 0.00234160665422678\n",
      "Iteration 1310, Loss: 0.0021769453305751085\n",
      "Iteration 1320, Loss: 0.0021094323601573706\n",
      "Iteration 1330, Loss: 0.002046868670731783\n",
      "Iteration 1340, Loss: 0.002251499332487583\n",
      "Iteration 1350, Loss: 0.0020559467375278473\n",
      "Iteration 1360, Loss: 0.002096917713060975\n",
      "Iteration 1370, Loss: 0.0020145829766988754\n",
      "Iteration 1380, Loss: 0.0020345584489405155\n",
      "Iteration 1390, Loss: 0.0020039291121065617\n",
      "Iteration 1400, Loss: 0.0019802760798484087\n",
      "Iteration 1410, Loss: 0.0019158093491569161\n",
      "Iteration 1420, Loss: 0.002041579456999898\n",
      "Iteration 1430, Loss: 0.0018827412277460098\n",
      "Iteration 1440, Loss: 0.0020210121292620897\n",
      "Iteration 1450, Loss: 0.0019440940814092755\n",
      "Iteration 1460, Loss: 0.0019600011873990297\n",
      "Iteration 1470, Loss: 0.0019118019845336676\n",
      "Iteration 1480, Loss: 0.0018882344011217356\n",
      "Iteration 1490, Loss: 0.0018871139036491513\n",
      "Iteration 1500, Loss: 0.00184950465336442\n",
      "Iteration 1510, Loss: 0.0017524358117952943\n",
      "Iteration 1520, Loss: 0.0016724120359867811\n",
      "Iteration 1530, Loss: 0.0017237343126907945\n",
      "Iteration 1540, Loss: 0.0018234529998153448\n",
      "Iteration 1550, Loss: 0.0017063067061826587\n",
      "Iteration 1560, Loss: 0.0017392509616911411\n",
      "Iteration 1570, Loss: 0.0016565052792429924\n",
      "Iteration 1580, Loss: 0.0016326718032360077\n",
      "Iteration 1590, Loss: 0.001668238895945251\n",
      "Iteration 1600, Loss: 0.0017537144012749195\n",
      "Iteration 1610, Loss: 0.00166499603074044\n",
      "Iteration 1620, Loss: 0.0015572872944176197\n",
      "Iteration 1630, Loss: 0.0016767418710514903\n",
      "Iteration 1640, Loss: 0.0015730656450614333\n",
      "Iteration 1650, Loss: 0.0015805339207872748\n",
      "Iteration 1660, Loss: 0.001614342792890966\n",
      "Iteration 1670, Loss: 0.00153844163287431\n",
      "Iteration 1680, Loss: 0.0016156770288944244\n",
      "Iteration 1690, Loss: 0.001584080047905445\n",
      "Iteration 1700, Loss: 0.0015604252694174647\n",
      "Iteration 1710, Loss: 0.0015743590192869306\n",
      "Iteration 1720, Loss: 0.0015274927718564868\n",
      "Iteration 1730, Loss: 0.0014961583074182272\n",
      "Iteration 1740, Loss: 0.0014951652847230434\n",
      "Iteration 1750, Loss: 0.0015138997696340084\n",
      "Iteration 1760, Loss: 0.0015272252494469285\n",
      "Iteration 1770, Loss: 0.0014336989261209965\n",
      "Iteration 1780, Loss: 0.001535350806079805\n",
      "Iteration 1790, Loss: 0.0014788040425628424\n",
      "Iteration 1800, Loss: 0.001468476839363575\n",
      "Iteration 1810, Loss: 0.0014630632940679789\n",
      "Iteration 1820, Loss: 0.0014735780423507094\n",
      "Iteration 1830, Loss: 0.0014210654189810157\n",
      "Iteration 1840, Loss: 0.0013804597547277808\n",
      "Iteration 1850, Loss: 0.0012915453407913446\n",
      "Iteration 1860, Loss: 0.001343538984656334\n",
      "Iteration 1870, Loss: 0.001436619320884347\n",
      "Iteration 1880, Loss: 0.0014065958093851805\n",
      "Iteration 1890, Loss: 0.0013631677720695734\n",
      "Iteration 1900, Loss: 0.0012812470085918903\n",
      "Iteration 1910, Loss: 0.001348548335954547\n",
      "Iteration 1920, Loss: 0.0012676013866439462\n",
      "Iteration 1930, Loss: 0.00133227719925344\n",
      "Iteration 1940, Loss: 0.001346325152553618\n",
      "Iteration 1950, Loss: 0.0012434071395546198\n",
      "Iteration 1960, Loss: 0.0012851880164816976\n",
      "Iteration 1970, Loss: 0.0012909997021779418\n",
      "Iteration 1980, Loss: 0.00126999884378165\n",
      "Iteration 1990, Loss: 0.0012113307602703571\n",
      "Iteration 2000, Loss: 0.0012628178810700774\n",
      "Iteration 2010, Loss: 0.0011817298363894224\n",
      "Iteration 2020, Loss: 0.0012614558218047023\n",
      "Iteration 2030, Loss: 0.001252374262548983\n",
      "Iteration 2040, Loss: 0.0012299512745812535\n",
      "Iteration 2050, Loss: 0.0012375827645882964\n",
      "Iteration 2060, Loss: 0.0012772624613717198\n",
      "Iteration 2070, Loss: 0.0012416819809004664\n",
      "Iteration 2080, Loss: 0.0011882000835612416\n",
      "Iteration 2090, Loss: 0.0011943817371502519\n",
      "Iteration 2100, Loss: 0.0011966865276917815\n",
      "Iteration 2110, Loss: 0.0012117702281102538\n",
      "Iteration 2120, Loss: 0.0011848369613289833\n",
      "Iteration 2130, Loss: 0.0011721247574314475\n",
      "Iteration 2140, Loss: 0.001117620849981904\n",
      "Iteration 2150, Loss: 0.0011568720219656825\n",
      "Iteration 2160, Loss: 0.0011821178486570716\n",
      "Iteration 2170, Loss: 0.0011283563217148185\n",
      "Iteration 2180, Loss: 0.0011485774302855134\n",
      "Iteration 2190, Loss: 0.00113171327393502\n",
      "Iteration 2200, Loss: 0.0011205142363905907\n",
      "Iteration 2210, Loss: 0.0010980920633301139\n",
      "Iteration 2220, Loss: 0.0011312576243653893\n",
      "Iteration 2230, Loss: 0.0010995299089699984\n",
      "Iteration 2240, Loss: 0.0010605035349726677\n",
      "Iteration 2250, Loss: 0.000992150860838592\n",
      "Iteration 2260, Loss: 0.0010957960039377213\n",
      "Iteration 2270, Loss: 0.0010716490214690566\n",
      "Iteration 2280, Loss: 0.0010711149079725146\n",
      "Iteration 2290, Loss: 0.001063331961631775\n",
      "Iteration 2300, Loss: 0.0010947725968435407\n",
      "Iteration 2310, Loss: 0.0010348171927034855\n",
      "Iteration 2320, Loss: 0.0010394381824880838\n",
      "Iteration 2330, Loss: 0.001031957333907485\n",
      "Iteration 2340, Loss: 0.000995459035038948\n",
      "Iteration 2350, Loss: 0.0010363786714151502\n",
      "Iteration 2360, Loss: 0.0010165858548134565\n",
      "Iteration 2370, Loss: 0.0009957581060007215\n",
      "Iteration 2380, Loss: 0.0009619527845643461\n",
      "Iteration 2390, Loss: 0.0010258050169795752\n",
      "Iteration 2400, Loss: 0.0009718976216390729\n",
      "Iteration 2410, Loss: 0.0009935974376276135\n",
      "Iteration 2420, Loss: 0.0009849705966189504\n",
      "Iteration 2430, Loss: 0.0009332204353995621\n",
      "Iteration 2440, Loss: 0.0009618580807000399\n",
      "Iteration 2450, Loss: 0.001001693424768746\n",
      "Iteration 2460, Loss: 0.0009927689097821712\n",
      "Iteration 2470, Loss: 0.0009799967519938946\n",
      "Iteration 2480, Loss: 0.0009652806329540908\n",
      "Iteration 2490, Loss: 0.0009523352491669357\n",
      "Iteration 2500, Loss: 0.0009385211742483079\n",
      "Iteration 2510, Loss: 0.0009412369108758867\n",
      "Iteration 2520, Loss: 0.0008747954270802438\n",
      "Iteration 2530, Loss: 0.0009342487319372594\n",
      "Iteration 2540, Loss: 0.0009087664075195789\n",
      "Iteration 2550, Loss: 0.0009169414988718927\n",
      "Iteration 2560, Loss: 0.000930268841329962\n",
      "Iteration 2570, Loss: 0.0009201531065627933\n",
      "Iteration 2580, Loss: 0.0009222519584000111\n",
      "Iteration 2590, Loss: 0.0008730012341402471\n",
      "Iteration 2600, Loss: 0.0008702765335328877\n",
      "Iteration 2610, Loss: 0.000868051836732775\n",
      "Iteration 2620, Loss: 0.0008694828138686717\n",
      "Iteration 2630, Loss: 0.0009095564601011574\n",
      "Iteration 2640, Loss: 0.0008738942560739815\n",
      "Iteration 2650, Loss: 0.0009065532358363271\n",
      "Iteration 2660, Loss: 0.0008550369529984891\n",
      "Iteration 2670, Loss: 0.0008342788205482066\n",
      "Iteration 2680, Loss: 0.0008633373654447496\n",
      "Iteration 2690, Loss: 0.000833837955724448\n",
      "Iteration 2700, Loss: 0.0008664890774525702\n",
      "Iteration 2710, Loss: 0.0008305237861350179\n",
      "Iteration 2720, Loss: 0.0008483093697577715\n",
      "Iteration 2730, Loss: 0.0008114738157019019\n",
      "Iteration 2740, Loss: 0.0008612043457105756\n",
      "Iteration 2750, Loss: 0.0008573361556045711\n",
      "Iteration 2760, Loss: 0.0008335254387930036\n",
      "Iteration 2770, Loss: 0.0008048939635045826\n",
      "Iteration 2780, Loss: 0.0008316965540871024\n",
      "Iteration 2790, Loss: 0.000817100633867085\n",
      "Iteration 2800, Loss: 0.0008297371678054333\n",
      "Iteration 2810, Loss: 0.0008283722563646734\n",
      "Iteration 2820, Loss: 0.0007722702575847507\n",
      "Iteration 2830, Loss: 0.0007707437034696341\n",
      "Iteration 2840, Loss: 0.0007699893321841955\n",
      "Iteration 2850, Loss: 0.000802659138571471\n",
      "Iteration 2860, Loss: 0.0008149605127982795\n",
      "Iteration 2870, Loss: 0.0008091432973742485\n",
      "Iteration 2880, Loss: 0.0007869211258366704\n",
      "Iteration 2890, Loss: 0.0007418119930662215\n",
      "Iteration 2900, Loss: 0.0007652224157936871\n",
      "Iteration 2910, Loss: 0.0007491460419259965\n",
      "Iteration 2920, Loss: 0.0007712680380791426\n",
      "Iteration 2930, Loss: 0.0008019537781365216\n",
      "Iteration 2940, Loss: 0.000764360127504915\n",
      "Iteration 2950, Loss: 0.000752559513784945\n",
      "Iteration 2960, Loss: 0.0007219727849587798\n",
      "Iteration 2970, Loss: 0.0007364322664216161\n",
      "Iteration 2980, Loss: 0.0007563686813227832\n",
      "Iteration 2990, Loss: 0.0007363711483776569\n",
      "Iteration 3000, Loss: 0.0007321585435420275\n",
      "Iteration 3010, Loss: 0.0007278703851625323\n",
      "Iteration 3020, Loss: 0.0006840178975835443\n",
      "Iteration 3030, Loss: 0.0007133432663977146\n",
      "Iteration 3040, Loss: 0.0006974937277846038\n",
      "Iteration 3050, Loss: 0.0007061361684463918\n",
      "Iteration 3060, Loss: 0.000716175592970103\n",
      "Iteration 3070, Loss: 0.0007210568292066455\n",
      "Iteration 3080, Loss: 0.0007089735008776188\n",
      "Iteration 3090, Loss: 0.0007087162230163813\n",
      "Iteration 3100, Loss: 0.0006565815419889987\n",
      "Iteration 3110, Loss: 0.0006700006197206676\n",
      "Iteration 3120, Loss: 0.0006787831662222743\n",
      "Iteration 3130, Loss: 0.0007092189625836909\n",
      "Iteration 3140, Loss: 0.0006758427480235696\n",
      "Iteration 3150, Loss: 0.0006884185131639242\n",
      "Iteration 3160, Loss: 0.000646647997200489\n",
      "Iteration 3170, Loss: 0.0006931552197784185\n",
      "Iteration 3180, Loss: 0.0006896540289744735\n",
      "Iteration 3190, Loss: 0.0006862122099846601\n",
      "Iteration 3200, Loss: 0.0006603403599001467\n",
      "Iteration 3210, Loss: 0.0006711140740662813\n",
      "Iteration 3220, Loss: 0.0006609660922549665\n",
      "Iteration 3230, Loss: 0.0006573107675649226\n",
      "Iteration 3240, Loss: 0.0006552888662554324\n",
      "Iteration 3250, Loss: 0.0006531327380798757\n",
      "Iteration 3260, Loss: 0.000671888526994735\n",
      "Iteration 3270, Loss: 0.0006379574770107865\n",
      "Iteration 3280, Loss: 0.0006450501387007535\n",
      "Iteration 3290, Loss: 0.0006218220805749297\n",
      "Iteration 3300, Loss: 0.0006166925886645913\n",
      "Iteration 3310, Loss: 0.0006167370011098683\n",
      "Iteration 3320, Loss: 0.0006394785013981164\n",
      "Iteration 3330, Loss: 0.0006269171135500073\n",
      "Iteration 3340, Loss: 0.0006428300985135138\n",
      "Iteration 3350, Loss: 0.0006330516189336777\n",
      "Iteration 3360, Loss: 0.0005897550727240741\n",
      "Iteration 3370, Loss: 0.0006151816342025995\n",
      "Iteration 3380, Loss: 0.0005834506591781974\n",
      "Iteration 3390, Loss: 0.0006071028183214366\n",
      "Iteration 3400, Loss: 0.0005885022692382336\n",
      "Iteration 3410, Loss: 0.0005520660197362304\n",
      "Iteration 3420, Loss: 0.0005914404755458236\n",
      "Iteration 3430, Loss: 0.0005775889731012285\n",
      "Iteration 3440, Loss: 0.0005660802125930786\n",
      "Iteration 3450, Loss: 0.0005812004674226046\n",
      "Iteration 3460, Loss: 0.0005782851949334145\n",
      "Iteration 3470, Loss: 0.0006014363025315106\n",
      "Iteration 3480, Loss: 0.0005845958366990089\n",
      "Iteration 3490, Loss: 0.0005625397898256779\n",
      "Iteration 3500, Loss: 0.0005762922228313982\n",
      "Iteration 3510, Loss: 0.0005478335660882294\n",
      "Iteration 3520, Loss: 0.0005686206859536469\n",
      "Iteration 3530, Loss: 0.0005399997462518513\n",
      "Iteration 3540, Loss: 0.0005739048938266933\n",
      "Iteration 3550, Loss: 0.0005747158429585397\n",
      "Iteration 3560, Loss: 0.000522188376635313\n",
      "Iteration 3570, Loss: 0.0005622891476377845\n",
      "Iteration 3580, Loss: 0.0005204321932978928\n",
      "Iteration 3590, Loss: 0.0005302379140630364\n",
      "Iteration 3600, Loss: 0.0005708346143364906\n",
      "Iteration 3610, Loss: 0.0005639854934997857\n",
      "Iteration 3620, Loss: 0.0005703007336705923\n",
      "Iteration 3630, Loss: 0.0005412412574514747\n",
      "Iteration 3640, Loss: 0.0005064140423201025\n",
      "Iteration 3650, Loss: 0.0005247779190540314\n",
      "Iteration 3660, Loss: 0.0005133751546964049\n",
      "Iteration 3670, Loss: 0.0005336239701136947\n",
      "Iteration 3680, Loss: 0.0005139497807249427\n",
      "Iteration 3690, Loss: 0.0005537419347092509\n",
      "Iteration 3700, Loss: 0.0005386563134379685\n",
      "Iteration 3710, Loss: 0.0005110648926347494\n",
      "Iteration 3720, Loss: 0.0005409740842878819\n",
      "Iteration 3730, Loss: 0.0005150050856173038\n",
      "Iteration 3740, Loss: 0.0005260405014269054\n",
      "Iteration 3750, Loss: 0.00048689404502511024\n",
      "Iteration 3760, Loss: 0.0005231297109276056\n",
      "Iteration 3770, Loss: 0.0005215387791395187\n",
      "Iteration 3780, Loss: 0.0004933060263283551\n",
      "Iteration 3790, Loss: 0.0004905274836346507\n",
      "Iteration 3800, Loss: 0.00047349222586490214\n",
      "Iteration 3810, Loss: 0.000493893981911242\n",
      "Iteration 3820, Loss: 0.0004866175295319408\n",
      "Iteration 3830, Loss: 0.00048030735342763364\n",
      "Iteration 3840, Loss: 0.00047615382936783135\n",
      "Iteration 3850, Loss: 0.00047616756637580693\n",
      "Iteration 3860, Loss: 0.00047272336087189615\n",
      "Iteration 3870, Loss: 0.00047809589887037873\n",
      "Iteration 3880, Loss: 0.0004542654496617615\n",
      "Iteration 3890, Loss: 0.0004820526810362935\n",
      "Iteration 3900, Loss: 0.00048809946747496724\n",
      "Iteration 3910, Loss: 0.0004569449520204216\n",
      "Iteration 3920, Loss: 0.00045605728519149125\n",
      "Iteration 3930, Loss: 0.0004604700661730021\n",
      "Iteration 3940, Loss: 0.00046649269643239677\n",
      "Iteration 3950, Loss: 0.0004849144315812737\n",
      "Iteration 3960, Loss: 0.00045929010957479477\n",
      "Iteration 3970, Loss: 0.00046113046118989587\n",
      "Iteration 3980, Loss: 0.0004564911359921098\n",
      "Iteration 3990, Loss: 0.000439308030763641\n",
      "Iteration 4000, Loss: 0.0004582963010761887\n",
      "Iteration 4010, Loss: 0.00046212098095566034\n",
      "Iteration 4020, Loss: 0.00042882285197265446\n",
      "Iteration 4030, Loss: 0.00044389587128534913\n",
      "Iteration 4040, Loss: 0.0004306829650886357\n",
      "Iteration 4050, Loss: 0.0004575256316456944\n",
      "Iteration 4060, Loss: 0.0004542428068816662\n",
      "Iteration 4070, Loss: 0.0004469476407393813\n",
      "Iteration 4080, Loss: 0.00040967902168631554\n",
      "Iteration 4090, Loss: 0.0004102297534700483\n",
      "Iteration 4100, Loss: 0.00041684129973873496\n",
      "Iteration 4110, Loss: 0.0004235098895151168\n",
      "Iteration 4120, Loss: 0.00040891068056225777\n",
      "Iteration 4130, Loss: 0.00040058273589238524\n",
      "Iteration 4140, Loss: 0.00043613833258859813\n",
      "Iteration 4150, Loss: 0.0004019537300337106\n",
      "Iteration 4160, Loss: 0.0004118138749618083\n",
      "Iteration 4170, Loss: 0.0003992202691733837\n",
      "Iteration 4180, Loss: 0.0004089654830750078\n",
      "Iteration 4190, Loss: 0.0003967174852732569\n",
      "Iteration 4200, Loss: 0.00040522703784517944\n",
      "Iteration 4210, Loss: 0.00040532852290198207\n",
      "Iteration 4220, Loss: 0.00038299363222904503\n",
      "Iteration 4230, Loss: 0.00039215502329170704\n",
      "Iteration 4240, Loss: 0.000401448953198269\n",
      "Iteration 4250, Loss: 0.00037809176137670875\n",
      "Iteration 4260, Loss: 0.0003830357745755464\n",
      "Iteration 4270, Loss: 0.00039345756522379816\n",
      "Iteration 4280, Loss: 0.0003795265220105648\n",
      "Iteration 4290, Loss: 0.00037883539334870875\n",
      "Iteration 4300, Loss: 0.0003888621286023408\n",
      "Iteration 4310, Loss: 0.00037212783354334533\n",
      "Iteration 4320, Loss: 0.0003682866517920047\n",
      "Iteration 4330, Loss: 0.0003731421020347625\n",
      "Iteration 4340, Loss: 0.00036986381746828556\n",
      "Iteration 4350, Loss: 0.0003676897322293371\n",
      "Iteration 4360, Loss: 0.00036456991801969707\n",
      "Iteration 4370, Loss: 0.0003486715431790799\n",
      "Iteration 4380, Loss: 0.00035235946415923536\n",
      "Iteration 4390, Loss: 0.00036424098652787507\n",
      "Iteration 4400, Loss: 0.0003831373469438404\n",
      "Iteration 4410, Loss: 0.00035372760612517595\n",
      "Iteration 4420, Loss: 0.0003400787536520511\n",
      "Iteration 4430, Loss: 0.00034419589792378247\n",
      "Iteration 4440, Loss: 0.0003507173096295446\n",
      "Iteration 4450, Loss: 0.0003506364009808749\n",
      "Iteration 4460, Loss: 0.00034728896571323276\n",
      "Iteration 4470, Loss: 0.00032979933894239366\n",
      "Iteration 4480, Loss: 0.0003244697581976652\n",
      "Iteration 4490, Loss: 0.00034971031709574163\n",
      "Iteration 4500, Loss: 0.00034763829899020493\n",
      "Iteration 4510, Loss: 0.00031862061587162316\n",
      "Iteration 4520, Loss: 0.00034811170189641416\n",
      "Iteration 4530, Loss: 0.00033699709456413984\n",
      "Iteration 4540, Loss: 0.0003233963798265904\n",
      "Iteration 4550, Loss: 0.00032618670957162976\n",
      "Iteration 4560, Loss: 0.0003284274716861546\n",
      "Iteration 4570, Loss: 0.00031568753183819354\n",
      "Iteration 4580, Loss: 0.00031899052555672824\n",
      "Iteration 4590, Loss: 0.00033807428553700447\n",
      "Iteration 4600, Loss: 0.0003291002940386534\n",
      "Iteration 4610, Loss: 0.000317376630846411\n",
      "Iteration 4620, Loss: 0.0003217183402739465\n",
      "Iteration 4630, Loss: 0.0003076865104958415\n",
      "Iteration 4640, Loss: 0.00031385154579766095\n",
      "Iteration 4650, Loss: 0.00031570257851853967\n",
      "Iteration 4660, Loss: 0.00031851755920797586\n",
      "Iteration 4670, Loss: 0.0003072316467296332\n",
      "Iteration 4680, Loss: 0.00029998162062838674\n",
      "Iteration 4690, Loss: 0.0003112428239546716\n",
      "Iteration 4700, Loss: 0.00029670033836737275\n",
      "Iteration 4710, Loss: 0.0002972000802401453\n",
      "Iteration 4720, Loss: 0.00029775794246234\n",
      "Iteration 4730, Loss: 0.00030087100458331406\n",
      "Iteration 4740, Loss: 0.00030841209809295833\n",
      "Iteration 4750, Loss: 0.00030329159926623106\n",
      "Iteration 4760, Loss: 0.0002962103462778032\n",
      "Iteration 4770, Loss: 0.0002834776241797954\n",
      "Iteration 4780, Loss: 0.0002889069728553295\n",
      "Iteration 4790, Loss: 0.00029318162705749273\n",
      "Iteration 4800, Loss: 0.0002913907519541681\n",
      "Iteration 4810, Loss: 0.0002685551007743925\n",
      "Iteration 4820, Loss: 0.0002781948714982718\n",
      "Iteration 4830, Loss: 0.0002974251692648977\n",
      "Iteration 4840, Loss: 0.0002879961393773556\n",
      "Iteration 4850, Loss: 0.0002822052629198879\n",
      "Iteration 4860, Loss: 0.000278577848803252\n",
      "Iteration 4870, Loss: 0.0002819017390720546\n",
      "Iteration 4880, Loss: 0.0002910531184170395\n",
      "Iteration 4890, Loss: 0.00027002886054106057\n",
      "Iteration 4900, Loss: 0.00027076114201918244\n",
      "Iteration 4910, Loss: 0.0002892356424126774\n",
      "Iteration 4920, Loss: 0.00027748459251597524\n",
      "Iteration 4930, Loss: 0.0002736273454502225\n",
      "Iteration 4940, Loss: 0.00027520087314769626\n",
      "Iteration 4950, Loss: 0.00026447392883710563\n",
      "Iteration 4960, Loss: 0.00025063299108296633\n",
      "Iteration 4970, Loss: 0.0002706180966924876\n",
      "Iteration 4980, Loss: 0.0002757917100097984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  67%|██████▋   | 16/24 [12:27<08:09, 61.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4990, Loss: 0.00026737336884252727\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.023347525324197874, 'L2_avg': 0.029898359965248582, 'End_point_L1_avg': 0.006465713986956486, 'End_point_L2_avg': 0.006708946124495868}\n",
      "Iteration 0, Loss: 1.5622918605804443\n",
      "Iteration 10, Loss: 0.18324536085128784\n",
      "Iteration 20, Loss: 0.12148083001375198\n",
      "Iteration 30, Loss: 0.05435697361826897\n",
      "Iteration 40, Loss: 0.03448056802153587\n",
      "Iteration 50, Loss: 0.03433765098452568\n",
      "Iteration 60, Loss: 0.015181278809905052\n",
      "Iteration 70, Loss: 0.01358301192522049\n",
      "Iteration 80, Loss: 0.010601743124425411\n",
      "Iteration 90, Loss: 0.008701808750629425\n",
      "Iteration 100, Loss: 0.007099873851984739\n",
      "Iteration 110, Loss: 0.006216634064912796\n",
      "Iteration 120, Loss: 0.004973896313458681\n",
      "Iteration 130, Loss: 0.005249034147709608\n",
      "Iteration 140, Loss: 0.003776771714910865\n",
      "Iteration 150, Loss: 0.004154611378908157\n",
      "Iteration 160, Loss: 0.0036590746603906155\n",
      "Iteration 170, Loss: 0.003403267590329051\n",
      "Iteration 180, Loss: 0.0029642211738973856\n",
      "Iteration 190, Loss: 0.0031620392110198736\n",
      "Iteration 200, Loss: 0.002953539602458477\n",
      "Iteration 210, Loss: 0.0028668849263340235\n",
      "Iteration 220, Loss: 0.002505771117284894\n",
      "Iteration 230, Loss: 0.0024165732320398092\n",
      "Iteration 240, Loss: 0.00229258113540709\n",
      "Iteration 250, Loss: 0.0024697151966392994\n",
      "Iteration 260, Loss: 0.0020257558207958937\n",
      "Iteration 270, Loss: 0.0020150181371718645\n",
      "Iteration 280, Loss: 0.0019208157900720835\n",
      "Iteration 290, Loss: 0.0018064503092318773\n",
      "Iteration 300, Loss: 0.0019468626705929637\n",
      "Iteration 310, Loss: 0.001881029107607901\n",
      "Iteration 320, Loss: 0.0017556052189320326\n",
      "Iteration 330, Loss: 0.001753991236910224\n",
      "Iteration 340, Loss: 0.0018084736075252295\n",
      "Iteration 350, Loss: 0.0014274119166657329\n",
      "Iteration 360, Loss: 0.0015756068751215935\n",
      "Iteration 370, Loss: 0.0014885314740240574\n",
      "Iteration 380, Loss: 0.001675182138569653\n",
      "Iteration 390, Loss: 0.0014311546692624688\n",
      "Iteration 400, Loss: 0.0014328754041343927\n",
      "Iteration 410, Loss: 0.001496476586908102\n",
      "Iteration 420, Loss: 0.0014536926755681634\n",
      "Iteration 430, Loss: 0.0013741666916757822\n",
      "Iteration 440, Loss: 0.001271785469725728\n",
      "Iteration 450, Loss: 0.00122846569865942\n",
      "Iteration 460, Loss: 0.0012297903886064887\n",
      "Iteration 470, Loss: 0.0011959444964304566\n",
      "Iteration 480, Loss: 0.001101462752558291\n",
      "Iteration 490, Loss: 0.0011177822016179562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  71%|███████   | 17/24 [12:36<05:18, 45.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 495\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 496, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.049116663619222636, 'L2_avg': 0.06310624073601794, 'End_point_L1_avg': 0.027619394423085065, 'End_point_L2_avg': 0.028995128710743855}\n",
      "Iteration 0, Loss: 0.6284762024879456\n",
      "Iteration 10, Loss: 0.12247040122747421\n",
      "Iteration 20, Loss: 0.050250060856342316\n",
      "Iteration 30, Loss: 0.04123835265636444\n",
      "Iteration 40, Loss: 0.018742268905043602\n",
      "Iteration 50, Loss: 0.016323303803801537\n",
      "Iteration 60, Loss: 0.012359078973531723\n",
      "Iteration 70, Loss: 0.010727881453931332\n",
      "Iteration 80, Loss: 0.009017063304781914\n",
      "Iteration 90, Loss: 0.007730377838015556\n",
      "Iteration 100, Loss: 0.005944747943431139\n",
      "Iteration 110, Loss: 0.004617747385054827\n",
      "Iteration 120, Loss: 0.004928660579025745\n",
      "Iteration 130, Loss: 0.00413227966055274\n",
      "Iteration 140, Loss: 0.0040306635200977325\n",
      "Iteration 150, Loss: 0.004021620377898216\n",
      "Iteration 160, Loss: 0.0036313103046268225\n",
      "Iteration 170, Loss: 0.0033657443709671497\n",
      "Iteration 180, Loss: 0.0029986670706421137\n",
      "Iteration 190, Loss: 0.0028185807168483734\n",
      "Iteration 200, Loss: 0.002856890205293894\n",
      "Iteration 210, Loss: 0.0024281274527311325\n",
      "Iteration 220, Loss: 0.0021018406841903925\n",
      "Iteration 230, Loss: 0.0022561531513929367\n",
      "Iteration 240, Loss: 0.002428322331979871\n",
      "Iteration 250, Loss: 0.0021395874209702015\n",
      "Iteration 260, Loss: 0.0019348926143720746\n",
      "Iteration 270, Loss: 0.002045078668743372\n",
      "Iteration 280, Loss: 0.001866379752755165\n",
      "Iteration 290, Loss: 0.0018315276829525828\n",
      "Iteration 300, Loss: 0.0020975677762180567\n",
      "Iteration 310, Loss: 0.001860283431597054\n",
      "Iteration 320, Loss: 0.001801184960640967\n",
      "Iteration 330, Loss: 0.0017850995063781738\n",
      "Iteration 340, Loss: 0.0015309653244912624\n",
      "Iteration 350, Loss: 0.0015255840262398124\n",
      "Iteration 360, Loss: 0.0017578811384737492\n",
      "Iteration 370, Loss: 0.0015818843385204673\n",
      "Iteration 380, Loss: 0.0014034734340384603\n",
      "Iteration 390, Loss: 0.0013953846646472812\n",
      "Iteration 400, Loss: 0.001307209488004446\n",
      "Iteration 410, Loss: 0.0014280976029112935\n",
      "Iteration 420, Loss: 0.0014323892537504435\n",
      "Iteration 430, Loss: 0.0013078644406050444\n",
      "Iteration 440, Loss: 0.0012529527302831411\n",
      "Iteration 450, Loss: 0.0013336080592125654\n",
      "Iteration 460, Loss: 0.001262883422896266\n",
      "Iteration 470, Loss: 0.001339816371910274\n",
      "Iteration 480, Loss: 0.0012327820295467973\n",
      "Iteration 490, Loss: 0.0012393000070005655\n",
      "Iteration 500, Loss: 0.0010966892587020993\n",
      "Iteration 510, Loss: 0.0011347740655764937\n",
      "Iteration 520, Loss: 0.0011198989814147353\n",
      "Iteration 530, Loss: 0.0011307259555906057\n",
      "Iteration 540, Loss: 0.001042836345732212\n",
      "Iteration 550, Loss: 0.0011171726509928703\n",
      "Iteration 560, Loss: 0.001015029032714665\n",
      "Iteration 570, Loss: 0.0010182146215811372\n",
      "Iteration 580, Loss: 0.000982475932687521\n",
      "Iteration 590, Loss: 0.0009959889575839043\n",
      "Iteration 600, Loss: 0.0009404844604432583\n",
      "Iteration 610, Loss: 0.0009250077418982983\n",
      "Iteration 620, Loss: 0.0009504859335720539\n",
      "Iteration 630, Loss: 0.0009741467656567693\n",
      "Iteration 640, Loss: 0.0009605091763660312\n",
      "Iteration 650, Loss: 0.0009886432671919465\n",
      "Iteration 660, Loss: 0.0011550652561709285\n",
      "Iteration 670, Loss: 0.0010016729356721044\n",
      "Iteration 680, Loss: 0.0008935240330174565\n",
      "Iteration 690, Loss: 0.0008828815189190209\n",
      "Iteration 700, Loss: 0.0009113802225328982\n",
      "Iteration 710, Loss: 0.0008502636337652802\n",
      "Iteration 720, Loss: 0.0008103752043098211\n",
      "Iteration 730, Loss: 0.0008124115993268788\n",
      "Iteration 740, Loss: 0.0007604282000102103\n",
      "Iteration 750, Loss: 0.0007923967204988003\n",
      "Iteration 760, Loss: 0.000775415392126888\n",
      "Iteration 770, Loss: 0.0009578340104781091\n",
      "Iteration 780, Loss: 0.0007560769445262849\n",
      "Iteration 790, Loss: 0.0008305181981995702\n",
      "Iteration 800, Loss: 0.0009124315693043172\n",
      "Iteration 810, Loss: 0.000713951129000634\n",
      "Iteration 820, Loss: 0.0007353847613558173\n",
      "Iteration 830, Loss: 0.000831952434964478\n",
      "Iteration 840, Loss: 0.0006594142178073525\n",
      "Iteration 850, Loss: 0.0007014169823378325\n",
      "Iteration 860, Loss: 0.0007197680533863604\n",
      "Iteration 870, Loss: 0.0007448252872563899\n",
      "Iteration 880, Loss: 0.0006579323089681566\n",
      "Iteration 890, Loss: 0.0006617636536248028\n",
      "Iteration 900, Loss: 0.0006520826136693358\n",
      "Iteration 910, Loss: 0.0005960177513770759\n",
      "Iteration 920, Loss: 0.0008493151981383562\n",
      "Iteration 930, Loss: 0.000748096383176744\n",
      "Iteration 940, Loss: 0.0006497383001260459\n",
      "Iteration 950, Loss: 0.0005778602208010852\n",
      "Iteration 960, Loss: 0.0005549901397898793\n",
      "Iteration 970, Loss: 0.0005962683353573084\n",
      "Iteration 980, Loss: 0.0006104081403464079\n",
      "Iteration 990, Loss: 0.0014966240851208568\n",
      "Iteration 1000, Loss: 0.0018629044061526656\n",
      "Iteration 1010, Loss: 0.0008377014892175794\n",
      "Iteration 1020, Loss: 0.0006560058682225645\n",
      "Iteration 1030, Loss: 0.0005890564061701298\n",
      "Iteration 1040, Loss: 0.0006048320792615414\n",
      "Iteration 1050, Loss: 0.00125648092944175\n",
      "Iteration 1060, Loss: 0.0011148668127134442\n",
      "Iteration 1070, Loss: 0.0013005289947614074\n",
      "Iteration 1080, Loss: 0.0005994618404656649\n",
      "Iteration 1090, Loss: 0.0006487175123766065\n",
      "Iteration 1100, Loss: 0.0007215854129754007\n",
      "Iteration 1110, Loss: 0.0004940926446579397\n",
      "Iteration 1120, Loss: 0.0004707062034867704\n",
      "Iteration 1130, Loss: 0.0005965585587546229\n",
      "Iteration 1140, Loss: 0.0006653832970187068\n",
      "Iteration 1150, Loss: 0.0010966900736093521\n",
      "Iteration 1160, Loss: 0.00042734728776849806\n",
      "Iteration 1170, Loss: 0.0004905629903078079\n",
      "Iteration 1180, Loss: 0.0005006400751881301\n",
      "Iteration 1190, Loss: 0.0007698633708059788\n",
      "Iteration 1200, Loss: 0.0005062175332568586\n",
      "Iteration 1210, Loss: 0.0026627937331795692\n",
      "Iteration 1220, Loss: 0.0005013870541006327\n",
      "Iteration 1230, Loss: 0.0008575083338655531\n",
      "Iteration 1240, Loss: 0.0009577193413861096\n",
      "Iteration 1250, Loss: 0.00034775931271724403\n",
      "Iteration 1260, Loss: 0.0003243951650802046\n",
      "Iteration 1270, Loss: 0.000475850363727659\n",
      "Iteration 1280, Loss: 0.0007286975160241127\n",
      "Iteration 1290, Loss: 0.0006626290851272643\n",
      "Iteration 1300, Loss: 0.00040807024925015867\n",
      "Iteration 1310, Loss: 0.0004211443883832544\n",
      "Iteration 1320, Loss: 0.0007227486930787563\n",
      "Iteration 1330, Loss: 0.0004502939700614661\n",
      "Iteration 1340, Loss: 0.00036568581708706915\n",
      "Iteration 1350, Loss: 0.0011983930598944426\n",
      "Iteration 1360, Loss: 0.0006462539313361049\n",
      "Iteration 1370, Loss: 0.0007534829783253372\n",
      "Iteration 1380, Loss: 0.0007536530029028654\n",
      "Iteration 1390, Loss: 0.0009758570813573897\n",
      "Iteration 1400, Loss: 0.0016354474937543273\n",
      "Iteration 1410, Loss: 0.0004307408817112446\n",
      "Iteration 1420, Loss: 0.00033160028397105634\n",
      "Iteration 1430, Loss: 0.0003097323642577976\n",
      "Iteration 1440, Loss: 0.0005274810246191919\n",
      "Iteration 1450, Loss: 0.0003102729097008705\n",
      "Iteration 1460, Loss: 0.00029170868219807744\n",
      "Iteration 1470, Loss: 0.0011953439097851515\n",
      "Iteration 1480, Loss: 0.0002820776717271656\n",
      "Iteration 1490, Loss: 0.0005271184490993619\n",
      "Iteration 1500, Loss: 0.00030106925987638533\n",
      "Iteration 1510, Loss: 0.0004127475549466908\n",
      "Iteration 1520, Loss: 0.00029004921088926494\n",
      "Iteration 1530, Loss: 0.0004452337743714452\n",
      "Iteration 1540, Loss: 0.000428248371463269\n",
      "Iteration 1550, Loss: 0.0007419537287205458\n",
      "Iteration 1560, Loss: 0.0006413091905415058\n",
      "Iteration 1570, Loss: 0.00030872825300320983\n",
      "Iteration 1580, Loss: 0.0017424196703359485\n",
      "Iteration 1590, Loss: 0.00044580374378710985\n",
      "Iteration 1600, Loss: 0.0006131656118668616\n",
      "Iteration 1610, Loss: 0.000373420916730538\n",
      "Iteration 1620, Loss: 0.0004043562803417444\n",
      "Iteration 1630, Loss: 0.00024858847609721124\n",
      "Iteration 1640, Loss: 0.0005711399135179818\n",
      "Iteration 1650, Loss: 0.00043836369877681136\n",
      "Iteration 1660, Loss: 0.00041904873796738684\n",
      "Iteration 1670, Loss: 0.0015640861820429564\n",
      "Iteration 1680, Loss: 0.0008973724325187504\n",
      "Iteration 1690, Loss: 0.000332410738337785\n",
      "Iteration 1700, Loss: 0.00035676563857123256\n",
      "Iteration 1710, Loss: 0.00022793673269916326\n",
      "Iteration 1720, Loss: 0.0003141460765618831\n",
      "Iteration 1730, Loss: 0.0007645961013622582\n",
      "Iteration 1740, Loss: 0.00028758044936694205\n",
      "Iteration 1750, Loss: 0.0004329146759118885\n",
      "Iteration 1760, Loss: 0.0020775182638317347\n",
      "Iteration 1770, Loss: 0.000984284677542746\n",
      "Iteration 1780, Loss: 0.0006477097631432116\n",
      "Iteration 1790, Loss: 0.0003202655934728682\n",
      "Iteration 1800, Loss: 0.0004769392544403672\n",
      "Iteration 1810, Loss: 0.0005675663123838603\n",
      "Iteration 1820, Loss: 0.0004971582093276083\n",
      "Iteration 1830, Loss: 0.0002511015045456588\n",
      "Iteration 1840, Loss: 0.0006966170622035861\n",
      "Iteration 1850, Loss: 0.00043774303048849106\n",
      "Iteration 1860, Loss: 0.0003311117470730096\n",
      "Iteration 1870, Loss: 0.001161172054708004\n",
      "Iteration 1880, Loss: 0.00019413365225773305\n",
      "Iteration 1890, Loss: 0.00024124939227476716\n",
      "Iteration 1900, Loss: 0.00026289233937859535\n",
      "Iteration 1910, Loss: 0.0015207993565127254\n",
      "Iteration 1920, Loss: 0.0010257813846692443\n",
      "Iteration 1930, Loss: 0.00019027703092433512\n",
      "Iteration 1940, Loss: 0.0001802092301659286\n",
      "Iteration 1950, Loss: 0.0004435361479409039\n",
      "Iteration 1960, Loss: 0.0006301987450569868\n",
      "Iteration 1970, Loss: 0.0006375901866704226\n",
      "Iteration 1980, Loss: 0.0002989513159263879\n",
      "Iteration 1990, Loss: 0.0005153908277861774\n",
      "Iteration 2000, Loss: 0.00018834703951142728\n",
      "Iteration 2010, Loss: 0.00019594613695517182\n",
      "Iteration 2020, Loss: 0.00033318367786705494\n",
      "Iteration 2030, Loss: 0.0013111740117892623\n",
      "Iteration 2040, Loss: 0.005896295420825481\n",
      "Iteration 2050, Loss: 0.00027427944587543607\n",
      "Iteration 2060, Loss: 0.0006078236037865281\n",
      "Iteration 2070, Loss: 0.0001632204366615042\n",
      "Iteration 2080, Loss: 0.00021003367146477103\n",
      "Iteration 2090, Loss: 0.00023431284353137016\n",
      "Iteration 2100, Loss: 0.0002243716735392809\n",
      "Iteration 2110, Loss: 0.0001986183924600482\n",
      "Iteration 2120, Loss: 0.0001868025428848341\n",
      "Iteration 2130, Loss: 0.00019071184215135872\n",
      "Iteration 2140, Loss: 0.00031294344807974994\n",
      "Iteration 2150, Loss: 0.0003837267868220806\n",
      "Iteration 2160, Loss: 0.00017487912555225194\n",
      "Iteration 2170, Loss: 0.0012790560722351074\n",
      "Iteration 2180, Loss: 0.00015823033754713833\n",
      "Iteration 2190, Loss: 0.0001741204468999058\n",
      "Iteration 2200, Loss: 0.00016892937128432095\n",
      "Iteration 2210, Loss: 0.0002335081371711567\n",
      "Iteration 2220, Loss: 0.0013970450963824987\n",
      "Iteration 2230, Loss: 0.0003251736343372613\n",
      "Iteration 2240, Loss: 0.0001975473278434947\n",
      "Iteration 2250, Loss: 0.00015877292025834322\n",
      "Iteration 2260, Loss: 0.0004744744801428169\n",
      "Iteration 2270, Loss: 0.00017696777649689466\n",
      "Iteration 2280, Loss: 0.000258756015682593\n",
      "Iteration 2290, Loss: 0.00016339360445272177\n",
      "Iteration 2300, Loss: 0.0008644998306408525\n",
      "Iteration 2310, Loss: 0.0033029995393007994\n",
      "Iteration 2320, Loss: 0.0011308683315292\n",
      "Iteration 2330, Loss: 0.0005411552847363055\n",
      "Iteration 2340, Loss: 0.0005412943428382277\n",
      "Iteration 2350, Loss: 0.00015602976782247424\n",
      "Iteration 2360, Loss: 0.0002829022123478353\n",
      "Iteration 2370, Loss: 0.00014506850857287645\n",
      "Iteration 2380, Loss: 0.00015361786063294858\n",
      "Iteration 2390, Loss: 0.00020785648666787893\n",
      "Iteration 2400, Loss: 0.00014943281712476164\n",
      "Iteration 2410, Loss: 0.00014807420666329563\n",
      "Iteration 2420, Loss: 0.0001424809015588835\n",
      "Iteration 2430, Loss: 0.00017223066242877394\n",
      "Iteration 2440, Loss: 0.00019493658328428864\n",
      "Iteration 2450, Loss: 0.0002077267417917028\n",
      "Iteration 2460, Loss: 0.001828596694394946\n",
      "Iteration 2470, Loss: 0.000885344110429287\n",
      "Iteration 2480, Loss: 0.0003235311305616051\n",
      "Iteration 2490, Loss: 0.0003052957181353122\n",
      "Iteration 2500, Loss: 0.0003279557859059423\n",
      "Iteration 2510, Loss: 0.00016742624575272202\n",
      "Iteration 2520, Loss: 0.00014100424596108496\n",
      "Iteration 2530, Loss: 0.0008510934421792626\n",
      "Iteration 2540, Loss: 0.00014072742487769574\n",
      "Iteration 2550, Loss: 0.00014278737944550812\n",
      "Iteration 2560, Loss: 0.00016730328206904233\n",
      "Iteration 2570, Loss: 0.0006480278680101037\n",
      "Iteration 2580, Loss: 0.000911830342374742\n",
      "Iteration 2590, Loss: 0.0010037797037512064\n",
      "Iteration 2600, Loss: 0.000665926025249064\n",
      "Iteration 2610, Loss: 0.00013122023665346205\n",
      "Iteration 2620, Loss: 0.00013713275257032365\n",
      "Iteration 2630, Loss: 0.001298026298172772\n",
      "Iteration 2640, Loss: 0.0002967713517136872\n",
      "Iteration 2650, Loss: 0.0004062122607138008\n",
      "Iteration 2660, Loss: 0.00013922835933044553\n",
      "Iteration 2670, Loss: 0.00015326848370023072\n",
      "Iteration 2680, Loss: 0.0014359864871948957\n",
      "Iteration 2690, Loss: 0.0003304676210973412\n",
      "Iteration 2700, Loss: 0.00024568208027631044\n",
      "Iteration 2710, Loss: 0.0001470270799472928\n",
      "Iteration 2720, Loss: 0.00021411456691566855\n",
      "Iteration 2730, Loss: 0.00013778015272691846\n",
      "Iteration 2740, Loss: 0.0002920184633694589\n",
      "Iteration 2750, Loss: 0.00020776130259037018\n",
      "Iteration 2760, Loss: 0.0007211263873614371\n",
      "Iteration 2770, Loss: 0.005742200650274754\n",
      "Iteration 2780, Loss: 0.001086513395421207\n",
      "Iteration 2790, Loss: 0.000173501786775887\n",
      "Iteration 2800, Loss: 0.0007121949456632137\n",
      "Iteration 2810, Loss: 0.0001603144482942298\n",
      "Iteration 2820, Loss: 0.00015527161303907633\n",
      "Iteration 2830, Loss: 0.00015462700685020536\n",
      "Iteration 2840, Loss: 0.00012867533951066434\n",
      "Iteration 2850, Loss: 0.00014357917825691402\n",
      "Iteration 2860, Loss: 0.0002412991743767634\n",
      "Iteration 2870, Loss: 0.00012034560495521873\n",
      "Iteration 2880, Loss: 0.00011837388592539355\n",
      "Iteration 2890, Loss: 0.000595125718973577\n",
      "Iteration 2900, Loss: 0.00015420779527630657\n",
      "Iteration 2910, Loss: 0.000275678321486339\n",
      "Iteration 2920, Loss: 0.0019465310033410788\n",
      "Iteration 2930, Loss: 0.0002086049207719043\n",
      "Iteration 2940, Loss: 0.0002538431726861745\n",
      "Iteration 2950, Loss: 0.00020853488240391016\n",
      "Iteration 2960, Loss: 0.00012220141070429236\n",
      "Iteration 2970, Loss: 0.002386088715866208\n",
      "Iteration 2980, Loss: 0.0002458485250826925\n",
      "Iteration 2990, Loss: 0.00011507282761158422\n",
      "Iteration 3000, Loss: 0.0001547429128549993\n",
      "Iteration 3010, Loss: 0.00014252809341996908\n",
      "Iteration 3020, Loss: 0.00014108791947364807\n",
      "Iteration 3030, Loss: 0.00011449489102233201\n",
      "Iteration 3040, Loss: 0.00011218748841201887\n",
      "Iteration 3050, Loss: 0.0006587202078662813\n",
      "Iteration 3060, Loss: 0.0003745064605027437\n",
      "Iteration 3070, Loss: 0.00011331732821417972\n",
      "Iteration 3080, Loss: 0.0002783793315757066\n",
      "Iteration 3090, Loss: 0.0007081582443788648\n",
      "Iteration 3100, Loss: 0.00027558088186196983\n",
      "Iteration 3110, Loss: 0.0001269863423658535\n",
      "Iteration 3120, Loss: 0.0002219861198682338\n",
      "Iteration 3130, Loss: 0.005948299076408148\n",
      "Iteration 3140, Loss: 0.0005581952282227576\n",
      "Iteration 3150, Loss: 0.00030106864869594574\n",
      "Iteration 3160, Loss: 0.00026233616517856717\n",
      "Iteration 3170, Loss: 0.00020671059610322118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  75%|███████▌  | 18/24 [13:43<05:10, 51.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3180, Loss: 0.0001251391222467646\n",
      "Stopping early at iteration 3183\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 3184, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.015062025810819848, 'L2_avg': 0.01912930138985077, 'End_point_L1_avg': 0.011581402322632458, 'End_point_L2_avg': 0.012939329283699336}\n",
      "Iteration 0, Loss: 1.3174850940704346\n",
      "Iteration 10, Loss: 0.10891776531934738\n",
      "Iteration 20, Loss: 0.09563564509153366\n",
      "Iteration 30, Loss: 0.041386693716049194\n",
      "Iteration 40, Loss: 0.025743678212165833\n",
      "Iteration 50, Loss: 0.01961343362927437\n",
      "Iteration 60, Loss: 0.012694518081843853\n",
      "Iteration 70, Loss: 0.010423297062516212\n",
      "Iteration 80, Loss: 0.008075179532170296\n",
      "Iteration 90, Loss: 0.006226369179785252\n",
      "Iteration 100, Loss: 0.005266772583127022\n",
      "Iteration 110, Loss: 0.004581403452903032\n",
      "Iteration 120, Loss: 0.0036882138811051846\n",
      "Iteration 130, Loss: 0.003716676728799939\n",
      "Iteration 140, Loss: 0.0031817832496017218\n",
      "Iteration 150, Loss: 0.002881883643567562\n",
      "Iteration 160, Loss: 0.0028199832886457443\n",
      "Iteration 170, Loss: 0.002738053211942315\n",
      "Iteration 180, Loss: 0.002503535710275173\n",
      "Iteration 190, Loss: 0.0024319926742464304\n",
      "Iteration 200, Loss: 0.0024377070367336273\n",
      "Iteration 210, Loss: 0.0022691921330988407\n",
      "Iteration 220, Loss: 0.0022183009423315525\n",
      "Iteration 230, Loss: 0.002140420489013195\n",
      "Iteration 240, Loss: 0.002137993462383747\n",
      "Iteration 250, Loss: 0.0020821315702050924\n",
      "Iteration 260, Loss: 0.0021270145662128925\n",
      "Iteration 270, Loss: 0.0021063475869596004\n",
      "Iteration 280, Loss: 0.0019386612111702561\n",
      "Iteration 290, Loss: 0.0019079598132520914\n",
      "Iteration 300, Loss: 0.0018846610328182578\n",
      "Iteration 310, Loss: 0.0018656227039173245\n",
      "Iteration 320, Loss: 0.0018851413624361157\n",
      "Iteration 330, Loss: 0.001805253908969462\n",
      "Iteration 340, Loss: 0.0017431763699278235\n",
      "Iteration 350, Loss: 0.001689905533567071\n",
      "Iteration 360, Loss: 0.00161385303363204\n",
      "Iteration 370, Loss: 0.0015704724937677383\n",
      "Iteration 380, Loss: 0.0015708768041804433\n",
      "Iteration 390, Loss: 0.0016334491083398461\n",
      "Iteration 400, Loss: 0.001549321343190968\n",
      "Iteration 410, Loss: 0.0014860148075968027\n",
      "Iteration 420, Loss: 0.001399385742843151\n",
      "Iteration 430, Loss: 0.0014597011031582952\n",
      "Iteration 440, Loss: 0.0014188484055921435\n",
      "Iteration 450, Loss: 0.0013916277093812823\n",
      "Iteration 460, Loss: 0.0013577706413343549\n",
      "Iteration 470, Loss: 0.0013515501050278544\n",
      "Iteration 480, Loss: 0.0012932544341310859\n",
      "Iteration 490, Loss: 0.0012777154333889484\n",
      "Iteration 500, Loss: 0.0012490575900301337\n",
      "Iteration 510, Loss: 0.0011845470871776342\n",
      "Iteration 520, Loss: 0.0011719961185008287\n",
      "Iteration 530, Loss: 0.0011578811099752784\n",
      "Iteration 540, Loss: 0.0011688555823639035\n",
      "Iteration 550, Loss: 0.001098213018849492\n",
      "Iteration 560, Loss: 0.0010840418981388211\n",
      "Iteration 570, Loss: 0.0010928831761702895\n",
      "Iteration 580, Loss: 0.0010505886748433113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  79%|███████▉  | 19/24 [13:54<03:19, 39.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 590, Loss: 0.0010426833759993315\n",
      "Stopping early at iteration 593\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 594, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0454694647354304, 'L2_avg': 0.05805069390627891, 'End_point_L1_avg': 0.025136236982065054, 'End_point_L2_avg': 0.025136385398771083}\n",
      "Iteration 0, Loss: 1.0007226467132568\n",
      "Iteration 10, Loss: 0.1389085054397583\n",
      "Iteration 20, Loss: 0.09699921309947968\n",
      "Iteration 30, Loss: 0.051855750381946564\n",
      "Iteration 40, Loss: 0.03191429376602173\n",
      "Iteration 50, Loss: 0.023081278428435326\n",
      "Iteration 60, Loss: 0.018144944682717323\n",
      "Iteration 70, Loss: 0.012770378962159157\n",
      "Iteration 80, Loss: 0.010692855343222618\n",
      "Iteration 90, Loss: 0.008239625953137875\n",
      "Iteration 100, Loss: 0.007666429504752159\n",
      "Iteration 110, Loss: 0.006282381247729063\n",
      "Iteration 120, Loss: 0.00558420130982995\n",
      "Iteration 130, Loss: 0.005167994182556868\n",
      "Iteration 140, Loss: 0.004427973181009293\n",
      "Iteration 150, Loss: 0.004097193479537964\n",
      "Iteration 160, Loss: 0.004184646066278219\n",
      "Iteration 170, Loss: 0.003893127664923668\n",
      "Iteration 180, Loss: 0.003450759220868349\n",
      "Iteration 190, Loss: 0.003275774884968996\n",
      "Iteration 200, Loss: 0.0029899009969085455\n",
      "Iteration 210, Loss: 0.00295382016338408\n",
      "Iteration 220, Loss: 0.0026045218110084534\n",
      "Iteration 230, Loss: 0.0025072162970900536\n",
      "Iteration 240, Loss: 0.0025782561860978603\n",
      "Iteration 250, Loss: 0.0024784267880022526\n",
      "Iteration 260, Loss: 0.00248808809556067\n",
      "Iteration 270, Loss: 0.0022679930552840233\n",
      "Iteration 280, Loss: 0.002071316819638014\n",
      "Iteration 290, Loss: 0.002228204859420657\n",
      "Iteration 300, Loss: 0.0021757122594863176\n",
      "Iteration 310, Loss: 0.0019463233184069395\n",
      "Iteration 320, Loss: 0.001992663135752082\n",
      "Iteration 330, Loss: 0.0019251464400440454\n",
      "Iteration 340, Loss: 0.001935359206981957\n",
      "Iteration 350, Loss: 0.0018247858388349414\n",
      "Iteration 360, Loss: 0.0017853269819170237\n",
      "Iteration 370, Loss: 0.001801077974960208\n",
      "Iteration 380, Loss: 0.001658427994698286\n",
      "Iteration 390, Loss: 0.0016981224762275815\n",
      "Iteration 400, Loss: 0.0017282115295529366\n",
      "Iteration 410, Loss: 0.0016531829023733735\n",
      "Iteration 420, Loss: 0.0015584910288453102\n",
      "Iteration 430, Loss: 0.0015204737428575754\n",
      "Iteration 440, Loss: 0.001536700176075101\n",
      "Iteration 450, Loss: 0.001406845636665821\n",
      "Iteration 460, Loss: 0.0014640595763921738\n",
      "Iteration 470, Loss: 0.001414577942341566\n",
      "Iteration 480, Loss: 0.0014345445670187473\n",
      "Iteration 490, Loss: 0.0013729477068409324\n",
      "Iteration 500, Loss: 0.0013325370382517576\n",
      "Iteration 510, Loss: 0.0012996237492188811\n",
      "Iteration 520, Loss: 0.0013147391146048903\n",
      "Iteration 530, Loss: 0.0012320756213739514\n",
      "Iteration 540, Loss: 0.0012573999119922519\n",
      "Iteration 550, Loss: 0.0011770239798352122\n",
      "Iteration 560, Loss: 0.001171947456896305\n",
      "Iteration 570, Loss: 0.0011294486466795206\n",
      "Iteration 580, Loss: 0.0010707256151363254\n",
      "Iteration 590, Loss: 0.0011065673315897584\n",
      "Iteration 600, Loss: 0.0011044194689020514\n",
      "Iteration 610, Loss: 0.0010379846207797527\n",
      "Iteration 620, Loss: 0.000997460214421153\n",
      "Iteration 630, Loss: 0.0010330920340493321\n",
      "Iteration 640, Loss: 0.000979871954768896\n",
      "Iteration 650, Loss: 0.0009548718808218837\n",
      "Iteration 660, Loss: 0.0009431784274056554\n",
      "Iteration 670, Loss: 0.0009391521452926099\n",
      "Iteration 680, Loss: 0.0009135802974924445\n",
      "Iteration 690, Loss: 0.0008975732489489019\n",
      "Iteration 700, Loss: 0.0008730989648029208\n",
      "Iteration 710, Loss: 0.0008219967712648213\n",
      "Iteration 720, Loss: 0.0008512071799486876\n",
      "Iteration 730, Loss: 0.0008172891102731228\n",
      "Iteration 740, Loss: 0.0008131221984513104\n",
      "Iteration 750, Loss: 0.0007757646380923688\n",
      "Iteration 760, Loss: 0.0007505076937377453\n",
      "Iteration 770, Loss: 0.0007777893333695829\n",
      "Iteration 780, Loss: 0.0007608680170960724\n",
      "Iteration 790, Loss: 0.0006731700850650668\n",
      "Iteration 800, Loss: 0.0007417488377541304\n",
      "Iteration 810, Loss: 0.0007058242335915565\n",
      "Iteration 820, Loss: 0.0006975542637519538\n",
      "Iteration 830, Loss: 0.0006968294619582593\n",
      "Iteration 840, Loss: 0.0007034037844277918\n",
      "Iteration 850, Loss: 0.000646841072011739\n",
      "Iteration 860, Loss: 0.0006792976055294275\n",
      "Iteration 870, Loss: 0.0006369850016199052\n",
      "Iteration 880, Loss: 0.000607962894719094\n",
      "Iteration 890, Loss: 0.0006218726630322635\n",
      "Iteration 900, Loss: 0.0006049684016034007\n",
      "Iteration 910, Loss: 0.0005721276393160224\n",
      "Iteration 920, Loss: 0.0005883899284526706\n",
      "Iteration 930, Loss: 0.0005604253965429962\n",
      "Iteration 940, Loss: 0.0005608717910945415\n",
      "Iteration 950, Loss: 0.0005913218483328819\n",
      "Iteration 960, Loss: 0.0005624531186185777\n",
      "Iteration 970, Loss: 0.0005321715725585818\n",
      "Iteration 980, Loss: 0.0005334681482054293\n",
      "Iteration 990, Loss: 0.0005359648494049907\n",
      "Iteration 1000, Loss: 0.0005455766804516315\n",
      "Iteration 1010, Loss: 0.0005269229295663536\n",
      "Iteration 1020, Loss: 0.0005572435911744833\n",
      "Iteration 1030, Loss: 0.000504590047057718\n",
      "Iteration 1040, Loss: 0.000498275039717555\n",
      "Iteration 1050, Loss: 0.0004973349859938025\n",
      "Iteration 1060, Loss: 0.0005229913513176143\n",
      "Iteration 1070, Loss: 0.0004718473646789789\n",
      "Iteration 1080, Loss: 0.00046661123633384705\n",
      "Iteration 1090, Loss: 0.0004456856404431164\n",
      "Iteration 1100, Loss: 0.0005153365200385451\n",
      "Iteration 1110, Loss: 0.00045738782500848174\n",
      "Iteration 1120, Loss: 0.00043920372263528407\n",
      "Iteration 1130, Loss: 0.0007751506054773927\n",
      "Iteration 1140, Loss: 0.0005094690714031458\n",
      "Iteration 1150, Loss: 0.0007562468526884913\n",
      "Iteration 1160, Loss: 0.0008787757251411676\n",
      "Iteration 1170, Loss: 0.00042171101085841656\n",
      "Iteration 1180, Loss: 0.0004423525824677199\n",
      "Iteration 1190, Loss: 0.00039058952825143933\n",
      "Iteration 1200, Loss: 0.0007221572450362146\n",
      "Iteration 1210, Loss: 0.003438991727307439\n",
      "Iteration 1220, Loss: 0.0004010357370134443\n",
      "Iteration 1230, Loss: 0.000938552722800523\n",
      "Iteration 1240, Loss: 0.00037238840013742447\n",
      "Iteration 1250, Loss: 0.00035692003439180553\n",
      "Iteration 1260, Loss: 0.00037567861727438867\n",
      "Iteration 1270, Loss: 0.0003546360821928829\n",
      "Iteration 1280, Loss: 0.00035670623765327036\n",
      "Iteration 1290, Loss: 0.0003591864078771323\n",
      "Iteration 1300, Loss: 0.0004619570099748671\n",
      "Iteration 1310, Loss: 0.0005671360995620489\n",
      "Iteration 1320, Loss: 0.00037863384932279587\n",
      "Iteration 1330, Loss: 0.00042363672400824726\n",
      "Iteration 1340, Loss: 0.0003342916024848819\n",
      "Iteration 1350, Loss: 0.000672397727612406\n",
      "Iteration 1360, Loss: 0.003157935570925474\n",
      "Iteration 1370, Loss: 0.0014447876019403338\n",
      "Iteration 1380, Loss: 0.0007641678676009178\n",
      "Iteration 1390, Loss: 0.0003460865991655737\n",
      "Iteration 1400, Loss: 0.0004160693206358701\n",
      "Iteration 1410, Loss: 0.0003100557660218328\n",
      "Iteration 1420, Loss: 0.00029766536317765713\n",
      "Iteration 1430, Loss: 0.0004506484547164291\n",
      "Iteration 1440, Loss: 0.00033584533957764506\n",
      "Iteration 1450, Loss: 0.0011306931264698505\n",
      "Iteration 1460, Loss: 0.00026925824931822717\n",
      "Iteration 1470, Loss: 0.0005373791791498661\n",
      "Iteration 1480, Loss: 0.0007042046636343002\n",
      "Iteration 1490, Loss: 0.0005519420956261456\n",
      "Iteration 1500, Loss: 0.000906892993953079\n",
      "Iteration 1510, Loss: 0.00045414752094075084\n",
      "Iteration 1520, Loss: 0.0004888524417765439\n",
      "Iteration 1530, Loss: 0.00071619515074417\n",
      "Iteration 1540, Loss: 0.0003610347048379481\n",
      "Iteration 1550, Loss: 0.00025741683202795684\n",
      "Iteration 1560, Loss: 0.00026161345886066556\n",
      "Iteration 1570, Loss: 0.000251035118708387\n",
      "Iteration 1580, Loss: 0.00044129337766207755\n",
      "Iteration 1590, Loss: 0.012101980857551098\n",
      "Iteration 1600, Loss: 0.0014153526863083243\n",
      "Iteration 1610, Loss: 0.0006916411221027374\n",
      "Iteration 1620, Loss: 0.00036000044201500714\n",
      "Iteration 1630, Loss: 0.0002702031342778355\n",
      "Iteration 1640, Loss: 0.00024649000260978937\n",
      "Iteration 1650, Loss: 0.00022036448353901505\n",
      "Iteration 1660, Loss: 0.0002227777149528265\n",
      "Iteration 1670, Loss: 0.00024533626856282353\n",
      "Iteration 1680, Loss: 0.00022484257351607084\n",
      "Iteration 1690, Loss: 0.0002175014524254948\n",
      "Iteration 1700, Loss: 0.00021599448518827558\n",
      "Iteration 1710, Loss: 0.0002305028319824487\n",
      "Iteration 1720, Loss: 0.00021483833552338183\n",
      "Iteration 1730, Loss: 0.00020817911718040705\n",
      "Iteration 1740, Loss: 0.0002455752110108733\n",
      "Iteration 1750, Loss: 0.00020409896387718618\n",
      "Iteration 1760, Loss: 0.0002043045242317021\n",
      "Iteration 1770, Loss: 0.00019608074217103422\n",
      "Iteration 1780, Loss: 0.00023334499564953148\n",
      "Iteration 1790, Loss: 0.00021180574549362063\n",
      "Iteration 1800, Loss: 0.0002045891305897385\n",
      "Iteration 1810, Loss: 0.0004333475953899324\n",
      "Iteration 1820, Loss: 0.00759507343173027\n",
      "Iteration 1830, Loss: 0.0018119768938049674\n",
      "Iteration 1840, Loss: 0.0007415107102133334\n",
      "Iteration 1850, Loss: 0.0003187176480423659\n",
      "Iteration 1860, Loss: 0.00026972551131621003\n",
      "Iteration 1870, Loss: 0.00020758490427397192\n",
      "Iteration 1880, Loss: 0.000196338354726322\n",
      "Iteration 1890, Loss: 0.00019621230603661388\n",
      "Iteration 1900, Loss: 0.00023032921308185905\n",
      "Iteration 1910, Loss: 0.00019502866780385375\n",
      "Iteration 1920, Loss: 0.0001925593096530065\n",
      "Iteration 1930, Loss: 0.00018170051043853164\n",
      "Iteration 1940, Loss: 0.0002492101048119366\n",
      "Iteration 1950, Loss: 0.000286220689304173\n",
      "Iteration 1960, Loss: 0.0004913572920486331\n",
      "Iteration 1970, Loss: 0.00027140582096762955\n",
      "Iteration 1980, Loss: 0.0007070912979543209\n",
      "Iteration 1990, Loss: 0.0008518416434526443\n",
      "Iteration 2000, Loss: 0.00028518488397821784\n",
      "Iteration 2010, Loss: 0.0006569374818354845\n",
      "Iteration 2020, Loss: 0.000721238786354661\n",
      "Iteration 2030, Loss: 0.0002720050106290728\n",
      "Iteration 2040, Loss: 0.00023563997820019722\n",
      "Iteration 2050, Loss: 0.0004133749462198466\n",
      "Iteration 2060, Loss: 0.0016761156730353832\n",
      "Iteration 2070, Loss: 0.00033834201167337596\n",
      "Iteration 2080, Loss: 0.0008063616114668548\n",
      "Iteration 2090, Loss: 0.0003996229206677526\n",
      "Iteration 2100, Loss: 0.00037884755874983966\n",
      "Iteration 2110, Loss: 0.0003660009824670851\n",
      "Iteration 2120, Loss: 0.00019658314704429358\n",
      "Iteration 2130, Loss: 0.00025205346173606813\n",
      "Iteration 2140, Loss: 0.00020901933021377772\n",
      "Iteration 2150, Loss: 0.00015790783800184727\n",
      "Iteration 2160, Loss: 0.000169558625202626\n",
      "Iteration 2170, Loss: 0.0009646064136177301\n",
      "Iteration 2180, Loss: 0.00398394837975502\n",
      "Iteration 2190, Loss: 0.0015031612711027265\n",
      "Iteration 2200, Loss: 0.0001613930071471259\n",
      "Iteration 2210, Loss: 0.0003772084310185164\n",
      "Iteration 2220, Loss: 0.00019072240684181452\n",
      "Iteration 2230, Loss: 0.0001509507856098935\n",
      "Iteration 2240, Loss: 0.0001537474599899724\n",
      "Iteration 2250, Loss: 0.00015004133456386626\n",
      "Iteration 2260, Loss: 0.0001621046249056235\n",
      "Iteration 2270, Loss: 0.00015455501852557063\n",
      "Iteration 2280, Loss: 0.00015316878852900118\n",
      "Iteration 2290, Loss: 0.00015386883751489222\n",
      "Iteration 2300, Loss: 0.00019423151388764381\n",
      "Iteration 2310, Loss: 0.0001843464997364208\n",
      "Iteration 2320, Loss: 0.00015519266889896244\n",
      "Iteration 2330, Loss: 0.00015360661200247705\n",
      "Iteration 2340, Loss: 0.0003110558318439871\n",
      "Iteration 2350, Loss: 0.00014317025488708168\n",
      "Iteration 2360, Loss: 0.0001518925273558125\n",
      "Iteration 2370, Loss: 0.00013824657071381807\n",
      "Iteration 2380, Loss: 0.00015976271242834628\n",
      "Iteration 2390, Loss: 0.002463418524712324\n",
      "Iteration 2400, Loss: 0.004931851755827665\n",
      "Iteration 2410, Loss: 0.0008271171245723963\n",
      "Iteration 2420, Loss: 0.0008216957212425768\n",
      "Iteration 2430, Loss: 0.0005234802374616265\n",
      "Iteration 2440, Loss: 0.00022841551981400698\n",
      "Iteration 2450, Loss: 0.00019441175390966237\n",
      "Iteration 2460, Loss: 0.0001562540710438043\n",
      "Iteration 2470, Loss: 0.00014413883036468178\n",
      "Iteration 2480, Loss: 0.00013498967746272683\n",
      "Iteration 2490, Loss: 0.0001307784259552136\n",
      "Iteration 2500, Loss: 0.00013017025776207447\n",
      "Iteration 2510, Loss: 0.00013182211841922253\n",
      "Iteration 2520, Loss: 0.00013723771553486586\n",
      "Iteration 2530, Loss: 0.00013743084855377674\n",
      "Iteration 2540, Loss: 0.00012649098061956465\n",
      "Iteration 2550, Loss: 0.00012908049393445253\n",
      "Iteration 2560, Loss: 0.00012939014413859695\n",
      "Iteration 2570, Loss: 0.00012649968266487122\n",
      "Iteration 2580, Loss: 0.00013287736510392278\n",
      "Iteration 2590, Loss: 0.00012341051478870213\n",
      "Iteration 2600, Loss: 0.00012436407268978655\n",
      "Iteration 2610, Loss: 0.0001261598663404584\n",
      "Iteration 2620, Loss: 0.00017968950851354748\n",
      "Iteration 2630, Loss: 0.00012494150723796338\n",
      "Iteration 2640, Loss: 0.00029655182152055204\n",
      "Iteration 2650, Loss: 0.0009430331410840154\n",
      "Iteration 2660, Loss: 0.0008896588115021586\n",
      "Iteration 2670, Loss: 0.00014762634236831218\n",
      "Iteration 2680, Loss: 0.00013244629371911287\n",
      "Iteration 2690, Loss: 0.00014850054867565632\n",
      "Iteration 2700, Loss: 0.0014471202157437801\n",
      "Iteration 2710, Loss: 0.00020594398665707558\n",
      "Iteration 2720, Loss: 0.00033531509689055383\n",
      "Iteration 2730, Loss: 0.0006538003799505532\n",
      "Iteration 2740, Loss: 0.0003540881152730435\n",
      "Iteration 2750, Loss: 0.00020698948355857283\n",
      "Iteration 2760, Loss: 0.00014913886843714863\n",
      "Iteration 2770, Loss: 0.00014571061183232814\n",
      "Iteration 2780, Loss: 0.00016263304860331118\n",
      "Iteration 2790, Loss: 0.00020506828150246292\n",
      "Iteration 2800, Loss: 0.0003282782854512334\n",
      "Iteration 2810, Loss: 0.0001746814523357898\n",
      "Iteration 2820, Loss: 0.00017518385720904917\n",
      "Iteration 2830, Loss: 0.00017204094910994172\n",
      "Iteration 2840, Loss: 0.00026674740365706384\n",
      "Iteration 2850, Loss: 0.0012100195745006204\n",
      "Iteration 2860, Loss: 0.0020890841260552406\n",
      "Iteration 2870, Loss: 0.0008267893572337925\n",
      "Iteration 2880, Loss: 0.000447391124907881\n",
      "Iteration 2890, Loss: 0.0003577994357328862\n",
      "Iteration 2900, Loss: 0.00019876626902259886\n",
      "Iteration 2910, Loss: 0.00011476940562715754\n",
      "Iteration 2920, Loss: 0.0001757358550094068\n",
      "Iteration 2930, Loss: 0.00026317668380215764\n",
      "Iteration 2940, Loss: 0.00043576356256380677\n",
      "Iteration 2950, Loss: 0.0026575708761811256\n",
      "Iteration 2960, Loss: 0.000303585606161505\n",
      "Iteration 2970, Loss: 0.0001124577465816401\n",
      "Iteration 2980, Loss: 0.00010682928405003622\n",
      "Iteration 2990, Loss: 0.00011680404713843018\n",
      "Iteration 3000, Loss: 0.00010534337343415245\n",
      "Iteration 3010, Loss: 0.00010148930596187711\n",
      "Iteration 3020, Loss: 0.00012449818314053118\n",
      "Iteration 3030, Loss: 0.000355500727891922\n",
      "Iteration 3040, Loss: 0.0067108809016644955\n",
      "Iteration 3050, Loss: 0.002685273066163063\n",
      "Iteration 3060, Loss: 0.00010257044050376862\n",
      "Iteration 3070, Loss: 0.0003725664864759892\n",
      "Iteration 3080, Loss: 0.0001351006212644279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  83%|████████▎ | 20/24 [14:55<03:03, 45.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 3089\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 3090, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014738459061141504, 'L2_avg': 0.018609817987041692, 'End_point_L1_avg': 0.011565862274152424, 'End_point_L2_avg': 0.014921437194925604}\n",
      "Iteration 0, Loss: 1.9046854972839355\n",
      "Iteration 10, Loss: 1.2185629606246948\n",
      "Iteration 20, Loss: 1.0275651216506958\n",
      "Iteration 30, Loss: 0.810406506061554\n",
      "Iteration 40, Loss: 0.6526362895965576\n",
      "Iteration 50, Loss: 0.5186553001403809\n",
      "Iteration 60, Loss: 0.4135047495365143\n",
      "Iteration 70, Loss: 0.33615243434906006\n",
      "Iteration 80, Loss: 0.2658475637435913\n",
      "Iteration 90, Loss: 0.2142435908317566\n",
      "Iteration 100, Loss: 0.17388996481895447\n",
      "Iteration 110, Loss: 0.1447087824344635\n",
      "Iteration 120, Loss: 0.12133698165416718\n",
      "Iteration 130, Loss: 0.1044425517320633\n",
      "Iteration 140, Loss: 0.08554567396640778\n",
      "Iteration 150, Loss: 0.08412198722362518\n",
      "Iteration 160, Loss: 0.0718836635351181\n",
      "Iteration 170, Loss: 0.06326943635940552\n",
      "Iteration 180, Loss: 0.0585399828851223\n",
      "Iteration 190, Loss: 0.05520685017108917\n",
      "Iteration 200, Loss: 0.0508824959397316\n",
      "Iteration 210, Loss: 0.04596755653619766\n",
      "Iteration 220, Loss: 0.0386827178299427\n",
      "Iteration 230, Loss: 0.047339536249637604\n",
      "Iteration 240, Loss: 0.03785519301891327\n",
      "Iteration 250, Loss: 0.0327557697892189\n",
      "Iteration 260, Loss: 0.03497748449444771\n",
      "Iteration 270, Loss: 0.03449973091483116\n",
      "Iteration 280, Loss: 0.03402826189994812\n",
      "Iteration 290, Loss: 0.030680956318974495\n",
      "Iteration 300, Loss: 0.02943415194749832\n",
      "Iteration 310, Loss: 0.02290661819279194\n",
      "Iteration 320, Loss: 0.030559595674276352\n",
      "Iteration 330, Loss: 0.0217864029109478\n",
      "Iteration 340, Loss: 0.021821951493620872\n",
      "Iteration 350, Loss: 0.025541093200445175\n",
      "Iteration 360, Loss: 0.01902584359049797\n",
      "Iteration 370, Loss: 0.01982492208480835\n",
      "Iteration 380, Loss: 0.02031191997230053\n",
      "Iteration 390, Loss: 0.014287653379142284\n",
      "Iteration 400, Loss: 0.01925724744796753\n",
      "Iteration 410, Loss: 0.018206505104899406\n",
      "Iteration 420, Loss: 0.017025485634803772\n",
      "Iteration 430, Loss: 0.01572091318666935\n",
      "Iteration 440, Loss: 0.01648370362818241\n",
      "Iteration 450, Loss: 0.01757141575217247\n",
      "Iteration 460, Loss: 0.01578918658196926\n",
      "Iteration 470, Loss: 0.015259893611073494\n",
      "Iteration 480, Loss: 0.014837712049484253\n",
      "Iteration 490, Loss: 0.01684916391968727\n",
      "Iteration 500, Loss: 0.016030244529247284\n",
      "Iteration 510, Loss: 0.014528011903166771\n",
      "Iteration 520, Loss: 0.012045059353113174\n",
      "Iteration 530, Loss: 0.013659175485372543\n",
      "Iteration 540, Loss: 0.01140398345887661\n",
      "Iteration 550, Loss: 0.01184162963181734\n",
      "Iteration 560, Loss: 0.010716577060520649\n",
      "Iteration 570, Loss: 0.010475775226950645\n",
      "Iteration 580, Loss: 0.010904780589044094\n",
      "Iteration 590, Loss: 0.011379857547581196\n",
      "Iteration 600, Loss: 0.009487527422606945\n",
      "Iteration 610, Loss: 0.00815943256020546\n",
      "Iteration 620, Loss: 0.008872692473232746\n",
      "Iteration 630, Loss: 0.007786600384861231\n",
      "Iteration 640, Loss: 0.009848539717495441\n",
      "Iteration 650, Loss: 0.006978090386837721\n",
      "Iteration 660, Loss: 0.00855756364762783\n",
      "Iteration 670, Loss: 0.0081704743206501\n",
      "Iteration 680, Loss: 0.008195485919713974\n",
      "Iteration 690, Loss: 0.007108256220817566\n",
      "Iteration 700, Loss: 0.00712421303614974\n",
      "Iteration 710, Loss: 0.007205162197351456\n",
      "Iteration 720, Loss: 0.00753382733091712\n",
      "Iteration 730, Loss: 0.008638317696750164\n",
      "Iteration 740, Loss: 0.006051497533917427\n",
      "Iteration 750, Loss: 0.006238928996026516\n",
      "Iteration 760, Loss: 0.007025982718914747\n",
      "Iteration 770, Loss: 0.006436181254684925\n",
      "Iteration 780, Loss: 0.006457350682467222\n",
      "Iteration 790, Loss: 0.006433183327317238\n",
      "Iteration 800, Loss: 0.006564906798303127\n",
      "Iteration 810, Loss: 0.00547095388174057\n",
      "Iteration 820, Loss: 0.005746362265199423\n",
      "Iteration 830, Loss: 0.004845221061259508\n",
      "Iteration 840, Loss: 0.005107406992465258\n",
      "Iteration 850, Loss: 0.004758836235851049\n",
      "Iteration 860, Loss: 0.004954156000167131\n",
      "Iteration 870, Loss: 0.0046714898198843\n",
      "Iteration 880, Loss: 0.00449336739256978\n",
      "Iteration 890, Loss: 0.004972133785486221\n",
      "Iteration 900, Loss: 0.004282213281840086\n",
      "Iteration 910, Loss: 0.004960956051945686\n",
      "Iteration 920, Loss: 0.004334278870373964\n",
      "Iteration 930, Loss: 0.004099467769265175\n",
      "Iteration 940, Loss: 0.004243167117238045\n",
      "Iteration 950, Loss: 0.004045908339321613\n",
      "Iteration 960, Loss: 0.0038710397202521563\n",
      "Iteration 970, Loss: 0.0038951411843299866\n",
      "Iteration 980, Loss: 0.003965705633163452\n",
      "Iteration 990, Loss: 0.003916105721145868\n",
      "Iteration 1000, Loss: 0.004315419588238001\n",
      "Iteration 1010, Loss: 0.004153469577431679\n",
      "Iteration 1020, Loss: 0.004050314426422119\n",
      "Iteration 1030, Loss: 0.004246462136507034\n",
      "Iteration 1040, Loss: 0.003254032228142023\n",
      "Iteration 1050, Loss: 0.0033296721521764994\n",
      "Iteration 1060, Loss: 0.0037667504511773586\n",
      "Iteration 1070, Loss: 0.00342492014169693\n",
      "Iteration 1080, Loss: 0.003666686825454235\n",
      "Iteration 1090, Loss: 0.0036118358839303255\n",
      "Iteration 1100, Loss: 0.0032942891120910645\n",
      "Iteration 1110, Loss: 0.003193603130057454\n",
      "Iteration 1120, Loss: 0.0033359068911522627\n",
      "Iteration 1130, Loss: 0.003482143860310316\n",
      "Iteration 1140, Loss: 0.0033258050680160522\n",
      "Iteration 1150, Loss: 0.0031118150800466537\n",
      "Iteration 1160, Loss: 0.0032850527204573154\n",
      "Iteration 1170, Loss: 0.0034524756483733654\n",
      "Iteration 1180, Loss: 0.003432381199672818\n",
      "Iteration 1190, Loss: 0.0030067709740251303\n",
      "Iteration 1200, Loss: 0.003291025757789612\n",
      "Iteration 1210, Loss: 0.0032980863470584154\n",
      "Iteration 1220, Loss: 0.0026912789326161146\n",
      "Iteration 1230, Loss: 0.002783665433526039\n",
      "Iteration 1240, Loss: 0.002941716695204377\n",
      "Iteration 1250, Loss: 0.003120825160294771\n",
      "Iteration 1260, Loss: 0.0027866922318935394\n",
      "Iteration 1270, Loss: 0.003188990755006671\n",
      "Iteration 1280, Loss: 0.0029270690865814686\n",
      "Iteration 1290, Loss: 0.0035523097030818462\n",
      "Iteration 1300, Loss: 0.002946152351796627\n",
      "Iteration 1310, Loss: 0.0032068355940282345\n",
      "Iteration 1320, Loss: 0.0029466524720191956\n",
      "Iteration 1330, Loss: 0.002805448370054364\n",
      "Iteration 1340, Loss: 0.0028498941101133823\n",
      "Iteration 1350, Loss: 0.0029826387763023376\n",
      "Iteration 1360, Loss: 0.00291038048453629\n",
      "Iteration 1370, Loss: 0.002921935636550188\n",
      "Iteration 1380, Loss: 0.0025639808736741543\n",
      "Iteration 1390, Loss: 0.0028330739587545395\n",
      "Iteration 1400, Loss: 0.0027481871657073498\n",
      "Iteration 1410, Loss: 0.0025612940080463886\n",
      "Iteration 1420, Loss: 0.0025498103350400925\n",
      "Iteration 1430, Loss: 0.002729519037529826\n",
      "Iteration 1440, Loss: 0.002770642749965191\n",
      "Iteration 1450, Loss: 0.002935064258053899\n",
      "Iteration 1460, Loss: 0.0023202039301395416\n",
      "Iteration 1470, Loss: 0.0023944734130054712\n",
      "Iteration 1480, Loss: 0.002288792748004198\n",
      "Iteration 1490, Loss: 0.002733613131567836\n",
      "Iteration 1500, Loss: 0.002550607779994607\n",
      "Iteration 1510, Loss: 0.0026907147839665413\n",
      "Iteration 1520, Loss: 0.0023032622411847115\n",
      "Iteration 1530, Loss: 0.0026359495241194963\n",
      "Iteration 1540, Loss: 0.0024859660770744085\n",
      "Iteration 1550, Loss: 0.0023858563508838415\n",
      "Iteration 1560, Loss: 0.002419303171336651\n",
      "Iteration 1570, Loss: 0.002573113888502121\n",
      "Iteration 1580, Loss: 0.002199231181293726\n",
      "Iteration 1590, Loss: 0.0025417145807296038\n",
      "Iteration 1600, Loss: 0.0023373463191092014\n",
      "Iteration 1610, Loss: 0.0024513867683708668\n",
      "Iteration 1620, Loss: 0.0024375300854444504\n",
      "Iteration 1630, Loss: 0.002381239552050829\n",
      "Iteration 1640, Loss: 0.0022977248299866915\n",
      "Iteration 1650, Loss: 0.0023231005761772394\n",
      "Iteration 1660, Loss: 0.0021280937362462282\n",
      "Iteration 1670, Loss: 0.002163569675758481\n",
      "Iteration 1680, Loss: 0.0023429132997989655\n",
      "Iteration 1690, Loss: 0.002134807873517275\n",
      "Iteration 1700, Loss: 0.002107539912685752\n",
      "Iteration 1710, Loss: 0.0022673008497804403\n",
      "Iteration 1720, Loss: 0.0021945771295577288\n",
      "Iteration 1730, Loss: 0.002042638836428523\n",
      "Iteration 1740, Loss: 0.002534741535782814\n",
      "Iteration 1750, Loss: 0.002055662451311946\n",
      "Iteration 1760, Loss: 0.0021539912559092045\n",
      "Iteration 1770, Loss: 0.002262209542095661\n",
      "Iteration 1780, Loss: 0.002486212644726038\n",
      "Iteration 1790, Loss: 0.0021644877269864082\n",
      "Iteration 1800, Loss: 0.0020520545076578856\n",
      "Iteration 1810, Loss: 0.0020599246490746737\n",
      "Iteration 1820, Loss: 0.0022646950092166662\n",
      "Iteration 1830, Loss: 0.0022090545389801264\n",
      "Iteration 1840, Loss: 0.0020221956074237823\n",
      "Iteration 1850, Loss: 0.0019335242686793208\n",
      "Iteration 1860, Loss: 0.0020593544468283653\n",
      "Iteration 1870, Loss: 0.001990135060623288\n",
      "Iteration 1880, Loss: 0.00210864027030766\n",
      "Iteration 1890, Loss: 0.0022994698956608772\n",
      "Iteration 1900, Loss: 0.0021352532785385847\n",
      "Iteration 1910, Loss: 0.0019305564928799868\n",
      "Iteration 1920, Loss: 0.001985908718779683\n",
      "Iteration 1930, Loss: 0.0017831583973020315\n",
      "Iteration 1940, Loss: 0.0018838605610653758\n",
      "Iteration 1950, Loss: 0.001727128284983337\n",
      "Iteration 1960, Loss: 0.0020374085288494825\n",
      "Iteration 1970, Loss: 0.0020959905814379454\n",
      "Iteration 1980, Loss: 0.0018669364508241415\n",
      "Iteration 1990, Loss: 0.0018076666165143251\n",
      "Iteration 2000, Loss: 0.0016822341131046414\n",
      "Iteration 2010, Loss: 0.0015772617189213634\n",
      "Iteration 2020, Loss: 0.001897818292491138\n",
      "Iteration 2030, Loss: 0.0019478097092360258\n",
      "Iteration 2040, Loss: 0.0020337868481874466\n",
      "Iteration 2050, Loss: 0.0019118121126666665\n",
      "Iteration 2060, Loss: 0.0018357986118644476\n",
      "Iteration 2070, Loss: 0.0017630258807912469\n",
      "Iteration 2080, Loss: 0.0015390050830319524\n",
      "Iteration 2090, Loss: 0.0017653837567195296\n",
      "Iteration 2100, Loss: 0.0016298176487907767\n",
      "Iteration 2110, Loss: 0.001604389282874763\n",
      "Iteration 2120, Loss: 0.001659767935052514\n",
      "Iteration 2130, Loss: 0.0017229611985385418\n",
      "Iteration 2140, Loss: 0.0016568180872127414\n",
      "Iteration 2150, Loss: 0.0016447673551738262\n",
      "Iteration 2160, Loss: 0.0014365117531269789\n",
      "Iteration 2170, Loss: 0.001622842508368194\n",
      "Iteration 2180, Loss: 0.001727534574456513\n",
      "Iteration 2190, Loss: 0.001526810578070581\n",
      "Iteration 2200, Loss: 0.0015766831347718835\n",
      "Iteration 2210, Loss: 0.0016671722987666726\n",
      "Iteration 2220, Loss: 0.0016358010470867157\n",
      "Iteration 2230, Loss: 0.0015538852894678712\n",
      "Iteration 2240, Loss: 0.0017782021313905716\n",
      "Iteration 2250, Loss: 0.0014908916782587767\n",
      "Iteration 2260, Loss: 0.0017812669975683093\n",
      "Iteration 2270, Loss: 0.0016266064485535026\n",
      "Iteration 2280, Loss: 0.001354462350718677\n",
      "Iteration 2290, Loss: 0.0015213554725050926\n",
      "Iteration 2300, Loss: 0.001387026277370751\n",
      "Iteration 2310, Loss: 0.0015442539006471634\n",
      "Iteration 2320, Loss: 0.0014706093352288008\n",
      "Iteration 2330, Loss: 0.0016355260740965605\n",
      "Iteration 2340, Loss: 0.0013531973818317056\n",
      "Iteration 2350, Loss: 0.0013637280790135264\n",
      "Iteration 2360, Loss: 0.0015604362124577165\n",
      "Iteration 2370, Loss: 0.0014248255174607038\n",
      "Iteration 2380, Loss: 0.0014111617347225547\n",
      "Iteration 2390, Loss: 0.0015345850260928273\n",
      "Iteration 2400, Loss: 0.0014902908587828279\n",
      "Iteration 2410, Loss: 0.001411973382346332\n",
      "Iteration 2420, Loss: 0.0012638666667044163\n",
      "Iteration 2430, Loss: 0.0014854994369670749\n",
      "Iteration 2440, Loss: 0.0014757504686713219\n",
      "Iteration 2450, Loss: 0.0013868558453395963\n",
      "Iteration 2460, Loss: 0.001275302143767476\n",
      "Iteration 2470, Loss: 0.0013782603200525045\n",
      "Iteration 2480, Loss: 0.0015356342773884535\n",
      "Iteration 2490, Loss: 0.0013131555169820786\n",
      "Iteration 2500, Loss: 0.001401278073899448\n",
      "Iteration 2510, Loss: 0.0014803600497543812\n",
      "Iteration 2520, Loss: 0.0015729442238807678\n",
      "Iteration 2530, Loss: 0.0015046009793877602\n",
      "Iteration 2540, Loss: 0.0013699275441467762\n",
      "Iteration 2550, Loss: 0.0014618472196161747\n",
      "Iteration 2560, Loss: 0.0013991675805300474\n",
      "Iteration 2570, Loss: 0.0013788589276373386\n",
      "Iteration 2580, Loss: 0.0012784574646502733\n",
      "Iteration 2590, Loss: 0.001269359141588211\n",
      "Iteration 2600, Loss: 0.0014444603584706783\n",
      "Iteration 2610, Loss: 0.0012653724988922477\n",
      "Iteration 2620, Loss: 0.0013796405401080847\n",
      "Iteration 2630, Loss: 0.0012781672412529588\n",
      "Iteration 2640, Loss: 0.001218218356370926\n",
      "Iteration 2650, Loss: 0.001301780459471047\n",
      "Iteration 2660, Loss: 0.0012475025141611695\n",
      "Iteration 2670, Loss: 0.0011985606979578733\n",
      "Iteration 2680, Loss: 0.0012117683654651046\n",
      "Iteration 2690, Loss: 0.0012102399487048388\n",
      "Iteration 2700, Loss: 0.0011845083208754659\n",
      "Iteration 2710, Loss: 0.001266735722310841\n",
      "Iteration 2720, Loss: 0.0011282062623649836\n",
      "Iteration 2730, Loss: 0.001128005445934832\n",
      "Iteration 2740, Loss: 0.001091127167455852\n",
      "Iteration 2750, Loss: 0.0012026590993627906\n",
      "Iteration 2760, Loss: 0.0012279433431103826\n",
      "Iteration 2770, Loss: 0.001072975224815309\n",
      "Stopping early at iteration 2778\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 2779, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04781734224959617, 'L2_avg': 0.062202351987123566, 'End_point_L1_avg': 0.022195385718363138, 'End_point_L2_avg': 0.022386552838665363}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  88%|████████▊ | 21/24 [15:53<02:29, 49.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.6677484512329102\n",
      "Iteration 10, Loss: 0.8467610478401184\n",
      "Iteration 20, Loss: 0.6658454537391663\n",
      "Iteration 30, Loss: 0.5159862041473389\n",
      "Iteration 40, Loss: 0.396806538105011\n",
      "Iteration 50, Loss: 0.3182312548160553\n",
      "Iteration 60, Loss: 0.24101583659648895\n",
      "Iteration 70, Loss: 0.20693133771419525\n",
      "Iteration 80, Loss: 0.16298209130764008\n",
      "Iteration 90, Loss: 0.14237259328365326\n",
      "Iteration 100, Loss: 0.10317911207675934\n",
      "Iteration 110, Loss: 0.0928390622138977\n",
      "Iteration 120, Loss: 0.083238884806633\n",
      "Iteration 130, Loss: 0.06943279504776001\n",
      "Iteration 140, Loss: 0.06292752921581268\n",
      "Iteration 150, Loss: 0.061107754707336426\n",
      "Iteration 160, Loss: 0.04846711456775665\n",
      "Iteration 170, Loss: 0.048732344061136246\n",
      "Iteration 180, Loss: 0.03999484330415726\n",
      "Iteration 190, Loss: 0.04763995110988617\n",
      "Iteration 200, Loss: 0.03846472501754761\n",
      "Iteration 210, Loss: 0.03275429457426071\n",
      "Iteration 220, Loss: 0.03592807427048683\n",
      "Iteration 230, Loss: 0.03618006780743599\n",
      "Iteration 240, Loss: 0.02593882754445076\n",
      "Iteration 250, Loss: 0.02617838978767395\n",
      "Iteration 260, Loss: 0.023754436522722244\n",
      "Iteration 270, Loss: 0.021317007020115852\n",
      "Iteration 280, Loss: 0.02151367999613285\n",
      "Iteration 290, Loss: 0.019495222717523575\n",
      "Iteration 300, Loss: 0.022131673991680145\n",
      "Iteration 310, Loss: 0.016778605058789253\n",
      "Iteration 320, Loss: 0.022250840440392494\n",
      "Iteration 330, Loss: 0.017966797575354576\n",
      "Iteration 340, Loss: 0.019232764840126038\n",
      "Iteration 350, Loss: 0.014649695716798306\n",
      "Iteration 360, Loss: 0.016468020156025887\n",
      "Iteration 370, Loss: 0.013750270940363407\n",
      "Iteration 380, Loss: 0.013120037503540516\n",
      "Iteration 390, Loss: 0.01571955904364586\n",
      "Iteration 400, Loss: 0.014238225296139717\n",
      "Iteration 410, Loss: 0.011630291119217873\n",
      "Iteration 420, Loss: 0.010844854637980461\n",
      "Iteration 430, Loss: 0.012164551764726639\n",
      "Iteration 440, Loss: 0.011921674013137817\n",
      "Iteration 450, Loss: 0.011171417310833931\n",
      "Iteration 460, Loss: 0.009515009820461273\n",
      "Iteration 470, Loss: 0.009637061506509781\n",
      "Iteration 480, Loss: 0.010269629769027233\n",
      "Iteration 490, Loss: 0.010011039674282074\n",
      "Iteration 500, Loss: 0.009029319509863853\n",
      "Iteration 510, Loss: 0.010052508674561977\n",
      "Iteration 520, Loss: 0.008052419871091843\n",
      "Iteration 530, Loss: 0.007345422171056271\n",
      "Iteration 540, Loss: 0.0072567579336464405\n",
      "Iteration 550, Loss: 0.008071064949035645\n",
      "Iteration 560, Loss: 0.006570324767380953\n",
      "Iteration 570, Loss: 0.006671355105936527\n",
      "Iteration 580, Loss: 0.007295716088265181\n",
      "Iteration 590, Loss: 0.006791734602302313\n",
      "Iteration 600, Loss: 0.006358136888593435\n",
      "Iteration 610, Loss: 0.006979692727327347\n",
      "Iteration 620, Loss: 0.007589800748974085\n",
      "Iteration 630, Loss: 0.005394299048930407\n",
      "Iteration 640, Loss: 0.006589622236788273\n",
      "Iteration 650, Loss: 0.005741283763200045\n",
      "Iteration 660, Loss: 0.005828979425132275\n",
      "Iteration 670, Loss: 0.005100050941109657\n",
      "Iteration 680, Loss: 0.005989604163914919\n",
      "Iteration 690, Loss: 0.005505087785422802\n",
      "Iteration 700, Loss: 0.004367858171463013\n",
      "Iteration 710, Loss: 0.005859512835741043\n",
      "Iteration 720, Loss: 0.0047141630202531815\n",
      "Iteration 730, Loss: 0.005913537461310625\n",
      "Iteration 740, Loss: 0.004454518668353558\n",
      "Iteration 750, Loss: 0.004623190965503454\n",
      "Iteration 760, Loss: 0.004647542722523212\n",
      "Iteration 770, Loss: 0.00504304701462388\n",
      "Iteration 780, Loss: 0.004090555943548679\n",
      "Iteration 790, Loss: 0.004398983903229237\n",
      "Iteration 800, Loss: 0.004355440381914377\n",
      "Iteration 810, Loss: 0.005090263672173023\n",
      "Iteration 820, Loss: 0.004466768819838762\n",
      "Iteration 830, Loss: 0.004341659136116505\n",
      "Iteration 840, Loss: 0.004081921186298132\n",
      "Iteration 850, Loss: 0.004075279925018549\n",
      "Iteration 860, Loss: 0.0037655215710401535\n",
      "Iteration 870, Loss: 0.003840974299237132\n",
      "Iteration 880, Loss: 0.003731503849849105\n",
      "Iteration 890, Loss: 0.00365538545884192\n",
      "Iteration 900, Loss: 0.004194682464003563\n",
      "Iteration 910, Loss: 0.003676983527839184\n",
      "Iteration 920, Loss: 0.0035222447477281094\n",
      "Iteration 930, Loss: 0.00361349037848413\n",
      "Iteration 940, Loss: 0.003186941146850586\n",
      "Iteration 950, Loss: 0.0029187288600951433\n",
      "Iteration 960, Loss: 0.0038348915986716747\n",
      "Iteration 970, Loss: 0.003144078655168414\n",
      "Iteration 980, Loss: 0.0032672591041773558\n",
      "Iteration 990, Loss: 0.003515519667416811\n",
      "Iteration 1000, Loss: 0.0030066859908401966\n",
      "Iteration 1010, Loss: 0.0036204014904797077\n",
      "Iteration 1020, Loss: 0.003376380540430546\n",
      "Iteration 1030, Loss: 0.0030303788371384144\n",
      "Iteration 1040, Loss: 0.0029582397546619177\n",
      "Iteration 1050, Loss: 0.0032408437691628933\n",
      "Iteration 1060, Loss: 0.003097997512668371\n",
      "Iteration 1070, Loss: 0.0032497267238795757\n",
      "Iteration 1080, Loss: 0.003110142657533288\n",
      "Iteration 1090, Loss: 0.0030223261564970016\n",
      "Iteration 1100, Loss: 0.0028331573121249676\n",
      "Iteration 1110, Loss: 0.002803906099870801\n",
      "Iteration 1120, Loss: 0.002999306656420231\n",
      "Iteration 1130, Loss: 0.0026337308809161186\n",
      "Iteration 1140, Loss: 0.0027806696016341448\n",
      "Iteration 1150, Loss: 0.0030336061026901007\n",
      "Iteration 1160, Loss: 0.0027181380428373814\n",
      "Iteration 1170, Loss: 0.0030389782041311264\n",
      "Iteration 1180, Loss: 0.002812605816870928\n",
      "Iteration 1190, Loss: 0.0028630809392780066\n",
      "Iteration 1200, Loss: 0.0028645836282521486\n",
      "Iteration 1210, Loss: 0.002704276004806161\n",
      "Iteration 1220, Loss: 0.0026619730051606894\n",
      "Iteration 1230, Loss: 0.002925408771261573\n",
      "Iteration 1240, Loss: 0.00250803679227829\n",
      "Iteration 1250, Loss: 0.0022951115388423204\n",
      "Iteration 1260, Loss: 0.0026127926539629698\n",
      "Iteration 1270, Loss: 0.002413337118923664\n",
      "Iteration 1280, Loss: 0.0026655960828065872\n",
      "Iteration 1290, Loss: 0.0025739099364727736\n",
      "Iteration 1300, Loss: 0.0022589247673749924\n",
      "Iteration 1310, Loss: 0.002292181830853224\n",
      "Iteration 1320, Loss: 0.0022412468679249287\n",
      "Iteration 1330, Loss: 0.0020716653671115637\n",
      "Iteration 1340, Loss: 0.002709493972361088\n",
      "Iteration 1350, Loss: 0.0020313472487032413\n",
      "Iteration 1360, Loss: 0.0022902428172528744\n",
      "Iteration 1370, Loss: 0.002225916599854827\n",
      "Iteration 1380, Loss: 0.0023483107797801495\n",
      "Iteration 1390, Loss: 0.0024087722413241863\n",
      "Iteration 1400, Loss: 0.002488398691639304\n",
      "Iteration 1410, Loss: 0.0023441880475729704\n",
      "Iteration 1420, Loss: 0.002231643069535494\n",
      "Iteration 1430, Loss: 0.0023325353395193815\n",
      "Iteration 1440, Loss: 0.002378620207309723\n",
      "Iteration 1450, Loss: 0.002301544416695833\n",
      "Iteration 1460, Loss: 0.0020668604411184788\n",
      "Iteration 1470, Loss: 0.002392922528088093\n",
      "Iteration 1480, Loss: 0.0019744255114346743\n",
      "Iteration 1490, Loss: 0.0023274412378668785\n",
      "Iteration 1500, Loss: 0.002372831106185913\n",
      "Iteration 1510, Loss: 0.0021983240731060505\n",
      "Iteration 1520, Loss: 0.0023020619992166758\n",
      "Iteration 1530, Loss: 0.0020862712990492582\n",
      "Iteration 1540, Loss: 0.0020340776536613703\n",
      "Iteration 1550, Loss: 0.0019376904238015413\n",
      "Iteration 1560, Loss: 0.0020576880779117346\n",
      "Iteration 1570, Loss: 0.001965227536857128\n",
      "Iteration 1580, Loss: 0.0019570596050471067\n",
      "Iteration 1590, Loss: 0.0019623509142547846\n",
      "Iteration 1600, Loss: 0.0018791367765516043\n",
      "Iteration 1610, Loss: 0.002120617078617215\n",
      "Iteration 1620, Loss: 0.0020730351097881794\n",
      "Iteration 1630, Loss: 0.0017896199133247137\n",
      "Iteration 1640, Loss: 0.0019906144589185715\n",
      "Iteration 1650, Loss: 0.001844010199420154\n",
      "Iteration 1660, Loss: 0.002162740333005786\n",
      "Iteration 1670, Loss: 0.0019031781703233719\n",
      "Iteration 1680, Loss: 0.001916009932756424\n",
      "Iteration 1690, Loss: 0.00178514642175287\n",
      "Iteration 1700, Loss: 0.001926019904203713\n",
      "Iteration 1710, Loss: 0.0018681910587474704\n",
      "Iteration 1720, Loss: 0.0022720179986208677\n",
      "Iteration 1730, Loss: 0.0018927949713543057\n",
      "Iteration 1740, Loss: 0.001862450735643506\n",
      "Iteration 1750, Loss: 0.0018983185291290283\n",
      "Iteration 1760, Loss: 0.0017036620993167162\n",
      "Iteration 1770, Loss: 0.0022179854568094015\n",
      "Iteration 1780, Loss: 0.0018713170429691672\n",
      "Iteration 1790, Loss: 0.001944736111909151\n",
      "Iteration 1800, Loss: 0.0018111536046490073\n",
      "Iteration 1810, Loss: 0.0016586779383942485\n",
      "Iteration 1820, Loss: 0.001666925149038434\n",
      "Iteration 1830, Loss: 0.0018121395260095596\n",
      "Iteration 1840, Loss: 0.0017994544468820095\n",
      "Iteration 1850, Loss: 0.0018411010969430208\n",
      "Iteration 1860, Loss: 0.001953418832272291\n",
      "Iteration 1870, Loss: 0.001682666246779263\n",
      "Iteration 1880, Loss: 0.0016519707860425115\n",
      "Iteration 1890, Loss: 0.0016177247744053602\n",
      "Iteration 1900, Loss: 0.0017139295814558864\n",
      "Iteration 1910, Loss: 0.0016936243046075106\n",
      "Iteration 1920, Loss: 0.001959516666829586\n",
      "Iteration 1930, Loss: 0.0017832941375672817\n",
      "Iteration 1940, Loss: 0.0017405650578439236\n",
      "Iteration 1950, Loss: 0.0018594374414533377\n",
      "Iteration 1960, Loss: 0.001732129487209022\n",
      "Iteration 1970, Loss: 0.0017890651943162084\n",
      "Iteration 1980, Loss: 0.0019095726311206818\n",
      "Iteration 1990, Loss: 0.001745825749821961\n",
      "Iteration 2000, Loss: 0.0017388182459399104\n",
      "Iteration 2010, Loss: 0.0019838407170027494\n",
      "Iteration 2020, Loss: 0.0017313488060608506\n",
      "Iteration 2030, Loss: 0.0017396295443177223\n",
      "Iteration 2040, Loss: 0.0017019023653119802\n",
      "Iteration 2050, Loss: 0.0016606277786195278\n",
      "Iteration 2060, Loss: 0.0015226297546178102\n",
      "Iteration 2070, Loss: 0.0016029607504606247\n",
      "Iteration 2080, Loss: 0.0016632768092676997\n",
      "Iteration 2090, Loss: 0.001866177306510508\n",
      "Iteration 2100, Loss: 0.0017887915018945932\n",
      "Iteration 2110, Loss: 0.0015364732826128602\n",
      "Iteration 2120, Loss: 0.0015817912062630057\n",
      "Iteration 2130, Loss: 0.0015680855140089989\n",
      "Iteration 2140, Loss: 0.0017674193950369954\n",
      "Iteration 2150, Loss: 0.0017914266791194677\n",
      "Iteration 2160, Loss: 0.0017985169542953372\n",
      "Iteration 2170, Loss: 0.0016468185931444168\n",
      "Iteration 2180, Loss: 0.001601669704541564\n",
      "Iteration 2190, Loss: 0.00162986246868968\n",
      "Iteration 2200, Loss: 0.0016075591556727886\n",
      "Iteration 2210, Loss: 0.0015263436362147331\n",
      "Iteration 2220, Loss: 0.0014875985216349363\n",
      "Iteration 2230, Loss: 0.001563119818456471\n",
      "Iteration 2240, Loss: 0.0016108823474496603\n",
      "Iteration 2250, Loss: 0.0015317132929340005\n",
      "Iteration 2260, Loss: 0.0016089687123894691\n",
      "Iteration 2270, Loss: 0.001356654567644\n",
      "Iteration 2280, Loss: 0.0014771432615816593\n",
      "Iteration 2290, Loss: 0.0014443625696003437\n",
      "Iteration 2300, Loss: 0.0014931916957721114\n",
      "Iteration 2310, Loss: 0.0015793968923389912\n",
      "Iteration 2320, Loss: 0.0015151792904362082\n",
      "Iteration 2330, Loss: 0.0012206070823594928\n",
      "Iteration 2340, Loss: 0.0015562078915536404\n",
      "Iteration 2350, Loss: 0.0013638722011819482\n",
      "Iteration 2360, Loss: 0.001388208125717938\n",
      "Iteration 2370, Loss: 0.001445029629394412\n",
      "Iteration 2380, Loss: 0.0013806849019601941\n",
      "Iteration 2390, Loss: 0.001443933229893446\n",
      "Iteration 2400, Loss: 0.0014303858624771237\n",
      "Iteration 2410, Loss: 0.0016773594543337822\n",
      "Iteration 2420, Loss: 0.001484906766563654\n",
      "Iteration 2430, Loss: 0.0012422651052474976\n",
      "Iteration 2440, Loss: 0.0015269855502992868\n",
      "Iteration 2450, Loss: 0.0013407175429165363\n",
      "Iteration 2460, Loss: 0.001495434669777751\n",
      "Iteration 2470, Loss: 0.001316887908615172\n",
      "Iteration 2480, Loss: 0.0013104142853990197\n",
      "Iteration 2490, Loss: 0.0013347865315154195\n",
      "Iteration 2500, Loss: 0.0014026191784068942\n",
      "Iteration 2510, Loss: 0.001489953137934208\n",
      "Iteration 2520, Loss: 0.001374277751892805\n",
      "Iteration 2530, Loss: 0.0014441084349527955\n",
      "Iteration 2540, Loss: 0.0013246345333755016\n",
      "Iteration 2550, Loss: 0.0014437258942052722\n",
      "Iteration 2560, Loss: 0.0013163293479010463\n",
      "Iteration 2570, Loss: 0.0012458502314984798\n",
      "Iteration 2580, Loss: 0.0013645453145727515\n",
      "Iteration 2590, Loss: 0.0013546496629714966\n",
      "Iteration 2600, Loss: 0.00124131771735847\n",
      "Iteration 2610, Loss: 0.0012883511371910572\n",
      "Iteration 2620, Loss: 0.0013685590820387006\n",
      "Iteration 2630, Loss: 0.001332922256551683\n",
      "Iteration 2640, Loss: 0.0012850566999986768\n",
      "Iteration 2650, Loss: 0.001265924540348351\n",
      "Iteration 2660, Loss: 0.0012380912667140365\n",
      "Iteration 2670, Loss: 0.001279943622648716\n",
      "Iteration 2680, Loss: 0.001303360448218882\n",
      "Iteration 2690, Loss: 0.001290670596063137\n",
      "Iteration 2700, Loss: 0.0013655729126185179\n",
      "Iteration 2710, Loss: 0.0013344575418159366\n",
      "Iteration 2720, Loss: 0.0011328905820846558\n",
      "Iteration 2730, Loss: 0.0011928470339626074\n",
      "Iteration 2740, Loss: 0.0012598844477906823\n",
      "Iteration 2750, Loss: 0.001153024728409946\n",
      "Iteration 2760, Loss: 0.0012203985825181007\n",
      "Iteration 2770, Loss: 0.0011357361217960715\n",
      "Iteration 2780, Loss: 0.0011411827290430665\n",
      "Iteration 2790, Loss: 0.0011834929464384913\n",
      "Iteration 2800, Loss: 0.0011998062254860997\n",
      "Iteration 2810, Loss: 0.0013276929967105389\n",
      "Iteration 2820, Loss: 0.001164333545602858\n",
      "Iteration 2830, Loss: 0.0012192000867798924\n",
      "Iteration 2840, Loss: 0.0012980438768863678\n",
      "Iteration 2850, Loss: 0.0012696743942797184\n",
      "Iteration 2860, Loss: 0.0011675340356305242\n",
      "Iteration 2870, Loss: 0.0012512273387983441\n",
      "Iteration 2880, Loss: 0.0012409357586875558\n",
      "Iteration 2890, Loss: 0.0011119903065264225\n",
      "Iteration 2900, Loss: 0.0011854639742523432\n",
      "Iteration 2910, Loss: 0.001188516616821289\n",
      "Iteration 2920, Loss: 0.0012550485553219914\n",
      "Iteration 2930, Loss: 0.0011608714703470469\n",
      "Iteration 2940, Loss: 0.0011841118102893233\n",
      "Iteration 2950, Loss: 0.0011896531796082854\n",
      "Iteration 2960, Loss: 0.0011471799807623029\n",
      "Iteration 2970, Loss: 0.0011898393277078867\n",
      "Iteration 2980, Loss: 0.001182383974082768\n",
      "Iteration 2990, Loss: 0.0010999363148584962\n",
      "Iteration 3000, Loss: 0.0010875228326767683\n",
      "Iteration 3010, Loss: 0.00117160240188241\n",
      "Iteration 3020, Loss: 0.00107724464032799\n",
      "Iteration 3030, Loss: 0.0011292664567008615\n",
      "Iteration 3040, Loss: 0.0011070241453126073\n",
      "Iteration 3050, Loss: 0.0010508188279345632\n",
      "Iteration 3060, Loss: 0.001079454435966909\n",
      "Iteration 3070, Loss: 0.001103865448385477\n",
      "Iteration 3080, Loss: 0.0011382775846868753\n",
      "Iteration 3090, Loss: 0.0010078862542286515\n",
      "Iteration 3100, Loss: 0.0011140238493680954\n",
      "Iteration 3110, Loss: 0.0011489217868074775\n",
      "Iteration 3120, Loss: 0.0010075729805976152\n",
      "Iteration 3130, Loss: 0.000991719658486545\n",
      "Iteration 3140, Loss: 0.0011492688208818436\n",
      "Iteration 3150, Loss: 0.0010772020323202014\n",
      "Iteration 3160, Loss: 0.001058076275512576\n",
      "Iteration 3170, Loss: 0.0010744481114670634\n",
      "Iteration 3180, Loss: 0.0010798178846016526\n",
      "Iteration 3190, Loss: 0.001064320676960051\n",
      "Iteration 3200, Loss: 0.0009514024131931365\n",
      "Iteration 3210, Loss: 0.0010330033255741\n",
      "Iteration 3220, Loss: 0.0011104720178991556\n",
      "Iteration 3230, Loss: 0.0010844165226444602\n",
      "Iteration 3240, Loss: 0.0009733959450386465\n",
      "Iteration 3250, Loss: 0.0010264785960316658\n",
      "Iteration 3260, Loss: 0.001078780391253531\n",
      "Iteration 3270, Loss: 0.0010860644979402423\n",
      "Iteration 3280, Loss: 0.0010816098656505346\n",
      "Iteration 3290, Loss: 0.0009430557256564498\n",
      "Iteration 3300, Loss: 0.000965386163443327\n",
      "Iteration 3310, Loss: 0.0009921392193064094\n",
      "Iteration 3320, Loss: 0.0010532846208661795\n",
      "Iteration 3330, Loss: 0.0009933465626090765\n",
      "Iteration 3340, Loss: 0.0010162752587348223\n",
      "Iteration 3350, Loss: 0.0009420160204172134\n",
      "Iteration 3360, Loss: 0.00114014046266675\n",
      "Iteration 3370, Loss: 0.0009159398614428937\n",
      "Iteration 3380, Loss: 0.000997134018689394\n",
      "Iteration 3390, Loss: 0.000905631750356406\n",
      "Iteration 3400, Loss: 0.0009573714341968298\n",
      "Iteration 3410, Loss: 0.0009226085967384279\n",
      "Iteration 3420, Loss: 0.0009345657890662551\n",
      "Iteration 3430, Loss: 0.0009117042645812035\n",
      "Iteration 3440, Loss: 0.001065819407813251\n",
      "Iteration 3450, Loss: 0.0010420943144708872\n",
      "Iteration 3460, Loss: 0.0009693217580206692\n",
      "Iteration 3470, Loss: 0.0008577062399126589\n",
      "Iteration 3480, Loss: 0.000836469407659024\n",
      "Iteration 3490, Loss: 0.0008727714885026217\n",
      "Iteration 3500, Loss: 0.0009810238843783736\n",
      "Iteration 3510, Loss: 0.0008951027411967516\n",
      "Iteration 3520, Loss: 0.0009963727788999677\n",
      "Iteration 3530, Loss: 0.0009061444434337318\n",
      "Iteration 3540, Loss: 0.0009202553192153573\n",
      "Iteration 3550, Loss: 0.0008896862273104489\n",
      "Iteration 3560, Loss: 0.0009169073891825974\n",
      "Iteration 3570, Loss: 0.0008437486831098795\n",
      "Iteration 3580, Loss: 0.0009012662339955568\n",
      "Iteration 3590, Loss: 0.0008370182476937771\n",
      "Iteration 3600, Loss: 0.0008575671818107367\n",
      "Iteration 3610, Loss: 0.0009126401855610311\n",
      "Iteration 3620, Loss: 0.0007968303980305791\n",
      "Iteration 3630, Loss: 0.0008760077762417495\n",
      "Iteration 3640, Loss: 0.0007955955807119608\n",
      "Iteration 3650, Loss: 0.0008687260560691357\n",
      "Iteration 3660, Loss: 0.0008932032505981624\n",
      "Iteration 3670, Loss: 0.0009171398705802858\n",
      "Iteration 3680, Loss: 0.0008707520901225507\n",
      "Iteration 3690, Loss: 0.0008564548334106803\n",
      "Iteration 3700, Loss: 0.0008200033917091787\n",
      "Iteration 3710, Loss: 0.0008652528049424291\n",
      "Iteration 3720, Loss: 0.0009487064671702683\n",
      "Iteration 3730, Loss: 0.0008106707828119397\n",
      "Iteration 3740, Loss: 0.0007406100630760193\n",
      "Iteration 3750, Loss: 0.0008400790393352509\n",
      "Iteration 3760, Loss: 0.0008358398335985839\n",
      "Iteration 3770, Loss: 0.0008032589685171843\n",
      "Iteration 3780, Loss: 0.000891751900780946\n",
      "Iteration 3790, Loss: 0.0007924999808892608\n",
      "Iteration 3800, Loss: 0.000751136802136898\n",
      "Iteration 3810, Loss: 0.0008067515445873141\n",
      "Iteration 3820, Loss: 0.0008476756047457457\n",
      "Iteration 3830, Loss: 0.00083601736696437\n",
      "Iteration 3840, Loss: 0.0008626884664408863\n",
      "Iteration 3850, Loss: 0.0008353064185939729\n",
      "Iteration 3860, Loss: 0.0008275363361462951\n",
      "Iteration 3870, Loss: 0.0007899234187789261\n",
      "Iteration 3880, Loss: 0.0008177497074939311\n",
      "Iteration 3890, Loss: 0.0007140420493669808\n",
      "Iteration 3900, Loss: 0.0007727394695393741\n",
      "Iteration 3910, Loss: 0.0008127382607199252\n",
      "Iteration 3920, Loss: 0.0007930698920972645\n",
      "Iteration 3930, Loss: 0.0007551670423708856\n",
      "Iteration 3940, Loss: 0.0007448619580827653\n",
      "Iteration 3950, Loss: 0.0007449741824530065\n",
      "Iteration 3960, Loss: 0.000806017720606178\n",
      "Iteration 3970, Loss: 0.0007440687622874975\n",
      "Iteration 3980, Loss: 0.0007057451293803751\n",
      "Iteration 3990, Loss: 0.0007858630269765854\n",
      "Iteration 4000, Loss: 0.0007648227619938552\n",
      "Iteration 4010, Loss: 0.0007063340744934976\n",
      "Iteration 4020, Loss: 0.0007596870418637991\n",
      "Iteration 4030, Loss: 0.0008362257503904402\n",
      "Iteration 4040, Loss: 0.0007245508022606373\n",
      "Iteration 4050, Loss: 0.0006938787992112339\n",
      "Iteration 4060, Loss: 0.0007272985531017184\n",
      "Iteration 4070, Loss: 0.0007551449234597385\n",
      "Iteration 4080, Loss: 0.0008139160927385092\n",
      "Iteration 4090, Loss: 0.000874772435054183\n",
      "Iteration 4100, Loss: 0.0007601759280078113\n",
      "Iteration 4110, Loss: 0.0007443520007655025\n",
      "Iteration 4120, Loss: 0.0006772471824660897\n",
      "Iteration 4130, Loss: 0.0006738454685546458\n",
      "Iteration 4140, Loss: 0.0007406470249406993\n",
      "Iteration 4150, Loss: 0.0007042390061542392\n",
      "Iteration 4160, Loss: 0.0006714931805618107\n",
      "Iteration 4170, Loss: 0.0006698553916066885\n",
      "Iteration 4180, Loss: 0.0006786507437936962\n",
      "Iteration 4190, Loss: 0.0007363507756963372\n",
      "Iteration 4200, Loss: 0.000614199903793633\n",
      "Iteration 4210, Loss: 0.00072072958573699\n",
      "Iteration 4220, Loss: 0.0006572256097570062\n",
      "Iteration 4230, Loss: 0.000688705185893923\n",
      "Iteration 4240, Loss: 0.0006806122837588191\n",
      "Iteration 4250, Loss: 0.0006357372039929032\n",
      "Iteration 4260, Loss: 0.0007104723481461406\n",
      "Iteration 4270, Loss: 0.0006893779500387609\n",
      "Iteration 4280, Loss: 0.0006816311506554484\n",
      "Iteration 4290, Loss: 0.0006416973192244768\n",
      "Iteration 4300, Loss: 0.0006113754352554679\n",
      "Iteration 4310, Loss: 0.000783595081884414\n",
      "Iteration 4320, Loss: 0.0006486221100203693\n",
      "Iteration 4330, Loss: 0.0006419152487069368\n",
      "Iteration 4340, Loss: 0.0006619697669520974\n",
      "Iteration 4350, Loss: 0.0006132032722234726\n",
      "Iteration 4360, Loss: 0.0006842841976322234\n",
      "Iteration 4370, Loss: 0.000631211674772203\n",
      "Iteration 4380, Loss: 0.0006651359726674855\n",
      "Iteration 4390, Loss: 0.0006667174166068435\n",
      "Iteration 4400, Loss: 0.0005950802005827427\n",
      "Iteration 4410, Loss: 0.0006270327721722424\n",
      "Iteration 4420, Loss: 0.0006664974498562515\n",
      "Iteration 4430, Loss: 0.0006769038154743612\n",
      "Iteration 4440, Loss: 0.0006726586725562811\n",
      "Iteration 4450, Loss: 0.0006361865671351552\n",
      "Iteration 4460, Loss: 0.0006046645576134324\n",
      "Iteration 4470, Loss: 0.0006882574525661767\n",
      "Iteration 4480, Loss: 0.0006438355194404721\n",
      "Iteration 4490, Loss: 0.0006068043876439333\n",
      "Iteration 4500, Loss: 0.0006292747566476464\n",
      "Iteration 4510, Loss: 0.0006109834648668766\n",
      "Iteration 4520, Loss: 0.0006412370130419731\n",
      "Iteration 4530, Loss: 0.0006077879224903882\n",
      "Iteration 4540, Loss: 0.0006171782733872533\n",
      "Iteration 4550, Loss: 0.0005549265770241618\n",
      "Iteration 4560, Loss: 0.0006517241708934307\n",
      "Iteration 4570, Loss: 0.0006357191014103591\n",
      "Iteration 4580, Loss: 0.0006350232288241386\n",
      "Iteration 4590, Loss: 0.0006367926835082471\n",
      "Iteration 4600, Loss: 0.0006054992554709315\n",
      "Iteration 4610, Loss: 0.0006218426278792322\n",
      "Iteration 4620, Loss: 0.0005801787483505905\n",
      "Iteration 4630, Loss: 0.0006253218743950129\n",
      "Iteration 4640, Loss: 0.0005345507524907589\n",
      "Iteration 4650, Loss: 0.0005496751982718706\n",
      "Iteration 4660, Loss: 0.000591171148698777\n",
      "Iteration 4670, Loss: 0.0005559402052313089\n",
      "Iteration 4680, Loss: 0.0005806980188935995\n",
      "Iteration 4690, Loss: 0.0005573746748268604\n",
      "Iteration 4700, Loss: 0.0005468305898830295\n",
      "Iteration 4710, Loss: 0.000580615655053407\n",
      "Iteration 4720, Loss: 0.0005819470970891416\n",
      "Iteration 4730, Loss: 0.0005367864505387843\n",
      "Iteration 4740, Loss: 0.000579928804654628\n",
      "Iteration 4750, Loss: 0.0005748298717662692\n",
      "Iteration 4760, Loss: 0.0005335710593499243\n",
      "Iteration 4770, Loss: 0.0005863552214577794\n",
      "Iteration 4780, Loss: 0.0005601668381132185\n",
      "Iteration 4790, Loss: 0.0005473361234180629\n",
      "Iteration 4800, Loss: 0.0005697026499547064\n",
      "Iteration 4810, Loss: 0.0005464996793307364\n",
      "Iteration 4820, Loss: 0.0005600948352366686\n",
      "Iteration 4830, Loss: 0.0005472232587635517\n",
      "Iteration 4840, Loss: 0.00048827246064320207\n",
      "Iteration 4850, Loss: 0.0005698545719496906\n",
      "Iteration 4860, Loss: 0.0005813381867483258\n",
      "Iteration 4870, Loss: 0.0005460705142468214\n",
      "Iteration 4880, Loss: 0.0005348441191017628\n",
      "Iteration 4890, Loss: 0.0005190360825508833\n",
      "Iteration 4900, Loss: 0.0004886343376711011\n",
      "Iteration 4910, Loss: 0.0005596014088951051\n",
      "Iteration 4920, Loss: 0.000534826482180506\n",
      "Iteration 4930, Loss: 0.0005147612537257373\n",
      "Iteration 4940, Loss: 0.0005469025927595794\n",
      "Iteration 4950, Loss: 0.0005005944985896349\n",
      "Iteration 4960, Loss: 0.00048150733346119523\n",
      "Iteration 4970, Loss: 0.0005213288241066039\n",
      "Iteration 4980, Loss: 0.0005097423563711345\n",
      "Iteration 4990, Loss: 0.0004980196827091277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  92%|█████████▏| 22/24 [17:31<02:08, 64.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.03220460369520656, 'L2_avg': 0.04100044701877933, 'End_point_L1_avg': 0.01587824518384299, 'End_point_L2_avg': 0.017219594497820012}\n",
      "Iteration 0, Loss: 2.3745481967926025\n",
      "Iteration 10, Loss: 1.5816694498062134\n",
      "Iteration 20, Loss: 1.350522518157959\n",
      "Iteration 30, Loss: 1.102649450302124\n",
      "Iteration 40, Loss: 0.9059091806411743\n",
      "Iteration 50, Loss: 0.7407535910606384\n",
      "Iteration 60, Loss: 0.6060578227043152\n",
      "Iteration 70, Loss: 0.4935447871685028\n",
      "Iteration 80, Loss: 0.4023129343986511\n",
      "Iteration 90, Loss: 0.32509762048721313\n",
      "Iteration 100, Loss: 0.26839473843574524\n",
      "Iteration 110, Loss: 0.2171456217765808\n",
      "Iteration 120, Loss: 0.18068790435791016\n",
      "Iteration 130, Loss: 0.15359219908714294\n",
      "Iteration 140, Loss: 0.127316415309906\n",
      "Iteration 150, Loss: 0.10978147387504578\n",
      "Iteration 160, Loss: 0.0938202366232872\n",
      "Iteration 170, Loss: 0.08980809897184372\n",
      "Iteration 180, Loss: 0.0776415690779686\n",
      "Iteration 190, Loss: 0.06699693202972412\n",
      "Iteration 200, Loss: 0.06673474609851837\n",
      "Iteration 210, Loss: 0.056322868913412094\n",
      "Iteration 220, Loss: 0.055904168635606766\n",
      "Iteration 230, Loss: 0.054649677127599716\n",
      "Iteration 240, Loss: 0.05363987386226654\n",
      "Iteration 250, Loss: 0.047892335802316666\n",
      "Iteration 260, Loss: 0.04547417163848877\n",
      "Iteration 270, Loss: 0.04479760676622391\n",
      "Iteration 280, Loss: 0.04190295189619064\n",
      "Iteration 290, Loss: 0.03987247496843338\n",
      "Iteration 300, Loss: 0.03542167693376541\n",
      "Iteration 310, Loss: 0.045610662549734116\n",
      "Iteration 320, Loss: 0.03909919410943985\n",
      "Iteration 330, Loss: 0.03572235256433487\n",
      "Iteration 340, Loss: 0.03830145299434662\n",
      "Iteration 350, Loss: 0.03965793177485466\n",
      "Iteration 360, Loss: 0.036109160631895065\n",
      "Iteration 370, Loss: 0.029620008543133736\n",
      "Iteration 380, Loss: 0.029388926923274994\n",
      "Iteration 390, Loss: 0.03298833593726158\n",
      "Iteration 400, Loss: 0.026126712560653687\n",
      "Iteration 410, Loss: 0.029868513345718384\n",
      "Iteration 420, Loss: 0.026796845719218254\n",
      "Iteration 430, Loss: 0.028182880952954292\n",
      "Iteration 440, Loss: 0.027513012290000916\n",
      "Iteration 450, Loss: 0.02465914376080036\n",
      "Iteration 460, Loss: 0.02497084066271782\n",
      "Iteration 470, Loss: 0.024651721119880676\n",
      "Iteration 480, Loss: 0.024221403524279594\n",
      "Iteration 490, Loss: 0.02195603772997856\n",
      "Iteration 500, Loss: 0.02109098993241787\n",
      "Iteration 510, Loss: 0.020950734615325928\n",
      "Iteration 520, Loss: 0.020469078794121742\n",
      "Iteration 530, Loss: 0.01841025985777378\n",
      "Iteration 540, Loss: 0.017731547355651855\n",
      "Iteration 550, Loss: 0.01817050762474537\n",
      "Iteration 560, Loss: 0.018366845324635506\n",
      "Iteration 570, Loss: 0.017775511369109154\n",
      "Iteration 580, Loss: 0.01743229664862156\n",
      "Iteration 590, Loss: 0.0173848494887352\n",
      "Iteration 600, Loss: 0.015254825353622437\n",
      "Iteration 610, Loss: 0.015550459735095501\n",
      "Iteration 620, Loss: 0.01446986012160778\n",
      "Iteration 630, Loss: 0.015976451337337494\n",
      "Iteration 640, Loss: 0.01439782977104187\n",
      "Iteration 650, Loss: 0.013099265284836292\n",
      "Iteration 660, Loss: 0.012583442963659763\n",
      "Iteration 670, Loss: 0.014004884287714958\n",
      "Iteration 680, Loss: 0.013081630691885948\n",
      "Iteration 690, Loss: 0.01170248631387949\n",
      "Iteration 700, Loss: 0.012996983714401722\n",
      "Iteration 710, Loss: 0.011625724844634533\n",
      "Iteration 720, Loss: 0.011908916756510735\n",
      "Iteration 730, Loss: 0.011040938086807728\n",
      "Iteration 740, Loss: 0.010442757979035378\n",
      "Iteration 750, Loss: 0.009947838261723518\n",
      "Iteration 760, Loss: 0.009591748006641865\n",
      "Iteration 770, Loss: 0.009221747517585754\n",
      "Iteration 780, Loss: 0.008762389421463013\n",
      "Iteration 790, Loss: 0.009600936435163021\n",
      "Iteration 800, Loss: 0.009555147960782051\n",
      "Iteration 810, Loss: 0.009734466671943665\n",
      "Iteration 820, Loss: 0.009345423430204391\n",
      "Iteration 830, Loss: 0.008327314630150795\n",
      "Iteration 840, Loss: 0.0081607885658741\n",
      "Iteration 850, Loss: 0.007665626704692841\n",
      "Iteration 860, Loss: 0.008626533672213554\n",
      "Iteration 870, Loss: 0.00753850769251585\n",
      "Iteration 880, Loss: 0.007874518632888794\n",
      "Iteration 890, Loss: 0.0069595021195709705\n",
      "Iteration 900, Loss: 0.007775414269417524\n",
      "Iteration 910, Loss: 0.007559020537883043\n",
      "Iteration 920, Loss: 0.007077694870531559\n",
      "Iteration 930, Loss: 0.006848894525319338\n",
      "Iteration 940, Loss: 0.0064975544810295105\n",
      "Iteration 950, Loss: 0.006801109295338392\n",
      "Iteration 960, Loss: 0.006457689218223095\n",
      "Iteration 970, Loss: 0.006718931719660759\n",
      "Iteration 980, Loss: 0.00602221442386508\n",
      "Iteration 990, Loss: 0.006280903238803148\n",
      "Iteration 1000, Loss: 0.006036226637661457\n",
      "Iteration 1010, Loss: 0.005743126850575209\n",
      "Iteration 1020, Loss: 0.005856740288436413\n",
      "Iteration 1030, Loss: 0.005711831618100405\n",
      "Iteration 1040, Loss: 0.005666112527251244\n",
      "Iteration 1050, Loss: 0.005583382677286863\n",
      "Iteration 1060, Loss: 0.0051620230078697205\n",
      "Iteration 1070, Loss: 0.005429401528090239\n",
      "Iteration 1080, Loss: 0.004725913517177105\n",
      "Iteration 1090, Loss: 0.005289324093610048\n",
      "Iteration 1100, Loss: 0.005353531800210476\n",
      "Iteration 1110, Loss: 0.005196250043809414\n",
      "Iteration 1120, Loss: 0.004894514102488756\n",
      "Iteration 1130, Loss: 0.004533656872808933\n",
      "Iteration 1140, Loss: 0.004746959079056978\n",
      "Iteration 1150, Loss: 0.00477647827938199\n",
      "Iteration 1160, Loss: 0.004782643169164658\n",
      "Iteration 1170, Loss: 0.00463969586417079\n",
      "Iteration 1180, Loss: 0.00474260188639164\n",
      "Iteration 1190, Loss: 0.0046950289979577065\n",
      "Iteration 1200, Loss: 0.004530065692961216\n",
      "Iteration 1210, Loss: 0.004235771019011736\n",
      "Iteration 1220, Loss: 0.004272978287190199\n",
      "Iteration 1230, Loss: 0.004061032552272081\n",
      "Iteration 1240, Loss: 0.00437052920460701\n",
      "Iteration 1250, Loss: 0.004349556285887957\n",
      "Iteration 1260, Loss: 0.004043914843350649\n",
      "Iteration 1270, Loss: 0.0042288778349757195\n",
      "Iteration 1280, Loss: 0.0038314179982990026\n",
      "Iteration 1290, Loss: 0.0038473443128168583\n",
      "Iteration 1300, Loss: 0.003954353742301464\n",
      "Iteration 1310, Loss: 0.0039648571982979774\n",
      "Iteration 1320, Loss: 0.003979907836765051\n",
      "Iteration 1330, Loss: 0.0038194444496184587\n",
      "Iteration 1340, Loss: 0.0039089578203856945\n",
      "Iteration 1350, Loss: 0.003880719654262066\n",
      "Iteration 1360, Loss: 0.003529004752635956\n",
      "Iteration 1370, Loss: 0.0037548195105046034\n",
      "Iteration 1380, Loss: 0.0036033163778483868\n",
      "Iteration 1390, Loss: 0.0035283900797367096\n",
      "Iteration 1400, Loss: 0.0036520124413073063\n",
      "Iteration 1410, Loss: 0.003664294257760048\n",
      "Iteration 1420, Loss: 0.00353880668990314\n",
      "Iteration 1430, Loss: 0.003290364984422922\n",
      "Iteration 1440, Loss: 0.003564974060282111\n",
      "Iteration 1450, Loss: 0.0035893444437533617\n",
      "Iteration 1460, Loss: 0.003536698641255498\n",
      "Iteration 1470, Loss: 0.003295707516372204\n",
      "Iteration 1480, Loss: 0.003426282200962305\n",
      "Iteration 1490, Loss: 0.0033784678671509027\n",
      "Iteration 1500, Loss: 0.0033722727093845606\n",
      "Iteration 1510, Loss: 0.0033871394116431475\n",
      "Iteration 1520, Loss: 0.0034469659440219402\n",
      "Iteration 1530, Loss: 0.0030215969309210777\n",
      "Iteration 1540, Loss: 0.003318279981613159\n",
      "Iteration 1550, Loss: 0.0032600457780063152\n",
      "Iteration 1560, Loss: 0.0032712530810385942\n",
      "Iteration 1570, Loss: 0.0032298066653311253\n",
      "Iteration 1580, Loss: 0.0031877143774181604\n",
      "Iteration 1590, Loss: 0.0030870907939970493\n",
      "Iteration 1600, Loss: 0.0030703118536621332\n",
      "Iteration 1610, Loss: 0.0030748394783586264\n",
      "Iteration 1620, Loss: 0.0032449623104184866\n",
      "Iteration 1630, Loss: 0.003014569403603673\n",
      "Iteration 1640, Loss: 0.002980868797749281\n",
      "Iteration 1650, Loss: 0.003111019730567932\n",
      "Iteration 1660, Loss: 0.0031466535292565823\n",
      "Iteration 1670, Loss: 0.00315850879997015\n",
      "Iteration 1680, Loss: 0.0030402354896068573\n",
      "Iteration 1690, Loss: 0.0028770852368324995\n",
      "Iteration 1700, Loss: 0.002979024313390255\n",
      "Iteration 1710, Loss: 0.0030664463993161917\n",
      "Iteration 1720, Loss: 0.0030547003261744976\n",
      "Iteration 1730, Loss: 0.0028006380889564753\n",
      "Iteration 1740, Loss: 0.002986945677548647\n",
      "Iteration 1750, Loss: 0.0028051172848790884\n",
      "Iteration 1760, Loss: 0.0027794765774160624\n",
      "Iteration 1770, Loss: 0.0029215493705123663\n",
      "Iteration 1780, Loss: 0.0027735463809221983\n",
      "Iteration 1790, Loss: 0.0027669472619891167\n",
      "Iteration 1800, Loss: 0.0028754703234881163\n",
      "Iteration 1810, Loss: 0.0027521690353751183\n",
      "Iteration 1820, Loss: 0.002783563919365406\n",
      "Iteration 1830, Loss: 0.0027213329449295998\n",
      "Iteration 1840, Loss: 0.0027879681438207626\n",
      "Iteration 1850, Loss: 0.0026201128493994474\n",
      "Iteration 1860, Loss: 0.002666632877662778\n",
      "Iteration 1870, Loss: 0.0025828236248344183\n",
      "Iteration 1880, Loss: 0.0027062923181802034\n",
      "Iteration 1890, Loss: 0.002635121578350663\n",
      "Iteration 1900, Loss: 0.0026286013890057802\n",
      "Iteration 1910, Loss: 0.0024625875521451235\n",
      "Iteration 1920, Loss: 0.002695653820410371\n",
      "Iteration 1930, Loss: 0.002719359239563346\n",
      "Iteration 1940, Loss: 0.0025359410792589188\n",
      "Iteration 1950, Loss: 0.0025408421643078327\n",
      "Iteration 1960, Loss: 0.002642245963215828\n",
      "Iteration 1970, Loss: 0.002607121132314205\n",
      "Iteration 1980, Loss: 0.0025412491522729397\n",
      "Iteration 1990, Loss: 0.0025236262008547783\n",
      "Iteration 2000, Loss: 0.00254652788862586\n",
      "Iteration 2010, Loss: 0.00240899296477437\n",
      "Iteration 2020, Loss: 0.002484974218532443\n",
      "Iteration 2030, Loss: 0.0024343407712876797\n",
      "Iteration 2040, Loss: 0.002405486535280943\n",
      "Iteration 2050, Loss: 0.002536036539822817\n",
      "Iteration 2060, Loss: 0.0025180820375680923\n",
      "Iteration 2070, Loss: 0.0024050010833889246\n",
      "Iteration 2080, Loss: 0.002439243718981743\n",
      "Iteration 2090, Loss: 0.002373682800680399\n",
      "Iteration 2100, Loss: 0.002515435451641679\n",
      "Iteration 2110, Loss: 0.0024246315006166697\n",
      "Iteration 2120, Loss: 0.002382381586357951\n",
      "Iteration 2130, Loss: 0.0023345251102000475\n",
      "Iteration 2140, Loss: 0.0023302629124373198\n",
      "Iteration 2150, Loss: 0.0021845113951712847\n",
      "Iteration 2160, Loss: 0.002320650964975357\n",
      "Iteration 2170, Loss: 0.002353829797357321\n",
      "Iteration 2180, Loss: 0.002293494064360857\n",
      "Iteration 2190, Loss: 0.0023262014146894217\n",
      "Iteration 2200, Loss: 0.0021178678143769503\n",
      "Iteration 2210, Loss: 0.002250394318252802\n",
      "Iteration 2220, Loss: 0.002370300702750683\n",
      "Iteration 2230, Loss: 0.0023394909221678972\n",
      "Iteration 2240, Loss: 0.0022555857431143522\n",
      "Iteration 2250, Loss: 0.0022453118581324816\n",
      "Iteration 2260, Loss: 0.002387241693213582\n",
      "Iteration 2270, Loss: 0.0022369169164448977\n",
      "Iteration 2280, Loss: 0.002197160152718425\n",
      "Iteration 2290, Loss: 0.0023256444837898016\n",
      "Iteration 2300, Loss: 0.002223135204985738\n",
      "Iteration 2310, Loss: 0.002178674563765526\n",
      "Iteration 2320, Loss: 0.002288728253915906\n",
      "Iteration 2330, Loss: 0.0021329117007553577\n",
      "Iteration 2340, Loss: 0.002232702448964119\n",
      "Iteration 2350, Loss: 0.0022208585869520903\n",
      "Iteration 2360, Loss: 0.0021779360249638557\n",
      "Iteration 2370, Loss: 0.0021139655727893114\n",
      "Iteration 2380, Loss: 0.0021822373382747173\n",
      "Iteration 2390, Loss: 0.0021999755408614874\n",
      "Iteration 2400, Loss: 0.0021472317166626453\n",
      "Iteration 2410, Loss: 0.0020485226996243\n",
      "Iteration 2420, Loss: 0.0021013147197663784\n",
      "Iteration 2430, Loss: 0.0020090590696781874\n",
      "Iteration 2440, Loss: 0.002196293557062745\n",
      "Iteration 2450, Loss: 0.0020530764013528824\n",
      "Iteration 2460, Loss: 0.0021963375620543957\n",
      "Iteration 2470, Loss: 0.001986156916245818\n",
      "Iteration 2480, Loss: 0.0019275677623227239\n",
      "Iteration 2490, Loss: 0.002050272189080715\n",
      "Iteration 2500, Loss: 0.0019176692003384233\n",
      "Iteration 2510, Loss: 0.002035370096564293\n",
      "Iteration 2520, Loss: 0.0019983449019491673\n",
      "Iteration 2530, Loss: 0.002113295253366232\n",
      "Iteration 2540, Loss: 0.0020973915234208107\n",
      "Iteration 2550, Loss: 0.0020645535551011562\n",
      "Iteration 2560, Loss: 0.002103107515722513\n",
      "Iteration 2570, Loss: 0.002090491121634841\n",
      "Iteration 2580, Loss: 0.0018863400910049677\n",
      "Iteration 2590, Loss: 0.001909624319523573\n",
      "Iteration 2600, Loss: 0.002026275498792529\n",
      "Iteration 2610, Loss: 0.0019262625137344003\n",
      "Iteration 2620, Loss: 0.0019501004135236144\n",
      "Iteration 2630, Loss: 0.0019578086212277412\n",
      "Iteration 2640, Loss: 0.00185475405305624\n",
      "Iteration 2650, Loss: 0.001939395209774375\n",
      "Iteration 2660, Loss: 0.0019155963091179729\n",
      "Iteration 2670, Loss: 0.0018916652770712972\n",
      "Iteration 2680, Loss: 0.001840745797380805\n",
      "Iteration 2690, Loss: 0.0018996886210516095\n",
      "Iteration 2700, Loss: 0.0018290667794644833\n",
      "Iteration 2710, Loss: 0.00178768509067595\n",
      "Iteration 2720, Loss: 0.0019216407090425491\n",
      "Iteration 2730, Loss: 0.0018282291712239385\n",
      "Iteration 2740, Loss: 0.001874274923466146\n",
      "Iteration 2750, Loss: 0.0018061317969113588\n",
      "Iteration 2760, Loss: 0.001783425803296268\n",
      "Iteration 2770, Loss: 0.0018401145935058594\n",
      "Iteration 2780, Loss: 0.0019022832857444882\n",
      "Iteration 2790, Loss: 0.0018431437201797962\n",
      "Iteration 2800, Loss: 0.0017858102219179273\n",
      "Iteration 2810, Loss: 0.0016436843434348702\n",
      "Iteration 2820, Loss: 0.0018049165373668075\n",
      "Iteration 2830, Loss: 0.0017790892161428928\n",
      "Iteration 2840, Loss: 0.001729726791381836\n",
      "Iteration 2850, Loss: 0.0016866737278178334\n",
      "Iteration 2860, Loss: 0.0017214161343872547\n",
      "Iteration 2870, Loss: 0.0017582657746970654\n",
      "Iteration 2880, Loss: 0.0017527216114103794\n",
      "Iteration 2890, Loss: 0.0016428084345534444\n",
      "Iteration 2900, Loss: 0.0017128668259829283\n",
      "Iteration 2910, Loss: 0.0017503737471997738\n",
      "Iteration 2920, Loss: 0.0016867646481841803\n",
      "Iteration 2930, Loss: 0.001669895718805492\n",
      "Iteration 2940, Loss: 0.0016621977556496859\n",
      "Iteration 2950, Loss: 0.001705238246358931\n",
      "Iteration 2960, Loss: 0.0016022525960579515\n",
      "Iteration 2970, Loss: 0.0016234115464612842\n",
      "Iteration 2980, Loss: 0.001592683489434421\n",
      "Iteration 2990, Loss: 0.001610783045180142\n",
      "Iteration 3000, Loss: 0.001649504411034286\n",
      "Iteration 3010, Loss: 0.0017329849069938064\n",
      "Iteration 3020, Loss: 0.0015942241298034787\n",
      "Iteration 3030, Loss: 0.0016376932617276907\n",
      "Iteration 3040, Loss: 0.0016296271933242679\n",
      "Iteration 3050, Loss: 0.0015819290420040488\n",
      "Iteration 3060, Loss: 0.0016234093345701694\n",
      "Iteration 3070, Loss: 0.0016138465143740177\n",
      "Iteration 3080, Loss: 0.001573367859236896\n",
      "Iteration 3090, Loss: 0.0016442176420241594\n",
      "Iteration 3100, Loss: 0.0015212089056149125\n",
      "Iteration 3110, Loss: 0.0015860460698604584\n",
      "Iteration 3120, Loss: 0.0016286018071696162\n",
      "Iteration 3130, Loss: 0.001570924068801105\n",
      "Iteration 3140, Loss: 0.0016037548193708062\n",
      "Iteration 3150, Loss: 0.0015676459297537804\n",
      "Iteration 3160, Loss: 0.00157889851834625\n",
      "Iteration 3170, Loss: 0.0015616088639944792\n",
      "Iteration 3180, Loss: 0.0014879027148708701\n",
      "Iteration 3190, Loss: 0.0015436350367963314\n",
      "Iteration 3200, Loss: 0.0015037852572277188\n",
      "Iteration 3210, Loss: 0.0014906337019056082\n",
      "Iteration 3220, Loss: 0.0014073996571823955\n",
      "Iteration 3230, Loss: 0.0014569584745913744\n",
      "Iteration 3240, Loss: 0.001504498883150518\n",
      "Iteration 3250, Loss: 0.0014841061783954501\n",
      "Iteration 3260, Loss: 0.0015121353790163994\n",
      "Iteration 3270, Loss: 0.0014785615494474769\n",
      "Iteration 3280, Loss: 0.001485962187871337\n",
      "Iteration 3290, Loss: 0.0014714502030983567\n",
      "Iteration 3300, Loss: 0.0014580409042537212\n",
      "Iteration 3310, Loss: 0.0014613672392442822\n",
      "Iteration 3320, Loss: 0.001456902245990932\n",
      "Iteration 3330, Loss: 0.0014785004314035177\n",
      "Iteration 3340, Loss: 0.0014367708936333656\n",
      "Iteration 3350, Loss: 0.0014402777887880802\n",
      "Iteration 3360, Loss: 0.0013900432968512177\n",
      "Iteration 3370, Loss: 0.0013591049937531352\n",
      "Iteration 3380, Loss: 0.0013920781202614307\n",
      "Iteration 3390, Loss: 0.0014017546782270074\n",
      "Iteration 3400, Loss: 0.0013343108585104346\n",
      "Iteration 3410, Loss: 0.0014082691632211208\n",
      "Iteration 3420, Loss: 0.0013956987531855702\n",
      "Iteration 3430, Loss: 0.001398021006025374\n",
      "Iteration 3440, Loss: 0.0014273603446781635\n",
      "Iteration 3450, Loss: 0.0013043403159826994\n",
      "Iteration 3460, Loss: 0.0012917360290884972\n",
      "Iteration 3470, Loss: 0.0014065043069422245\n",
      "Iteration 3480, Loss: 0.0012606899254024029\n",
      "Iteration 3490, Loss: 0.0013627198059111834\n",
      "Iteration 3500, Loss: 0.0012961046304553747\n",
      "Iteration 3510, Loss: 0.0013198564993217587\n",
      "Iteration 3520, Loss: 0.0013144033728167415\n",
      "Iteration 3530, Loss: 0.0013093006564304233\n",
      "Iteration 3540, Loss: 0.0013683143770322204\n",
      "Iteration 3550, Loss: 0.001338192611001432\n",
      "Iteration 3560, Loss: 0.0013628349406644702\n",
      "Iteration 3570, Loss: 0.0012760274112224579\n",
      "Iteration 3580, Loss: 0.001301978132687509\n",
      "Iteration 3590, Loss: 0.001299997908063233\n",
      "Iteration 3600, Loss: 0.0012767548905685544\n",
      "Iteration 3610, Loss: 0.001317924470640719\n",
      "Iteration 3620, Loss: 0.0012790218461304903\n",
      "Iteration 3630, Loss: 0.0012828931212425232\n",
      "Iteration 3640, Loss: 0.0012946274364367127\n",
      "Iteration 3650, Loss: 0.0012665878748521209\n",
      "Iteration 3660, Loss: 0.001226673717610538\n",
      "Iteration 3670, Loss: 0.0012791419867426157\n",
      "Iteration 3680, Loss: 0.001214084099046886\n",
      "Iteration 3690, Loss: 0.0012565782526507974\n",
      "Iteration 3700, Loss: 0.0012043945025652647\n",
      "Iteration 3710, Loss: 0.0012793358182534575\n",
      "Iteration 3720, Loss: 0.001252559246495366\n",
      "Iteration 3730, Loss: 0.001226317952387035\n",
      "Iteration 3740, Loss: 0.0012137733865529299\n",
      "Iteration 3750, Loss: 0.001180302700959146\n",
      "Iteration 3760, Loss: 0.0012507304782047868\n",
      "Iteration 3770, Loss: 0.0012234714813530445\n",
      "Iteration 3780, Loss: 0.0012290956219658256\n",
      "Iteration 3790, Loss: 0.0011711467523127794\n",
      "Iteration 3800, Loss: 0.0012101889587938786\n",
      "Iteration 3810, Loss: 0.0011892501497641206\n",
      "Iteration 3820, Loss: 0.0011428340803831816\n",
      "Iteration 3830, Loss: 0.0011866878485307097\n",
      "Iteration 3840, Loss: 0.0012061360757797956\n",
      "Iteration 3850, Loss: 0.0011273878626525402\n",
      "Iteration 3860, Loss: 0.001168060814961791\n",
      "Iteration 3870, Loss: 0.0011951287742704153\n",
      "Iteration 3880, Loss: 0.0012030641082674265\n",
      "Iteration 3890, Loss: 0.0010825636563822627\n",
      "Iteration 3900, Loss: 0.0011759363114833832\n",
      "Iteration 3910, Loss: 0.0011495533399283886\n",
      "Iteration 3920, Loss: 0.0011246580397710204\n",
      "Iteration 3930, Loss: 0.0011329674161970615\n",
      "Iteration 3940, Loss: 0.0011235730489715934\n",
      "Iteration 3950, Loss: 0.0011070662876591086\n",
      "Iteration 3960, Loss: 0.0011615508701652288\n",
      "Iteration 3970, Loss: 0.0011169667122885585\n",
      "Iteration 3980, Loss: 0.001095598447136581\n",
      "Iteration 3990, Loss: 0.0011143963783979416\n",
      "Iteration 4000, Loss: 0.001089582801796496\n",
      "Iteration 4010, Loss: 0.0011231092503294349\n",
      "Iteration 4020, Loss: 0.0011995198437944055\n",
      "Iteration 4030, Loss: 0.001116186031140387\n",
      "Iteration 4040, Loss: 0.0010564812691882253\n",
      "Iteration 4050, Loss: 0.00108038738835603\n",
      "Iteration 4060, Loss: 0.0011266012443229556\n",
      "Iteration 4070, Loss: 0.0011351440334692597\n",
      "Iteration 4080, Loss: 0.0010292025981470942\n",
      "Iteration 4090, Loss: 0.0010417537996545434\n",
      "Iteration 4100, Loss: 0.0010156037751585245\n",
      "Iteration 4110, Loss: 0.001033091451972723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  96%|█████████▌| 23/24 [18:47<01:07, 67.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 4115\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 4116, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.047478739386526164, 'L2_avg': 0.060860562455968735, 'End_point_L1_avg': 0.03083204472960791, 'End_point_L2_avg': 0.03135279330766175}\n",
      "Iteration 0, Loss: 1.1487267017364502\n",
      "Iteration 10, Loss: 0.7776565551757812\n",
      "Iteration 20, Loss: 0.5811975598335266\n",
      "Iteration 30, Loss: 0.43260058760643005\n",
      "Iteration 40, Loss: 0.31768885254859924\n",
      "Iteration 50, Loss: 0.23754467070102692\n",
      "Iteration 60, Loss: 0.17714884877204895\n",
      "Iteration 70, Loss: 0.13549569249153137\n",
      "Iteration 80, Loss: 0.11153502762317657\n",
      "Iteration 90, Loss: 0.08484762161970139\n",
      "Iteration 100, Loss: 0.07268813997507095\n",
      "Iteration 110, Loss: 0.05709322541952133\n",
      "Iteration 120, Loss: 0.05571138486266136\n",
      "Iteration 130, Loss: 0.04894236847758293\n",
      "Iteration 140, Loss: 0.04273262619972229\n",
      "Iteration 150, Loss: 0.03802567720413208\n",
      "Iteration 160, Loss: 0.03946540504693985\n",
      "Iteration 170, Loss: 0.036772243678569794\n",
      "Iteration 180, Loss: 0.03225703164935112\n",
      "Iteration 190, Loss: 0.030940860509872437\n",
      "Iteration 200, Loss: 0.029923975467681885\n",
      "Iteration 210, Loss: 0.027845339849591255\n",
      "Iteration 220, Loss: 0.02447735145688057\n",
      "Iteration 230, Loss: 0.022467076778411865\n",
      "Iteration 240, Loss: 0.021303905174136162\n",
      "Iteration 250, Loss: 0.022807346656918526\n",
      "Iteration 260, Loss: 0.0200220737606287\n",
      "Iteration 270, Loss: 0.01866190694272518\n",
      "Iteration 280, Loss: 0.017827829346060753\n",
      "Iteration 290, Loss: 0.017256906256079674\n",
      "Iteration 300, Loss: 0.01870039477944374\n",
      "Iteration 310, Loss: 0.017681773751974106\n",
      "Iteration 320, Loss: 0.015931477770209312\n",
      "Iteration 330, Loss: 0.01427539810538292\n",
      "Iteration 340, Loss: 0.0153184300288558\n",
      "Iteration 350, Loss: 0.013425587676465511\n",
      "Iteration 360, Loss: 0.013312425464391708\n",
      "Iteration 370, Loss: 0.014029073528945446\n",
      "Iteration 380, Loss: 0.012927893549203873\n",
      "Iteration 390, Loss: 0.012392712756991386\n",
      "Iteration 400, Loss: 0.010943719185888767\n",
      "Iteration 410, Loss: 0.011823841370642185\n",
      "Iteration 420, Loss: 0.011445780284702778\n",
      "Iteration 430, Loss: 0.009638335555791855\n",
      "Iteration 440, Loss: 0.010831641964614391\n",
      "Iteration 450, Loss: 0.009472241625189781\n",
      "Iteration 460, Loss: 0.009944841265678406\n",
      "Iteration 470, Loss: 0.009490265510976315\n",
      "Iteration 480, Loss: 0.009323745965957642\n",
      "Iteration 490, Loss: 0.008418704383075237\n",
      "Iteration 500, Loss: 0.008153743110597134\n",
      "Iteration 510, Loss: 0.007454417180269957\n",
      "Iteration 520, Loss: 0.008065963163971901\n",
      "Iteration 530, Loss: 0.008368765003979206\n",
      "Iteration 540, Loss: 0.008554881438612938\n",
      "Iteration 550, Loss: 0.007359073497354984\n",
      "Iteration 560, Loss: 0.007015296723693609\n",
      "Iteration 570, Loss: 0.008357093669474125\n",
      "Iteration 580, Loss: 0.007707735523581505\n",
      "Iteration 590, Loss: 0.007338014431297779\n",
      "Iteration 600, Loss: 0.0071540228091180325\n",
      "Iteration 610, Loss: 0.00697245541960001\n",
      "Iteration 620, Loss: 0.0066948700696229935\n",
      "Iteration 630, Loss: 0.006717974785715342\n",
      "Iteration 640, Loss: 0.006735009141266346\n",
      "Iteration 650, Loss: 0.006017965264618397\n",
      "Iteration 660, Loss: 0.005733110010623932\n",
      "Iteration 670, Loss: 0.0065959300845861435\n",
      "Iteration 680, Loss: 0.005800480954349041\n",
      "Iteration 690, Loss: 0.006325580179691315\n",
      "Iteration 700, Loss: 0.005451219156384468\n",
      "Iteration 710, Loss: 0.00546176265925169\n",
      "Iteration 720, Loss: 0.005433279555290937\n",
      "Iteration 730, Loss: 0.0061491383239626884\n",
      "Iteration 740, Loss: 0.004778984002768993\n",
      "Iteration 750, Loss: 0.005438320804387331\n",
      "Iteration 760, Loss: 0.005042101256549358\n",
      "Iteration 770, Loss: 0.004797168076038361\n",
      "Iteration 780, Loss: 0.005072989501059055\n",
      "Iteration 790, Loss: 0.004821787588298321\n",
      "Iteration 800, Loss: 0.004394411109387875\n",
      "Iteration 810, Loss: 0.004934652242809534\n",
      "Iteration 820, Loss: 0.004464130848646164\n",
      "Iteration 830, Loss: 0.004405817948281765\n",
      "Iteration 840, Loss: 0.004262206144630909\n",
      "Iteration 850, Loss: 0.004461782984435558\n",
      "Iteration 860, Loss: 0.0043263621628284454\n",
      "Iteration 870, Loss: 0.00428870040923357\n",
      "Iteration 880, Loss: 0.004085117019712925\n",
      "Iteration 890, Loss: 0.004097568802535534\n",
      "Iteration 900, Loss: 0.0037333955988287926\n",
      "Iteration 910, Loss: 0.0035731729585677385\n",
      "Iteration 920, Loss: 0.004251616541296244\n",
      "Iteration 930, Loss: 0.003726618131622672\n",
      "Iteration 940, Loss: 0.003695898689329624\n",
      "Iteration 950, Loss: 0.0037170604337006807\n",
      "Iteration 960, Loss: 0.0037348917685449123\n",
      "Iteration 970, Loss: 0.003371125552803278\n",
      "Iteration 980, Loss: 0.003663301933556795\n",
      "Iteration 990, Loss: 0.0033919650595635176\n",
      "Iteration 1000, Loss: 0.0033852728083729744\n",
      "Iteration 1010, Loss: 0.0033012221101671457\n",
      "Iteration 1020, Loss: 0.0033510494977235794\n",
      "Iteration 1030, Loss: 0.003516208613291383\n",
      "Iteration 1040, Loss: 0.0032691515516489744\n",
      "Iteration 1050, Loss: 0.0033631969708949327\n",
      "Iteration 1060, Loss: 0.0031543332152068615\n",
      "Iteration 1070, Loss: 0.00313272001221776\n",
      "Iteration 1080, Loss: 0.0032275826670229435\n",
      "Iteration 1090, Loss: 0.002956790616735816\n",
      "Iteration 1100, Loss: 0.0029739192686975002\n",
      "Iteration 1110, Loss: 0.0031529043335467577\n",
      "Iteration 1120, Loss: 0.003015342867001891\n",
      "Iteration 1130, Loss: 0.0028618075884878635\n",
      "Iteration 1140, Loss: 0.002902912674471736\n",
      "Iteration 1150, Loss: 0.0026339951436966658\n",
      "Iteration 1160, Loss: 0.003030979074537754\n",
      "Iteration 1170, Loss: 0.0028411175590008497\n",
      "Iteration 1180, Loss: 0.0028112877625972033\n",
      "Iteration 1190, Loss: 0.00264683342538774\n",
      "Iteration 1200, Loss: 0.002642559353262186\n",
      "Iteration 1210, Loss: 0.0026484327390789986\n",
      "Iteration 1220, Loss: 0.0027392320334911346\n",
      "Iteration 1230, Loss: 0.0025592155288904905\n",
      "Iteration 1240, Loss: 0.0026256609708070755\n",
      "Iteration 1250, Loss: 0.002640526043251157\n",
      "Iteration 1260, Loss: 0.0025087047833949327\n",
      "Iteration 1270, Loss: 0.002800997346639633\n",
      "Iteration 1280, Loss: 0.0025417394936084747\n",
      "Iteration 1290, Loss: 0.0024535611737519503\n",
      "Iteration 1300, Loss: 0.0025445499923080206\n",
      "Iteration 1310, Loss: 0.0024732465390115976\n",
      "Iteration 1320, Loss: 0.0023831443395465612\n",
      "Iteration 1330, Loss: 0.002396441763266921\n",
      "Iteration 1340, Loss: 0.002392034512013197\n",
      "Iteration 1350, Loss: 0.0022580677177757025\n",
      "Iteration 1360, Loss: 0.0022781065199524164\n",
      "Iteration 1370, Loss: 0.0023101139813661575\n",
      "Iteration 1380, Loss: 0.0022394321858882904\n",
      "Iteration 1390, Loss: 0.002245262498036027\n",
      "Iteration 1400, Loss: 0.0021607540547847748\n",
      "Iteration 1410, Loss: 0.0021250557620078325\n",
      "Iteration 1420, Loss: 0.002136415336281061\n",
      "Iteration 1430, Loss: 0.00220243982039392\n",
      "Iteration 1440, Loss: 0.0021881975699216127\n",
      "Iteration 1450, Loss: 0.002258161548525095\n",
      "Iteration 1460, Loss: 0.002174271969124675\n",
      "Iteration 1470, Loss: 0.002129185711964965\n",
      "Iteration 1480, Loss: 0.002047252142801881\n",
      "Iteration 1490, Loss: 0.002075736876577139\n",
      "Iteration 1500, Loss: 0.001984942937269807\n",
      "Iteration 1510, Loss: 0.0020111966878175735\n",
      "Iteration 1520, Loss: 0.0021084605250507593\n",
      "Iteration 1530, Loss: 0.0020823858212679625\n",
      "Iteration 1540, Loss: 0.0019269525073468685\n",
      "Iteration 1550, Loss: 0.0020009935833513737\n",
      "Iteration 1560, Loss: 0.00196463824249804\n",
      "Iteration 1570, Loss: 0.0019161261152476072\n",
      "Iteration 1580, Loss: 0.0018965571653097868\n",
      "Iteration 1590, Loss: 0.0019475026056170464\n",
      "Iteration 1600, Loss: 0.0019615290220826864\n",
      "Iteration 1610, Loss: 0.0019472201820462942\n",
      "Iteration 1620, Loss: 0.0018920983420684934\n",
      "Iteration 1630, Loss: 0.0019566707778722048\n",
      "Iteration 1640, Loss: 0.0018844044534489512\n",
      "Iteration 1650, Loss: 0.001765758148394525\n",
      "Iteration 1660, Loss: 0.0018430071650072932\n",
      "Iteration 1670, Loss: 0.0019250304903835058\n",
      "Iteration 1680, Loss: 0.0019095721654593945\n",
      "Iteration 1690, Loss: 0.0018088178476318717\n",
      "Iteration 1700, Loss: 0.00184978311881423\n",
      "Iteration 1710, Loss: 0.0017397244228050113\n",
      "Iteration 1720, Loss: 0.001778502599336207\n",
      "Iteration 1730, Loss: 0.0017767779063433409\n",
      "Iteration 1740, Loss: 0.0016948225675150752\n",
      "Iteration 1750, Loss: 0.0016573953907936811\n",
      "Iteration 1760, Loss: 0.0016706668538972735\n",
      "Iteration 1770, Loss: 0.0018476452678442001\n",
      "Iteration 1780, Loss: 0.001739965402521193\n",
      "Iteration 1790, Loss: 0.0017504459246993065\n",
      "Iteration 1800, Loss: 0.0017626014305278659\n",
      "Iteration 1810, Loss: 0.001695733517408371\n",
      "Iteration 1820, Loss: 0.0017187828198075294\n",
      "Iteration 1830, Loss: 0.001659513683989644\n",
      "Iteration 1840, Loss: 0.0017850868171080947\n",
      "Iteration 1850, Loss: 0.0017878323560580611\n",
      "Iteration 1860, Loss: 0.0016567768761888146\n",
      "Iteration 1870, Loss: 0.0017019559163600206\n",
      "Iteration 1880, Loss: 0.0016884792130440474\n",
      "Iteration 1890, Loss: 0.0016722542932257056\n",
      "Iteration 1900, Loss: 0.0016234088689088821\n",
      "Iteration 1910, Loss: 0.001658173161558807\n",
      "Iteration 1920, Loss: 0.0015830218326300383\n",
      "Iteration 1930, Loss: 0.0016297699185088277\n",
      "Iteration 1940, Loss: 0.001639335067011416\n",
      "Iteration 1950, Loss: 0.0016887702513486147\n",
      "Iteration 1960, Loss: 0.0015642185462638736\n",
      "Iteration 1970, Loss: 0.001513565774075687\n",
      "Iteration 1980, Loss: 0.0015422716969624162\n",
      "Iteration 1990, Loss: 0.0015215741004794836\n",
      "Iteration 2000, Loss: 0.0015310568269342184\n",
      "Iteration 2010, Loss: 0.0015169945545494556\n",
      "Iteration 2020, Loss: 0.0015580074395984411\n",
      "Iteration 2030, Loss: 0.0014857698697596788\n",
      "Iteration 2040, Loss: 0.0014906178694218397\n",
      "Iteration 2050, Loss: 0.0015033893287181854\n",
      "Iteration 2060, Loss: 0.0015019145794212818\n",
      "Iteration 2070, Loss: 0.0014430091250687838\n",
      "Iteration 2080, Loss: 0.0015531243989244103\n",
      "Iteration 2090, Loss: 0.0014249609084799886\n",
      "Iteration 2100, Loss: 0.0014220570446923375\n",
      "Iteration 2110, Loss: 0.001518276403658092\n",
      "Iteration 2120, Loss: 0.0014502133708447218\n",
      "Iteration 2130, Loss: 0.0013348072534427047\n",
      "Iteration 2140, Loss: 0.0014817682094871998\n",
      "Iteration 2150, Loss: 0.001469222828745842\n",
      "Iteration 2160, Loss: 0.0014572461368516088\n",
      "Iteration 2170, Loss: 0.0014387641567736864\n",
      "Iteration 2180, Loss: 0.0014298438327386975\n",
      "Iteration 2190, Loss: 0.0014687019865959883\n",
      "Iteration 2200, Loss: 0.0013845704961568117\n",
      "Iteration 2210, Loss: 0.0013754024403169751\n",
      "Iteration 2220, Loss: 0.001412698533385992\n",
      "Iteration 2230, Loss: 0.001382015529088676\n",
      "Iteration 2240, Loss: 0.001360817812383175\n",
      "Iteration 2250, Loss: 0.0013622075784951448\n",
      "Iteration 2260, Loss: 0.0012864172458648682\n",
      "Iteration 2270, Loss: 0.0014109212206676602\n",
      "Iteration 2280, Loss: 0.0014008323196321726\n",
      "Iteration 2290, Loss: 0.0013462461065500975\n",
      "Iteration 2300, Loss: 0.0012913142563775182\n",
      "Iteration 2310, Loss: 0.001261844183318317\n",
      "Iteration 2320, Loss: 0.0012605924857780337\n",
      "Iteration 2330, Loss: 0.0012983217602595687\n",
      "Iteration 2340, Loss: 0.0013013428542762995\n",
      "Iteration 2350, Loss: 0.001311453408561647\n",
      "Iteration 2360, Loss: 0.0012924792245030403\n",
      "Iteration 2370, Loss: 0.0012395536759868264\n",
      "Iteration 2380, Loss: 0.001255506300367415\n",
      "Iteration 2390, Loss: 0.001303582452237606\n",
      "Iteration 2400, Loss: 0.001226159860379994\n",
      "Iteration 2410, Loss: 0.0012433727970346808\n",
      "Iteration 2420, Loss: 0.0012775539653375745\n",
      "Iteration 2430, Loss: 0.0012753182090818882\n",
      "Iteration 2440, Loss: 0.001282556913793087\n",
      "Iteration 2450, Loss: 0.0012379358522593975\n",
      "Iteration 2460, Loss: 0.001230223337188363\n",
      "Iteration 2470, Loss: 0.0012442610459402204\n",
      "Iteration 2480, Loss: 0.0012276313500478864\n",
      "Iteration 2490, Loss: 0.0012314064661040902\n",
      "Iteration 2500, Loss: 0.0011831927113234997\n",
      "Iteration 2510, Loss: 0.0012139531318098307\n",
      "Iteration 2520, Loss: 0.001224673818796873\n",
      "Iteration 2530, Loss: 0.0011689683888107538\n",
      "Iteration 2540, Loss: 0.0011765982490032911\n",
      "Iteration 2550, Loss: 0.00116715207695961\n",
      "Iteration 2560, Loss: 0.0012212652945891023\n",
      "Iteration 2570, Loss: 0.0011695623397827148\n",
      "Iteration 2580, Loss: 0.0012278653448447585\n",
      "Iteration 2590, Loss: 0.001167350565083325\n",
      "Iteration 2600, Loss: 0.0011857474455609918\n",
      "Iteration 2610, Loss: 0.0012009965721517801\n",
      "Iteration 2620, Loss: 0.0011435672640800476\n",
      "Iteration 2630, Loss: 0.001153906574472785\n",
      "Iteration 2640, Loss: 0.001183875254355371\n",
      "Iteration 2650, Loss: 0.0011684412602335215\n",
      "Iteration 2660, Loss: 0.0011173044331371784\n",
      "Iteration 2670, Loss: 0.0011344033991917968\n",
      "Iteration 2680, Loss: 0.0011162899900227785\n",
      "Iteration 2690, Loss: 0.0011162664741277695\n",
      "Iteration 2700, Loss: 0.0011199482250958681\n",
      "Iteration 2710, Loss: 0.001146696275100112\n",
      "Iteration 2720, Loss: 0.001096770167350769\n",
      "Iteration 2730, Loss: 0.0010689744958654046\n",
      "Iteration 2740, Loss: 0.0010554484324529767\n",
      "Iteration 2750, Loss: 0.0010474001755937934\n",
      "Iteration 2760, Loss: 0.0010607193689793348\n",
      "Iteration 2770, Loss: 0.001109361182898283\n",
      "Iteration 2780, Loss: 0.0010570562444627285\n",
      "Iteration 2790, Loss: 0.0010203588753938675\n",
      "Iteration 2800, Loss: 0.0010497025214135647\n",
      "Iteration 2810, Loss: 0.001064254785887897\n",
      "Iteration 2820, Loss: 0.0011652986286208034\n",
      "Iteration 2830, Loss: 0.0010158794466406107\n",
      "Iteration 2840, Loss: 0.0010701022110879421\n",
      "Iteration 2850, Loss: 0.0010178013471886516\n",
      "Iteration 2860, Loss: 0.001053644809871912\n",
      "Iteration 2870, Loss: 0.0009982616174966097\n",
      "Iteration 2880, Loss: 0.001050161081366241\n",
      "Iteration 2890, Loss: 0.000995582900941372\n",
      "Iteration 2900, Loss: 0.0010282492730766535\n",
      "Iteration 2910, Loss: 0.0010318502318114042\n",
      "Iteration 2920, Loss: 0.0010120334336534142\n",
      "Iteration 2930, Loss: 0.0010331713128834963\n",
      "Iteration 2940, Loss: 0.0009808308677747846\n",
      "Iteration 2950, Loss: 0.0010196070652455091\n",
      "Iteration 2960, Loss: 0.0009565293439663947\n",
      "Iteration 2970, Loss: 0.0010177399963140488\n",
      "Iteration 2980, Loss: 0.00099031045101583\n",
      "Iteration 2990, Loss: 0.0009808230679482222\n",
      "Iteration 3000, Loss: 0.0009839205304160714\n",
      "Iteration 3010, Loss: 0.0009479648433625698\n",
      "Iteration 3020, Loss: 0.0009467953350394964\n",
      "Iteration 3030, Loss: 0.0009399348055012524\n",
      "Iteration 3040, Loss: 0.0009083868353627622\n",
      "Iteration 3050, Loss: 0.000945878098718822\n",
      "Iteration 3060, Loss: 0.000999521929770708\n",
      "Iteration 3070, Loss: 0.0009663127129897475\n",
      "Iteration 3080, Loss: 0.0009229495190083981\n",
      "Iteration 3090, Loss: 0.0009473004611209035\n",
      "Iteration 3100, Loss: 0.0009058256400749087\n",
      "Iteration 3110, Loss: 0.0009102030890062451\n",
      "Iteration 3120, Loss: 0.000906767207197845\n",
      "Iteration 3130, Loss: 0.000907948415260762\n",
      "Iteration 3140, Loss: 0.0008994631934911013\n",
      "Iteration 3150, Loss: 0.0009277659701183438\n",
      "Iteration 3160, Loss: 0.0008407322457060218\n",
      "Iteration 3170, Loss: 0.0008981598075479269\n",
      "Iteration 3180, Loss: 0.0008820102084428072\n",
      "Iteration 3190, Loss: 0.0008604647591710091\n",
      "Iteration 3200, Loss: 0.0008806691039353609\n",
      "Iteration 3210, Loss: 0.0008911322220228612\n",
      "Iteration 3220, Loss: 0.0008926302543841302\n",
      "Iteration 3230, Loss: 0.0008579804562032223\n",
      "Iteration 3240, Loss: 0.0008464877610094845\n",
      "Iteration 3250, Loss: 0.0008289814577437937\n",
      "Iteration 3260, Loss: 0.0008492887718603015\n",
      "Iteration 3270, Loss: 0.0008770002168603241\n",
      "Iteration 3280, Loss: 0.0008601460140198469\n",
      "Iteration 3290, Loss: 0.0008188638603314757\n",
      "Iteration 3300, Loss: 0.0008156367111951113\n",
      "Iteration 3310, Loss: 0.0008219881565310061\n",
      "Iteration 3320, Loss: 0.0007758053252473474\n",
      "Iteration 3330, Loss: 0.0008247055811807513\n",
      "Iteration 3340, Loss: 0.0008017346845008433\n",
      "Iteration 3350, Loss: 0.0008379612700082362\n",
      "Iteration 3360, Loss: 0.0007874856237322092\n",
      "Iteration 3370, Loss: 0.0007534486940130591\n",
      "Iteration 3380, Loss: 0.0007986953714862466\n",
      "Iteration 3390, Loss: 0.0007681954302825034\n",
      "Iteration 3400, Loss: 0.0008083260036073625\n",
      "Iteration 3410, Loss: 0.0007680062553845346\n",
      "Iteration 3420, Loss: 0.0007666749879717827\n",
      "Iteration 3430, Loss: 0.0007500772480852902\n",
      "Iteration 3440, Loss: 0.0007824612548574805\n",
      "Iteration 3450, Loss: 0.0007775091798976064\n",
      "Iteration 3460, Loss: 0.0007355218986049294\n",
      "Iteration 3470, Loss: 0.0007897690520621836\n",
      "Iteration 3480, Loss: 0.0007876118179410696\n",
      "Iteration 3490, Loss: 0.0007554361363872886\n",
      "Iteration 3500, Loss: 0.0007538255304098129\n",
      "Iteration 3510, Loss: 0.0007769824005663395\n",
      "Iteration 3520, Loss: 0.0007238038233481348\n",
      "Iteration 3530, Loss: 0.000753289379645139\n",
      "Iteration 3540, Loss: 0.0007360873860307038\n",
      "Iteration 3550, Loss: 0.0006974981515668333\n",
      "Iteration 3560, Loss: 0.0007398204761557281\n",
      "Iteration 3570, Loss: 0.0007166508003138006\n",
      "Iteration 3580, Loss: 0.000685068778693676\n",
      "Iteration 3590, Loss: 0.0006702013197354972\n",
      "Iteration 3600, Loss: 0.0007199373212642968\n",
      "Iteration 3610, Loss: 0.0007067605620250106\n",
      "Iteration 3620, Loss: 0.0007341564632952213\n",
      "Iteration 3630, Loss: 0.0007022139616310596\n",
      "Iteration 3640, Loss: 0.0006842826260253787\n",
      "Iteration 3650, Loss: 0.00066317745950073\n",
      "Iteration 3660, Loss: 0.0006757451337762177\n",
      "Iteration 3670, Loss: 0.0006507015787065029\n",
      "Iteration 3680, Loss: 0.0006998863536864519\n",
      "Iteration 3690, Loss: 0.0006790639599785209\n",
      "Iteration 3700, Loss: 0.0006682193488813937\n",
      "Iteration 3710, Loss: 0.0006355778314173222\n",
      "Iteration 3720, Loss: 0.0006402311264537275\n",
      "Iteration 3730, Loss: 0.0006810481427237391\n",
      "Iteration 3740, Loss: 0.0006589750992134213\n",
      "Iteration 3750, Loss: 0.0006436469848267734\n",
      "Iteration 3760, Loss: 0.0006195949972607195\n",
      "Iteration 3770, Loss: 0.0006797289825044572\n",
      "Iteration 3780, Loss: 0.0006182073266245425\n",
      "Iteration 3790, Loss: 0.000637509860098362\n",
      "Iteration 3800, Loss: 0.0006098178564570844\n",
      "Iteration 3810, Loss: 0.0006396473618224263\n",
      "Iteration 3820, Loss: 0.000617528276052326\n",
      "Iteration 3830, Loss: 0.0006544225034303963\n",
      "Iteration 3840, Loss: 0.0006266519194468856\n",
      "Iteration 3850, Loss: 0.0006581941852346063\n",
      "Iteration 3860, Loss: 0.0006140389014035463\n",
      "Iteration 3870, Loss: 0.0005926043959334493\n",
      "Iteration 3880, Loss: 0.0006097377627156675\n",
      "Iteration 3890, Loss: 0.0005762602668255568\n",
      "Iteration 3900, Loss: 0.0005911363987252116\n",
      "Iteration 3910, Loss: 0.0005856956704519689\n",
      "Iteration 3920, Loss: 0.0005922932177782059\n",
      "Iteration 3930, Loss: 0.0005684243515133858\n",
      "Iteration 3940, Loss: 0.0005543933948501945\n",
      "Iteration 3950, Loss: 0.0005580669385381043\n",
      "Iteration 3960, Loss: 0.0005556351970881224\n",
      "Iteration 3970, Loss: 0.0005512505886144936\n",
      "Iteration 3980, Loss: 0.0005327341496013105\n",
      "Iteration 3990, Loss: 0.0005351852159947157\n",
      "Iteration 4000, Loss: 0.0005649527884088457\n",
      "Iteration 4010, Loss: 0.0005596608389168978\n",
      "Iteration 4020, Loss: 0.0005482686683535576\n",
      "Iteration 4030, Loss: 0.0005735468002967536\n",
      "Iteration 4040, Loss: 0.0005359784699976444\n",
      "Iteration 4050, Loss: 0.0005244631320238113\n",
      "Iteration 4060, Loss: 0.000522935763001442\n",
      "Iteration 4070, Loss: 0.0005446065915748477\n",
      "Iteration 4080, Loss: 0.000517929729539901\n",
      "Iteration 4090, Loss: 0.0005341421347111464\n",
      "Iteration 4100, Loss: 0.0005074418149888515\n",
      "Iteration 4110, Loss: 0.0005160230793990195\n",
      "Iteration 4120, Loss: 0.0005250729736872017\n",
      "Iteration 4130, Loss: 0.0005251935217529535\n",
      "Iteration 4140, Loss: 0.0004999713855795562\n",
      "Iteration 4150, Loss: 0.0004943521926179528\n",
      "Iteration 4160, Loss: 0.000483633775729686\n",
      "Iteration 4170, Loss: 0.0005355161265470088\n",
      "Iteration 4180, Loss: 0.0004966851556673646\n",
      "Iteration 4190, Loss: 0.00047144299605861306\n",
      "Iteration 4200, Loss: 0.00046828118502162397\n",
      "Iteration 4210, Loss: 0.0004783850163221359\n",
      "Iteration 4220, Loss: 0.0004760327865369618\n",
      "Iteration 4230, Loss: 0.00046209769789129496\n",
      "Iteration 4240, Loss: 0.0004903182270936668\n",
      "Iteration 4250, Loss: 0.0004487508558668196\n",
      "Iteration 4260, Loss: 0.00047149619786068797\n",
      "Iteration 4270, Loss: 0.0004624371067620814\n",
      "Iteration 4280, Loss: 0.0004493383748922497\n",
      "Iteration 4290, Loss: 0.00047445620293729007\n",
      "Iteration 4300, Loss: 0.00046469640801660717\n",
      "Iteration 4310, Loss: 0.00045374600449576974\n",
      "Iteration 4320, Loss: 0.0004310391959734261\n",
      "Iteration 4330, Loss: 0.0004478806222323328\n",
      "Iteration 4340, Loss: 0.0004340770829003304\n",
      "Iteration 4350, Loss: 0.00043377644033171237\n",
      "Iteration 4360, Loss: 0.00044684679596684873\n",
      "Iteration 4370, Loss: 0.00042813719483092427\n",
      "Iteration 4380, Loss: 0.0004539511282928288\n",
      "Iteration 4390, Loss: 0.000403645884944126\n",
      "Iteration 4400, Loss: 0.00042010279139503837\n",
      "Iteration 4410, Loss: 0.0004293458769097924\n",
      "Iteration 4420, Loss: 0.000429088540840894\n",
      "Iteration 4430, Loss: 0.0004238444089423865\n",
      "Iteration 4440, Loss: 0.00041487530688755214\n",
      "Iteration 4450, Loss: 0.00041013190639205277\n",
      "Iteration 4460, Loss: 0.00038769494858570397\n",
      "Iteration 4470, Loss: 0.0004158095398452133\n",
      "Iteration 4480, Loss: 0.0004300904111005366\n",
      "Iteration 4490, Loss: 0.0004125603009015322\n",
      "Iteration 4500, Loss: 0.0003780885017476976\n",
      "Iteration 4510, Loss: 0.0003935833810828626\n",
      "Iteration 4520, Loss: 0.00038306403439491987\n",
      "Iteration 4530, Loss: 0.0004026875540148467\n",
      "Iteration 4540, Loss: 0.0004007275274489075\n",
      "Iteration 4550, Loss: 0.00038434192538261414\n",
      "Iteration 4560, Loss: 0.00039331248262897134\n",
      "Iteration 4570, Loss: 0.00037888524821028113\n",
      "Iteration 4580, Loss: 0.0003876867704093456\n",
      "Iteration 4590, Loss: 0.00035200107959099114\n",
      "Iteration 4600, Loss: 0.00034915731521323323\n",
      "Iteration 4610, Loss: 0.00036401438410393894\n",
      "Iteration 4620, Loss: 0.0003805296728387475\n",
      "Iteration 4630, Loss: 0.0003633828309830278\n",
      "Iteration 4640, Loss: 0.0003808054607361555\n",
      "Iteration 4650, Loss: 0.00035013986052945256\n",
      "Iteration 4660, Loss: 0.00036702147917822003\n",
      "Iteration 4670, Loss: 0.0003566536179278046\n",
      "Iteration 4680, Loss: 0.0003453283861745149\n",
      "Iteration 4690, Loss: 0.0003455348196439445\n",
      "Iteration 4700, Loss: 0.0003557246527634561\n",
      "Iteration 4710, Loss: 0.0003336380759719759\n",
      "Iteration 4720, Loss: 0.00033334660110995173\n",
      "Iteration 4730, Loss: 0.00033224336220882833\n",
      "Iteration 4740, Loss: 0.00034418245195411146\n",
      "Iteration 4750, Loss: 0.0003350227198097855\n",
      "Iteration 4760, Loss: 0.00033984778565354645\n",
      "Iteration 4770, Loss: 0.00032683476456440985\n",
      "Iteration 4780, Loss: 0.0003391439968254417\n",
      "Iteration 4790, Loss: 0.000336136989062652\n",
      "Iteration 4800, Loss: 0.00033632919075898826\n",
      "Iteration 4810, Loss: 0.0003305636055301875\n",
      "Iteration 4820, Loss: 0.00031883915653452277\n",
      "Iteration 4830, Loss: 0.00034177451743744314\n",
      "Iteration 4840, Loss: 0.0003143349022138864\n",
      "Iteration 4850, Loss: 0.00031800169381313026\n",
      "Iteration 4860, Loss: 0.00031822448363527656\n",
      "Iteration 4870, Loss: 0.0003144138609059155\n",
      "Iteration 4880, Loss: 0.000301681604469195\n",
      "Iteration 4890, Loss: 0.00030368915759027004\n",
      "Iteration 4900, Loss: 0.000305565248709172\n",
      "Iteration 4910, Loss: 0.00031873886473476887\n",
      "Iteration 4920, Loss: 0.0003124541835859418\n",
      "Iteration 4930, Loss: 0.00030630090623162687\n",
      "Iteration 4940, Loss: 0.00030608923407271504\n",
      "Iteration 4950, Loss: 0.00029892148450016975\n",
      "Iteration 4960, Loss: 0.0002972940856125206\n",
      "Iteration 4970, Loss: 0.00028972161817364395\n",
      "Iteration 4980, Loss: 0.0002837078645825386\n",
      "Iteration 4990, Loss: 0.0002821811649482697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture: 100%|██████████| 24/24 [20:30<00:00, 51.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 5000, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.024899378052969514, 'L2_avg': 0.03204914398566527, 'End_point_L1_avg': 0.007109332391821751, 'End_point_L2_avg': 0.007353753560285475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.0046456647105515, Min w: 0.0\n",
      "Iteration 10, Loss: 0.002844293601810932, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0023737107403576374, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0020912617910653353, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0024950068909674883, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0022590819280594587, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002021726220846176, Min w: 9.556606028716334e-15\n",
      "Iteration 70, Loss: 0.0021142959594726562, Min w: 3.306791207782565e-26\n",
      "Iteration 80, Loss: 0.0021069420035928488, Min w: 8.424434465821289e-33\n",
      "Iteration 90, Loss: 0.0020853180903941393, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0020011786837130785, Min w: 0.0\n",
      "Iteration 110, Loss: 0.001896410365588963, Min w: 9.80908925027372e-45\n",
      "Iteration 120, Loss: 0.0016404327470809221, Min w: 0.09421173483133316\n",
      "Iteration 130, Loss: 0.002102138474583626, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0020205832552164793, Min w: 9.265763196708576e-07\n",
      "Iteration 150, Loss: 0.002033885568380356, Min w: 2.7315191791938465e-19\n",
      "Iteration 160, Loss: 0.0019731002394109964, Min w: 2.7172261662933295e-10\n",
      "Iteration 170, Loss: 0.0020229879301041365, Min w: 5.5464173783548176e-05\n",
      "Iteration 180, Loss: 0.0020018417853862047, Min w: 3.394939060777369e-12\n",
      "Iteration 190, Loss: 0.002243109280243516, Min w: 6.768245902968872e-13\n",
      "Iteration 200, Loss: 0.0020888536237180233, Min w: 1.5812765593453681e-12\n",
      "Iteration 210, Loss: 0.001961482223123312, Min w: 0.010438693687319756\n",
      "Iteration 220, Loss: 0.0019503546645864844, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002077368786558509, Min w: 1.7850680933406693e-07\n",
      "Iteration 240, Loss: 0.0021230578422546387, Min w: 3.4190093068387153e-23\n",
      "Iteration 250, Loss: 0.0020148560870438814, Min w: 1.98602905244042e-17\n",
      "Iteration 260, Loss: 0.001984412083402276, Min w: 3.99614831333489e-21\n",
      "Iteration 270, Loss: 0.0019822113681584597, Min w: 2.51617252948544e-19\n",
      "Iteration 280, Loss: 0.002013221848756075, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002032806631177664, Min w: 5.469353254738962e-06\n",
      "Iteration 300, Loss: 0.001724880887195468, Min w: 0.001154783763922751\n",
      "Iteration 310, Loss: 0.0018428820185363293, Min w: 0.0003273605543654412\n",
      "Iteration 320, Loss: 0.0018100274028256536, Min w: 0.00017133263463620096\n",
      "Iteration 330, Loss: 0.001958849374204874, Min w: 0.004798486828804016\n",
      "Iteration 340, Loss: 0.002010190626606345, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0020520377438515425, Min w: 2.6819225240615197e-06\n",
      "Iteration 360, Loss: 0.001932969898916781, Min w: 9.388699710976274e-44\n",
      "Iteration 370, Loss: 0.0020100469700992107, Min w: 3.5711866530618863e-07\n",
      "Iteration 380, Loss: 0.0019933392759412527, Min w: 3.163507062708959e-05\n",
      "Iteration 390, Loss: 0.001961643109098077, Min w: 9.6150552797436e-12\n",
      "Iteration 400, Loss: 0.0020011295564472675, Min w: 1.3402622176739496e-16\n",
      "Iteration 410, Loss: 0.0017453720793128014, Min w: 2.263101123389788e-06\n",
      "Iteration 420, Loss: 0.0016938154585659504, Min w: 0.14404484629631042\n",
      "Iteration 430, Loss: 0.0015980444150045514, Min w: 0.06459870934486389\n",
      "Iteration 440, Loss: 0.0018769897287711501, Min w: 0.0001655418600421399\n",
      "Iteration 450, Loss: 0.0020395591855049133, Min w: 4.456700786192869e-09\n",
      "Iteration 460, Loss: 0.002041180618107319, Min w: 9.662746691674329e-08\n",
      "Iteration 470, Loss: 0.0015355159994214773, Min w: 0.1022699698805809\n",
      "Iteration 480, Loss: 0.0016139170620590448, Min w: 0.09961490333080292\n",
      "Iteration 490, Loss: 0.0020005456171929836, Min w: 1.3723945672110116e-26\n",
      "Iteration 500, Loss: 0.002026202389970422, Min w: 1.8675158641734413e-11\n",
      "Iteration 510, Loss: 0.0020370858255773783, Min w: 1.3183318667353379e-30\n",
      "Iteration 520, Loss: 0.0020639835856854916, Min w: 5.386613338487223e-06\n",
      "Iteration 530, Loss: 0.0020796305034309626, Min w: 3.962524804140735e-36\n",
      "Iteration 540, Loss: 0.002033266704529524, Min w: 5.655102312272035e-32\n",
      "Iteration 550, Loss: 0.0021262583322823048, Min w: 3.204418880849852e-13\n",
      "Iteration 560, Loss: 0.001965421251952648, Min w: 0.0023677118588238955\n",
      "Iteration 570, Loss: 0.0018139306921511889, Min w: 0.006302107125520706\n",
      "Iteration 580, Loss: 0.0019891648553311825, Min w: 3.199988714186475e-05\n",
      "Iteration 590, Loss: 0.0019849734380841255, Min w: 6.37292078223289e-16\n",
      "Iteration 600, Loss: 0.0020226561464369297, Min w: 5.040250243837363e-07\n",
      "Iteration 610, Loss: 0.002039087237790227, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0020521022379398346, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0019906912930309772, Min w: 5.66906193134461e-22\n",
      "Iteration 640, Loss: 0.0019450249383226037, Min w: 7.908794259492424e-07\n",
      "Iteration 650, Loss: 0.0020084918942302465, Min w: 1.4829745850875042e-05\n",
      "Iteration 660, Loss: 0.0020589556079357862, Min w: 2.4319448272615172e-22\n",
      "Iteration 670, Loss: 0.0020277348812669516, Min w: 6.918059170857305e-06\n",
      "Iteration 680, Loss: 0.001167737296782434, Min w: 0.39965125918388367\n",
      "Iteration 690, Loss: 0.001381952897645533, Min w: 0.1643882691860199\n",
      "Iteration 700, Loss: 0.000886051042471081, Min w: 0.35942012071609497\n",
      "Iteration 710, Loss: 0.0011700757313519716, Min w: 0.3786700963973999\n",
      "Iteration 720, Loss: 0.00116730818990618, Min w: 0.3577103316783905\n",
      "Iteration 730, Loss: 0.001032925909385085, Min w: 0.424358069896698\n",
      "Iteration 740, Loss: 0.00098367256578058, Min w: 0.46616482734680176\n",
      "Iteration 750, Loss: 0.0010910610435530543, Min w: 0.43136146664619446\n",
      "Iteration 760, Loss: 0.0010610345052555203, Min w: 0.4645345211029053\n",
      "Iteration 770, Loss: 0.0008037199731916189, Min w: 0.5016984939575195\n",
      "Iteration 780, Loss: 0.0009941771859303117, Min w: 0.4939400851726532\n",
      "Iteration 790, Loss: 0.0007782239117659628, Min w: 0.5503025054931641\n",
      "Iteration 800, Loss: 0.0006403632578440011, Min w: 0.5778785943984985\n",
      "Iteration 810, Loss: 0.0006349834147840738, Min w: 0.5680270195007324\n",
      "Iteration 820, Loss: 0.0009404235170222819, Min w: 0.5157107710838318\n",
      "Iteration 830, Loss: 0.000751011073589325, Min w: 0.5640447735786438\n",
      "Iteration 840, Loss: 0.0007549661677330732, Min w: 0.5820496082305908\n",
      "Iteration 850, Loss: 0.0008893213234841824, Min w: 0.5365502238273621\n",
      "Iteration 860, Loss: 0.0006390800699591637, Min w: 0.6234421730041504\n",
      "Iteration 870, Loss: 0.0005092836217954755, Min w: 0.6589654684066772\n",
      "Iteration 880, Loss: 0.0005177927087061107, Min w: 0.6297258138656616\n",
      "Iteration 890, Loss: 0.0005109780468046665, Min w: 0.6728353500366211\n",
      "Iteration 900, Loss: 0.0009605791419744492, Min w: 0.45963454246520996\n",
      "Iteration 910, Loss: 0.0005289974506013095, Min w: 0.6818670630455017\n",
      "Iteration 920, Loss: 0.0004789697995875031, Min w: 0.670413613319397\n",
      "Iteration 930, Loss: 0.00045342548401094973, Min w: 0.6924765706062317\n",
      "Iteration 940, Loss: 0.0006829342455603182, Min w: 0.6306803226470947\n",
      "Iteration 950, Loss: 0.0006643565138801932, Min w: 0.653013288974762\n",
      "Iteration 960, Loss: 0.0008941512787714601, Min w: 0.4385187029838562\n",
      "Iteration 970, Loss: 0.0005298543837852776, Min w: 0.7156690955162048\n",
      "Iteration 980, Loss: 0.00044976582285016775, Min w: 0.7084231376647949\n",
      "Iteration 990, Loss: 0.00040267189615406096, Min w: 0.7504944801330566\n",
      "Iteration 1000, Loss: 0.00046715623466297984, Min w: 0.7281855344772339\n",
      "Iteration 1010, Loss: 0.00037950469413772225, Min w: 0.7587095499038696\n",
      "Iteration 1020, Loss: 0.0005121648428030312, Min w: 0.7351204752922058\n",
      "Iteration 1030, Loss: 0.0008051135228015482, Min w: 0.5093844532966614\n",
      "Iteration 1040, Loss: 0.0006692487513646483, Min w: 0.6255015730857849\n",
      "Iteration 1050, Loss: 0.0007603677222505212, Min w: 0.5059085488319397\n",
      "Iteration 1060, Loss: 0.00035754815326072276, Min w: 0.7544775605201721\n",
      "Iteration 1070, Loss: 0.00031248785671778023, Min w: 0.7912577986717224\n",
      "Iteration 1080, Loss: 0.0004755619738716632, Min w: 0.7440460920333862\n",
      "Iteration 1090, Loss: 0.0008124298765324056, Min w: 0.4563365876674652\n",
      "Iteration 1100, Loss: 0.0007367801736108959, Min w: 0.5540436506271362\n",
      "Iteration 1110, Loss: 0.0005874483031220734, Min w: 0.6856517195701599\n",
      "Iteration 1120, Loss: 0.0003971825062762946, Min w: 0.7888662219047546\n",
      "Iteration 1130, Loss: 0.000591673597227782, Min w: 0.6560363173484802\n",
      "Iteration 1140, Loss: 0.0006279099616222084, Min w: 0.6694417595863342\n",
      "Iteration 1150, Loss: 0.0005802458617836237, Min w: 0.6671409606933594\n",
      "Iteration 1160, Loss: 0.0004975629854016006, Min w: 0.7361683249473572\n",
      "Iteration 1170, Loss: 0.00043533765710890293, Min w: 0.7505688667297363\n",
      "Iteration 1180, Loss: 0.0005272513953968883, Min w: 0.7079294919967651\n",
      "Iteration 1190, Loss: 0.00042288884287700057, Min w: 0.7664462924003601\n",
      "Iteration 1200, Loss: 0.00028008257504552603, Min w: 0.8452571034431458\n",
      "Iteration 1210, Loss: 0.0003407312324270606, Min w: 0.8080236911773682\n",
      "Iteration 1220, Loss: 0.0003523838531691581, Min w: 0.7905340194702148\n",
      "Iteration 1230, Loss: 0.0003357139939907938, Min w: 0.8174707293510437\n",
      "Iteration 1240, Loss: 0.00048087877803482115, Min w: 0.7133498191833496\n",
      "Iteration 0, Loss: 0.0004434931033756584, Min w: 0.7184131741523743\n",
      "Iteration 10, Loss: 0.00043970232945866883, Min w: 0.709891676902771\n",
      "Iteration 20, Loss: 0.00044364421046338975, Min w: 0.7307383418083191\n",
      "Iteration 30, Loss: 0.0004134605987928808, Min w: 0.7663519382476807\n",
      "Iteration 40, Loss: 0.0004174353671260178, Min w: 0.7564955353736877\n",
      "Iteration 50, Loss: 0.00040713470662012696, Min w: 0.7775461077690125\n",
      "Iteration 60, Loss: 0.00036859902320429683, Min w: 0.80296391248703\n",
      "Iteration 70, Loss: 0.0003509384405333549, Min w: 0.8195920586585999\n",
      "Iteration 80, Loss: 0.00028461578767746687, Min w: 0.8466166853904724\n",
      "Iteration 90, Loss: 0.0002617313002701849, Min w: 0.8546996712684631\n",
      "Iteration 100, Loss: 0.0002123437006957829, Min w: 0.8712467551231384\n",
      "Iteration 110, Loss: 0.00019265623996034265, Min w: 0.8869181275367737\n",
      "Iteration 120, Loss: 0.000521237263455987, Min w: 0.6606864929199219\n",
      "Iteration 130, Loss: 0.0003805592132266611, Min w: 0.7435876727104187\n",
      "Iteration 140, Loss: 0.0003468656213954091, Min w: 0.787835955619812\n",
      "Iteration 150, Loss: 0.00046166093670763075, Min w: 0.7009872794151306\n",
      "Iteration 160, Loss: 0.0002815936750266701, Min w: 0.8407707810401917\n",
      "Iteration 170, Loss: 0.00027100753504782915, Min w: 0.8576433062553406\n",
      "Iteration 180, Loss: 0.0003669336438179016, Min w: 0.7797961235046387\n",
      "Iteration 190, Loss: 0.0001833050191635266, Min w: 0.9002913236618042\n",
      "Iteration 200, Loss: 0.0001961960078915581, Min w: 0.8940714001655579\n",
      "Iteration 210, Loss: 0.0005760887288488448, Min w: 0.6279133558273315\n",
      "Iteration 220, Loss: 0.0005817222991026938, Min w: 0.5997219085693359\n",
      "Iteration 230, Loss: 0.0003011906810570508, Min w: 0.8204423189163208\n",
      "Iteration 240, Loss: 0.00040865695336833596, Min w: 0.7259902358055115\n",
      "Iteration 250, Loss: 0.00032934488262981176, Min w: 0.815227210521698\n",
      "Iteration 260, Loss: 0.00019837295985780656, Min w: 0.8938213586807251\n",
      "Iteration 270, Loss: 0.00031561776995658875, Min w: 0.7993136048316956\n",
      "Iteration 280, Loss: 0.0002998832205776125, Min w: 0.8031488656997681\n",
      "Iteration 290, Loss: 0.00038018086343072355, Min w: 0.756895899772644\n",
      "Iteration 300, Loss: 0.00039002991979941726, Min w: 0.7698827981948853\n",
      "Iteration 310, Loss: 0.0004475994501262903, Min w: 0.6885005235671997\n",
      "Iteration 320, Loss: 0.0002532408107072115, Min w: 0.8415741920471191\n",
      "Iteration 330, Loss: 0.00019868645176757127, Min w: 0.8888225555419922\n",
      "Iteration 340, Loss: 0.0004621471744030714, Min w: 0.6845753788948059\n",
      "Iteration 350, Loss: 0.0003301827819086611, Min w: 0.7963772416114807\n",
      "Iteration 360, Loss: 0.0003911240492016077, Min w: 0.7459773421287537\n",
      "Iteration 370, Loss: 0.0002479688555467874, Min w: 0.8704087138175964\n",
      "Iteration 380, Loss: 0.00024695639149285853, Min w: 0.8537563681602478\n",
      "Iteration 390, Loss: 0.00031736615346744657, Min w: 0.7999565601348877\n",
      "Iteration 400, Loss: 0.0002587315102573484, Min w: 0.8325074911117554\n",
      "Iteration 410, Loss: 0.00020244106417521834, Min w: 0.8956587314605713\n",
      "Iteration 420, Loss: 0.000295198115054518, Min w: 0.7942171692848206\n",
      "Iteration 430, Loss: 0.00023103794956114143, Min w: 0.8580076694488525\n",
      "Iteration 440, Loss: 0.00036522551090456545, Min w: 0.7425245046615601\n",
      "Iteration 450, Loss: 0.00029052767786197364, Min w: 0.7975062727928162\n",
      "Iteration 460, Loss: 0.00014798264601267874, Min w: 0.9223625659942627\n",
      "Iteration 470, Loss: 0.0001910635328385979, Min w: 0.8877719044685364\n",
      "Iteration 480, Loss: 0.0002475509827490896, Min w: 0.8682225942611694\n",
      "Iteration 490, Loss: 0.00029630010249093175, Min w: 0.8336425423622131\n",
      "Iteration 500, Loss: 0.0003525869396980852, Min w: 0.7953241467475891\n",
      "Iteration 510, Loss: 0.0002464798162691295, Min w: 0.8384600877761841\n",
      "Iteration 520, Loss: 0.0003025687183253467, Min w: 0.8330821394920349\n",
      "Iteration 530, Loss: 0.00015826249727979302, Min w: 0.9011861681938171\n",
      "Iteration 540, Loss: 0.00033693734440021217, Min w: 0.784203290939331\n",
      "Iteration 550, Loss: 0.0004342689353507012, Min w: 0.7297304272651672\n",
      "Iteration 560, Loss: 0.0003492091491352767, Min w: 0.7693364024162292\n",
      "Iteration 570, Loss: 0.0002834380720742047, Min w: 0.7894679307937622\n",
      "Iteration 580, Loss: 0.0001955851912498474, Min w: 0.8657229542732239\n",
      "Iteration 590, Loss: 0.0002069075999315828, Min w: 0.8685913681983948\n",
      "Iteration 600, Loss: 0.00030352119938470423, Min w: 0.7881712317466736\n",
      "Iteration 610, Loss: 0.00037406603223644197, Min w: 0.7506623864173889\n",
      "Iteration 620, Loss: 0.00040954991709440947, Min w: 0.7156020402908325\n",
      "Iteration 630, Loss: 0.0003838344709947705, Min w: 0.7219931483268738\n",
      "Iteration 640, Loss: 0.00017084847786463797, Min w: 0.8914998173713684\n",
      "Iteration 650, Loss: 0.00014344441296998411, Min w: 0.910492479801178\n",
      "Iteration 660, Loss: 0.00026866281405091286, Min w: 0.8121411204338074\n",
      "Iteration 670, Loss: 0.00020478731312323362, Min w: 0.8555063605308533\n",
      "Iteration 680, Loss: 0.0003106936637777835, Min w: 0.779319167137146\n",
      "Iteration 690, Loss: 0.00035229860804975033, Min w: 0.7449485063552856\n",
      "Iteration 700, Loss: 0.00015347753651440144, Min w: 0.9057700037956238\n",
      "Iteration 710, Loss: 0.00023542232520412654, Min w: 0.8371235132217407\n",
      "Iteration 720, Loss: 0.0003727483272086829, Min w: 0.7240616679191589\n",
      "Iteration 730, Loss: 0.00024823585408739746, Min w: 0.8106650710105896\n",
      "Iteration 740, Loss: 0.0002831107412930578, Min w: 0.803708016872406\n",
      "Iteration 750, Loss: 0.0002900329418480396, Min w: 0.7931379079818726\n",
      "Iteration 760, Loss: 0.000340567174134776, Min w: 0.7533520460128784\n",
      "Iteration 770, Loss: 0.0001571414031786844, Min w: 0.9042560458183289\n",
      "Iteration 780, Loss: 0.00014808478590566665, Min w: 0.914044976234436\n",
      "Iteration 790, Loss: 0.0003338733804412186, Min w: 0.7691213488578796\n",
      "Iteration 800, Loss: 0.00030276936013251543, Min w: 0.7953199148178101\n",
      "Iteration 810, Loss: 0.00032500276574864984, Min w: 0.7642778158187866\n",
      "Iteration 820, Loss: 0.00024259871861431748, Min w: 0.8275548815727234\n",
      "Iteration 830, Loss: 0.00016458788013551384, Min w: 0.8867324590682983\n",
      "Iteration 840, Loss: 0.00016364699695259333, Min w: 0.8833139538764954\n",
      "Iteration 850, Loss: 0.00021653850853908807, Min w: 0.8376116156578064\n",
      "Iteration 860, Loss: 0.00022794739925302565, Min w: 0.8355798721313477\n",
      "Iteration 870, Loss: 0.00026968534803017974, Min w: 0.8108981251716614\n",
      "Iteration 880, Loss: 0.0002295907324878499, Min w: 0.8479697704315186\n",
      "Iteration 890, Loss: 0.00010770046355901286, Min w: 0.9292929172515869\n",
      "Iteration 900, Loss: 0.00016978842904791236, Min w: 0.8876583576202393\n",
      "Iteration 910, Loss: 0.00018445224850438535, Min w: 0.878747820854187\n",
      "Iteration 920, Loss: 0.0001380980247631669, Min w: 0.9041109681129456\n",
      "Iteration 930, Loss: 7.56103327148594e-05, Min w: 0.9598193764686584\n",
      "Iteration 940, Loss: 0.00026173327933065593, Min w: 0.8049997091293335\n",
      "Iteration 950, Loss: 0.0001204852742375806, Min w: 0.9196193814277649\n",
      "Iteration 960, Loss: 0.00013761957234237343, Min w: 0.9108068346977234\n",
      "Iteration 970, Loss: 0.0002986215113196522, Min w: 0.7680426836013794\n",
      "Iteration 980, Loss: 0.0002547269978094846, Min w: 0.8095614910125732\n",
      "Iteration 990, Loss: 0.00015991037071216851, Min w: 0.8993437886238098\n",
      "Iteration 1000, Loss: 0.000153916742419824, Min w: 0.8805663585662842\n",
      "Iteration 1010, Loss: 0.0002591306692920625, Min w: 0.8066839575767517\n",
      "Iteration 1020, Loss: 0.00021065803593955934, Min w: 0.849179744720459\n",
      "Iteration 1030, Loss: 0.00012554707063827664, Min w: 0.9091159701347351\n",
      "Iteration 1040, Loss: 0.00014880283561069518, Min w: 0.9196726679801941\n",
      "Iteration 1050, Loss: 0.00019852601690217853, Min w: 0.8443629145622253\n",
      "Iteration 1060, Loss: 0.00024186953669413924, Min w: 0.8373196125030518\n",
      "Iteration 1070, Loss: 0.00017545685113873333, Min w: 0.8671433329582214\n",
      "Iteration 1080, Loss: 6.302596011664718e-05, Min w: 0.9639076590538025\n",
      "Iteration 1090, Loss: 6.430863140849397e-05, Min w: 0.9642328023910522\n",
      "Iteration 1100, Loss: 0.00012760369281750172, Min w: 0.9049903750419617\n",
      "Iteration 1110, Loss: 0.00020305131329223514, Min w: 0.8455386161804199\n",
      "Iteration 1120, Loss: 0.00018655339954420924, Min w: 0.872629702091217\n",
      "Iteration 1130, Loss: 0.00012499878357630223, Min w: 0.9190394878387451\n",
      "Iteration 1140, Loss: 0.0001801479811547324, Min w: 0.875545859336853\n",
      "Iteration 1150, Loss: 0.00011844777327496558, Min w: 0.9355677366256714\n",
      "Iteration 1160, Loss: 0.00033372570760548115, Min w: 0.7736614942550659\n",
      "Iteration 1170, Loss: 0.0003310771135147661, Min w: 0.738357663154602\n",
      "Iteration 1180, Loss: 0.00045124939060769975, Min w: 0.662796676158905\n",
      "Iteration 1190, Loss: 5.9938796766800806e-05, Min w: 0.9663804173469543\n",
      "Iteration 1200, Loss: 0.00022781694133300334, Min w: 0.8443914651870728\n",
      "Iteration 1210, Loss: 0.0001938909263117239, Min w: 0.863828718662262\n",
      "Iteration 1220, Loss: 0.00025269424077123404, Min w: 0.8244598507881165\n",
      "Iteration 1230, Loss: 0.0002301878557773307, Min w: 0.8140920996665955\n",
      "Iteration 1240, Loss: 0.00017562128778081387, Min w: 0.8700292110443115\n",
      "Iteration 0, Loss: 0.0002616804849822074, Min w: 0.8117243647575378\n",
      "Iteration 10, Loss: 0.0002313970326213166, Min w: 0.8299011588096619\n",
      "Iteration 20, Loss: 0.0002268329990329221, Min w: 0.8343396782875061\n",
      "Iteration 30, Loss: 0.00024916414986364543, Min w: 0.8036075830459595\n",
      "Iteration 40, Loss: 0.00021353033662308007, Min w: 0.8401553630828857\n",
      "Iteration 50, Loss: 0.00021744689729530364, Min w: 0.8481041789054871\n",
      "Iteration 60, Loss: 0.0002240972826257348, Min w: 0.8225542306900024\n",
      "Iteration 70, Loss: 9.402542491443455e-05, Min w: 0.9389919638633728\n",
      "Iteration 80, Loss: 0.00017359896446578205, Min w: 0.8725228309631348\n",
      "Iteration 90, Loss: 0.00023478751245420426, Min w: 0.8231405019760132\n",
      "Iteration 100, Loss: 0.0001869582338258624, Min w: 0.8502526879310608\n",
      "Iteration 110, Loss: 0.00020487955771386623, Min w: 0.8430341482162476\n",
      "Iteration 120, Loss: 0.0002740655327215791, Min w: 0.7988759279251099\n",
      "Iteration 130, Loss: 0.00024678101181052625, Min w: 0.8029245734214783\n",
      "Iteration 140, Loss: 0.00021591507538687438, Min w: 0.8227033615112305\n",
      "Iteration 150, Loss: 0.00035649017081595957, Min w: 0.7217715978622437\n",
      "Iteration 160, Loss: 0.00031451540417037904, Min w: 0.75375896692276\n",
      "Iteration 170, Loss: 0.00029988575261086226, Min w: 0.7878226637840271\n",
      "Iteration 180, Loss: 0.00018462116713635623, Min w: 0.8593760132789612\n",
      "Iteration 190, Loss: 7.095102046150714e-05, Min w: 0.9569023251533508\n",
      "Iteration 200, Loss: 0.00020942963601555675, Min w: 0.8309810161590576\n",
      "Iteration 210, Loss: 0.0002509325568098575, Min w: 0.8121600151062012\n",
      "Iteration 220, Loss: 0.0002934484218712896, Min w: 0.7603170871734619\n",
      "Iteration 230, Loss: 0.00024238544574473053, Min w: 0.809542715549469\n",
      "Iteration 240, Loss: 0.0001077517808880657, Min w: 0.9237396121025085\n",
      "Iteration 250, Loss: 0.0003534876450430602, Min w: 0.7126975655555725\n",
      "Iteration 260, Loss: 0.00036356464261189103, Min w: 0.7194133996963501\n",
      "Iteration 270, Loss: 0.0002295642188983038, Min w: 0.8345987200737\n",
      "Iteration 280, Loss: 8.148945198627189e-05, Min w: 0.9557854533195496\n",
      "Iteration 290, Loss: 0.00029879232170060277, Min w: 0.7778717875480652\n",
      "Iteration 300, Loss: 0.00020064431009814143, Min w: 0.8334774971008301\n",
      "Iteration 310, Loss: 0.00019007164519280195, Min w: 0.8652109503746033\n",
      "Iteration 320, Loss: 0.0002971726353280246, Min w: 0.7806481122970581\n",
      "Iteration 330, Loss: 0.00023849325953051448, Min w: 0.7966611385345459\n",
      "Iteration 340, Loss: 0.00020444235997274518, Min w: 0.8498523235321045\n",
      "Iteration 350, Loss: 0.0001852890563895926, Min w: 0.8503749370574951\n",
      "Iteration 360, Loss: 0.00024052443041000515, Min w: 0.8262802958488464\n",
      "Iteration 370, Loss: 0.0002968867192976177, Min w: 0.793510377407074\n",
      "Iteration 380, Loss: 0.0002316299214726314, Min w: 0.8247219324111938\n",
      "Iteration 390, Loss: 8.064846770139411e-05, Min w: 0.9359734058380127\n",
      "Iteration 400, Loss: 8.868706208886579e-05, Min w: 0.9346476197242737\n",
      "Iteration 410, Loss: 5.507776222657412e-05, Min w: 0.9614750146865845\n",
      "Iteration 420, Loss: 4.03465201088693e-05, Min w: 0.9765596985816956\n",
      "Iteration 430, Loss: 9.780430991668254e-05, Min w: 0.9285139441490173\n",
      "Iteration 440, Loss: 0.00014101561100687832, Min w: 0.9099973440170288\n",
      "Iteration 450, Loss: 0.00012939063890371472, Min w: 0.9006177186965942\n",
      "Iteration 460, Loss: 0.0003726128488779068, Min w: 0.7049292325973511\n",
      "Iteration 470, Loss: 0.000412661669543013, Min w: 0.6941184401512146\n",
      "Iteration 480, Loss: 0.00025930622359737754, Min w: 0.8308565616607666\n",
      "Iteration 490, Loss: 6.569538527401164e-05, Min w: 0.9654375910758972\n",
      "Iteration 500, Loss: 0.00027386826695874333, Min w: 0.7802560329437256\n",
      "Iteration 510, Loss: 0.00037571851862594485, Min w: 0.7536801695823669\n",
      "Iteration 520, Loss: 0.0005922302952967584, Min w: 0.5435000061988831\n",
      "Iteration 530, Loss: 0.0003430674260016531, Min w: 0.7372527718544006\n",
      "Iteration 540, Loss: 0.00033884766162373126, Min w: 0.7445587515830994\n",
      "Iteration 550, Loss: 0.0004348249058239162, Min w: 0.6508241891860962\n",
      "Iteration 560, Loss: 0.0005749371484853327, Min w: 0.5726922154426575\n",
      "Iteration 570, Loss: 0.00022013462148606777, Min w: 0.8315585851669312\n",
      "Iteration 580, Loss: 0.0001349112280877307, Min w: 0.8854865431785583\n",
      "Iteration 590, Loss: 0.0003778798854909837, Min w: 0.7205111384391785\n",
      "Iteration 600, Loss: 0.00025312663638032973, Min w: 0.8053674101829529\n",
      "Iteration 610, Loss: 0.00013821078755427152, Min w: 0.8814601898193359\n",
      "Iteration 620, Loss: 0.00031579469214193523, Min w: 0.7415051460266113\n",
      "Iteration 630, Loss: 0.0001252178190043196, Min w: 0.9017742276191711\n",
      "Iteration 640, Loss: 0.00045939438859932125, Min w: 0.6561299562454224\n",
      "Iteration 650, Loss: 3.918358197552152e-05, Min w: 0.9739603400230408\n",
      "Iteration 660, Loss: 8.517938840668648e-05, Min w: 0.9290465116500854\n",
      "Iteration 670, Loss: 6.847004988230765e-05, Min w: 0.9585409164428711\n",
      "Iteration 680, Loss: 0.00016745951143093407, Min w: 0.8840903043746948\n",
      "Iteration 690, Loss: 0.00012556514411699027, Min w: 0.8904882073402405\n",
      "Iteration 700, Loss: 0.00010197595111094415, Min w: 0.925216794013977\n",
      "Iteration 710, Loss: 0.00019785977201536298, Min w: 0.8712214827537537\n",
      "Iteration 720, Loss: 0.00020275280985515565, Min w: 0.835227370262146\n",
      "Iteration 730, Loss: 0.00016743902233429253, Min w: 0.8686820864677429\n",
      "Iteration 740, Loss: 0.00028191166347824037, Min w: 0.7754707932472229\n",
      "Iteration 750, Loss: 0.0001314741966780275, Min w: 0.9089383482933044\n",
      "Iteration 760, Loss: 0.00025346127222292125, Min w: 0.791737973690033\n",
      "Iteration 770, Loss: 0.00025493925204500556, Min w: 0.8066728711128235\n",
      "Iteration 780, Loss: 0.00021986132196616381, Min w: 0.8071067333221436\n",
      "Iteration 790, Loss: 0.00010646390001056716, Min w: 0.9280108213424683\n",
      "Iteration 800, Loss: 0.00017062091501429677, Min w: 0.8762966394424438\n",
      "Iteration 810, Loss: 3.238530189264566e-05, Min w: 0.980187177658081\n",
      "Iteration 820, Loss: 7.39191600587219e-05, Min w: 0.9492555260658264\n",
      "Iteration 830, Loss: 0.0001303638273384422, Min w: 0.8945682644844055\n",
      "Iteration 840, Loss: 0.0003646868863143027, Min w: 0.743060290813446\n",
      "Iteration 850, Loss: 0.00020093948114663363, Min w: 0.8408493995666504\n",
      "Iteration 860, Loss: 0.00021464104065671563, Min w: 0.8340993523597717\n",
      "Iteration 870, Loss: 0.00022329050989355892, Min w: 0.8139390349388123\n",
      "Iteration 880, Loss: 0.00026432418962940574, Min w: 0.7842032313346863\n",
      "Iteration 890, Loss: 0.00030325455009005964, Min w: 0.7666600346565247\n",
      "Iteration 900, Loss: 0.0002879145322367549, Min w: 0.7631362676620483\n",
      "Iteration 910, Loss: 0.00012100703315809369, Min w: 0.9185025095939636\n",
      "Iteration 920, Loss: 0.00010096206096932292, Min w: 0.9158894419670105\n",
      "Iteration 930, Loss: 0.00023346241505350918, Min w: 0.811346173286438\n",
      "Iteration 940, Loss: 0.0001504342508269474, Min w: 0.8913850784301758\n",
      "Iteration 950, Loss: 0.00018572964472696185, Min w: 0.8540598750114441\n",
      "Iteration 960, Loss: 0.00020753912394866347, Min w: 0.8387495279312134\n",
      "Iteration 970, Loss: 0.00021575632854364812, Min w: 0.8288781046867371\n",
      "Iteration 980, Loss: 0.00019581273954827338, Min w: 0.8479461669921875\n",
      "Iteration 990, Loss: 0.0003162838111165911, Min w: 0.7840043902397156\n",
      "Iteration 1000, Loss: 0.00018724659457802773, Min w: 0.8490643501281738\n",
      "Iteration 1010, Loss: 0.00016793141548987478, Min w: 0.8695548176765442\n",
      "Iteration 1020, Loss: 0.00016506716201547533, Min w: 0.8699772953987122\n",
      "Iteration 1030, Loss: 0.00018993308185599744, Min w: 0.8549835681915283\n",
      "Iteration 1040, Loss: 3.116669540759176e-05, Min w: 0.9819139242172241\n",
      "Iteration 1050, Loss: 0.00030446224263869226, Min w: 0.7501785755157471\n",
      "Iteration 1060, Loss: 0.00023045203124638647, Min w: 0.8280730843544006\n",
      "Iteration 1070, Loss: 0.00024240350467152894, Min w: 0.7908122539520264\n",
      "Iteration 1080, Loss: 0.00019872841949108988, Min w: 0.8425087332725525\n",
      "Iteration 1090, Loss: 0.00022751206415705383, Min w: 0.833243727684021\n",
      "Iteration 1100, Loss: 0.00013090914580971003, Min w: 0.8877325654029846\n",
      "Iteration 1110, Loss: 0.00013417925219982862, Min w: 0.8894209265708923\n",
      "Iteration 1120, Loss: 0.0001550510060042143, Min w: 0.8773489594459534\n",
      "Iteration 1130, Loss: 0.0002937058452516794, Min w: 0.7636972665786743\n",
      "Iteration 1140, Loss: 0.00022693388746120036, Min w: 0.8281765580177307\n",
      "Iteration 1150, Loss: 0.00027509438223205507, Min w: 0.8133906126022339\n",
      "Iteration 1160, Loss: 0.00014927185839042068, Min w: 0.8645215034484863\n",
      "Iteration 1170, Loss: 0.00020624145690817386, Min w: 0.8388479351997375\n",
      "Iteration 1180, Loss: 0.00019868715025950223, Min w: 0.8653400540351868\n",
      "Iteration 1190, Loss: 0.0001982131798285991, Min w: 0.849071204662323\n",
      "Iteration 1200, Loss: 0.0003153870638925582, Min w: 0.7533002495765686\n",
      "Iteration 1210, Loss: 0.00016101474466267973, Min w: 0.863135576248169\n",
      "Iteration 1220, Loss: 0.0001942456583492458, Min w: 0.8558147549629211\n",
      "Iteration 1230, Loss: 0.00024851123453117907, Min w: 0.8043514490127563\n",
      "Iteration 1240, Loss: 0.00029001384973526, Min w: 0.7956458926200867\n",
      "Iteration 0, Loss: 0.0002488555619493127, Min w: 0.7910621762275696\n",
      "Iteration 10, Loss: 0.0001293158857151866, Min w: 0.9155516028404236\n",
      "Iteration 20, Loss: 3.301801916677505e-05, Min w: 0.9763921499252319\n",
      "Iteration 30, Loss: 6.0792699514422566e-05, Min w: 0.9548431634902954\n",
      "Iteration 40, Loss: 0.00034550894633866847, Min w: 0.7325271964073181\n",
      "Iteration 50, Loss: 0.00019386701751500368, Min w: 0.8375945687294006\n",
      "Iteration 60, Loss: 9.95975497062318e-05, Min w: 0.927483320236206\n",
      "Iteration 70, Loss: 0.00010262725845677778, Min w: 0.9115150570869446\n",
      "Iteration 80, Loss: 0.00026087742298841476, Min w: 0.7945706248283386\n",
      "Iteration 90, Loss: 0.00019245114526711404, Min w: 0.8450174331665039\n",
      "Iteration 100, Loss: 0.0002539951528888196, Min w: 0.7896946668624878\n",
      "Iteration 110, Loss: 0.00015588726091664284, Min w: 0.8661746978759766\n",
      "Iteration 120, Loss: 0.000133918336359784, Min w: 0.8879362344741821\n",
      "Iteration 130, Loss: 0.0001670339988777414, Min w: 0.8763993382453918\n",
      "Iteration 140, Loss: 0.0001641062117414549, Min w: 0.8668070435523987\n",
      "Iteration 150, Loss: 0.00026394572341814637, Min w: 0.8148399591445923\n",
      "Iteration 160, Loss: 0.0002798698260448873, Min w: 0.7539069056510925\n",
      "Iteration 170, Loss: 0.00012477378186304122, Min w: 0.9020806550979614\n",
      "Iteration 180, Loss: 3.632964217104018e-05, Min w: 0.9784018993377686\n",
      "Iteration 190, Loss: 0.0001369733945466578, Min w: 0.8933905363082886\n",
      "Iteration 200, Loss: 0.00017550103075336665, Min w: 0.853929340839386\n",
      "Iteration 210, Loss: 0.00029254890978336334, Min w: 0.7684135437011719\n",
      "Iteration 220, Loss: 0.00026322589837946, Min w: 0.8088766932487488\n",
      "Iteration 230, Loss: 0.00015306880231946707, Min w: 0.8714781999588013\n",
      "Iteration 240, Loss: 0.0002508831676095724, Min w: 0.8024673461914062\n",
      "Iteration 250, Loss: 0.00015417202666867524, Min w: 0.874212920665741\n",
      "Iteration 260, Loss: 0.00023915365454740822, Min w: 0.7985355854034424\n",
      "Iteration 270, Loss: 0.00025451547116972506, Min w: 0.8050404191017151\n",
      "Iteration 280, Loss: 3.732578261406161e-05, Min w: 0.9708669185638428\n",
      "Iteration 290, Loss: 4.8519286792725325e-05, Min w: 0.9709711074829102\n",
      "Iteration 300, Loss: 0.00010762254532892257, Min w: 0.911082923412323\n",
      "Iteration 310, Loss: 0.00011327125685056672, Min w: 0.9014805555343628\n",
      "Iteration 320, Loss: 0.00010630390897858888, Min w: 0.9169020652770996\n",
      "Iteration 330, Loss: 0.00010557599307503551, Min w: 0.9286366701126099\n",
      "Iteration 340, Loss: 4.676176104112528e-05, Min w: 0.9650887250900269\n",
      "Iteration 350, Loss: 0.00013415135617833585, Min w: 0.8878897428512573\n",
      "Iteration 360, Loss: 0.00018378952518105507, Min w: 0.8621234893798828\n",
      "Iteration 370, Loss: 0.0001793050905689597, Min w: 0.8393786549568176\n",
      "Iteration 380, Loss: 0.00032736369757913053, Min w: 0.7705585360527039\n",
      "Iteration 390, Loss: 6.402067810995504e-05, Min w: 0.9437330961227417\n",
      "Iteration 400, Loss: 0.00010119559010490775, Min w: 0.9271879196166992\n",
      "Iteration 410, Loss: 7.234771328512579e-05, Min w: 0.9503189325332642\n",
      "Iteration 420, Loss: 4.3920172174694017e-05, Min w: 0.9631709456443787\n",
      "Iteration 430, Loss: 0.00014460751845035702, Min w: 0.87981116771698\n",
      "Iteration 440, Loss: 9.773032797966152e-05, Min w: 0.919438362121582\n",
      "Iteration 450, Loss: 0.00017456822388339788, Min w: 0.8792882561683655\n",
      "Iteration 460, Loss: 8.461585093755275e-05, Min w: 0.9333658218383789\n",
      "Iteration 470, Loss: 0.00011161873408127576, Min w: 0.906950056552887\n",
      "Iteration 480, Loss: 0.00021490766084752977, Min w: 0.8232613801956177\n",
      "Iteration 490, Loss: 0.0002833999751601368, Min w: 0.7874618768692017\n",
      "Iteration 500, Loss: 4.0251095924759284e-05, Min w: 0.9684577584266663\n",
      "Iteration 510, Loss: 0.00010502809163881466, Min w: 0.9182623028755188\n",
      "Iteration 520, Loss: 0.00013231384218670428, Min w: 0.8866117596626282\n",
      "Iteration 530, Loss: 0.00029884243849664927, Min w: 0.76918625831604\n",
      "Iteration 540, Loss: 0.0002089828922180459, Min w: 0.8176932334899902\n",
      "Iteration 550, Loss: 0.00030507807969115674, Min w: 0.808137834072113\n",
      "Iteration 560, Loss: 0.00024389535246882588, Min w: 0.7907429337501526\n",
      "Iteration 570, Loss: 0.00012702417734544724, Min w: 0.9284455180168152\n",
      "Iteration 580, Loss: 0.00021858389663975686, Min w: 0.8359096646308899\n",
      "Iteration 590, Loss: 0.0001434389705536887, Min w: 0.8822188377380371\n",
      "Iteration 600, Loss: 0.0001856073213275522, Min w: 0.8475379943847656\n",
      "Iteration 610, Loss: 0.0001700937282294035, Min w: 0.8744266033172607\n",
      "Iteration 620, Loss: 0.00020935221982654184, Min w: 0.8319235444068909\n",
      "Iteration 630, Loss: 0.00020262660109438002, Min w: 0.8441999554634094\n",
      "Iteration 640, Loss: 0.00021127282525412738, Min w: 0.8060956001281738\n",
      "Iteration 650, Loss: 0.00021375043434090912, Min w: 0.8583444952964783\n",
      "Iteration 660, Loss: 0.00019033343414776027, Min w: 0.8439393043518066\n",
      "Iteration 670, Loss: 0.00010625719005474821, Min w: 0.9281910061836243\n",
      "Iteration 680, Loss: 8.489238825859502e-05, Min w: 0.9351955652236938\n",
      "Iteration 690, Loss: 5.912861888646148e-05, Min w: 0.9582374095916748\n",
      "Iteration 700, Loss: 4.315619662520476e-05, Min w: 0.9756308794021606\n",
      "Iteration 710, Loss: 0.00015631556743755937, Min w: 0.86271733045578\n",
      "Iteration 720, Loss: 0.00019025469373445958, Min w: 0.8611031770706177\n",
      "Iteration 730, Loss: 0.0001950136647792533, Min w: 0.8584065437316895\n",
      "Iteration 740, Loss: 0.00010187037696596235, Min w: 0.9123324751853943\n",
      "Iteration 750, Loss: 0.00010559585643932223, Min w: 0.9164403080940247\n",
      "Iteration 760, Loss: 0.00012395747762639076, Min w: 0.8924077153205872\n",
      "Iteration 770, Loss: 0.00024475916870869696, Min w: 0.8083028793334961\n",
      "Iteration 780, Loss: 0.00031947423121891916, Min w: 0.7675870060920715\n",
      "Iteration 790, Loss: 0.0002860303211491555, Min w: 0.7833816409111023\n",
      "Iteration 800, Loss: 0.00037286916631273925, Min w: 0.7159070372581482\n",
      "Iteration 810, Loss: 0.00017479006783105433, Min w: 0.8617194294929504\n",
      "Iteration 820, Loss: 0.00012190666166134179, Min w: 0.8933849930763245\n",
      "Iteration 830, Loss: 0.00011260661267442629, Min w: 0.9084734916687012\n",
      "Iteration 840, Loss: 0.00010405967623228207, Min w: 0.9142903685569763\n",
      "Iteration 850, Loss: 0.00021678159828297794, Min w: 0.8222999572753906\n",
      "Iteration 860, Loss: 0.00023949510068632662, Min w: 0.8093120455741882\n",
      "Iteration 870, Loss: 0.0003468228387646377, Min w: 0.7107682824134827\n",
      "Iteration 880, Loss: 0.0002730923006311059, Min w: 0.7835929989814758\n",
      "Iteration 890, Loss: 0.0003085750504396856, Min w: 0.729632556438446\n",
      "Iteration 900, Loss: 0.00010269373888149858, Min w: 0.9139915108680725\n",
      "Iteration 910, Loss: 2.8260421458981e-05, Min w: 0.9791028499603271\n",
      "Iteration 920, Loss: 0.000100129414931871, Min w: 0.9298813343048096\n",
      "Iteration 930, Loss: 0.00019529032579157501, Min w: 0.8379632234573364\n",
      "Iteration 940, Loss: 0.00017934649076778442, Min w: 0.8534116148948669\n",
      "Iteration 950, Loss: 0.00017530655895825475, Min w: 0.8669404983520508\n",
      "Iteration 960, Loss: 0.00016309373313561082, Min w: 0.85616135597229\n",
      "Iteration 970, Loss: 4.798374357051216e-05, Min w: 0.9695534110069275\n",
      "Iteration 980, Loss: 7.96626991359517e-05, Min w: 0.9365766644477844\n",
      "Iteration 990, Loss: 0.00011728134995792061, Min w: 0.9103848934173584\n",
      "Iteration 1000, Loss: 0.00015617672761436552, Min w: 0.8632562160491943\n",
      "Iteration 1010, Loss: 0.00018520028970669955, Min w: 0.8532590270042419\n",
      "Iteration 1020, Loss: 0.00026951415929943323, Min w: 0.7987882494926453\n",
      "Iteration 1030, Loss: 0.00021502675372175872, Min w: 0.8228750228881836\n",
      "Iteration 1040, Loss: 0.0001919147907756269, Min w: 0.8543780446052551\n",
      "Iteration 1050, Loss: 0.0001859914482338354, Min w: 0.828828752040863\n",
      "Iteration 1060, Loss: 0.00016144140681717545, Min w: 0.9093161225318909\n",
      "Iteration 1070, Loss: 0.00022249789617490023, Min w: 0.8194357752799988\n",
      "Iteration 1080, Loss: 0.0001791832037270069, Min w: 0.8437789678573608\n",
      "Iteration 1090, Loss: 0.00016731620416976511, Min w: 0.8767582178115845\n",
      "Iteration 1100, Loss: 0.00016616098582744598, Min w: 0.8545773029327393\n",
      "Iteration 1110, Loss: 0.0001795084390323609, Min w: 0.863085150718689\n",
      "Iteration 1120, Loss: 9.599473560228944e-05, Min w: 0.9269073009490967\n",
      "Iteration 1130, Loss: 0.00013426024815998971, Min w: 0.8861748576164246\n",
      "Iteration 1140, Loss: 9.348687308374792e-05, Min w: 0.9336760640144348\n",
      "Iteration 1150, Loss: 6.549950921908021e-05, Min w: 0.9454270601272583\n",
      "Iteration 1160, Loss: 5.491822957992554e-05, Min w: 0.956000030040741\n",
      "Iteration 1170, Loss: 0.00025203824043273926, Min w: 0.8020155429840088\n",
      "Iteration 1180, Loss: 0.00022130005527287722, Min w: 0.8366551399230957\n",
      "Iteration 1190, Loss: 0.00016617080837022513, Min w: 0.8590397238731384\n",
      "Iteration 1200, Loss: 0.00015299041115213186, Min w: 0.8838570713996887\n",
      "Iteration 1210, Loss: 0.00011517078382894397, Min w: 0.9050384759902954\n",
      "Iteration 1220, Loss: 0.00013331625086721033, Min w: 0.8938117623329163\n",
      "Iteration 1230, Loss: 0.00020722733461298048, Min w: 0.8508396148681641\n",
      "Iteration 1240, Loss: 0.00018038768030237406, Min w: 0.8523609638214111\n",
      "Iteration 0, Loss: 0.00019794628315139562, Min w: 0.8508807420730591\n",
      "Iteration 10, Loss: 0.00024897753610275686, Min w: 0.8282848596572876\n",
      "Iteration 20, Loss: 0.00021091848611831665, Min w: 0.8452500104904175\n",
      "Iteration 30, Loss: 0.00019150962179992348, Min w: 0.8418447971343994\n",
      "Iteration 40, Loss: 0.0002260782930534333, Min w: 0.8198615312576294\n",
      "Iteration 50, Loss: 0.00023990008048713207, Min w: 0.8004340529441833\n",
      "Iteration 60, Loss: 0.0001931185252033174, Min w: 0.8467797040939331\n",
      "Iteration 70, Loss: 0.00016456673620268703, Min w: 0.8716346621513367\n",
      "Iteration 80, Loss: 0.00016892420535441488, Min w: 0.8852285146713257\n",
      "Iteration 90, Loss: 0.00018564304627943784, Min w: 0.8347638249397278\n",
      "Iteration 100, Loss: 0.00018076041305903345, Min w: 0.8709867596626282\n",
      "Iteration 110, Loss: 0.0001968925353139639, Min w: 0.8443310260772705\n",
      "Iteration 120, Loss: 0.00019117227930109948, Min w: 0.8468732237815857\n",
      "Iteration 130, Loss: 0.000259053340414539, Min w: 0.7948194146156311\n",
      "Iteration 140, Loss: 0.00019802771566901356, Min w: 0.847086489200592\n",
      "Iteration 150, Loss: 0.0002177741698687896, Min w: 0.8373370170593262\n",
      "Iteration 160, Loss: 0.0002001674147322774, Min w: 0.8420017957687378\n",
      "Iteration 170, Loss: 0.00021957105491310358, Min w: 0.8447595238685608\n",
      "Iteration 180, Loss: 0.000322721985867247, Min w: 0.777722954750061\n",
      "Iteration 190, Loss: 0.00023965479340404272, Min w: 0.7882047891616821\n",
      "Iteration 200, Loss: 0.00015473348321393132, Min w: 0.8696675300598145\n",
      "Iteration 210, Loss: 0.0001511194568593055, Min w: 0.8814279437065125\n",
      "Iteration 220, Loss: 9.280416998080909e-05, Min w: 0.9466184377670288\n",
      "Iteration 230, Loss: 6.706703425152227e-05, Min w: 0.9452529549598694\n",
      "Iteration 240, Loss: 8.876328502083197e-05, Min w: 0.9371163845062256\n",
      "Iteration 250, Loss: 0.00030249691917560995, Min w: 0.7383498549461365\n",
      "Iteration 260, Loss: 0.00041222042636945844, Min w: 0.7300345301628113\n",
      "Iteration 270, Loss: 0.000420643511461094, Min w: 0.7577422857284546\n",
      "Iteration 280, Loss: 0.0002444885321892798, Min w: 0.7859529852867126\n",
      "Iteration 290, Loss: 5.439471351564862e-05, Min w: 0.9575031399726868\n",
      "Iteration 300, Loss: 2.692513407964725e-05, Min w: 0.9794591069221497\n",
      "Iteration 310, Loss: 0.0004242729628458619, Min w: 0.6978266835212708\n",
      "Iteration 320, Loss: 0.0019818192813545465, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002036911668255925, Min w: 4.203895392974451e-45\n",
      "Iteration 340, Loss: 0.002018863568082452, Min w: 3.248475195505307e-07\n",
      "Iteration 350, Loss: 0.0016888960963115096, Min w: 0.00021267615375109017\n",
      "Iteration 360, Loss: 0.0011119019472971559, Min w: 0.36086684465408325\n",
      "Iteration 370, Loss: 0.0016053402796387672, Min w: 0.00016865256475284696\n",
      "Iteration 380, Loss: 0.0018589902902022004, Min w: 0.0006253818282857537\n",
      "Iteration 390, Loss: 0.0011841475497931242, Min w: 8.862194954417646e-05\n",
      "Iteration 400, Loss: 0.00197942485101521, Min w: 1.699723694629122e-27\n",
      "Iteration 410, Loss: 0.002006485592573881, Min w: 8.87813209947106e-20\n",
      "Iteration 420, Loss: 0.0020342443604022264, Min w: 1.1293484713532998e-40\n",
      "Iteration 430, Loss: 0.0020002478267997503, Min w: 5.823636711754787e-11\n",
      "Iteration 440, Loss: 0.002012358047068119, Min w: 8.083664937430513e-08\n",
      "Iteration 450, Loss: 0.002032970078289509, Min w: 3.024628725256662e-08\n",
      "Iteration 460, Loss: 0.0019891902338713408, Min w: 0.014703541062772274\n",
      "Iteration 470, Loss: 0.001410900498740375, Min w: 0.20868897438049316\n",
      "Iteration 480, Loss: 0.0009340638644061983, Min w: 0.5098531246185303\n",
      "Iteration 490, Loss: 0.00024092505918815732, Min w: 0.8246563076972961\n",
      "Iteration 500, Loss: 0.0003430458891671151, Min w: 0.7703715562820435\n",
      "Iteration 510, Loss: 0.00015132517728488892, Min w: 0.9042800068855286\n",
      "Iteration 520, Loss: 4.178949893685058e-05, Min w: 0.9747961759567261\n",
      "Iteration 530, Loss: 0.0002870058233384043, Min w: 0.8123216032981873\n",
      "Iteration 540, Loss: 0.00019821593014057726, Min w: 0.8485056757926941\n",
      "Iteration 550, Loss: 0.00022435587015934289, Min w: 0.8278313875198364\n",
      "Iteration 560, Loss: 0.00012086415517842397, Min w: 0.9075385928153992\n",
      "Iteration 570, Loss: 0.00020275272254366428, Min w: 0.8429962396621704\n",
      "Iteration 580, Loss: 0.00020756028243340552, Min w: 0.8297927379608154\n",
      "Iteration 590, Loss: 0.0001597409718669951, Min w: 0.8684830665588379\n",
      "Iteration 600, Loss: 0.0002022098924499005, Min w: 0.8273172974586487\n",
      "Iteration 610, Loss: 0.00017794522864278406, Min w: 0.8548224568367004\n",
      "Iteration 620, Loss: 0.00015311520837713033, Min w: 0.8684689402580261\n",
      "Iteration 630, Loss: 0.00010045223461929709, Min w: 0.919344961643219\n",
      "Iteration 640, Loss: 0.00014974796795286238, Min w: 0.8952664732933044\n",
      "Iteration 650, Loss: 0.00010836112778633833, Min w: 0.9269691109657288\n",
      "Iteration 660, Loss: 9.146719094133005e-05, Min w: 0.9306008219718933\n",
      "Iteration 670, Loss: 7.470390846719965e-05, Min w: 0.9428467154502869\n",
      "Iteration 680, Loss: 8.981255086837336e-05, Min w: 0.9294119477272034\n",
      "Iteration 690, Loss: 2.6846129912883043e-05, Min w: 0.9837020039558411\n",
      "Iteration 700, Loss: 0.0001405113289365545, Min w: 0.8863352537155151\n",
      "Iteration 710, Loss: 0.00011669191007968038, Min w: 0.9049427509307861\n",
      "Iteration 720, Loss: 7.905263191787526e-05, Min w: 0.938974142074585\n",
      "Iteration 730, Loss: 0.00012011429498670623, Min w: 0.9084762930870056\n",
      "Iteration 740, Loss: 2.383525497862138e-05, Min w: 0.9869734644889832\n",
      "Iteration 750, Loss: 0.00022174011974129826, Min w: 0.8228095173835754\n",
      "Iteration 760, Loss: 0.00026400317437946796, Min w: 0.7802546620368958\n",
      "Iteration 770, Loss: 0.0001935395412147045, Min w: 0.8549844026565552\n",
      "Iteration 780, Loss: 0.0002912330091930926, Min w: 0.8028033971786499\n",
      "Iteration 790, Loss: 0.00029824540251865983, Min w: 0.7836905121803284\n",
      "Iteration 800, Loss: 0.00021316994389053434, Min w: 0.8332950472831726\n",
      "Iteration 810, Loss: 0.00015243976667989045, Min w: 0.8774001002311707\n",
      "Iteration 820, Loss: 0.00013081601355224848, Min w: 0.895663321018219\n",
      "Iteration 830, Loss: 0.00016447858070023358, Min w: 0.8680956363677979\n",
      "Iteration 840, Loss: 0.00011106191959697753, Min w: 0.9088260531425476\n",
      "Iteration 850, Loss: 0.00011265854845987633, Min w: 0.9141173958778381\n",
      "Iteration 860, Loss: 0.00016629803576506674, Min w: 0.8795372247695923\n",
      "Iteration 870, Loss: 0.00032445992110297084, Min w: 0.7627363801002502\n",
      "Iteration 880, Loss: 3.872960587614216e-05, Min w: 0.975078284740448\n",
      "Iteration 890, Loss: 7.914906018413603e-05, Min w: 0.9378865361213684\n",
      "Iteration 900, Loss: 0.00016067454998847097, Min w: 0.8713451623916626\n",
      "Iteration 910, Loss: 0.00019100037752650678, Min w: 0.8425605297088623\n",
      "Iteration 920, Loss: 6.789663166273385e-05, Min w: 0.9454612135887146\n",
      "Iteration 930, Loss: 6.373960059136152e-05, Min w: 0.9457557201385498\n",
      "Iteration 940, Loss: 0.00010529495921218768, Min w: 0.9184794425964355\n",
      "Iteration 950, Loss: 0.00016798531578388065, Min w: 0.8644958734512329\n",
      "Iteration 960, Loss: 0.00018578920571599156, Min w: 0.8417887091636658\n",
      "Iteration 970, Loss: 0.00014034750347491354, Min w: 0.8811591267585754\n",
      "Iteration 980, Loss: 0.00015453055675607175, Min w: 0.8702477812767029\n",
      "Iteration 990, Loss: 0.000237205924349837, Min w: 0.8165987133979797\n",
      "Iteration 1000, Loss: 0.00023331727425102144, Min w: 0.8137063980102539\n",
      "Iteration 1010, Loss: 0.00032139322138391435, Min w: 0.7488781213760376\n",
      "Iteration 1020, Loss: 0.0002700819168239832, Min w: 0.7918689250946045\n",
      "Iteration 1030, Loss: 0.0003400605346541852, Min w: 0.7323175072669983\n",
      "Iteration 1040, Loss: 0.0002359857753617689, Min w: 0.8019112944602966\n",
      "Iteration 1050, Loss: 0.000242307607550174, Min w: 0.8052487373352051\n",
      "Iteration 1060, Loss: 0.00024676238535903394, Min w: 0.8163895606994629\n",
      "Iteration 1070, Loss: 0.00024303022655658424, Min w: 0.8151618838310242\n",
      "Iteration 1080, Loss: 0.0002631288080010563, Min w: 0.7694982290267944\n",
      "Iteration 1090, Loss: 0.00023288195370696485, Min w: 0.8098962903022766\n",
      "Iteration 1100, Loss: 0.00021884088346268982, Min w: 0.8471251726150513\n",
      "Iteration 1110, Loss: 0.00016773978131823242, Min w: 0.8753812909126282\n",
      "Iteration 1120, Loss: 3.51301277987659e-05, Min w: 0.9796684980392456\n",
      "Iteration 1130, Loss: 6.589115218957886e-05, Min w: 0.9504520297050476\n",
      "Iteration 1140, Loss: 0.00011194288526894525, Min w: 0.9062570929527283\n",
      "Iteration 1150, Loss: 0.00012680194049607962, Min w: 0.9250143766403198\n",
      "Iteration 1160, Loss: 0.00013329404464457184, Min w: 0.8956789970397949\n",
      "Iteration 1170, Loss: 0.00019025857909582555, Min w: 0.8580664396286011\n",
      "Iteration 1180, Loss: 0.00016472909192088991, Min w: 0.8759970664978027\n",
      "Iteration 1190, Loss: 4.204807919450104e-05, Min w: 0.9701710343360901\n",
      "Iteration 1200, Loss: 2.869648415071424e-05, Min w: 0.9802793860435486\n",
      "Iteration 1210, Loss: 0.00011210213415324688, Min w: 0.9105190634727478\n",
      "Iteration 1220, Loss: 7.822978659532964e-05, Min w: 0.9314897060394287\n",
      "Iteration 1230, Loss: 8.598023123340681e-05, Min w: 0.9370257258415222\n",
      "Iteration 1240, Loss: 7.936451584100723e-05, Min w: 0.9384090304374695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   4%|▍         | 1/24 [01:32<35:36, 92.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.008401187025960353, 'L2_avg': 0.01006805660957793, 'End_point_L1_avg': 0.007457880353910115, 'End_point_L2_avg': 0.00906589252624498}\n",
      "Iteration 0, Loss: 0.0033084293827414513, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0028797504492104053, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0023000906221568584, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0021723120007663965, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002061918843537569, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0025134882889688015, Min w: 1.0408760393143359e-21\n",
      "Iteration 60, Loss: 0.002296932740136981, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0020878652576357126, Min w: 2.473202163018654e-15\n",
      "Iteration 80, Loss: 0.0020506256259977818, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0020609621424227953, Min w: 4.726495670542841e-12\n",
      "Iteration 100, Loss: 0.002327754395082593, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0022809559013694525, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002222102601081133, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0020769976545125246, Min w: 0.0\n",
      "Iteration 140, Loss: 0.00226821587421, Min w: 1.6379960450007757e-29\n",
      "Iteration 150, Loss: 0.0020129699259996414, Min w: 3.3622722119507065e-13\n",
      "Iteration 160, Loss: 0.0019248535390943289, Min w: 0.0012050532968714833\n",
      "Iteration 170, Loss: 0.0020649810321629047, Min w: 1.1566194278896925e-20\n",
      "Iteration 180, Loss: 0.0020744511857628822, Min w: 5.054642482349436e-09\n",
      "Iteration 190, Loss: 0.002070506103336811, Min w: 1.4067635283356839e-41\n",
      "Iteration 200, Loss: 0.002089505083858967, Min w: 2.543396004710067e-34\n",
      "Iteration 210, Loss: 0.0020918957889080048, Min w: 4.8223114467814765e-23\n",
      "Iteration 220, Loss: 0.002006355207413435, Min w: 3.552092509018223e-10\n",
      "Iteration 230, Loss: 0.0020781480707228184, Min w: 2.2715099246006787e-10\n",
      "Iteration 240, Loss: 0.0020399533677846193, Min w: 1.3798403809406111e-39\n",
      "Iteration 250, Loss: 0.0020469441078603268, Min w: 0.0\n",
      "Iteration 260, Loss: 0.002036451594904065, Min w: 2.844770407231954e-38\n",
      "Iteration 270, Loss: 0.001968519063666463, Min w: 1.440939815383624e-11\n",
      "Iteration 280, Loss: 0.002073826501145959, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0020523685961961746, Min w: 5.096452008808137e-21\n",
      "Iteration 300, Loss: 0.0020443687681108713, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0016118013300001621, Min w: 3.4136945657389783e-14\n",
      "Iteration 320, Loss: 0.001974943559616804, Min w: 3.425078102736734e-05\n",
      "Iteration 330, Loss: 0.00164600252173841, Min w: 2.1174398625589674e-06\n",
      "Iteration 340, Loss: 0.0019814514089375734, Min w: 1.3288392240706704e-22\n",
      "Iteration 350, Loss: 0.001829668995924294, Min w: 1.1949709005421028e-05\n",
      "Iteration 360, Loss: 0.001979521242901683, Min w: 1.3509535392586258e-06\n",
      "Iteration 370, Loss: 0.0020402143709361553, Min w: 1.5170481674431358e-05\n",
      "Iteration 380, Loss: 0.0020211199298501015, Min w: 4.0355871422370626e-10\n",
      "Iteration 390, Loss: 0.002090766793116927, Min w: 2.1860256043467146e-43\n",
      "Iteration 400, Loss: 0.0021667429246008396, Min w: 3.0845290418139034e-17\n",
      "Iteration 410, Loss: 0.0021395296789705753, Min w: 1.6348839716083685e-33\n",
      "Iteration 420, Loss: 0.0022296227980405092, Min w: 4.741916931859643e-39\n",
      "Iteration 430, Loss: 0.0020394735038280487, Min w: 2.138788820528481e-13\n",
      "Iteration 440, Loss: 0.0020387324038892984, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001996754901483655, Min w: 3.887661655616443e-36\n",
      "Iteration 460, Loss: 0.002066537505015731, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0019873876590281725, Min w: 8.744227311535458e-27\n",
      "Iteration 480, Loss: 0.0017681660829111934, Min w: 1.5858743761558089e-15\n",
      "Iteration 490, Loss: 0.001998180290684104, Min w: 1.7001486053112554e-23\n",
      "Iteration 500, Loss: 0.001997848739847541, Min w: 9.918155260200552e-26\n",
      "Iteration 510, Loss: 0.0020493254996836185, Min w: 5.270161196335721e-09\n",
      "Iteration 520, Loss: 0.0016549478750675917, Min w: 0.0820908471941948\n",
      "Iteration 530, Loss: 0.001996571198105812, Min w: 1.676646861222911e-23\n",
      "Iteration 540, Loss: 0.001983955269679427, Min w: 0.00035126155125908554\n",
      "Iteration 550, Loss: 0.002065514912828803, Min w: 2.9244431321018283e-09\n",
      "Iteration 560, Loss: 0.001997523009777069, Min w: 3.990722039122225e-15\n",
      "Iteration 570, Loss: 0.002025569323450327, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0020416982006281614, Min w: 2.0453945204224055e-09\n",
      "Iteration 590, Loss: 0.001979958964511752, Min w: 1.517325626037777e-13\n",
      "Iteration 600, Loss: 0.002011658390983939, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002097031334415078, Min w: 2.6912753275931678e-11\n",
      "Iteration 620, Loss: 0.0019520667847245932, Min w: 5.068039321542983e-10\n",
      "Iteration 630, Loss: 0.00199941941536963, Min w: 0.00011391955194994807\n",
      "Iteration 640, Loss: 0.002002429449930787, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0020037612412124872, Min w: 4.440649448156364e-08\n",
      "Iteration 660, Loss: 0.0019900226034224033, Min w: 1.8285281298297959e-31\n",
      "Iteration 670, Loss: 0.002001466928049922, Min w: 2.1305540665039757e-11\n",
      "Iteration 680, Loss: 0.0020367861725389957, Min w: 0.0\n",
      "Iteration 690, Loss: 0.001900643459521234, Min w: 2.4824117645039223e-05\n",
      "Iteration 700, Loss: 0.001644956530071795, Min w: 0.00017551632481627166\n",
      "Iteration 710, Loss: 0.0019125896506011486, Min w: 8.374476578865142e-08\n",
      "Iteration 720, Loss: 0.0020332783460617065, Min w: 1.257270554333445e-07\n",
      "Iteration 730, Loss: 0.0019206134602427483, Min w: 0.005476796999573708\n",
      "Iteration 740, Loss: 0.0017498305533081293, Min w: 0.008182274177670479\n",
      "Iteration 750, Loss: 0.0017262137262150645, Min w: 0.00027573699480853975\n",
      "Iteration 760, Loss: 0.0018419381231069565, Min w: 0.06953179091215134\n",
      "Iteration 770, Loss: 0.0019368354696780443, Min w: 0.00040672102477401495\n",
      "Iteration 780, Loss: 0.001908344216644764, Min w: 3.8263576335184624e-11\n",
      "Iteration 790, Loss: 0.0020095189101994038, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0020098895765841007, Min w: 0.00021398410899564624\n",
      "Iteration 810, Loss: 0.0019841748289763927, Min w: 4.033171535411384e-06\n",
      "Iteration 820, Loss: 0.0015359815442934632, Min w: 0.0024131666868925095\n",
      "Iteration 830, Loss: 0.0013737373519688845, Min w: 0.14687098562717438\n",
      "Iteration 840, Loss: 0.0008995464886538684, Min w: 0.502989649772644\n",
      "Iteration 850, Loss: 0.00118548225145787, Min w: 0.3882826566696167\n",
      "Iteration 860, Loss: 0.0010241979034617543, Min w: 0.41302528977394104\n",
      "Iteration 870, Loss: 0.0007694174419157207, Min w: 0.4449620842933655\n",
      "Iteration 880, Loss: 0.0007917652255855501, Min w: 0.4521806240081787\n",
      "Iteration 890, Loss: 0.0007453903672285378, Min w: 0.44786086678504944\n",
      "Iteration 900, Loss: 0.0008150662179104984, Min w: 0.5053040385246277\n",
      "Iteration 910, Loss: 0.0007227715104818344, Min w: 0.514177680015564\n",
      "Iteration 920, Loss: 0.0009066151105798781, Min w: 0.45711445808410645\n",
      "Iteration 930, Loss: 0.0006862232694402337, Min w: 0.5340349674224854\n",
      "Iteration 940, Loss: 0.000829386233817786, Min w: 0.5470680594444275\n",
      "Iteration 950, Loss: 0.0008349071722477674, Min w: 0.542706310749054\n",
      "Iteration 960, Loss: 0.0008689574897289276, Min w: 0.5085477232933044\n",
      "Iteration 970, Loss: 0.0008435519994236529, Min w: 0.5225350260734558\n",
      "Iteration 980, Loss: 0.0006109644891694188, Min w: 0.6003357768058777\n",
      "Iteration 990, Loss: 0.0007443923386745155, Min w: 0.5576534271240234\n",
      "Iteration 1000, Loss: 0.0007111159502528608, Min w: 0.5845822691917419\n",
      "Iteration 1010, Loss: 0.0005555179086513817, Min w: 0.6236001253128052\n",
      "Iteration 1020, Loss: 0.0005340814241208136, Min w: 0.6362215280532837\n",
      "Iteration 1030, Loss: 0.0006259502843022346, Min w: 0.6364649534225464\n",
      "Iteration 1040, Loss: 0.0005931124906055629, Min w: 0.6550752520561218\n",
      "Iteration 1050, Loss: 0.0005217207944951952, Min w: 0.6765813231468201\n",
      "Iteration 1060, Loss: 0.0007506167166866362, Min w: 0.6141471266746521\n",
      "Iteration 1070, Loss: 0.0006589764379896224, Min w: 0.6502736806869507\n",
      "Iteration 1080, Loss: 0.0006262959796003997, Min w: 0.6858008503913879\n",
      "Iteration 1090, Loss: 0.00044338940642774105, Min w: 0.7142104506492615\n",
      "Iteration 1100, Loss: 0.00046402617590501904, Min w: 0.6982344388961792\n",
      "Iteration 1110, Loss: 0.00043092589476145804, Min w: 0.7199055552482605\n",
      "Iteration 1120, Loss: 0.00045543137821368873, Min w: 0.7193033695220947\n",
      "Iteration 1130, Loss: 0.0008275806903839111, Min w: 0.5446945428848267\n",
      "Iteration 1140, Loss: 0.0004485304525587708, Min w: 0.7081871628761292\n",
      "Iteration 1150, Loss: 0.0004149913147557527, Min w: 0.7371006608009338\n",
      "Iteration 1160, Loss: 0.00046278670197352767, Min w: 0.7406525611877441\n",
      "Iteration 1170, Loss: 0.0005017489893361926, Min w: 0.7359638810157776\n",
      "Iteration 1180, Loss: 0.0005231873947195709, Min w: 0.7323603630065918\n",
      "Iteration 1190, Loss: 0.00040465110214427114, Min w: 0.7594729065895081\n",
      "Iteration 1200, Loss: 0.00041100740781985223, Min w: 0.7596694827079773\n",
      "Iteration 1210, Loss: 0.0003700215893331915, Min w: 0.7711370587348938\n",
      "Iteration 1220, Loss: 0.0005246109794825315, Min w: 0.7290621995925903\n",
      "Iteration 1230, Loss: 0.0004200502298772335, Min w: 0.7637892961502075\n",
      "Iteration 1240, Loss: 0.0005381446680985391, Min w: 0.7001347541809082\n",
      "Iteration 0, Loss: 0.0003873093519359827, Min w: 0.7959292531013489\n",
      "Iteration 10, Loss: 0.0004062811203766614, Min w: 0.7824633121490479\n",
      "Iteration 20, Loss: 0.00034458949812687933, Min w: 0.7947659492492676\n",
      "Iteration 30, Loss: 0.000323556741932407, Min w: 0.8090002536773682\n",
      "Iteration 40, Loss: 0.00036866229493170977, Min w: 0.7815784215927124\n",
      "Iteration 50, Loss: 0.0003409612982068211, Min w: 0.8140507340431213\n",
      "Iteration 60, Loss: 0.0003370021586306393, Min w: 0.8123620748519897\n",
      "Iteration 70, Loss: 0.00030782524845562875, Min w: 0.8152519464492798\n",
      "Iteration 80, Loss: 0.00040980911580845714, Min w: 0.765307605266571\n",
      "Iteration 90, Loss: 0.0005202030297368765, Min w: 0.7214998006820679\n",
      "Iteration 100, Loss: 0.0004339393926784396, Min w: 0.7593246102333069\n",
      "Iteration 110, Loss: 0.0005249311798252165, Min w: 0.6941291689872742\n",
      "Iteration 120, Loss: 0.0006086521316319704, Min w: 0.6440788507461548\n",
      "Iteration 130, Loss: 0.00045801291707903147, Min w: 0.6963207721710205\n",
      "Iteration 140, Loss: 0.00044316769344732165, Min w: 0.7662566304206848\n",
      "Iteration 150, Loss: 0.0004166029393672943, Min w: 0.7587917447090149\n",
      "Iteration 160, Loss: 0.00031234341440722346, Min w: 0.8377701640129089\n",
      "Iteration 170, Loss: 0.00024781227693893015, Min w: 0.8731045126914978\n",
      "Iteration 180, Loss: 0.00022602605167776346, Min w: 0.8684046268463135\n",
      "Iteration 190, Loss: 0.0004007515963166952, Min w: 0.7394590377807617\n",
      "Iteration 200, Loss: 0.0003059989248868078, Min w: 0.8410143256187439\n",
      "Iteration 210, Loss: 0.00022633957269135863, Min w: 0.8738234639167786\n",
      "Iteration 220, Loss: 0.0002987172920256853, Min w: 0.8293406963348389\n",
      "Iteration 230, Loss: 0.00023678713478147984, Min w: 0.8680851459503174\n",
      "Iteration 240, Loss: 0.00026113406056538224, Min w: 0.8454271554946899\n",
      "Iteration 250, Loss: 0.00031414226396009326, Min w: 0.8098561763763428\n",
      "Iteration 260, Loss: 0.00021496048429980874, Min w: 0.8832067251205444\n",
      "Iteration 270, Loss: 0.00020259038137737662, Min w: 0.8931999802589417\n",
      "Iteration 280, Loss: 0.00021418850519694388, Min w: 0.8873103857040405\n",
      "Iteration 290, Loss: 0.0002580946311354637, Min w: 0.8611701726913452\n",
      "Iteration 300, Loss: 0.00021403766004368663, Min w: 0.8840852379798889\n",
      "Iteration 310, Loss: 0.00020156738173682243, Min w: 0.89683598279953\n",
      "Iteration 320, Loss: 0.00036365786218084395, Min w: 0.7776243686676025\n",
      "Iteration 330, Loss: 0.0002223921474069357, Min w: 0.8826057314872742\n",
      "Iteration 340, Loss: 0.00037397100823000073, Min w: 0.7770382761955261\n",
      "Iteration 350, Loss: 0.00020572380162775517, Min w: 0.888384997844696\n",
      "Iteration 360, Loss: 0.00034943962236866355, Min w: 0.7709407210350037\n",
      "Iteration 370, Loss: 0.0002900598046835512, Min w: 0.8151728510856628\n",
      "Iteration 380, Loss: 0.00035307693178765476, Min w: 0.7655977606773376\n",
      "Iteration 390, Loss: 0.00027839007088914514, Min w: 0.8312614560127258\n",
      "Iteration 400, Loss: 0.00023966813751030713, Min w: 0.8723498582839966\n",
      "Iteration 410, Loss: 0.0002443234552629292, Min w: 0.8497374653816223\n",
      "Iteration 420, Loss: 0.00027015150408260524, Min w: 0.8551079630851746\n",
      "Iteration 430, Loss: 0.0002339367347303778, Min w: 0.8739134669303894\n",
      "Iteration 440, Loss: 0.00016242454876191914, Min w: 0.9111352562904358\n",
      "Iteration 450, Loss: 0.00027465936727821827, Min w: 0.8161035180091858\n",
      "Iteration 460, Loss: 0.0002875016944017261, Min w: 0.8200574517250061\n",
      "Iteration 470, Loss: 0.0003719198575709015, Min w: 0.7677109241485596\n",
      "Iteration 480, Loss: 0.0002925858134403825, Min w: 0.8126654028892517\n",
      "Iteration 490, Loss: 0.00029435381293296814, Min w: 0.8132207989692688\n",
      "Iteration 500, Loss: 0.00023153392248786986, Min w: 0.8764020800590515\n",
      "Iteration 510, Loss: 0.00015861594874877483, Min w: 0.9165645837783813\n",
      "Iteration 520, Loss: 0.00015843301662243903, Min w: 0.9176255464553833\n",
      "Iteration 530, Loss: 0.00016146218695212156, Min w: 0.9172545671463013\n",
      "Iteration 540, Loss: 0.00014367428957484663, Min w: 0.9230196475982666\n",
      "Iteration 550, Loss: 0.00015702698146924376, Min w: 0.916373610496521\n",
      "Iteration 560, Loss: 0.00019209226593375206, Min w: 0.8974577188491821\n",
      "Iteration 570, Loss: 0.0003045972844120115, Min w: 0.8078629970550537\n",
      "Iteration 580, Loss: 0.0002784905082080513, Min w: 0.8168900012969971\n",
      "Iteration 590, Loss: 0.00025641900720074773, Min w: 0.8359128832817078\n",
      "Iteration 600, Loss: 0.00014598510460928082, Min w: 0.9231788516044617\n",
      "Iteration 610, Loss: 0.00018852447101380676, Min w: 0.890835702419281\n",
      "Iteration 620, Loss: 0.00023648796195629984, Min w: 0.8519617915153503\n",
      "Iteration 630, Loss: 0.00029986281879246235, Min w: 0.791321337223053\n",
      "Iteration 640, Loss: 0.00036461875424720347, Min w: 0.7486122250556946\n",
      "Iteration 650, Loss: 0.0001662836002651602, Min w: 0.9013198614120483\n",
      "Iteration 660, Loss: 0.00013216801744420081, Min w: 0.925451934337616\n",
      "Iteration 670, Loss: 0.0003958595625590533, Min w: 0.7358047366142273\n",
      "Iteration 680, Loss: 0.0002365198452025652, Min w: 0.8438493013381958\n",
      "Iteration 690, Loss: 0.0002287649258505553, Min w: 0.8561920523643494\n",
      "Iteration 700, Loss: 0.0001318795111728832, Min w: 0.9291441440582275\n",
      "Iteration 710, Loss: 0.0001444263762095943, Min w: 0.9203977584838867\n",
      "Iteration 720, Loss: 0.0002089490444632247, Min w: 0.8615842461585999\n",
      "Iteration 730, Loss: 0.0002177358401240781, Min w: 0.8645111918449402\n",
      "Iteration 740, Loss: 0.00014876465138513595, Min w: 0.9096106290817261\n",
      "Iteration 750, Loss: 0.0004498446942307055, Min w: 0.6815053224563599\n",
      "Iteration 760, Loss: 0.0001124570335377939, Min w: 0.9395608305931091\n",
      "Iteration 770, Loss: 0.0001307340426137671, Min w: 0.9224510192871094\n",
      "Iteration 780, Loss: 0.000129967593238689, Min w: 0.9326387047767639\n",
      "Iteration 790, Loss: 0.00013509124983102083, Min w: 0.9156635999679565\n",
      "Iteration 800, Loss: 0.00019573915051296353, Min w: 0.8754875659942627\n",
      "Iteration 810, Loss: 0.00013617648801300675, Min w: 0.9239699840545654\n",
      "Iteration 820, Loss: 0.0001123276524594985, Min w: 0.9378948211669922\n",
      "Iteration 830, Loss: 0.00021435844246298075, Min w: 0.858943521976471\n",
      "Iteration 840, Loss: 0.00012000957212876529, Min w: 0.932783305644989\n",
      "Iteration 850, Loss: 0.00029422336956486106, Min w: 0.8030188083648682\n",
      "Iteration 860, Loss: 0.0001373131526634097, Min w: 0.9281250834465027\n",
      "Iteration 870, Loss: 0.00010824903438333422, Min w: 0.9407773613929749\n",
      "Iteration 880, Loss: 0.00010531861335039139, Min w: 0.9436174035072327\n",
      "Iteration 890, Loss: 0.0001257481926586479, Min w: 0.9285421967506409\n",
      "Iteration 900, Loss: 0.0001071063379640691, Min w: 0.9436588883399963\n",
      "Iteration 910, Loss: 0.00028020492754876614, Min w: 0.8031530976295471\n",
      "Iteration 920, Loss: 0.00010905247472692281, Min w: 0.9422652721405029\n",
      "Iteration 930, Loss: 0.00011834321048809215, Min w: 0.9298059344291687\n",
      "Iteration 940, Loss: 0.00027673240401782095, Min w: 0.8135568499565125\n",
      "Iteration 950, Loss: 0.0001851602573879063, Min w: 0.8799084424972534\n",
      "Iteration 960, Loss: 0.00021659933554474264, Min w: 0.850326418876648\n",
      "Iteration 970, Loss: 0.00015785485447850078, Min w: 0.8994035720825195\n",
      "Iteration 980, Loss: 0.00012418108235578984, Min w: 0.9273945093154907\n",
      "Iteration 990, Loss: 0.0001302381861023605, Min w: 0.9261796474456787\n",
      "Iteration 1000, Loss: 0.00012484520266298205, Min w: 0.9293314814567566\n",
      "Iteration 1010, Loss: 0.00010897737229242921, Min w: 0.9356368184089661\n",
      "Iteration 1020, Loss: 0.00032941505196504295, Min w: 0.7794113755226135\n",
      "Iteration 1030, Loss: 0.00021473973174579442, Min w: 0.8518543243408203\n",
      "Iteration 1040, Loss: 0.0003281565150246024, Min w: 0.770913302898407\n",
      "Iteration 1050, Loss: 0.00010825863137142733, Min w: 0.9401469826698303\n",
      "Iteration 1060, Loss: 0.00046017018030397594, Min w: 0.670946478843689\n",
      "Iteration 1070, Loss: 0.00012103446351829916, Min w: 0.9251703023910522\n",
      "Iteration 1080, Loss: 0.00018054817337542772, Min w: 0.8748115301132202\n",
      "Iteration 1090, Loss: 0.0003432540106587112, Min w: 0.7516148090362549\n",
      "Iteration 1100, Loss: 0.0002898247039411217, Min w: 0.7890819907188416\n",
      "Iteration 1110, Loss: 0.00018552187248133123, Min w: 0.8741301894187927\n",
      "Iteration 1120, Loss: 0.00022312176588457078, Min w: 0.8392894268035889\n",
      "Iteration 1130, Loss: 0.00018878717673942447, Min w: 0.8675866723060608\n",
      "Iteration 1140, Loss: 0.00016016529116313905, Min w: 0.9129742383956909\n",
      "Iteration 1150, Loss: 0.0002561711589805782, Min w: 0.8210198879241943\n",
      "Iteration 1160, Loss: 9.069420775631443e-05, Min w: 0.9479608535766602\n",
      "Iteration 1170, Loss: 0.00029149046167731285, Min w: 0.7747225761413574\n",
      "Iteration 1180, Loss: 0.00022624884149990976, Min w: 0.833063006401062\n",
      "Iteration 1190, Loss: 7.565454143332317e-05, Min w: 0.9588181972503662\n",
      "Iteration 1200, Loss: 0.0001075391483027488, Min w: 0.9344624280929565\n",
      "Iteration 1210, Loss: 0.0002816571795847267, Min w: 0.80540531873703\n",
      "Iteration 1220, Loss: 8.792807057034224e-05, Min w: 0.9522646069526672\n",
      "Iteration 1230, Loss: 9.062913886737078e-05, Min w: 0.9484105706214905\n",
      "Iteration 1240, Loss: 0.00021522220049519092, Min w: 0.8534179329872131\n",
      "Iteration 0, Loss: 0.00010498074698261917, Min w: 0.9340837001800537\n",
      "Iteration 10, Loss: 0.00027043389854952693, Min w: 0.8091295957565308\n",
      "Iteration 20, Loss: 0.00023695718846283853, Min w: 0.8270482420921326\n",
      "Iteration 30, Loss: 0.0002895871875807643, Min w: 0.7976973056793213\n",
      "Iteration 40, Loss: 0.00010230878979200497, Min w: 0.9356760382652283\n",
      "Iteration 50, Loss: 0.0002943975559901446, Min w: 0.7701924443244934\n",
      "Iteration 60, Loss: 0.0002498801040928811, Min w: 0.8300540447235107\n",
      "Iteration 70, Loss: 0.00010111101437360048, Min w: 0.933657169342041\n",
      "Iteration 80, Loss: 0.0002467528101988137, Min w: 0.8311469554901123\n",
      "Iteration 90, Loss: 9.43428385653533e-05, Min w: 0.9442030191421509\n",
      "Iteration 100, Loss: 0.0001924866228364408, Min w: 0.8661308288574219\n",
      "Iteration 110, Loss: 0.0003252188325859606, Min w: 0.7667126059532166\n",
      "Iteration 120, Loss: 8.603645255789161e-05, Min w: 0.9487782716751099\n",
      "Iteration 130, Loss: 6.787065649405122e-05, Min w: 0.9623903036117554\n",
      "Iteration 140, Loss: 0.00020516235963441432, Min w: 0.8642991781234741\n",
      "Iteration 150, Loss: 6.964644126128405e-05, Min w: 0.9618772864341736\n",
      "Iteration 160, Loss: 7.287271728273481e-05, Min w: 0.96017986536026\n",
      "Iteration 170, Loss: 0.00030657011666335166, Min w: 0.7705560922622681\n",
      "Iteration 180, Loss: 0.0002904222928918898, Min w: 0.777211606502533\n",
      "Iteration 190, Loss: 0.0003334365028422326, Min w: 0.7619208097457886\n",
      "Iteration 200, Loss: 6.658239726675674e-05, Min w: 0.9657800793647766\n",
      "Iteration 210, Loss: 8.279131725430489e-05, Min w: 0.9518375396728516\n",
      "Iteration 220, Loss: 0.00010553558968240395, Min w: 0.9352685809135437\n",
      "Iteration 230, Loss: 8.796407928457484e-05, Min w: 0.9434331655502319\n",
      "Iteration 240, Loss: 0.0002918712852988392, Min w: 0.7714032530784607\n",
      "Iteration 250, Loss: 0.0004082952218595892, Min w: 0.7721725106239319\n",
      "Iteration 260, Loss: 0.00038510115700773895, Min w: 0.7406092882156372\n",
      "Iteration 270, Loss: 8.342170622199774e-05, Min w: 0.9543425440788269\n",
      "Iteration 280, Loss: 0.0003530178510118276, Min w: 0.7455873489379883\n",
      "Iteration 290, Loss: 8.968533802544698e-05, Min w: 0.9487630724906921\n",
      "Iteration 300, Loss: 5.840857920702547e-05, Min w: 0.9678068161010742\n",
      "Iteration 310, Loss: 0.0001868335239123553, Min w: 0.8666971325874329\n",
      "Iteration 320, Loss: 6.755068170605227e-05, Min w: 0.9624160528182983\n",
      "Iteration 330, Loss: 0.00014005557750351727, Min w: 0.9162149429321289\n",
      "Iteration 340, Loss: 0.00016182742547243834, Min w: 0.8889948725700378\n",
      "Iteration 350, Loss: 0.00010126759298145771, Min w: 0.9381239414215088\n",
      "Iteration 360, Loss: 7.589541928609833e-05, Min w: 0.9490413069725037\n",
      "Iteration 370, Loss: 0.0001719594292808324, Min w: 0.8696226477622986\n",
      "Iteration 380, Loss: 6.241903611226007e-05, Min w: 0.9672331809997559\n",
      "Iteration 390, Loss: 0.00015244916721712798, Min w: 0.9055331945419312\n",
      "Iteration 400, Loss: 0.0001682290603639558, Min w: 0.8857917785644531\n",
      "Iteration 410, Loss: 0.00014974702207837254, Min w: 0.910855233669281\n",
      "Iteration 420, Loss: 9.314419003203511e-05, Min w: 0.9419257044792175\n",
      "Iteration 430, Loss: 5.251592301647179e-05, Min w: 0.9727764129638672\n",
      "Iteration 440, Loss: 8.070893818512559e-05, Min w: 0.9488812685012817\n",
      "Iteration 450, Loss: 0.0001785017375368625, Min w: 0.875985860824585\n",
      "Iteration 460, Loss: 0.00010732319060480222, Min w: 0.925710141658783\n",
      "Iteration 470, Loss: 0.00013258621038403362, Min w: 0.9056711792945862\n",
      "Iteration 480, Loss: 0.00024281657533720136, Min w: 0.8336543440818787\n",
      "Iteration 490, Loss: 0.00010587315045995638, Min w: 0.9319524168968201\n",
      "Iteration 500, Loss: 0.00011172756785526872, Min w: 0.9155265092849731\n",
      "Iteration 510, Loss: 0.00014334479055833071, Min w: 0.901732325553894\n",
      "Iteration 520, Loss: 0.0001831473782658577, Min w: 0.8772472739219666\n",
      "Iteration 530, Loss: 0.00016419992607552558, Min w: 0.8761227130889893\n",
      "Iteration 540, Loss: 0.00021925425971858203, Min w: 0.837367057800293\n",
      "Iteration 550, Loss: 7.168246520450339e-05, Min w: 0.9595174789428711\n",
      "Iteration 560, Loss: 7.922257645986974e-05, Min w: 0.9509185552597046\n",
      "Iteration 570, Loss: 0.00012742221588268876, Min w: 0.9044684171676636\n",
      "Iteration 580, Loss: 0.0001725782931316644, Min w: 0.8756211400032043\n",
      "Iteration 590, Loss: 8.308238466270268e-05, Min w: 0.9439945816993713\n",
      "Iteration 600, Loss: 8.838991925586015e-05, Min w: 0.9426375031471252\n",
      "Iteration 610, Loss: 0.00010697119432734326, Min w: 0.9228757619857788\n",
      "Iteration 620, Loss: 0.00027513696113601327, Min w: 0.7905915975570679\n",
      "Iteration 630, Loss: 0.0002803697425406426, Min w: 0.7741181254386902\n",
      "Iteration 640, Loss: 0.00024192048294935375, Min w: 0.8309470415115356\n",
      "Iteration 650, Loss: 0.00017243888578377664, Min w: 0.8823271989822388\n",
      "Iteration 660, Loss: 0.00013243150897324085, Min w: 0.9011437296867371\n",
      "Iteration 670, Loss: 0.0001178079255623743, Min w: 0.911984384059906\n",
      "Iteration 680, Loss: 0.0002004602865781635, Min w: 0.842124879360199\n",
      "Iteration 690, Loss: 0.000159677307237871, Min w: 0.8705954551696777\n",
      "Iteration 700, Loss: 0.00010412726260256022, Min w: 0.9349933862686157\n",
      "Iteration 710, Loss: 0.00015346857253462076, Min w: 0.8807665109634399\n",
      "Iteration 720, Loss: 0.00011771212302846834, Min w: 0.9094412326812744\n",
      "Iteration 730, Loss: 0.0001377649314235896, Min w: 0.9019355773925781\n",
      "Iteration 740, Loss: 0.00024275564646814018, Min w: 0.821949303150177\n",
      "Iteration 750, Loss: 4.988262662664056e-05, Min w: 0.9722094535827637\n",
      "Iteration 760, Loss: 7.397143781417981e-05, Min w: 0.9506619572639465\n",
      "Iteration 770, Loss: 0.0005857777432538569, Min w: 0.5745366215705872\n",
      "Iteration 780, Loss: 0.0007326288032345474, Min w: 0.4441341459751129\n",
      "Iteration 790, Loss: 0.0004921137006022036, Min w: 0.6613405346870422\n",
      "Iteration 800, Loss: 4.425199585966766e-05, Min w: 0.9740121960639954\n",
      "Iteration 810, Loss: 6.287675932981074e-05, Min w: 0.9569755792617798\n",
      "Iteration 820, Loss: 5.371113365981728e-05, Min w: 0.9660736322402954\n",
      "Iteration 830, Loss: 7.466285023838282e-05, Min w: 0.9480204582214355\n",
      "Iteration 840, Loss: 0.00013996886264067143, Min w: 0.9044511318206787\n",
      "Iteration 850, Loss: 4.813312625628896e-05, Min w: 0.9736084938049316\n",
      "Iteration 860, Loss: 4.4980173697695136e-05, Min w: 0.9730522632598877\n",
      "Iteration 870, Loss: 0.00014093448407948017, Min w: 0.9051854014396667\n",
      "Iteration 880, Loss: 4.808785524801351e-05, Min w: 0.97478848695755\n",
      "Iteration 890, Loss: 0.00012349376629572362, Min w: 0.90861976146698\n",
      "Iteration 900, Loss: 0.0001609685568837449, Min w: 0.8849559426307678\n",
      "Iteration 910, Loss: 5.850443631061353e-05, Min w: 0.9696532487869263\n",
      "Iteration 920, Loss: 8.274162973975763e-05, Min w: 0.9486104249954224\n",
      "Iteration 930, Loss: 7.368411752395332e-05, Min w: 0.9486873745918274\n",
      "Iteration 940, Loss: 4.238840119796805e-05, Min w: 0.9756810665130615\n",
      "Iteration 950, Loss: 6.850047793705016e-05, Min w: 0.9546497464179993\n",
      "Iteration 960, Loss: 0.00018215709133073688, Min w: 0.8679553270339966\n",
      "Iteration 970, Loss: 0.00010853865387616679, Min w: 0.9234997630119324\n",
      "Iteration 980, Loss: 0.00015783522394485772, Min w: 0.884877622127533\n",
      "Iteration 990, Loss: 0.00013896575546823442, Min w: 0.8940097093582153\n",
      "Iteration 1000, Loss: 0.00016004759527277201, Min w: 0.917434811592102\n",
      "Iteration 1010, Loss: 7.270622154464945e-05, Min w: 0.9551504850387573\n",
      "Iteration 1020, Loss: 0.00023025466362014413, Min w: 0.8561515808105469\n",
      "Iteration 1030, Loss: 0.0003152378194499761, Min w: 0.7757270336151123\n",
      "Iteration 1040, Loss: 4.8329973651561886e-05, Min w: 0.971918523311615\n",
      "Iteration 1050, Loss: 0.00012473338574636728, Min w: 0.9109996557235718\n",
      "Iteration 1060, Loss: 0.00029386478126980364, Min w: 0.7665651440620422\n",
      "Iteration 1070, Loss: 0.00040097671444527805, Min w: 0.705460786819458\n",
      "Iteration 1080, Loss: 0.0005513352225534618, Min w: 0.5726621150970459\n",
      "Iteration 1090, Loss: 0.000189883096027188, Min w: 0.8347415328025818\n",
      "Iteration 1100, Loss: 0.0003507950168568641, Min w: 0.7521440386772156\n",
      "Iteration 1110, Loss: 0.00012403505388647318, Min w: 0.9302933216094971\n",
      "Iteration 1120, Loss: 0.0001224202278535813, Min w: 0.9070237278938293\n",
      "Iteration 1130, Loss: 4.9292732001049444e-05, Min w: 0.9705396294593811\n",
      "Iteration 1140, Loss: 0.00028105967794544995, Min w: 0.7888628244400024\n",
      "Iteration 1150, Loss: 7.715805259067565e-05, Min w: 0.9443468451499939\n",
      "Iteration 1160, Loss: 9.807444439502433e-05, Min w: 0.9233582019805908\n",
      "Iteration 1170, Loss: 5.809684080304578e-05, Min w: 0.9580718278884888\n",
      "Iteration 1180, Loss: 3.590390406316146e-05, Min w: 0.9801079034805298\n",
      "Iteration 1190, Loss: 9.020735160447657e-05, Min w: 0.9369564056396484\n",
      "Iteration 1200, Loss: 3.786253000725992e-05, Min w: 0.9782696962356567\n",
      "Iteration 1210, Loss: 7.840205216780305e-05, Min w: 0.9488638043403625\n",
      "Iteration 1220, Loss: 8.004035771591589e-05, Min w: 0.948058545589447\n",
      "Iteration 1230, Loss: 0.00012048728240188211, Min w: 0.9062719345092773\n",
      "Iteration 1240, Loss: 0.0001239911071024835, Min w: 0.9185982942581177\n",
      "Iteration 0, Loss: 5.624279219773598e-05, Min w: 0.9669316411018372\n",
      "Iteration 10, Loss: 0.00019986067491117865, Min w: 0.8485353589057922\n",
      "Iteration 20, Loss: 0.00012454732495825738, Min w: 0.9091110229492188\n",
      "Iteration 30, Loss: 9.351334301754832e-05, Min w: 0.9355969429016113\n",
      "Iteration 40, Loss: 8.56993647175841e-05, Min w: 0.9406019449234009\n",
      "Iteration 50, Loss: 0.0001455861347494647, Min w: 0.8939560651779175\n",
      "Iteration 60, Loss: 4.547203207039274e-05, Min w: 0.9693242907524109\n",
      "Iteration 70, Loss: 4.0876933780964464e-05, Min w: 0.9725291132926941\n",
      "Iteration 80, Loss: 3.954498970415443e-05, Min w: 0.9762402772903442\n",
      "Iteration 90, Loss: 0.00012356153456494212, Min w: 0.9093775153160095\n",
      "Iteration 100, Loss: 0.00014427040878217667, Min w: 0.8797745704650879\n",
      "Iteration 110, Loss: 0.00012242927914485335, Min w: 0.9031403064727783\n",
      "Iteration 120, Loss: 0.00014881770766805857, Min w: 0.900399386882782\n",
      "Iteration 130, Loss: 8.663383778184652e-05, Min w: 0.9390585422515869\n",
      "Iteration 140, Loss: 4.701864600065164e-05, Min w: 0.9727996587753296\n",
      "Iteration 150, Loss: 3.832735455944203e-05, Min w: 0.9766082167625427\n",
      "Iteration 160, Loss: 6.536258297273889e-05, Min w: 0.960645318031311\n",
      "Iteration 170, Loss: 3.367309182067402e-05, Min w: 0.9799811840057373\n",
      "Iteration 180, Loss: 6.722606485709548e-05, Min w: 0.9468553066253662\n",
      "Iteration 190, Loss: 4.1163137211697176e-05, Min w: 0.976257860660553\n",
      "Iteration 200, Loss: 0.00013028565444983542, Min w: 0.8997737169265747\n",
      "Iteration 210, Loss: 0.00022989172430243343, Min w: 0.8311170339584351\n",
      "Iteration 220, Loss: 6.138682510936633e-05, Min w: 0.9547739624977112\n",
      "Iteration 230, Loss: 8.387092384509742e-05, Min w: 0.9354948997497559\n",
      "Iteration 240, Loss: 6.535551801789552e-05, Min w: 0.9484758973121643\n",
      "Iteration 250, Loss: 3.4979071642737836e-05, Min w: 0.9798644781112671\n",
      "Iteration 260, Loss: 0.00018403553985990584, Min w: 0.8661478757858276\n",
      "Iteration 270, Loss: 0.0001321036252193153, Min w: 0.8973251581192017\n",
      "Iteration 280, Loss: 4.4982327381148934e-05, Min w: 0.9717106819152832\n",
      "Iteration 290, Loss: 0.00013285728346090764, Min w: 0.9152342677116394\n",
      "Iteration 300, Loss: 0.00021729152649641037, Min w: 0.8208470344543457\n",
      "Iteration 310, Loss: 0.00023237567802425474, Min w: 0.8163214325904846\n",
      "Iteration 320, Loss: 0.0001422127679688856, Min w: 0.8942635655403137\n",
      "Iteration 330, Loss: 4.832063859794289e-05, Min w: 0.9738010168075562\n",
      "Iteration 340, Loss: 0.00012508404324762523, Min w: 0.8956109285354614\n",
      "Iteration 350, Loss: 0.00016435985162388533, Min w: 0.8785600662231445\n",
      "Iteration 360, Loss: 0.00022593565518036485, Min w: 0.8221712708473206\n",
      "Iteration 370, Loss: 0.00014508984168060124, Min w: 0.8947107195854187\n",
      "Iteration 380, Loss: 5.756050450145267e-05, Min w: 0.957756757736206\n",
      "Iteration 390, Loss: 6.413533992599696e-05, Min w: 0.9611831307411194\n",
      "Iteration 400, Loss: 0.00011290430120425299, Min w: 0.904665470123291\n",
      "Iteration 410, Loss: 0.00021229208505246788, Min w: 0.823615550994873\n",
      "Iteration 420, Loss: 0.00014053890481591225, Min w: 0.8865252137184143\n",
      "Iteration 430, Loss: 0.00026770110707730055, Min w: 0.7842025756835938\n",
      "Iteration 440, Loss: 0.00016335202963091433, Min w: 0.8643664121627808\n",
      "Iteration 450, Loss: 0.00020505592692643404, Min w: 0.8531777858734131\n",
      "Iteration 460, Loss: 0.0001301573502132669, Min w: 0.8980550765991211\n",
      "Iteration 470, Loss: 5.324961239239201e-05, Min w: 0.9617531895637512\n",
      "Iteration 480, Loss: 0.00016472254355903715, Min w: 0.8738957047462463\n",
      "Iteration 490, Loss: 8.979583799373358e-05, Min w: 0.9374696016311646\n",
      "Iteration 500, Loss: 0.0002080015983665362, Min w: 0.8457655906677246\n",
      "Iteration 510, Loss: 9.226939437212422e-05, Min w: 0.9365958571434021\n",
      "Iteration 520, Loss: 4.372333569335751e-05, Min w: 0.9703124761581421\n",
      "Iteration 530, Loss: 0.0002101902646245435, Min w: 0.842723548412323\n",
      "Iteration 540, Loss: 8.233433618443087e-05, Min w: 0.9391358494758606\n",
      "Iteration 550, Loss: 6.081114406697452e-05, Min w: 0.9589793682098389\n",
      "Iteration 560, Loss: 3.97315998270642e-05, Min w: 0.9726473689079285\n",
      "Iteration 570, Loss: 9.626500104786828e-05, Min w: 0.927915096282959\n",
      "Iteration 580, Loss: 7.443530921591446e-05, Min w: 0.9544084072113037\n",
      "Iteration 590, Loss: 5.922692798776552e-05, Min w: 0.9536838531494141\n",
      "Iteration 600, Loss: 4.869834447163157e-05, Min w: 0.9621806144714355\n",
      "Iteration 610, Loss: 4.058848935528658e-05, Min w: 0.9706450700759888\n",
      "Iteration 620, Loss: 0.00012532695836853236, Min w: 0.92296302318573\n",
      "Iteration 630, Loss: 3.436275801504962e-05, Min w: 0.9805794954299927\n",
      "Iteration 640, Loss: 8.193016401492059e-05, Min w: 0.9393026232719421\n",
      "Iteration 650, Loss: 4.500377326621674e-05, Min w: 0.966555655002594\n",
      "Iteration 660, Loss: 0.00022320335847325623, Min w: 0.8206602334976196\n",
      "Iteration 670, Loss: 7.72600105847232e-05, Min w: 0.9460119009017944\n",
      "Iteration 680, Loss: 0.0003641267539933324, Min w: 0.7268707156181335\n",
      "Iteration 690, Loss: 0.00010828844096977264, Min w: 0.9113593101501465\n",
      "Iteration 700, Loss: 0.00011197146523045376, Min w: 0.9254016280174255\n",
      "Iteration 710, Loss: 0.00025586411356925964, Min w: 0.8030275106430054\n",
      "Iteration 720, Loss: 0.0005332916043698788, Min w: 0.6561059951782227\n",
      "Iteration 730, Loss: 0.00016678193060215563, Min w: 0.8614597916603088\n",
      "Iteration 740, Loss: 8.285338117275387e-05, Min w: 0.937740683555603\n",
      "Iteration 750, Loss: 0.0016937904292717576, Min w: 0.04409077391028404\n",
      "Iteration 760, Loss: 0.0013383899349719286, Min w: 0.12765292823314667\n",
      "Iteration 770, Loss: 0.002047470072284341, Min w: 1.8563772755442187e-05\n",
      "Iteration 780, Loss: 0.001994847785681486, Min w: 3.199627144567785e-06\n",
      "Iteration 790, Loss: 0.0019672270864248276, Min w: 9.502594331459496e-21\n",
      "Iteration 800, Loss: 0.0020739571191370487, Min w: 3.4292505799251877e-15\n",
      "Iteration 810, Loss: 0.002029129071161151, Min w: 1.0618823154118218e-08\n",
      "Iteration 820, Loss: 0.0017063572304323316, Min w: 0.09271901845932007\n",
      "Iteration 830, Loss: 0.0011461873073130846, Min w: 0.33629339933395386\n",
      "Iteration 840, Loss: 0.0005732310237362981, Min w: 0.663901686668396\n",
      "Iteration 850, Loss: 0.0006553165731020272, Min w: 0.4614267945289612\n",
      "Iteration 860, Loss: 0.00010994764306815341, Min w: 0.9367856979370117\n",
      "Iteration 870, Loss: 0.00039952294901013374, Min w: 0.6674226522445679\n",
      "Iteration 880, Loss: 0.00027617806335911155, Min w: 0.7524929046630859\n",
      "Iteration 890, Loss: 0.00013504920934792608, Min w: 0.8975532054901123\n",
      "Iteration 900, Loss: 0.0001041849609464407, Min w: 0.9140240550041199\n",
      "Iteration 910, Loss: 6.875672988826409e-05, Min w: 0.9483775496482849\n",
      "Iteration 920, Loss: 3.572388959582895e-05, Min w: 0.979623556137085\n",
      "Iteration 930, Loss: 3.429617208894342e-05, Min w: 0.980676531791687\n",
      "Iteration 940, Loss: 5.65458758501336e-05, Min w: 0.9615119099617004\n",
      "Iteration 950, Loss: 7.225472654681653e-05, Min w: 0.9510034322738647\n",
      "Iteration 960, Loss: 6.0181009757798165e-05, Min w: 0.9622568488121033\n",
      "Iteration 970, Loss: 3.330227991682477e-05, Min w: 0.9809847474098206\n",
      "Iteration 980, Loss: 6.605147791560739e-05, Min w: 0.952603816986084\n",
      "Iteration 990, Loss: 3.139516411465593e-05, Min w: 0.9835706353187561\n",
      "Iteration 1000, Loss: 0.00010466145613463596, Min w: 0.9219650030136108\n",
      "Iteration 1010, Loss: 5.040575342718512e-05, Min w: 0.9678032994270325\n",
      "Iteration 1020, Loss: 9.212899749400094e-05, Min w: 0.9321630597114563\n",
      "Iteration 1030, Loss: 6.086572466301732e-05, Min w: 0.9573832750320435\n",
      "Iteration 1040, Loss: 0.00019749830244109035, Min w: 0.844423234462738\n",
      "Iteration 1050, Loss: 0.00013776382547803223, Min w: 0.8905649781227112\n",
      "Iteration 1060, Loss: 3.967000520788133e-05, Min w: 0.9787057638168335\n",
      "Iteration 1070, Loss: 7.789035589667037e-05, Min w: 0.943949282169342\n",
      "Iteration 1080, Loss: 0.00011927622108487412, Min w: 0.9105559587478638\n",
      "Iteration 1090, Loss: 0.00014146177272778004, Min w: 0.8951273560523987\n",
      "Iteration 1100, Loss: 4.205763616482727e-05, Min w: 0.9748265147209167\n",
      "Iteration 1110, Loss: 9.876605327008292e-05, Min w: 0.9266382455825806\n",
      "Iteration 1120, Loss: 0.00019277264073025435, Min w: 0.8403183221817017\n",
      "Iteration 1130, Loss: 7.025360537227243e-05, Min w: 0.9483931064605713\n",
      "Iteration 1140, Loss: 5.947292083874345e-05, Min w: 0.954522967338562\n",
      "Iteration 1150, Loss: 6.833457882748917e-05, Min w: 0.9464671015739441\n",
      "Iteration 1160, Loss: 0.00016454428259748966, Min w: 0.8724351525306702\n",
      "Iteration 1170, Loss: 0.0001879529154393822, Min w: 0.8517655730247498\n",
      "Iteration 1180, Loss: 3.020919393748045e-05, Min w: 0.9811108708381653\n",
      "Iteration 1190, Loss: 3.903445031028241e-05, Min w: 0.9754281640052795\n",
      "Iteration 1200, Loss: 0.00016001077892724425, Min w: 0.8774498105049133\n",
      "Iteration 1210, Loss: 0.0001044190430548042, Min w: 0.9235226511955261\n",
      "Iteration 1220, Loss: 8.483957208227366e-05, Min w: 0.939936637878418\n",
      "Iteration 1230, Loss: 0.00020064956333953887, Min w: 0.8432297110557556\n",
      "Iteration 1240, Loss: 3.097174339927733e-05, Min w: 0.9813172817230225\n",
      "Iteration 0, Loss: 0.00012044267350574955, Min w: 0.9061896204948425\n",
      "Iteration 10, Loss: 0.00012190893903607503, Min w: 0.9046129584312439\n",
      "Iteration 20, Loss: 2.930512164311949e-05, Min w: 0.9817832112312317\n",
      "Iteration 30, Loss: 0.0002546115720178932, Min w: 0.8040812611579895\n",
      "Iteration 40, Loss: 9.013976523419842e-05, Min w: 0.9282770752906799\n",
      "Iteration 50, Loss: 9.897451673168689e-05, Min w: 0.9224538207054138\n",
      "Iteration 60, Loss: 0.00012869847705587745, Min w: 0.8952768445014954\n",
      "Iteration 70, Loss: 0.00013628831948153675, Min w: 0.8901854753494263\n",
      "Iteration 80, Loss: 2.7997917641187087e-05, Min w: 0.9817425012588501\n",
      "Iteration 90, Loss: 7.77814639150165e-05, Min w: 0.9436321258544922\n",
      "Iteration 100, Loss: 0.00015870424977038056, Min w: 0.8707723021507263\n",
      "Iteration 110, Loss: 2.9033699320279993e-05, Min w: 0.9812754988670349\n",
      "Iteration 120, Loss: 6.880886940052733e-05, Min w: 0.9430419206619263\n",
      "Iteration 130, Loss: 0.00011250059469603002, Min w: 0.910119354724884\n",
      "Iteration 140, Loss: 7.903437654022127e-05, Min w: 0.9407978057861328\n",
      "Iteration 150, Loss: 2.715665141295176e-05, Min w: 0.985923171043396\n",
      "Iteration 160, Loss: 0.0001256469840882346, Min w: 0.8967756032943726\n",
      "Iteration 170, Loss: 0.00011071600602008402, Min w: 0.9121897220611572\n",
      "Iteration 180, Loss: 0.0001759446895448491, Min w: 0.8623239994049072\n",
      "Iteration 190, Loss: 0.00011222824832657352, Min w: 0.9102393984794617\n",
      "Iteration 200, Loss: 0.00018767033179756254, Min w: 0.8552883267402649\n",
      "Iteration 210, Loss: 3.358073445269838e-05, Min w: 0.9790109992027283\n",
      "Iteration 220, Loss: 0.00010940345237031579, Min w: 0.9209986925125122\n",
      "Iteration 230, Loss: 4.29510218964424e-05, Min w: 0.9662325382232666\n",
      "Iteration 240, Loss: 8.978783444035798e-05, Min w: 0.9290647506713867\n",
      "Iteration 250, Loss: 0.00014831306179985404, Min w: 0.8801659941673279\n",
      "Iteration 260, Loss: 0.0001687027543084696, Min w: 0.8663204908370972\n",
      "Iteration 270, Loss: 9.754330676514655e-05, Min w: 0.9201685190200806\n",
      "Iteration 280, Loss: 4.061231447849423e-05, Min w: 0.9689050316810608\n",
      "Iteration 290, Loss: 7.049953273963183e-05, Min w: 0.9447075128555298\n",
      "Iteration 300, Loss: 5.462118497234769e-05, Min w: 0.9586237072944641\n",
      "Iteration 310, Loss: 4.405629078974016e-05, Min w: 0.9667029976844788\n",
      "Iteration 320, Loss: 5.580771539825946e-05, Min w: 0.9592744708061218\n",
      "Iteration 330, Loss: 0.00024236718309111893, Min w: 0.8108906745910645\n",
      "Iteration 340, Loss: 0.00014166157052386552, Min w: 0.8917824029922485\n",
      "Iteration 350, Loss: 8.000442176125944e-05, Min w: 0.9413145780563354\n",
      "Iteration 360, Loss: 9.369982581119984e-05, Min w: 0.9323862195014954\n",
      "Iteration 370, Loss: 7.407842349493876e-05, Min w: 0.9445644617080688\n",
      "Iteration 380, Loss: 0.0001071882143151015, Min w: 0.9193208813667297\n",
      "Iteration 390, Loss: 0.0001346617063973099, Min w: 0.8970196843147278\n",
      "Iteration 400, Loss: 0.00021309567091520876, Min w: 0.8204095959663391\n",
      "Iteration 410, Loss: 0.0001516259799245745, Min w: 0.88856440782547\n",
      "Iteration 420, Loss: 0.0001348403748124838, Min w: 0.8992332220077515\n",
      "Iteration 430, Loss: 0.0001020411800709553, Min w: 0.9260181784629822\n",
      "Iteration 440, Loss: 6.285819836193696e-05, Min w: 0.9639888405799866\n",
      "Iteration 450, Loss: 9.64590726653114e-05, Min w: 0.9221397042274475\n",
      "Iteration 460, Loss: 4.808746962225996e-05, Min w: 0.9629835486412048\n",
      "Iteration 470, Loss: 5.502582644112408e-05, Min w: 0.9598415493965149\n",
      "Iteration 480, Loss: 0.00032349431421607733, Min w: 0.7340258955955505\n",
      "Iteration 490, Loss: 5.493726348504424e-05, Min w: 0.9576224684715271\n",
      "Iteration 500, Loss: 3.5577879316406325e-05, Min w: 0.9798882007598877\n",
      "Iteration 510, Loss: 0.00024897640105336905, Min w: 0.8010715842247009\n",
      "Iteration 520, Loss: 2.3783550204825588e-05, Min w: 0.9857218861579895\n",
      "Iteration 530, Loss: 2.19718294829363e-05, Min w: 0.9870680570602417\n",
      "Iteration 540, Loss: 0.00017250723612960428, Min w: 0.8639143109321594\n",
      "Iteration 550, Loss: 0.00018645510135684162, Min w: 0.8441924452781677\n",
      "Iteration 560, Loss: 0.00013940631470177323, Min w: 0.883354902267456\n",
      "Iteration 570, Loss: 0.00016526837134733796, Min w: 0.8710001707077026\n",
      "Iteration 580, Loss: 0.00022888781677465886, Min w: 0.8136667609214783\n",
      "Iteration 590, Loss: 3.224254396627657e-05, Min w: 0.9755966067314148\n",
      "Iteration 600, Loss: 5.192228491068818e-05, Min w: 0.9618803858757019\n",
      "Iteration 610, Loss: 0.0001611242478247732, Min w: 0.8746176362037659\n",
      "Iteration 620, Loss: 0.00019139914365950972, Min w: 0.8650304675102234\n",
      "Iteration 630, Loss: 0.0001214797084685415, Min w: 0.9048340916633606\n",
      "Iteration 640, Loss: 3.314501736895181e-05, Min w: 0.9788417816162109\n",
      "Iteration 650, Loss: 8.99347141967155e-05, Min w: 0.9271641969680786\n",
      "Iteration 660, Loss: 4.515030741458759e-05, Min w: 0.9621012806892395\n",
      "Iteration 670, Loss: 0.00017675560957286507, Min w: 0.870486319065094\n",
      "Iteration 680, Loss: 0.0002686896768864244, Min w: 0.7854510545730591\n",
      "Iteration 690, Loss: 0.00014188248314894736, Min w: 0.8998170495033264\n",
      "Iteration 700, Loss: 2.3218983187689446e-05, Min w: 0.9859296083450317\n",
      "Iteration 710, Loss: 0.00011720089969458058, Min w: 0.8963093161582947\n",
      "Iteration 720, Loss: 9.604154183762148e-05, Min w: 0.9253813624382019\n",
      "Iteration 730, Loss: 8.18063854239881e-05, Min w: 0.9331304430961609\n",
      "Iteration 740, Loss: 5.461207183543593e-05, Min w: 0.9625807404518127\n",
      "Iteration 750, Loss: 5.618525028694421e-05, Min w: 0.9624186754226685\n",
      "Iteration 760, Loss: 0.00019377619901206344, Min w: 0.8282953500747681\n",
      "Iteration 770, Loss: 0.00010008053504861891, Min w: 0.9197799563407898\n",
      "Iteration 780, Loss: 3.2997031667036936e-05, Min w: 0.9754226207733154\n",
      "Iteration 790, Loss: 6.428305641748011e-05, Min w: 0.9670698642730713\n",
      "Iteration 800, Loss: 0.00010605897841742262, Min w: 0.9103657603263855\n",
      "Iteration 810, Loss: 2.7975140255875885e-05, Min w: 0.9799381494522095\n",
      "Iteration 820, Loss: 0.00015034932584967464, Min w: 0.899059534072876\n",
      "Iteration 830, Loss: 0.00013739269343204796, Min w: 0.892828106880188\n",
      "Iteration 840, Loss: 9.446493641007692e-05, Min w: 0.9283978343009949\n",
      "Iteration 850, Loss: 0.00015101810276973993, Min w: 0.8720026612281799\n",
      "Iteration 860, Loss: 0.0002383495884714648, Min w: 0.8404648900032043\n",
      "Iteration 870, Loss: 0.00012321615940891206, Min w: 0.8986084461212158\n",
      "Iteration 880, Loss: 0.00013086396211292595, Min w: 0.9095733165740967\n",
      "Iteration 890, Loss: 0.00013866223162040114, Min w: 0.8833675384521484\n",
      "Iteration 900, Loss: 5.116889224154875e-05, Min w: 0.9644253253936768\n",
      "Iteration 910, Loss: 0.00018488983914721757, Min w: 0.8540694117546082\n",
      "Iteration 920, Loss: 0.00019400598830543458, Min w: 0.8492984175682068\n",
      "Iteration 930, Loss: 8.114786760415882e-05, Min w: 0.933457612991333\n",
      "Iteration 940, Loss: 2.2004425773047842e-05, Min w: 0.9853456616401672\n",
      "Iteration 950, Loss: 7.492501754313707e-05, Min w: 0.9332664608955383\n",
      "Iteration 960, Loss: 0.0002459143288433552, Min w: 0.8127707242965698\n",
      "Iteration 970, Loss: 0.00012156174489064142, Min w: 0.9048192501068115\n",
      "Iteration 980, Loss: 6.347686576191336e-05, Min w: 0.959104061126709\n",
      "Iteration 990, Loss: 4.425994848133996e-05, Min w: 0.963572084903717\n",
      "Iteration 1000, Loss: 7.834289135644212e-05, Min w: 0.9391873478889465\n",
      "Iteration 1010, Loss: 2.051386945822742e-05, Min w: 0.9852681159973145\n",
      "Iteration 1020, Loss: 9.765366849023849e-05, Min w: 0.9189488291740417\n",
      "Iteration 1030, Loss: 4.427504609338939e-05, Min w: 0.9678930044174194\n",
      "Iteration 1040, Loss: 0.00013893379946239293, Min w: 0.8888219594955444\n",
      "Iteration 1050, Loss: 3.542484773788601e-05, Min w: 0.9762338995933533\n",
      "Iteration 1060, Loss: 0.0001715938124107197, Min w: 0.8512493371963501\n",
      "Iteration 1070, Loss: 0.00016682440764270723, Min w: 0.8795632123947144\n",
      "Iteration 1080, Loss: 0.00014908112643752247, Min w: 0.8892093896865845\n",
      "Iteration 1090, Loss: 3.3465355954831466e-05, Min w: 0.9782701134681702\n",
      "Iteration 1100, Loss: 8.076734229689464e-05, Min w: 0.928998589515686\n",
      "Iteration 1110, Loss: 0.00016797413991298527, Min w: 0.8727208971977234\n",
      "Iteration 1120, Loss: 0.0001579820818733424, Min w: 0.8804444670677185\n",
      "Iteration 1130, Loss: 0.0002200173621531576, Min w: 0.8436303734779358\n",
      "Iteration 1140, Loss: 6.307123112492263e-05, Min w: 0.9500489830970764\n",
      "Iteration 1150, Loss: 4.5360073272604495e-05, Min w: 0.9635778665542603\n",
      "Iteration 1160, Loss: 8.99902661330998e-05, Min w: 0.9362977147102356\n",
      "Iteration 1170, Loss: 0.00017906364519149065, Min w: 0.849664032459259\n",
      "Iteration 1180, Loss: 0.00015811444609425962, Min w: 0.8812023997306824\n",
      "Iteration 1190, Loss: 5.984038580209017e-05, Min w: 0.9499493837356567\n",
      "Iteration 1200, Loss: 0.00011851915041916072, Min w: 0.9076258540153503\n",
      "Iteration 1210, Loss: 8.795585745247081e-05, Min w: 0.9299237132072449\n",
      "Iteration 1220, Loss: 0.00010345934424549341, Min w: 0.9247071146965027\n",
      "Iteration 1230, Loss: 3.614830711740069e-05, Min w: 0.9759560823440552\n",
      "Iteration 1240, Loss: 5.319494448485784e-05, Min w: 0.960172176361084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   8%|▊         | 2/24 [03:07<34:29, 94.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.012028156635721194, 'L2_avg': 0.014184639726271146, 'End_point_L1_avg': 0.01064542264660538, 'End_point_L2_avg': 0.011827169972759297}\n",
      "Iteration 0, Loss: 0.001865196623839438, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0009484474430792034, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006822278955951333, Min w: 7.723518939230352e-29\n",
      "Iteration 30, Loss: 0.0005989847122691572, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005590717773884535, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005417460342869163, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005615251138806343, Min w: 0.0\n",
      "Iteration 70, Loss: 0.000557351449970156, Min w: 0.0\n",
      "Iteration 80, Loss: 0.000603011401835829, Min w: 6.910770377179312e-14\n",
      "Iteration 90, Loss: 0.0005621010786853731, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005217248690314591, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005042797420173883, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005406640702858567, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0004809777601622045, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0004533016763161868, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005100264679640532, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005276587326079607, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005325703532435, Min w: 4.44211613190967e-43\n",
      "Iteration 180, Loss: 0.000517582637257874, Min w: 2.8127740793543917e-24\n",
      "Iteration 190, Loss: 0.0005328910774551332, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006121274782344699, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005448705633170903, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0004962033126503229, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005150020006112754, Min w: 6.173476436521555e-40\n",
      "Iteration 240, Loss: 0.0005158308194950223, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0005124416202306747, Min w: 1.3986684481095838e-17\n",
      "Iteration 260, Loss: 0.0005351901054382324, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005024042911827564, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0004977125790901482, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005027161678299308, Min w: 5.472961940798915e-18\n",
      "Iteration 300, Loss: 0.0005300493794493377, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005279884790070355, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005411647143773735, Min w: 4.829463898233154e-34\n",
      "Iteration 330, Loss: 0.0005238777957856655, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000583720684517175, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0005058980896137655, Min w: 2.5655690924726906e-23\n",
      "Iteration 360, Loss: 0.0005064650904387236, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0005054700886830688, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0004944329266436398, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005220162565819919, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005290873814374208, Min w: 0.0\n",
      "Iteration 410, Loss: 0.000530027027707547, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004940234939567745, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004961162339895964, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0004862145578954369, Min w: 6.333869058748173e-43\n",
      "Iteration 450, Loss: 0.000501113710924983, Min w: 2.4114945272565777e-41\n",
      "Iteration 460, Loss: 0.0005077713285572827, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005258789169602096, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0005647630314342678, Min w: 4.3693385832873515e-33\n",
      "Iteration 490, Loss: 0.0005288736429065466, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004982628161087632, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005231965915299952, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0005062526906840503, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0004983464605174959, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005348529666662216, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005542677245102823, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0005454006022773683, Min w: 1.904888698643084e-39\n",
      "Iteration 570, Loss: 0.0004919875646010041, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0004339379956945777, Min w: 1.5143526346253299e-18\n",
      "Iteration 590, Loss: 0.0005007241852581501, Min w: 0.0\n",
      "Iteration 600, Loss: 0.000541495275683701, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0004992387257516384, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0004969525034539402, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0005281515186652541, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005030675674788654, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0005183593020774424, Min w: 8.794772078420179e-35\n",
      "Iteration 660, Loss: 0.0004865482624154538, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00048788380809128284, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0004923756932839751, Min w: 2.933815324013267e-07\n",
      "Iteration 690, Loss: 0.0004969419678673148, Min w: 1.4397361383089446e-06\n",
      "Iteration 700, Loss: 0.0005114101804792881, Min w: 7.807243046498158e-11\n",
      "Iteration 710, Loss: 0.000513040809892118, Min w: 4.0271760549919847e-32\n",
      "Iteration 720, Loss: 0.0005344359087757766, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0005364962853491306, Min w: 1.087407608316058e-42\n",
      "Iteration 740, Loss: 0.0005329755949787796, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0005053036147728562, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0005171675584279001, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0005101969582028687, Min w: 2.7773540845627e-13\n",
      "Iteration 780, Loss: 0.0005080905975773931, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0004930342547595501, Min w: 2.213925426985952e-06\n",
      "Iteration 800, Loss: 0.0004949845606461167, Min w: 9.806853950872912e-14\n",
      "Iteration 810, Loss: 0.0005026256549172103, Min w: 1.1197856877864787e-13\n",
      "Iteration 820, Loss: 0.0005108233890496194, Min w: 1.0350702313111882e-23\n",
      "Iteration 830, Loss: 0.0005055709043517709, Min w: 1.0695860429982273e-12\n",
      "Iteration 840, Loss: 0.000499392335768789, Min w: 0.0003277782234363258\n",
      "Iteration 850, Loss: 0.0005036587826907635, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0004959325306117535, Min w: 0.0\n",
      "Iteration 870, Loss: 0.000502976996358484, Min w: 1.1800944291642096e-18\n",
      "Iteration 880, Loss: 0.0004605127323884517, Min w: 7.630243293221417e-30\n",
      "Iteration 890, Loss: 0.0004959654179401696, Min w: 8.092874460852162e-12\n",
      "Iteration 900, Loss: 0.0004947868292219937, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0005052197957411408, Min w: 3.708229351432864e-15\n",
      "Iteration 920, Loss: 0.0005019859527237713, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005116089596413076, Min w: 0.0\n",
      "Iteration 940, Loss: 0.000493941770400852, Min w: 4.670170361542603e-10\n",
      "Iteration 950, Loss: 0.0005000040400773287, Min w: 2.3922671261691803e-31\n",
      "Iteration 960, Loss: 0.0004948966670781374, Min w: 2.822006137884886e-13\n",
      "Iteration 970, Loss: 0.0004910564166493714, Min w: 1.0965458575873388e-11\n",
      "Iteration 980, Loss: 0.00047427797107957304, Min w: 0.0010375570273026824\n",
      "Iteration 990, Loss: 0.000496292079333216, Min w: 2.2291965606768827e-08\n",
      "Iteration 1000, Loss: 0.0004985685227438807, Min w: 4.904760278479081e-11\n",
      "Iteration 1010, Loss: 0.0004750603111460805, Min w: 1.3247455292187523e-40\n",
      "Iteration 1020, Loss: 0.0004948131972923875, Min w: 1.015470616039238e-06\n",
      "Iteration 1030, Loss: 0.0004951217561028898, Min w: 2.6637226255843416e-06\n",
      "Iteration 1040, Loss: 0.0004962653620168567, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0005116670508868992, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0004965554107911885, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0004982047248631716, Min w: 4.198506016497588e-26\n",
      "Iteration 1080, Loss: 0.00047966159763745964, Min w: 1.6061983512124069e-21\n",
      "Iteration 1090, Loss: 0.0004991584573872387, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.000513558741658926, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0005043432465754449, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0005218640435487032, Min w: 2.382207389352189e-44\n",
      "Iteration 1130, Loss: 0.0004943248932249844, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0004940993967466056, Min w: 6.11503367053956e-07\n",
      "Iteration 1150, Loss: 0.0005144248134456575, Min w: 1.3169009434932377e-05\n",
      "Iteration 1160, Loss: 0.0005079972906969488, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0004889459232799709, Min w: 0.0029417583718895912\n",
      "Iteration 1180, Loss: 0.0005009667947888374, Min w: 7.41516579829461e-25\n",
      "Iteration 1190, Loss: 0.0004883751389570534, Min w: 3.147068922734059e-14\n",
      "Iteration 1200, Loss: 0.0004623861750587821, Min w: 1.6327369186927039e-40\n",
      "Iteration 1210, Loss: 0.0004914698074571788, Min w: 0.0011860438389703631\n",
      "Iteration 1220, Loss: 0.0004961973754689097, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0005027183215133846, Min w: 8.1462002299304e-07\n",
      "Iteration 1240, Loss: 0.0005012251785956323, Min w: 1.4461400151832112e-42\n",
      "Iteration 0, Loss: 0.000497276138048619, Min w: 1.5414283107572988e-44\n",
      "Iteration 10, Loss: 0.0004961936501786113, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0004975269548594952, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0005055966903455555, Min w: 2.1734721225008055e-36\n",
      "Iteration 40, Loss: 0.0005143622402101755, Min w: 7.206575690774136e-24\n",
      "Iteration 50, Loss: 0.0005190171650610864, Min w: 0.0\n",
      "Iteration 60, Loss: 0.000537688028998673, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0004976639174856246, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0004967414424754679, Min w: 1.4195256815236553e-15\n",
      "Iteration 90, Loss: 0.0005017431103624403, Min w: 2.3239323481716984e-32\n",
      "Iteration 100, Loss: 0.0005221000174060464, Min w: 1.569154349603016e-26\n",
      "Iteration 110, Loss: 0.0005249895039014518, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005140407592989504, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0004987383144907653, Min w: 3.7742586300737457e-06\n",
      "Iteration 140, Loss: 0.0004928717971779406, Min w: 2.3619935745955445e-05\n",
      "Iteration 150, Loss: 0.000497901055496186, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0004978314973413944, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0004956091870553792, Min w: 6.444629583679561e-22\n",
      "Iteration 180, Loss: 0.00048270882689394057, Min w: 1.4847669262962881e-06\n",
      "Iteration 190, Loss: 0.0004927592817693949, Min w: 0.00010705446766223758\n",
      "Iteration 200, Loss: 0.0004927022382616997, Min w: 4.8177589633269235e-05\n",
      "Iteration 210, Loss: 0.0005008970620110631, Min w: 5.791806589883208e-09\n",
      "Iteration 220, Loss: 0.0004941198276355863, Min w: 1.0421114112705437e-14\n",
      "Iteration 230, Loss: 0.000496771652251482, Min w: 3.420150562760682e-08\n",
      "Iteration 240, Loss: 0.000496634456794709, Min w: 6.3895063249219675e-06\n",
      "Iteration 250, Loss: 0.0004948232090100646, Min w: 1.3856693511054272e-15\n",
      "Iteration 260, Loss: 0.00049357715761289, Min w: 1.5248428062754338e-13\n",
      "Iteration 270, Loss: 0.0004959774087183177, Min w: 6.991090445903964e-24\n",
      "Iteration 280, Loss: 0.0004947312409058213, Min w: 1.4767419058425713e-13\n",
      "Iteration 290, Loss: 0.0005015582428313792, Min w: 7.681034142059673e-10\n",
      "Iteration 300, Loss: 0.0005060326075181365, Min w: 2.5616815375524012e-27\n",
      "Iteration 310, Loss: 0.0005080797127448022, Min w: 3.0080304392317205e-27\n",
      "Iteration 320, Loss: 0.0004179484094493091, Min w: 6.635642873900388e-16\n",
      "Iteration 330, Loss: 0.0005042464472353458, Min w: 2.388021153033007e-21\n",
      "Iteration 340, Loss: 0.0005302445497363806, Min w: 1.4852967310867676e-15\n",
      "Iteration 350, Loss: 0.0004924757522530854, Min w: 3.487568567273058e-11\n",
      "Iteration 360, Loss: 0.0004855163861066103, Min w: 0.012227293103933334\n",
      "Iteration 370, Loss: 0.0004978567594662309, Min w: 1.598815697889666e-11\n",
      "Iteration 380, Loss: 0.000495274958666414, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005057264352217317, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0004927730769850314, Min w: 7.753524532955645e-41\n",
      "Iteration 410, Loss: 0.0004430510161910206, Min w: 0.00027755636256188154\n",
      "Iteration 420, Loss: 0.0004948546993546188, Min w: 7.193396811371044e-15\n",
      "Iteration 430, Loss: 0.0004952481831423938, Min w: 0.0004991706809960306\n",
      "Iteration 440, Loss: 0.0004958493518643081, Min w: 3.922979985304664e-08\n",
      "Iteration 450, Loss: 0.000511223915964365, Min w: 3.6416132325176013e-23\n",
      "Iteration 460, Loss: 0.0005234703421592712, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005042288103140891, Min w: 1.401298464324817e-45\n",
      "Iteration 480, Loss: 0.0005169195355847478, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0004951033624820411, Min w: 3.237707912899225e-30\n",
      "Iteration 500, Loss: 0.0004927092813886702, Min w: 6.550541494865572e-14\n",
      "Iteration 510, Loss: 0.0004885023226961493, Min w: 0.0060941604897379875\n",
      "Iteration 520, Loss: 0.0004925660323351622, Min w: 2.895246097978088e-06\n",
      "Iteration 530, Loss: 0.0004961813683621585, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0004966234555467963, Min w: 0.0\n",
      "Iteration 550, Loss: 0.000495306623633951, Min w: 4.189275991286409e-33\n",
      "Iteration 560, Loss: 0.0005030129104852676, Min w: 1.1760579501463881e-27\n",
      "Iteration 570, Loss: 0.0004952492890879512, Min w: 4.203895392974451e-45\n",
      "Iteration 580, Loss: 0.0004977033822797239, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005023275734856725, Min w: 1.1988896631009993e-07\n",
      "Iteration 600, Loss: 0.0003929404483642429, Min w: 7.684184623307277e-25\n",
      "Iteration 610, Loss: 0.0004834634892176837, Min w: 0.006315512582659721\n",
      "Iteration 620, Loss: 0.00042590111843310297, Min w: 0.07559771090745926\n",
      "Iteration 630, Loss: 0.0004903143853880465, Min w: 0.0005975938402116299\n",
      "Iteration 640, Loss: 0.0005018105730414391, Min w: 2.68787244616533e-16\n",
      "Iteration 650, Loss: 0.0005047825980000198, Min w: 1.9310891730128787e-07\n",
      "Iteration 660, Loss: 0.0005084474687464535, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0004960274673067033, Min w: 2.1397951059043407e-05\n",
      "Iteration 680, Loss: 0.00048419885570183396, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0004992898902855814, Min w: 5.229620084968474e-38\n",
      "Iteration 700, Loss: 0.0005120726418681443, Min w: 6.117382816029517e-30\n",
      "Iteration 710, Loss: 0.0004921153886243701, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0004968325374647975, Min w: 6.726232628759122e-44\n",
      "Iteration 730, Loss: 0.0005010024760849774, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0004929009010083973, Min w: 1.608736754921125e-10\n",
      "Iteration 750, Loss: 0.0004940680810250342, Min w: 1.2606870411600606e-34\n",
      "Iteration 760, Loss: 0.0004936135374009609, Min w: 3.640220043776412e-18\n",
      "Iteration 770, Loss: 0.0004951866576448083, Min w: 1.0567191719473446e-41\n",
      "Iteration 780, Loss: 0.0004945244872942567, Min w: 2.3415697338867693e-41\n",
      "Iteration 790, Loss: 0.0004886910901404917, Min w: 0.0032766477670520544\n",
      "Iteration 800, Loss: 0.00040744675789028406, Min w: 0.04011787101626396\n",
      "Iteration 810, Loss: 0.0004982598475180566, Min w: 3.355372739065702e-39\n",
      "Iteration 820, Loss: 0.0004782759351655841, Min w: 1.3982421478431206e-05\n",
      "Iteration 830, Loss: 0.0004970036679878831, Min w: 2.5750126055780263e-37\n",
      "Iteration 840, Loss: 0.0004974361509084702, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0004930802388116717, Min w: 0.0035361263435333967\n",
      "Iteration 860, Loss: 0.0004812151310034096, Min w: 0.0027607486117631197\n",
      "Iteration 870, Loss: 0.00048774154856801033, Min w: 1.0671822536778564e-07\n",
      "Iteration 880, Loss: 0.00046872388338670135, Min w: 0.04654964432120323\n",
      "Iteration 890, Loss: 0.000488798541482538, Min w: 8.509576376880545e-10\n",
      "Iteration 900, Loss: 0.0004949120339006186, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0004986310377717018, Min w: 2.1925879167827844e-10\n",
      "Iteration 920, Loss: 0.0004941076622344553, Min w: 0.0\n",
      "Iteration 930, Loss: 0.000497049477417022, Min w: 4.62192247641623e-31\n",
      "Iteration 940, Loss: 0.0005075112567283213, Min w: 6.991656081176757e-30\n",
      "Iteration 950, Loss: 0.0005260696052573621, Min w: 2.2562880966451234e-22\n",
      "Iteration 960, Loss: 0.0005023691337555647, Min w: 2.802596928649634e-45\n",
      "Iteration 970, Loss: 0.0004867236712016165, Min w: 0.002221914706751704\n",
      "Iteration 980, Loss: 0.00042418253724463284, Min w: 0.000603610766120255\n",
      "Iteration 990, Loss: 0.00046164554078131914, Min w: 0.001538831740617752\n",
      "Iteration 1000, Loss: 0.00047798777814023197, Min w: 2.850978125934489e-05\n",
      "Iteration 1010, Loss: 0.0004642983549274504, Min w: 0.00017027012654580176\n",
      "Iteration 1020, Loss: 0.0005036080838181078, Min w: 8.68169496624663e-30\n",
      "Iteration 1030, Loss: 0.0004975647898390889, Min w: 1.5023186438537252e-29\n",
      "Iteration 1040, Loss: 0.0004951287992298603, Min w: 4.006612416917385e-17\n",
      "Iteration 1050, Loss: 0.00048613164108246565, Min w: 0.0017628027126193047\n",
      "Iteration 1060, Loss: 0.0005025422433391213, Min w: 2.7795512733284903e-22\n",
      "Iteration 1070, Loss: 0.000501321570482105, Min w: 1.2018376409128226e-40\n",
      "Iteration 1080, Loss: 0.000494195322971791, Min w: 1.2893014839465571e-23\n",
      "Iteration 1090, Loss: 0.0005019944510422647, Min w: 1.263402387192712e-34\n",
      "Iteration 1100, Loss: 0.0005071119521744549, Min w: 6.906834485214642e-28\n",
      "Iteration 1110, Loss: 0.000524025468621403, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.000492193503305316, Min w: 0.00028251507319509983\n",
      "Iteration 1130, Loss: 0.00048671505646780133, Min w: 3.047367442832183e-07\n",
      "Iteration 1140, Loss: 0.0004975912743248045, Min w: 3.886506405509026e-28\n",
      "Iteration 1150, Loss: 0.0004958543577231467, Min w: 1.2664938271299969e-14\n",
      "Iteration 1160, Loss: 0.0004954239120706916, Min w: 6.879811661770346e-14\n",
      "Iteration 1170, Loss: 0.0005024918937124312, Min w: 1.1813453966169618e-05\n",
      "Iteration 1180, Loss: 0.0004750837979372591, Min w: 8.413164054310585e-10\n",
      "Iteration 1190, Loss: 0.0004926045658066869, Min w: 6.976215161103028e-08\n",
      "Iteration 1200, Loss: 0.0004966446431353688, Min w: 0.0014181493315845728\n",
      "Iteration 1210, Loss: 0.000495443819090724, Min w: 7.961877190909597e-23\n",
      "Iteration 1220, Loss: 0.0004982120590284467, Min w: 3.1231046637714144e-09\n",
      "Iteration 1230, Loss: 0.000505023926962167, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0004961761878803372, Min w: 7.545770119854467e-10\n",
      "Iteration 0, Loss: 0.0004959508660249412, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0005098797264508903, Min w: 1.8005853830867382e-30\n",
      "Iteration 20, Loss: 0.0005018903757445514, Min w: 4.697609266281494e-31\n",
      "Iteration 30, Loss: 0.0005051668267697096, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005116407992318273, Min w: 1.2011493552291636e-19\n",
      "Iteration 50, Loss: 0.0005000642850063741, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0004945924156345427, Min w: 3.24497269332813e-11\n",
      "Iteration 70, Loss: 0.00048005275311879814, Min w: 1.0722460740517108e-30\n",
      "Iteration 80, Loss: 0.0004919422208331525, Min w: 1.3405933704986345e-14\n",
      "Iteration 90, Loss: 0.0004459263291209936, Min w: 0.01107880100607872\n",
      "Iteration 100, Loss: 0.0003811985079664737, Min w: 0.20103400945663452\n",
      "Iteration 110, Loss: 0.00047406466910615563, Min w: 0.006124086212366819\n",
      "Iteration 120, Loss: 0.0004720379947684705, Min w: 0.02812732756137848\n",
      "Iteration 130, Loss: 0.00045843745465390384, Min w: 0.02216191589832306\n",
      "Iteration 140, Loss: 0.0003171216230839491, Min w: 0.24269628524780273\n",
      "Iteration 150, Loss: 0.0004987668944522738, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005017670919187367, Min w: 3.838487916429348e-28\n",
      "Iteration 170, Loss: 0.0004738115530926734, Min w: 7.315367111004889e-05\n",
      "Iteration 180, Loss: 0.00048388290451839566, Min w: 7.89907862781547e-05\n",
      "Iteration 190, Loss: 0.000490592559799552, Min w: 0.010082482360303402\n",
      "Iteration 200, Loss: 0.0004921600339002907, Min w: 9.595376013749046e-07\n",
      "Iteration 210, Loss: 0.0004960003425367177, Min w: 1.2318506769285286e-25\n",
      "Iteration 220, Loss: 0.0005068843020126224, Min w: 9.628454942131164e-34\n",
      "Iteration 230, Loss: 0.0005060368566773832, Min w: 3.9751901415522106e-17\n",
      "Iteration 240, Loss: 0.0005046207807026803, Min w: 5.268866988109728e-23\n",
      "Iteration 250, Loss: 0.0005046733422204852, Min w: 3.146005815231728e-22\n",
      "Iteration 260, Loss: 0.0005098299006931484, Min w: 5.824398412836077e-20\n",
      "Iteration 270, Loss: 0.0005094886291772127, Min w: 2.9722314650748474e-16\n",
      "Iteration 280, Loss: 0.0004938350757583976, Min w: 5.4830368352236884e-17\n",
      "Iteration 290, Loss: 0.0005043167620897293, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004998869844712317, Min w: 5.222190822050072e-28\n",
      "Iteration 310, Loss: 0.00047002435894683003, Min w: 0.0\n",
      "Iteration 320, Loss: 0.00045641802717000246, Min w: 3.308102236587729e-08\n",
      "Iteration 330, Loss: 0.0004855621955357492, Min w: 0.0038709882646799088\n",
      "Iteration 340, Loss: 0.0005026232684031129, Min w: 1.981439909978173e-20\n",
      "Iteration 350, Loss: 0.0004999375087209046, Min w: 2.8947072516771755e-10\n",
      "Iteration 360, Loss: 0.0005108813056722283, Min w: 4.612073778442749e-10\n",
      "Iteration 370, Loss: 0.0005029582534916699, Min w: 1.0230352746778278e-22\n",
      "Iteration 380, Loss: 0.0005086573655717075, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005157812847755849, Min w: 3.7601288691551347e-19\n",
      "Iteration 400, Loss: 0.000495049636811018, Min w: 3.7057301949853332e-28\n",
      "Iteration 410, Loss: 0.0004921485087834299, Min w: 1.1601941629635348e-09\n",
      "Iteration 420, Loss: 0.0004990652669221163, Min w: 5.409555524238385e-05\n",
      "Iteration 430, Loss: 0.0004986391286365688, Min w: 1.910256742121419e-06\n",
      "Iteration 440, Loss: 0.00046067629591561854, Min w: 0.043675754219293594\n",
      "Iteration 450, Loss: 0.0004425670194905251, Min w: 0.017401954159140587\n",
      "Iteration 460, Loss: 0.0004910972202196717, Min w: 3.102057462456287e-06\n",
      "Iteration 470, Loss: 0.0004974303883500397, Min w: 1.0558641026600072e-30\n",
      "Iteration 480, Loss: 0.0004949530120939016, Min w: 6.549932466365488e-39\n",
      "Iteration 490, Loss: 0.0005010386812500656, Min w: 5.395497282734141e-06\n",
      "Iteration 500, Loss: 0.0004653925425373018, Min w: 0.011370209977030754\n",
      "Iteration 510, Loss: 0.0004921664949506521, Min w: 0.00044583724229596555\n",
      "Iteration 520, Loss: 0.00034612268791534007, Min w: 2.5890931283356622e-05\n",
      "Iteration 530, Loss: 0.000495807034894824, Min w: 7.662106192574125e-12\n",
      "Iteration 540, Loss: 0.0005096924141980708, Min w: 2.6664410480739454e-35\n",
      "Iteration 550, Loss: 0.0004975225310772657, Min w: 4.7336998768856383e-29\n",
      "Iteration 560, Loss: 0.0005043902201578021, Min w: 1.7865179821607846e-12\n",
      "Iteration 570, Loss: 0.0004386698710732162, Min w: 0.0449954979121685\n",
      "Iteration 580, Loss: 0.0004907256807200611, Min w: 0.0032588595058768988\n",
      "Iteration 590, Loss: 0.0004296490806154907, Min w: 0.027823809534311295\n",
      "Iteration 600, Loss: 0.0004852274723816663, Min w: 1.6292631688230585e-09\n",
      "Iteration 610, Loss: 0.0005036212969571352, Min w: 2.3772990520587456e-11\n",
      "Iteration 620, Loss: 0.0004954045289196074, Min w: 4.409386918091673e-12\n",
      "Iteration 630, Loss: 0.0005037442315369844, Min w: 6.222959157575232e-18\n",
      "Iteration 640, Loss: 0.000500800902955234, Min w: 0.0\n",
      "Iteration 650, Loss: 0.000509483041241765, Min w: 7.698325941109495e-25\n",
      "Iteration 660, Loss: 0.0004765517369378358, Min w: 4.248886887151932e-19\n",
      "Iteration 670, Loss: 0.0004705564642790705, Min w: 2.0846126908002915e-11\n",
      "Iteration 680, Loss: 0.00036033563083037734, Min w: 0.16866034269332886\n",
      "Iteration 690, Loss: 0.00035415077582001686, Min w: 0.1848008781671524\n",
      "Iteration 700, Loss: 0.00042731399298645556, Min w: 0.09971446543931961\n",
      "Iteration 710, Loss: 0.000487367418827489, Min w: 0.0009359683026559651\n",
      "Iteration 720, Loss: 0.0004490172432269901, Min w: 0.0007936486508697271\n",
      "Iteration 730, Loss: 0.00042794557521119714, Min w: 0.0051648556254804134\n",
      "Iteration 740, Loss: 0.0004955981275998056, Min w: 2.153135574189946e-05\n",
      "Iteration 750, Loss: 0.0004974835901521146, Min w: 2.9925355239385485e-26\n",
      "Iteration 760, Loss: 0.0004971236921846867, Min w: 3.0660531891157916e-09\n",
      "Iteration 770, Loss: 0.0004985628766007721, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0004936933401040733, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0004973227623850107, Min w: 2.7511690842141334e-11\n",
      "Iteration 800, Loss: 0.0004875985032413155, Min w: 0.021178465336561203\n",
      "Iteration 810, Loss: 0.0004521210794337094, Min w: 0.008583073504269123\n",
      "Iteration 820, Loss: 0.0004615832294803113, Min w: 0.0001347189099760726\n",
      "Iteration 830, Loss: 0.00048501824494451284, Min w: 0.002367163309827447\n",
      "Iteration 840, Loss: 0.0004884109366685152, Min w: 2.0413183008918318e-16\n",
      "Iteration 850, Loss: 0.0005028656451031566, Min w: 1.0357407292937992e-10\n",
      "Iteration 860, Loss: 0.0005012703477405012, Min w: 1.401298464324817e-45\n",
      "Iteration 870, Loss: 0.0004911708529107273, Min w: 0.0004935478791594505\n",
      "Iteration 880, Loss: 0.0004932335577905178, Min w: 0.0\n",
      "Iteration 890, Loss: 0.00047707086196169257, Min w: 6.896656486787833e-06\n",
      "Iteration 900, Loss: 0.0004962255479767919, Min w: 1.2746193562903645e-18\n",
      "Iteration 910, Loss: 0.0004979204968549311, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0005059639224782586, Min w: 5.8068030533608526e-21\n",
      "Iteration 930, Loss: 0.0005075740627944469, Min w: 4.189275991286409e-33\n",
      "Iteration 940, Loss: 0.000500328082125634, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0005103432922624052, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0004977222997695208, Min w: 1.1062014544666585e-17\n",
      "Iteration 970, Loss: 0.00048781069926917553, Min w: 0.0087056215852499\n",
      "Iteration 980, Loss: 0.0003785395820159465, Min w: 0.0790640115737915\n",
      "Iteration 990, Loss: 0.0004946704139001667, Min w: 4.478189007180807e-36\n",
      "Iteration 1000, Loss: 0.00047292024828493595, Min w: 0.005468128249049187\n",
      "Iteration 1010, Loss: 0.00043637410271912813, Min w: 0.0001773917902028188\n",
      "Iteration 1020, Loss: 0.0004678629629779607, Min w: 4.078096260076916e-26\n",
      "Iteration 1030, Loss: 0.0005028725718148053, Min w: 0.00014585713506676257\n",
      "Iteration 1040, Loss: 0.0005052059423178434, Min w: 1.2441836955317966e-29\n",
      "Iteration 1050, Loss: 0.000506000651512295, Min w: 4.2230539269542955e-13\n",
      "Iteration 1060, Loss: 0.0004965610569342971, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0004950486472807825, Min w: 5.058796249645096e-29\n",
      "Iteration 1080, Loss: 0.0005026722210459411, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0005067253368906677, Min w: 2.068325378245352e-20\n",
      "Iteration 1100, Loss: 0.0004944305401295424, Min w: 9.927274732035585e-06\n",
      "Iteration 1110, Loss: 0.00048131431685760617, Min w: 0.008611220866441727\n",
      "Iteration 1120, Loss: 0.0004921412328258157, Min w: 0.0005144032766111195\n",
      "Iteration 1130, Loss: 0.0003212248848285526, Min w: 0.2525498569011688\n",
      "Iteration 1140, Loss: 0.0004882166103925556, Min w: 0.009997887536883354\n",
      "Iteration 1150, Loss: 0.00047225927119143307, Min w: 1.2038080967613496e-05\n",
      "Iteration 1160, Loss: 0.000493717729113996, Min w: 2.78520513448322e-17\n",
      "Iteration 1170, Loss: 0.0005048297462053597, Min w: 2.0687466305403897e-32\n",
      "Iteration 1180, Loss: 0.0005035476060584188, Min w: 3.8249973499659973e-07\n",
      "Iteration 1190, Loss: 0.0004994512419216335, Min w: 5.274488046325132e-08\n",
      "Iteration 1200, Loss: 0.0004950374714098871, Min w: 1.2557948139146902e-06\n",
      "Iteration 1210, Loss: 0.000493100262247026, Min w: 2.5090337388136484e-25\n",
      "Iteration 1220, Loss: 0.0004989675944671035, Min w: 6.267553705168885e-19\n",
      "Iteration 1230, Loss: 0.0005016470095142722, Min w: 8.251665462033486e-10\n",
      "Iteration 1240, Loss: 0.0005050959880463779, Min w: 2.032930768169905e-11\n",
      "Iteration 0, Loss: 0.0004958576173521578, Min w: 9.356462420172073e-18\n",
      "Iteration 10, Loss: 0.0005002826801501215, Min w: 0.0\n",
      "Iteration 20, Loss: 0.00041285812039859593, Min w: 3.0251301934289514e-27\n",
      "Iteration 30, Loss: 0.0005033163470216095, Min w: 1.8803418566117058e-13\n",
      "Iteration 40, Loss: 0.0004938777419738472, Min w: 1.6417612808029557e-41\n",
      "Iteration 50, Loss: 0.0004962404491379857, Min w: 1.037478524657214e-29\n",
      "Iteration 60, Loss: 0.0004958674544468522, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0004958451609127223, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0004996589850634336, Min w: 4.246088152568632e-17\n",
      "Iteration 90, Loss: 0.00050110905431211, Min w: 4.3324979288545255e-23\n",
      "Iteration 100, Loss: 0.000496123218908906, Min w: 5.616630207802564e-13\n",
      "Iteration 110, Loss: 0.0005056858062744141, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005038233357481658, Min w: 8.701522835607989e-11\n",
      "Iteration 130, Loss: 0.0005084201111458242, Min w: 3.20790523766396e-24\n",
      "Iteration 140, Loss: 0.0005093001527711749, Min w: 3.739793631024613e-12\n",
      "Iteration 150, Loss: 0.0005024507408961654, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005079725524410605, Min w: 1.385860031177799e-07\n",
      "Iteration 170, Loss: 0.0004963831743225455, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0004922469379380345, Min w: 7.260549050869258e-09\n",
      "Iteration 190, Loss: 0.00046970153925940394, Min w: 0.015073277987539768\n",
      "Iteration 200, Loss: 0.00041716397390700877, Min w: 0.0011045073624700308\n",
      "Iteration 210, Loss: 0.00039530100184492767, Min w: 0.1313750147819519\n",
      "Iteration 220, Loss: 0.00033806273131631315, Min w: 0.2675460875034332\n",
      "Iteration 230, Loss: 0.00041695492109283805, Min w: 0.028961053118109703\n",
      "Iteration 240, Loss: 0.0003700691449921578, Min w: 0.14565113186836243\n",
      "Iteration 250, Loss: 0.0002595934784039855, Min w: 0.4485113322734833\n",
      "Iteration 260, Loss: 0.0004890402778983116, Min w: 0.009095431305468082\n",
      "Iteration 270, Loss: 0.0004999845987185836, Min w: 4.540078979431428e-09\n",
      "Iteration 280, Loss: 0.0004997664946131408, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0004815539577975869, Min w: 1.071774693680569e-17\n",
      "Iteration 300, Loss: 0.00046398284030146897, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005036630318500102, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005091712810099125, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0004917279584333301, Min w: 1.401298464324817e-45\n",
      "Iteration 340, Loss: 0.000429630686994642, Min w: 0.12204095721244812\n",
      "Iteration 350, Loss: 0.00046123593347147107, Min w: 0.003306560218334198\n",
      "Iteration 360, Loss: 0.00037334172520786524, Min w: 0.14059247076511383\n",
      "Iteration 370, Loss: 0.00047600865946151316, Min w: 0.028015218675136566\n",
      "Iteration 380, Loss: 0.0004785591154359281, Min w: 0.004811445716768503\n",
      "Iteration 390, Loss: 0.00046840778668411076, Min w: 0.0014978356193751097\n",
      "Iteration 400, Loss: 0.0004991474561393261, Min w: 1.3745573596679606e-05\n",
      "Iteration 410, Loss: 0.00050083186943084, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005032632034271955, Min w: 4.0644942148446606e-17\n",
      "Iteration 430, Loss: 0.00043702570837922394, Min w: 0.09026554226875305\n",
      "Iteration 440, Loss: 0.00038511352613568306, Min w: 0.0031571933068335056\n",
      "Iteration 450, Loss: 0.0004911992000415921, Min w: 3.4381555451545864e-05\n",
      "Iteration 460, Loss: 0.0005019294330850244, Min w: 9.542768797388135e-10\n",
      "Iteration 470, Loss: 0.0004960758960805833, Min w: 9.346559084970022e-30\n",
      "Iteration 480, Loss: 0.0004979828954674304, Min w: 4.780695599038154e-05\n",
      "Iteration 490, Loss: 0.0004991116584278643, Min w: 4.064199738546592e-17\n",
      "Iteration 500, Loss: 0.000504138704854995, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0004967956920154393, Min w: 1.3052549415339704e-17\n",
      "Iteration 520, Loss: 0.00043834903044626117, Min w: 0.00016282701108139008\n",
      "Iteration 530, Loss: 0.0004908397677354515, Min w: 1.1651656818795928e-21\n",
      "Iteration 540, Loss: 0.0004924180102534592, Min w: 4.086509353129486e-09\n",
      "Iteration 550, Loss: 0.000492517021484673, Min w: 1.3865276571323193e-07\n",
      "Iteration 560, Loss: 0.0005001628305763006, Min w: 1.7679902680756143e-11\n",
      "Iteration 570, Loss: 0.0004898112965747714, Min w: 0.00013202076661400497\n",
      "Iteration 580, Loss: 0.0004832198901567608, Min w: 6.076243952435334e-10\n",
      "Iteration 590, Loss: 0.0005005237180739641, Min w: 3.777677797311941e-37\n",
      "Iteration 600, Loss: 0.0005036648362874985, Min w: 1.7238024341281744e-08\n",
      "Iteration 610, Loss: 0.0005027793813496828, Min w: 2.6612330117359306e-09\n",
      "Iteration 620, Loss: 0.0004962368402630091, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0004975776537321508, Min w: 2.2695673465578103e-12\n",
      "Iteration 640, Loss: 0.0005070224869996309, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0005016133072786033, Min w: 6.162676591259242e-09\n",
      "Iteration 660, Loss: 0.0004965944681316614, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0004940839135088027, Min w: 7.250552561772691e-14\n",
      "Iteration 680, Loss: 0.0004952833405695856, Min w: 2.9744071095016977e-10\n",
      "Iteration 690, Loss: 0.0004938439815305173, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0004954042960889637, Min w: 1.9073150041103812e-34\n",
      "Iteration 710, Loss: 0.0005042922566644847, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0005212127580307424, Min w: 2.1167658283745977e-15\n",
      "Iteration 730, Loss: 0.0004986303974874318, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0004936824552714825, Min w: 1.7795120635985523e-16\n",
      "Iteration 750, Loss: 0.0004995004273951054, Min w: 1.2204667655169033e-05\n",
      "Iteration 760, Loss: 0.000496322347316891, Min w: 1.7551259585773214e-14\n",
      "Iteration 770, Loss: 0.000495489570312202, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0004961739759892225, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0004951293230988085, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0004995671915821731, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005074089858680964, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0004979601944796741, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0005101146525703371, Min w: 3.8101013899449754e-08\n",
      "Iteration 840, Loss: 0.000493291299790144, Min w: 5.994639314359846e-25\n",
      "Iteration 850, Loss: 0.0004704669117927551, Min w: 3.4874461306641296e-20\n",
      "Iteration 860, Loss: 0.0004147844447288662, Min w: 1.469355818760035e-20\n",
      "Iteration 870, Loss: 0.0004837453889194876, Min w: 1.432791485456164e-08\n",
      "Iteration 880, Loss: 0.0004920639330521226, Min w: 2.0344133888909773e-14\n",
      "Iteration 890, Loss: 0.0004942735540680587, Min w: 7.203407551423058e-26\n",
      "Iteration 900, Loss: 0.0005017915391363204, Min w: 5.2168411805535086e-18\n",
      "Iteration 910, Loss: 0.0004959863726980984, Min w: 1.6919313566177152e-05\n",
      "Iteration 920, Loss: 0.0005034980713389814, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0004996905918233097, Min w: 2.5360461222589947e-05\n",
      "Iteration 940, Loss: 0.0004989219596609473, Min w: 1.2611686178923354e-44\n",
      "Iteration 950, Loss: 0.0004916631150990725, Min w: 7.363636037544609e-33\n",
      "Iteration 960, Loss: 0.0004937765770591795, Min w: 4.491417726626423e-08\n",
      "Iteration 970, Loss: 0.0004932792508043349, Min w: 5.580851061772092e-15\n",
      "Iteration 980, Loss: 0.0004966529668308794, Min w: 2.133277226903883e-16\n",
      "Iteration 990, Loss: 0.000493551604449749, Min w: 1.2421676380845431e-30\n",
      "Iteration 1000, Loss: 0.0004936654004268348, Min w: 5.620904297565232e-10\n",
      "Iteration 1010, Loss: 0.0004986347048543394, Min w: 5.671545832547947e-31\n",
      "Iteration 1020, Loss: 0.0004940878716297448, Min w: 2.7086911734223163e-34\n",
      "Iteration 1030, Loss: 0.0004999750526621938, Min w: 1.1515884410871368e-18\n",
      "Iteration 1040, Loss: 0.0004243279399815947, Min w: 0.0001481436047470197\n",
      "Iteration 1050, Loss: 0.0004523689567577094, Min w: 0.009530420415103436\n",
      "Iteration 1060, Loss: 0.000430907093686983, Min w: 3.548649374351953e-06\n",
      "Iteration 1070, Loss: 0.0004925206303596497, Min w: 2.2716368164310552e-07\n",
      "Iteration 1080, Loss: 0.0004937597550451756, Min w: 4.627964234060755e-09\n",
      "Iteration 1090, Loss: 0.0004991361638531089, Min w: 1.3614677961404364e-11\n",
      "Iteration 1100, Loss: 0.0005071645718999207, Min w: 9.806475669588001e-30\n",
      "Iteration 1110, Loss: 0.0005127180484123528, Min w: 2.1297641081177457e-24\n",
      "Iteration 1120, Loss: 0.0004997460637241602, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0004956532502546906, Min w: 2.1975772785880023e-26\n",
      "Iteration 1140, Loss: 0.0004988553118892014, Min w: 1.4159521808092962e-13\n",
      "Iteration 1150, Loss: 0.00039088117773644626, Min w: 0.00028535447199828923\n",
      "Iteration 1160, Loss: 0.000381889141863212, Min w: 0.17207613587379456\n",
      "Iteration 1170, Loss: 0.00047870102571323514, Min w: 2.7729370882800808e-11\n",
      "Iteration 1180, Loss: 0.00046217633644118905, Min w: 0.00020637728448491544\n",
      "Iteration 1190, Loss: 0.0004925935063511133, Min w: 5.100947601022199e-05\n",
      "Iteration 1200, Loss: 0.0005001228419132531, Min w: 5.329037925579617e-25\n",
      "Iteration 1210, Loss: 0.0004941999795846641, Min w: 1.783369008023783e-08\n",
      "Iteration 1220, Loss: 0.0005022943951189518, Min w: 2.1483498929118823e-26\n",
      "Iteration 1230, Loss: 0.0005017879302613437, Min w: 7.234123849540926e-15\n",
      "Iteration 1240, Loss: 0.0005058754468336701, Min w: 1.0563451155465309e-12\n",
      "Iteration 0, Loss: 0.0005022645345889032, Min w: 3.772005811697454e-06\n",
      "Iteration 10, Loss: 0.0004272488004062325, Min w: 1.404658718229257e-07\n",
      "Iteration 20, Loss: 0.0004728657950181514, Min w: 0.0040632616728544235\n",
      "Iteration 30, Loss: 0.0004215071676298976, Min w: 0.006203819997608662\n",
      "Iteration 40, Loss: 0.0004432229034136981, Min w: 5.2603802032535896e-05\n",
      "Iteration 50, Loss: 0.0004987523425370455, Min w: 9.047692937426646e-17\n",
      "Iteration 60, Loss: 0.0004282332956790924, Min w: 0.028669161722064018\n",
      "Iteration 70, Loss: 0.0004943932290188968, Min w: 8.601243693535338e-34\n",
      "Iteration 80, Loss: 0.0004976894124411047, Min w: 4.46091107733082e-05\n",
      "Iteration 90, Loss: 0.0004101002705283463, Min w: 0.019478343427181244\n",
      "Iteration 100, Loss: 0.0004963228129781783, Min w: 1.884764319721729e-18\n",
      "Iteration 110, Loss: 0.0004876701277680695, Min w: 2.27643727157556e-06\n",
      "Iteration 120, Loss: 0.0004946515546180308, Min w: 1.6047112640429906e-12\n",
      "Iteration 130, Loss: 0.0004972717142663896, Min w: 8.665010731046544e-17\n",
      "Iteration 140, Loss: 0.000503180839587003, Min w: 5.590049568127142e-06\n",
      "Iteration 150, Loss: 0.0005001691170036793, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005037341616116464, Min w: 1.6364083206692349e-40\n",
      "Iteration 170, Loss: 0.000486708217067644, Min w: 2.8741577839698358e-22\n",
      "Iteration 180, Loss: 0.0004843300557695329, Min w: 0.021429847925901413\n",
      "Iteration 190, Loss: 0.000492967024911195, Min w: 4.580085755101493e-10\n",
      "Iteration 200, Loss: 0.0004959639627486467, Min w: 0.0012694115284830332\n",
      "Iteration 210, Loss: 0.0004900681669823825, Min w: 1.4018229910206514e-09\n",
      "Iteration 220, Loss: 0.0004938427009619772, Min w: 6.316297262998205e-09\n",
      "Iteration 230, Loss: 0.0004914234159514308, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004987966967746615, Min w: 4.936342179462372e-07\n",
      "Iteration 250, Loss: 0.0005076989764347672, Min w: 4.478051334214569e-29\n",
      "Iteration 260, Loss: 0.000499443500302732, Min w: 1.3994053915666882e-07\n",
      "Iteration 270, Loss: 0.0005005105049349368, Min w: 2.692798736847002e-16\n",
      "Iteration 280, Loss: 0.0004967726417817175, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005023640114814043, Min w: 4.105804500471714e-43\n",
      "Iteration 300, Loss: 0.0004937724443152547, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0004951904411427677, Min w: 1.6586542924852056e-18\n",
      "Iteration 320, Loss: 0.0004988822038285434, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005144439055584371, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0005071747582405806, Min w: 6.974378106289203e-12\n",
      "Iteration 350, Loss: 0.0004927309928461909, Min w: 4.170537613173986e-12\n",
      "Iteration 360, Loss: 0.0004932330921292305, Min w: 1.1503958914892967e-15\n",
      "Iteration 370, Loss: 0.000493162136990577, Min w: 3.8615608649074373e-13\n",
      "Iteration 380, Loss: 0.0004960945807397366, Min w: 2.5548834159394573e-09\n",
      "Iteration 390, Loss: 0.0004936033510603011, Min w: 0.0\n",
      "Iteration 400, Loss: 0.000495736429002136, Min w: 4.8757971882196216e-08\n",
      "Iteration 410, Loss: 0.0005013631889596581, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005018737865611911, Min w: 1.5825407760523721e-27\n",
      "Iteration 430, Loss: 0.0005052989581599832, Min w: 7.852736464229842e-40\n",
      "Iteration 440, Loss: 0.0004940989310853183, Min w: 7.904744728709871e-22\n",
      "Iteration 450, Loss: 0.00048768724082037807, Min w: 3.3799609703948075e-13\n",
      "Iteration 460, Loss: 0.0004919004277326167, Min w: 1.0449567883780516e-23\n",
      "Iteration 470, Loss: 0.0004945413675159216, Min w: 6.692115177980851e-12\n",
      "Iteration 480, Loss: 0.000500800262670964, Min w: 1.279294030363739e-28\n",
      "Iteration 490, Loss: 0.000505608506500721, Min w: 4.044772572431299e-10\n",
      "Iteration 500, Loss: 0.0004993241163901985, Min w: 1.2274661286567056e-38\n",
      "Iteration 510, Loss: 0.0005107907927595079, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0004998098593205214, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0005131560610607266, Min w: 1.5456322061502732e-42\n",
      "Iteration 540, Loss: 0.0004960550577379763, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0004977536736987531, Min w: 8.951603891387149e-39\n",
      "Iteration 560, Loss: 0.0005071276682429016, Min w: 4.7390095320176684e-11\n",
      "Iteration 570, Loss: 0.0004987717256881297, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0004765294142998755, Min w: 6.487010484335087e-09\n",
      "Iteration 590, Loss: 0.0004057641781400889, Min w: 0.06558547914028168\n",
      "Iteration 600, Loss: 0.0004368439258541912, Min w: 1.9084335010194874e-14\n",
      "Iteration 610, Loss: 0.0004812546831090003, Min w: 2.8831594047618313e-24\n",
      "Iteration 620, Loss: 0.0004948051646351814, Min w: 1.5670555131297448e-10\n",
      "Iteration 630, Loss: 0.000496160238981247, Min w: 1.2645157273713514e-12\n",
      "Iteration 640, Loss: 0.0004889345145784318, Min w: 0.001333775813691318\n",
      "Iteration 650, Loss: 0.00044921337394043803, Min w: 0.036471642553806305\n",
      "Iteration 660, Loss: 0.0003502880281303078, Min w: 0.11863084882497787\n",
      "Iteration 670, Loss: 0.0004540627123787999, Min w: 0.010097132995724678\n",
      "Iteration 680, Loss: 0.0004909020499326289, Min w: 0.004009796306490898\n",
      "Iteration 690, Loss: 0.0005010785534977913, Min w: 1.3889762736106264e-16\n",
      "Iteration 700, Loss: 0.0005018305382691324, Min w: 5.101530753393035e-09\n",
      "Iteration 710, Loss: 0.0005074107320979238, Min w: 2.1799000875339646e-20\n",
      "Iteration 720, Loss: 0.0004985305713489652, Min w: 2.635923187591285e-17\n",
      "Iteration 730, Loss: 0.0005057443049736321, Min w: 2.3014272779176004e-13\n",
      "Iteration 740, Loss: 0.0004959700745530427, Min w: 1.977992397549107e-24\n",
      "Iteration 750, Loss: 0.0005029450403526425, Min w: 8.654994776424729e-11\n",
      "Iteration 760, Loss: 0.0004939702921546996, Min w: 2.6694668543258797e-14\n",
      "Iteration 770, Loss: 0.0005015485221520066, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0004954717005603015, Min w: 5.688126429289134e-14\n",
      "Iteration 790, Loss: 0.0004747086204588413, Min w: 6.964948170207208e-06\n",
      "Iteration 800, Loss: 0.0004752988461405039, Min w: 0.01916337013244629\n",
      "Iteration 810, Loss: 0.0003096963919233531, Min w: 0.16134744882583618\n",
      "Iteration 820, Loss: 0.0004906792310066521, Min w: 6.0381933827957646e-12\n",
      "Iteration 830, Loss: 0.0004747993953060359, Min w: 0.0005652400432154536\n",
      "Iteration 840, Loss: 0.0004127426363993436, Min w: 0.009966871701180935\n",
      "Iteration 850, Loss: 0.0003532735863700509, Min w: 1.0072567420138512e-06\n",
      "Iteration 860, Loss: 0.00048791628796607256, Min w: 0.008278783410787582\n",
      "Iteration 870, Loss: 0.0004919981583952904, Min w: 6.95345864221153e-12\n",
      "Iteration 880, Loss: 0.0004888752591796219, Min w: 0.0028045838698744774\n",
      "Iteration 890, Loss: 0.0004927690606564283, Min w: 0.0008861426613293588\n",
      "Iteration 900, Loss: 0.0004969954025000334, Min w: 2.190838775653154e-19\n",
      "Iteration 910, Loss: 0.0004909395356662571, Min w: 0.00020701991161331534\n",
      "Iteration 920, Loss: 0.0004920391365885735, Min w: 7.37664936120129e-19\n",
      "Iteration 930, Loss: 0.0004915904719382524, Min w: 1.9410930446899055e-20\n",
      "Iteration 940, Loss: 0.0004945147084072232, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0004996010684408247, Min w: 2.3109782316954597e-12\n",
      "Iteration 960, Loss: 0.000490984006319195, Min w: 1.8936310297590353e-08\n",
      "Iteration 970, Loss: 0.0004738675197586417, Min w: 1.778348005668225e-20\n",
      "Iteration 980, Loss: 0.0004977865610271692, Min w: 1.985919650948631e-09\n",
      "Iteration 990, Loss: 0.0005026966100558639, Min w: 9.995509872269895e-14\n",
      "Iteration 1000, Loss: 0.0004962883540429175, Min w: 3.4094185252797615e-07\n",
      "Iteration 1010, Loss: 0.0004961547674611211, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0005038247909396887, Min w: 6.565662566897789e-18\n",
      "Iteration 1030, Loss: 0.0004902748041786253, Min w: 0.0003297824296168983\n",
      "Iteration 1040, Loss: 0.0004918940248899162, Min w: 1.8435043769304826e-10\n",
      "Iteration 1050, Loss: 0.0004929032293148339, Min w: 5.038759665586257e-13\n",
      "Iteration 1060, Loss: 0.0004779001174028963, Min w: 1.0622760763974149e-29\n",
      "Iteration 1070, Loss: 0.0004979828954674304, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0004835540021304041, Min w: 1.0172206599012065e-16\n",
      "Iteration 1090, Loss: 0.0004919563070870936, Min w: 2.912274304077901e-17\n",
      "Iteration 1100, Loss: 0.000499713234603405, Min w: 7.656718751321463e-15\n",
      "Iteration 1110, Loss: 0.0004927738336846232, Min w: 3.0113689319932746e-10\n",
      "Iteration 1120, Loss: 0.0004925847752019763, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.00043780976557172835, Min w: 5.5674150863495656e-14\n",
      "Iteration 1140, Loss: 0.0004928021808154881, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0004937241319566965, Min w: 1.0282132784089626e-11\n",
      "Iteration 1160, Loss: 0.0004906101967208087, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0004931499133817852, Min w: 3.6835219019809654e-26\n",
      "Iteration 1180, Loss: 0.0004919636412523687, Min w: 3.5486481739459676e-31\n",
      "Iteration 1190, Loss: 0.00047442459617741406, Min w: 1.1175675364685965e-19\n",
      "Iteration 1200, Loss: 0.00047435599844902754, Min w: 1.9398310541873798e-05\n",
      "Iteration 1210, Loss: 0.00039646332152187824, Min w: 0.17155469954013824\n",
      "Iteration 1220, Loss: 0.00035630230559036136, Min w: 0.14123603701591492\n",
      "Iteration 1230, Loss: 0.0003859992721118033, Min w: 0.059934601187705994\n",
      "Iteration 1240, Loss: 0.0004941670340485871, Min w: 7.231453764688922e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  12%|█▎        | 3/24 [04:37<32:15, 92.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.10126019799553423, 'L2_avg': 0.12847607044512202, 'End_point_L1_avg': 0.08980919601919017, 'End_point_L2_avg': 0.09056022251031286}\n",
      "Iteration 0, Loss: 0.0015340633690357208, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0009579584002494812, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005655665881931782, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0005649468512274325, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005899738753214478, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005135252722539008, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005163755267858505, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005619561998173594, Min w: 2.086613679755689e-37\n",
      "Iteration 80, Loss: 0.0005642172181978822, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005553699447773397, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005160003784112632, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005044456920586526, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005537935649044812, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005223922780714929, Min w: 5.710827656407794e-28\n",
      "Iteration 140, Loss: 0.0005176745471544564, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005152722587808967, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005134887178428471, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005476718069985509, Min w: 0.0\n",
      "Iteration 180, Loss: 0.000552017823792994, Min w: 0.0\n",
      "Iteration 190, Loss: 0.000531311088707298, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005548864719457924, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005120272981002927, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005035946960560977, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005620206356979907, Min w: 0.0\n",
      "Iteration 240, Loss: 0.000496940512675792, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0005108492914587259, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0004961416125297546, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005141763249412179, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0004615341895259917, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005080249975435436, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0005166293703950942, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005047478480264544, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005161414155736566, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005062908167019486, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0005005751154385507, Min w: 1.0102130860041567e-32\n",
      "Iteration 350, Loss: 0.0005070382612757385, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0005022020195610821, Min w: 0.0\n",
      "Iteration 370, Loss: 0.00054500054102391, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0004984147963114083, Min w: 2.0614501708682384e-41\n",
      "Iteration 390, Loss: 0.0005391131853684783, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005311182467266917, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005093546933494508, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005202260799705982, Min w: 0.0\n",
      "Iteration 430, Loss: 0.000528839067555964, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0005046703736297786, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0004986583953723311, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005209204973652959, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005265732761472464, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0005021631950512528, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000497938715852797, Min w: 0.0\n",
      "Iteration 500, Loss: 0.000520668807439506, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005030565080232918, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00043174903839826584, Min w: 5.101707319067362e-41\n",
      "Iteration 530, Loss: 0.0005019577802158892, Min w: 6.520017546749082e-39\n",
      "Iteration 540, Loss: 0.0005172181990928948, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005464512505568564, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0005676300497725606, Min w: 0.0\n",
      "Iteration 570, Loss: 0.000501534843351692, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0004990639863535762, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0004988688742741942, Min w: 2.839490313302376e-23\n",
      "Iteration 600, Loss: 0.0004958587232977152, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005044133285991848, Min w: 2.3997953005167955e-26\n",
      "Iteration 620, Loss: 0.0005037548253312707, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0004933178424835205, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00047490192810073495, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0005004109698347747, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0005004133563488722, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0005044760764576495, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0005415761843323708, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005222097388468683, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0004987919819541276, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0005338282790035009, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0005057529197074473, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0005405106930993497, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0005026493454352021, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0005188027862459421, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0004984596744179726, Min w: 1.7648086953019475e-31\n",
      "Iteration 770, Loss: 0.0005001939134672284, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0005240133032202721, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0005067018792033195, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0005262127378955483, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005152301746420562, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0005073875654488802, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0004803405608981848, Min w: 0.0\n",
      "Iteration 840, Loss: 0.00047140507376752794, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0004511944716796279, Min w: 7.991610074615026e-37\n",
      "Iteration 860, Loss: 0.0004694203089457005, Min w: 0.0020188794005662203\n",
      "Iteration 870, Loss: 0.0004987638676539063, Min w: 0.01774176023900509\n",
      "Iteration 880, Loss: 0.0005201789317652583, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0005013943882659078, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0005328009719960392, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0004977487842552364, Min w: 1.0540166961447994e-08\n",
      "Iteration 920, Loss: 0.0005260866601020098, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0004997304058633745, Min w: 1.1210387714598537e-44\n",
      "Iteration 940, Loss: 0.000507140182889998, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0005193160613998771, Min w: 4.933572483878379e-08\n",
      "Iteration 960, Loss: 0.0005273949354887009, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0005172623204998672, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0005172588862478733, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0005197387072257698, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0005257073789834976, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0004964059335179627, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0005117749096825719, Min w: 7.630525942659006e-06\n",
      "Iteration 1030, Loss: 0.0005110458587296307, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0005343583761714399, Min w: 2.1802632297490427e-15\n",
      "Iteration 1050, Loss: 0.0004944017855450511, Min w: 2.9913674188433958e-21\n",
      "Iteration 1060, Loss: 0.000500391295645386, Min w: 6.802920765743631e-20\n",
      "Iteration 1070, Loss: 0.0005029678577557206, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0005157662089914083, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0004993328475393355, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0004906847607344389, Min w: 1.4996016261592483e-18\n",
      "Iteration 1110, Loss: 0.0004652889911085367, Min w: 0.010959962382912636\n",
      "Iteration 1120, Loss: 0.0004979678778909147, Min w: 1.7250092413517715e-12\n",
      "Iteration 1130, Loss: 0.00046513834968209267, Min w: 0.00021144251513760537\n",
      "Iteration 1140, Loss: 0.0005070901825092733, Min w: 1.5545290749097163e-13\n",
      "Iteration 1150, Loss: 0.0005030878819525242, Min w: 9.645085945197973e-12\n",
      "Iteration 1160, Loss: 0.0005114474915899336, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.000500423542689532, Min w: 1.996912064842036e-20\n",
      "Iteration 1180, Loss: 0.0005150445504114032, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0005288615357130766, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0004989842418581247, Min w: 9.298441067181937e-23\n",
      "Iteration 1210, Loss: 0.0005062943091616035, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0005217274301685393, Min w: 7.84816527569437e-30\n",
      "Iteration 1230, Loss: 0.0005030096508562565, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0005133301019668579, Min w: 4.2909182696865653e-38\n",
      "Iteration 0, Loss: 0.000496633758302778, Min w: 1.2058608963870797e-32\n",
      "Iteration 10, Loss: 0.0004362917097751051, Min w: 3.755930083571002e-05\n",
      "Iteration 20, Loss: 0.0004760895681101829, Min w: 3.0721820643009323e-09\n",
      "Iteration 30, Loss: 0.0004999627126380801, Min w: 0.0007995590567588806\n",
      "Iteration 40, Loss: 0.0005078199319541454, Min w: 4.941135772664511e-30\n",
      "Iteration 50, Loss: 0.0005093541112728417, Min w: 8.621729172085958e-22\n",
      "Iteration 60, Loss: 0.0005167791969142854, Min w: 8.194199961826897e-25\n",
      "Iteration 70, Loss: 0.0005102214636281133, Min w: 1.3994683608176621e-33\n",
      "Iteration 80, Loss: 0.0004982840619049966, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005002157995477319, Min w: 7.902568581954366e-16\n",
      "Iteration 100, Loss: 0.0005114665254950523, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005044587305746973, Min w: 2.1949238495951772e-39\n",
      "Iteration 120, Loss: 0.0005258143064565957, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005262343911454082, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005081634153611958, Min w: 7.146622168056567e-44\n",
      "Iteration 150, Loss: 0.0004930977011099458, Min w: 6.257117491176665e-33\n",
      "Iteration 160, Loss: 0.0004987084539607167, Min w: 1.0581204704116694e-41\n",
      "Iteration 170, Loss: 0.0004996348288841546, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0004999482771381736, Min w: 8.448055290117093e-33\n",
      "Iteration 190, Loss: 0.0005041359108872712, Min w: 0.0\n",
      "Iteration 200, Loss: 0.00050113326869905, Min w: 2.2673566135722467e-08\n",
      "Iteration 210, Loss: 0.0004959878860972822, Min w: 2.2604205833498536e-13\n",
      "Iteration 220, Loss: 0.0004972583265043795, Min w: 4.559644253276929e-07\n",
      "Iteration 230, Loss: 0.0004973884206265211, Min w: 4.350262782605193e-18\n",
      "Iteration 240, Loss: 0.0004991652094759047, Min w: 0.0\n",
      "Iteration 250, Loss: 0.00045238120947033167, Min w: 1.445857588573707e-21\n",
      "Iteration 260, Loss: 0.0005048337625339627, Min w: 1.7423427909614614e-27\n",
      "Iteration 270, Loss: 0.000504844996612519, Min w: 1.401298464324817e-45\n",
      "Iteration 280, Loss: 0.000505282252561301, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005136076943017542, Min w: 2.6811252464052984e-15\n",
      "Iteration 300, Loss: 0.0004980287048965693, Min w: 9.591731212914529e-32\n",
      "Iteration 310, Loss: 0.0005070401239208877, Min w: 1.709818166228689e-14\n",
      "Iteration 320, Loss: 0.0004970114678144455, Min w: 5.754425558279763e-08\n",
      "Iteration 330, Loss: 0.000494472507853061, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000501100963447243, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0005016799550503492, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004938545753248036, Min w: 1.7958389795260637e-37\n",
      "Iteration 370, Loss: 0.0004947425331920385, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005059721297584474, Min w: 1.0836739856275801e-29\n",
      "Iteration 390, Loss: 0.000507077609654516, Min w: 1.5672443904326925e-28\n",
      "Iteration 400, Loss: 0.0005106758326292038, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005064929719083011, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005008074804209173, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004990858142264187, Min w: 2.8192930913548304e-14\n",
      "Iteration 440, Loss: 0.0005012082401663065, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0004962775856256485, Min w: 1.8755928077468888e-31\n",
      "Iteration 460, Loss: 0.0004990019369870424, Min w: 3.578155441645639e-18\n",
      "Iteration 470, Loss: 0.0005022600525990129, Min w: 2.133548051194441e-29\n",
      "Iteration 480, Loss: 0.0004931452567689121, Min w: 0.00021713301248382777\n",
      "Iteration 490, Loss: 0.0004709737258963287, Min w: 2.132740739568817e-08\n",
      "Iteration 500, Loss: 0.0004847731033805758, Min w: 3.6815365547226975e-06\n",
      "Iteration 510, Loss: 0.000494981708470732, Min w: 0.0031311423517763615\n",
      "Iteration 520, Loss: 0.0004985714913345873, Min w: 5.180937023396837e-06\n",
      "Iteration 530, Loss: 0.0005043421988375485, Min w: 1.7447492837163736e-06\n",
      "Iteration 540, Loss: 0.000469945021905005, Min w: 1.208905905514257e-05\n",
      "Iteration 550, Loss: 0.0004678036202676594, Min w: 0.021771106868982315\n",
      "Iteration 560, Loss: 0.00043383342563174665, Min w: 2.4849343390087597e-05\n",
      "Iteration 570, Loss: 0.0005014752387069166, Min w: 2.0850453583378033e-23\n",
      "Iteration 580, Loss: 0.0005037717055529356, Min w: 2.3120443752434454e-40\n",
      "Iteration 590, Loss: 0.0005019326345063746, Min w: 1.4773729081201653e-32\n",
      "Iteration 600, Loss: 0.0005107955657877028, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005201218300499022, Min w: 1.3336290881785208e-28\n",
      "Iteration 620, Loss: 0.0004998870426788926, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0005013798363506794, Min w: 2.2690029211819352e-36\n",
      "Iteration 640, Loss: 0.000519987428560853, Min w: 1.4302822037848273e-08\n",
      "Iteration 650, Loss: 0.0005016157520003617, Min w: 1.5326540564506358e-32\n",
      "Iteration 660, Loss: 0.0005117779946886003, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0004994331393390894, Min w: 3.4009904770754607e-17\n",
      "Iteration 680, Loss: 0.0004351287498138845, Min w: 2.0096126984725515e-09\n",
      "Iteration 690, Loss: 0.0004719434946309775, Min w: 1.4449380277350987e-12\n",
      "Iteration 700, Loss: 0.0004995169001631439, Min w: 5.787141344626434e-05\n",
      "Iteration 710, Loss: 0.0005086403107270598, Min w: 3.56330128852278e-05\n",
      "Iteration 720, Loss: 0.0005032272893004119, Min w: 2.5093330080494525e-08\n",
      "Iteration 730, Loss: 0.0004993436741642654, Min w: 1.8629800251801498e-05\n",
      "Iteration 740, Loss: 0.0005042721750214696, Min w: 4.847485115533345e-07\n",
      "Iteration 750, Loss: 0.0004931058501824737, Min w: 7.741887384327129e-05\n",
      "Iteration 760, Loss: 0.0004977688076905906, Min w: 3.238244872250107e-08\n",
      "Iteration 770, Loss: 0.0005041820113547146, Min w: 0.0\n",
      "Iteration 780, Loss: 0.00045872206101194024, Min w: 0.0002459986717440188\n",
      "Iteration 790, Loss: 0.0004971593152731657, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0004992875037714839, Min w: 5.787003740419857e-16\n",
      "Iteration 810, Loss: 0.0004974736948497593, Min w: 7.719026833734668e-14\n",
      "Iteration 820, Loss: 0.0004986871499568224, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0004984450642950833, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0004941733204759657, Min w: 1.8360452637563808e-35\n",
      "Iteration 850, Loss: 0.00048430063179694116, Min w: 4.91533238302828e-34\n",
      "Iteration 860, Loss: 0.0004940148210152984, Min w: 3.5379355001197155e-09\n",
      "Iteration 870, Loss: 0.0004983128746971488, Min w: 8.139446554906657e-14\n",
      "Iteration 880, Loss: 0.0004961148370057344, Min w: 0.000248169555561617\n",
      "Iteration 890, Loss: 0.0004969479632563889, Min w: 6.344942138339932e-19\n",
      "Iteration 900, Loss: 0.0005009765736758709, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0004979772493243217, Min w: 2.687093175853856e-16\n",
      "Iteration 920, Loss: 0.0004990177694708109, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0004974130424670875, Min w: 8.90484977422723e-11\n",
      "Iteration 940, Loss: 0.0005012304754927754, Min w: 0.0\n",
      "Iteration 950, Loss: 0.000502898299600929, Min w: 1.559331656852958e-12\n",
      "Iteration 960, Loss: 0.0004909790004603565, Min w: 0.0002860426902770996\n",
      "Iteration 970, Loss: 0.0004986146814189851, Min w: 4.7902359068717875e-34\n",
      "Iteration 980, Loss: 0.000492323306389153, Min w: 5.168709904523894e-09\n",
      "Iteration 990, Loss: 0.00047411886043846607, Min w: 5.067957431492687e-08\n",
      "Iteration 1000, Loss: 0.0004939513746649027, Min w: 2.3994672915250703e-10\n",
      "Iteration 1010, Loss: 0.0004977587959729135, Min w: 5.990512448074414e-14\n",
      "Iteration 1020, Loss: 0.000489065598230809, Min w: 6.890565253851913e-37\n",
      "Iteration 1030, Loss: 0.00048154109390452504, Min w: 0.005794829688966274\n",
      "Iteration 1040, Loss: 0.0004982448881492019, Min w: 5.067059934208947e-15\n",
      "Iteration 1050, Loss: 0.0004982499522157013, Min w: 2.4367849960071908e-09\n",
      "Iteration 1060, Loss: 0.0004964840481989086, Min w: 9.356890222989023e-05\n",
      "Iteration 1070, Loss: 0.000501565111335367, Min w: 0.0008074994548223913\n",
      "Iteration 1080, Loss: 0.00047625083243474364, Min w: 0.002353535732254386\n",
      "Iteration 1090, Loss: 0.0004986252752132714, Min w: 3.5236265460980576e-08\n",
      "Iteration 1100, Loss: 0.0004992895992472768, Min w: 2.722744599226168e-11\n",
      "Iteration 1110, Loss: 0.0005115513340570033, Min w: 7.006492321624085e-45\n",
      "Iteration 1120, Loss: 0.0005066367448307574, Min w: 6.692385716916072e-15\n",
      "Iteration 1130, Loss: 0.0005034493515267968, Min w: 5.032978716543223e-16\n",
      "Iteration 1140, Loss: 0.0005006415885873139, Min w: 8.662787517714185e-19\n",
      "Iteration 1150, Loss: 0.0005135738174431026, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0005040941177867353, Min w: 2.833629972922572e-20\n",
      "Iteration 1170, Loss: 0.000511844758875668, Min w: 1.479019731195997e-24\n",
      "Iteration 1180, Loss: 0.0005011525936424732, Min w: 2.324021419752853e-09\n",
      "Iteration 1190, Loss: 0.0005075887311249971, Min w: 4.203895392974451e-45\n",
      "Iteration 1200, Loss: 0.0005051775369793177, Min w: 1.558392635166448e-19\n",
      "Iteration 1210, Loss: 0.0005011886241845787, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0004990948364138603, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0005047293961979449, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0005026511498726904, Min w: 2.6796937607244387e-15\n",
      "Iteration 0, Loss: 0.0004980745143257082, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0004995064809918404, Min w: 3.488612574144387e-30\n",
      "Iteration 20, Loss: 0.0004528439894784242, Min w: 2.2413591693748458e-07\n",
      "Iteration 30, Loss: 0.0004363452026154846, Min w: 5.614189113600787e-09\n",
      "Iteration 40, Loss: 0.0004944528336636722, Min w: 1.617423883715219e-08\n",
      "Iteration 50, Loss: 0.0004906664835289121, Min w: 0.0025961273349821568\n",
      "Iteration 60, Loss: 0.0004821488109882921, Min w: 0.0002061274863081053\n",
      "Iteration 70, Loss: 0.0005017894436605275, Min w: 3.679546352941543e-06\n",
      "Iteration 80, Loss: 0.0004998024087399244, Min w: 4.8423773444313655e-19\n",
      "Iteration 90, Loss: 0.0004971117014065385, Min w: 1.4657706652400911e-38\n",
      "Iteration 100, Loss: 0.0004980048979632556, Min w: 1.3027109391217095e-09\n",
      "Iteration 110, Loss: 0.000462174357380718, Min w: 5.361573273028608e-13\n",
      "Iteration 120, Loss: 0.00045560975559055805, Min w: 0.020704587921500206\n",
      "Iteration 130, Loss: 0.0003933956322725862, Min w: 0.06726913899183273\n",
      "Iteration 140, Loss: 0.0004998556687496603, Min w: 1.114766681742374e-10\n",
      "Iteration 150, Loss: 0.0004590286989696324, Min w: 0.00015122648619581014\n",
      "Iteration 160, Loss: 0.0005083779687993228, Min w: 1.387399265116872e-37\n",
      "Iteration 170, Loss: 0.0004967029672116041, Min w: 1.9478048654114957e-43\n",
      "Iteration 180, Loss: 0.00044625820009969175, Min w: 0.0032863819506019354\n",
      "Iteration 190, Loss: 0.000454014225397259, Min w: 0.05865079164505005\n",
      "Iteration 200, Loss: 0.0004755717236548662, Min w: 0.01855344884097576\n",
      "Iteration 210, Loss: 0.0005008241860195994, Min w: 1.1144808240715065e-06\n",
      "Iteration 220, Loss: 0.0004969277651980519, Min w: 5.2269078878453e-06\n",
      "Iteration 230, Loss: 0.0004989622393622994, Min w: 9.815872181206942e-05\n",
      "Iteration 240, Loss: 0.0004971498856320977, Min w: 1.395445243098941e-23\n",
      "Iteration 250, Loss: 0.0005076886154711246, Min w: 2.5471074817324862e-17\n",
      "Iteration 260, Loss: 0.0005000231321901083, Min w: 1.6129810186547226e-16\n",
      "Iteration 270, Loss: 0.0004995488561689854, Min w: 2.2771100045278277e-42\n",
      "Iteration 280, Loss: 0.0004991592722944915, Min w: 7.780721086012534e-34\n",
      "Iteration 290, Loss: 0.0004966851556673646, Min w: 7.477348162865383e-07\n",
      "Iteration 300, Loss: 0.0005038054659962654, Min w: 5.4618331918039695e-15\n",
      "Iteration 310, Loss: 0.0005037338705733418, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005028764717280865, Min w: 1.891711266799323e-11\n",
      "Iteration 330, Loss: 0.0004387179506011307, Min w: 0.09544045478105545\n",
      "Iteration 340, Loss: 0.0004849876568187028, Min w: 9.146655344238752e-08\n",
      "Iteration 350, Loss: 0.0004954667529091239, Min w: 1.401298464324817e-45\n",
      "Iteration 360, Loss: 0.0005034392233937979, Min w: 1.120011248190167e-07\n",
      "Iteration 370, Loss: 0.0004944218089804053, Min w: 1.3245291974328666e-08\n",
      "Iteration 380, Loss: 0.0004897223552688956, Min w: 0.0005294980946928263\n",
      "Iteration 390, Loss: 0.0005012854817323387, Min w: 1.343853007658922e-28\n",
      "Iteration 400, Loss: 0.0005015784408897161, Min w: 5.916709184257581e-19\n",
      "Iteration 410, Loss: 0.0004971069283783436, Min w: 3.036950135815175e-10\n",
      "Iteration 420, Loss: 0.0004730432410724461, Min w: 0.04315231740474701\n",
      "Iteration 430, Loss: 0.0003860733122564852, Min w: 0.07853507250547409\n",
      "Iteration 440, Loss: 0.000490883772727102, Min w: 0.0039663114584982395\n",
      "Iteration 450, Loss: 0.0004890607669949532, Min w: 2.0839230785441032e-07\n",
      "Iteration 460, Loss: 0.00044765902566723526, Min w: 0.026475412771105766\n",
      "Iteration 470, Loss: 0.0004399702011141926, Min w: 0.0022810588125139475\n",
      "Iteration 480, Loss: 0.00045071454951539636, Min w: 0.05357207730412483\n",
      "Iteration 490, Loss: 0.0003037863061763346, Min w: 0.0844539999961853\n",
      "Iteration 500, Loss: 0.0003949223319068551, Min w: 0.15031875669956207\n",
      "Iteration 510, Loss: 0.0003962055197916925, Min w: 0.15175777673721313\n",
      "Iteration 520, Loss: 0.0003676116175483912, Min w: 0.17131060361862183\n",
      "Iteration 530, Loss: 0.00038577819941565394, Min w: 0.1796071082353592\n",
      "Iteration 540, Loss: 0.0003752663033083081, Min w: 0.16604632139205933\n",
      "Iteration 550, Loss: 0.0003322134434711188, Min w: 0.2016894668340683\n",
      "Iteration 560, Loss: 0.0003668394929263741, Min w: 0.18149085342884064\n",
      "Iteration 570, Loss: 0.0004998471704311669, Min w: 5.409849558518186e-22\n",
      "Iteration 580, Loss: 0.0004825596115551889, Min w: 0.0013239484978839755\n",
      "Iteration 590, Loss: 0.00034868752118200064, Min w: 0.03508041054010391\n",
      "Iteration 600, Loss: 0.0003746618749573827, Min w: 0.14908172190189362\n",
      "Iteration 610, Loss: 0.0004415626171976328, Min w: 0.11684724688529968\n",
      "Iteration 620, Loss: 0.0004652565985452384, Min w: 2.98587501390557e-08\n",
      "Iteration 630, Loss: 0.00038906914414837956, Min w: 0.06350897997617722\n",
      "Iteration 640, Loss: 0.0004067126428708434, Min w: 0.11975017189979553\n",
      "Iteration 650, Loss: 0.00035635041422210634, Min w: 0.23371879756450653\n",
      "Iteration 660, Loss: 0.0003205153625458479, Min w: 0.22626999020576477\n",
      "Iteration 670, Loss: 0.00033177522709593177, Min w: 0.19130250811576843\n",
      "Iteration 680, Loss: 0.00032344614737667143, Min w: 0.2547958195209503\n",
      "Iteration 690, Loss: 0.00030308347777463496, Min w: 0.2388046830892563\n",
      "Iteration 700, Loss: 0.0003110574616584927, Min w: 0.2569672465324402\n",
      "Iteration 710, Loss: 0.000296300946502015, Min w: 0.2547842860221863\n",
      "Iteration 720, Loss: 0.0002943903673440218, Min w: 0.28156957030296326\n",
      "Iteration 730, Loss: 0.0002901757834479213, Min w: 0.2874141037464142\n",
      "Iteration 740, Loss: 0.00029437828925438225, Min w: 0.28309527039527893\n",
      "Iteration 750, Loss: 0.00031201160163618624, Min w: 0.2806818187236786\n",
      "Iteration 760, Loss: 0.0002898651291616261, Min w: 0.3067730665206909\n",
      "Iteration 770, Loss: 0.00027938507264479995, Min w: 0.29315677285194397\n",
      "Iteration 780, Loss: 0.00028617194038815796, Min w: 0.2992766499519348\n",
      "Iteration 790, Loss: 0.0002856555220205337, Min w: 0.32704392075538635\n",
      "Iteration 800, Loss: 0.0002572847588453442, Min w: 0.3363994359970093\n",
      "Iteration 810, Loss: 0.00025743484729900956, Min w: 0.3507201373577118\n",
      "Iteration 820, Loss: 0.0002837801293935627, Min w: 0.3521549105644226\n",
      "Iteration 830, Loss: 0.0002828776487149298, Min w: 0.3678176701068878\n",
      "Iteration 840, Loss: 0.0002511644852347672, Min w: 0.37947937846183777\n",
      "Iteration 850, Loss: 0.0002764426462817937, Min w: 0.36768585443496704\n",
      "Iteration 860, Loss: 0.00021976628340780735, Min w: 0.43585851788520813\n",
      "Iteration 870, Loss: 0.00027186909574083984, Min w: 0.32916346192359924\n",
      "Iteration 880, Loss: 0.000198778958292678, Min w: 0.44589218497276306\n",
      "Iteration 890, Loss: 0.000290492462227121, Min w: 0.43218445777893066\n",
      "Iteration 900, Loss: 0.00023919921659398824, Min w: 0.4107716381549835\n",
      "Iteration 910, Loss: 0.00027038896223530173, Min w: 0.3832116425037384\n",
      "Iteration 920, Loss: 0.00020069601305294782, Min w: 0.47059229016304016\n",
      "Iteration 930, Loss: 0.00024229526752606034, Min w: 0.4402287006378174\n",
      "Iteration 940, Loss: 0.00019105439423583448, Min w: 0.47955718636512756\n",
      "Iteration 950, Loss: 0.0002481083502061665, Min w: 0.4496272802352905\n",
      "Iteration 960, Loss: 0.00023650602088309824, Min w: 0.4473612308502197\n",
      "Iteration 970, Loss: 0.00020059118105564266, Min w: 0.4868149757385254\n",
      "Iteration 980, Loss: 0.00020904718257952482, Min w: 0.5015414953231812\n",
      "Iteration 990, Loss: 0.0001770079106790945, Min w: 0.5145024657249451\n",
      "Iteration 1000, Loss: 0.00018371010082773864, Min w: 0.49882739782333374\n",
      "Iteration 1010, Loss: 0.0001925735268741846, Min w: 0.5001899600028992\n",
      "Iteration 1020, Loss: 0.00023740308824926615, Min w: 0.4757157266139984\n",
      "Iteration 1030, Loss: 0.00022064430231694132, Min w: 0.5049984455108643\n",
      "Iteration 1040, Loss: 0.00021061675215605646, Min w: 0.5137159824371338\n",
      "Iteration 1050, Loss: 0.00025000362074933946, Min w: 0.44769221544265747\n",
      "Iteration 1060, Loss: 0.00019294637604616582, Min w: 0.5194636583328247\n",
      "Iteration 1070, Loss: 0.0002101848367601633, Min w: 0.4892505705356598\n",
      "Iteration 1080, Loss: 0.00021612024283967912, Min w: 0.522720456123352\n",
      "Iteration 1090, Loss: 0.00021440989803522825, Min w: 0.49560999870300293\n",
      "Iteration 1100, Loss: 0.00018733253818936646, Min w: 0.5122422575950623\n",
      "Iteration 1110, Loss: 0.000193628846318461, Min w: 0.5101034045219421\n",
      "Iteration 1120, Loss: 0.00019714598602149636, Min w: 0.5152698159217834\n",
      "Iteration 1130, Loss: 0.00020186281471978873, Min w: 0.512161910533905\n",
      "Iteration 1140, Loss: 0.0002069560287054628, Min w: 0.5099766850471497\n",
      "Iteration 1150, Loss: 0.00018583668861538172, Min w: 0.5386478304862976\n",
      "Iteration 1160, Loss: 0.00019328814232721925, Min w: 0.5512128472328186\n",
      "Iteration 1170, Loss: 0.0001685574825387448, Min w: 0.551939070224762\n",
      "Iteration 1180, Loss: 0.00019788110512308776, Min w: 0.5321035981178284\n",
      "Iteration 1190, Loss: 0.00017269949603360146, Min w: 0.5421018004417419\n",
      "Iteration 1200, Loss: 0.00021109981753397733, Min w: 0.515891432762146\n",
      "Iteration 1210, Loss: 0.0001708009367575869, Min w: 0.5299449563026428\n",
      "Iteration 1220, Loss: 0.00016293635417241603, Min w: 0.5740110278129578\n",
      "Iteration 1230, Loss: 0.00020081028924323618, Min w: 0.5381919741630554\n",
      "Iteration 1240, Loss: 0.0001899671187857166, Min w: 0.5510427355766296\n",
      "Iteration 0, Loss: 0.00019761218572966754, Min w: 0.5598494410514832\n",
      "Iteration 10, Loss: 0.00017197191482409835, Min w: 0.5577649474143982\n",
      "Iteration 20, Loss: 0.00018679190543480217, Min w: 0.5641100406646729\n",
      "Iteration 30, Loss: 0.0001748536160448566, Min w: 0.5775260329246521\n",
      "Iteration 40, Loss: 0.00018947635544463992, Min w: 0.5407862067222595\n",
      "Iteration 50, Loss: 0.00015950313536450267, Min w: 0.5974810123443604\n",
      "Iteration 60, Loss: 0.00016923045041039586, Min w: 0.572800874710083\n",
      "Iteration 70, Loss: 0.00017076055519282818, Min w: 0.5738634467124939\n",
      "Iteration 80, Loss: 0.00017124591977335513, Min w: 0.5962828397750854\n",
      "Iteration 90, Loss: 0.00014422078675124794, Min w: 0.6226781010627747\n",
      "Iteration 100, Loss: 0.00014343483780976385, Min w: 0.6103232502937317\n",
      "Iteration 110, Loss: 0.00013861514162272215, Min w: 0.6076094508171082\n",
      "Iteration 120, Loss: 0.0001328177168034017, Min w: 0.622590959072113\n",
      "Iteration 130, Loss: 0.00014963495777919888, Min w: 0.6286115050315857\n",
      "Iteration 140, Loss: 0.00018039050337392837, Min w: 0.5941815376281738\n",
      "Iteration 150, Loss: 0.0001967330026673153, Min w: 0.5558894872665405\n",
      "Iteration 160, Loss: 0.00014608640049118549, Min w: 0.6227278113365173\n",
      "Iteration 170, Loss: 0.00015747321594972163, Min w: 0.6411723494529724\n",
      "Iteration 180, Loss: 0.00020386635151226074, Min w: 0.5605419278144836\n",
      "Iteration 190, Loss: 0.00014434642798732966, Min w: 0.6417130827903748\n",
      "Iteration 200, Loss: 0.00018887672922573984, Min w: 0.611744225025177\n",
      "Iteration 210, Loss: 0.000162606593221426, Min w: 0.633598804473877\n",
      "Iteration 220, Loss: 0.00014309135440271348, Min w: 0.6266123652458191\n",
      "Iteration 230, Loss: 0.00015642923244740814, Min w: 0.6482581496238708\n",
      "Iteration 240, Loss: 0.0001696400868240744, Min w: 0.6501600742340088\n",
      "Iteration 250, Loss: 0.0001203167557832785, Min w: 0.6934669613838196\n",
      "Iteration 260, Loss: 0.00013345404295250773, Min w: 0.6420029997825623\n",
      "Iteration 270, Loss: 0.00016597700596321374, Min w: 0.653616189956665\n",
      "Iteration 280, Loss: 0.0001393993734382093, Min w: 0.6745059490203857\n",
      "Iteration 290, Loss: 0.00012398514081723988, Min w: 0.6877458095550537\n",
      "Iteration 300, Loss: 0.0001607162703294307, Min w: 0.6655225157737732\n",
      "Iteration 310, Loss: 0.00015012829680927098, Min w: 0.6727885007858276\n",
      "Iteration 320, Loss: 0.00015314760094042867, Min w: 0.6749692559242249\n",
      "Iteration 330, Loss: 0.00014773612201679498, Min w: 0.6791947484016418\n",
      "Iteration 340, Loss: 0.00013325783947948366, Min w: 0.6781935095787048\n",
      "Iteration 350, Loss: 0.00013321539154276252, Min w: 0.6603282690048218\n",
      "Iteration 360, Loss: 0.00013838981976732612, Min w: 0.6598331928253174\n",
      "Iteration 370, Loss: 0.00014717724116053432, Min w: 0.6726735234260559\n",
      "Iteration 380, Loss: 0.00013215502258390188, Min w: 0.7066811919212341\n",
      "Iteration 390, Loss: 0.00016576945199631155, Min w: 0.6331120133399963\n",
      "Iteration 400, Loss: 0.00013634530478157103, Min w: 0.6856489181518555\n",
      "Iteration 410, Loss: 0.00011959300900343806, Min w: 0.7116920351982117\n",
      "Iteration 420, Loss: 0.00013926257088314742, Min w: 0.6914617419242859\n",
      "Iteration 430, Loss: 0.0001499220379628241, Min w: 0.6726561188697815\n",
      "Iteration 440, Loss: 0.00013831215619575232, Min w: 0.6866940855979919\n",
      "Iteration 450, Loss: 0.00014323827053885907, Min w: 0.6849666833877563\n",
      "Iteration 460, Loss: 0.00014472295879386365, Min w: 0.7073279023170471\n",
      "Iteration 470, Loss: 0.0001172058837255463, Min w: 0.7356874942779541\n",
      "Iteration 480, Loss: 0.00011455312051111832, Min w: 0.7569435834884644\n",
      "Iteration 490, Loss: 0.0001650812482694164, Min w: 0.6099921464920044\n",
      "Iteration 500, Loss: 0.00012162914936197922, Min w: 0.7303233742713928\n",
      "Iteration 510, Loss: 0.0001013977816910483, Min w: 0.7680242657661438\n",
      "Iteration 520, Loss: 0.00012810304178856313, Min w: 0.7302075028419495\n",
      "Iteration 530, Loss: 0.0001388944947393611, Min w: 0.7123202085494995\n",
      "Iteration 540, Loss: 0.00011606689804466441, Min w: 0.7635370492935181\n",
      "Iteration 550, Loss: 0.00012867852638009936, Min w: 0.7355729341506958\n",
      "Iteration 560, Loss: 0.00011995695967925712, Min w: 0.733187735080719\n",
      "Iteration 570, Loss: 0.00011186431220266968, Min w: 0.7344321012496948\n",
      "Iteration 580, Loss: 0.00012167914246674627, Min w: 0.7209870219230652\n",
      "Iteration 590, Loss: 0.0001035736859194003, Min w: 0.7827014327049255\n",
      "Iteration 600, Loss: 0.0001446174137527123, Min w: 0.6900840997695923\n",
      "Iteration 610, Loss: 8.748080290388316e-05, Min w: 0.8021926879882812\n",
      "Iteration 620, Loss: 0.00011310925765428692, Min w: 0.7532415390014648\n",
      "Iteration 630, Loss: 0.0001352669351035729, Min w: 0.7129507660865784\n",
      "Iteration 640, Loss: 0.00011611729860305786, Min w: 0.7339914441108704\n",
      "Iteration 650, Loss: 0.00010963985550915822, Min w: 0.7771809697151184\n",
      "Iteration 660, Loss: 0.00012052623787894845, Min w: 0.7482262849807739\n",
      "Iteration 670, Loss: 0.00011118677502963692, Min w: 0.7534529566764832\n",
      "Iteration 680, Loss: 9.994519496103749e-05, Min w: 0.786328136920929\n",
      "Iteration 690, Loss: 0.00012838075053878129, Min w: 0.7217816114425659\n",
      "Iteration 700, Loss: 0.00010834160639205948, Min w: 0.7366860508918762\n",
      "Iteration 710, Loss: 0.0001314739929512143, Min w: 0.7030134797096252\n",
      "Iteration 720, Loss: 0.0001177169251604937, Min w: 0.7506623268127441\n",
      "Iteration 730, Loss: 0.00010083202505484223, Min w: 0.7759717106819153\n",
      "Iteration 740, Loss: 0.00011303883366053924, Min w: 0.7294915318489075\n",
      "Iteration 750, Loss: 0.0001093440514523536, Min w: 0.7497173547744751\n",
      "Iteration 760, Loss: 9.614398732082918e-05, Min w: 0.7831565141677856\n",
      "Iteration 770, Loss: 0.00010629815369611606, Min w: 0.7798293828964233\n",
      "Iteration 780, Loss: 9.187010437017307e-05, Min w: 0.7873015403747559\n",
      "Iteration 790, Loss: 0.00011488304153317586, Min w: 0.7370930314064026\n",
      "Iteration 800, Loss: 9.095864515984431e-05, Min w: 0.8109745979309082\n",
      "Iteration 810, Loss: 0.00011097106471424922, Min w: 0.7491216659545898\n",
      "Iteration 820, Loss: 0.00010618124360917136, Min w: 0.7363762855529785\n",
      "Iteration 830, Loss: 9.644700185162947e-05, Min w: 0.7899458408355713\n",
      "Iteration 840, Loss: 6.232057785382494e-05, Min w: 0.8548133373260498\n",
      "Iteration 850, Loss: 8.627158968010917e-05, Min w: 0.79975825548172\n",
      "Iteration 860, Loss: 0.00011341610661474988, Min w: 0.7468540668487549\n",
      "Iteration 870, Loss: 9.609986591385677e-05, Min w: 0.7949557900428772\n",
      "Iteration 880, Loss: 7.840124453650787e-05, Min w: 0.8279412984848022\n",
      "Iteration 890, Loss: 0.00011122626165160909, Min w: 0.7359040379524231\n",
      "Iteration 900, Loss: 9.774776117410511e-05, Min w: 0.785854697227478\n",
      "Iteration 910, Loss: 5.729332769988105e-05, Min w: 0.8661943078041077\n",
      "Iteration 920, Loss: 9.385311568621546e-05, Min w: 0.7561909556388855\n",
      "Iteration 930, Loss: 0.0001135584752773866, Min w: 0.7473927736282349\n",
      "Iteration 940, Loss: 7.779015140840784e-05, Min w: 0.814444899559021\n",
      "Iteration 950, Loss: 0.00011037015792680904, Min w: 0.7165964245796204\n",
      "Iteration 960, Loss: 9.389030310558155e-05, Min w: 0.7731279730796814\n",
      "Iteration 970, Loss: 7.281429134309292e-05, Min w: 0.8296658992767334\n",
      "Iteration 980, Loss: 0.00011874438496306539, Min w: 0.6998578906059265\n",
      "Iteration 990, Loss: 7.316631672438234e-05, Min w: 0.8376821875572205\n",
      "Iteration 1000, Loss: 6.356420635711402e-05, Min w: 0.8675405383110046\n",
      "Iteration 1010, Loss: 0.00010805548663483933, Min w: 0.7335565090179443\n",
      "Iteration 1020, Loss: 7.115862536011264e-05, Min w: 0.8359252214431763\n",
      "Iteration 1030, Loss: 8.353147131856531e-05, Min w: 0.8291123509407043\n",
      "Iteration 1040, Loss: 0.00010384764027548954, Min w: 0.7431359887123108\n",
      "Iteration 1050, Loss: 7.346761412918568e-05, Min w: 0.839911162853241\n",
      "Iteration 1060, Loss: 6.70868466841057e-05, Min w: 0.8436665534973145\n",
      "Iteration 1070, Loss: 9.948365914169699e-05, Min w: 0.7785682678222656\n",
      "Iteration 1080, Loss: 9.005871106637642e-05, Min w: 0.7906157374382019\n",
      "Iteration 1090, Loss: 6.809869955759495e-05, Min w: 0.8379884362220764\n",
      "Iteration 1100, Loss: 0.00010456291056470945, Min w: 0.758699893951416\n",
      "Iteration 1110, Loss: 8.155515388352796e-05, Min w: 0.8132181763648987\n",
      "Iteration 1120, Loss: 6.601461791433394e-05, Min w: 0.8638339042663574\n",
      "Iteration 1130, Loss: 8.092784264590591e-05, Min w: 0.811814546585083\n",
      "Iteration 1140, Loss: 0.00010081597429234535, Min w: 0.7594305276870728\n",
      "Iteration 1150, Loss: 9.829940972849727e-05, Min w: 0.7473800182342529\n",
      "Iteration 1160, Loss: 6.725779530825093e-05, Min w: 0.8347582817077637\n",
      "Iteration 1170, Loss: 7.617846131324768e-05, Min w: 0.8044276833534241\n",
      "Iteration 1180, Loss: 7.67782112234272e-05, Min w: 0.8217812180519104\n",
      "Iteration 1190, Loss: 8.415024058194831e-05, Min w: 0.7993119359016418\n",
      "Iteration 1200, Loss: 9.069663065019995e-05, Min w: 0.7682680487632751\n",
      "Iteration 1210, Loss: 7.634871144546196e-05, Min w: 0.7990415692329407\n",
      "Iteration 1220, Loss: 8.489757601637393e-05, Min w: 0.7897860407829285\n",
      "Iteration 1230, Loss: 9.263675747206435e-05, Min w: 0.7814233303070068\n",
      "Iteration 1240, Loss: 7.43754644645378e-05, Min w: 0.8139625191688538\n",
      "Iteration 0, Loss: 6.837669934611768e-05, Min w: 0.818511962890625\n",
      "Iteration 10, Loss: 7.53932908992283e-05, Min w: 0.8113052248954773\n",
      "Iteration 20, Loss: 7.593492045998573e-05, Min w: 0.8159666657447815\n",
      "Iteration 30, Loss: 7.943897799123079e-05, Min w: 0.7966306209564209\n",
      "Iteration 40, Loss: 7.601824472658336e-05, Min w: 0.8145950436592102\n",
      "Iteration 50, Loss: 9.070909436559305e-05, Min w: 0.7640949487686157\n",
      "Iteration 60, Loss: 7.322018063860014e-05, Min w: 0.8180440664291382\n",
      "Iteration 70, Loss: 6.704939005430788e-05, Min w: 0.8435145020484924\n",
      "Iteration 80, Loss: 5.9296697145327926e-05, Min w: 0.8663070797920227\n",
      "Iteration 90, Loss: 5.259290264802985e-05, Min w: 0.8810986280441284\n",
      "Iteration 100, Loss: 6.956861761864275e-05, Min w: 0.8306483626365662\n",
      "Iteration 110, Loss: 9.45697829592973e-05, Min w: 0.753730833530426\n",
      "Iteration 120, Loss: 0.00010377587022958323, Min w: 0.7316138744354248\n",
      "Iteration 130, Loss: 7.800291496096179e-05, Min w: 0.7983365654945374\n",
      "Iteration 140, Loss: 6.821851275162771e-05, Min w: 0.8320556879043579\n",
      "Iteration 150, Loss: 7.791948155499995e-05, Min w: 0.7978605031967163\n",
      "Iteration 160, Loss: 8.507332677254453e-05, Min w: 0.7961640357971191\n",
      "Iteration 170, Loss: 8.575809624744579e-05, Min w: 0.7944926023483276\n",
      "Iteration 180, Loss: 5.7624394685262814e-05, Min w: 0.8537843823432922\n",
      "Iteration 190, Loss: 6.274237239267677e-05, Min w: 0.8401244878768921\n",
      "Iteration 200, Loss: 5.130128556629643e-05, Min w: 0.894521951675415\n",
      "Iteration 210, Loss: 7.196412479970604e-05, Min w: 0.8258055448532104\n",
      "Iteration 220, Loss: 6.837373075541109e-05, Min w: 0.8186271786689758\n",
      "Iteration 230, Loss: 6.285946437856182e-05, Min w: 0.829774796962738\n",
      "Iteration 240, Loss: 6.880527507746592e-05, Min w: 0.82468181848526\n",
      "Iteration 250, Loss: 6.142277561593801e-05, Min w: 0.8478263020515442\n",
      "Iteration 260, Loss: 8.828799764160067e-05, Min w: 0.7707453370094299\n",
      "Iteration 270, Loss: 7.229400216601789e-05, Min w: 0.7993426322937012\n",
      "Iteration 280, Loss: 8.001087553566322e-05, Min w: 0.7852193117141724\n",
      "Iteration 290, Loss: 6.38519850326702e-05, Min w: 0.8473540544509888\n",
      "Iteration 300, Loss: 5.6813223636709154e-05, Min w: 0.8711830377578735\n",
      "Iteration 310, Loss: 6.49810244794935e-05, Min w: 0.829224705696106\n",
      "Iteration 320, Loss: 6.39562276774086e-05, Min w: 0.831732988357544\n",
      "Iteration 330, Loss: 5.3245701565174386e-05, Min w: 0.8624628782272339\n",
      "Iteration 340, Loss: 6.827520701335743e-05, Min w: 0.8283581733703613\n",
      "Iteration 350, Loss: 7.742064190097153e-05, Min w: 0.8025640845298767\n",
      "Iteration 360, Loss: 6.435549585148692e-05, Min w: 0.8261535167694092\n",
      "Iteration 370, Loss: 7.067432306939736e-05, Min w: 0.8210035562515259\n",
      "Iteration 380, Loss: 5.296455856296234e-05, Min w: 0.8756694197654724\n",
      "Iteration 390, Loss: 7.768123032292351e-05, Min w: 0.8079416155815125\n",
      "Iteration 400, Loss: 8.014836930669844e-05, Min w: 0.7664873003959656\n",
      "Iteration 410, Loss: 8.516272646375e-05, Min w: 0.7676746845245361\n",
      "Iteration 420, Loss: 7.782344619045034e-05, Min w: 0.7928240299224854\n",
      "Iteration 430, Loss: 8.690002141520381e-05, Min w: 0.7673612833023071\n",
      "Iteration 440, Loss: 7.269015623023733e-05, Min w: 0.7958000302314758\n",
      "Iteration 450, Loss: 8.336118480656296e-05, Min w: 0.7502276301383972\n",
      "Iteration 460, Loss: 6.0924681747565046e-05, Min w: 0.8521390557289124\n",
      "Iteration 470, Loss: 7.029886182863265e-05, Min w: 0.8234720230102539\n",
      "Iteration 480, Loss: 7.794694101903588e-05, Min w: 0.7857502102851868\n",
      "Iteration 490, Loss: 4.418018943397328e-05, Min w: 0.897914469242096\n",
      "Iteration 500, Loss: 5.375261025619693e-05, Min w: 0.8590388894081116\n",
      "Iteration 510, Loss: 8.081845589913428e-05, Min w: 0.7741837501525879\n",
      "Iteration 520, Loss: 7.630952313775197e-05, Min w: 0.7932087779045105\n",
      "Iteration 530, Loss: 6.723141996189952e-05, Min w: 0.8384548425674438\n",
      "Iteration 540, Loss: 5.154822065378539e-05, Min w: 0.8670626878738403\n",
      "Iteration 550, Loss: 6.194572051754221e-05, Min w: 0.8418998122215271\n",
      "Iteration 560, Loss: 5.46614064660389e-05, Min w: 0.855989396572113\n",
      "Iteration 570, Loss: 6.072910036891699e-05, Min w: 0.8393356204032898\n",
      "Iteration 580, Loss: 5.5884276662254706e-05, Min w: 0.8535715937614441\n",
      "Iteration 590, Loss: 5.58779138373211e-05, Min w: 0.8542320728302002\n",
      "Iteration 600, Loss: 5.179336585570127e-05, Min w: 0.8703004121780396\n",
      "Iteration 610, Loss: 5.009174856240861e-05, Min w: 0.8664388060569763\n",
      "Iteration 620, Loss: 3.887279672198929e-05, Min w: 0.9052317142486572\n",
      "Iteration 630, Loss: 3.3512616937514395e-05, Min w: 0.9240654706954956\n",
      "Iteration 640, Loss: 4.1468607378192246e-05, Min w: 0.8924455046653748\n",
      "Iteration 650, Loss: 4.563789116218686e-05, Min w: 0.8903008103370667\n",
      "Iteration 660, Loss: 5.0864186050603166e-05, Min w: 0.8724159002304077\n",
      "Iteration 670, Loss: 6.591463898075745e-05, Min w: 0.8147440552711487\n",
      "Iteration 680, Loss: 6.792417843826115e-05, Min w: 0.8147252798080444\n",
      "Iteration 690, Loss: 8.990881906356663e-05, Min w: 0.7601406574249268\n",
      "Iteration 700, Loss: 6.747040606569499e-05, Min w: 0.8103951215744019\n",
      "Iteration 710, Loss: 5.480111940414645e-05, Min w: 0.8532376885414124\n",
      "Iteration 720, Loss: 6.812831270508468e-05, Min w: 0.8098334074020386\n",
      "Iteration 730, Loss: 6.628150003962219e-05, Min w: 0.8140250444412231\n",
      "Iteration 740, Loss: 7.202604319900274e-05, Min w: 0.8082830905914307\n",
      "Iteration 750, Loss: 5.850616071256809e-05, Min w: 0.8633362054824829\n",
      "Iteration 760, Loss: 8.591600635554641e-05, Min w: 0.7960619330406189\n",
      "Iteration 770, Loss: 6.256558845052496e-05, Min w: 0.8434897661209106\n",
      "Iteration 780, Loss: 0.0002812498132698238, Min w: 0.27433183789253235\n",
      "Iteration 790, Loss: 0.00015045666077639908, Min w: 0.5535350441932678\n",
      "Iteration 800, Loss: 0.00042129712528549135, Min w: 4.083947757749229e-08\n",
      "Iteration 810, Loss: 0.0004917588667012751, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0005080822156742215, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0004919542116113007, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0004921542131341994, Min w: 0.0\n",
      "Iteration 850, Loss: 0.00048980483552441, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0004122333484701812, Min w: 8.200733282137662e-05\n",
      "Iteration 870, Loss: 0.0004838554305024445, Min w: 1.3352631446274937e-13\n",
      "Iteration 880, Loss: 0.0004684396553784609, Min w: 1.2145234817850792e-10\n",
      "Iteration 890, Loss: 0.0004931316361762583, Min w: 1.0986108236465952e-06\n",
      "Iteration 900, Loss: 0.0005019361269660294, Min w: 1.6315401720617961e-12\n",
      "Iteration 910, Loss: 0.0004976104246452451, Min w: 2.7416208592928847e-29\n",
      "Iteration 920, Loss: 0.0004907192196696997, Min w: 0.0\n",
      "Iteration 930, Loss: 0.00047507142880931497, Min w: 0.01312428992241621\n",
      "Iteration 940, Loss: 0.0004938042256981134, Min w: 1.6190009402561323e-12\n",
      "Iteration 950, Loss: 0.0004868346732109785, Min w: 6.295369558984021e-09\n",
      "Iteration 960, Loss: 0.0004908020491711795, Min w: 4.976272519052749e-11\n",
      "Iteration 970, Loss: 0.00027036224491894245, Min w: 0.14602310955524445\n",
      "Iteration 980, Loss: 0.0004479054769035429, Min w: 0.001020018826238811\n",
      "Iteration 990, Loss: 0.00028716790257021785, Min w: 0.04683539643883705\n",
      "Iteration 1000, Loss: 0.00047912198351696134, Min w: 2.109111713402556e-12\n",
      "Iteration 1010, Loss: 0.0004914716701023281, Min w: 1.2372216390223092e-14\n",
      "Iteration 1020, Loss: 0.000494972278829664, Min w: 7.697687273307387e-38\n",
      "Iteration 1030, Loss: 0.0004916558973491192, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0004946698900312185, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0005119353299960494, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.000506042328197509, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.000528200063854456, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0005124941817484796, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.000511947029735893, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0004920319188386202, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0004950332222506404, Min w: 2.512145005906241e-11\n",
      "Iteration 1120, Loss: 0.0005039130919612944, Min w: 2.738016772821707e-35\n",
      "Iteration 1130, Loss: 0.00047344446647912264, Min w: 6.824151799200706e-10\n",
      "Iteration 1140, Loss: 0.00030671432614326477, Min w: 0.2631133794784546\n",
      "Iteration 1150, Loss: 0.0002915521909017116, Min w: 0.2609206736087799\n",
      "Iteration 1160, Loss: 0.00048517706454731524, Min w: 1.1178464837807711e-12\n",
      "Iteration 1170, Loss: 0.0004761579621117562, Min w: 1.9172626577843857e-29\n",
      "Iteration 1180, Loss: 0.0004901688080281019, Min w: 1.469054495828459e-07\n",
      "Iteration 1190, Loss: 0.0004919185885228217, Min w: 2.3565011995120557e-22\n",
      "Iteration 1200, Loss: 0.0004940063809044659, Min w: 3.493773326201932e-11\n",
      "Iteration 1210, Loss: 0.0004951484152115881, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0004953898605890572, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0004914310993626714, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  17%|█▋        | 4/24 [06:09<30:43, 92.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.0004950878792442381, Min w: 2.9401061851785926e-07\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.06661771922346252, 'L2_avg': 0.08217017013119307, 'End_point_L1_avg': 0.10728508052824177, 'End_point_L2_avg': 0.11905728814766849}\n",
      "Iteration 0, Loss: 0.003907974809408188, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0038888799026608467, Min w: 1.0101599556833207e-08\n",
      "Iteration 20, Loss: 0.003625234356150031, Min w: 9.681323717813939e-06\n",
      "Iteration 30, Loss: 0.0032079557422548532, Min w: 1.3320367543201428e-05\n",
      "Iteration 40, Loss: 0.0029130256734788418, Min w: 2.3616714315721765e-05\n",
      "Iteration 50, Loss: 0.002747061662375927, Min w: 9.584181270838599e-07\n",
      "Iteration 60, Loss: 0.002606923459097743, Min w: 1.2449383746115927e-07\n",
      "Iteration 70, Loss: 0.002477162517607212, Min w: 3.6745440024077425e-09\n",
      "Iteration 80, Loss: 0.0023845143150538206, Min w: 3.35361821646174e-10\n",
      "Iteration 90, Loss: 0.0022786487825214863, Min w: 2.578000139752401e-11\n",
      "Iteration 100, Loss: 0.002237608889117837, Min w: 5.457270052522389e-12\n",
      "Iteration 110, Loss: 0.0021013023797422647, Min w: 3.214789274629676e-13\n",
      "Iteration 120, Loss: 0.002075802767649293, Min w: 5.357137259839884e-13\n",
      "Iteration 130, Loss: 0.0020294447895139456, Min w: 6.308855347858522e-13\n",
      "Iteration 140, Loss: 0.0019919811747968197, Min w: 4.8910628151765945e-12\n",
      "Iteration 150, Loss: 0.0020073868799954653, Min w: 3.292008679545155e-11\n",
      "Iteration 160, Loss: 0.001983057474717498, Min w: 7.397496837313611e-09\n",
      "Iteration 170, Loss: 0.0019422186305746436, Min w: 3.4380946090095676e-06\n",
      "Iteration 180, Loss: 0.0020020960364490747, Min w: 0.0008304216898977757\n",
      "Iteration 190, Loss: 0.002078387886285782, Min w: 0.046198852360248566\n",
      "Iteration 200, Loss: 0.0017676742281764746, Min w: 0.024088269099593163\n",
      "Iteration 210, Loss: 0.0017497226363047957, Min w: 0.05452367663383484\n",
      "Iteration 220, Loss: 0.0017388385022059083, Min w: 0.08223957568407059\n",
      "Iteration 230, Loss: 0.0016574913170188665, Min w: 0.127947136759758\n",
      "Iteration 240, Loss: 0.001616723951883614, Min w: 0.1361839771270752\n",
      "Iteration 250, Loss: 0.0015790225006639957, Min w: 0.15885786712169647\n",
      "Iteration 260, Loss: 0.0015354376519098878, Min w: 0.18124619126319885\n",
      "Iteration 270, Loss: 0.0015041662845760584, Min w: 0.1849292665719986\n",
      "Iteration 280, Loss: 0.001506560598500073, Min w: 0.20111073553562164\n",
      "Iteration 290, Loss: 0.0014823578530922532, Min w: 0.2116200476884842\n",
      "Iteration 300, Loss: 0.001424127258360386, Min w: 0.22154982388019562\n",
      "Iteration 310, Loss: 0.001312931883148849, Min w: 0.24174730479717255\n",
      "Iteration 320, Loss: 0.0013217214727774262, Min w: 0.23476314544677734\n",
      "Iteration 330, Loss: 0.001278204726986587, Min w: 0.2585313320159912\n",
      "Iteration 340, Loss: 0.001267939805984497, Min w: 0.2621943950653076\n",
      "Iteration 350, Loss: 0.0012364673893898726, Min w: 0.2791995704174042\n",
      "Iteration 360, Loss: 0.0011725036893039942, Min w: 0.2989550232887268\n",
      "Iteration 370, Loss: 0.0012120796600356698, Min w: 0.30018189549446106\n",
      "Iteration 380, Loss: 0.001166168018244207, Min w: 0.32501494884490967\n",
      "Iteration 390, Loss: 0.0011151657672598958, Min w: 0.33348989486694336\n",
      "Iteration 400, Loss: 0.001147103845141828, Min w: 0.3358725607395172\n",
      "Iteration 410, Loss: 0.001048967125825584, Min w: 0.370572030544281\n",
      "Iteration 420, Loss: 0.0011147373588755727, Min w: 0.3599760830402374\n",
      "Iteration 430, Loss: 0.0010705901077017188, Min w: 0.3754705786705017\n",
      "Iteration 440, Loss: 0.0010085490066558123, Min w: 0.3854376971721649\n",
      "Iteration 450, Loss: 0.0010015065781772137, Min w: 0.39641687273979187\n",
      "Iteration 460, Loss: 0.0010350254597142339, Min w: 0.39164090156555176\n",
      "Iteration 470, Loss: 0.0009530484676361084, Min w: 0.4113900065422058\n",
      "Iteration 480, Loss: 0.0009809028124436736, Min w: 0.40078601241111755\n",
      "Iteration 490, Loss: 0.0009661898366175592, Min w: 0.42754167318344116\n",
      "Iteration 500, Loss: 0.0009474848047830164, Min w: 0.416798859834671\n",
      "Iteration 510, Loss: 0.0009048787760548294, Min w: 0.45954129099845886\n",
      "Iteration 520, Loss: 0.0008943805587477982, Min w: 0.44408103823661804\n",
      "Iteration 530, Loss: 0.0008993630181066692, Min w: 0.4537721872329712\n",
      "Iteration 540, Loss: 0.0008889635792002082, Min w: 0.4790235459804535\n",
      "Iteration 550, Loss: 0.0008510115440003574, Min w: 0.49087032675743103\n",
      "Iteration 560, Loss: 0.0008147557382471859, Min w: 0.503205418586731\n",
      "Iteration 570, Loss: 0.0008273300481960177, Min w: 0.4884614050388336\n",
      "Iteration 580, Loss: 0.0007870420813560486, Min w: 0.5092273950576782\n",
      "Iteration 590, Loss: 0.0008068874594755471, Min w: 0.5170918703079224\n",
      "Iteration 600, Loss: 0.0007884978549554944, Min w: 0.5249741077423096\n",
      "Iteration 610, Loss: 0.0007576541393063962, Min w: 0.5037561655044556\n",
      "Iteration 620, Loss: 0.0007652293425053358, Min w: 0.5179430246353149\n",
      "Iteration 630, Loss: 0.0007470224518328905, Min w: 0.5437657833099365\n",
      "Iteration 640, Loss: 0.0007901827339082956, Min w: 0.5191406607627869\n",
      "Iteration 650, Loss: 0.000714791240170598, Min w: 0.5639143586158752\n",
      "Iteration 660, Loss: 0.0007071546278893948, Min w: 0.560232937335968\n",
      "Iteration 670, Loss: 0.0006718284566886723, Min w: 0.5799396634101868\n",
      "Iteration 680, Loss: 0.0007633086061105132, Min w: 0.5657210946083069\n",
      "Iteration 690, Loss: 0.0006949473172426224, Min w: 0.5614483952522278\n",
      "Iteration 700, Loss: 0.0006589622935280204, Min w: 0.5893024802207947\n",
      "Iteration 710, Loss: 0.0006702129612676799, Min w: 0.5962328910827637\n",
      "Iteration 720, Loss: 0.0006564942304976285, Min w: 0.5863725543022156\n",
      "Iteration 730, Loss: 0.0006307451985776424, Min w: 0.6122077703475952\n",
      "Iteration 740, Loss: 0.0006372593925334513, Min w: 0.5859434604644775\n",
      "Iteration 750, Loss: 0.0006178001058287919, Min w: 0.5984154939651489\n",
      "Iteration 760, Loss: 0.0006120529724285007, Min w: 0.6219775080680847\n",
      "Iteration 770, Loss: 0.0006341571570374072, Min w: 0.6100072264671326\n",
      "Iteration 780, Loss: 0.0006182888755574822, Min w: 0.6207823753356934\n",
      "Iteration 790, Loss: 0.0005837702192366123, Min w: 0.6279644966125488\n",
      "Iteration 800, Loss: 0.0005707366508431733, Min w: 0.6282840967178345\n",
      "Iteration 810, Loss: 0.0005512090283446014, Min w: 0.6357901096343994\n",
      "Iteration 820, Loss: 0.0005549627239815891, Min w: 0.6463711857795715\n",
      "Iteration 830, Loss: 0.0005649228696711361, Min w: 0.6276427507400513\n",
      "Iteration 840, Loss: 0.0005524964071810246, Min w: 0.6444960832595825\n",
      "Iteration 850, Loss: 0.0005372187006287277, Min w: 0.6406140327453613\n",
      "Iteration 860, Loss: 0.0005405788542702794, Min w: 0.6385573744773865\n",
      "Iteration 870, Loss: 0.000519456050824374, Min w: 0.6675968766212463\n",
      "Iteration 880, Loss: 0.0005402234965004027, Min w: 0.6615269184112549\n",
      "Iteration 890, Loss: 0.0004925320972688496, Min w: 0.6739042401313782\n",
      "Iteration 900, Loss: 0.0005024336860515177, Min w: 0.6746985912322998\n",
      "Iteration 910, Loss: 0.0005202391184866428, Min w: 0.6648544669151306\n",
      "Iteration 920, Loss: 0.0004983553662896156, Min w: 0.6693711280822754\n",
      "Iteration 930, Loss: 0.0005014257039874792, Min w: 0.6864598393440247\n",
      "Iteration 940, Loss: 0.00047231477219611406, Min w: 0.6882852911949158\n",
      "Iteration 950, Loss: 0.00047356425784528255, Min w: 0.6706722974777222\n",
      "Iteration 960, Loss: 0.00045603388571180403, Min w: 0.6928985118865967\n",
      "Iteration 970, Loss: 0.00048206030623987317, Min w: 0.6781625747680664\n",
      "Iteration 980, Loss: 0.00047039915807545185, Min w: 0.6967085003852844\n",
      "Iteration 990, Loss: 0.00044555339263752103, Min w: 0.7082956433296204\n",
      "Iteration 1000, Loss: 0.00045411824248731136, Min w: 0.7092518210411072\n",
      "Iteration 1010, Loss: 0.0004589182499330491, Min w: 0.6938907504081726\n",
      "Iteration 1020, Loss: 0.00044082841486670077, Min w: 0.703801691532135\n",
      "Iteration 1030, Loss: 0.00044373259879648685, Min w: 0.7095516324043274\n",
      "Iteration 1040, Loss: 0.00043728461605496705, Min w: 0.7134049534797668\n",
      "Iteration 1050, Loss: 0.0004106435808353126, Min w: 0.725956380367279\n",
      "Iteration 1060, Loss: 0.00043114591971971095, Min w: 0.715067446231842\n",
      "Iteration 1070, Loss: 0.0004171259643044323, Min w: 0.717298150062561\n",
      "Iteration 1080, Loss: 0.0004039446066599339, Min w: 0.7253846526145935\n",
      "Iteration 1090, Loss: 0.00040376605466008186, Min w: 0.7378239631652832\n",
      "Iteration 1100, Loss: 0.0004188154707662761, Min w: 0.7334027886390686\n",
      "Iteration 1110, Loss: 0.00040030881064012647, Min w: 0.7234799265861511\n",
      "Iteration 1120, Loss: 0.0003998326137661934, Min w: 0.7211332321166992\n",
      "Iteration 1130, Loss: 0.0003893801767844707, Min w: 0.7460870742797852\n",
      "Iteration 1140, Loss: 0.00037751131458207965, Min w: 0.7491505146026611\n",
      "Iteration 1150, Loss: 0.000418742245528847, Min w: 0.7431904673576355\n",
      "Iteration 1160, Loss: 0.0003829224151559174, Min w: 0.7537818551063538\n",
      "Iteration 1170, Loss: 0.00039403143455274403, Min w: 0.7590888142585754\n",
      "Iteration 1180, Loss: 0.00037994750891812146, Min w: 0.7534215450286865\n",
      "Iteration 1190, Loss: 0.0003690776356961578, Min w: 0.764606773853302\n",
      "Iteration 1200, Loss: 0.00034265450085513294, Min w: 0.7732959985733032\n",
      "Iteration 1210, Loss: 0.00035545119317248464, Min w: 0.7646574378013611\n",
      "Iteration 1220, Loss: 0.0003369318728800863, Min w: 0.7737164497375488\n",
      "Iteration 1230, Loss: 0.00035824536462314427, Min w: 0.7799494862556458\n",
      "Iteration 1240, Loss: 0.00035852810833603144, Min w: 0.7721184492111206\n",
      "Iteration 0, Loss: 0.00033252392313443124, Min w: 0.7743896842002869\n",
      "Iteration 10, Loss: 0.00033277313923463225, Min w: 0.788372278213501\n",
      "Iteration 20, Loss: 0.0003277531359344721, Min w: 0.7923244833946228\n",
      "Iteration 30, Loss: 0.00032517610816285014, Min w: 0.7826052308082581\n",
      "Iteration 40, Loss: 0.0003225863038096577, Min w: 0.787756085395813\n",
      "Iteration 50, Loss: 0.000320626626489684, Min w: 0.7950050234794617\n",
      "Iteration 60, Loss: 0.00033920578425750136, Min w: 0.7951693534851074\n",
      "Iteration 70, Loss: 0.0003109596436843276, Min w: 0.7995255589485168\n",
      "Iteration 80, Loss: 0.00031947658862918615, Min w: 0.7968859076499939\n",
      "Iteration 90, Loss: 0.0002920349361374974, Min w: 0.8146052360534668\n",
      "Iteration 100, Loss: 0.00028273771749809384, Min w: 0.8151847720146179\n",
      "Iteration 110, Loss: 0.00029155623633414507, Min w: 0.8142359852790833\n",
      "Iteration 120, Loss: 0.0002911557094193995, Min w: 0.8137324452400208\n",
      "Iteration 130, Loss: 0.00027678062906488776, Min w: 0.8202149271965027\n",
      "Iteration 140, Loss: 0.00028366100741550326, Min w: 0.8229182958602905\n",
      "Iteration 150, Loss: 0.0002654086274560541, Min w: 0.8265567421913147\n",
      "Iteration 160, Loss: 0.00028397885034792125, Min w: 0.8110859990119934\n",
      "Iteration 170, Loss: 0.000260869535850361, Min w: 0.8320212364196777\n",
      "Iteration 180, Loss: 0.0002809052530210465, Min w: 0.8183410167694092\n",
      "Iteration 190, Loss: 0.00025999912759289145, Min w: 0.8327376246452332\n",
      "Iteration 200, Loss: 0.0002578762941993773, Min w: 0.8360352516174316\n",
      "Iteration 210, Loss: 0.00027296022744849324, Min w: 0.8239450454711914\n",
      "Iteration 220, Loss: 0.00027248013066127896, Min w: 0.8342985510826111\n",
      "Iteration 230, Loss: 0.000302940170513466, Min w: 0.825014591217041\n",
      "Iteration 240, Loss: 0.00032418061164207757, Min w: 0.8244567513465881\n",
      "Iteration 250, Loss: 0.0002446423750370741, Min w: 0.8416140675544739\n",
      "Iteration 260, Loss: 0.00025959339109249413, Min w: 0.8387266397476196\n",
      "Iteration 270, Loss: 0.00024800116079859436, Min w: 0.8432285189628601\n",
      "Iteration 280, Loss: 0.0002388905850239098, Min w: 0.8432033658027649\n",
      "Iteration 290, Loss: 0.0002477864909451455, Min w: 0.8477559089660645\n",
      "Iteration 300, Loss: 0.00025518183247186244, Min w: 0.845922589302063\n",
      "Iteration 310, Loss: 0.00022848747903481126, Min w: 0.850140392780304\n",
      "Iteration 320, Loss: 0.0002546844771131873, Min w: 0.8377813100814819\n",
      "Iteration 330, Loss: 0.00023384149244520813, Min w: 0.8577383160591125\n",
      "Iteration 340, Loss: 0.00025249001919291914, Min w: 0.8460346460342407\n",
      "Iteration 350, Loss: 0.00023444990802090615, Min w: 0.8526517152786255\n",
      "Iteration 360, Loss: 0.00022231946059037, Min w: 0.8659939765930176\n",
      "Iteration 370, Loss: 0.00023716306895948946, Min w: 0.848450243473053\n",
      "Iteration 380, Loss: 0.000235118975979276, Min w: 0.8616458773612976\n",
      "Iteration 390, Loss: 0.00024514252436347306, Min w: 0.85469651222229\n",
      "Iteration 400, Loss: 0.0002376667398493737, Min w: 0.8613565564155579\n",
      "Iteration 410, Loss: 0.00022982624068390578, Min w: 0.8649628758430481\n",
      "Iteration 420, Loss: 0.00020878494251519442, Min w: 0.8624979853630066\n",
      "Iteration 430, Loss: 0.00023720772878732532, Min w: 0.8631728887557983\n",
      "Iteration 440, Loss: 0.00022971486032474786, Min w: 0.8653550148010254\n",
      "Iteration 450, Loss: 0.0002182214957429096, Min w: 0.8574833869934082\n",
      "Iteration 460, Loss: 0.00021151622058823705, Min w: 0.8728154301643372\n",
      "Iteration 470, Loss: 0.0002196084096794948, Min w: 0.865014374256134\n",
      "Iteration 480, Loss: 0.00020698938169516623, Min w: 0.8762362003326416\n",
      "Iteration 490, Loss: 0.00021198138711042702, Min w: 0.8696427345275879\n",
      "Iteration 500, Loss: 0.00021448270126711577, Min w: 0.8817663788795471\n",
      "Iteration 510, Loss: 0.00021013704827055335, Min w: 0.8684326410293579\n",
      "Iteration 520, Loss: 0.0001998705993173644, Min w: 0.8825607895851135\n",
      "Iteration 530, Loss: 0.0002035075449384749, Min w: 0.8780751824378967\n",
      "Iteration 540, Loss: 0.00019795385014731437, Min w: 0.8781176209449768\n",
      "Iteration 550, Loss: 0.00018988554074894637, Min w: 0.8827977776527405\n",
      "Iteration 560, Loss: 0.00021567789372056723, Min w: 0.8775256872177124\n",
      "Iteration 570, Loss: 0.00019853310368489474, Min w: 0.8855416774749756\n",
      "Iteration 580, Loss: 0.00019249966135248542, Min w: 0.8811508417129517\n",
      "Iteration 590, Loss: 0.000189070007763803, Min w: 0.8874647617340088\n",
      "Iteration 600, Loss: 0.0001881026109913364, Min w: 0.8888742327690125\n",
      "Iteration 610, Loss: 0.0001763518521329388, Min w: 0.8920511603355408\n",
      "Iteration 620, Loss: 0.0001846526429289952, Min w: 0.888659656047821\n",
      "Iteration 630, Loss: 0.00018230846035294235, Min w: 0.8947456479072571\n",
      "Iteration 640, Loss: 0.00017045270942617208, Min w: 0.8907811045646667\n",
      "Iteration 650, Loss: 0.00018331652972847223, Min w: 0.879666805267334\n",
      "Iteration 660, Loss: 0.00018278032075613737, Min w: 0.890062689781189\n",
      "Iteration 670, Loss: 0.00017270055832341313, Min w: 0.8907792568206787\n",
      "Iteration 680, Loss: 0.00018790614558383822, Min w: 0.8836007714271545\n",
      "Iteration 690, Loss: 0.00017592454969417304, Min w: 0.8903325200080872\n",
      "Iteration 700, Loss: 0.0001945647964021191, Min w: 0.8861544132232666\n",
      "Iteration 710, Loss: 0.00017377629410475492, Min w: 0.8924325108528137\n",
      "Iteration 720, Loss: 0.0001685814349912107, Min w: 0.8965939879417419\n",
      "Iteration 730, Loss: 0.0001779320155037567, Min w: 0.8945891261100769\n",
      "Iteration 740, Loss: 0.00016765529289841652, Min w: 0.8966464400291443\n",
      "Iteration 750, Loss: 0.000191185885341838, Min w: 0.8955402970314026\n",
      "Iteration 760, Loss: 0.00017123032012023032, Min w: 0.8943501114845276\n",
      "Iteration 770, Loss: 0.00017010878946166486, Min w: 0.9027066826820374\n",
      "Iteration 780, Loss: 0.00018846782040782273, Min w: 0.8917809724807739\n",
      "Iteration 790, Loss: 0.0001869731058832258, Min w: 0.8965622186660767\n",
      "Iteration 800, Loss: 0.00015834177611395717, Min w: 0.9054646492004395\n",
      "Iteration 810, Loss: 0.00016011082334443927, Min w: 0.8989751935005188\n",
      "Iteration 820, Loss: 0.0001597608206793666, Min w: 0.9031237363815308\n",
      "Iteration 830, Loss: 0.00016518079792149365, Min w: 0.8970474600791931\n",
      "Iteration 840, Loss: 0.0001543808466522023, Min w: 0.9038988351821899\n",
      "Iteration 850, Loss: 0.00017441558884456754, Min w: 0.9077199697494507\n",
      "Iteration 860, Loss: 0.0001636553934076801, Min w: 0.9084039330482483\n",
      "Iteration 870, Loss: 0.00022287777392193675, Min w: 0.8856214284896851\n",
      "Iteration 880, Loss: 0.00016990644508041441, Min w: 0.9040419459342957\n",
      "Iteration 890, Loss: 0.00015961773169692606, Min w: 0.9009546637535095\n",
      "Iteration 900, Loss: 0.0001538639480713755, Min w: 0.9092330932617188\n",
      "Iteration 910, Loss: 0.0001653390791034326, Min w: 0.9047985076904297\n",
      "Iteration 920, Loss: 0.00014282208576332778, Min w: 0.9070314764976501\n",
      "Iteration 930, Loss: 0.00014470976020675153, Min w: 0.9091683030128479\n",
      "Iteration 940, Loss: 0.00015886659093666822, Min w: 0.9067035913467407\n",
      "Iteration 950, Loss: 0.0001460878411307931, Min w: 0.9089460372924805\n",
      "Iteration 960, Loss: 0.00014587593614123762, Min w: 0.9096032381057739\n",
      "Iteration 970, Loss: 0.00014692323748022318, Min w: 0.9088110327720642\n",
      "Iteration 980, Loss: 0.0001490686263423413, Min w: 0.9090371131896973\n",
      "Iteration 990, Loss: 0.00014614111569244415, Min w: 0.9123895764350891\n",
      "Iteration 1000, Loss: 0.00014937353262212127, Min w: 0.9113218188285828\n",
      "Iteration 1010, Loss: 0.00013936980394646525, Min w: 0.9178820252418518\n",
      "Iteration 1020, Loss: 0.00014987470058258623, Min w: 0.9082463383674622\n",
      "Iteration 1030, Loss: 0.00013924234372098, Min w: 0.9141396880149841\n",
      "Iteration 1040, Loss: 0.0001425761729478836, Min w: 0.9166824221611023\n",
      "Iteration 1050, Loss: 0.00015420645650010556, Min w: 0.9112536311149597\n",
      "Iteration 1060, Loss: 0.00015402612916659564, Min w: 0.9120784997940063\n",
      "Iteration 1070, Loss: 0.00013628645683638752, Min w: 0.9206510782241821\n",
      "Iteration 1080, Loss: 0.0001419481122866273, Min w: 0.9164169430732727\n",
      "Iteration 1090, Loss: 0.00013750338985119015, Min w: 0.916586697101593\n",
      "Iteration 1100, Loss: 0.00013979105278849602, Min w: 0.9195083975791931\n",
      "Iteration 1110, Loss: 0.00014647851639892906, Min w: 0.9083106517791748\n",
      "Iteration 1120, Loss: 0.00014136594836600125, Min w: 0.9198834300041199\n",
      "Iteration 1130, Loss: 0.00013739279529545456, Min w: 0.9190571904182434\n",
      "Iteration 1140, Loss: 0.00013267682516016066, Min w: 0.9163380265235901\n",
      "Iteration 1150, Loss: 0.00013744548778049648, Min w: 0.9184096455574036\n",
      "Iteration 1160, Loss: 0.0001459174236515537, Min w: 0.9128233194351196\n",
      "Iteration 1170, Loss: 0.0001416145678376779, Min w: 0.9190918803215027\n",
      "Iteration 1180, Loss: 0.00013332975504454225, Min w: 0.9206900000572205\n",
      "Iteration 1190, Loss: 0.00012429065827745944, Min w: 0.9294228553771973\n",
      "Iteration 1200, Loss: 0.00013238588871899992, Min w: 0.917683482170105\n",
      "Iteration 1210, Loss: 0.00013753899838775396, Min w: 0.9132832884788513\n",
      "Iteration 1220, Loss: 0.00012339491513557732, Min w: 0.9193541407585144\n",
      "Iteration 1230, Loss: 0.0001268283958779648, Min w: 0.9233420491218567\n",
      "Iteration 1240, Loss: 0.00013422204938251525, Min w: 0.9213629364967346\n",
      "Iteration 0, Loss: 0.00013963108358439058, Min w: 0.9206550121307373\n",
      "Iteration 10, Loss: 0.00014137914695311338, Min w: 0.9165940880775452\n",
      "Iteration 20, Loss: 0.00013437472807709128, Min w: 0.9211264848709106\n",
      "Iteration 30, Loss: 0.00012352931662462652, Min w: 0.9261232018470764\n",
      "Iteration 40, Loss: 0.00013062835205346346, Min w: 0.9176007509231567\n",
      "Iteration 50, Loss: 0.00012363922724034637, Min w: 0.9279289841651917\n",
      "Iteration 60, Loss: 0.00013036544260103256, Min w: 0.9230849742889404\n",
      "Iteration 70, Loss: 0.00013727316400036216, Min w: 0.9183487296104431\n",
      "Iteration 80, Loss: 0.00012146520748501644, Min w: 0.9276096820831299\n",
      "Iteration 90, Loss: 0.00013936073810327798, Min w: 0.9255592823028564\n",
      "Iteration 100, Loss: 0.00013105770631227642, Min w: 0.9236723184585571\n",
      "Iteration 110, Loss: 0.00011574077507248148, Min w: 0.9305821657180786\n",
      "Iteration 120, Loss: 0.0001228817127412185, Min w: 0.923590362071991\n",
      "Iteration 130, Loss: 0.00011849559814436361, Min w: 0.9310595989227295\n",
      "Iteration 140, Loss: 0.00011725008516805246, Min w: 0.926652729511261\n",
      "Iteration 150, Loss: 0.00012684780813287944, Min w: 0.9237912893295288\n",
      "Iteration 160, Loss: 0.00012780982069671154, Min w: 0.9237869381904602\n",
      "Iteration 170, Loss: 0.00011325972445774823, Min w: 0.9338386654853821\n",
      "Iteration 180, Loss: 0.00011201894812984392, Min w: 0.9311361312866211\n",
      "Iteration 190, Loss: 0.00011949596955673769, Min w: 0.9289154410362244\n",
      "Iteration 200, Loss: 0.00012099599553039297, Min w: 0.9339017271995544\n",
      "Iteration 210, Loss: 0.00011185578478034586, Min w: 0.9338632822036743\n",
      "Iteration 220, Loss: 0.00011809800344053656, Min w: 0.9295992851257324\n",
      "Iteration 230, Loss: 0.00012686154514085501, Min w: 0.9229324460029602\n",
      "Iteration 240, Loss: 0.00011457761138444766, Min w: 0.9310029745101929\n",
      "Iteration 250, Loss: 0.00011008972796844319, Min w: 0.9358287453651428\n",
      "Iteration 260, Loss: 0.00011482409172458574, Min w: 0.9369640946388245\n",
      "Iteration 270, Loss: 0.00011279090540483594, Min w: 0.9312300086021423\n",
      "Iteration 280, Loss: 0.00011232831457164139, Min w: 0.9338871240615845\n",
      "Iteration 290, Loss: 0.00011295660078758374, Min w: 0.9324305057525635\n",
      "Iteration 300, Loss: 0.00012234576570335776, Min w: 0.9303220510482788\n",
      "Iteration 310, Loss: 0.00011420775990700349, Min w: 0.930692195892334\n",
      "Iteration 320, Loss: 0.00011280716717010364, Min w: 0.9337314963340759\n",
      "Iteration 330, Loss: 0.0001388461678288877, Min w: 0.9280180335044861\n",
      "Iteration 340, Loss: 0.00012372904166113585, Min w: 0.9312759041786194\n",
      "Iteration 350, Loss: 0.00011722068302333355, Min w: 0.9311930537223816\n",
      "Iteration 360, Loss: 0.00011705138604156673, Min w: 0.9355445504188538\n",
      "Iteration 370, Loss: 0.0001547152060084045, Min w: 0.9121148586273193\n",
      "Iteration 380, Loss: 0.00012307334691286087, Min w: 0.9268206357955933\n",
      "Iteration 390, Loss: 0.00011680943134706467, Min w: 0.9324765205383301\n",
      "Iteration 400, Loss: 9.955248242476955e-05, Min w: 0.9409659504890442\n",
      "Iteration 410, Loss: 0.00011714157881215215, Min w: 0.937027633190155\n",
      "Iteration 420, Loss: 0.00011578003613976762, Min w: 0.9358341097831726\n",
      "Iteration 430, Loss: 0.0001164822606369853, Min w: 0.937103807926178\n",
      "Iteration 440, Loss: 0.00010946058318950236, Min w: 0.93239426612854\n",
      "Iteration 450, Loss: 0.00011622064630500972, Min w: 0.9362357258796692\n",
      "Iteration 460, Loss: 9.898080315906554e-05, Min w: 0.942572295665741\n",
      "Iteration 470, Loss: 0.00010591543832561001, Min w: 0.9399104118347168\n",
      "Iteration 480, Loss: 0.00012296740896999836, Min w: 0.9329359531402588\n",
      "Iteration 490, Loss: 0.00011387905396986753, Min w: 0.9369819760322571\n",
      "Iteration 500, Loss: 0.00011146023462060839, Min w: 0.9406313300132751\n",
      "Iteration 510, Loss: 0.00010236380330752581, Min w: 0.9359632134437561\n",
      "Iteration 520, Loss: 9.298342047259212e-05, Min w: 0.9471517205238342\n",
      "Iteration 530, Loss: 0.00010123886750079691, Min w: 0.9387140870094299\n",
      "Iteration 540, Loss: 0.00010636980732670054, Min w: 0.9431585669517517\n",
      "Iteration 550, Loss: 0.00010583265247987583, Min w: 0.9402626752853394\n",
      "Iteration 560, Loss: 0.00010040227061836049, Min w: 0.940768301486969\n",
      "Iteration 570, Loss: 0.00010589831799734384, Min w: 0.9363844394683838\n",
      "Iteration 580, Loss: 9.632587170926854e-05, Min w: 0.9424371719360352\n",
      "Iteration 590, Loss: 0.00010468103573657572, Min w: 0.9373003840446472\n",
      "Iteration 600, Loss: 9.857268014457077e-05, Min w: 0.9413223266601562\n",
      "Iteration 610, Loss: 0.00010990245209541172, Min w: 0.9383289217948914\n",
      "Iteration 620, Loss: 0.00011973574146395549, Min w: 0.9365161061286926\n",
      "Iteration 630, Loss: 9.698779467726126e-05, Min w: 0.9454108476638794\n",
      "Iteration 640, Loss: 0.00010242636926705018, Min w: 0.9385791420936584\n",
      "Iteration 650, Loss: 0.00010143275721929967, Min w: 0.942055881023407\n",
      "Iteration 660, Loss: 0.00010060556815005839, Min w: 0.9423931837081909\n",
      "Iteration 670, Loss: 9.707735443953425e-05, Min w: 0.9468514919281006\n",
      "Iteration 680, Loss: 9.183169458992779e-05, Min w: 0.9492250680923462\n",
      "Iteration 690, Loss: 9.971595864044502e-05, Min w: 0.9449248909950256\n",
      "Iteration 700, Loss: 0.00010523354285396636, Min w: 0.9390369057655334\n",
      "Iteration 710, Loss: 0.00010524314711801708, Min w: 0.9453495740890503\n",
      "Iteration 720, Loss: 0.0001117517240345478, Min w: 0.9416180849075317\n",
      "Iteration 730, Loss: 9.303807746618986e-05, Min w: 0.9462848901748657\n",
      "Iteration 740, Loss: 0.00010379815648775548, Min w: 0.9363245368003845\n",
      "Iteration 750, Loss: 0.00011248751252423972, Min w: 0.9398933053016663\n",
      "Iteration 760, Loss: 0.00010043343354482204, Min w: 0.9435922503471375\n",
      "Iteration 770, Loss: 0.00010104082321049646, Min w: 0.9477933049201965\n",
      "Iteration 780, Loss: 9.856052201939747e-05, Min w: 0.9435533881187439\n",
      "Iteration 790, Loss: 0.00010020907211583108, Min w: 0.9437152147293091\n",
      "Iteration 800, Loss: 0.0001046917968778871, Min w: 0.9449625611305237\n",
      "Iteration 810, Loss: 8.41894288896583e-05, Min w: 0.9492715001106262\n",
      "Iteration 820, Loss: 9.923352627083659e-05, Min w: 0.9417840242385864\n",
      "Iteration 830, Loss: 9.197696635965258e-05, Min w: 0.9463620781898499\n",
      "Iteration 840, Loss: 8.769003034103662e-05, Min w: 0.951371967792511\n",
      "Iteration 850, Loss: 9.11146416910924e-05, Min w: 0.9484765529632568\n",
      "Iteration 860, Loss: 9.673473687143996e-05, Min w: 0.9472554326057434\n",
      "Iteration 870, Loss: 8.809592691250145e-05, Min w: 0.9475036859512329\n",
      "Iteration 880, Loss: 8.928995521273464e-05, Min w: 0.9496899843215942\n",
      "Iteration 890, Loss: 9.240859071724117e-05, Min w: 0.9474841356277466\n",
      "Iteration 900, Loss: 8.494373469147831e-05, Min w: 0.9486415386199951\n",
      "Iteration 910, Loss: 9.122073970502242e-05, Min w: 0.9474853873252869\n",
      "Iteration 920, Loss: 8.85495901457034e-05, Min w: 0.9475906491279602\n",
      "Iteration 930, Loss: 9.16555873118341e-05, Min w: 0.9494892954826355\n",
      "Iteration 940, Loss: 9.245301771443337e-05, Min w: 0.9495490789413452\n",
      "Iteration 950, Loss: 9.388578473590314e-05, Min w: 0.9483476281166077\n",
      "Iteration 960, Loss: 8.835287007968873e-05, Min w: 0.9501658082008362\n",
      "Iteration 970, Loss: 9.072529064724222e-05, Min w: 0.9487295150756836\n",
      "Iteration 980, Loss: 8.54435347719118e-05, Min w: 0.9520329236984253\n",
      "Iteration 990, Loss: 8.59080973896198e-05, Min w: 0.9509406089782715\n",
      "Iteration 1000, Loss: 8.428803266724572e-05, Min w: 0.9502097964286804\n",
      "Iteration 1010, Loss: 8.859717490850016e-05, Min w: 0.9500322341918945\n",
      "Iteration 1020, Loss: 8.743420039536431e-05, Min w: 0.9497227072715759\n",
      "Iteration 1030, Loss: 8.988689660327509e-05, Min w: 0.9482368230819702\n",
      "Iteration 1040, Loss: 8.655407873447984e-05, Min w: 0.9508484601974487\n",
      "Iteration 1050, Loss: 9.1171583335381e-05, Min w: 0.9472985863685608\n",
      "Iteration 1060, Loss: 8.526278543286026e-05, Min w: 0.9521457552909851\n",
      "Iteration 1070, Loss: 8.49381904117763e-05, Min w: 0.9471445083618164\n",
      "Iteration 1080, Loss: 8.431517926510423e-05, Min w: 0.9526958465576172\n",
      "Iteration 1090, Loss: 8.547992183594033e-05, Min w: 0.9493960738182068\n",
      "Iteration 1100, Loss: 8.617380808573216e-05, Min w: 0.948492169380188\n",
      "Iteration 1110, Loss: 7.705079769948497e-05, Min w: 0.9532444477081299\n",
      "Iteration 1120, Loss: 8.418600191362202e-05, Min w: 0.9502803683280945\n",
      "Iteration 1130, Loss: 8.210875967051834e-05, Min w: 0.952046275138855\n",
      "Iteration 1140, Loss: 8.634555706521496e-05, Min w: 0.9478780627250671\n",
      "Iteration 1150, Loss: 8.456994692096487e-05, Min w: 0.9504052400588989\n",
      "Iteration 1160, Loss: 8.109842019621283e-05, Min w: 0.9508199691772461\n",
      "Iteration 1170, Loss: 7.96702443039976e-05, Min w: 0.9527034759521484\n",
      "Iteration 1180, Loss: 8.056194928940386e-05, Min w: 0.952239990234375\n",
      "Iteration 1190, Loss: 7.967941928654909e-05, Min w: 0.9544972777366638\n",
      "Iteration 1200, Loss: 8.07471587904729e-05, Min w: 0.9533411860466003\n",
      "Iteration 1210, Loss: 8.613208046881482e-05, Min w: 0.9528246521949768\n",
      "Iteration 1220, Loss: 8.054532372625545e-05, Min w: 0.9502846598625183\n",
      "Iteration 1230, Loss: 9.632500587031245e-05, Min w: 0.9488447904586792\n",
      "Iteration 1240, Loss: 8.178658754331991e-05, Min w: 0.9529868960380554\n",
      "Iteration 0, Loss: 8.616610284661874e-05, Min w: 0.9517533779144287\n",
      "Iteration 10, Loss: 8.072673517744988e-05, Min w: 0.952426552772522\n",
      "Iteration 20, Loss: 8.617788989795372e-05, Min w: 0.9555110335350037\n",
      "Iteration 30, Loss: 9.007102926261723e-05, Min w: 0.9532166123390198\n",
      "Iteration 40, Loss: 8.479636744596064e-05, Min w: 0.954633355140686\n",
      "Iteration 50, Loss: 7.322664168896154e-05, Min w: 0.9575138092041016\n",
      "Iteration 60, Loss: 9.04533444554545e-05, Min w: 0.9519347548484802\n",
      "Iteration 70, Loss: 7.465365342795849e-05, Min w: 0.9540543556213379\n",
      "Iteration 80, Loss: 7.827156514395028e-05, Min w: 0.9549500346183777\n",
      "Iteration 90, Loss: 7.501986692659557e-05, Min w: 0.9555241465568542\n",
      "Iteration 100, Loss: 7.464751979568973e-05, Min w: 0.9567654132843018\n",
      "Iteration 110, Loss: 7.296034164028242e-05, Min w: 0.9565327167510986\n",
      "Iteration 120, Loss: 7.64967844588682e-05, Min w: 0.9550768136978149\n",
      "Iteration 130, Loss: 8.306247764267027e-05, Min w: 0.9552094340324402\n",
      "Iteration 140, Loss: 7.435775478370488e-05, Min w: 0.9577959179878235\n",
      "Iteration 150, Loss: 8.061225526034832e-05, Min w: 0.952405571937561\n",
      "Iteration 160, Loss: 7.084640674293041e-05, Min w: 0.9569256901741028\n",
      "Iteration 170, Loss: 7.689068297622725e-05, Min w: 0.9554378390312195\n",
      "Iteration 180, Loss: 7.385279604932293e-05, Min w: 0.9556974768638611\n",
      "Iteration 190, Loss: 8.002352114999667e-05, Min w: 0.9558646082878113\n",
      "Iteration 200, Loss: 6.968784146010876e-05, Min w: 0.9586573839187622\n",
      "Iteration 210, Loss: 7.474846643162891e-05, Min w: 0.9560344815254211\n",
      "Iteration 220, Loss: 7.37012451281771e-05, Min w: 0.95639568567276\n",
      "Iteration 230, Loss: 7.563618419226259e-05, Min w: 0.9560744762420654\n",
      "Iteration 240, Loss: 7.94671504991129e-05, Min w: 0.9523253440856934\n",
      "Iteration 250, Loss: 7.871416164562106e-05, Min w: 0.9594833850860596\n",
      "Iteration 260, Loss: 7.687803008593619e-05, Min w: 0.9558297395706177\n",
      "Iteration 270, Loss: 7.431541598634794e-05, Min w: 0.9582950472831726\n",
      "Iteration 280, Loss: 8.376057667192072e-05, Min w: 0.955174446105957\n",
      "Iteration 290, Loss: 7.255582022480667e-05, Min w: 0.9574538469314575\n",
      "Iteration 300, Loss: 6.664410466328263e-05, Min w: 0.9606852531433105\n",
      "Iteration 310, Loss: 6.904901965754107e-05, Min w: 0.9599480628967285\n",
      "Iteration 320, Loss: 7.045311940601096e-05, Min w: 0.9572627544403076\n",
      "Iteration 330, Loss: 7.294337410712615e-05, Min w: 0.9576576948165894\n",
      "Iteration 340, Loss: 6.700077938148752e-05, Min w: 0.9599029421806335\n",
      "Iteration 350, Loss: 7.128284050850198e-05, Min w: 0.9575049877166748\n",
      "Iteration 360, Loss: 7.46041041566059e-05, Min w: 0.9598066806793213\n",
      "Iteration 370, Loss: 9.658180351834744e-05, Min w: 0.9441471695899963\n",
      "Iteration 380, Loss: 7.78411267674528e-05, Min w: 0.9573355913162231\n",
      "Iteration 390, Loss: 6.416682299459353e-05, Min w: 0.9602049589157104\n",
      "Iteration 400, Loss: 7.595642091473565e-05, Min w: 0.956779420375824\n",
      "Iteration 410, Loss: 7.7212302130647e-05, Min w: 0.9569100141525269\n",
      "Iteration 420, Loss: 6.763507553841919e-05, Min w: 0.9589690566062927\n",
      "Iteration 430, Loss: 7.494983583455905e-05, Min w: 0.9588685035705566\n",
      "Iteration 440, Loss: 6.393105286406353e-05, Min w: 0.9634971618652344\n",
      "Iteration 450, Loss: 6.369228503899649e-05, Min w: 0.9627626538276672\n",
      "Iteration 460, Loss: 7.37084774300456e-05, Min w: 0.9558538198471069\n",
      "Iteration 470, Loss: 7.037910108920187e-05, Min w: 0.9619367718696594\n",
      "Iteration 480, Loss: 6.993443821556866e-05, Min w: 0.9575843214988708\n",
      "Iteration 490, Loss: 0.00011152178922202438, Min w: 0.9354289174079895\n",
      "Iteration 500, Loss: 7.101728260749951e-05, Min w: 0.9626970291137695\n",
      "Iteration 510, Loss: 7.474834274034947e-05, Min w: 0.958909809589386\n",
      "Iteration 520, Loss: 6.514866254292428e-05, Min w: 0.9615013003349304\n",
      "Iteration 530, Loss: 7.421222107950598e-05, Min w: 0.9596801996231079\n",
      "Iteration 540, Loss: 8.924357825890183e-05, Min w: 0.9527218341827393\n",
      "Iteration 550, Loss: 6.370365736074746e-05, Min w: 0.9622823596000671\n",
      "Iteration 560, Loss: 6.452606612583622e-05, Min w: 0.96290522813797\n",
      "Iteration 570, Loss: 6.22777224634774e-05, Min w: 0.9638633131980896\n",
      "Iteration 580, Loss: 6.500470044557005e-05, Min w: 0.9609101414680481\n",
      "Iteration 590, Loss: 6.682844832539558e-05, Min w: 0.9592016339302063\n",
      "Iteration 600, Loss: 7.197436934802681e-05, Min w: 0.9590825438499451\n",
      "Iteration 610, Loss: 6.39800782664679e-05, Min w: 0.9623920917510986\n",
      "Iteration 620, Loss: 6.086368375690654e-05, Min w: 0.965707540512085\n",
      "Iteration 630, Loss: 6.33693634881638e-05, Min w: 0.9613760113716125\n",
      "Iteration 640, Loss: 7.226504385471344e-05, Min w: 0.9615957140922546\n",
      "Iteration 650, Loss: 6.24566018814221e-05, Min w: 0.9629797339439392\n",
      "Iteration 660, Loss: 6.327683513518423e-05, Min w: 0.9619831442832947\n",
      "Iteration 670, Loss: 6.272795144468546e-05, Min w: 0.9603496193885803\n",
      "Iteration 680, Loss: 6.051527816453017e-05, Min w: 0.9650728702545166\n",
      "Iteration 690, Loss: 6.0639340517809615e-05, Min w: 0.9640116691589355\n",
      "Iteration 700, Loss: 6.431746442103758e-05, Min w: 0.9633266925811768\n",
      "Iteration 710, Loss: 5.852459798916243e-05, Min w: 0.9639476537704468\n",
      "Iteration 720, Loss: 6.809961632825434e-05, Min w: 0.9620344042778015\n",
      "Iteration 730, Loss: 6.660421786364168e-05, Min w: 0.9625029563903809\n",
      "Iteration 740, Loss: 6.181924254633486e-05, Min w: 0.9658048152923584\n",
      "Iteration 750, Loss: 6.485132325906307e-05, Min w: 0.9646509885787964\n",
      "Iteration 760, Loss: 6.392494833562523e-05, Min w: 0.9611403942108154\n",
      "Iteration 770, Loss: 6.276370550040156e-05, Min w: 0.966118335723877\n",
      "Iteration 780, Loss: 6.134990690043196e-05, Min w: 0.9628337025642395\n",
      "Iteration 790, Loss: 6.42893064650707e-05, Min w: 0.9635363221168518\n",
      "Iteration 800, Loss: 6.0573704104172066e-05, Min w: 0.9654867649078369\n",
      "Iteration 810, Loss: 6.832014332758263e-05, Min w: 0.9630802273750305\n",
      "Iteration 820, Loss: 6.134078284958377e-05, Min w: 0.9653016924858093\n",
      "Iteration 830, Loss: 6.0371148720150813e-05, Min w: 0.9630441069602966\n",
      "Iteration 840, Loss: 5.5908345530042425e-05, Min w: 0.9674583673477173\n",
      "Iteration 850, Loss: 6.405175372492522e-05, Min w: 0.962364137172699\n",
      "Iteration 860, Loss: 6.476006819866598e-05, Min w: 0.9616920948028564\n",
      "Iteration 870, Loss: 6.746169674443081e-05, Min w: 0.963290810585022\n",
      "Iteration 880, Loss: 6.204939563758671e-05, Min w: 0.9616189002990723\n",
      "Iteration 890, Loss: 5.717020758311264e-05, Min w: 0.9671486020088196\n",
      "Iteration 900, Loss: 6.093469710322097e-05, Min w: 0.9668327569961548\n",
      "Iteration 910, Loss: 0.00011273588461335748, Min w: 0.929062008857727\n",
      "Iteration 920, Loss: 7.411057595163584e-05, Min w: 0.9598322510719299\n",
      "Iteration 930, Loss: 6.310548633337021e-05, Min w: 0.965680718421936\n",
      "Iteration 940, Loss: 5.6817425502231345e-05, Min w: 0.9664630889892578\n",
      "Iteration 950, Loss: 6.368499452946708e-05, Min w: 0.9636449217796326\n",
      "Iteration 960, Loss: 6.117374141467735e-05, Min w: 0.966862678527832\n",
      "Iteration 970, Loss: 5.756280734203756e-05, Min w: 0.9695310592651367\n",
      "Iteration 980, Loss: 5.639501250698231e-05, Min w: 0.9669739007949829\n",
      "Iteration 990, Loss: 6.012328594806604e-05, Min w: 0.9648410677909851\n",
      "Iteration 1000, Loss: 7.082202500896528e-05, Min w: 0.9623715877532959\n",
      "Iteration 1010, Loss: 6.288842268986627e-05, Min w: 0.9611777663230896\n",
      "Iteration 1020, Loss: 5.901418990106322e-05, Min w: 0.965683102607727\n",
      "Iteration 1030, Loss: 5.948902980890125e-05, Min w: 0.9673852920532227\n",
      "Iteration 1040, Loss: 6.02289401285816e-05, Min w: 0.9658604264259338\n",
      "Iteration 1050, Loss: 6.513520202133805e-05, Min w: 0.9630818963050842\n",
      "Iteration 1060, Loss: 6.123673665570095e-05, Min w: 0.9645877480506897\n",
      "Iteration 1070, Loss: 6.0786995163653046e-05, Min w: 0.9665780663490295\n",
      "Iteration 1080, Loss: 5.630345185636543e-05, Min w: 0.967705488204956\n",
      "Iteration 1090, Loss: 5.638401489704847e-05, Min w: 0.9676473140716553\n",
      "Iteration 1100, Loss: 7.045664824545383e-05, Min w: 0.963131308555603\n",
      "Iteration 1110, Loss: 5.4385309340432286e-05, Min w: 0.9674859642982483\n",
      "Iteration 1120, Loss: 5.555940151680261e-05, Min w: 0.9675522446632385\n",
      "Iteration 1130, Loss: 5.4486197768710554e-05, Min w: 0.9681745767593384\n",
      "Iteration 1140, Loss: 5.489160321303643e-05, Min w: 0.9665303826332092\n",
      "Iteration 1150, Loss: 7.470489072147757e-05, Min w: 0.9590299129486084\n",
      "Iteration 1160, Loss: 5.7096727687167004e-05, Min w: 0.9664938449859619\n",
      "Iteration 1170, Loss: 5.7568264310248196e-05, Min w: 0.9660022258758545\n",
      "Iteration 1180, Loss: 6.19003621977754e-05, Min w: 0.9664806723594666\n",
      "Iteration 1190, Loss: 6.11110299360007e-05, Min w: 0.9667177200317383\n",
      "Iteration 1200, Loss: 5.74142650293652e-05, Min w: 0.9678043127059937\n",
      "Iteration 1210, Loss: 5.303197758621536e-05, Min w: 0.9689211845397949\n",
      "Iteration 1220, Loss: 4.94563537358772e-05, Min w: 0.9707563519477844\n",
      "Iteration 1230, Loss: 6.497428694274276e-05, Min w: 0.9637190699577332\n",
      "Iteration 1240, Loss: 5.164679168956354e-05, Min w: 0.9696049094200134\n",
      "Iteration 0, Loss: 5.666106881108135e-05, Min w: 0.9679742455482483\n",
      "Iteration 10, Loss: 5.660951865138486e-05, Min w: 0.9656826257705688\n",
      "Iteration 20, Loss: 7.029027619864792e-05, Min w: 0.9630802869796753\n",
      "Iteration 30, Loss: 5.891087857889943e-05, Min w: 0.9677305221557617\n",
      "Iteration 40, Loss: 7.676840323256329e-05, Min w: 0.9602561593055725\n",
      "Iteration 50, Loss: 5.88595648878254e-05, Min w: 0.9668067693710327\n",
      "Iteration 60, Loss: 0.00011362321674823761, Min w: 0.9243514537811279\n",
      "Iteration 70, Loss: 5.4527878091903403e-05, Min w: 0.9666595458984375\n",
      "Iteration 80, Loss: 4.853130303672515e-05, Min w: 0.9710661768913269\n",
      "Iteration 90, Loss: 5.32029771420639e-05, Min w: 0.9684016108512878\n",
      "Iteration 100, Loss: 4.8371581215178594e-05, Min w: 0.9723600745201111\n",
      "Iteration 110, Loss: 5.033338675275445e-05, Min w: 0.9687508344650269\n",
      "Iteration 120, Loss: 6.022172237862833e-05, Min w: 0.9673104882240295\n",
      "Iteration 130, Loss: 5.148592754267156e-05, Min w: 0.9693396687507629\n",
      "Iteration 140, Loss: 5.460551619762555e-05, Min w: 0.9683074355125427\n",
      "Iteration 150, Loss: 5.439030428533442e-05, Min w: 0.9676370024681091\n",
      "Iteration 160, Loss: 5.6690671044634655e-05, Min w: 0.9697381854057312\n",
      "Iteration 170, Loss: 5.347649130271748e-05, Min w: 0.9674698710441589\n",
      "Iteration 180, Loss: 6.806191231589764e-05, Min w: 0.9621834754943848\n",
      "Iteration 190, Loss: 5.4101670684758574e-05, Min w: 0.9676846265792847\n",
      "Iteration 200, Loss: 5.2192743169143796e-05, Min w: 0.9718043804168701\n",
      "Iteration 210, Loss: 4.732013985631056e-05, Min w: 0.9706559777259827\n",
      "Iteration 220, Loss: 4.804891796084121e-05, Min w: 0.9693483114242554\n",
      "Iteration 230, Loss: 5.5832864745752886e-05, Min w: 0.9683228731155396\n",
      "Iteration 240, Loss: 4.635217192117125e-05, Min w: 0.9720478057861328\n",
      "Iteration 250, Loss: 5.5447151680709794e-05, Min w: 0.9699267148971558\n",
      "Iteration 260, Loss: 4.987362990505062e-05, Min w: 0.9685749411582947\n",
      "Iteration 270, Loss: 5.520957347471267e-05, Min w: 0.969223141670227\n",
      "Iteration 280, Loss: 5.261982005322352e-05, Min w: 0.9693565964698792\n",
      "Iteration 290, Loss: 4.9795493396231905e-05, Min w: 0.9719134569168091\n",
      "Iteration 300, Loss: 5.014537964598276e-05, Min w: 0.9725351333618164\n",
      "Iteration 310, Loss: 6.194192974362522e-05, Min w: 0.9646845459938049\n",
      "Iteration 320, Loss: 5.198162762098946e-05, Min w: 0.9703536033630371\n",
      "Iteration 330, Loss: 6.126306834630668e-05, Min w: 0.9681218266487122\n",
      "Iteration 340, Loss: 5.236229480942711e-05, Min w: 0.970647394657135\n",
      "Iteration 350, Loss: 5.212411633692682e-05, Min w: 0.970302164554596\n",
      "Iteration 360, Loss: 7.160296809161082e-05, Min w: 0.9630641341209412\n",
      "Iteration 370, Loss: 5.405296178651042e-05, Min w: 0.9713814854621887\n",
      "Iteration 380, Loss: 4.639267717720941e-05, Min w: 0.973242998123169\n",
      "Iteration 390, Loss: 4.707160042016767e-05, Min w: 0.9704716801643372\n",
      "Iteration 400, Loss: 4.7764166083652526e-05, Min w: 0.9733532667160034\n",
      "Iteration 410, Loss: 4.418698154040612e-05, Min w: 0.9733869433403015\n",
      "Iteration 420, Loss: 8.412908209720626e-05, Min w: 0.9505801200866699\n",
      "Iteration 430, Loss: 4.8968107876135036e-05, Min w: 0.9720399379730225\n",
      "Iteration 440, Loss: 4.716301918961108e-05, Min w: 0.9738290905952454\n",
      "Iteration 450, Loss: 5.605111800832674e-05, Min w: 0.9698397517204285\n",
      "Iteration 460, Loss: 4.7351033572340384e-05, Min w: 0.9736375212669373\n",
      "Iteration 470, Loss: 4.852140409639105e-05, Min w: 0.9702607989311218\n",
      "Iteration 480, Loss: 5.207063441048376e-05, Min w: 0.9711511135101318\n",
      "Iteration 490, Loss: 4.8840342060429975e-05, Min w: 0.9706756472587585\n",
      "Iteration 500, Loss: 4.6250788727775216e-05, Min w: 0.9720394611358643\n",
      "Iteration 510, Loss: 4.547586286207661e-05, Min w: 0.9740554690361023\n",
      "Iteration 520, Loss: 4.359008016763255e-05, Min w: 0.9738481640815735\n",
      "Iteration 530, Loss: 5.838770812260918e-05, Min w: 0.9696559309959412\n",
      "Iteration 540, Loss: 7.345014455495402e-05, Min w: 0.9559730291366577\n",
      "Iteration 550, Loss: 4.755256304633804e-05, Min w: 0.9709034562110901\n",
      "Iteration 560, Loss: 5.415830673882738e-05, Min w: 0.9692291617393494\n",
      "Iteration 570, Loss: 4.616947626345791e-05, Min w: 0.9715861678123474\n",
      "Iteration 580, Loss: 5.264056017040275e-05, Min w: 0.972575306892395\n",
      "Iteration 590, Loss: 5.401213275035843e-05, Min w: 0.9705238938331604\n",
      "Iteration 600, Loss: 4.819038076675497e-05, Min w: 0.9735285043716431\n",
      "Iteration 610, Loss: 4.570455712382682e-05, Min w: 0.9729706645011902\n",
      "Iteration 620, Loss: 4.4900392822455615e-05, Min w: 0.9725842475891113\n",
      "Iteration 630, Loss: 4.678737968788482e-05, Min w: 0.973270058631897\n",
      "Iteration 640, Loss: 5.166128175915219e-05, Min w: 0.9731631278991699\n",
      "Iteration 650, Loss: 4.7158842789940536e-05, Min w: 0.9730147123336792\n",
      "Iteration 660, Loss: 4.752793756779283e-05, Min w: 0.9739086031913757\n",
      "Iteration 670, Loss: 4.7098012146307155e-05, Min w: 0.9727233052253723\n",
      "Iteration 680, Loss: 4.65898665424902e-05, Min w: 0.9729045629501343\n",
      "Iteration 690, Loss: 5.537286779144779e-05, Min w: 0.9706181287765503\n",
      "Iteration 700, Loss: 4.492011430556886e-05, Min w: 0.9717546105384827\n",
      "Iteration 710, Loss: 4.5925880840513855e-05, Min w: 0.9727229475975037\n",
      "Iteration 720, Loss: 5.65982518310193e-05, Min w: 0.9700077772140503\n",
      "Iteration 730, Loss: 4.3035473936470225e-05, Min w: 0.9736557602882385\n",
      "Iteration 740, Loss: 4.43945755250752e-05, Min w: 0.975220799446106\n",
      "Iteration 750, Loss: 5.07686345372349e-05, Min w: 0.9722998738288879\n",
      "Iteration 760, Loss: 4.721722871181555e-05, Min w: 0.9738274812698364\n",
      "Iteration 770, Loss: 4.611797703546472e-05, Min w: 0.9713023900985718\n",
      "Iteration 780, Loss: 4.090281072421931e-05, Min w: 0.9749133586883545\n",
      "Iteration 790, Loss: 4.7207267925841734e-05, Min w: 0.9744106531143188\n",
      "Iteration 800, Loss: 4.257950058672577e-05, Min w: 0.9750053286552429\n",
      "Iteration 810, Loss: 4.623842687578872e-05, Min w: 0.973197877407074\n",
      "Iteration 820, Loss: 5.651413812302053e-05, Min w: 0.9711011648178101\n",
      "Iteration 830, Loss: 4.3592925067059696e-05, Min w: 0.9733931422233582\n",
      "Iteration 840, Loss: 4.3182066292501986e-05, Min w: 0.9738635420799255\n",
      "Iteration 850, Loss: 4.073841773788445e-05, Min w: 0.9760265350341797\n",
      "Iteration 860, Loss: 4.576319770421833e-05, Min w: 0.9740127921104431\n",
      "Iteration 870, Loss: 4.84557676827535e-05, Min w: 0.9727576375007629\n",
      "Iteration 880, Loss: 4.2671061237342656e-05, Min w: 0.9752942323684692\n",
      "Iteration 890, Loss: 4.8266829253407195e-05, Min w: 0.9739472270011902\n",
      "Iteration 900, Loss: 4.3385687604313716e-05, Min w: 0.9748191237449646\n",
      "Iteration 910, Loss: 5.0882688810816035e-05, Min w: 0.9739317893981934\n",
      "Iteration 920, Loss: 4.853167411056347e-05, Min w: 0.9722613096237183\n",
      "Iteration 930, Loss: 4.5898686948930845e-05, Min w: 0.9762313365936279\n",
      "Iteration 940, Loss: 4.4227133912499994e-05, Min w: 0.97565758228302\n",
      "Iteration 950, Loss: 4.431866909726523e-05, Min w: 0.9745471477508545\n",
      "Iteration 960, Loss: 4.5411947212414816e-05, Min w: 0.9745478630065918\n",
      "Iteration 970, Loss: 5.230197712080553e-05, Min w: 0.9729694128036499\n",
      "Iteration 980, Loss: 4.461015487322584e-05, Min w: 0.9753053188323975\n",
      "Iteration 990, Loss: 4.458635885384865e-05, Min w: 0.9742392301559448\n",
      "Iteration 1000, Loss: 4.9147987738251686e-05, Min w: 0.9745338559150696\n",
      "Iteration 1010, Loss: 3.998827014584094e-05, Min w: 0.9761269688606262\n",
      "Iteration 1020, Loss: 4.434402580955066e-05, Min w: 0.9742330312728882\n",
      "Iteration 1030, Loss: 4.263999289833009e-05, Min w: 0.9752297401428223\n",
      "Iteration 1040, Loss: 4.3858679418917745e-05, Min w: 0.9740765690803528\n",
      "Iteration 1050, Loss: 4.021337008452974e-05, Min w: 0.9770216345787048\n",
      "Iteration 1060, Loss: 4.489271668717265e-05, Min w: 0.9751690030097961\n",
      "Iteration 1070, Loss: 4.0966282540466636e-05, Min w: 0.9762657880783081\n",
      "Iteration 1080, Loss: 5.2255189075367525e-05, Min w: 0.9725251793861389\n",
      "Iteration 1090, Loss: 4.161356991971843e-05, Min w: 0.9754974842071533\n",
      "Iteration 1100, Loss: 4.232743231114e-05, Min w: 0.9750034213066101\n",
      "Iteration 1110, Loss: 4.208471727906726e-05, Min w: 0.975517213344574\n",
      "Iteration 1120, Loss: 6.419013516278937e-05, Min w: 0.9635976552963257\n",
      "Iteration 1130, Loss: 4.702406658907421e-05, Min w: 0.973981499671936\n",
      "Iteration 1140, Loss: 4.800379610969685e-05, Min w: 0.9746696352958679\n",
      "Iteration 1150, Loss: 3.951878898078576e-05, Min w: 0.9765560626983643\n",
      "Iteration 1160, Loss: 4.453447400010191e-05, Min w: 0.9742550253868103\n",
      "Iteration 1170, Loss: 4.539148721960373e-05, Min w: 0.9745358824729919\n",
      "Iteration 1180, Loss: 4.068057023687288e-05, Min w: 0.9768854379653931\n",
      "Iteration 1190, Loss: 4.0577942854724824e-05, Min w: 0.9757794737815857\n",
      "Iteration 1200, Loss: 4.232605715515092e-05, Min w: 0.9765104651451111\n",
      "Iteration 1210, Loss: 4.478575283428654e-05, Min w: 0.9750545024871826\n",
      "Iteration 1220, Loss: 4.055295357829891e-05, Min w: 0.9750362634658813\n",
      "Iteration 1230, Loss: 4.353949407231994e-05, Min w: 0.9747285842895508\n",
      "Iteration 1240, Loss: 4.134313348913565e-05, Min w: 0.9760555028915405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  21%|██        | 5/24 [07:42<29:11, 92.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.013037801436050756, 'L2_avg': 0.015138844582825349, 'End_point_L1_avg': 0.013613206385058549, 'End_point_L2_avg': 0.014260605541613633}\n",
      "Iteration 0, Loss: 0.006331246346235275, Min w: 5.761675592363347e-30\n",
      "Iteration 10, Loss: 0.005730184726417065, Min w: 9.762243316708854e-23\n",
      "Iteration 20, Loss: 0.0052550737746059895, Min w: 1.529963843073807e-21\n",
      "Iteration 30, Loss: 0.004853866994380951, Min w: 2.1816931007733468e-16\n",
      "Iteration 40, Loss: 0.0045983316376805305, Min w: 3.0585939597010947e-13\n",
      "Iteration 50, Loss: 0.004318540450185537, Min w: 4.604264018659432e-12\n",
      "Iteration 60, Loss: 0.004061619285494089, Min w: 1.2392842307917817e-09\n",
      "Iteration 70, Loss: 0.003828904591500759, Min w: 4.9691571746279806e-08\n",
      "Iteration 80, Loss: 0.0035966276191174984, Min w: 2.2017154606146505e-06\n",
      "Iteration 90, Loss: 0.0033828988671302795, Min w: 0.00010457455937284976\n",
      "Iteration 100, Loss: 0.003165836213156581, Min w: 0.0024796908255666494\n",
      "Iteration 110, Loss: 0.0029495367780327797, Min w: 0.020005494356155396\n",
      "Iteration 120, Loss: 0.0027883274015039206, Min w: 0.017526885494589806\n",
      "Iteration 130, Loss: 0.002639401936903596, Min w: 0.015500293113291264\n",
      "Iteration 140, Loss: 0.0025437765289098024, Min w: 0.012938518077135086\n",
      "Iteration 150, Loss: 0.0024058634880930185, Min w: 0.009309950284659863\n",
      "Iteration 160, Loss: 0.002324606291949749, Min w: 0.009355180896818638\n",
      "Iteration 170, Loss: 0.0022566516418009996, Min w: 0.011765250004827976\n",
      "Iteration 180, Loss: 0.002225521020591259, Min w: 0.00832413975149393\n",
      "Iteration 190, Loss: 0.002137182978913188, Min w: 0.007720825728029013\n",
      "Iteration 200, Loss: 0.002095420379191637, Min w: 0.008108451031148434\n",
      "Iteration 210, Loss: 0.0020041640382260084, Min w: 0.007415100000798702\n",
      "Iteration 220, Loss: 0.001994028454646468, Min w: 0.007398482412099838\n",
      "Iteration 230, Loss: 0.0019322603475302458, Min w: 0.012915137223899364\n",
      "Iteration 240, Loss: 0.0018736741039901972, Min w: 0.014443577267229557\n",
      "Iteration 250, Loss: 0.0017974033253267407, Min w: 0.016123950481414795\n",
      "Iteration 260, Loss: 0.001779321813955903, Min w: 0.02298017404973507\n",
      "Iteration 270, Loss: 0.0017212900565937161, Min w: 0.037713680416345596\n",
      "Iteration 280, Loss: 0.0017179630231112242, Min w: 0.05440637469291687\n",
      "Iteration 290, Loss: 0.0016174264019355178, Min w: 0.06459826231002808\n",
      "Iteration 300, Loss: 0.0015917874407023191, Min w: 0.08078087121248245\n",
      "Iteration 310, Loss: 0.0015465511241927743, Min w: 0.10628485679626465\n",
      "Iteration 320, Loss: 0.0014879957307130098, Min w: 0.1316385418176651\n",
      "Iteration 330, Loss: 0.0014769965782761574, Min w: 0.1363195776939392\n",
      "Iteration 340, Loss: 0.0013666379963979125, Min w: 0.18117651343345642\n",
      "Iteration 350, Loss: 0.0013225652510300279, Min w: 0.1952265202999115\n",
      "Iteration 360, Loss: 0.0013255883241072297, Min w: 0.21003267168998718\n",
      "Iteration 370, Loss: 0.0012718761572614312, Min w: 0.23346658051013947\n",
      "Iteration 380, Loss: 0.0012260022340342402, Min w: 0.25339218974113464\n",
      "Iteration 390, Loss: 0.0012141027254983783, Min w: 0.26103445887565613\n",
      "Iteration 400, Loss: 0.001195056946016848, Min w: 0.2766033113002777\n",
      "Iteration 410, Loss: 0.0011146524921059608, Min w: 0.31100642681121826\n",
      "Iteration 420, Loss: 0.0010958672501146793, Min w: 0.32091668248176575\n",
      "Iteration 430, Loss: 0.001144738052971661, Min w: 0.278717964887619\n",
      "Iteration 440, Loss: 0.0010789543157443404, Min w: 0.32007285952568054\n",
      "Iteration 450, Loss: 0.0010562308598309755, Min w: 0.34964004158973694\n",
      "Iteration 460, Loss: 0.0010379105806350708, Min w: 0.35334843397140503\n",
      "Iteration 470, Loss: 0.0010578943183645606, Min w: 0.34026071429252625\n",
      "Iteration 480, Loss: 0.001013676286675036, Min w: 0.35113826394081116\n",
      "Iteration 490, Loss: 0.001006328035145998, Min w: 0.3524855375289917\n",
      "Iteration 500, Loss: 0.0009525231434963644, Min w: 0.377548485994339\n",
      "Iteration 510, Loss: 0.0009104867931455374, Min w: 0.3965410888195038\n",
      "Iteration 520, Loss: 0.0009494430851191282, Min w: 0.38811394572257996\n",
      "Iteration 530, Loss: 0.0009388329344801605, Min w: 0.3807303011417389\n",
      "Iteration 540, Loss: 0.000978454714640975, Min w: 0.38597920536994934\n",
      "Iteration 550, Loss: 0.0008971811039373279, Min w: 0.4324291944503784\n",
      "Iteration 560, Loss: 0.0009331813780590892, Min w: 0.392843633890152\n",
      "Iteration 570, Loss: 0.0008941579726524651, Min w: 0.42136844992637634\n",
      "Iteration 580, Loss: 0.0008872151374816895, Min w: 0.42436763644218445\n",
      "Iteration 590, Loss: 0.0008897938532754779, Min w: 0.4405786097049713\n",
      "Iteration 600, Loss: 0.0008570774807594717, Min w: 0.44235289096832275\n",
      "Iteration 610, Loss: 0.0008551900391466916, Min w: 0.43593335151672363\n",
      "Iteration 620, Loss: 0.0008349481504410505, Min w: 0.44676756858825684\n",
      "Iteration 630, Loss: 0.0008657404105179012, Min w: 0.4389858543872833\n",
      "Iteration 640, Loss: 0.0008375076577067375, Min w: 0.45138466358184814\n",
      "Iteration 650, Loss: 0.0008340789354406297, Min w: 0.4528903663158417\n",
      "Iteration 660, Loss: 0.000801112677436322, Min w: 0.4596557319164276\n",
      "Iteration 670, Loss: 0.0008158758864738047, Min w: 0.4605289399623871\n",
      "Iteration 680, Loss: 0.0007832854171283543, Min w: 0.4867120087146759\n",
      "Iteration 690, Loss: 0.0008198721334338188, Min w: 0.47349831461906433\n",
      "Iteration 700, Loss: 0.0008153414237312973, Min w: 0.4661305248737335\n",
      "Iteration 710, Loss: 0.0007322452729567885, Min w: 0.49980393052101135\n",
      "Iteration 720, Loss: 0.0007174672209657729, Min w: 0.5174964070320129\n",
      "Iteration 730, Loss: 0.0007384504424408078, Min w: 0.51630038022995\n",
      "Iteration 740, Loss: 0.0007576468051411211, Min w: 0.5023615956306458\n",
      "Iteration 750, Loss: 0.0007626305450685322, Min w: 0.5191940665245056\n",
      "Iteration 760, Loss: 0.0007029594271443784, Min w: 0.5300296545028687\n",
      "Iteration 770, Loss: 0.0006732231704518199, Min w: 0.5412625074386597\n",
      "Iteration 780, Loss: 0.0007224999135360122, Min w: 0.5190960168838501\n",
      "Iteration 790, Loss: 0.0006978123565204442, Min w: 0.5477544665336609\n",
      "Iteration 800, Loss: 0.0006528611411340535, Min w: 0.5605231523513794\n",
      "Iteration 810, Loss: 0.0006616966566070914, Min w: 0.5509547591209412\n",
      "Iteration 820, Loss: 0.0006676385528407991, Min w: 0.550935685634613\n",
      "Iteration 830, Loss: 0.0006535353022627532, Min w: 0.5696878433227539\n",
      "Iteration 840, Loss: 0.0006648593116551638, Min w: 0.5661322474479675\n",
      "Iteration 850, Loss: 0.0006458070711232722, Min w: 0.5669568181037903\n",
      "Iteration 860, Loss: 0.0006223865784704685, Min w: 0.5859212875366211\n",
      "Iteration 870, Loss: 0.0006307978183031082, Min w: 0.581350564956665\n",
      "Iteration 880, Loss: 0.0006062955362722278, Min w: 0.5946236252784729\n",
      "Iteration 890, Loss: 0.0006239627255126834, Min w: 0.5926134586334229\n",
      "Iteration 900, Loss: 0.0006244269898161292, Min w: 0.5822740197181702\n",
      "Iteration 910, Loss: 0.0006026597693562508, Min w: 0.5910360217094421\n",
      "Iteration 920, Loss: 0.000600051018409431, Min w: 0.6182067394256592\n",
      "Iteration 930, Loss: 0.000605113513302058, Min w: 0.6150883436203003\n",
      "Iteration 940, Loss: 0.0005919830873608589, Min w: 0.6039146184921265\n",
      "Iteration 950, Loss: 0.0005711103440262377, Min w: 0.6140516400337219\n",
      "Iteration 960, Loss: 0.0005932013154961169, Min w: 0.598514199256897\n",
      "Iteration 970, Loss: 0.000544761074706912, Min w: 0.6331232786178589\n",
      "Iteration 980, Loss: 0.0005459322710521519, Min w: 0.6288096308708191\n",
      "Iteration 990, Loss: 0.0005582052981480956, Min w: 0.6293299198150635\n",
      "Iteration 1000, Loss: 0.0005321918870322406, Min w: 0.6491453647613525\n",
      "Iteration 1010, Loss: 0.0005498770624399185, Min w: 0.631046712398529\n",
      "Iteration 1020, Loss: 0.0005314172594808042, Min w: 0.6384108662605286\n",
      "Iteration 1030, Loss: 0.000594719429500401, Min w: 0.625518262386322\n",
      "Iteration 1040, Loss: 0.0005071136401966214, Min w: 0.6600147485733032\n",
      "Iteration 1050, Loss: 0.0005111871287226677, Min w: 0.6548767685890198\n",
      "Iteration 1060, Loss: 0.0004796654684469104, Min w: 0.6761009693145752\n",
      "Iteration 1070, Loss: 0.0004975355695933104, Min w: 0.6561465859413147\n",
      "Iteration 1080, Loss: 0.0005485888104885817, Min w: 0.6494899988174438\n",
      "Iteration 1090, Loss: 0.0005067047895863652, Min w: 0.6706401705741882\n",
      "Iteration 1100, Loss: 0.0004522154340520501, Min w: 0.6857503652572632\n",
      "Iteration 1110, Loss: 0.00048392184544354677, Min w: 0.6693627238273621\n",
      "Iteration 1120, Loss: 0.0004963648971170187, Min w: 0.6751160025596619\n",
      "Iteration 1130, Loss: 0.00046785923768766224, Min w: 0.6917981505393982\n",
      "Iteration 1140, Loss: 0.0004953453899361193, Min w: 0.6730349659919739\n",
      "Iteration 1150, Loss: 0.0004502588417381048, Min w: 0.7025389671325684\n",
      "Iteration 1160, Loss: 0.0004543558752629906, Min w: 0.695669949054718\n",
      "Iteration 1170, Loss: 0.00044077244820073247, Min w: 0.7158123254776001\n",
      "Iteration 1180, Loss: 0.0004367572837509215, Min w: 0.7048841118812561\n",
      "Iteration 1190, Loss: 0.00044644641457125545, Min w: 0.7024800181388855\n",
      "Iteration 1200, Loss: 0.00044909262214787304, Min w: 0.6980342864990234\n",
      "Iteration 1210, Loss: 0.0004549015429802239, Min w: 0.7000157237052917\n",
      "Iteration 1220, Loss: 0.00043978585745207965, Min w: 0.7008631229400635\n",
      "Iteration 1230, Loss: 0.0004509711579885334, Min w: 0.7018982768058777\n",
      "Iteration 1240, Loss: 0.0004065281536895782, Min w: 0.7389368414878845\n",
      "Iteration 0, Loss: 0.0004223651485517621, Min w: 0.719039261341095\n",
      "Iteration 10, Loss: 0.0003925389319192618, Min w: 0.7407769560813904\n",
      "Iteration 20, Loss: 0.00043027588981203735, Min w: 0.7090194821357727\n",
      "Iteration 30, Loss: 0.00038801072514615953, Min w: 0.7378661036491394\n",
      "Iteration 40, Loss: 0.00041374354623258114, Min w: 0.7329865097999573\n",
      "Iteration 50, Loss: 0.00039631102117709816, Min w: 0.7284632325172424\n",
      "Iteration 60, Loss: 0.00041063057142309844, Min w: 0.7354993224143982\n",
      "Iteration 70, Loss: 0.00040597442421130836, Min w: 0.7345845699310303\n",
      "Iteration 80, Loss: 0.0003699704247992486, Min w: 0.7474504709243774\n",
      "Iteration 90, Loss: 0.0003778880345635116, Min w: 0.7599593997001648\n",
      "Iteration 100, Loss: 0.0003523611230775714, Min w: 0.7623382210731506\n",
      "Iteration 110, Loss: 0.00036326091503724456, Min w: 0.7581433057785034\n",
      "Iteration 120, Loss: 0.00036029439070262015, Min w: 0.7587488293647766\n",
      "Iteration 130, Loss: 0.00036570546217262745, Min w: 0.76682049036026\n",
      "Iteration 140, Loss: 0.00035332542029209435, Min w: 0.7606914639472961\n",
      "Iteration 150, Loss: 0.00037006125785410404, Min w: 0.7511550188064575\n",
      "Iteration 160, Loss: 0.0003251349553465843, Min w: 0.7840345501899719\n",
      "Iteration 170, Loss: 0.00033112135133706033, Min w: 0.7844741344451904\n",
      "Iteration 180, Loss: 0.00031848036451265216, Min w: 0.7795189023017883\n",
      "Iteration 190, Loss: 0.0003448811767157167, Min w: 0.7579254508018494\n",
      "Iteration 200, Loss: 0.0003354298823978752, Min w: 0.7806900143623352\n",
      "Iteration 210, Loss: 0.0003506472858134657, Min w: 0.7725393772125244\n",
      "Iteration 220, Loss: 0.00033492519287392497, Min w: 0.7750190496444702\n",
      "Iteration 230, Loss: 0.00033576233545318246, Min w: 0.7909474968910217\n",
      "Iteration 240, Loss: 0.0003040399169549346, Min w: 0.7979112863540649\n",
      "Iteration 250, Loss: 0.0003567253006622195, Min w: 0.7629600167274475\n",
      "Iteration 260, Loss: 0.0003056742425542325, Min w: 0.7945438623428345\n",
      "Iteration 270, Loss: 0.0003195341269019991, Min w: 0.7999081015586853\n",
      "Iteration 280, Loss: 0.00031370605574920774, Min w: 0.7958081960678101\n",
      "Iteration 290, Loss: 0.0003178956394549459, Min w: 0.7934313416481018\n",
      "Iteration 300, Loss: 0.0002984197053592652, Min w: 0.7954365611076355\n",
      "Iteration 310, Loss: 0.0003021936281584203, Min w: 0.807780385017395\n",
      "Iteration 320, Loss: 0.00031619417131878436, Min w: 0.7968799471855164\n",
      "Iteration 330, Loss: 0.000285954971332103, Min w: 0.8162493705749512\n",
      "Iteration 340, Loss: 0.0002860110253095627, Min w: 0.8165267109870911\n",
      "Iteration 350, Loss: 0.00029207803891040385, Min w: 0.8140342831611633\n",
      "Iteration 360, Loss: 0.0002807272830978036, Min w: 0.8201935291290283\n",
      "Iteration 370, Loss: 0.0002824573020916432, Min w: 0.8213896155357361\n",
      "Iteration 380, Loss: 0.0002801271330099553, Min w: 0.8200588226318359\n",
      "Iteration 390, Loss: 0.00027540692826732993, Min w: 0.8181216716766357\n",
      "Iteration 400, Loss: 0.0002973044174723327, Min w: 0.8163576722145081\n",
      "Iteration 410, Loss: 0.0002551294455770403, Min w: 0.8334274888038635\n",
      "Iteration 420, Loss: 0.0002793127205222845, Min w: 0.8193137049674988\n",
      "Iteration 430, Loss: 0.0002679242752492428, Min w: 0.8357216715812683\n",
      "Iteration 440, Loss: 0.00026151537895202637, Min w: 0.8300699591636658\n",
      "Iteration 450, Loss: 0.00026703986804932356, Min w: 0.8251036405563354\n",
      "Iteration 460, Loss: 0.0002476238878443837, Min w: 0.8378250598907471\n",
      "Iteration 470, Loss: 0.0002525615564081818, Min w: 0.838162899017334\n",
      "Iteration 480, Loss: 0.0002421612589387223, Min w: 0.8457181453704834\n",
      "Iteration 490, Loss: 0.00025741991703398526, Min w: 0.8386570811271667\n",
      "Iteration 500, Loss: 0.00024221774947363883, Min w: 0.8440638780593872\n",
      "Iteration 510, Loss: 0.00022884398640599102, Min w: 0.8535836935043335\n",
      "Iteration 520, Loss: 0.0002590011863503605, Min w: 0.8393699526786804\n",
      "Iteration 530, Loss: 0.00023467917344532907, Min w: 0.8445515036582947\n",
      "Iteration 540, Loss: 0.00021913037926424295, Min w: 0.8588113188743591\n",
      "Iteration 550, Loss: 0.00022767444897908717, Min w: 0.8483648300170898\n",
      "Iteration 560, Loss: 0.0002287333772983402, Min w: 0.8528199195861816\n",
      "Iteration 570, Loss: 0.0002585680049378425, Min w: 0.8441917896270752\n",
      "Iteration 580, Loss: 0.00024347324506379664, Min w: 0.84772127866745\n",
      "Iteration 590, Loss: 0.00023355100711341947, Min w: 0.8526984453201294\n",
      "Iteration 600, Loss: 0.00022324512246996164, Min w: 0.8567647337913513\n",
      "Iteration 610, Loss: 0.0002137183619197458, Min w: 0.8583691716194153\n",
      "Iteration 620, Loss: 0.00020648338249884546, Min w: 0.8670907616615295\n",
      "Iteration 630, Loss: 0.00021664652740582824, Min w: 0.8608554005622864\n",
      "Iteration 640, Loss: 0.0002211022365372628, Min w: 0.8569501042366028\n",
      "Iteration 650, Loss: 0.00022565819381270558, Min w: 0.8527815341949463\n",
      "Iteration 660, Loss: 0.00022599342628382146, Min w: 0.859932541847229\n",
      "Iteration 670, Loss: 0.00021907908376306295, Min w: 0.8614175319671631\n",
      "Iteration 680, Loss: 0.00020954743376933038, Min w: 0.8680100440979004\n",
      "Iteration 690, Loss: 0.00020133340149186552, Min w: 0.8787946105003357\n",
      "Iteration 700, Loss: 0.0002064985892502591, Min w: 0.8648645877838135\n",
      "Iteration 710, Loss: 0.00019518127373885363, Min w: 0.8771330714225769\n",
      "Iteration 720, Loss: 0.0002054314099950716, Min w: 0.8738271594047546\n",
      "Iteration 730, Loss: 0.00019353513198439032, Min w: 0.8703597784042358\n",
      "Iteration 740, Loss: 0.00019097082258667797, Min w: 0.8734274506568909\n",
      "Iteration 750, Loss: 0.00019638727826531976, Min w: 0.8757326602935791\n",
      "Iteration 760, Loss: 0.00020869496802333742, Min w: 0.8691331148147583\n",
      "Iteration 770, Loss: 0.00018942647147923708, Min w: 0.8794423937797546\n",
      "Iteration 780, Loss: 0.00018955403356812894, Min w: 0.8807158470153809\n",
      "Iteration 790, Loss: 0.00017682608449831605, Min w: 0.8905453681945801\n",
      "Iteration 800, Loss: 0.00019224830612074584, Min w: 0.8776811361312866\n",
      "Iteration 810, Loss: 0.00017460233357269317, Min w: 0.8910455107688904\n",
      "Iteration 820, Loss: 0.00018695883045438677, Min w: 0.8817529678344727\n",
      "Iteration 830, Loss: 0.0001775286509655416, Min w: 0.8876686096191406\n",
      "Iteration 840, Loss: 0.00017978055984713137, Min w: 0.8911340236663818\n",
      "Iteration 850, Loss: 0.00018886089674197137, Min w: 0.8737552762031555\n",
      "Iteration 860, Loss: 0.00016152390162460506, Min w: 0.8953592777252197\n",
      "Iteration 870, Loss: 0.00016750273061916232, Min w: 0.8917434215545654\n",
      "Iteration 880, Loss: 0.00017697940347716212, Min w: 0.8844454288482666\n",
      "Iteration 890, Loss: 0.00015420245472341776, Min w: 0.9007033109664917\n",
      "Iteration 900, Loss: 0.00017306036897934973, Min w: 0.8923746347427368\n",
      "Iteration 910, Loss: 0.00015905762847978622, Min w: 0.8984367847442627\n",
      "Iteration 920, Loss: 0.0001727726630633697, Min w: 0.8891920447349548\n",
      "Iteration 930, Loss: 0.00018746888963505626, Min w: 0.8942875862121582\n",
      "Iteration 940, Loss: 0.00016923024668358266, Min w: 0.8955238461494446\n",
      "Iteration 950, Loss: 0.0001619191316422075, Min w: 0.906240701675415\n",
      "Iteration 960, Loss: 0.00016891238919924945, Min w: 0.891940176486969\n",
      "Iteration 970, Loss: 0.0001532167079858482, Min w: 0.9003990292549133\n",
      "Iteration 980, Loss: 0.00016239202523138374, Min w: 0.9015300869941711\n",
      "Iteration 990, Loss: 0.00015195700689218938, Min w: 0.9023783206939697\n",
      "Iteration 1000, Loss: 0.00014999796985648572, Min w: 0.9048890471458435\n",
      "Iteration 1010, Loss: 0.0001494312018621713, Min w: 0.9023605585098267\n",
      "Iteration 1020, Loss: 0.00015211518621072173, Min w: 0.9031391739845276\n",
      "Iteration 1030, Loss: 0.0001671413629082963, Min w: 0.9006126523017883\n",
      "Iteration 1040, Loss: 0.0001611488696653396, Min w: 0.9040212631225586\n",
      "Iteration 1050, Loss: 0.00013751363439951092, Min w: 0.9146241545677185\n",
      "Iteration 1060, Loss: 0.00013790561934001744, Min w: 0.9124436378479004\n",
      "Iteration 1070, Loss: 0.00014134174853097647, Min w: 0.909871518611908\n",
      "Iteration 1080, Loss: 0.00014885241398587823, Min w: 0.9062148332595825\n",
      "Iteration 1090, Loss: 0.00014248619845602661, Min w: 0.9081284999847412\n",
      "Iteration 1100, Loss: 0.00014637570711784065, Min w: 0.9135310649871826\n",
      "Iteration 1110, Loss: 0.00016300409333780408, Min w: 0.8979275226593018\n",
      "Iteration 1120, Loss: 0.00014610381913371384, Min w: 0.9129394888877869\n",
      "Iteration 1130, Loss: 0.00013801810564473271, Min w: 0.9167720675468445\n",
      "Iteration 1140, Loss: 0.00012981587497051805, Min w: 0.9219409227371216\n",
      "Iteration 1150, Loss: 0.00014546807506121695, Min w: 0.9145644307136536\n",
      "Iteration 1160, Loss: 0.0001253873051609844, Min w: 0.9230018258094788\n",
      "Iteration 1170, Loss: 0.00013574000331573188, Min w: 0.9125385284423828\n",
      "Iteration 1180, Loss: 0.00013454174040816724, Min w: 0.9161017537117004\n",
      "Iteration 1190, Loss: 0.00012132889969507232, Min w: 0.9243286848068237\n",
      "Iteration 1200, Loss: 0.00012659947969950736, Min w: 0.9209429025650024\n",
      "Iteration 1210, Loss: 0.00013427015801426023, Min w: 0.9162845015525818\n",
      "Iteration 1220, Loss: 0.0001277187984669581, Min w: 0.9233466982841492\n",
      "Iteration 1230, Loss: 0.00013209751341491938, Min w: 0.9162781238555908\n",
      "Iteration 1240, Loss: 0.0001344559423159808, Min w: 0.9176220297813416\n",
      "Iteration 0, Loss: 0.00012645285460166633, Min w: 0.9230852723121643\n",
      "Iteration 10, Loss: 0.00011914648348465562, Min w: 0.9259597063064575\n",
      "Iteration 20, Loss: 0.0001281269796891138, Min w: 0.9221014380455017\n",
      "Iteration 30, Loss: 0.00013398074952419847, Min w: 0.9227553009986877\n",
      "Iteration 40, Loss: 0.00013998139183968306, Min w: 0.9253171682357788\n",
      "Iteration 50, Loss: 0.0001261741272173822, Min w: 0.9257769584655762\n",
      "Iteration 60, Loss: 0.00011605305917328224, Min w: 0.9256070256233215\n",
      "Iteration 70, Loss: 0.00011686045036185533, Min w: 0.927831768989563\n",
      "Iteration 80, Loss: 0.00011518569226609543, Min w: 0.9309970736503601\n",
      "Iteration 90, Loss: 0.00011244393681408837, Min w: 0.9320670962333679\n",
      "Iteration 100, Loss: 0.00011567921319510788, Min w: 0.9300270080566406\n",
      "Iteration 110, Loss: 0.00011886679567396641, Min w: 0.9321762323379517\n",
      "Iteration 120, Loss: 0.00010924115485977381, Min w: 0.9295759201049805\n",
      "Iteration 130, Loss: 0.00011963870201725513, Min w: 0.923477292060852\n",
      "Iteration 140, Loss: 0.00011509809701237828, Min w: 0.9307731986045837\n",
      "Iteration 150, Loss: 0.00011340415949234739, Min w: 0.931236207485199\n",
      "Iteration 160, Loss: 0.00010338466381654143, Min w: 0.9351983070373535\n",
      "Iteration 170, Loss: 0.00011780073691625148, Min w: 0.9257972836494446\n",
      "Iteration 180, Loss: 0.00010431085684103891, Min w: 0.9339781403541565\n",
      "Iteration 190, Loss: 0.00011337698379065841, Min w: 0.9302959442138672\n",
      "Iteration 200, Loss: 0.00011432301835156977, Min w: 0.9330108761787415\n",
      "Iteration 210, Loss: 0.00011900244862772524, Min w: 0.9360086917877197\n",
      "Iteration 220, Loss: 0.00011643909238046035, Min w: 0.9334946274757385\n",
      "Iteration 230, Loss: 0.00010464371007401496, Min w: 0.9369140863418579\n",
      "Iteration 240, Loss: 0.00010306996409781277, Min w: 0.9370759725570679\n",
      "Iteration 250, Loss: 9.736263746162876e-05, Min w: 0.9433461427688599\n",
      "Iteration 260, Loss: 0.0001241390418726951, Min w: 0.9325799345970154\n",
      "Iteration 270, Loss: 0.00012100286403438076, Min w: 0.934282660484314\n",
      "Iteration 280, Loss: 8.996008546091616e-05, Min w: 0.9444352388381958\n",
      "Iteration 290, Loss: 0.00010004545038100332, Min w: 0.9407423734664917\n",
      "Iteration 300, Loss: 9.766959556145594e-05, Min w: 0.9425603151321411\n",
      "Iteration 310, Loss: 9.954645065590739e-05, Min w: 0.941650390625\n",
      "Iteration 320, Loss: 0.00010250623017782345, Min w: 0.9405493140220642\n",
      "Iteration 330, Loss: 9.731970931170508e-05, Min w: 0.9404182434082031\n",
      "Iteration 340, Loss: 9.681036317488179e-05, Min w: 0.9388431906700134\n",
      "Iteration 350, Loss: 0.00010093139280797914, Min w: 0.9403024315834045\n",
      "Iteration 360, Loss: 9.741454414324835e-05, Min w: 0.9432173371315002\n",
      "Iteration 370, Loss: 0.00010340021981392056, Min w: 0.9445999264717102\n",
      "Iteration 380, Loss: 9.292709728470072e-05, Min w: 0.9455685615539551\n",
      "Iteration 390, Loss: 9.06779823708348e-05, Min w: 0.9483426213264465\n",
      "Iteration 400, Loss: 0.00010193520574830472, Min w: 0.9413945078849792\n",
      "Iteration 410, Loss: 8.88406066223979e-05, Min w: 0.9450021386146545\n",
      "Iteration 420, Loss: 0.00010405600914964452, Min w: 0.9443590044975281\n",
      "Iteration 430, Loss: 8.881062967702746e-05, Min w: 0.9451794028282166\n",
      "Iteration 440, Loss: 8.909787720767781e-05, Min w: 0.9461096525192261\n",
      "Iteration 450, Loss: 8.881773828761652e-05, Min w: 0.9482611417770386\n",
      "Iteration 460, Loss: 8.876585343386978e-05, Min w: 0.9471240639686584\n",
      "Iteration 470, Loss: 9.790349577087909e-05, Min w: 0.9455844163894653\n",
      "Iteration 480, Loss: 8.50251381052658e-05, Min w: 0.9513813853263855\n",
      "Iteration 490, Loss: 8.088714093901217e-05, Min w: 0.9528036117553711\n",
      "Iteration 500, Loss: 9.569488611305133e-05, Min w: 0.9506320357322693\n",
      "Iteration 510, Loss: 8.470996544929221e-05, Min w: 0.9534005522727966\n",
      "Iteration 520, Loss: 8.967100438894704e-05, Min w: 0.9498489499092102\n",
      "Iteration 530, Loss: 7.838382589397952e-05, Min w: 0.9540256857872009\n",
      "Iteration 540, Loss: 8.45917165861465e-05, Min w: 0.9529163837432861\n",
      "Iteration 550, Loss: 7.912574801594019e-05, Min w: 0.9551593661308289\n",
      "Iteration 560, Loss: 7.780107262078673e-05, Min w: 0.9539864659309387\n",
      "Iteration 570, Loss: 9.991003025788814e-05, Min w: 0.9470670223236084\n",
      "Iteration 580, Loss: 8.728857937967405e-05, Min w: 0.9499664306640625\n",
      "Iteration 590, Loss: 8.744069782551378e-05, Min w: 0.9551094770431519\n",
      "Iteration 600, Loss: 7.508286216761917e-05, Min w: 0.9551960825920105\n",
      "Iteration 610, Loss: 8.062124834395945e-05, Min w: 0.9528366923332214\n",
      "Iteration 620, Loss: 8.481924305669963e-05, Min w: 0.9524110555648804\n",
      "Iteration 630, Loss: 8.969523332780227e-05, Min w: 0.9539293050765991\n",
      "Iteration 640, Loss: 8.90221053850837e-05, Min w: 0.9531031250953674\n",
      "Iteration 650, Loss: 8.956430247053504e-05, Min w: 0.9525262117385864\n",
      "Iteration 660, Loss: 7.620018732268363e-05, Min w: 0.9580363035202026\n",
      "Iteration 670, Loss: 7.634039502590895e-05, Min w: 0.9588475823402405\n",
      "Iteration 680, Loss: 7.247025496326387e-05, Min w: 0.9576390981674194\n",
      "Iteration 690, Loss: 7.652993372175843e-05, Min w: 0.9583249092102051\n",
      "Iteration 700, Loss: 7.8731267421972e-05, Min w: 0.9550923109054565\n",
      "Iteration 710, Loss: 7.646765880053863e-05, Min w: 0.9577347636222839\n",
      "Iteration 720, Loss: 9.912808309309185e-05, Min w: 0.942870557308197\n",
      "Iteration 730, Loss: 7.425664080074057e-05, Min w: 0.9618368744850159\n",
      "Iteration 740, Loss: 8.338676707353443e-05, Min w: 0.9567151665687561\n",
      "Iteration 750, Loss: 7.766556518618017e-05, Min w: 0.9558624029159546\n",
      "Iteration 760, Loss: 7.174050551839173e-05, Min w: 0.9582812786102295\n",
      "Iteration 770, Loss: 7.089806604199111e-05, Min w: 0.9606397151947021\n",
      "Iteration 780, Loss: 7.386384822893888e-05, Min w: 0.9586005210876465\n",
      "Iteration 790, Loss: 7.605712744407356e-05, Min w: 0.9597192406654358\n",
      "Iteration 800, Loss: 7.544377876911312e-05, Min w: 0.9588905572891235\n",
      "Iteration 810, Loss: 8.256074215751141e-05, Min w: 0.9527261257171631\n",
      "Iteration 820, Loss: 7.190590986283496e-05, Min w: 0.9616147875785828\n",
      "Iteration 830, Loss: 6.729502638336271e-05, Min w: 0.9632413983345032\n",
      "Iteration 840, Loss: 6.857978587504476e-05, Min w: 0.9608749747276306\n",
      "Iteration 850, Loss: 6.948089867364615e-05, Min w: 0.9638384580612183\n",
      "Iteration 860, Loss: 6.632928125327453e-05, Min w: 0.9642701148986816\n",
      "Iteration 870, Loss: 6.422351725632325e-05, Min w: 0.9630776047706604\n",
      "Iteration 880, Loss: 6.724111153744161e-05, Min w: 0.965438723564148\n",
      "Iteration 890, Loss: 7.622066914336756e-05, Min w: 0.9588382244110107\n",
      "Iteration 900, Loss: 7.296325929928571e-05, Min w: 0.9602553248405457\n",
      "Iteration 910, Loss: 6.482684693764895e-05, Min w: 0.9654837250709534\n",
      "Iteration 920, Loss: 6.785599543945864e-05, Min w: 0.9623553156852722\n",
      "Iteration 930, Loss: 6.308688170975074e-05, Min w: 0.9649859666824341\n",
      "Iteration 940, Loss: 6.805139128118753e-05, Min w: 0.9633635878562927\n",
      "Iteration 950, Loss: 6.0363036027411e-05, Min w: 0.9669287800788879\n",
      "Iteration 960, Loss: 8.362252992810681e-05, Min w: 0.9510759711265564\n",
      "Iteration 970, Loss: 6.243545067263767e-05, Min w: 0.967857837677002\n",
      "Iteration 980, Loss: 6.502171163447201e-05, Min w: 0.9655254483222961\n",
      "Iteration 990, Loss: 6.845090683782473e-05, Min w: 0.9631896615028381\n",
      "Iteration 1000, Loss: 7.452604040736333e-05, Min w: 0.9610547423362732\n",
      "Iteration 1010, Loss: 6.305745046120137e-05, Min w: 0.9667652249336243\n",
      "Iteration 1020, Loss: 6.520841270685196e-05, Min w: 0.9643586277961731\n",
      "Iteration 1030, Loss: 6.850052159279585e-05, Min w: 0.9629369974136353\n",
      "Iteration 1040, Loss: 5.888930900255218e-05, Min w: 0.9683483839035034\n",
      "Iteration 1050, Loss: 6.816737004555762e-05, Min w: 0.9644125699996948\n",
      "Iteration 1060, Loss: 6.253892206586897e-05, Min w: 0.9676270484924316\n",
      "Iteration 1070, Loss: 6.181051139719784e-05, Min w: 0.9681147933006287\n",
      "Iteration 1080, Loss: 6.101649341871962e-05, Min w: 0.9682444334030151\n",
      "Iteration 1090, Loss: 6.004884926369414e-05, Min w: 0.9678398966789246\n",
      "Iteration 1100, Loss: 6.305073475232348e-05, Min w: 0.9676738381385803\n",
      "Iteration 1110, Loss: 6.194503657752648e-05, Min w: 0.9676865339279175\n",
      "Iteration 1120, Loss: 6.075212877476588e-05, Min w: 0.968603253364563\n",
      "Iteration 1130, Loss: 6.237395427888259e-05, Min w: 0.966178834438324\n",
      "Iteration 1140, Loss: 6.28072812105529e-05, Min w: 0.9677070379257202\n",
      "Iteration 1150, Loss: 6.107315130066127e-05, Min w: 0.9665573835372925\n",
      "Iteration 1160, Loss: 5.623109245789237e-05, Min w: 0.9708571434020996\n",
      "Iteration 1170, Loss: 5.551829963224009e-05, Min w: 0.9706978797912598\n",
      "Iteration 1180, Loss: 6.63368045934476e-05, Min w: 0.9629833102226257\n",
      "Iteration 1190, Loss: 5.953248546575196e-05, Min w: 0.9686991572380066\n",
      "Iteration 1200, Loss: 6.291058525675908e-05, Min w: 0.9672619104385376\n",
      "Iteration 1210, Loss: 5.040852556703612e-05, Min w: 0.9732924699783325\n",
      "Iteration 1220, Loss: 5.913061977480538e-05, Min w: 0.9689978957176208\n",
      "Iteration 1230, Loss: 7.140934030758217e-05, Min w: 0.9594043493270874\n",
      "Iteration 1240, Loss: 5.704861905542202e-05, Min w: 0.9703847765922546\n",
      "Iteration 0, Loss: 5.455207428894937e-05, Min w: 0.9714561104774475\n",
      "Iteration 10, Loss: 5.966151366010308e-05, Min w: 0.966744601726532\n",
      "Iteration 20, Loss: 5.6663702707737684e-05, Min w: 0.9708626866340637\n",
      "Iteration 30, Loss: 5.6488512200303376e-05, Min w: 0.9695566892623901\n",
      "Iteration 40, Loss: 5.320131458574906e-05, Min w: 0.9708578586578369\n",
      "Iteration 50, Loss: 5.748260082327761e-05, Min w: 0.9703078866004944\n",
      "Iteration 60, Loss: 5.0347614887868986e-05, Min w: 0.9731904864311218\n",
      "Iteration 70, Loss: 5.1169619837310165e-05, Min w: 0.9736015796661377\n",
      "Iteration 80, Loss: 5.3667332394979894e-05, Min w: 0.971225380897522\n",
      "Iteration 90, Loss: 5.365176184568554e-05, Min w: 0.9725081324577332\n",
      "Iteration 100, Loss: 5.593819878413342e-05, Min w: 0.9711406230926514\n",
      "Iteration 110, Loss: 5.1056013035122305e-05, Min w: 0.9733418822288513\n",
      "Iteration 120, Loss: 5.739871266996488e-05, Min w: 0.9687671661376953\n",
      "Iteration 130, Loss: 5.222733670962043e-05, Min w: 0.9714035391807556\n",
      "Iteration 140, Loss: 5.3098479838809e-05, Min w: 0.9722663164138794\n",
      "Iteration 150, Loss: 5.541311838896945e-05, Min w: 0.9699215888977051\n",
      "Iteration 160, Loss: 5.8520476159173995e-05, Min w: 0.9667215943336487\n",
      "Iteration 170, Loss: 6.667854904662818e-05, Min w: 0.9608471989631653\n",
      "Iteration 180, Loss: 6.76305644446984e-05, Min w: 0.9590842723846436\n",
      "Iteration 190, Loss: 4.936009645462036e-05, Min w: 0.9743505120277405\n",
      "Iteration 200, Loss: 5.0386606744723395e-05, Min w: 0.9732167720794678\n",
      "Iteration 210, Loss: 6.189192936290056e-05, Min w: 0.9641103148460388\n",
      "Iteration 220, Loss: 5.004227568861097e-05, Min w: 0.9728049039840698\n",
      "Iteration 230, Loss: 8.035976497922093e-05, Min w: 0.9486427903175354\n",
      "Iteration 240, Loss: 7.547561835963279e-05, Min w: 0.9526062607765198\n",
      "Iteration 250, Loss: 5.4711897973902524e-05, Min w: 0.9681536555290222\n",
      "Iteration 260, Loss: 4.797185101779178e-05, Min w: 0.974280059337616\n",
      "Iteration 270, Loss: 5.4396579798776656e-05, Min w: 0.9690899848937988\n",
      "Iteration 280, Loss: 5.210460221860558e-05, Min w: 0.9699028134346008\n",
      "Iteration 290, Loss: 4.867339521297254e-05, Min w: 0.9746196269989014\n",
      "Iteration 300, Loss: 5.72429780731909e-05, Min w: 0.9686710238456726\n",
      "Iteration 310, Loss: 4.647089008358307e-05, Min w: 0.9753656387329102\n",
      "Iteration 320, Loss: 5.78252220293507e-05, Min w: 0.963132381439209\n",
      "Iteration 330, Loss: 5.34210485056974e-05, Min w: 0.9693477749824524\n",
      "Iteration 340, Loss: 4.3341067794244736e-05, Min w: 0.9769920110702515\n",
      "Iteration 350, Loss: 4.396995063871145e-05, Min w: 0.9773426055908203\n",
      "Iteration 360, Loss: 4.705826722783968e-05, Min w: 0.9740646481513977\n",
      "Iteration 370, Loss: 5.8299669035477564e-05, Min w: 0.9626590013504028\n",
      "Iteration 380, Loss: 5.409198274719529e-05, Min w: 0.9689579606056213\n",
      "Iteration 390, Loss: 5.734370643040165e-05, Min w: 0.9673838019371033\n",
      "Iteration 400, Loss: 4.539092333288863e-05, Min w: 0.9760204553604126\n",
      "Iteration 410, Loss: 4.5761051296722144e-05, Min w: 0.9741231799125671\n",
      "Iteration 420, Loss: 4.453651490621269e-05, Min w: 0.9762665033340454\n",
      "Iteration 430, Loss: 4.743320823763497e-05, Min w: 0.9738413095474243\n",
      "Iteration 440, Loss: 5.1928953325841576e-05, Min w: 0.9692338109016418\n",
      "Iteration 450, Loss: 4.503756281337701e-05, Min w: 0.973783016204834\n",
      "Iteration 460, Loss: 5.202900501899421e-05, Min w: 0.9703096151351929\n",
      "Iteration 470, Loss: 4.670961425290443e-05, Min w: 0.9752171635627747\n",
      "Iteration 480, Loss: 4.3093903514090925e-05, Min w: 0.9748677015304565\n",
      "Iteration 490, Loss: 4.2410461901454255e-05, Min w: 0.975360631942749\n",
      "Iteration 500, Loss: 4.4012140278937295e-05, Min w: 0.9762246608734131\n",
      "Iteration 510, Loss: 5.993220838718116e-05, Min w: 0.9621500968933105\n",
      "Iteration 520, Loss: 5.7218927395297214e-05, Min w: 0.9622241258621216\n",
      "Iteration 530, Loss: 4.394855204736814e-05, Min w: 0.9752672910690308\n",
      "Iteration 540, Loss: 4.613321289070882e-05, Min w: 0.9735158085823059\n",
      "Iteration 550, Loss: 4.832888225791976e-05, Min w: 0.9717733860015869\n",
      "Iteration 560, Loss: 4.472413638723083e-05, Min w: 0.9751216769218445\n",
      "Iteration 570, Loss: 4.331227682996541e-05, Min w: 0.9765786528587341\n",
      "Iteration 580, Loss: 4.521051232586615e-05, Min w: 0.976094126701355\n",
      "Iteration 590, Loss: 4.434979928191751e-05, Min w: 0.9744671583175659\n",
      "Iteration 600, Loss: 3.913229375029914e-05, Min w: 0.9797266721725464\n",
      "Iteration 610, Loss: 4.372168405097909e-05, Min w: 0.9755926728248596\n",
      "Iteration 620, Loss: 4.7421093768207356e-05, Min w: 0.9714316129684448\n",
      "Iteration 630, Loss: 4.3150568671990186e-05, Min w: 0.9766643643379211\n",
      "Iteration 640, Loss: 6.393089279299602e-05, Min w: 0.9622496366500854\n",
      "Iteration 650, Loss: 5.658297595800832e-05, Min w: 0.9628543257713318\n",
      "Iteration 660, Loss: 6.322241824818775e-05, Min w: 0.9585057497024536\n",
      "Iteration 670, Loss: 4.0944854845292866e-05, Min w: 0.9787161350250244\n",
      "Iteration 680, Loss: 4.1930692532332614e-05, Min w: 0.97603839635849\n",
      "Iteration 690, Loss: 4.87359102407936e-05, Min w: 0.9698126912117004\n",
      "Iteration 700, Loss: 3.995657243649475e-05, Min w: 0.9777401685714722\n",
      "Iteration 710, Loss: 4.658228499465622e-05, Min w: 0.9735671877861023\n",
      "Iteration 720, Loss: 3.747089431271888e-05, Min w: 0.979155957698822\n",
      "Iteration 730, Loss: 3.938346344511956e-05, Min w: 0.9781656861305237\n",
      "Iteration 740, Loss: 4.0667255234438926e-05, Min w: 0.9763261079788208\n",
      "Iteration 750, Loss: 3.997841486125253e-05, Min w: 0.9779905676841736\n",
      "Iteration 760, Loss: 3.828220360446721e-05, Min w: 0.9786241054534912\n",
      "Iteration 770, Loss: 4.934865137329325e-05, Min w: 0.9689862132072449\n",
      "Iteration 780, Loss: 3.886284684995189e-05, Min w: 0.9777392745018005\n",
      "Iteration 790, Loss: 3.782066414714791e-05, Min w: 0.9781593084335327\n",
      "Iteration 800, Loss: 3.877852577716112e-05, Min w: 0.9784486889839172\n",
      "Iteration 810, Loss: 3.672377351904288e-05, Min w: 0.9780592322349548\n",
      "Iteration 820, Loss: 3.6964363971492276e-05, Min w: 0.9792490005493164\n",
      "Iteration 830, Loss: 3.779226608457975e-05, Min w: 0.9784693121910095\n",
      "Iteration 840, Loss: 3.985755756730214e-05, Min w: 0.9774549007415771\n",
      "Iteration 850, Loss: 4.172667831880972e-05, Min w: 0.9755033850669861\n",
      "Iteration 860, Loss: 3.987984382547438e-05, Min w: 0.9757479429244995\n",
      "Iteration 870, Loss: 4.292481389711611e-05, Min w: 0.9743173122406006\n",
      "Iteration 880, Loss: 4.902162618236616e-05, Min w: 0.9681719541549683\n",
      "Iteration 890, Loss: 3.8254933315329254e-05, Min w: 0.9777746200561523\n",
      "Iteration 900, Loss: 3.726417344296351e-05, Min w: 0.9783152341842651\n",
      "Iteration 910, Loss: 6.693587056361139e-05, Min w: 0.9563730359077454\n",
      "Iteration 920, Loss: 3.6493402149062604e-05, Min w: 0.979185163974762\n",
      "Iteration 930, Loss: 3.9866103179519996e-05, Min w: 0.9767689108848572\n",
      "Iteration 940, Loss: 3.61572892870754e-05, Min w: 0.9793285131454468\n",
      "Iteration 950, Loss: 3.898630529874936e-05, Min w: 0.9787731170654297\n",
      "Iteration 960, Loss: 4.3057927541667596e-05, Min w: 0.9740433096885681\n",
      "Iteration 970, Loss: 8.711997361388057e-05, Min w: 0.9334964752197266\n",
      "Iteration 980, Loss: 3.8098733057267964e-05, Min w: 0.9776977896690369\n",
      "Iteration 990, Loss: 4.31099470006302e-05, Min w: 0.9746680855751038\n",
      "Iteration 1000, Loss: 4.6215089241741225e-05, Min w: 0.9721859097480774\n",
      "Iteration 1010, Loss: 3.905184712493792e-05, Min w: 0.9775799512863159\n",
      "Iteration 1020, Loss: 3.6407902371138334e-05, Min w: 0.9790605306625366\n",
      "Iteration 1030, Loss: 3.5813634895021096e-05, Min w: 0.9792662858963013\n",
      "Iteration 1040, Loss: 3.8937021599849686e-05, Min w: 0.9771692752838135\n",
      "Iteration 1050, Loss: 3.798819307121448e-05, Min w: 0.9769530892372131\n",
      "Iteration 1060, Loss: 3.6339828511700034e-05, Min w: 0.978682816028595\n",
      "Iteration 1070, Loss: 4.0250542951980606e-05, Min w: 0.9752287864685059\n",
      "Iteration 1080, Loss: 3.697305510286242e-05, Min w: 0.9780961871147156\n",
      "Iteration 1090, Loss: 3.516777724144049e-05, Min w: 0.9799866676330566\n",
      "Iteration 1100, Loss: 3.1932642741594464e-05, Min w: 0.9810751676559448\n",
      "Iteration 1110, Loss: 3.8074413168942556e-05, Min w: 0.9784810543060303\n",
      "Iteration 1120, Loss: 3.294103589723818e-05, Min w: 0.9801609516143799\n",
      "Iteration 1130, Loss: 3.449925861787051e-05, Min w: 0.9795771837234497\n",
      "Iteration 1140, Loss: 3.699310764204711e-05, Min w: 0.9782163500785828\n",
      "Iteration 1150, Loss: 3.9352707972284406e-05, Min w: 0.9770396947860718\n",
      "Iteration 1160, Loss: 3.697242573252879e-05, Min w: 0.9782553315162659\n",
      "Iteration 1170, Loss: 5.281436460791156e-05, Min w: 0.9652958512306213\n",
      "Iteration 1180, Loss: 3.968986857216805e-05, Min w: 0.9755806922912598\n",
      "Iteration 1190, Loss: 3.9379054214805365e-05, Min w: 0.975464940071106\n",
      "Iteration 1200, Loss: 5.8022065786644816e-05, Min w: 0.9607048630714417\n",
      "Iteration 1210, Loss: 3.776074663619511e-05, Min w: 0.9762388467788696\n",
      "Iteration 1220, Loss: 4.193431232124567e-05, Min w: 0.9734368324279785\n",
      "Iteration 1230, Loss: 3.941460818168707e-05, Min w: 0.9760323762893677\n",
      "Iteration 1240, Loss: 7.036166061880067e-05, Min w: 0.9474601745605469\n",
      "Iteration 0, Loss: 3.422764712013304e-05, Min w: 0.9791203141212463\n",
      "Iteration 10, Loss: 3.759490209631622e-05, Min w: 0.9758886694908142\n",
      "Iteration 20, Loss: 3.706241841427982e-05, Min w: 0.9777361750602722\n",
      "Iteration 30, Loss: 3.365607699379325e-05, Min w: 0.978932797908783\n",
      "Iteration 40, Loss: 4.921776780975051e-05, Min w: 0.9671671390533447\n",
      "Iteration 50, Loss: 3.1823237804928795e-05, Min w: 0.9818847179412842\n",
      "Iteration 60, Loss: 3.1880717870080844e-05, Min w: 0.9807856678962708\n",
      "Iteration 70, Loss: 4.0033814002526924e-05, Min w: 0.974116325378418\n",
      "Iteration 80, Loss: 3.3157848520204425e-05, Min w: 0.9795092940330505\n",
      "Iteration 90, Loss: 3.567942258086987e-05, Min w: 0.9772822856903076\n",
      "Iteration 100, Loss: 3.9884718717075884e-05, Min w: 0.9741933345794678\n",
      "Iteration 110, Loss: 3.225041291443631e-05, Min w: 0.9800516963005066\n",
      "Iteration 120, Loss: 3.2219173590419814e-05, Min w: 0.9805278182029724\n",
      "Iteration 130, Loss: 3.267376814619638e-05, Min w: 0.9807262420654297\n",
      "Iteration 140, Loss: 3.1915977160679176e-05, Min w: 0.9797864556312561\n",
      "Iteration 150, Loss: 2.9698032449232414e-05, Min w: 0.9820987582206726\n",
      "Iteration 160, Loss: 3.9504218875663355e-05, Min w: 0.9748340249061584\n",
      "Iteration 170, Loss: 3.4089043765561655e-05, Min w: 0.9790026545524597\n",
      "Iteration 180, Loss: 3.220624421373941e-05, Min w: 0.9809328317642212\n",
      "Iteration 190, Loss: 3.153982470394112e-05, Min w: 0.9804116487503052\n",
      "Iteration 200, Loss: 3.1217237847158685e-05, Min w: 0.9804023504257202\n",
      "Iteration 210, Loss: 2.9665823603863828e-05, Min w: 0.9821373820304871\n",
      "Iteration 220, Loss: 3.607929829740897e-05, Min w: 0.9766397476196289\n",
      "Iteration 230, Loss: 3.230520087527111e-05, Min w: 0.9792640209197998\n",
      "Iteration 240, Loss: 3.8838425098219886e-05, Min w: 0.9760854244232178\n",
      "Iteration 250, Loss: 3.778097016038373e-05, Min w: 0.9752821326255798\n",
      "Iteration 260, Loss: 3.987337913713418e-05, Min w: 0.9739450216293335\n",
      "Iteration 270, Loss: 4.265563256922178e-05, Min w: 0.9711282849311829\n",
      "Iteration 280, Loss: 3.7050653190817684e-05, Min w: 0.9757108688354492\n",
      "Iteration 290, Loss: 3.4051769034704193e-05, Min w: 0.9787850379943848\n",
      "Iteration 300, Loss: 3.455021578702144e-05, Min w: 0.9781915545463562\n",
      "Iteration 310, Loss: 2.92889671982266e-05, Min w: 0.9822565913200378\n",
      "Iteration 320, Loss: 2.9598015316878445e-05, Min w: 0.9823391437530518\n",
      "Iteration 330, Loss: 3.1133738957578316e-05, Min w: 0.9807614088058472\n",
      "Iteration 340, Loss: 3.5688095522345975e-05, Min w: 0.9765865206718445\n",
      "Iteration 350, Loss: 3.337274756631814e-05, Min w: 0.9787763357162476\n",
      "Iteration 360, Loss: 3.320141331641935e-05, Min w: 0.9790657162666321\n",
      "Iteration 370, Loss: 3.6168305086903274e-05, Min w: 0.9757363200187683\n",
      "Iteration 380, Loss: 4.107618588022888e-05, Min w: 0.9738845229148865\n",
      "Iteration 390, Loss: 3.591994027374312e-05, Min w: 0.9756230711936951\n",
      "Iteration 400, Loss: 3.0513214369420893e-05, Min w: 0.9808228015899658\n",
      "Iteration 410, Loss: 2.9946453651064076e-05, Min w: 0.9808866381645203\n",
      "Iteration 420, Loss: 3.963347990065813e-05, Min w: 0.9726479053497314\n",
      "Iteration 430, Loss: 4.0310300391865894e-05, Min w: 0.9732494950294495\n",
      "Iteration 440, Loss: 3.3789016015361995e-05, Min w: 0.978429913520813\n",
      "Iteration 450, Loss: 3.382028444320895e-05, Min w: 0.9783064126968384\n",
      "Iteration 460, Loss: 3.317056689411402e-05, Min w: 0.9785985946655273\n",
      "Iteration 470, Loss: 2.976008727273438e-05, Min w: 0.9809211492538452\n",
      "Iteration 480, Loss: 5.2452131058089435e-05, Min w: 0.9617540240287781\n",
      "Iteration 490, Loss: 2.9291104510775767e-05, Min w: 0.9825416803359985\n",
      "Iteration 500, Loss: 3.769576142076403e-05, Min w: 0.9742550253868103\n",
      "Iteration 510, Loss: 3.919734081136994e-05, Min w: 0.9738796353340149\n",
      "Iteration 520, Loss: 3.409708369872533e-05, Min w: 0.9774063229560852\n",
      "Iteration 530, Loss: 2.7263988158665597e-05, Min w: 0.9832294583320618\n",
      "Iteration 540, Loss: 2.887014670704957e-05, Min w: 0.9828697443008423\n",
      "Iteration 550, Loss: 3.600840864237398e-05, Min w: 0.9760433435440063\n",
      "Iteration 560, Loss: 2.969875822600443e-05, Min w: 0.9801697134971619\n",
      "Iteration 570, Loss: 2.8632723115151748e-05, Min w: 0.9826866984367371\n",
      "Iteration 580, Loss: 3.0693634471390396e-05, Min w: 0.9801895618438721\n",
      "Iteration 590, Loss: 3.099498280789703e-05, Min w: 0.9815021753311157\n",
      "Iteration 600, Loss: 3.207160625606775e-05, Min w: 0.979249894618988\n",
      "Iteration 610, Loss: 2.6648993298294954e-05, Min w: 0.9832993745803833\n",
      "Iteration 620, Loss: 3.265470513724722e-05, Min w: 0.9795699715614319\n",
      "Iteration 630, Loss: 3.158388426527381e-05, Min w: 0.9792577624320984\n",
      "Iteration 640, Loss: 2.8294543881202117e-05, Min w: 0.9819832444190979\n",
      "Iteration 650, Loss: 2.7523863536771387e-05, Min w: 0.9828565716743469\n",
      "Iteration 660, Loss: 2.729520019784104e-05, Min w: 0.9831337332725525\n",
      "Iteration 670, Loss: 3.237033524783328e-05, Min w: 0.9787216186523438\n",
      "Iteration 680, Loss: 2.813015271385666e-05, Min w: 0.9830641150474548\n",
      "Iteration 690, Loss: 2.812312959576957e-05, Min w: 0.9824057817459106\n",
      "Iteration 700, Loss: 3.3056425309041515e-05, Min w: 0.9791702032089233\n",
      "Iteration 710, Loss: 4.619754690793343e-05, Min w: 0.9672089219093323\n",
      "Iteration 720, Loss: 2.925242188211996e-05, Min w: 0.9815447330474854\n",
      "Iteration 730, Loss: 2.8709115213132463e-05, Min w: 0.9818590879440308\n",
      "Iteration 740, Loss: 3.763776840060018e-05, Min w: 0.9757168292999268\n",
      "Iteration 750, Loss: 2.6471838282304816e-05, Min w: 0.9836177825927734\n",
      "Iteration 760, Loss: 3.000569085997995e-05, Min w: 0.9801795482635498\n",
      "Iteration 770, Loss: 2.9429216738208197e-05, Min w: 0.980689525604248\n",
      "Iteration 780, Loss: 3.0013665309525095e-05, Min w: 0.9808257818222046\n",
      "Iteration 790, Loss: 2.6781592168845236e-05, Min w: 0.9836403131484985\n",
      "Iteration 800, Loss: 4.6811532229185104e-05, Min w: 0.9649789333343506\n",
      "Iteration 810, Loss: 3.1101979402592406e-05, Min w: 0.9793253540992737\n",
      "Iteration 820, Loss: 3.1785122700966895e-05, Min w: 0.9803078770637512\n",
      "Iteration 830, Loss: 2.6492994948057458e-05, Min w: 0.9828016757965088\n",
      "Iteration 840, Loss: 2.5928376999218017e-05, Min w: 0.9840185642242432\n",
      "Iteration 850, Loss: 2.591020347608719e-05, Min w: 0.9837916493415833\n",
      "Iteration 860, Loss: 2.6581863494357094e-05, Min w: 0.9831625819206238\n",
      "Iteration 870, Loss: 2.91165506496327e-05, Min w: 0.9806104898452759\n",
      "Iteration 880, Loss: 3.4037908335449174e-05, Min w: 0.9772560000419617\n",
      "Iteration 890, Loss: 2.5995994292316027e-05, Min w: 0.9839509725570679\n",
      "Iteration 900, Loss: 2.7372982003726065e-05, Min w: 0.9821566343307495\n",
      "Iteration 910, Loss: 3.5348839446669444e-05, Min w: 0.9750370979309082\n",
      "Iteration 920, Loss: 2.7184813006897457e-05, Min w: 0.982570230960846\n",
      "Iteration 930, Loss: 4.18238305428531e-05, Min w: 0.9693436026573181\n",
      "Iteration 940, Loss: 2.8783924790332094e-05, Min w: 0.9817851781845093\n",
      "Iteration 950, Loss: 2.4462220608256757e-05, Min w: 0.9841946959495544\n",
      "Iteration 960, Loss: 5.17748630954884e-05, Min w: 0.9612754583358765\n",
      "Iteration 970, Loss: 4.6242857933975756e-05, Min w: 0.9671452045440674\n",
      "Iteration 980, Loss: 2.554519051045645e-05, Min w: 0.983333170413971\n",
      "Iteration 990, Loss: 2.5753508452908136e-05, Min w: 0.9836636185646057\n",
      "Iteration 1000, Loss: 2.813232276821509e-05, Min w: 0.9815382361412048\n",
      "Iteration 1010, Loss: 2.8309203116805293e-05, Min w: 0.9817652702331543\n",
      "Iteration 1020, Loss: 2.5311721401521936e-05, Min w: 0.9844602346420288\n",
      "Iteration 1030, Loss: 2.6698262445279397e-05, Min w: 0.983293890953064\n",
      "Iteration 1040, Loss: 2.3830401914892718e-05, Min w: 0.9844064116477966\n",
      "Iteration 1050, Loss: 4.45772020611912e-05, Min w: 0.9683252573013306\n",
      "Iteration 1060, Loss: 2.7590725949266925e-05, Min w: 0.9820699691772461\n",
      "Iteration 1070, Loss: 2.60806245933054e-05, Min w: 0.9837380051612854\n",
      "Iteration 1080, Loss: 2.7297735869069584e-05, Min w: 0.982640266418457\n",
      "Iteration 1090, Loss: 3.01130858133547e-05, Min w: 0.9805811643600464\n",
      "Iteration 1100, Loss: 4.6353816287592053e-05, Min w: 0.9676924347877502\n",
      "Iteration 1110, Loss: 2.4221031708293594e-05, Min w: 0.9853976368904114\n",
      "Iteration 1120, Loss: 2.4541754100937396e-05, Min w: 0.9845558404922485\n",
      "Iteration 1130, Loss: 2.5651414034655318e-05, Min w: 0.9831064343452454\n",
      "Iteration 1140, Loss: 2.7654772566165775e-05, Min w: 0.9828031063079834\n",
      "Iteration 1150, Loss: 3.3884534786920995e-05, Min w: 0.976350724697113\n",
      "Iteration 1160, Loss: 3.299471427453682e-05, Min w: 0.9782726168632507\n",
      "Iteration 1170, Loss: 2.514329935365822e-05, Min w: 0.9838495254516602\n",
      "Iteration 1180, Loss: 3.231029040762223e-05, Min w: 0.9776909351348877\n",
      "Iteration 1190, Loss: 2.2044538127374835e-05, Min w: 0.9859477877616882\n",
      "Iteration 1200, Loss: 2.457881964801345e-05, Min w: 0.9846570491790771\n",
      "Iteration 1210, Loss: 3.362685674801469e-05, Min w: 0.9773422479629517\n",
      "Iteration 1220, Loss: 2.5667213776614517e-05, Min w: 0.983807384967804\n",
      "Iteration 1230, Loss: 2.5414308765903115e-05, Min w: 0.9834150075912476\n",
      "Iteration 1240, Loss: 2.2689802790409885e-05, Min w: 0.9851953387260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  25%|██▌       | 6/24 [09:15<27:45, 92.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.009098983132742402, 'L2_avg': 0.010411645292843257, 'End_point_L1_avg': 0.00877508712409177, 'End_point_L2_avg': 0.008994844387406106}\n",
      "Iteration 0, Loss: 0.0014480284880846739, Min w: 0.0\n",
      "Iteration 10, Loss: 0.001140038250014186, Min w: 0.0\n",
      "Iteration 20, Loss: 0.001011367654427886, Min w: 0.0\n",
      "Iteration 30, Loss: 0.001019175280816853, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0010512737790122628, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0010580564849078655, Min w: 0.0\n",
      "Iteration 60, Loss: 0.001000166404992342, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0009045155602507293, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007928089471533895, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007151059107854962, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006938625010661781, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006717081414535642, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006579406908713281, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006405775784514844, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006217087502591312, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006067425129003823, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005927187739871442, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005814187461510301, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005679872701875865, Min w: 0.0\n",
      "Iteration 190, Loss: 0.000558365776669234, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005437989020720124, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005306552047841251, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005223898915573955, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005106557509861887, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005029460298828781, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004959837533533573, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00048657675506547093, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00047633846406824887, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00046960293548181653, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00046737122465856373, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004714007955044508, Min w: 0.0\n",
      "Iteration 310, Loss: 0.00046047530486248434, Min w: 0.0\n",
      "Iteration 320, Loss: 0.00045258866157382727, Min w: 0.0\n",
      "Iteration 330, Loss: 0.000445893791038543, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000445477751782164, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004295022808946669, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004416436713654548, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0004319983709137887, Min w: 0.0\n",
      "Iteration 380, Loss: 0.00043895846465602517, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000442127842688933, Min w: 0.0\n",
      "Iteration 400, Loss: 0.00043699066736735404, Min w: 0.0\n",
      "Iteration 410, Loss: 0.00045692891580983996, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004596147919073701, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004485798126552254, Min w: 0.0\n",
      "Iteration 440, Loss: 0.00044394383439794183, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00044011769932694733, Min w: 0.0\n",
      "Iteration 460, Loss: 0.00042081778519786894, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00044081523083150387, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0004047088441438973, Min w: 0.0\n",
      "Iteration 490, Loss: 0.00039912908687256277, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004065428511239588, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00040289873140864074, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00039636221481487155, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0003852108202408999, Min w: 0.0\n",
      "Iteration 540, Loss: 0.00039311699219979346, Min w: 0.0\n",
      "Iteration 550, Loss: 0.00038511501043103635, Min w: 4.0637655465419695e-44\n",
      "Iteration 560, Loss: 0.00037237894139252603, Min w: 1.8584720883107886e-40\n",
      "Iteration 570, Loss: 0.0003752766642719507, Min w: 3.2390184434177266e-37\n",
      "Iteration 580, Loss: 0.00037039973540231586, Min w: 2.1907857863619683e-29\n",
      "Iteration 590, Loss: 0.00037087377859279513, Min w: 2.4203144277744893e-27\n",
      "Iteration 600, Loss: 0.0003702347166836262, Min w: 4.865637857063704e-25\n",
      "Iteration 610, Loss: 0.0003677546919789165, Min w: 3.299492924033609e-20\n",
      "Iteration 620, Loss: 0.0003649781283456832, Min w: 5.488977811819167e-18\n",
      "Iteration 630, Loss: 0.0003611111606005579, Min w: 1.395589377467196e-15\n",
      "Iteration 640, Loss: 0.000356372504029423, Min w: 8.366708205160417e-14\n",
      "Iteration 650, Loss: 0.00035829885746352375, Min w: 4.4607229693870154e-13\n",
      "Iteration 660, Loss: 0.00036023242864757776, Min w: 2.726182181476272e-13\n",
      "Iteration 670, Loss: 0.0003628979029599577, Min w: 2.9021703524525697e-14\n",
      "Iteration 680, Loss: 0.0003659011563286185, Min w: 2.02970882099465e-17\n",
      "Iteration 690, Loss: 0.00036905979504808784, Min w: 3.8459288380585675e-23\n",
      "Iteration 700, Loss: 0.000381365796783939, Min w: 7.38901716463077e-33\n",
      "Iteration 710, Loss: 0.0003814793308265507, Min w: 3.90962271546624e-43\n",
      "Iteration 720, Loss: 0.00038251158548519015, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0003826075990218669, Min w: 0.0\n",
      "Iteration 740, Loss: 0.00037918146699666977, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0003777282254304737, Min w: 4.400077177979926e-43\n",
      "Iteration 760, Loss: 0.00037527974927797914, Min w: 1.978311132979847e-40\n",
      "Iteration 770, Loss: 0.0003758832172024995, Min w: 3.135298277144879e-35\n",
      "Iteration 780, Loss: 0.0003743748238775879, Min w: 1.088864384460119e-32\n",
      "Iteration 790, Loss: 0.000374870200175792, Min w: 3.4966215086791384e-29\n",
      "Iteration 800, Loss: 0.00037378788692876697, Min w: 1.220423518270897e-26\n",
      "Iteration 810, Loss: 0.0003722244000528008, Min w: 4.279769519316467e-23\n",
      "Iteration 820, Loss: 0.000377565564122051, Min w: 2.032556036762899e-21\n",
      "Iteration 830, Loss: 0.0003866212791763246, Min w: 3.75452647826389e-18\n",
      "Iteration 840, Loss: 0.0003748276794794947, Min w: 1.4270942385447277e-15\n",
      "Iteration 850, Loss: 0.00036732034641318023, Min w: 4.722215674046737e-12\n",
      "Iteration 860, Loss: 0.0003702883841469884, Min w: 6.993980949943079e-10\n",
      "Iteration 870, Loss: 0.0003695642517413944, Min w: 6.833680288309552e-08\n",
      "Iteration 880, Loss: 0.00037916022120043635, Min w: 2.16400276258355e-05\n",
      "Iteration 890, Loss: 0.0003680241934489459, Min w: 0.0009681180818006396\n",
      "Iteration 900, Loss: 0.00036435527727007866, Min w: 0.030916163697838783\n",
      "Iteration 910, Loss: 0.0003539063618518412, Min w: 0.1060248613357544\n",
      "Iteration 920, Loss: 0.00035742929321713746, Min w: 0.1176467314362526\n",
      "Iteration 930, Loss: 0.00033387340954504907, Min w: 0.1314515620470047\n",
      "Iteration 940, Loss: 0.00032454627216793597, Min w: 0.12932875752449036\n",
      "Iteration 950, Loss: 0.0003220912767574191, Min w: 0.13110576570034027\n",
      "Iteration 960, Loss: 0.00032034656032919884, Min w: 0.13655588030815125\n",
      "Iteration 970, Loss: 0.00032719658338464797, Min w: 0.13666968047618866\n",
      "Iteration 980, Loss: 0.0003183200897183269, Min w: 0.15178190171718597\n",
      "Iteration 990, Loss: 0.0003154381993226707, Min w: 0.1638249307870865\n",
      "Iteration 1000, Loss: 0.00032087875297293067, Min w: 0.16943064332008362\n",
      "Iteration 1010, Loss: 0.00031182225211523473, Min w: 0.17944379150867462\n",
      "Iteration 1020, Loss: 0.00031073857098817825, Min w: 0.17183339595794678\n",
      "Iteration 1030, Loss: 0.0003070352540817112, Min w: 0.19185879826545715\n",
      "Iteration 1040, Loss: 0.0003078379959333688, Min w: 0.18655475974082947\n",
      "Iteration 1050, Loss: 0.000301754946121946, Min w: 0.19785191118717194\n",
      "Iteration 1060, Loss: 0.0002994215174112469, Min w: 0.20714063942432404\n",
      "Iteration 1070, Loss: 0.0002919450344052166, Min w: 0.21253031492233276\n",
      "Iteration 1080, Loss: 0.00029693986289203167, Min w: 0.2154034525156021\n",
      "Iteration 1090, Loss: 0.0002894698118325323, Min w: 0.22586458921432495\n",
      "Iteration 1100, Loss: 0.00028984452364966273, Min w: 0.22375252842903137\n",
      "Iteration 1110, Loss: 0.0002903161512222141, Min w: 0.23155845701694489\n",
      "Iteration 1120, Loss: 0.00028372753877192736, Min w: 0.23128743469715118\n",
      "Iteration 1130, Loss: 0.0002776338660623878, Min w: 0.2545022666454315\n",
      "Iteration 1140, Loss: 0.00028187010320834816, Min w: 0.24905610084533691\n",
      "Iteration 1150, Loss: 0.00027808104641735554, Min w: 0.2467999905347824\n",
      "Iteration 1160, Loss: 0.0002756370813585818, Min w: 0.25477150082588196\n",
      "Iteration 1170, Loss: 0.0002820616355165839, Min w: 0.2579793334007263\n",
      "Iteration 1180, Loss: 0.0002685182262212038, Min w: 0.26946645975112915\n",
      "Iteration 1190, Loss: 0.0002737612521741539, Min w: 0.2830772399902344\n",
      "Iteration 1200, Loss: 0.00026535324286669493, Min w: 0.2746799886226654\n",
      "Iteration 1210, Loss: 0.00025969298440031707, Min w: 0.2925777733325958\n",
      "Iteration 1220, Loss: 0.00026680954033508897, Min w: 0.27330684661865234\n",
      "Iteration 1230, Loss: 0.0002596105041448027, Min w: 0.29752659797668457\n",
      "Iteration 1240, Loss: 0.0002661534526851028, Min w: 0.3003300130367279\n",
      "Iteration 0, Loss: 0.0002502011484466493, Min w: 0.3145861029624939\n",
      "Iteration 10, Loss: 0.0002496024826541543, Min w: 0.3186292350292206\n",
      "Iteration 20, Loss: 0.0002506741730030626, Min w: 0.3098350763320923\n",
      "Iteration 30, Loss: 0.00025066881789825857, Min w: 0.3205508589744568\n",
      "Iteration 40, Loss: 0.0002540225686971098, Min w: 0.3250294029712677\n",
      "Iteration 50, Loss: 0.0002466026053298265, Min w: 0.3234357237815857\n",
      "Iteration 60, Loss: 0.0002420830714982003, Min w: 0.3347678780555725\n",
      "Iteration 70, Loss: 0.0002386263367952779, Min w: 0.344250351190567\n",
      "Iteration 80, Loss: 0.00023742105986457318, Min w: 0.34800395369529724\n",
      "Iteration 90, Loss: 0.00023571249039378017, Min w: 0.3467794954776764\n",
      "Iteration 100, Loss: 0.0002332639996893704, Min w: 0.3589255213737488\n",
      "Iteration 110, Loss: 0.00022998791246209294, Min w: 0.36860838532447815\n",
      "Iteration 120, Loss: 0.00022928428370505571, Min w: 0.3640718162059784\n",
      "Iteration 130, Loss: 0.00023584072187077254, Min w: 0.3663228154182434\n",
      "Iteration 140, Loss: 0.00022817013086751103, Min w: 0.376989483833313\n",
      "Iteration 150, Loss: 0.00022671736951451749, Min w: 0.37744611501693726\n",
      "Iteration 160, Loss: 0.0002201012976001948, Min w: 0.38161972165107727\n",
      "Iteration 170, Loss: 0.00021949457004666328, Min w: 0.39646896719932556\n",
      "Iteration 180, Loss: 0.00022159426589496434, Min w: 0.39565253257751465\n",
      "Iteration 190, Loss: 0.00022733754303772002, Min w: 0.38367733359336853\n",
      "Iteration 200, Loss: 0.00023072591284289956, Min w: 0.3891580104827881\n",
      "Iteration 210, Loss: 0.00021357156219892204, Min w: 0.39986902475357056\n",
      "Iteration 220, Loss: 0.0002171692467527464, Min w: 0.4042130708694458\n",
      "Iteration 230, Loss: 0.00021173460118006915, Min w: 0.407917320728302\n",
      "Iteration 240, Loss: 0.00020941838738508523, Min w: 0.4146735966205597\n",
      "Iteration 250, Loss: 0.00020550706540234387, Min w: 0.4271899461746216\n",
      "Iteration 260, Loss: 0.00020435980695765465, Min w: 0.43253034353256226\n",
      "Iteration 270, Loss: 0.0002090590278385207, Min w: 0.41926419734954834\n",
      "Iteration 280, Loss: 0.0002035718207480386, Min w: 0.43147704005241394\n",
      "Iteration 290, Loss: 0.00020579980628099293, Min w: 0.4345458447933197\n",
      "Iteration 300, Loss: 0.000200558002688922, Min w: 0.438632071018219\n",
      "Iteration 310, Loss: 0.0001971713500097394, Min w: 0.44315436482429504\n",
      "Iteration 320, Loss: 0.00019287753093522042, Min w: 0.44687700271606445\n",
      "Iteration 330, Loss: 0.00019500692724250257, Min w: 0.4471307396888733\n",
      "Iteration 340, Loss: 0.00019511881691869348, Min w: 0.44935891032218933\n",
      "Iteration 350, Loss: 0.00020688006770797074, Min w: 0.44183123111724854\n",
      "Iteration 360, Loss: 0.00019097926269751042, Min w: 0.4579908549785614\n",
      "Iteration 370, Loss: 0.0001905459794215858, Min w: 0.46032142639160156\n",
      "Iteration 380, Loss: 0.00018939957953989506, Min w: 0.47597578167915344\n",
      "Iteration 390, Loss: 0.0001880105846794322, Min w: 0.4677942097187042\n",
      "Iteration 400, Loss: 0.00021888152696192265, Min w: 0.4557759463787079\n",
      "Iteration 410, Loss: 0.00019043903739657253, Min w: 0.4675999879837036\n",
      "Iteration 420, Loss: 0.00018505197658669204, Min w: 0.47688034176826477\n",
      "Iteration 430, Loss: 0.00018543134501669556, Min w: 0.48083987832069397\n",
      "Iteration 440, Loss: 0.0001835231960285455, Min w: 0.47362908720970154\n",
      "Iteration 450, Loss: 0.00017954612849280238, Min w: 0.48785656690597534\n",
      "Iteration 460, Loss: 0.0001772545656422153, Min w: 0.4938366413116455\n",
      "Iteration 470, Loss: 0.00017893929907586426, Min w: 0.49968957901000977\n",
      "Iteration 480, Loss: 0.00018167533562518656, Min w: 0.4881543219089508\n",
      "Iteration 490, Loss: 0.00017420740914531052, Min w: 0.4985660910606384\n",
      "Iteration 500, Loss: 0.00017401766672264785, Min w: 0.5070211291313171\n",
      "Iteration 510, Loss: 0.00017281925829593092, Min w: 0.5153067111968994\n",
      "Iteration 520, Loss: 0.00017898634541779757, Min w: 0.5177539587020874\n",
      "Iteration 530, Loss: 0.00017218654102180153, Min w: 0.5089332461357117\n",
      "Iteration 540, Loss: 0.00017278920859098434, Min w: 0.5128856301307678\n",
      "Iteration 550, Loss: 0.0001715158432489261, Min w: 0.5193271040916443\n",
      "Iteration 560, Loss: 0.00016795338888186961, Min w: 0.5222453474998474\n",
      "Iteration 570, Loss: 0.00016851976397447288, Min w: 0.5164471864700317\n",
      "Iteration 580, Loss: 0.00016635088832117617, Min w: 0.5229383111000061\n",
      "Iteration 590, Loss: 0.00017078295059036463, Min w: 0.5285367369651794\n",
      "Iteration 600, Loss: 0.0001648577890591696, Min w: 0.5272483825683594\n",
      "Iteration 610, Loss: 0.00016796044656075537, Min w: 0.5365114212036133\n",
      "Iteration 620, Loss: 0.0001660892303334549, Min w: 0.5350337624549866\n",
      "Iteration 630, Loss: 0.0001619389367988333, Min w: 0.5422930717468262\n",
      "Iteration 640, Loss: 0.00015760958194732666, Min w: 0.5441691279411316\n",
      "Iteration 650, Loss: 0.00015931634698063135, Min w: 0.551152229309082\n",
      "Iteration 660, Loss: 0.00015745424025226384, Min w: 0.5477740168571472\n",
      "Iteration 670, Loss: 0.00016070900892373174, Min w: 0.5535379648208618\n",
      "Iteration 680, Loss: 0.00017271262186113745, Min w: 0.5417504906654358\n",
      "Iteration 690, Loss: 0.00016255388618446887, Min w: 0.5521553754806519\n",
      "Iteration 700, Loss: 0.00017033620679285377, Min w: 0.5582398772239685\n",
      "Iteration 710, Loss: 0.00015628519759047776, Min w: 0.5626476407051086\n",
      "Iteration 720, Loss: 0.0001523607352282852, Min w: 0.5665974020957947\n",
      "Iteration 730, Loss: 0.00016054951993282884, Min w: 0.5693957209587097\n",
      "Iteration 740, Loss: 0.00015380939294118434, Min w: 0.5647015571594238\n",
      "Iteration 750, Loss: 0.00015008366608526558, Min w: 0.5709241032600403\n",
      "Iteration 760, Loss: 0.00015399233961943537, Min w: 0.5752267837524414\n",
      "Iteration 770, Loss: 0.00015972489200066775, Min w: 0.5743833780288696\n",
      "Iteration 780, Loss: 0.0001517947093816474, Min w: 0.5801910161972046\n",
      "Iteration 790, Loss: 0.00014936691150069237, Min w: 0.5781239867210388\n",
      "Iteration 800, Loss: 0.00014775953604839742, Min w: 0.5756445527076721\n",
      "Iteration 810, Loss: 0.00014747778186574578, Min w: 0.5843316912651062\n",
      "Iteration 820, Loss: 0.00015761346730869263, Min w: 0.5741798877716064\n",
      "Iteration 830, Loss: 0.00015297869686037302, Min w: 0.5855763554573059\n",
      "Iteration 840, Loss: 0.0001453664299333468, Min w: 0.5924593806266785\n",
      "Iteration 850, Loss: 0.00014484013081528246, Min w: 0.589372456073761\n",
      "Iteration 860, Loss: 0.0001419348845956847, Min w: 0.5962374210357666\n",
      "Iteration 870, Loss: 0.00014694871788378805, Min w: 0.5922735929489136\n",
      "Iteration 880, Loss: 0.0001391959813190624, Min w: 0.6027246713638306\n",
      "Iteration 890, Loss: 0.0001381714828312397, Min w: 0.6024457812309265\n",
      "Iteration 900, Loss: 0.00014067340816836804, Min w: 0.6093451380729675\n",
      "Iteration 910, Loss: 0.00014448903675656766, Min w: 0.6036756634712219\n",
      "Iteration 920, Loss: 0.00013587095600087196, Min w: 0.617476224899292\n",
      "Iteration 930, Loss: 0.00014038864173926413, Min w: 0.615338921546936\n",
      "Iteration 940, Loss: 0.00013562488311436027, Min w: 0.6177009344100952\n",
      "Iteration 950, Loss: 0.0001660495763644576, Min w: 0.604686439037323\n",
      "Iteration 960, Loss: 0.0001370335230603814, Min w: 0.625795304775238\n",
      "Iteration 970, Loss: 0.0001339058653684333, Min w: 0.6231600642204285\n",
      "Iteration 980, Loss: 0.00013972683518659323, Min w: 0.6217889785766602\n",
      "Iteration 990, Loss: 0.00013026683882344514, Min w: 0.6417869329452515\n",
      "Iteration 1000, Loss: 0.00012990807590540498, Min w: 0.6338945031166077\n",
      "Iteration 1010, Loss: 0.000129850217490457, Min w: 0.6333270072937012\n",
      "Iteration 1020, Loss: 0.00012892231461592019, Min w: 0.6319907903671265\n",
      "Iteration 1030, Loss: 0.0001376987056573853, Min w: 0.6304339170455933\n",
      "Iteration 1040, Loss: 0.0001279568678000942, Min w: 0.6407192945480347\n",
      "Iteration 1050, Loss: 0.0001258605916518718, Min w: 0.6451584100723267\n",
      "Iteration 1060, Loss: 0.00012577237794175744, Min w: 0.6456534266471863\n",
      "Iteration 1070, Loss: 0.00013480574125424027, Min w: 0.6374759674072266\n",
      "Iteration 1080, Loss: 0.00012665745452977717, Min w: 0.6454124450683594\n",
      "Iteration 1090, Loss: 0.00012940718443132937, Min w: 0.6474279761314392\n",
      "Iteration 1100, Loss: 0.00013484239752870053, Min w: 0.6517671346664429\n",
      "Iteration 1110, Loss: 0.0001250615605385974, Min w: 0.6568174958229065\n",
      "Iteration 1120, Loss: 0.00012533724657259881, Min w: 0.6527093648910522\n",
      "Iteration 1130, Loss: 0.00012106270878575742, Min w: 0.6622251272201538\n",
      "Iteration 1140, Loss: 0.00012839073315262794, Min w: 0.6579722166061401\n",
      "Iteration 1150, Loss: 0.00012123813212383538, Min w: 0.6693553924560547\n",
      "Iteration 1160, Loss: 0.00012090970994904637, Min w: 0.6661059260368347\n",
      "Iteration 1170, Loss: 0.0001343319017905742, Min w: 0.6599422097206116\n",
      "Iteration 1180, Loss: 0.00011637002899078652, Min w: 0.6732654571533203\n",
      "Iteration 1190, Loss: 0.0001221006241394207, Min w: 0.6683761477470398\n",
      "Iteration 1200, Loss: 0.00012154754949733615, Min w: 0.6681880354881287\n",
      "Iteration 1210, Loss: 0.00012037668784614652, Min w: 0.6752446889877319\n",
      "Iteration 1220, Loss: 0.0001232587092090398, Min w: 0.6700131893157959\n",
      "Iteration 1230, Loss: 0.00012590468395501375, Min w: 0.6714706420898438\n",
      "Iteration 1240, Loss: 0.0001132645775214769, Min w: 0.6834608912467957\n",
      "Iteration 0, Loss: 0.00012712071475107223, Min w: 0.6759095191955566\n",
      "Iteration 10, Loss: 0.00011519800318637863, Min w: 0.6900206804275513\n",
      "Iteration 20, Loss: 0.00011581624858081341, Min w: 0.683219850063324\n",
      "Iteration 30, Loss: 0.00011282811465207487, Min w: 0.6856299042701721\n",
      "Iteration 40, Loss: 0.00011225775961065665, Min w: 0.6898432374000549\n",
      "Iteration 50, Loss: 0.00011054514470743015, Min w: 0.694096028804779\n",
      "Iteration 60, Loss: 0.00011545595043571666, Min w: 0.6926912069320679\n",
      "Iteration 70, Loss: 0.00011760466441046447, Min w: 0.6897721290588379\n",
      "Iteration 80, Loss: 0.00011027541768271476, Min w: 0.6915172934532166\n",
      "Iteration 90, Loss: 0.00011615378753049299, Min w: 0.6968264579772949\n",
      "Iteration 100, Loss: 0.00010792610555654392, Min w: 0.7001097798347473\n",
      "Iteration 110, Loss: 0.00010683075379347429, Min w: 0.7060781121253967\n",
      "Iteration 120, Loss: 0.00010735885007306933, Min w: 0.7052716016769409\n",
      "Iteration 130, Loss: 0.00011167959019076079, Min w: 0.7053025960922241\n",
      "Iteration 140, Loss: 0.00011290955444565043, Min w: 0.6978062391281128\n",
      "Iteration 150, Loss: 0.000112797504698392, Min w: 0.6988237500190735\n",
      "Iteration 160, Loss: 0.00011761474161176011, Min w: 0.7023344039916992\n",
      "Iteration 170, Loss: 0.00011148572230013087, Min w: 0.7144064903259277\n",
      "Iteration 180, Loss: 0.0001060424474417232, Min w: 0.7133609056472778\n",
      "Iteration 190, Loss: 0.00010551937884883955, Min w: 0.715735673904419\n",
      "Iteration 200, Loss: 0.00010342975292587653, Min w: 0.7154837250709534\n",
      "Iteration 210, Loss: 0.00010437529272167012, Min w: 0.7243308424949646\n",
      "Iteration 220, Loss: 0.00010355442645959556, Min w: 0.7210885882377625\n",
      "Iteration 230, Loss: 0.00010456350719323382, Min w: 0.7221272587776184\n",
      "Iteration 240, Loss: 0.00010433133138576522, Min w: 0.7285594344139099\n",
      "Iteration 250, Loss: 0.00010058606858365238, Min w: 0.7282168865203857\n",
      "Iteration 260, Loss: 0.00010865252261282876, Min w: 0.7311328649520874\n",
      "Iteration 270, Loss: 9.988684178097174e-05, Min w: 0.732144832611084\n",
      "Iteration 280, Loss: 9.973104897653684e-05, Min w: 0.731428325176239\n",
      "Iteration 290, Loss: 0.0001096413325285539, Min w: 0.7187355756759644\n",
      "Iteration 300, Loss: 9.669193968875334e-05, Min w: 0.7389644384384155\n",
      "Iteration 310, Loss: 9.976705041481182e-05, Min w: 0.7265971899032593\n",
      "Iteration 320, Loss: 0.00010117929195985198, Min w: 0.7326125502586365\n",
      "Iteration 330, Loss: 9.76536757661961e-05, Min w: 0.7406247854232788\n",
      "Iteration 340, Loss: 0.00010355423000873998, Min w: 0.7344301342964172\n",
      "Iteration 350, Loss: 0.00010037911124527454, Min w: 0.7323245406150818\n",
      "Iteration 360, Loss: 9.691340528661385e-05, Min w: 0.7429041266441345\n",
      "Iteration 370, Loss: 0.00010197585652349517, Min w: 0.7468562722206116\n",
      "Iteration 380, Loss: 9.728121221996844e-05, Min w: 0.7435059547424316\n",
      "Iteration 390, Loss: 9.429336932953447e-05, Min w: 0.7480261921882629\n",
      "Iteration 400, Loss: 9.515308192931116e-05, Min w: 0.7490679621696472\n",
      "Iteration 410, Loss: 9.762163972482085e-05, Min w: 0.7486818432807922\n",
      "Iteration 420, Loss: 9.332417539553717e-05, Min w: 0.7511236071586609\n",
      "Iteration 430, Loss: 9.452416270505637e-05, Min w: 0.7524904608726501\n",
      "Iteration 440, Loss: 9.395492088515311e-05, Min w: 0.7534679770469666\n",
      "Iteration 450, Loss: 0.00010390301031293347, Min w: 0.7376385927200317\n",
      "Iteration 460, Loss: 9.5689894806128e-05, Min w: 0.7566341757774353\n",
      "Iteration 470, Loss: 9.889147622743621e-05, Min w: 0.7534202337265015\n",
      "Iteration 480, Loss: 9.377551032230258e-05, Min w: 0.7561345100402832\n",
      "Iteration 490, Loss: 0.00010633594501996413, Min w: 0.7553356885910034\n",
      "Iteration 500, Loss: 9.95985756162554e-05, Min w: 0.7535147666931152\n",
      "Iteration 510, Loss: 8.905599679565057e-05, Min w: 0.7667699456214905\n",
      "Iteration 520, Loss: 9.02104948181659e-05, Min w: 0.7649722695350647\n",
      "Iteration 530, Loss: 9.628482803236693e-05, Min w: 0.7528507709503174\n",
      "Iteration 540, Loss: 8.815922046778724e-05, Min w: 0.7745863795280457\n",
      "Iteration 550, Loss: 8.56688420753926e-05, Min w: 0.7723390460014343\n",
      "Iteration 560, Loss: 9.318310912931338e-05, Min w: 0.7670124173164368\n",
      "Iteration 570, Loss: 9.125762153416872e-05, Min w: 0.7699938416481018\n",
      "Iteration 580, Loss: 8.75137047842145e-05, Min w: 0.776765763759613\n",
      "Iteration 590, Loss: 9.29773086681962e-05, Min w: 0.764940083026886\n",
      "Iteration 600, Loss: 8.633271500002593e-05, Min w: 0.7720972299575806\n",
      "Iteration 610, Loss: 8.850236918078735e-05, Min w: 0.7737771272659302\n",
      "Iteration 620, Loss: 8.490117033943534e-05, Min w: 0.7841162085533142\n",
      "Iteration 630, Loss: 9.402276191394776e-05, Min w: 0.7751489281654358\n",
      "Iteration 640, Loss: 8.795280882623047e-05, Min w: 0.7822248339653015\n",
      "Iteration 650, Loss: 8.397939382120967e-05, Min w: 0.7856080532073975\n",
      "Iteration 660, Loss: 8.601185982115567e-05, Min w: 0.7802807688713074\n",
      "Iteration 670, Loss: 8.400611841352656e-05, Min w: 0.7814362049102783\n",
      "Iteration 680, Loss: 8.514630462741479e-05, Min w: 0.7841116786003113\n",
      "Iteration 690, Loss: 8.154789975378662e-05, Min w: 0.7893857955932617\n",
      "Iteration 700, Loss: 0.00010179787204833701, Min w: 0.7681522965431213\n",
      "Iteration 710, Loss: 8.391862502321601e-05, Min w: 0.7850098609924316\n",
      "Iteration 720, Loss: 8.121760765789077e-05, Min w: 0.7959138751029968\n",
      "Iteration 730, Loss: 8.572286606067792e-05, Min w: 0.7782844305038452\n",
      "Iteration 740, Loss: 8.443184924544767e-05, Min w: 0.7886026501655579\n",
      "Iteration 750, Loss: 7.983928662724793e-05, Min w: 0.7936517596244812\n",
      "Iteration 760, Loss: 8.282707131002098e-05, Min w: 0.7898959517478943\n",
      "Iteration 770, Loss: 8.183130557881668e-05, Min w: 0.7914459705352783\n",
      "Iteration 780, Loss: 8.590632205596194e-05, Min w: 0.7927502393722534\n",
      "Iteration 790, Loss: 7.98506589489989e-05, Min w: 0.7960047125816345\n",
      "Iteration 800, Loss: 8.024273120099679e-05, Min w: 0.797387957572937\n",
      "Iteration 810, Loss: 8.435749623458833e-05, Min w: 0.7965733408927917\n",
      "Iteration 820, Loss: 7.799688319209963e-05, Min w: 0.8048001527786255\n",
      "Iteration 830, Loss: 8.577824337407947e-05, Min w: 0.793921709060669\n",
      "Iteration 840, Loss: 8.146568143274635e-05, Min w: 0.799239993095398\n",
      "Iteration 850, Loss: 8.864152914611623e-05, Min w: 0.7928968667984009\n",
      "Iteration 860, Loss: 8.891894685802981e-05, Min w: 0.7911351323127747\n",
      "Iteration 870, Loss: 8.46625043777749e-05, Min w: 0.8043795228004456\n",
      "Iteration 880, Loss: 7.992680184543133e-05, Min w: 0.807037889957428\n",
      "Iteration 890, Loss: 8.525481825927272e-05, Min w: 0.8075817227363586\n",
      "Iteration 900, Loss: 7.959680806379765e-05, Min w: 0.8041474223136902\n",
      "Iteration 910, Loss: 7.720344729023054e-05, Min w: 0.8075333833694458\n",
      "Iteration 920, Loss: 7.585385901620612e-05, Min w: 0.813746452331543\n",
      "Iteration 930, Loss: 7.487233233405277e-05, Min w: 0.8113787770271301\n",
      "Iteration 940, Loss: 7.44879653211683e-05, Min w: 0.8149821162223816\n",
      "Iteration 950, Loss: 7.833958807168528e-05, Min w: 0.8129136562347412\n",
      "Iteration 960, Loss: 8.814342436380684e-05, Min w: 0.7966169714927673\n",
      "Iteration 970, Loss: 7.857154560042545e-05, Min w: 0.8119950890541077\n",
      "Iteration 980, Loss: 7.317017298191786e-05, Min w: 0.8166726231575012\n",
      "Iteration 990, Loss: 7.520885992562398e-05, Min w: 0.8181572556495667\n",
      "Iteration 1000, Loss: 7.991205347934738e-05, Min w: 0.8090155720710754\n",
      "Iteration 1010, Loss: 7.467969408025965e-05, Min w: 0.8159160017967224\n",
      "Iteration 1020, Loss: 7.866469240980223e-05, Min w: 0.8115902543067932\n",
      "Iteration 1030, Loss: 7.040480704745278e-05, Min w: 0.8271493315696716\n",
      "Iteration 1040, Loss: 7.520976214436814e-05, Min w: 0.822904646396637\n",
      "Iteration 1050, Loss: 7.552706665592268e-05, Min w: 0.8222547173500061\n",
      "Iteration 1060, Loss: 7.482977525796741e-05, Min w: 0.821984052658081\n",
      "Iteration 1070, Loss: 6.918158760527149e-05, Min w: 0.8248554468154907\n",
      "Iteration 1080, Loss: 7.540250226156786e-05, Min w: 0.8287339210510254\n",
      "Iteration 1090, Loss: 7.49870523577556e-05, Min w: 0.8246091604232788\n",
      "Iteration 1100, Loss: 7.162234396673739e-05, Min w: 0.8262302875518799\n",
      "Iteration 1110, Loss: 6.936387944733724e-05, Min w: 0.8315891623497009\n",
      "Iteration 1120, Loss: 7.559633377240971e-05, Min w: 0.8270043730735779\n",
      "Iteration 1130, Loss: 7.76144297560677e-05, Min w: 0.8250147700309753\n",
      "Iteration 1140, Loss: 6.975825090194121e-05, Min w: 0.8281821012496948\n",
      "Iteration 1150, Loss: 7.304702012334019e-05, Min w: 0.8318678140640259\n",
      "Iteration 1160, Loss: 6.872538506286219e-05, Min w: 0.8375051021575928\n",
      "Iteration 1170, Loss: 6.754025525879115e-05, Min w: 0.8365075588226318\n",
      "Iteration 1180, Loss: 6.994479917921126e-05, Min w: 0.8332525491714478\n",
      "Iteration 1190, Loss: 6.853930972283706e-05, Min w: 0.8345856070518494\n",
      "Iteration 1200, Loss: 6.79057848174125e-05, Min w: 0.8351137638092041\n",
      "Iteration 1210, Loss: 6.678255886072293e-05, Min w: 0.8414095640182495\n",
      "Iteration 1220, Loss: 6.961487815715373e-05, Min w: 0.8342958688735962\n",
      "Iteration 1230, Loss: 7.356573041761294e-05, Min w: 0.8370258212089539\n",
      "Iteration 1240, Loss: 6.706389831379056e-05, Min w: 0.8401337265968323\n",
      "Iteration 0, Loss: 6.651068542851135e-05, Min w: 0.8400614261627197\n",
      "Iteration 10, Loss: 6.532446423079818e-05, Min w: 0.8450839519500732\n",
      "Iteration 20, Loss: 6.431809742935002e-05, Min w: 0.8430856466293335\n",
      "Iteration 30, Loss: 6.638657214352861e-05, Min w: 0.8409029841423035\n",
      "Iteration 40, Loss: 6.241184746613726e-05, Min w: 0.8489609360694885\n",
      "Iteration 50, Loss: 6.420580757549033e-05, Min w: 0.8426592350006104\n",
      "Iteration 60, Loss: 6.837616820121184e-05, Min w: 0.8466781377792358\n",
      "Iteration 70, Loss: 6.317389488685876e-05, Min w: 0.8487995862960815\n",
      "Iteration 80, Loss: 6.36362747172825e-05, Min w: 0.8481205105781555\n",
      "Iteration 90, Loss: 7.361638563452289e-05, Min w: 0.8440386652946472\n",
      "Iteration 100, Loss: 6.313820631476119e-05, Min w: 0.8513402938842773\n",
      "Iteration 110, Loss: 6.371538620442152e-05, Min w: 0.8486286997795105\n",
      "Iteration 120, Loss: 6.226078403415158e-05, Min w: 0.8496469855308533\n",
      "Iteration 130, Loss: 7.184805872384459e-05, Min w: 0.8435070514678955\n",
      "Iteration 140, Loss: 7.651174382772297e-05, Min w: 0.8397122621536255\n",
      "Iteration 150, Loss: 6.577106250915676e-05, Min w: 0.8508694767951965\n",
      "Iteration 160, Loss: 6.053460674593225e-05, Min w: 0.8527831435203552\n",
      "Iteration 170, Loss: 6.410153582692146e-05, Min w: 0.8557276725769043\n",
      "Iteration 180, Loss: 6.216048495844007e-05, Min w: 0.8539754152297974\n",
      "Iteration 190, Loss: 6.110437971074134e-05, Min w: 0.8553075790405273\n",
      "Iteration 200, Loss: 5.926752419327386e-05, Min w: 0.860516369342804\n",
      "Iteration 210, Loss: 6.27929184702225e-05, Min w: 0.8583531379699707\n",
      "Iteration 220, Loss: 6.407582986867055e-05, Min w: 0.8596087098121643\n",
      "Iteration 230, Loss: 6.20054270257242e-05, Min w: 0.8574456572532654\n",
      "Iteration 240, Loss: 6.51282534818165e-05, Min w: 0.8591238856315613\n",
      "Iteration 250, Loss: 6.574792496394366e-05, Min w: 0.8594573736190796\n",
      "Iteration 260, Loss: 6.098814992583357e-05, Min w: 0.8621161580085754\n",
      "Iteration 270, Loss: 6.256254710024223e-05, Min w: 0.862381637096405\n",
      "Iteration 280, Loss: 6.0023183323210105e-05, Min w: 0.858963131904602\n",
      "Iteration 290, Loss: 6.0014051996404305e-05, Min w: 0.8607872128486633\n",
      "Iteration 300, Loss: 5.9588481235550717e-05, Min w: 0.8623213171958923\n",
      "Iteration 310, Loss: 5.575341856456362e-05, Min w: 0.8652454018592834\n",
      "Iteration 320, Loss: 6.367216701619327e-05, Min w: 0.8622220158576965\n",
      "Iteration 330, Loss: 5.7891422329703346e-05, Min w: 0.8656870126724243\n",
      "Iteration 340, Loss: 5.6195265642600134e-05, Min w: 0.8704872727394104\n",
      "Iteration 350, Loss: 5.641854659188539e-05, Min w: 0.8692468404769897\n",
      "Iteration 360, Loss: 6.53504830552265e-05, Min w: 0.8602273464202881\n",
      "Iteration 370, Loss: 5.431794488686137e-05, Min w: 0.8711124658584595\n",
      "Iteration 380, Loss: 6.113453855505213e-05, Min w: 0.8663779497146606\n",
      "Iteration 390, Loss: 5.928887185291387e-05, Min w: 0.8672105669975281\n",
      "Iteration 400, Loss: 5.962311843177304e-05, Min w: 0.8705906271934509\n",
      "Iteration 410, Loss: 5.721588240703568e-05, Min w: 0.8682618737220764\n",
      "Iteration 420, Loss: 5.559731653193012e-05, Min w: 0.8733104467391968\n",
      "Iteration 430, Loss: 5.357208283385262e-05, Min w: 0.8758577108383179\n",
      "Iteration 440, Loss: 5.4312084103003144e-05, Min w: 0.8745877742767334\n",
      "Iteration 450, Loss: 7.032658322714269e-05, Min w: 0.8524377942085266\n",
      "Iteration 460, Loss: 5.736790626542643e-05, Min w: 0.8747512698173523\n",
      "Iteration 470, Loss: 5.563311788137071e-05, Min w: 0.8737041354179382\n",
      "Iteration 480, Loss: 5.192235767026432e-05, Min w: 0.8785187005996704\n",
      "Iteration 490, Loss: 5.537655306397937e-05, Min w: 0.8757420182228088\n",
      "Iteration 500, Loss: 5.248020534054376e-05, Min w: 0.8779911398887634\n",
      "Iteration 510, Loss: 7.624834688613191e-05, Min w: 0.8273018598556519\n",
      "Iteration 520, Loss: 5.550641071749851e-05, Min w: 0.8773629665374756\n",
      "Iteration 530, Loss: 6.19643833488226e-05, Min w: 0.8738502264022827\n",
      "Iteration 540, Loss: 5.333752778824419e-05, Min w: 0.8812308311462402\n",
      "Iteration 550, Loss: 5.3390958782983944e-05, Min w: 0.8819332122802734\n",
      "Iteration 560, Loss: 5.45259281352628e-05, Min w: 0.8805867433547974\n",
      "Iteration 570, Loss: 4.896308382740244e-05, Min w: 0.8855912685394287\n",
      "Iteration 580, Loss: 4.9236026825383306e-05, Min w: 0.8863373398780823\n",
      "Iteration 590, Loss: 5.368229540181346e-05, Min w: 0.8815193772315979\n",
      "Iteration 600, Loss: 5.122256698086858e-05, Min w: 0.8859041333198547\n",
      "Iteration 610, Loss: 5.1006438297918066e-05, Min w: 0.88413006067276\n",
      "Iteration 620, Loss: 4.838565655518323e-05, Min w: 0.8879113793373108\n",
      "Iteration 630, Loss: 5.584721657214686e-05, Min w: 0.8797628879547119\n",
      "Iteration 640, Loss: 5.205641718930565e-05, Min w: 0.8878241181373596\n",
      "Iteration 650, Loss: 5.27993033756502e-05, Min w: 0.8856781125068665\n",
      "Iteration 660, Loss: 4.900297790300101e-05, Min w: 0.8835744857788086\n",
      "Iteration 670, Loss: 4.7599922254448757e-05, Min w: 0.8909378051757812\n",
      "Iteration 680, Loss: 4.851739140576683e-05, Min w: 0.8898583054542542\n",
      "Iteration 690, Loss: 5.232778858044185e-05, Min w: 0.8838810324668884\n",
      "Iteration 700, Loss: 4.9860351282404736e-05, Min w: 0.8885782957077026\n",
      "Iteration 710, Loss: 5.201248495723121e-05, Min w: 0.8870445489883423\n",
      "Iteration 720, Loss: 5.498211248777807e-05, Min w: 0.8878585696220398\n",
      "Iteration 730, Loss: 4.743396129924804e-05, Min w: 0.8900030255317688\n",
      "Iteration 740, Loss: 5.020291428081691e-05, Min w: 0.8933711051940918\n",
      "Iteration 750, Loss: 5.293742651701905e-05, Min w: 0.8918408155441284\n",
      "Iteration 760, Loss: 4.8004814743762836e-05, Min w: 0.8918128609657288\n",
      "Iteration 770, Loss: 5.66239541512914e-05, Min w: 0.8807243704795837\n",
      "Iteration 780, Loss: 5.287148815114051e-05, Min w: 0.8916799426078796\n",
      "Iteration 790, Loss: 4.594086931319907e-05, Min w: 0.8950401544570923\n",
      "Iteration 800, Loss: 4.8190711822826415e-05, Min w: 0.8970901966094971\n",
      "Iteration 810, Loss: 4.4828579120803624e-05, Min w: 0.8986613154411316\n",
      "Iteration 820, Loss: 4.6048731746850535e-05, Min w: 0.8964975476264954\n",
      "Iteration 830, Loss: 4.559119770419784e-05, Min w: 0.8990616798400879\n",
      "Iteration 840, Loss: 4.5193017285782844e-05, Min w: 0.8998590111732483\n",
      "Iteration 850, Loss: 4.310451549827121e-05, Min w: 0.9015395045280457\n",
      "Iteration 860, Loss: 4.305653055780567e-05, Min w: 0.9015936255455017\n",
      "Iteration 870, Loss: 4.52108470199164e-05, Min w: 0.8983563184738159\n",
      "Iteration 880, Loss: 4.820395406568423e-05, Min w: 0.8943871855735779\n",
      "Iteration 890, Loss: 4.275555329513736e-05, Min w: 0.9031702280044556\n",
      "Iteration 900, Loss: 6.284891424002126e-05, Min w: 0.8601466417312622\n",
      "Iteration 910, Loss: 4.354399425210431e-05, Min w: 0.9029668569564819\n",
      "Iteration 920, Loss: 4.2080173443537205e-05, Min w: 0.904694139957428\n",
      "Iteration 930, Loss: 4.573764817905612e-05, Min w: 0.9019110202789307\n",
      "Iteration 940, Loss: 4.288889613235369e-05, Min w: 0.9030337929725647\n",
      "Iteration 950, Loss: 4.119305231142789e-05, Min w: 0.9060436487197876\n",
      "Iteration 960, Loss: 4.336079291533679e-05, Min w: 0.9079813361167908\n",
      "Iteration 970, Loss: 4.1043153032660484e-05, Min w: 0.9060863256454468\n",
      "Iteration 980, Loss: 4.133349284529686e-05, Min w: 0.9065600633621216\n",
      "Iteration 990, Loss: 4.198127498966642e-05, Min w: 0.9088676571846008\n",
      "Iteration 1000, Loss: 5.080687333247624e-05, Min w: 0.8913422226905823\n",
      "Iteration 1010, Loss: 4.547884964267723e-05, Min w: 0.9066195487976074\n",
      "Iteration 1020, Loss: 4.002988862339407e-05, Min w: 0.9079204797744751\n",
      "Iteration 1030, Loss: 3.9234073483385146e-05, Min w: 0.9108726382255554\n",
      "Iteration 1040, Loss: 4.707332846010104e-05, Min w: 0.9008637070655823\n",
      "Iteration 1050, Loss: 4.4269188947509974e-05, Min w: 0.9060673117637634\n",
      "Iteration 1060, Loss: 4.967546192347072e-05, Min w: 0.8930644392967224\n",
      "Iteration 1070, Loss: 3.8944803236518055e-05, Min w: 0.9130726456642151\n",
      "Iteration 1080, Loss: 4.7499790525762364e-05, Min w: 0.8988730311393738\n",
      "Iteration 1090, Loss: 3.820581696345471e-05, Min w: 0.9137728810310364\n",
      "Iteration 1100, Loss: 4.421586709213443e-05, Min w: 0.9058594703674316\n",
      "Iteration 1110, Loss: 3.779925827984698e-05, Min w: 0.915067732334137\n",
      "Iteration 1120, Loss: 3.777863457798958e-05, Min w: 0.9167464375495911\n",
      "Iteration 1130, Loss: 4.322896711528301e-05, Min w: 0.9112756252288818\n",
      "Iteration 1140, Loss: 4.422173151397146e-05, Min w: 0.9088408946990967\n",
      "Iteration 1150, Loss: 4.41663469246123e-05, Min w: 0.9079701900482178\n",
      "Iteration 1160, Loss: 4.494211680139415e-05, Min w: 0.9082616567611694\n",
      "Iteration 1170, Loss: 3.8458965718746185e-05, Min w: 0.9150583744049072\n",
      "Iteration 1180, Loss: 3.766219015233219e-05, Min w: 0.9156644940376282\n",
      "Iteration 1190, Loss: 3.65474188583903e-05, Min w: 0.9191059470176697\n",
      "Iteration 1200, Loss: 4.2613381083356217e-05, Min w: 0.9114173054695129\n",
      "Iteration 1210, Loss: 3.7677353248000145e-05, Min w: 0.9172558784484863\n",
      "Iteration 1220, Loss: 5.199351653573103e-05, Min w: 0.8799716234207153\n",
      "Iteration 1230, Loss: 4.4801785406889394e-05, Min w: 0.9035876393318176\n",
      "Iteration 1240, Loss: 3.5980781831312925e-05, Min w: 0.9215887188911438\n",
      "Iteration 0, Loss: 3.6781970266019925e-05, Min w: 0.91754549741745\n",
      "Iteration 10, Loss: 3.631348954513669e-05, Min w: 0.9182593822479248\n",
      "Iteration 20, Loss: 4.9228485295316204e-05, Min w: 0.8906041979789734\n",
      "Iteration 30, Loss: 3.686784111778252e-05, Min w: 0.9188992381095886\n",
      "Iteration 40, Loss: 3.77429423679132e-05, Min w: 0.9197498559951782\n",
      "Iteration 50, Loss: 4.744235047837719e-05, Min w: 0.8934306502342224\n",
      "Iteration 60, Loss: 3.9512324292445555e-05, Min w: 0.9176908135414124\n",
      "Iteration 70, Loss: 3.779124017455615e-05, Min w: 0.9203811883926392\n",
      "Iteration 80, Loss: 4.012748831883073e-05, Min w: 0.9180701971054077\n",
      "Iteration 90, Loss: 4.0809882193570957e-05, Min w: 0.914734959602356\n",
      "Iteration 100, Loss: 4.5312190195545554e-05, Min w: 0.8966274857521057\n",
      "Iteration 110, Loss: 4.293574602343142e-05, Min w: 0.9035055041313171\n",
      "Iteration 120, Loss: 3.328986349515617e-05, Min w: 0.9285895228385925\n",
      "Iteration 130, Loss: 4.043946319143288e-05, Min w: 0.9154006838798523\n",
      "Iteration 140, Loss: 3.373938307049684e-05, Min w: 0.9261733293533325\n",
      "Iteration 150, Loss: 3.387012839084491e-05, Min w: 0.9245480895042419\n",
      "Iteration 160, Loss: 3.564136568456888e-05, Min w: 0.9248235821723938\n",
      "Iteration 170, Loss: 3.831857975455932e-05, Min w: 0.9211701154708862\n",
      "Iteration 180, Loss: 3.728686351678334e-05, Min w: 0.9234322905540466\n",
      "Iteration 190, Loss: 3.700604793266393e-05, Min w: 0.9237141013145447\n",
      "Iteration 200, Loss: 5.03609080624301e-05, Min w: 0.8789607286453247\n",
      "Iteration 210, Loss: 3.9071030187187716e-05, Min w: 0.9145755767822266\n",
      "Iteration 220, Loss: 3.705920244101435e-05, Min w: 0.9231793284416199\n",
      "Iteration 230, Loss: 3.1589781428920105e-05, Min w: 0.9288148880004883\n",
      "Iteration 240, Loss: 4.950760558131151e-05, Min w: 0.8789289593696594\n",
      "Iteration 250, Loss: 3.953168197767809e-05, Min w: 0.9156465530395508\n",
      "Iteration 260, Loss: 3.541254045558162e-05, Min w: 0.926708996295929\n",
      "Iteration 270, Loss: 3.327470039948821e-05, Min w: 0.9278159141540527\n",
      "Iteration 280, Loss: 3.231082882848568e-05, Min w: 0.9307327270507812\n",
      "Iteration 290, Loss: 4.870013435720466e-05, Min w: 0.8902623653411865\n",
      "Iteration 300, Loss: 3.95093702536542e-05, Min w: 0.9121837019920349\n",
      "Iteration 310, Loss: 4.379856909508817e-05, Min w: 0.8986859917640686\n",
      "Iteration 320, Loss: 3.157999526592903e-05, Min w: 0.931368887424469\n",
      "Iteration 330, Loss: 3.190919233020395e-05, Min w: 0.9305585026741028\n",
      "Iteration 340, Loss: 3.105435098404996e-05, Min w: 0.9321480989456177\n",
      "Iteration 350, Loss: 3.611144711612724e-05, Min w: 0.9222532510757446\n",
      "Iteration 360, Loss: 3.951094549847767e-05, Min w: 0.9096893072128296\n",
      "Iteration 370, Loss: 3.1203366233967245e-05, Min w: 0.9318655133247375\n",
      "Iteration 380, Loss: 3.7047324440209195e-05, Min w: 0.9164707660675049\n",
      "Iteration 390, Loss: 3.882323289872147e-05, Min w: 0.9135959148406982\n",
      "Iteration 400, Loss: 5.0792961701517925e-05, Min w: 0.8757390379905701\n",
      "Iteration 410, Loss: 3.29508438881021e-05, Min w: 0.9312663674354553\n",
      "Iteration 420, Loss: 3.0456982130999677e-05, Min w: 0.9327044486999512\n",
      "Iteration 430, Loss: 3.2738520530983806e-05, Min w: 0.9326195120811462\n",
      "Iteration 440, Loss: 3.466342604951933e-05, Min w: 0.9278548955917358\n",
      "Iteration 450, Loss: 3.104151983279735e-05, Min w: 0.9335878491401672\n",
      "Iteration 460, Loss: 3.263896724092774e-05, Min w: 0.9307740330696106\n",
      "Iteration 470, Loss: 2.9873035600758158e-05, Min w: 0.9358479380607605\n",
      "Iteration 480, Loss: 2.8573387680808082e-05, Min w: 0.9396489262580872\n",
      "Iteration 490, Loss: 3.731332253664732e-05, Min w: 0.9189644455909729\n",
      "Iteration 500, Loss: 3.553799251676537e-05, Min w: 0.9221574068069458\n",
      "Iteration 510, Loss: 3.505988570395857e-05, Min w: 0.9236946105957031\n",
      "Iteration 520, Loss: 3.048227335966658e-05, Min w: 0.9372976422309875\n",
      "Iteration 530, Loss: 3.4957956813741475e-05, Min w: 0.9242414832115173\n",
      "Iteration 540, Loss: 3.489195660222322e-05, Min w: 0.9239669442176819\n",
      "Iteration 550, Loss: 3.0652667192043737e-05, Min w: 0.9357491135597229\n",
      "Iteration 560, Loss: 3.0837614758638665e-05, Min w: 0.9356906414031982\n",
      "Iteration 570, Loss: 3.133370046271011e-05, Min w: 0.9330001473426819\n",
      "Iteration 580, Loss: 2.876734288292937e-05, Min w: 0.9368753433227539\n",
      "Iteration 590, Loss: 2.9555387300206348e-05, Min w: 0.9394807815551758\n",
      "Iteration 600, Loss: 3.3394055208191276e-05, Min w: 0.9258164167404175\n",
      "Iteration 610, Loss: 3.803066647378728e-05, Min w: 0.916568398475647\n",
      "Iteration 620, Loss: 4.1967254219343886e-05, Min w: 0.8981842398643494\n",
      "Iteration 630, Loss: 3.145354276057333e-05, Min w: 0.9344289302825928\n",
      "Iteration 640, Loss: 2.8806442060158588e-05, Min w: 0.9383524060249329\n",
      "Iteration 650, Loss: 3.0335069823195226e-05, Min w: 0.9341965317726135\n",
      "Iteration 660, Loss: 2.994846181536559e-05, Min w: 0.9372509121894836\n",
      "Iteration 670, Loss: 2.732771827140823e-05, Min w: 0.9416477084159851\n",
      "Iteration 680, Loss: 2.8096774258301593e-05, Min w: 0.9406319260597229\n",
      "Iteration 690, Loss: 2.8016933356411755e-05, Min w: 0.9421967267990112\n",
      "Iteration 700, Loss: 2.7500607757247053e-05, Min w: 0.9401174783706665\n",
      "Iteration 710, Loss: 3.5787703382084146e-05, Min w: 0.9172806143760681\n",
      "Iteration 720, Loss: 2.6398090994916856e-05, Min w: 0.9436309337615967\n",
      "Iteration 730, Loss: 4.067824920639396e-05, Min w: 0.9038070440292358\n",
      "Iteration 740, Loss: 4.116956552024931e-05, Min w: 0.8995689749717712\n",
      "Iteration 750, Loss: 3.20015569741372e-05, Min w: 0.9306126236915588\n",
      "Iteration 760, Loss: 2.6602681828080676e-05, Min w: 0.9454837441444397\n",
      "Iteration 770, Loss: 2.5477216695435345e-05, Min w: 0.9466333985328674\n",
      "Iteration 780, Loss: 3.4864839108195156e-05, Min w: 0.9158556461334229\n",
      "Iteration 790, Loss: 2.977601070597302e-05, Min w: 0.9386135935783386\n",
      "Iteration 800, Loss: 2.5479970645392314e-05, Min w: 0.9457286596298218\n",
      "Iteration 810, Loss: 2.7026750103686936e-05, Min w: 0.9447569847106934\n",
      "Iteration 820, Loss: 3.014284993696492e-05, Min w: 0.9329044222831726\n",
      "Iteration 830, Loss: 2.6315190552850254e-05, Min w: 0.9458404779434204\n",
      "Iteration 840, Loss: 2.5365990950376727e-05, Min w: 0.9456061720848083\n",
      "Iteration 850, Loss: 2.869384115911089e-05, Min w: 0.9394829273223877\n",
      "Iteration 860, Loss: 2.613204014778603e-05, Min w: 0.9462785720825195\n",
      "Iteration 870, Loss: 2.5190012820530683e-05, Min w: 0.9479117393493652\n",
      "Iteration 880, Loss: 2.6349787731305696e-05, Min w: 0.9451314806938171\n",
      "Iteration 890, Loss: 2.5804720280575566e-05, Min w: 0.9448703527450562\n",
      "Iteration 900, Loss: 2.8205487978993915e-05, Min w: 0.9389017224311829\n",
      "Iteration 910, Loss: 2.737996692303568e-05, Min w: 0.94277024269104\n",
      "Iteration 920, Loss: 2.6530919058131985e-05, Min w: 0.943754255771637\n",
      "Iteration 930, Loss: 2.5972276489483193e-05, Min w: 0.9452531337738037\n",
      "Iteration 940, Loss: 3.3560037991264835e-05, Min w: 0.9236421585083008\n",
      "Iteration 950, Loss: 3.2231044315267354e-05, Min w: 0.9285712242126465\n",
      "Iteration 960, Loss: 4.251617065165192e-05, Min w: 0.888854444026947\n",
      "Iteration 970, Loss: 2.8560481950989924e-05, Min w: 0.9353722929954529\n",
      "Iteration 980, Loss: 3.03654251183616e-05, Min w: 0.9308810234069824\n",
      "Iteration 990, Loss: 2.456618494761642e-05, Min w: 0.9495589137077332\n",
      "Iteration 1000, Loss: 2.5034783902810887e-05, Min w: 0.9460077881813049\n",
      "Iteration 1010, Loss: 2.523254261177499e-05, Min w: 0.9444764256477356\n",
      "Iteration 1020, Loss: 2.508057514205575e-05, Min w: 0.9479014277458191\n",
      "Iteration 1030, Loss: 3.572764035197906e-05, Min w: 0.9124730229377747\n",
      "Iteration 1040, Loss: 2.984577622555662e-05, Min w: 0.9318854212760925\n",
      "Iteration 1050, Loss: 2.908306305471342e-05, Min w: 0.933201253414154\n",
      "Iteration 1060, Loss: 2.603018219815567e-05, Min w: 0.9453153014183044\n",
      "Iteration 1070, Loss: 2.6818244805326685e-05, Min w: 0.9385652542114258\n",
      "Iteration 1080, Loss: 2.3704296836513095e-05, Min w: 0.951261043548584\n",
      "Iteration 1090, Loss: 2.7211077394895256e-05, Min w: 0.9386100769042969\n",
      "Iteration 1100, Loss: 2.3003913156571798e-05, Min w: 0.952958881855011\n",
      "Iteration 1110, Loss: 2.2458285457105376e-05, Min w: 0.9527262449264526\n",
      "Iteration 1120, Loss: 2.734421650529839e-05, Min w: 0.9390472769737244\n",
      "Iteration 1130, Loss: 2.3727781808702275e-05, Min w: 0.9510242938995361\n",
      "Iteration 1140, Loss: 2.2776072000851855e-05, Min w: 0.9519608020782471\n",
      "Iteration 1150, Loss: 2.660522295627743e-05, Min w: 0.9390628337860107\n",
      "Iteration 1160, Loss: 2.5096558601944707e-05, Min w: 0.9448322653770447\n",
      "Iteration 1170, Loss: 2.325644345546607e-05, Min w: 0.9508252143859863\n",
      "Iteration 1180, Loss: 2.2369169528246857e-05, Min w: 0.9532514810562134\n",
      "Iteration 1190, Loss: 3.220314465579577e-05, Min w: 0.9203630089759827\n",
      "Iteration 1200, Loss: 4.2504143493715674e-05, Min w: 0.8851249814033508\n",
      "Iteration 1210, Loss: 3.245116022299044e-05, Min w: 0.919447124004364\n",
      "Iteration 1220, Loss: 2.966612191812601e-05, Min w: 0.9308119416236877\n",
      "Iteration 1230, Loss: 3.018644747498911e-05, Min w: 0.9303658604621887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  29%|██▉       | 7/24 [10:45<25:57, 91.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 2.3542474082205445e-05, Min w: 0.9515001177787781\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.019207934161810658, 'L2_avg': 0.030965441117039638, 'End_point_L1_avg': 0.004780425740760949, 'End_point_L2_avg': 0.005127372188783872}\n",
      "Iteration 0, Loss: 0.0014006271958351135, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0012655430473387241, Min w: 0.0\n",
      "Iteration 20, Loss: 0.001072375220246613, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0010086821857839823, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009557685698382556, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0009118015877902508, Min w: 0.0\n",
      "Iteration 60, Loss: 0.00087259232532233, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008331805584020913, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007887171232141554, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007628101157024503, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0007284985040314496, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007015166920609772, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006736772484146059, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006517602014355361, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006257790955714881, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006039153668098152, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005853986949659884, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005630856030620635, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005485418369062245, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005293301655910909, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005144355818629265, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005061867996118963, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005001453682780266, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00048236578004434705, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004655690281651914, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004592265759129077, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0004513279418461025, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00044072914170101285, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00043434445979073644, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00043002323945984244, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004274643142707646, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0004293872625567019, Min w: 0.0\n",
      "Iteration 320, Loss: 0.000422997196437791, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0004018557956442237, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00040974043076857924, Min w: 0.0\n",
      "Iteration 350, Loss: 0.00043589831329882145, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004290376673452556, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0004261267895344645, Min w: 0.0\n",
      "Iteration 380, Loss: 0.00043864353210665286, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0004208083846606314, Min w: 0.0\n",
      "Iteration 400, Loss: 0.00039781120722182095, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004230131162330508, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004077054909430444, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0003883743775077164, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0003931362589355558, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00038797614979557693, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0003734423953574151, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00036567417555488646, Min w: 0.0\n",
      "Iteration 480, Loss: 0.00036713978624902666, Min w: 0.0\n",
      "Iteration 490, Loss: 0.00035955102066509426, Min w: 0.0\n",
      "Iteration 500, Loss: 0.00035064606345258653, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00034938304452225566, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00034538735053502023, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0003482446481939405, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0003449048090260476, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0003619462077040225, Min w: 0.0\n",
      "Iteration 560, Loss: 0.00034642586251720786, Min w: 0.0\n",
      "Iteration 570, Loss: 0.00034591357689350843, Min w: 0.0\n",
      "Iteration 580, Loss: 0.00033765751868486404, Min w: 0.0\n",
      "Iteration 590, Loss: 0.00033639848697930574, Min w: 0.0\n",
      "Iteration 600, Loss: 0.00033636376610957086, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0003387531323824078, Min w: 0.0\n",
      "Iteration 620, Loss: 0.00034868117654696107, Min w: 0.0\n",
      "Iteration 630, Loss: 0.00034119351767003536, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0003456210542935878, Min w: 0.0\n",
      "Iteration 650, Loss: 0.00034689990570768714, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0003463163156993687, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00034825532929971814, Min w: 0.0\n",
      "Iteration 680, Loss: 0.00034718416281975806, Min w: 1.7331397294538227e-37\n",
      "Iteration 690, Loss: 0.00035220844438299537, Min w: 2.29547902953393e-20\n",
      "Iteration 700, Loss: 0.000351112597854808, Min w: 1.3138456544936616e-08\n",
      "Iteration 710, Loss: 0.0003496701829135418, Min w: 0.0062391492538154125\n",
      "Iteration 720, Loss: 0.00035347003722563386, Min w: 2.681545629457105e-05\n",
      "Iteration 730, Loss: 0.00035400313208810985, Min w: 1.3150390998362127e-08\n",
      "Iteration 740, Loss: 0.00035355627187527716, Min w: 1.1439491487408304e-07\n",
      "Iteration 750, Loss: 0.00035657058469951153, Min w: 4.479579729377292e-05\n",
      "Iteration 760, Loss: 0.0003488947404548526, Min w: 0.018998492509126663\n",
      "Iteration 770, Loss: 0.00034321832936257124, Min w: 0.06740840524435043\n",
      "Iteration 780, Loss: 0.0003443493624217808, Min w: 0.07744129002094269\n",
      "Iteration 790, Loss: 0.0003451521333772689, Min w: 0.08292670547962189\n",
      "Iteration 800, Loss: 0.00033006479497998953, Min w: 0.09047664701938629\n",
      "Iteration 810, Loss: 0.0003229114809073508, Min w: 0.10551284998655319\n",
      "Iteration 820, Loss: 0.0003262386890128255, Min w: 0.11510533094406128\n",
      "Iteration 830, Loss: 0.0003219505597371608, Min w: 0.12997044622898102\n",
      "Iteration 840, Loss: 0.00031499561737291515, Min w: 0.1456279456615448\n",
      "Iteration 850, Loss: 0.00031062684138305485, Min w: 0.15344581007957458\n",
      "Iteration 860, Loss: 0.0003189760900568217, Min w: 0.16011931002140045\n",
      "Iteration 870, Loss: 0.0003052259562537074, Min w: 0.1736164540052414\n",
      "Iteration 880, Loss: 0.0002988816413562745, Min w: 0.18585264682769775\n",
      "Iteration 890, Loss: 0.00029810937121510506, Min w: 0.19056501984596252\n",
      "Iteration 900, Loss: 0.0002950076595880091, Min w: 0.19443374872207642\n",
      "Iteration 910, Loss: 0.0002912581549026072, Min w: 0.2106095850467682\n",
      "Iteration 920, Loss: 0.00029006123077124357, Min w: 0.21317943930625916\n",
      "Iteration 930, Loss: 0.0002850988239515573, Min w: 0.21539540588855743\n",
      "Iteration 940, Loss: 0.00028307855245657265, Min w: 0.2307923138141632\n",
      "Iteration 950, Loss: 0.0002836344938259572, Min w: 0.23323506116867065\n",
      "Iteration 960, Loss: 0.00028451529215089977, Min w: 0.24418145418167114\n",
      "Iteration 970, Loss: 0.0002797821653075516, Min w: 0.24754460155963898\n",
      "Iteration 980, Loss: 0.0002778953639790416, Min w: 0.2420147955417633\n",
      "Iteration 990, Loss: 0.0002675413270480931, Min w: 0.25529932975769043\n",
      "Iteration 1000, Loss: 0.0002648841473273933, Min w: 0.2604357600212097\n",
      "Iteration 1010, Loss: 0.0002605401969049126, Min w: 0.2707661986351013\n",
      "Iteration 1020, Loss: 0.0002651777758728713, Min w: 0.27496370673179626\n",
      "Iteration 1030, Loss: 0.0002597058191895485, Min w: 0.2723272144794464\n",
      "Iteration 1040, Loss: 0.0002627653011586517, Min w: 0.2878318428993225\n",
      "Iteration 1050, Loss: 0.00025666714645922184, Min w: 0.2854163646697998\n",
      "Iteration 1060, Loss: 0.00025509551051072776, Min w: 0.29228082299232483\n",
      "Iteration 1070, Loss: 0.0002579127612989396, Min w: 0.29448655247688293\n",
      "Iteration 1080, Loss: 0.0002504676813259721, Min w: 0.3010920584201813\n",
      "Iteration 1090, Loss: 0.0002686571388039738, Min w: 0.28620588779449463\n",
      "Iteration 1100, Loss: 0.00025016095605678856, Min w: 0.31323277950286865\n",
      "Iteration 1110, Loss: 0.00024363274860661477, Min w: 0.3208152651786804\n",
      "Iteration 1120, Loss: 0.00024896743707358837, Min w: 0.3176690936088562\n",
      "Iteration 1130, Loss: 0.00024168599338736385, Min w: 0.3290088176727295\n",
      "Iteration 1140, Loss: 0.00023798576148692518, Min w: 0.32267048954963684\n",
      "Iteration 1150, Loss: 0.00023914242046885192, Min w: 0.3361167907714844\n",
      "Iteration 1160, Loss: 0.00023548069293610752, Min w: 0.3408188819885254\n",
      "Iteration 1170, Loss: 0.00023250601952895522, Min w: 0.34754642844200134\n",
      "Iteration 1180, Loss: 0.00023350502306129783, Min w: 0.3427271246910095\n",
      "Iteration 1190, Loss: 0.00024853364448063076, Min w: 0.3489529490470886\n",
      "Iteration 1200, Loss: 0.0002248251112177968, Min w: 0.35925233364105225\n",
      "Iteration 1210, Loss: 0.00022605697449762374, Min w: 0.35681381821632385\n",
      "Iteration 1220, Loss: 0.0002239388704765588, Min w: 0.3633331060409546\n",
      "Iteration 1230, Loss: 0.00022700463887304068, Min w: 0.35830435156822205\n",
      "Iteration 1240, Loss: 0.00022636502399109304, Min w: 0.3642800450325012\n",
      "Iteration 0, Loss: 0.0002197873400291428, Min w: 0.37515515089035034\n",
      "Iteration 10, Loss: 0.00022607202117796987, Min w: 0.3727561831474304\n",
      "Iteration 20, Loss: 0.0002130947686964646, Min w: 0.38891538977622986\n",
      "Iteration 30, Loss: 0.00024282335652969778, Min w: 0.37072813510894775\n",
      "Iteration 40, Loss: 0.0002289740223204717, Min w: 0.38013675808906555\n",
      "Iteration 50, Loss: 0.00021223608928266913, Min w: 0.3895728290081024\n",
      "Iteration 60, Loss: 0.00020922267867717892, Min w: 0.3985469937324524\n",
      "Iteration 70, Loss: 0.00021192400890868157, Min w: 0.3962627053260803\n",
      "Iteration 80, Loss: 0.00020449701696634293, Min w: 0.41252803802490234\n",
      "Iteration 90, Loss: 0.00020921416580677032, Min w: 0.4020078778266907\n",
      "Iteration 100, Loss: 0.00020661701273638755, Min w: 0.41100549697875977\n",
      "Iteration 110, Loss: 0.00020400604989845306, Min w: 0.4132727086544037\n",
      "Iteration 120, Loss: 0.00020090928592253476, Min w: 0.42575472593307495\n",
      "Iteration 130, Loss: 0.0002012519835261628, Min w: 0.42336568236351013\n",
      "Iteration 140, Loss: 0.00019945407984778285, Min w: 0.4251020550727844\n",
      "Iteration 150, Loss: 0.00020268499793019146, Min w: 0.42165184020996094\n",
      "Iteration 160, Loss: 0.00019748415797948837, Min w: 0.43219688534736633\n",
      "Iteration 170, Loss: 0.0001949268626049161, Min w: 0.44782301783561707\n",
      "Iteration 180, Loss: 0.00019418160081841052, Min w: 0.4430312216281891\n",
      "Iteration 190, Loss: 0.00020127533935010433, Min w: 0.42334988713264465\n",
      "Iteration 200, Loss: 0.00019418378360569477, Min w: 0.4484817683696747\n",
      "Iteration 210, Loss: 0.0001919677306432277, Min w: 0.455965131521225\n",
      "Iteration 220, Loss: 0.00019551109289750457, Min w: 0.4474032521247864\n",
      "Iteration 230, Loss: 0.0001889151899376884, Min w: 0.45651859045028687\n",
      "Iteration 240, Loss: 0.00019229728786740452, Min w: 0.4610944986343384\n",
      "Iteration 250, Loss: 0.0001840809709392488, Min w: 0.4595668315887451\n",
      "Iteration 260, Loss: 0.0001865265949163586, Min w: 0.46822860836982727\n",
      "Iteration 270, Loss: 0.0001888939004857093, Min w: 0.45760437846183777\n",
      "Iteration 280, Loss: 0.00018852399080060422, Min w: 0.4765649735927582\n",
      "Iteration 290, Loss: 0.00020181320724077523, Min w: 0.45850399136543274\n",
      "Iteration 300, Loss: 0.00019284510926809162, Min w: 0.45806387066841125\n",
      "Iteration 310, Loss: 0.00018329545855522156, Min w: 0.4779258966445923\n",
      "Iteration 320, Loss: 0.0001821920450311154, Min w: 0.47516900300979614\n",
      "Iteration 330, Loss: 0.00018397369422018528, Min w: 0.4753403961658478\n",
      "Iteration 340, Loss: 0.00017607229528948665, Min w: 0.49339359998703003\n",
      "Iteration 350, Loss: 0.00017636039410717785, Min w: 0.4908048212528229\n",
      "Iteration 360, Loss: 0.00017770659178495407, Min w: 0.48739224672317505\n",
      "Iteration 370, Loss: 0.00017726555233821273, Min w: 0.4876159131526947\n",
      "Iteration 380, Loss: 0.00017307653615716845, Min w: 0.4954964518547058\n",
      "Iteration 390, Loss: 0.00017176895926240832, Min w: 0.5018514394760132\n",
      "Iteration 400, Loss: 0.00016980961663648486, Min w: 0.5073208212852478\n",
      "Iteration 410, Loss: 0.0001694193488219753, Min w: 0.5079509019851685\n",
      "Iteration 420, Loss: 0.00017148868937510997, Min w: 0.5038530826568604\n",
      "Iteration 430, Loss: 0.00016868079546839, Min w: 0.5131375193595886\n",
      "Iteration 440, Loss: 0.00017077730444725603, Min w: 0.5075835585594177\n",
      "Iteration 450, Loss: 0.00017101374396588653, Min w: 0.5144147276878357\n",
      "Iteration 460, Loss: 0.00018976724823005497, Min w: 0.4975125789642334\n",
      "Iteration 470, Loss: 0.0001687250769464299, Min w: 0.5199406743049622\n",
      "Iteration 480, Loss: 0.00016312548541463912, Min w: 0.5270158648490906\n",
      "Iteration 490, Loss: 0.0001613752538105473, Min w: 0.5318606495857239\n",
      "Iteration 500, Loss: 0.00018436410755384713, Min w: 0.5219925045967102\n",
      "Iteration 510, Loss: 0.00016939881606958807, Min w: 0.5321069359779358\n",
      "Iteration 520, Loss: 0.00016063658404164016, Min w: 0.5360483527183533\n",
      "Iteration 530, Loss: 0.000164349825354293, Min w: 0.5324440598487854\n",
      "Iteration 540, Loss: 0.00015882345905993134, Min w: 0.5447298884391785\n",
      "Iteration 550, Loss: 0.00016147860151249915, Min w: 0.5347817540168762\n",
      "Iteration 560, Loss: 0.00015983164485078305, Min w: 0.5423257946968079\n",
      "Iteration 570, Loss: 0.00015787033771630377, Min w: 0.5458289384841919\n",
      "Iteration 580, Loss: 0.00015505433839280158, Min w: 0.5531140565872192\n",
      "Iteration 590, Loss: 0.0001568988081999123, Min w: 0.5558566451072693\n",
      "Iteration 600, Loss: 0.00015386522863991559, Min w: 0.5578996539115906\n",
      "Iteration 610, Loss: 0.0001550229062559083, Min w: 0.552668035030365\n",
      "Iteration 620, Loss: 0.00015181816706899554, Min w: 0.5596544146537781\n",
      "Iteration 630, Loss: 0.00015505497867707163, Min w: 0.5589933395385742\n",
      "Iteration 640, Loss: 0.0001521472877357155, Min w: 0.5483427047729492\n",
      "Iteration 650, Loss: 0.00014906926662661135, Min w: 0.5645892024040222\n",
      "Iteration 660, Loss: 0.00014681238099001348, Min w: 0.566875159740448\n",
      "Iteration 670, Loss: 0.00015255104517564178, Min w: 0.5677171349525452\n",
      "Iteration 680, Loss: 0.0001511544396635145, Min w: 0.5646036267280579\n",
      "Iteration 690, Loss: 0.00014551715867128223, Min w: 0.5816843509674072\n",
      "Iteration 700, Loss: 0.00014601272414438426, Min w: 0.5750311613082886\n",
      "Iteration 710, Loss: 0.00014704119530506432, Min w: 0.5770444869995117\n",
      "Iteration 720, Loss: 0.00015175031148828566, Min w: 0.5745794177055359\n",
      "Iteration 730, Loss: 0.00014490613830275834, Min w: 0.5788896083831787\n",
      "Iteration 740, Loss: 0.00014443695545196533, Min w: 0.5853556394577026\n",
      "Iteration 750, Loss: 0.00014353841834235936, Min w: 0.5827311873435974\n",
      "Iteration 760, Loss: 0.00014564582670573145, Min w: 0.5849106907844543\n",
      "Iteration 770, Loss: 0.00015399839321617037, Min w: 0.565505862236023\n",
      "Iteration 780, Loss: 0.00013968687562737614, Min w: 0.592279851436615\n",
      "Iteration 790, Loss: 0.00014213747635949403, Min w: 0.5913323760032654\n",
      "Iteration 800, Loss: 0.00014130909403320402, Min w: 0.5960935950279236\n",
      "Iteration 810, Loss: 0.00014469459711108357, Min w: 0.5957258343696594\n",
      "Iteration 820, Loss: 0.0001424879301339388, Min w: 0.5964334607124329\n",
      "Iteration 830, Loss: 0.0001423605572199449, Min w: 0.5956370234489441\n",
      "Iteration 840, Loss: 0.00013788286014460027, Min w: 0.5983242988586426\n",
      "Iteration 850, Loss: 0.00013381658936850727, Min w: 0.6122828125953674\n",
      "Iteration 860, Loss: 0.00015038596757221967, Min w: 0.5931150913238525\n",
      "Iteration 870, Loss: 0.00013690615014638752, Min w: 0.6010828614234924\n",
      "Iteration 880, Loss: 0.0001348110963590443, Min w: 0.6109253764152527\n",
      "Iteration 890, Loss: 0.00013320910511538386, Min w: 0.6119207143783569\n",
      "Iteration 900, Loss: 0.00013201675028540194, Min w: 0.6111586689949036\n",
      "Iteration 910, Loss: 0.00013239687541499734, Min w: 0.6138008236885071\n",
      "Iteration 920, Loss: 0.00013832694094162434, Min w: 0.6103216409683228\n",
      "Iteration 930, Loss: 0.00013697563554160297, Min w: 0.6212202310562134\n",
      "Iteration 940, Loss: 0.00013357105490285903, Min w: 0.6158646941184998\n",
      "Iteration 950, Loss: 0.00015103555051609874, Min w: 0.6125757694244385\n",
      "Iteration 960, Loss: 0.00013087202387396246, Min w: 0.6292018294334412\n",
      "Iteration 970, Loss: 0.00013176817446947098, Min w: 0.6198818683624268\n",
      "Iteration 980, Loss: 0.00013498794578481466, Min w: 0.6239993572235107\n",
      "Iteration 990, Loss: 0.00013596958888228983, Min w: 0.6288991570472717\n",
      "Iteration 1000, Loss: 0.00012705758854281157, Min w: 0.6280760169029236\n",
      "Iteration 1010, Loss: 0.00012385309673845768, Min w: 0.6434417963027954\n",
      "Iteration 1020, Loss: 0.00012763254926539958, Min w: 0.632311224937439\n",
      "Iteration 1030, Loss: 0.00013422381016425788, Min w: 0.6295408010482788\n",
      "Iteration 1040, Loss: 0.0001249646011274308, Min w: 0.6365901827812195\n",
      "Iteration 1050, Loss: 0.00012559909373521805, Min w: 0.6374480724334717\n",
      "Iteration 1060, Loss: 0.0001272990630241111, Min w: 0.635515570640564\n",
      "Iteration 1070, Loss: 0.0001244952145498246, Min w: 0.6462284326553345\n",
      "Iteration 1080, Loss: 0.00012402144784573466, Min w: 0.6441978216171265\n",
      "Iteration 1090, Loss: 0.00012827766477130353, Min w: 0.6416287422180176\n",
      "Iteration 1100, Loss: 0.00012264025281183422, Min w: 0.6490404009819031\n",
      "Iteration 1110, Loss: 0.00012390987831167877, Min w: 0.6445920467376709\n",
      "Iteration 1120, Loss: 0.00012612725549843162, Min w: 0.651455819606781\n",
      "Iteration 1130, Loss: 0.0001233621733263135, Min w: 0.646223783493042\n",
      "Iteration 1140, Loss: 0.00011866848217323422, Min w: 0.6512340307235718\n",
      "Iteration 1150, Loss: 0.0001252275105798617, Min w: 0.6501624584197998\n",
      "Iteration 1160, Loss: 0.0001208745816256851, Min w: 0.6599391102790833\n",
      "Iteration 1170, Loss: 0.00011731491395039484, Min w: 0.6602261662483215\n",
      "Iteration 1180, Loss: 0.00011897366493940353, Min w: 0.66130131483078\n",
      "Iteration 1190, Loss: 0.00011452718899818137, Min w: 0.6633589267730713\n",
      "Iteration 1200, Loss: 0.00012655992759391665, Min w: 0.659130871295929\n",
      "Iteration 1210, Loss: 0.00011558921687537804, Min w: 0.6669562458992004\n",
      "Iteration 1220, Loss: 0.00012596556916832924, Min w: 0.6642749905586243\n",
      "Iteration 1230, Loss: 0.00011555782111827284, Min w: 0.6730170249938965\n",
      "Iteration 1240, Loss: 0.00011670157255139202, Min w: 0.6679694056510925\n",
      "Iteration 0, Loss: 0.00011672826076392084, Min w: 0.6706846356391907\n",
      "Iteration 10, Loss: 0.00011711895058397204, Min w: 0.669585645198822\n",
      "Iteration 20, Loss: 0.00011786034883698449, Min w: 0.6709471344947815\n",
      "Iteration 30, Loss: 0.00011429576989030465, Min w: 0.6799532771110535\n",
      "Iteration 40, Loss: 0.00011277868907200173, Min w: 0.6788604855537415\n",
      "Iteration 50, Loss: 0.00011183511378476396, Min w: 0.6778004169464111\n",
      "Iteration 60, Loss: 0.00011361090582795441, Min w: 0.6779300570487976\n",
      "Iteration 70, Loss: 0.00011120578710688278, Min w: 0.6865599751472473\n",
      "Iteration 80, Loss: 0.00010764100443338975, Min w: 0.6889910697937012\n",
      "Iteration 90, Loss: 0.0001147993971244432, Min w: 0.6852648258209229\n",
      "Iteration 100, Loss: 0.00012572201376315206, Min w: 0.6718581914901733\n",
      "Iteration 110, Loss: 0.00011727427772711962, Min w: 0.6869304180145264\n",
      "Iteration 120, Loss: 0.00011000501399394125, Min w: 0.6819106936454773\n",
      "Iteration 130, Loss: 0.00010760605073301122, Min w: 0.6986477971076965\n",
      "Iteration 140, Loss: 0.00010939275671262294, Min w: 0.6927627921104431\n",
      "Iteration 150, Loss: 0.00011677556176437065, Min w: 0.6928911209106445\n",
      "Iteration 160, Loss: 0.00011992619693046436, Min w: 0.6931090950965881\n",
      "Iteration 170, Loss: 0.00010801442113006487, Min w: 0.6979270577430725\n",
      "Iteration 180, Loss: 0.00011031316535081714, Min w: 0.6973696947097778\n",
      "Iteration 190, Loss: 0.00010697612015064806, Min w: 0.7009909749031067\n",
      "Iteration 200, Loss: 0.00010456779273226857, Min w: 0.707007884979248\n",
      "Iteration 210, Loss: 0.00010469232802279294, Min w: 0.7015713453292847\n",
      "Iteration 220, Loss: 0.0001045921744662337, Min w: 0.7018390893936157\n",
      "Iteration 230, Loss: 0.0001052927109412849, Min w: 0.7095903158187866\n",
      "Iteration 240, Loss: 0.00010230460611637682, Min w: 0.7092646956443787\n",
      "Iteration 250, Loss: 0.00010363506589783356, Min w: 0.709622323513031\n",
      "Iteration 260, Loss: 0.00010303421731805429, Min w: 0.7095109820365906\n",
      "Iteration 270, Loss: 0.00010921865759883076, Min w: 0.7142493724822998\n",
      "Iteration 280, Loss: 0.00010522081720409915, Min w: 0.7131431698799133\n",
      "Iteration 290, Loss: 0.00010267277684761211, Min w: 0.7128223776817322\n",
      "Iteration 300, Loss: 0.0001021044299704954, Min w: 0.7098135948181152\n",
      "Iteration 310, Loss: 0.0001058174020727165, Min w: 0.716488778591156\n",
      "Iteration 320, Loss: 9.965508070308715e-05, Min w: 0.7219240069389343\n",
      "Iteration 330, Loss: 0.00010744135943241417, Min w: 0.7097912430763245\n",
      "Iteration 340, Loss: 0.00010363320325268432, Min w: 0.7242842316627502\n",
      "Iteration 350, Loss: 9.976623550755903e-05, Min w: 0.7219524383544922\n",
      "Iteration 360, Loss: 0.00010110980656463653, Min w: 0.7260710000991821\n",
      "Iteration 370, Loss: 9.499109728494659e-05, Min w: 0.7312126755714417\n",
      "Iteration 380, Loss: 9.730669262353331e-05, Min w: 0.7267130017280579\n",
      "Iteration 390, Loss: 9.82263736659661e-05, Min w: 0.7294527888298035\n",
      "Iteration 400, Loss: 9.573777788318694e-05, Min w: 0.7301940321922302\n",
      "Iteration 410, Loss: 0.00010210738400928676, Min w: 0.7257103323936462\n",
      "Iteration 420, Loss: 0.00010155566997127607, Min w: 0.7256491780281067\n",
      "Iteration 430, Loss: 9.904780745273456e-05, Min w: 0.7400749325752258\n",
      "Iteration 440, Loss: 0.00010980786464642733, Min w: 0.7253361940383911\n",
      "Iteration 450, Loss: 9.691122977528721e-05, Min w: 0.7376375794410706\n",
      "Iteration 460, Loss: 9.600108751328662e-05, Min w: 0.7443782091140747\n",
      "Iteration 470, Loss: 9.616103488951921e-05, Min w: 0.7394760251045227\n",
      "Iteration 480, Loss: 9.482359746471047e-05, Min w: 0.745165228843689\n",
      "Iteration 490, Loss: 9.802080603549257e-05, Min w: 0.7390246987342834\n",
      "Iteration 500, Loss: 9.216530452249572e-05, Min w: 0.7455312609672546\n",
      "Iteration 510, Loss: 9.984507050830871e-05, Min w: 0.7423719167709351\n",
      "Iteration 520, Loss: 9.41480029723607e-05, Min w: 0.7458116412162781\n",
      "Iteration 530, Loss: 9.058391879079863e-05, Min w: 0.7459020018577576\n",
      "Iteration 540, Loss: 9.129916725214571e-05, Min w: 0.7532182335853577\n",
      "Iteration 550, Loss: 0.0001057766712619923, Min w: 0.7422366142272949\n",
      "Iteration 560, Loss: 9.156954183708876e-05, Min w: 0.7563197016716003\n",
      "Iteration 570, Loss: 9.557977318763733e-05, Min w: 0.742246687412262\n",
      "Iteration 580, Loss: 8.92940879566595e-05, Min w: 0.756758451461792\n",
      "Iteration 590, Loss: 9.068030340131372e-05, Min w: 0.7562098503112793\n",
      "Iteration 600, Loss: 9.133746789302677e-05, Min w: 0.7500530481338501\n",
      "Iteration 610, Loss: 9.171579586109146e-05, Min w: 0.7561956644058228\n",
      "Iteration 620, Loss: 8.939649706007913e-05, Min w: 0.7560402750968933\n",
      "Iteration 630, Loss: 8.966741006588563e-05, Min w: 0.7586112022399902\n",
      "Iteration 640, Loss: 8.70605290401727e-05, Min w: 0.7647367715835571\n",
      "Iteration 650, Loss: 9.482204040978104e-05, Min w: 0.7554575800895691\n",
      "Iteration 660, Loss: 0.00010018469765782356, Min w: 0.7541202306747437\n",
      "Iteration 670, Loss: 8.602561865700409e-05, Min w: 0.7651466727256775\n",
      "Iteration 680, Loss: 9.021636651596054e-05, Min w: 0.7688436508178711\n",
      "Iteration 690, Loss: 9.257043711841106e-05, Min w: 0.7610569596290588\n",
      "Iteration 700, Loss: 9.309160668635741e-05, Min w: 0.7576608061790466\n",
      "Iteration 710, Loss: 9.218892228091136e-05, Min w: 0.7692804932594299\n",
      "Iteration 720, Loss: 9.755771316122264e-05, Min w: 0.7568609118461609\n",
      "Iteration 730, Loss: 8.331121352966875e-05, Min w: 0.77097487449646\n",
      "Iteration 740, Loss: 8.421226812060922e-05, Min w: 0.7759764790534973\n",
      "Iteration 750, Loss: 9.903083264362067e-05, Min w: 0.7587842345237732\n",
      "Iteration 760, Loss: 9.64101345743984e-05, Min w: 0.7662391066551208\n",
      "Iteration 770, Loss: 8.183132740668952e-05, Min w: 0.7760892510414124\n",
      "Iteration 780, Loss: 9.969950042432174e-05, Min w: 0.7634632587432861\n",
      "Iteration 790, Loss: 8.262291521532461e-05, Min w: 0.7736445665359497\n",
      "Iteration 800, Loss: 9.014496754389256e-05, Min w: 0.7699521780014038\n",
      "Iteration 810, Loss: 8.261358016170561e-05, Min w: 0.7801128625869751\n",
      "Iteration 820, Loss: 8.345615060534328e-05, Min w: 0.7802260518074036\n",
      "Iteration 830, Loss: 8.354139572475106e-05, Min w: 0.7816089391708374\n",
      "Iteration 840, Loss: 8.506314770784229e-05, Min w: 0.7828204035758972\n",
      "Iteration 850, Loss: 8.68564093252644e-05, Min w: 0.7811334133148193\n",
      "Iteration 860, Loss: 8.444772538496181e-05, Min w: 0.7795467376708984\n",
      "Iteration 870, Loss: 7.806457142578438e-05, Min w: 0.784711480140686\n",
      "Iteration 880, Loss: 8.134794916259125e-05, Min w: 0.7814672589302063\n",
      "Iteration 890, Loss: 8.183262252714485e-05, Min w: 0.7870997190475464\n",
      "Iteration 900, Loss: 7.660223491257057e-05, Min w: 0.7907290458679199\n",
      "Iteration 910, Loss: 8.420571248279884e-05, Min w: 0.7867032289505005\n",
      "Iteration 920, Loss: 7.91104685049504e-05, Min w: 0.7855941653251648\n",
      "Iteration 930, Loss: 8.038152009248734e-05, Min w: 0.7873116135597229\n",
      "Iteration 940, Loss: 7.684010051889345e-05, Min w: 0.7955175042152405\n",
      "Iteration 950, Loss: 7.762072345940396e-05, Min w: 0.7922312021255493\n",
      "Iteration 960, Loss: 7.941027433844283e-05, Min w: 0.7945834994316101\n",
      "Iteration 970, Loss: 7.78826724854298e-05, Min w: 0.7968376874923706\n",
      "Iteration 980, Loss: 8.552835788577795e-05, Min w: 0.7839229106903076\n",
      "Iteration 990, Loss: 8.065581641858444e-05, Min w: 0.7940343022346497\n",
      "Iteration 1000, Loss: 7.988992001628503e-05, Min w: 0.8007974624633789\n",
      "Iteration 1010, Loss: 7.503366941818967e-05, Min w: 0.8064659237861633\n",
      "Iteration 1020, Loss: 7.576367352157831e-05, Min w: 0.8033515214920044\n",
      "Iteration 1030, Loss: 8.461188554065302e-05, Min w: 0.796130359172821\n",
      "Iteration 1040, Loss: 7.593774353154004e-05, Min w: 0.8021440505981445\n",
      "Iteration 1050, Loss: 7.506206020480022e-05, Min w: 0.8022340536117554\n",
      "Iteration 1060, Loss: 7.497867045458406e-05, Min w: 0.8043732643127441\n",
      "Iteration 1070, Loss: 7.47893427615054e-05, Min w: 0.8003602623939514\n",
      "Iteration 1080, Loss: 7.417034794343635e-05, Min w: 0.8127422332763672\n",
      "Iteration 1090, Loss: 7.379596354439855e-05, Min w: 0.8089084625244141\n",
      "Iteration 1100, Loss: 7.178824307629839e-05, Min w: 0.8109801411628723\n",
      "Iteration 1110, Loss: 7.581213139928877e-05, Min w: 0.808713972568512\n",
      "Iteration 1120, Loss: 8.09819539426826e-05, Min w: 0.8022135496139526\n",
      "Iteration 1130, Loss: 7.630197069374844e-05, Min w: 0.8121315836906433\n",
      "Iteration 1140, Loss: 8.219211304094642e-05, Min w: 0.8011976480484009\n",
      "Iteration 1150, Loss: 8.104212611215189e-05, Min w: 0.8062778115272522\n",
      "Iteration 1160, Loss: 8.313252328662202e-05, Min w: 0.8084890842437744\n",
      "Iteration 1170, Loss: 7.013793219812214e-05, Min w: 0.8154330849647522\n",
      "Iteration 1180, Loss: 7.409914542222396e-05, Min w: 0.8148945569992065\n",
      "Iteration 1190, Loss: 7.635989459231496e-05, Min w: 0.8137337565422058\n",
      "Iteration 1200, Loss: 7.866491796448827e-05, Min w: 0.8112426996231079\n",
      "Iteration 1210, Loss: 8.348907431354746e-05, Min w: 0.8064015507698059\n",
      "Iteration 1220, Loss: 7.13943227310665e-05, Min w: 0.817601203918457\n",
      "Iteration 1230, Loss: 7.157975051086396e-05, Min w: 0.8213139772415161\n",
      "Iteration 1240, Loss: 6.690014561172575e-05, Min w: 0.823465883731842\n",
      "Iteration 0, Loss: 7.471828575944528e-05, Min w: 0.8171772360801697\n",
      "Iteration 10, Loss: 6.738876982126385e-05, Min w: 0.8246250748634338\n",
      "Iteration 20, Loss: 7.849825487937778e-05, Min w: 0.8165397644042969\n",
      "Iteration 30, Loss: 6.716054485877976e-05, Min w: 0.8245584964752197\n",
      "Iteration 40, Loss: 7.133706094464287e-05, Min w: 0.8265979290008545\n",
      "Iteration 50, Loss: 7.333112444030121e-05, Min w: 0.8208712935447693\n",
      "Iteration 60, Loss: 6.687050336040556e-05, Min w: 0.8315736651420593\n",
      "Iteration 70, Loss: 6.735423085046932e-05, Min w: 0.8303437232971191\n",
      "Iteration 80, Loss: 6.879371358081698e-05, Min w: 0.832851767539978\n",
      "Iteration 90, Loss: 6.843241862952709e-05, Min w: 0.8303101658821106\n",
      "Iteration 100, Loss: 8.381314546568319e-05, Min w: 0.8187614679336548\n",
      "Iteration 110, Loss: 6.634153396589682e-05, Min w: 0.8323246240615845\n",
      "Iteration 120, Loss: 7.08355219103396e-05, Min w: 0.8287197351455688\n",
      "Iteration 130, Loss: 6.442873564083129e-05, Min w: 0.8373433947563171\n",
      "Iteration 140, Loss: 6.615959136979654e-05, Min w: 0.8305457830429077\n",
      "Iteration 150, Loss: 7.464054215233773e-05, Min w: 0.8189157843589783\n",
      "Iteration 160, Loss: 6.492373358923942e-05, Min w: 0.8418347239494324\n",
      "Iteration 170, Loss: 6.38065321254544e-05, Min w: 0.8361400961875916\n",
      "Iteration 180, Loss: 7.526537956437096e-05, Min w: 0.8314849734306335\n",
      "Iteration 190, Loss: 6.372367352014408e-05, Min w: 0.8376351594924927\n",
      "Iteration 200, Loss: 7.65437216614373e-05, Min w: 0.8296884298324585\n",
      "Iteration 210, Loss: 6.382133869919926e-05, Min w: 0.8373282551765442\n",
      "Iteration 220, Loss: 8.648255607113242e-05, Min w: 0.8215571641921997\n",
      "Iteration 230, Loss: 7.129077130230144e-05, Min w: 0.8389114141464233\n",
      "Iteration 240, Loss: 6.380272679962218e-05, Min w: 0.8435925841331482\n",
      "Iteration 250, Loss: 8.430668094661087e-05, Min w: 0.8272900581359863\n",
      "Iteration 260, Loss: 6.43641033093445e-05, Min w: 0.8401715755462646\n",
      "Iteration 270, Loss: 6.311329343589023e-05, Min w: 0.8420774936676025\n",
      "Iteration 280, Loss: 6.135263538453728e-05, Min w: 0.8444352746009827\n",
      "Iteration 290, Loss: 6.298142398009077e-05, Min w: 0.843826949596405\n",
      "Iteration 300, Loss: 6.2426486692857e-05, Min w: 0.8456491231918335\n",
      "Iteration 310, Loss: 6.171973655000329e-05, Min w: 0.8481974005699158\n",
      "Iteration 320, Loss: 6.448921340052038e-05, Min w: 0.8444390296936035\n",
      "Iteration 330, Loss: 7.029574044281617e-05, Min w: 0.8417415022850037\n",
      "Iteration 340, Loss: 6.0995571402600035e-05, Min w: 0.8485774397850037\n",
      "Iteration 350, Loss: 7.394282147288322e-05, Min w: 0.8355429172515869\n",
      "Iteration 360, Loss: 5.9106620028615e-05, Min w: 0.8535124659538269\n",
      "Iteration 370, Loss: 6.075227429391816e-05, Min w: 0.8518064022064209\n",
      "Iteration 380, Loss: 5.725617302232422e-05, Min w: 0.8546786308288574\n",
      "Iteration 390, Loss: 6.335287616821006e-05, Min w: 0.8497961759567261\n",
      "Iteration 400, Loss: 6.48968925816007e-05, Min w: 0.8491308093070984\n",
      "Iteration 410, Loss: 5.824989057146013e-05, Min w: 0.8548786640167236\n",
      "Iteration 420, Loss: 5.96949685132131e-05, Min w: 0.8534590005874634\n",
      "Iteration 430, Loss: 5.930768384132534e-05, Min w: 0.8525429368019104\n",
      "Iteration 440, Loss: 5.747913019149564e-05, Min w: 0.8595820069313049\n",
      "Iteration 450, Loss: 5.8554338465910405e-05, Min w: 0.8572801351547241\n",
      "Iteration 460, Loss: 6.549675890710205e-05, Min w: 0.8468103408813477\n",
      "Iteration 470, Loss: 8.193992107408121e-05, Min w: 0.8202096819877625\n",
      "Iteration 480, Loss: 5.9042478824267164e-05, Min w: 0.8577598929405212\n",
      "Iteration 490, Loss: 6.67764907120727e-05, Min w: 0.8495420217514038\n",
      "Iteration 500, Loss: 5.679660171153955e-05, Min w: 0.8617827296257019\n",
      "Iteration 510, Loss: 5.6432498240610585e-05, Min w: 0.8627312779426575\n",
      "Iteration 520, Loss: 6.265172123676166e-05, Min w: 0.8585953116416931\n",
      "Iteration 530, Loss: 6.668121932307258e-05, Min w: 0.8570126891136169\n",
      "Iteration 540, Loss: 6.207107071531937e-05, Min w: 0.8564225435256958\n",
      "Iteration 550, Loss: 6.198627670528367e-05, Min w: 0.8620224595069885\n",
      "Iteration 560, Loss: 5.7654440752230585e-05, Min w: 0.8625160455703735\n",
      "Iteration 570, Loss: 5.400450754677877e-05, Min w: 0.8684656023979187\n",
      "Iteration 580, Loss: 5.549451452679932e-05, Min w: 0.8652715086936951\n",
      "Iteration 590, Loss: 5.514373697224073e-05, Min w: 0.8655185103416443\n",
      "Iteration 600, Loss: 5.442385372589342e-05, Min w: 0.866377055644989\n",
      "Iteration 610, Loss: 5.5762789997970685e-05, Min w: 0.8680073618888855\n",
      "Iteration 620, Loss: 6.103757186792791e-05, Min w: 0.8651034235954285\n",
      "Iteration 630, Loss: 5.311377753969282e-05, Min w: 0.8708561658859253\n",
      "Iteration 640, Loss: 5.611700180452317e-05, Min w: 0.866921067237854\n",
      "Iteration 650, Loss: 5.467676601256244e-05, Min w: 0.8707004189491272\n",
      "Iteration 660, Loss: 5.551037611439824e-05, Min w: 0.8700911998748779\n",
      "Iteration 670, Loss: 5.689850149792619e-05, Min w: 0.868791401386261\n",
      "Iteration 680, Loss: 6.0862137615913525e-05, Min w: 0.8622259497642517\n",
      "Iteration 690, Loss: 6.412877701222897e-05, Min w: 0.8663756847381592\n",
      "Iteration 700, Loss: 5.4448304581455886e-05, Min w: 0.8754633069038391\n",
      "Iteration 710, Loss: 5.3550807933788747e-05, Min w: 0.8701712489128113\n",
      "Iteration 720, Loss: 5.419515582616441e-05, Min w: 0.8764097690582275\n",
      "Iteration 730, Loss: 5.2514402341330424e-05, Min w: 0.8764566779136658\n",
      "Iteration 740, Loss: 5.278800745145418e-05, Min w: 0.8728585243225098\n",
      "Iteration 750, Loss: 8.162333688233048e-05, Min w: 0.8096131086349487\n",
      "Iteration 760, Loss: 5.28039745404385e-05, Min w: 0.8743077516555786\n",
      "Iteration 770, Loss: 5.127466283738613e-05, Min w: 0.8755784034729004\n",
      "Iteration 780, Loss: 5.307413448463194e-05, Min w: 0.8763559460639954\n",
      "Iteration 790, Loss: 5.491789852385409e-05, Min w: 0.8753642439842224\n",
      "Iteration 800, Loss: 5.640741437673569e-05, Min w: 0.8779351115226746\n",
      "Iteration 810, Loss: 5.196050551603548e-05, Min w: 0.8785785436630249\n",
      "Iteration 820, Loss: 5.920287003391422e-05, Min w: 0.871419370174408\n",
      "Iteration 830, Loss: 5.0552949687698856e-05, Min w: 0.879066526889801\n",
      "Iteration 840, Loss: 4.897957114735618e-05, Min w: 0.8831949830055237\n",
      "Iteration 850, Loss: 5.7992507208837196e-05, Min w: 0.8809689283370972\n",
      "Iteration 860, Loss: 6.188413681229576e-05, Min w: 0.8697758316993713\n",
      "Iteration 870, Loss: 4.817951412405819e-05, Min w: 0.884945809841156\n",
      "Iteration 880, Loss: 5.190719457459636e-05, Min w: 0.8846796154975891\n",
      "Iteration 890, Loss: 5.754449011874385e-05, Min w: 0.8780229687690735\n",
      "Iteration 900, Loss: 6.482510070782155e-05, Min w: 0.8662797808647156\n",
      "Iteration 910, Loss: 4.7732468374306336e-05, Min w: 0.8885444402694702\n",
      "Iteration 920, Loss: 5.0383430789224803e-05, Min w: 0.8842023611068726\n",
      "Iteration 930, Loss: 6.501696043414995e-05, Min w: 0.862294614315033\n",
      "Iteration 940, Loss: 4.698854900198057e-05, Min w: 0.8876073360443115\n",
      "Iteration 950, Loss: 4.8999045247910544e-05, Min w: 0.8876286149024963\n",
      "Iteration 960, Loss: 4.9862115702126175e-05, Min w: 0.8824387192726135\n",
      "Iteration 970, Loss: 4.781949246535078e-05, Min w: 0.888532280921936\n",
      "Iteration 980, Loss: 4.801195609616116e-05, Min w: 0.8890113234519958\n",
      "Iteration 990, Loss: 5.863698970642872e-05, Min w: 0.8778972029685974\n",
      "Iteration 1000, Loss: 5.0352955440757796e-05, Min w: 0.8848103880882263\n",
      "Iteration 1010, Loss: 4.7215511585818604e-05, Min w: 0.8873239159584045\n",
      "Iteration 1020, Loss: 5.2349430916365236e-05, Min w: 0.8866181373596191\n",
      "Iteration 1030, Loss: 5.14102830493357e-05, Min w: 0.888245165348053\n",
      "Iteration 1040, Loss: 4.8127192712854594e-05, Min w: 0.8913376331329346\n",
      "Iteration 1050, Loss: 4.7526482376269996e-05, Min w: 0.8919521570205688\n",
      "Iteration 1060, Loss: 4.617430749931373e-05, Min w: 0.8907245993614197\n",
      "Iteration 1070, Loss: 4.867401366936974e-05, Min w: 0.8912429213523865\n",
      "Iteration 1080, Loss: 4.7664572775829583e-05, Min w: 0.8905125856399536\n",
      "Iteration 1090, Loss: 4.480393909034319e-05, Min w: 0.8950070738792419\n",
      "Iteration 1100, Loss: 4.533687388175167e-05, Min w: 0.8946070671081543\n",
      "Iteration 1110, Loss: 4.742734017781913e-05, Min w: 0.8930744528770447\n",
      "Iteration 1120, Loss: 4.605502908816561e-05, Min w: 0.8951629400253296\n",
      "Iteration 1130, Loss: 4.710451321443543e-05, Min w: 0.8953610062599182\n",
      "Iteration 1140, Loss: 6.327303708530962e-05, Min w: 0.8542752861976624\n",
      "Iteration 1150, Loss: 4.48865866928827e-05, Min w: 0.8976605534553528\n",
      "Iteration 1160, Loss: 5.6944078096421435e-05, Min w: 0.8761063814163208\n",
      "Iteration 1170, Loss: 6.822922296123579e-05, Min w: 0.8367218375205994\n",
      "Iteration 1180, Loss: 5.037551454734057e-05, Min w: 0.8929935693740845\n",
      "Iteration 1190, Loss: 4.530063597485423e-05, Min w: 0.8985037207603455\n",
      "Iteration 1200, Loss: 5.4924887081142515e-05, Min w: 0.8849621415138245\n",
      "Iteration 1210, Loss: 4.5827520807506517e-05, Min w: 0.8979687094688416\n",
      "Iteration 1220, Loss: 4.3952248233836144e-05, Min w: 0.9009389877319336\n",
      "Iteration 1230, Loss: 4.5309276174521074e-05, Min w: 0.8990275859832764\n",
      "Iteration 1240, Loss: 4.512161831371486e-05, Min w: 0.8992028832435608\n",
      "Iteration 0, Loss: 4.8533671360928565e-05, Min w: 0.8902609348297119\n",
      "Iteration 10, Loss: 4.323785469750874e-05, Min w: 0.9031189680099487\n",
      "Iteration 20, Loss: 4.756906855618581e-05, Min w: 0.8983478546142578\n",
      "Iteration 30, Loss: 4.5300941565074027e-05, Min w: 0.9015436172485352\n",
      "Iteration 40, Loss: 5.07860750076361e-05, Min w: 0.8946002125740051\n",
      "Iteration 50, Loss: 4.781951429322362e-05, Min w: 0.8982234597206116\n",
      "Iteration 60, Loss: 5.168748975847848e-05, Min w: 0.8930976390838623\n",
      "Iteration 70, Loss: 4.275943138054572e-05, Min w: 0.906435489654541\n",
      "Iteration 80, Loss: 4.2541232687653974e-05, Min w: 0.9034743905067444\n",
      "Iteration 90, Loss: 4.66172605229076e-05, Min w: 0.9039000868797302\n",
      "Iteration 100, Loss: 4.642796193365939e-05, Min w: 0.9012162685394287\n",
      "Iteration 110, Loss: 6.267930439207703e-05, Min w: 0.8598272800445557\n",
      "Iteration 120, Loss: 4.2745166865643114e-05, Min w: 0.9051207304000854\n",
      "Iteration 130, Loss: 4.137832729611546e-05, Min w: 0.9095626473426819\n",
      "Iteration 140, Loss: 4.156318391324021e-05, Min w: 0.9059655666351318\n",
      "Iteration 150, Loss: 4.26021397288423e-05, Min w: 0.9096524119377136\n",
      "Iteration 160, Loss: 5.0900063797598705e-05, Min w: 0.8912713527679443\n",
      "Iteration 170, Loss: 4.056360194226727e-05, Min w: 0.9087662100791931\n",
      "Iteration 180, Loss: 4.73600193799939e-05, Min w: 0.9018452167510986\n",
      "Iteration 190, Loss: 4.2565359763102606e-05, Min w: 0.9062299132347107\n",
      "Iteration 200, Loss: 4.987949796486646e-05, Min w: 0.893417477607727\n",
      "Iteration 210, Loss: 5.2251172746764496e-05, Min w: 0.8913659453392029\n",
      "Iteration 220, Loss: 4.736330811283551e-05, Min w: 0.9012939929962158\n",
      "Iteration 230, Loss: 4.5241962652653456e-05, Min w: 0.905704140663147\n",
      "Iteration 240, Loss: 4.324200563132763e-05, Min w: 0.9076170921325684\n",
      "Iteration 250, Loss: 4.91381470055785e-05, Min w: 0.8967974185943604\n",
      "Iteration 260, Loss: 4.4430416892282665e-05, Min w: 0.9078527092933655\n",
      "Iteration 270, Loss: 4.1809416870819405e-05, Min w: 0.9088723063468933\n",
      "Iteration 280, Loss: 4.741946031572297e-05, Min w: 0.9003708958625793\n",
      "Iteration 290, Loss: 4.0148119296645746e-05, Min w: 0.9120725393295288\n",
      "Iteration 300, Loss: 4.2761152144521475e-05, Min w: 0.9086687564849854\n",
      "Iteration 310, Loss: 4.196755980956368e-05, Min w: 0.9133524894714355\n",
      "Iteration 320, Loss: 4.059210914419964e-05, Min w: 0.9115632176399231\n",
      "Iteration 330, Loss: 4.190547042526305e-05, Min w: 0.9099752902984619\n",
      "Iteration 340, Loss: 4.2766019760165364e-05, Min w: 0.9103579521179199\n",
      "Iteration 350, Loss: 5.6415923609165475e-05, Min w: 0.8732417225837708\n",
      "Iteration 360, Loss: 4.252991493558511e-05, Min w: 0.9085040092468262\n",
      "Iteration 370, Loss: 4.1154020436806604e-05, Min w: 0.9119036793708801\n",
      "Iteration 380, Loss: 4.5076481910655275e-05, Min w: 0.9059515595436096\n",
      "Iteration 390, Loss: 3.8531856262125075e-05, Min w: 0.914266049861908\n",
      "Iteration 400, Loss: 4.0938477468444034e-05, Min w: 0.9146424531936646\n",
      "Iteration 410, Loss: 3.841361831291579e-05, Min w: 0.9151712656021118\n",
      "Iteration 420, Loss: 3.796060991589911e-05, Min w: 0.9164832830429077\n",
      "Iteration 430, Loss: 3.832884976873174e-05, Min w: 0.9164032340049744\n",
      "Iteration 440, Loss: 3.863529855152592e-05, Min w: 0.9159888029098511\n",
      "Iteration 450, Loss: 4.1849994886433706e-05, Min w: 0.9139569997787476\n",
      "Iteration 460, Loss: 4.356559657026082e-05, Min w: 0.9103037118911743\n",
      "Iteration 470, Loss: 5.146880357642658e-05, Min w: 0.8802671432495117\n",
      "Iteration 480, Loss: 4.743086901726201e-05, Min w: 0.8936978578567505\n",
      "Iteration 490, Loss: 4.252450162312016e-05, Min w: 0.9128718972206116\n",
      "Iteration 500, Loss: 3.9572481909999624e-05, Min w: 0.9160280227661133\n",
      "Iteration 510, Loss: 3.7183021049713716e-05, Min w: 0.9181733131408691\n",
      "Iteration 520, Loss: 3.969619865529239e-05, Min w: 0.9179268479347229\n",
      "Iteration 530, Loss: 3.909211955033243e-05, Min w: 0.9171029925346375\n",
      "Iteration 540, Loss: 3.690150333568454e-05, Min w: 0.9198204278945923\n",
      "Iteration 550, Loss: 4.168704981566407e-05, Min w: 0.9141295552253723\n",
      "Iteration 560, Loss: 4.4358766899676993e-05, Min w: 0.9013770222663879\n",
      "Iteration 570, Loss: 3.927936631953344e-05, Min w: 0.9194673299789429\n",
      "Iteration 580, Loss: 4.417041418491863e-05, Min w: 0.8996962904930115\n",
      "Iteration 590, Loss: 3.6939585697837174e-05, Min w: 0.9202091097831726\n",
      "Iteration 600, Loss: 3.964126517530531e-05, Min w: 0.9186148047447205\n",
      "Iteration 610, Loss: 4.344068656791933e-05, Min w: 0.9050258994102478\n",
      "Iteration 620, Loss: 4.048967093694955e-05, Min w: 0.9167096614837646\n",
      "Iteration 630, Loss: 3.900531737599522e-05, Min w: 0.9173780679702759\n",
      "Iteration 640, Loss: 3.6599503800971434e-05, Min w: 0.9227078557014465\n",
      "Iteration 650, Loss: 3.7305773730622604e-05, Min w: 0.9226056933403015\n",
      "Iteration 660, Loss: 3.6114903195993975e-05, Min w: 0.9241237640380859\n",
      "Iteration 670, Loss: 3.750005271285772e-05, Min w: 0.9221265316009521\n",
      "Iteration 680, Loss: 3.951663165935315e-05, Min w: 0.9185609221458435\n",
      "Iteration 690, Loss: 3.611070496845059e-05, Min w: 0.9242250323295593\n",
      "Iteration 700, Loss: 3.534661664161831e-05, Min w: 0.9252329468727112\n",
      "Iteration 710, Loss: 4.0491642721462995e-05, Min w: 0.9117934107780457\n",
      "Iteration 720, Loss: 3.585973900044337e-05, Min w: 0.9245912432670593\n",
      "Iteration 730, Loss: 3.642991941887885e-05, Min w: 0.9243074059486389\n",
      "Iteration 740, Loss: 3.576364542823285e-05, Min w: 0.9253795742988586\n",
      "Iteration 750, Loss: 3.889600338879973e-05, Min w: 0.9160618185997009\n",
      "Iteration 760, Loss: 3.576370363589376e-05, Min w: 0.9246517419815063\n",
      "Iteration 770, Loss: 3.4222590329591185e-05, Min w: 0.9259933233261108\n",
      "Iteration 780, Loss: 3.719630331033841e-05, Min w: 0.9213904142379761\n",
      "Iteration 790, Loss: 4.559245644486509e-05, Min w: 0.894551694393158\n",
      "Iteration 800, Loss: 3.285654020146467e-05, Min w: 0.9301304221153259\n",
      "Iteration 810, Loss: 3.963135168305598e-05, Min w: 0.914365291595459\n",
      "Iteration 820, Loss: 4.557109059533104e-05, Min w: 0.8936756253242493\n",
      "Iteration 830, Loss: 3.469930015853606e-05, Min w: 0.9279031157493591\n",
      "Iteration 840, Loss: 3.60467893187888e-05, Min w: 0.9253050684928894\n",
      "Iteration 850, Loss: 3.372327046236023e-05, Min w: 0.9309966564178467\n",
      "Iteration 860, Loss: 3.7468878872459754e-05, Min w: 0.9211193919181824\n",
      "Iteration 870, Loss: 3.520157406455837e-05, Min w: 0.9265897870063782\n",
      "Iteration 880, Loss: 3.636861583800055e-05, Min w: 0.9221920371055603\n",
      "Iteration 890, Loss: 4.091383016202599e-05, Min w: 0.9081035852432251\n",
      "Iteration 900, Loss: 3.896951238857582e-05, Min w: 0.9159629344940186\n",
      "Iteration 910, Loss: 3.501733226585202e-05, Min w: 0.9269278049468994\n",
      "Iteration 920, Loss: 3.758245293283835e-05, Min w: 0.9172922372817993\n",
      "Iteration 930, Loss: 3.210140857845545e-05, Min w: 0.9323005676269531\n",
      "Iteration 940, Loss: 4.2337796912761405e-05, Min w: 0.905521810054779\n",
      "Iteration 950, Loss: 4.770839950651862e-05, Min w: 0.8864325284957886\n",
      "Iteration 960, Loss: 3.3437750971643254e-05, Min w: 0.9295646548271179\n",
      "Iteration 970, Loss: 3.8690570363542065e-05, Min w: 0.9150047302246094\n",
      "Iteration 980, Loss: 5.39023858436849e-05, Min w: 0.8632850050926208\n",
      "Iteration 990, Loss: 3.741856926353648e-05, Min w: 0.9204240441322327\n",
      "Iteration 1000, Loss: 3.3265052479691803e-05, Min w: 0.9295322895050049\n",
      "Iteration 1010, Loss: 3.247906352044083e-05, Min w: 0.9335353374481201\n",
      "Iteration 1020, Loss: 3.2515221391804516e-05, Min w: 0.9332393407821655\n",
      "Iteration 1030, Loss: 3.677458516904153e-05, Min w: 0.9182509779930115\n",
      "Iteration 1040, Loss: 3.5199118428863585e-05, Min w: 0.9256198406219482\n",
      "Iteration 1050, Loss: 3.68572655133903e-05, Min w: 0.9182146191596985\n",
      "Iteration 1060, Loss: 3.201834260835312e-05, Min w: 0.9338563084602356\n",
      "Iteration 1070, Loss: 3.312570333946496e-05, Min w: 0.9321659207344055\n",
      "Iteration 1080, Loss: 3.52626848325599e-05, Min w: 0.922471284866333\n",
      "Iteration 1090, Loss: 3.530918911565095e-05, Min w: 0.9225955009460449\n",
      "Iteration 1100, Loss: 3.141830165986903e-05, Min w: 0.9352447390556335\n",
      "Iteration 1110, Loss: 3.612085129134357e-05, Min w: 0.9198726415634155\n",
      "Iteration 1120, Loss: 3.5003140510525554e-05, Min w: 0.9215823411941528\n",
      "Iteration 1130, Loss: 3.3540934964548796e-05, Min w: 0.9296546578407288\n",
      "Iteration 1140, Loss: 3.334596840431914e-05, Min w: 0.9289616942405701\n",
      "Iteration 1150, Loss: 3.23457206832245e-05, Min w: 0.933491587638855\n",
      "Iteration 1160, Loss: 3.559522519935854e-05, Min w: 0.9235667586326599\n",
      "Iteration 1170, Loss: 3.212581214029342e-05, Min w: 0.933643639087677\n",
      "Iteration 1180, Loss: 3.5859568015439436e-05, Min w: 0.9213625192642212\n",
      "Iteration 1190, Loss: 4.856044688494876e-05, Min w: 0.8860660791397095\n",
      "Iteration 1200, Loss: 3.879583164234646e-05, Min w: 0.9077533483505249\n",
      "Iteration 1210, Loss: 3.262414611526765e-05, Min w: 0.9309890270233154\n",
      "Iteration 1220, Loss: 3.27082525473088e-05, Min w: 0.9307641983032227\n",
      "Iteration 1230, Loss: 3.1162799132289365e-05, Min w: 0.9355739951133728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  33%|███▎      | 8/24 [12:14<24:13, 90.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 3.282414763816632e-05, Min w: 0.92910236120224\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.02041125792263619, 'L2_avg': 0.031062699222208175, 'End_point_L1_avg': 0.008517753383499768, 'End_point_L2_avg': 0.008899945236246563}\n",
      "Iteration 0, Loss: 0.00332237989641726, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0023747545201331377, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0022296246606856585, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0021387895103543997, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002176285721361637, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0024662590585649014, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0022645348217338324, Min w: 0.000796845240984112\n",
      "Iteration 70, Loss: 0.0022660410031676292, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0022679741960018873, Min w: 1.5558217214550751e-10\n",
      "Iteration 90, Loss: 0.002137599978595972, Min w: 6.5327216065227735e-37\n",
      "Iteration 100, Loss: 0.00240999273955822, Min w: 1.4880071840461346e-23\n",
      "Iteration 110, Loss: 0.002129526110365987, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002509244019165635, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002026220550760627, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0020877120550721884, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002110223053023219, Min w: 4.7539228269327645e-25\n",
      "Iteration 160, Loss: 0.0019483740907162428, Min w: 0.0015525080962106586\n",
      "Iteration 170, Loss: 0.0017744135111570358, Min w: 0.009293144568800926\n",
      "Iteration 180, Loss: 0.0020264985505491495, Min w: 3.3646458015568204e-13\n",
      "Iteration 190, Loss: 0.0019615949131548405, Min w: 3.0933444172397113e-31\n",
      "Iteration 200, Loss: 0.0021011806093156338, Min w: 1.1601967773730782e-16\n",
      "Iteration 210, Loss: 0.0021481248550117016, Min w: 1.8349495759029582e-16\n",
      "Iteration 220, Loss: 0.0019414322450757027, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00207038433291018, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0018000284908339381, Min w: 1.2504132904743183e-27\n",
      "Iteration 250, Loss: 0.0020174605306237936, Min w: 9.965401659428608e-07\n",
      "Iteration 260, Loss: 0.002016326878219843, Min w: 0.0011954036308452487\n",
      "Iteration 270, Loss: 0.0021569430828094482, Min w: 1.1532686361393244e-42\n",
      "Iteration 280, Loss: 0.0019781463779509068, Min w: 0.0052546849474310875\n",
      "Iteration 290, Loss: 0.0018756279023364186, Min w: 9.459708829484257e-19\n",
      "Iteration 300, Loss: 0.0012964294292032719, Min w: 0.13638220727443695\n",
      "Iteration 310, Loss: 0.0017847783165052533, Min w: 0.08760253340005875\n",
      "Iteration 320, Loss: 0.001989726908504963, Min w: 8.785890604425858e-19\n",
      "Iteration 330, Loss: 0.0020494211930781603, Min w: 6.298313778033507e-31\n",
      "Iteration 340, Loss: 0.0020472302567213774, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002290362259373069, Min w: 1.8820086114534895e-11\n",
      "Iteration 360, Loss: 0.002028197282925248, Min w: 1.1391682264161318e-08\n",
      "Iteration 370, Loss: 0.002171184169128537, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0017484268173575401, Min w: 2.1846114656088505e-28\n",
      "Iteration 390, Loss: 0.0020099745597690344, Min w: 3.6577188841988486e-17\n",
      "Iteration 400, Loss: 0.0018034124514088035, Min w: 7.467323878381296e-14\n",
      "Iteration 410, Loss: 0.00140689080581069, Min w: 0.01982683688402176\n",
      "Iteration 420, Loss: 0.0019996515475213528, Min w: 5.35789589038448e-27\n",
      "Iteration 430, Loss: 0.0019510680576786399, Min w: 6.015186682084561e-10\n",
      "Iteration 440, Loss: 0.0020140716806054115, Min w: 6.229313731509478e-10\n",
      "Iteration 450, Loss: 0.002025056164711714, Min w: 5.047144890593743e-25\n",
      "Iteration 460, Loss: 0.0020450439769774675, Min w: 4.9283666990303816e-42\n",
      "Iteration 470, Loss: 0.002027265029028058, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0018952508689835668, Min w: 1.962756160470118e-17\n",
      "Iteration 490, Loss: 0.002009517513215542, Min w: 8.266421537084581e-15\n",
      "Iteration 500, Loss: 0.0020437990315258503, Min w: 1.3840429419675806e-14\n",
      "Iteration 510, Loss: 0.0021489602513611317, Min w: 1.2906681460218073e-25\n",
      "Iteration 520, Loss: 0.002149481326341629, Min w: 6.121825419246297e-20\n",
      "Iteration 530, Loss: 0.002014185767620802, Min w: 7.84859750524447e-08\n",
      "Iteration 540, Loss: 0.0017419675132259727, Min w: 0.0981142520904541\n",
      "Iteration 550, Loss: 0.0016909583937376738, Min w: 4.404676474223379e-06\n",
      "Iteration 560, Loss: 0.0010885432129725814, Min w: 0.30775195360183716\n",
      "Iteration 570, Loss: 0.0010977234924212098, Min w: 0.3477073013782501\n",
      "Iteration 580, Loss: 0.001975155668333173, Min w: 0.0017062474507838488\n",
      "Iteration 590, Loss: 0.0018430332420393825, Min w: 0.024972299113869667\n",
      "Iteration 600, Loss: 0.0015823181020095944, Min w: 0.12211904674768448\n",
      "Iteration 610, Loss: 0.0019154573092237115, Min w: 0.02258235402405262\n",
      "Iteration 620, Loss: 0.00172373466193676, Min w: 0.021214760839939117\n",
      "Iteration 630, Loss: 0.0015963392797857523, Min w: 0.006361647043377161\n",
      "Iteration 640, Loss: 0.001988115021958947, Min w: 5.209229493630119e-05\n",
      "Iteration 650, Loss: 0.002038848353549838, Min w: 1.2352930687036868e-21\n",
      "Iteration 660, Loss: 0.0019531708676368, Min w: 0.000358869117917493\n",
      "Iteration 670, Loss: 0.002056690864264965, Min w: 8.209988678481439e-13\n",
      "Iteration 680, Loss: 0.0020930145401507616, Min w: 1.7340792227171255e-14\n",
      "Iteration 690, Loss: 0.0021068935748189688, Min w: 2.315108868500282e-11\n",
      "Iteration 700, Loss: 0.002075865166261792, Min w: 0.0\n",
      "Iteration 710, Loss: 0.001970467856153846, Min w: 0.0003220088256057352\n",
      "Iteration 720, Loss: 0.001954552484676242, Min w: 3.616694063154756e-23\n",
      "Iteration 730, Loss: 0.001941197318956256, Min w: 0.008028806187212467\n",
      "Iteration 740, Loss: 0.0019331901567056775, Min w: 0.022305447608232498\n",
      "Iteration 750, Loss: 0.001690298318862915, Min w: 0.0118326460942626\n",
      "Iteration 760, Loss: 0.0019375908887013793, Min w: 0.005599093157798052\n",
      "Iteration 770, Loss: 0.001998805208131671, Min w: 7.587799889098337e-17\n",
      "Iteration 780, Loss: 0.002017945982515812, Min w: 0.0004394151910673827\n",
      "Iteration 790, Loss: 0.0016467756358906627, Min w: 0.004538761451840401\n",
      "Iteration 800, Loss: 0.0010539497015997767, Min w: 0.3321599066257477\n",
      "Iteration 810, Loss: 0.0011466862633824348, Min w: 0.3085891306400299\n",
      "Iteration 820, Loss: 0.0018754261545836926, Min w: 0.0036472096107900143\n",
      "Iteration 830, Loss: 0.0012370332842692733, Min w: 0.32138150930404663\n",
      "Iteration 840, Loss: 0.0019573993049561977, Min w: 0.004393982235342264\n",
      "Iteration 850, Loss: 0.001870084903202951, Min w: 0.029163962230086327\n",
      "Iteration 860, Loss: 0.001887903199531138, Min w: 0.0005773098673671484\n",
      "Iteration 870, Loss: 0.0020004066172987223, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0018524967599660158, Min w: 0.0001279715943383053\n",
      "Iteration 890, Loss: 0.0017088241875171661, Min w: 0.00033833933412097394\n",
      "Iteration 900, Loss: 0.0018747830763459206, Min w: 0.03208938613533974\n",
      "Iteration 910, Loss: 0.001808261382393539, Min w: 9.230784053215757e-05\n",
      "Iteration 920, Loss: 0.0016366021009162068, Min w: 0.001542831538245082\n",
      "Iteration 930, Loss: 0.001665094867348671, Min w: 0.011549348011612892\n",
      "Iteration 940, Loss: 0.0018539124866947532, Min w: 0.04492798075079918\n",
      "Iteration 950, Loss: 0.00146940303966403, Min w: 0.18432457745075226\n",
      "Iteration 960, Loss: 0.0009247686830349267, Min w: 0.5346554517745972\n",
      "Iteration 970, Loss: 0.0010974443284794688, Min w: 0.2618506848812103\n",
      "Iteration 980, Loss: 0.0017374170711264014, Min w: 0.021899569779634476\n",
      "Iteration 990, Loss: 0.0007542863604612648, Min w: 0.4404982626438141\n",
      "Iteration 1000, Loss: 0.0007064801757223904, Min w: 0.5346638560295105\n",
      "Iteration 1010, Loss: 0.0006307512521743774, Min w: 0.5376141667366028\n",
      "Iteration 1020, Loss: 0.0007262970320880413, Min w: 0.5300933122634888\n",
      "Iteration 1030, Loss: 0.0007144815754145384, Min w: 0.5464432835578918\n",
      "Iteration 1040, Loss: 0.0007336422568187118, Min w: 0.5430908203125\n",
      "Iteration 1050, Loss: 0.0006687712157145143, Min w: 0.5547952651977539\n",
      "Iteration 1060, Loss: 0.0006917007849551737, Min w: 0.5789104700088501\n",
      "Iteration 1070, Loss: 0.0005245053325779736, Min w: 0.6179167032241821\n",
      "Iteration 1080, Loss: 0.0005400371737778187, Min w: 0.6160285472869873\n",
      "Iteration 1090, Loss: 0.0005815676413476467, Min w: 0.613006591796875\n",
      "Iteration 1100, Loss: 0.0005140546127222478, Min w: 0.6262367367744446\n",
      "Iteration 1110, Loss: 0.000522651185747236, Min w: 0.6279415488243103\n",
      "Iteration 1120, Loss: 0.0008913419442251325, Min w: 0.5437841415405273\n",
      "Iteration 1130, Loss: 0.0005784004461020231, Min w: 0.6324820518493652\n",
      "Iteration 1140, Loss: 0.0005129617056809366, Min w: 0.6893776655197144\n",
      "Iteration 1150, Loss: 0.0004459912597667426, Min w: 0.6792178750038147\n",
      "Iteration 1160, Loss: 0.0005200380692258477, Min w: 0.7023984789848328\n",
      "Iteration 1170, Loss: 0.00044017520849592984, Min w: 0.6888851523399353\n",
      "Iteration 1180, Loss: 0.0007678853580728173, Min w: 0.5766307711601257\n",
      "Iteration 1190, Loss: 0.0005151120712980628, Min w: 0.691210150718689\n",
      "Iteration 1200, Loss: 0.000537671206984669, Min w: 0.6938153505325317\n",
      "Iteration 1210, Loss: 0.0005588668864220381, Min w: 0.6920767426490784\n",
      "Iteration 1220, Loss: 0.00042904660222120583, Min w: 0.7185573577880859\n",
      "Iteration 1230, Loss: 0.0005286679952405393, Min w: 0.6967431902885437\n",
      "Iteration 1240, Loss: 0.000565504829864949, Min w: 0.7128731608390808\n",
      "Iteration 0, Loss: 0.0005071178311482072, Min w: 0.7196615934371948\n",
      "Iteration 10, Loss: 0.0004922194639220834, Min w: 0.7072163224220276\n",
      "Iteration 20, Loss: 0.0005180179141461849, Min w: 0.7137067317962646\n",
      "Iteration 30, Loss: 0.00040809251368045807, Min w: 0.7466821670532227\n",
      "Iteration 40, Loss: 0.00035480328369885683, Min w: 0.7670465111732483\n",
      "Iteration 50, Loss: 0.0004862482310272753, Min w: 0.7349536418914795\n",
      "Iteration 60, Loss: 0.000512928469106555, Min w: 0.7310360670089722\n",
      "Iteration 70, Loss: 0.0005415206542238593, Min w: 0.7056289911270142\n",
      "Iteration 80, Loss: 0.00039856144576333463, Min w: 0.7773803472518921\n",
      "Iteration 90, Loss: 0.00045795462210662663, Min w: 0.7660524249076843\n",
      "Iteration 100, Loss: 0.0005366955301724374, Min w: 0.7165669798851013\n",
      "Iteration 110, Loss: 0.00047590472968295217, Min w: 0.7469366192817688\n",
      "Iteration 120, Loss: 0.00032223970629274845, Min w: 0.7925871014595032\n",
      "Iteration 130, Loss: 0.000446397258201614, Min w: 0.7450582981109619\n",
      "Iteration 140, Loss: 0.00030333211179822683, Min w: 0.7841157913208008\n",
      "Iteration 150, Loss: 0.00036983765312470496, Min w: 0.7990289926528931\n",
      "Iteration 160, Loss: 0.0003235899785067886, Min w: 0.8153480887413025\n",
      "Iteration 170, Loss: 0.00027770866290666163, Min w: 0.8155104517936707\n",
      "Iteration 180, Loss: 0.00028094014851376414, Min w: 0.8203421831130981\n",
      "Iteration 190, Loss: 0.00029607495525851846, Min w: 0.8191264271736145\n",
      "Iteration 200, Loss: 0.0005381635273806751, Min w: 0.6802718639373779\n",
      "Iteration 210, Loss: 0.0005330989370122552, Min w: 0.7142970561981201\n",
      "Iteration 220, Loss: 0.0006206176476553082, Min w: 0.6432033181190491\n",
      "Iteration 230, Loss: 0.00045193915138952434, Min w: 0.766298770904541\n",
      "Iteration 240, Loss: 0.0005873553454875946, Min w: 0.6565698981285095\n",
      "Iteration 250, Loss: 0.0004017935134470463, Min w: 0.7919331192970276\n",
      "Iteration 260, Loss: 0.0003327852173242718, Min w: 0.8080738186836243\n",
      "Iteration 270, Loss: 0.0005717441090382636, Min w: 0.6681427359580994\n",
      "Iteration 280, Loss: 0.0005393907777033746, Min w: 0.6887407302856445\n",
      "Iteration 290, Loss: 0.0005587809719145298, Min w: 0.691476047039032\n",
      "Iteration 300, Loss: 0.0005086149321869016, Min w: 0.7134544849395752\n",
      "Iteration 310, Loss: 0.00027984759071841836, Min w: 0.8560376167297363\n",
      "Iteration 320, Loss: 0.0002903747954405844, Min w: 0.8448065519332886\n",
      "Iteration 330, Loss: 0.00023433678143192083, Min w: 0.8460326790809631\n",
      "Iteration 340, Loss: 0.0002670948742888868, Min w: 0.8460009098052979\n",
      "Iteration 350, Loss: 0.00021921338338870555, Min w: 0.8748204112052917\n",
      "Iteration 360, Loss: 0.0004253771039657295, Min w: 0.7559540271759033\n",
      "Iteration 370, Loss: 0.0003994106373284012, Min w: 0.7580721378326416\n",
      "Iteration 380, Loss: 0.0003067174111492932, Min w: 0.8327200412750244\n",
      "Iteration 390, Loss: 0.00035162296262569726, Min w: 0.8034271597862244\n",
      "Iteration 400, Loss: 0.00042622178443707526, Min w: 0.7476013898849487\n",
      "Iteration 410, Loss: 0.00029509904561564326, Min w: 0.8357827067375183\n",
      "Iteration 420, Loss: 0.0002202644682256505, Min w: 0.8684154748916626\n",
      "Iteration 430, Loss: 0.00041737520950846374, Min w: 0.7812662124633789\n",
      "Iteration 440, Loss: 0.000330466398736462, Min w: 0.8067426085472107\n",
      "Iteration 450, Loss: 0.00033591900137253106, Min w: 0.7978442311286926\n",
      "Iteration 460, Loss: 0.00020063147530891, Min w: 0.8781304359436035\n",
      "Iteration 470, Loss: 0.00019060232443735003, Min w: 0.8749987483024597\n",
      "Iteration 480, Loss: 0.00018673254817258567, Min w: 0.8812491297721863\n",
      "Iteration 490, Loss: 0.00038990264874882996, Min w: 0.7413045167922974\n",
      "Iteration 500, Loss: 0.00047003733925521374, Min w: 0.6906291246414185\n",
      "Iteration 510, Loss: 0.00033002524287439883, Min w: 0.8057364225387573\n",
      "Iteration 520, Loss: 0.0004266593314241618, Min w: 0.6986585259437561\n",
      "Iteration 530, Loss: 0.0004492963198572397, Min w: 0.687332808971405\n",
      "Iteration 540, Loss: 0.0005592067027464509, Min w: 0.6081044673919678\n",
      "Iteration 550, Loss: 0.00017723962082527578, Min w: 0.8924458622932434\n",
      "Iteration 560, Loss: 0.00023695528216194361, Min w: 0.8756093978881836\n",
      "Iteration 570, Loss: 0.0001846991799538955, Min w: 0.8803153038024902\n",
      "Iteration 580, Loss: 0.00023684419284109026, Min w: 0.8687253594398499\n",
      "Iteration 590, Loss: 0.00047061542863957584, Min w: 0.6919724345207214\n",
      "Iteration 600, Loss: 0.0004232153878547251, Min w: 0.7388857007026672\n",
      "Iteration 610, Loss: 0.00035326919169165194, Min w: 0.7920970320701599\n",
      "Iteration 620, Loss: 0.0002700230397749692, Min w: 0.832491397857666\n",
      "Iteration 630, Loss: 0.00020763237262144685, Min w: 0.8777883052825928\n",
      "Iteration 640, Loss: 0.0004500540380831808, Min w: 0.6818361878395081\n",
      "Iteration 650, Loss: 0.00017653641407378018, Min w: 0.8984297513961792\n",
      "Iteration 660, Loss: 0.00019091057765763253, Min w: 0.8957101702690125\n",
      "Iteration 670, Loss: 0.00015437018009833992, Min w: 0.9034305810928345\n",
      "Iteration 680, Loss: 0.000648279907181859, Min w: 0.5753942131996155\n",
      "Iteration 690, Loss: 0.00016923512157518417, Min w: 0.898176372051239\n",
      "Iteration 700, Loss: 0.0003100598696619272, Min w: 0.8125939965248108\n",
      "Iteration 710, Loss: 0.0005308435647748411, Min w: 0.6730821132659912\n",
      "Iteration 720, Loss: 0.0001975531195057556, Min w: 0.8873441219329834\n",
      "Iteration 730, Loss: 0.00023896497441455722, Min w: 0.8718795776367188\n",
      "Iteration 740, Loss: 0.00016512225556652993, Min w: 0.9031068086624146\n",
      "Iteration 750, Loss: 0.00022818060824647546, Min w: 0.8668407201766968\n",
      "Iteration 760, Loss: 0.0004442910721991211, Min w: 0.718140184879303\n",
      "Iteration 770, Loss: 0.00023086785222403705, Min w: 0.8704604506492615\n",
      "Iteration 780, Loss: 0.0003539962926879525, Min w: 0.7791130542755127\n",
      "Iteration 790, Loss: 0.0003978408349212259, Min w: 0.7320218682289124\n",
      "Iteration 800, Loss: 0.0002844582195393741, Min w: 0.8488180637359619\n",
      "Iteration 810, Loss: 0.00018714416364673525, Min w: 0.9031941890716553\n",
      "Iteration 820, Loss: 0.00038413514266721904, Min w: 0.7490653991699219\n",
      "Iteration 830, Loss: 0.0003383065341040492, Min w: 0.7709488868713379\n",
      "Iteration 840, Loss: 0.00017102033598348498, Min w: 0.9113373160362244\n",
      "Iteration 850, Loss: 0.00021661473147105426, Min w: 0.8690624237060547\n",
      "Iteration 860, Loss: 0.0003486111236270517, Min w: 0.7799734473228455\n",
      "Iteration 870, Loss: 0.00031201113597489893, Min w: 0.7845140695571899\n",
      "Iteration 880, Loss: 0.00035492723691277206, Min w: 0.7817562818527222\n",
      "Iteration 890, Loss: 0.00030330102890729904, Min w: 0.8250169157981873\n",
      "Iteration 900, Loss: 0.00012979474558960646, Min w: 0.9221400022506714\n",
      "Iteration 910, Loss: 0.00037708523450419307, Min w: 0.7395247220993042\n",
      "Iteration 920, Loss: 0.0002609762887004763, Min w: 0.829272449016571\n",
      "Iteration 930, Loss: 0.00024353213666472584, Min w: 0.8407679796218872\n",
      "Iteration 940, Loss: 0.00032795907463878393, Min w: 0.7865760326385498\n",
      "Iteration 950, Loss: 0.0002429796295473352, Min w: 0.8625098466873169\n",
      "Iteration 960, Loss: 0.0002546676550991833, Min w: 0.8435473442077637\n",
      "Iteration 970, Loss: 0.0002516128297429532, Min w: 0.8462311625480652\n",
      "Iteration 980, Loss: 0.0002679191529750824, Min w: 0.8367810249328613\n",
      "Iteration 990, Loss: 0.0002619897713884711, Min w: 0.8360434770584106\n",
      "Iteration 1000, Loss: 0.00026157876709476113, Min w: 0.8479600548744202\n",
      "Iteration 1010, Loss: 0.00030109568615444005, Min w: 0.812865674495697\n",
      "Iteration 1020, Loss: 0.0002796113258227706, Min w: 0.8164937496185303\n",
      "Iteration 1030, Loss: 0.0002644470951054245, Min w: 0.817106306552887\n",
      "Iteration 1040, Loss: 0.0002166907215723768, Min w: 0.8682512044906616\n",
      "Iteration 1050, Loss: 0.00020936058717779815, Min w: 0.8735938668251038\n",
      "Iteration 1060, Loss: 0.00020129485346842557, Min w: 0.8798141479492188\n",
      "Iteration 1070, Loss: 0.00011094121146015823, Min w: 0.9371582865715027\n",
      "Iteration 1080, Loss: 0.0003302732075098902, Min w: 0.7795742154121399\n",
      "Iteration 1090, Loss: 0.00024573711561970413, Min w: 0.8515735864639282\n",
      "Iteration 1100, Loss: 0.0002642192121129483, Min w: 0.8383297920227051\n",
      "Iteration 1110, Loss: 0.00021950264635961503, Min w: 0.8818297982215881\n",
      "Iteration 1120, Loss: 0.00012961021275259554, Min w: 0.9336982369422913\n",
      "Iteration 1130, Loss: 0.00014422334788832814, Min w: 0.9158427119255066\n",
      "Iteration 1140, Loss: 0.00018406263552606106, Min w: 0.8878033757209778\n",
      "Iteration 1150, Loss: 0.0001884256926132366, Min w: 0.8687807321548462\n",
      "Iteration 1160, Loss: 0.0001730574294924736, Min w: 0.8897550106048584\n",
      "Iteration 1170, Loss: 0.00032588947215117514, Min w: 0.7784553170204163\n",
      "Iteration 1180, Loss: 0.00026177987456321716, Min w: 0.844577968120575\n",
      "Iteration 1190, Loss: 0.00014698770246468484, Min w: 0.9224278330802917\n",
      "Iteration 1200, Loss: 0.00015709383296780288, Min w: 0.9154208302497864\n",
      "Iteration 1210, Loss: 0.00016285217134281993, Min w: 0.8982993960380554\n",
      "Iteration 1220, Loss: 0.0002653574338182807, Min w: 0.8198493719100952\n",
      "Iteration 1230, Loss: 0.00024217153259087354, Min w: 0.8537453413009644\n",
      "Iteration 1240, Loss: 0.0002455887442920357, Min w: 0.8356181979179382\n",
      "Iteration 0, Loss: 0.00027187279192730784, Min w: 0.8302501440048218\n",
      "Iteration 10, Loss: 0.00040192672167904675, Min w: 0.7297724485397339\n",
      "Iteration 20, Loss: 0.00010445539373904467, Min w: 0.9428492784500122\n",
      "Iteration 30, Loss: 0.00027632078854367137, Min w: 0.8047122955322266\n",
      "Iteration 40, Loss: 0.00029047028510831296, Min w: 0.7885499000549316\n",
      "Iteration 50, Loss: 0.0002308940893271938, Min w: 0.8591076135635376\n",
      "Iteration 60, Loss: 8.776254253461957e-05, Min w: 0.9481986165046692\n",
      "Iteration 70, Loss: 0.00024656622554175556, Min w: 0.8184682130813599\n",
      "Iteration 80, Loss: 0.0003526117361616343, Min w: 0.7580711841583252\n",
      "Iteration 90, Loss: 0.00032952323090285063, Min w: 0.7692237496376038\n",
      "Iteration 100, Loss: 0.0003645989636424929, Min w: 0.7258251905441284\n",
      "Iteration 110, Loss: 0.0003912793181370944, Min w: 0.7184289693832397\n",
      "Iteration 120, Loss: 0.0001930625003296882, Min w: 0.8790820240974426\n",
      "Iteration 130, Loss: 0.00033405551221221685, Min w: 0.764454185962677\n",
      "Iteration 140, Loss: 0.00032225606264546514, Min w: 0.7620760202407837\n",
      "Iteration 150, Loss: 0.0002359752543270588, Min w: 0.8193835020065308\n",
      "Iteration 160, Loss: 0.00020200475410092622, Min w: 0.8843083381652832\n",
      "Iteration 170, Loss: 0.00021126848878338933, Min w: 0.8537557721138\n",
      "Iteration 180, Loss: 0.00013737181143369526, Min w: 0.9181245565414429\n",
      "Iteration 190, Loss: 0.00019793014507740736, Min w: 0.8617868423461914\n",
      "Iteration 200, Loss: 0.00011380732030374929, Min w: 0.9270192384719849\n",
      "Iteration 210, Loss: 0.00014841450320091099, Min w: 0.9037075042724609\n",
      "Iteration 220, Loss: 7.703033770667389e-05, Min w: 0.9588143825531006\n",
      "Iteration 230, Loss: 0.00029102753615006804, Min w: 0.7935768961906433\n",
      "Iteration 240, Loss: 0.00026050081942230463, Min w: 0.8239136338233948\n",
      "Iteration 250, Loss: 0.0002801936643663794, Min w: 0.7674626111984253\n",
      "Iteration 260, Loss: 0.00016496448370162398, Min w: 0.8936753869056702\n",
      "Iteration 270, Loss: 0.00017495047359261662, Min w: 0.8707793354988098\n",
      "Iteration 280, Loss: 0.0002173675602534786, Min w: 0.8475208282470703\n",
      "Iteration 290, Loss: 0.00020180316641926765, Min w: 0.8511154055595398\n",
      "Iteration 300, Loss: 0.0002721735218074173, Min w: 0.7963898181915283\n",
      "Iteration 310, Loss: 7.608432497363538e-05, Min w: 0.9562240242958069\n",
      "Iteration 320, Loss: 6.142559868749231e-05, Min w: 0.966590940952301\n",
      "Iteration 330, Loss: 6.491733074653894e-05, Min w: 0.9659889936447144\n",
      "Iteration 340, Loss: 0.00010512000153539702, Min w: 0.934116542339325\n",
      "Iteration 350, Loss: 0.0001585269783390686, Min w: 0.8922330737113953\n",
      "Iteration 360, Loss: 0.0003412736114114523, Min w: 0.7459562420845032\n",
      "Iteration 370, Loss: 0.0002922055427916348, Min w: 0.7803077101707458\n",
      "Iteration 380, Loss: 0.00021857696992810816, Min w: 0.8333528637886047\n",
      "Iteration 390, Loss: 0.0002048991882475093, Min w: 0.8500280380249023\n",
      "Iteration 400, Loss: 0.00017039786325767636, Min w: 0.8696910738945007\n",
      "Iteration 410, Loss: 9.741110261529684e-05, Min w: 0.9306421279907227\n",
      "Iteration 420, Loss: 0.0002456257934682071, Min w: 0.8167336583137512\n",
      "Iteration 430, Loss: 0.00028763842419721186, Min w: 0.8054792284965515\n",
      "Iteration 440, Loss: 0.00020276913710404187, Min w: 0.8662028908729553\n",
      "Iteration 450, Loss: 5.3982133977115154e-05, Min w: 0.9699365496635437\n",
      "Iteration 460, Loss: 0.00013424344069790095, Min w: 0.9097561240196228\n",
      "Iteration 470, Loss: 0.0005825008847750723, Min w: 0.5698269009590149\n",
      "Iteration 480, Loss: 5.424666960607283e-05, Min w: 0.9721798896789551\n",
      "Iteration 490, Loss: 7.10239983163774e-05, Min w: 0.9599187970161438\n",
      "Iteration 500, Loss: 0.0003074086853303015, Min w: 0.7338660955429077\n",
      "Iteration 510, Loss: 0.0002895311336033046, Min w: 0.7612612247467041\n",
      "Iteration 520, Loss: 0.00013956462498754263, Min w: 0.8910565376281738\n",
      "Iteration 530, Loss: 0.0002829248842317611, Min w: 0.7677348256111145\n",
      "Iteration 540, Loss: 0.0007078796625137329, Min w: 0.4571208655834198\n",
      "Iteration 550, Loss: 0.0003147117677144706, Min w: 0.7153257727622986\n",
      "Iteration 560, Loss: 0.0001799929013941437, Min w: 0.8634024262428284\n",
      "Iteration 570, Loss: 0.00047747386270202696, Min w: 0.6708021759986877\n",
      "Iteration 580, Loss: 6.352556374622509e-05, Min w: 0.962918221950531\n",
      "Iteration 590, Loss: 0.00032012027804739773, Min w: 0.7422055006027222\n",
      "Iteration 600, Loss: 0.00016979080101009458, Min w: 0.8661532402038574\n",
      "Iteration 610, Loss: 0.00010511182335903868, Min w: 0.9191198945045471\n",
      "Iteration 620, Loss: 8.420002995990217e-05, Min w: 0.9483451843261719\n",
      "Iteration 630, Loss: 7.148604345275089e-05, Min w: 0.9518122673034668\n",
      "Iteration 640, Loss: 0.00010595189087325707, Min w: 0.922511100769043\n",
      "Iteration 650, Loss: 0.00030252712895162404, Min w: 0.7646026611328125\n",
      "Iteration 660, Loss: 0.0002629358205012977, Min w: 0.7915443181991577\n",
      "Iteration 670, Loss: 0.00013263807340990752, Min w: 0.8908563852310181\n",
      "Iteration 680, Loss: 6.715711788274348e-05, Min w: 0.9578410983085632\n",
      "Iteration 690, Loss: 4.53837747045327e-05, Min w: 0.975904643535614\n",
      "Iteration 700, Loss: 0.00028581407968886197, Min w: 0.7774804830551147\n",
      "Iteration 710, Loss: 0.00048800031072460115, Min w: 0.6707639098167419\n",
      "Iteration 720, Loss: 8.32819496281445e-05, Min w: 0.9497513175010681\n",
      "Iteration 730, Loss: 8.736187737667933e-05, Min w: 0.9328432083129883\n",
      "Iteration 740, Loss: 0.00014067845768295228, Min w: 0.8815442323684692\n",
      "Iteration 750, Loss: 0.00013429515820462257, Min w: 0.8869685530662537\n",
      "Iteration 760, Loss: 0.00022250093752518296, Min w: 0.8356684446334839\n",
      "Iteration 770, Loss: 0.00029175824602134526, Min w: 0.7801606059074402\n",
      "Iteration 780, Loss: 0.00020744476933032274, Min w: 0.8315900564193726\n",
      "Iteration 790, Loss: 0.00015719365910626948, Min w: 0.8770725131034851\n",
      "Iteration 800, Loss: 0.00016503948427271098, Min w: 0.886696457862854\n",
      "Iteration 810, Loss: 0.00017002230742946267, Min w: 0.8594528436660767\n",
      "Iteration 820, Loss: 0.000134775647893548, Min w: 0.8934267163276672\n",
      "Iteration 830, Loss: 0.00015407121099997312, Min w: 0.8666614294052124\n",
      "Iteration 840, Loss: 5.476305159390904e-05, Min w: 0.9642502665519714\n",
      "Iteration 850, Loss: 0.00015687740233261138, Min w: 0.8781992793083191\n",
      "Iteration 860, Loss: 0.00010662157728802413, Min w: 0.9097062349319458\n",
      "Iteration 870, Loss: 0.00010450636182213202, Min w: 0.925743043422699\n",
      "Iteration 880, Loss: 0.00010845815995708108, Min w: 0.9192491769790649\n",
      "Iteration 890, Loss: 9.429567580809817e-05, Min w: 0.9308770895004272\n",
      "Iteration 900, Loss: 0.00024363037664443254, Min w: 0.8068295121192932\n",
      "Iteration 910, Loss: 0.0001662497379584238, Min w: 0.8841562271118164\n",
      "Iteration 920, Loss: 4.228376201353967e-05, Min w: 0.9771287441253662\n",
      "Iteration 930, Loss: 0.0001855207810876891, Min w: 0.8466143608093262\n",
      "Iteration 940, Loss: 6.368540925905108e-05, Min w: 0.9500333070755005\n",
      "Iteration 950, Loss: 0.0001606897421879694, Min w: 0.8904981017112732\n",
      "Iteration 960, Loss: 0.0001966029085451737, Min w: 0.8431745171546936\n",
      "Iteration 970, Loss: 0.00020318498718552291, Min w: 0.8200713992118835\n",
      "Iteration 980, Loss: 0.00015807953604962677, Min w: 0.9074661135673523\n",
      "Iteration 990, Loss: 0.00022909391555003822, Min w: 0.8070464134216309\n",
      "Iteration 1000, Loss: 0.00019412698748055845, Min w: 0.8404031991958618\n",
      "Iteration 1010, Loss: 6.463828322011977e-05, Min w: 0.9610478281974792\n",
      "Iteration 1020, Loss: 0.0001283434685319662, Min w: 0.9050936698913574\n",
      "Iteration 1030, Loss: 0.00012538682494778186, Min w: 0.8914979696273804\n",
      "Iteration 1040, Loss: 6.141377525636926e-05, Min w: 0.9521836042404175\n",
      "Iteration 1050, Loss: 0.00014223648759070784, Min w: 0.9208279252052307\n",
      "Iteration 1060, Loss: 0.00019295417587272823, Min w: 0.8473734259605408\n",
      "Iteration 1070, Loss: 0.00014891581668052822, Min w: 0.861899197101593\n",
      "Iteration 1080, Loss: 0.00011885963613167405, Min w: 0.9144029021263123\n",
      "Iteration 1090, Loss: 0.00014766694221179932, Min w: 0.8830195665359497\n",
      "Iteration 1100, Loss: 0.00021496650879271328, Min w: 0.8347676396369934\n",
      "Iteration 1110, Loss: 0.0002286076924065128, Min w: 0.8083200454711914\n",
      "Iteration 1120, Loss: 0.00022911856649443507, Min w: 0.8271843194961548\n",
      "Iteration 1130, Loss: 0.00017857753846328706, Min w: 0.8725369572639465\n",
      "Iteration 1140, Loss: 0.0001983828260563314, Min w: 0.8376645445823669\n",
      "Iteration 1150, Loss: 8.524874283466488e-05, Min w: 0.9320440888404846\n",
      "Iteration 1160, Loss: 0.00016668027092237025, Min w: 0.8725740909576416\n",
      "Iteration 1170, Loss: 0.0003091761900577694, Min w: 0.7662382125854492\n",
      "Iteration 1180, Loss: 0.00023501245595980436, Min w: 0.8127190470695496\n",
      "Iteration 1190, Loss: 0.0001903949596453458, Min w: 0.8320866823196411\n",
      "Iteration 1200, Loss: 8.603628521086648e-05, Min w: 0.92979496717453\n",
      "Iteration 1210, Loss: 9.564134961692616e-05, Min w: 0.9382054805755615\n",
      "Iteration 1220, Loss: 2.969957495224662e-05, Min w: 0.9801163077354431\n",
      "Iteration 1230, Loss: 0.00014471715257968754, Min w: 0.8892533183097839\n",
      "Iteration 1240, Loss: 0.0002529734338168055, Min w: 0.7987632155418396\n",
      "Iteration 0, Loss: 5.8356083172839135e-05, Min w: 0.9550921320915222\n",
      "Iteration 10, Loss: 0.000125439022667706, Min w: 0.8986625075340271\n",
      "Iteration 20, Loss: 0.00016632994811516255, Min w: 0.8545305132865906\n",
      "Iteration 30, Loss: 0.00016463210340589285, Min w: 0.8580060601234436\n",
      "Iteration 40, Loss: 0.00019098803750239313, Min w: 0.8500729203224182\n",
      "Iteration 50, Loss: 0.00016019371105358005, Min w: 0.8782846927642822\n",
      "Iteration 60, Loss: 0.00024000056146178395, Min w: 0.8148609399795532\n",
      "Iteration 70, Loss: 0.0002623952750582248, Min w: 0.7794609665870667\n",
      "Iteration 80, Loss: 0.00011303351493552327, Min w: 0.9009195566177368\n",
      "Iteration 90, Loss: 2.4879140255507082e-05, Min w: 0.9834930896759033\n",
      "Iteration 100, Loss: 0.00023803023213986307, Min w: 0.8158850073814392\n",
      "Iteration 110, Loss: 8.595090184826404e-05, Min w: 0.9370126128196716\n",
      "Iteration 120, Loss: 0.000140641481266357, Min w: 0.8916165828704834\n",
      "Iteration 130, Loss: 0.0002027947484748438, Min w: 0.8215318918228149\n",
      "Iteration 140, Loss: 8.235472341766581e-05, Min w: 0.9343858361244202\n",
      "Iteration 150, Loss: 0.00011986038589384407, Min w: 0.9122109413146973\n",
      "Iteration 160, Loss: 0.00011781623470596969, Min w: 0.9177690744400024\n",
      "Iteration 170, Loss: 0.00025855316198430955, Min w: 0.819380521774292\n",
      "Iteration 180, Loss: 0.0001845141960075125, Min w: 0.8675829768180847\n",
      "Iteration 190, Loss: 0.00016473393770866096, Min w: 0.8667694330215454\n",
      "Iteration 200, Loss: 0.00018425966845825315, Min w: 0.8604141473770142\n",
      "Iteration 210, Loss: 0.00014781214122194797, Min w: 0.8779253363609314\n",
      "Iteration 220, Loss: 0.00015334457566495985, Min w: 0.8741664290428162\n",
      "Iteration 230, Loss: 8.667982183396816e-05, Min w: 0.932716965675354\n",
      "Iteration 240, Loss: 3.9524020394310355e-05, Min w: 0.9707345366477966\n",
      "Iteration 250, Loss: 0.00017632429080549628, Min w: 0.8887918591499329\n",
      "Iteration 260, Loss: 0.00022930411796551198, Min w: 0.8336469531059265\n",
      "Iteration 270, Loss: 0.00013101538934279233, Min w: 0.9072405099868774\n",
      "Iteration 280, Loss: 2.6077641450683586e-05, Min w: 0.9823582172393799\n",
      "Iteration 290, Loss: 0.00025364558678120375, Min w: 0.8515426516532898\n",
      "Iteration 300, Loss: 0.00029031740268692374, Min w: 0.789909303188324\n",
      "Iteration 310, Loss: 0.00031170458532869816, Min w: 0.8163754343986511\n",
      "Iteration 320, Loss: 0.00019388235523365438, Min w: 0.8455257415771484\n",
      "Iteration 330, Loss: 5.356742622097954e-05, Min w: 0.9678941369056702\n",
      "Iteration 340, Loss: 4.5347638661041856e-05, Min w: 0.9619143009185791\n",
      "Iteration 350, Loss: 0.0006242270465008914, Min w: 0.5123485922813416\n",
      "Iteration 360, Loss: 0.0007178491214290261, Min w: 0.48714613914489746\n",
      "Iteration 370, Loss: 6.059551742509939e-05, Min w: 0.9548878073692322\n",
      "Iteration 380, Loss: 7.152705802582204e-05, Min w: 0.9426365494728088\n",
      "Iteration 390, Loss: 4.081165388925001e-05, Min w: 0.9672539234161377\n",
      "Iteration 400, Loss: 0.00017877940263133496, Min w: 0.860673189163208\n",
      "Iteration 410, Loss: 0.000276255450444296, Min w: 0.8097374439239502\n",
      "Iteration 420, Loss: 0.00010756886331364512, Min w: 0.8980237245559692\n",
      "Iteration 430, Loss: 0.0005254105781204998, Min w: 0.507702648639679\n",
      "Iteration 440, Loss: 0.00028004407067783177, Min w: 0.8172348141670227\n",
      "Iteration 450, Loss: 2.7981197490589693e-05, Min w: 0.9792722463607788\n",
      "Iteration 460, Loss: 0.00010334834951208904, Min w: 0.9079606533050537\n",
      "Iteration 470, Loss: 3.945192656829022e-05, Min w: 0.9683818221092224\n",
      "Iteration 480, Loss: 6.860506982775405e-05, Min w: 0.9455367922782898\n",
      "Iteration 490, Loss: 7.094537431839854e-05, Min w: 0.9495933651924133\n",
      "Iteration 500, Loss: 2.405172745056916e-05, Min w: 0.9827744364738464\n",
      "Iteration 510, Loss: 6.621093780267984e-05, Min w: 0.9424856901168823\n",
      "Iteration 520, Loss: 4.82994073536247e-05, Min w: 0.9676996469497681\n",
      "Iteration 530, Loss: 0.00019556991173885763, Min w: 0.8686951398849487\n",
      "Iteration 540, Loss: 4.5672237320104614e-05, Min w: 0.9702854156494141\n",
      "Iteration 550, Loss: 0.00012102776963729411, Min w: 0.9053872227668762\n",
      "Iteration 560, Loss: 2.7330146622261964e-05, Min w: 0.9798954725265503\n",
      "Iteration 570, Loss: 9.340391989098862e-05, Min w: 0.927959144115448\n",
      "Iteration 580, Loss: 9.581129415892065e-05, Min w: 0.9197104573249817\n",
      "Iteration 590, Loss: 2.3678525394643657e-05, Min w: 0.9834671020507812\n",
      "Iteration 600, Loss: 0.00021918164566159248, Min w: 0.8227826356887817\n",
      "Iteration 610, Loss: 0.00017446617130190134, Min w: 0.8617849349975586\n",
      "Iteration 620, Loss: 2.716409471759107e-05, Min w: 0.9807623028755188\n",
      "Iteration 630, Loss: 0.0003002060402650386, Min w: 0.7859013080596924\n",
      "Iteration 640, Loss: 0.00024519843282178044, Min w: 0.8039526343345642\n",
      "Iteration 650, Loss: 0.00010353729157941416, Min w: 0.9125338196754456\n",
      "Iteration 660, Loss: 3.482466854620725e-05, Min w: 0.977482795715332\n",
      "Iteration 670, Loss: 6.523135380120948e-05, Min w: 0.9451773762702942\n",
      "Iteration 680, Loss: 0.00018727703718468547, Min w: 0.8630554676055908\n",
      "Iteration 690, Loss: 0.00024308577121701092, Min w: 0.7803317308425903\n",
      "Iteration 700, Loss: 0.00023046822752803564, Min w: 0.8416309952735901\n",
      "Iteration 710, Loss: 0.0002100365236401558, Min w: 0.8317738175392151\n",
      "Iteration 720, Loss: 0.0001579604431753978, Min w: 0.8664277791976929\n",
      "Iteration 730, Loss: 5.5037555284798145e-05, Min w: 0.9576084613800049\n",
      "Iteration 740, Loss: 0.00013636551739182323, Min w: 0.8843615055084229\n",
      "Iteration 750, Loss: 0.0001907318946905434, Min w: 0.8468912839889526\n",
      "Iteration 760, Loss: 6.776944792363793e-05, Min w: 0.9568676948547363\n",
      "Iteration 770, Loss: 9.109688107855618e-05, Min w: 0.9251351356506348\n",
      "Iteration 780, Loss: 3.480279337964021e-05, Min w: 0.9743195176124573\n",
      "Iteration 790, Loss: 7.926864782348275e-05, Min w: 0.9391841292381287\n",
      "Iteration 800, Loss: 0.00012953074474353343, Min w: 0.908668577671051\n",
      "Iteration 810, Loss: 4.821080437977798e-05, Min w: 0.9607341289520264\n",
      "Iteration 820, Loss: 0.0001933955354616046, Min w: 0.8382383584976196\n",
      "Iteration 830, Loss: 7.754482794553041e-05, Min w: 0.9431763291358948\n",
      "Iteration 840, Loss: 3.628211925388314e-05, Min w: 0.9714176058769226\n",
      "Iteration 850, Loss: 0.00011822867963928729, Min w: 0.8972751498222351\n",
      "Iteration 860, Loss: 4.318432183936238e-05, Min w: 0.9773778915405273\n",
      "Iteration 870, Loss: 0.00014928134623914957, Min w: 0.8730726838111877\n",
      "Iteration 880, Loss: 6.01871834078338e-05, Min w: 0.9579591155052185\n",
      "Iteration 890, Loss: 2.023295201070141e-05, Min w: 0.9867863059043884\n",
      "Iteration 900, Loss: 7.505271059926599e-05, Min w: 0.9405437707901001\n",
      "Iteration 910, Loss: 0.00011094730871263891, Min w: 0.9175342321395874\n",
      "Iteration 920, Loss: 0.00018430507043376565, Min w: 0.8490848541259766\n",
      "Iteration 930, Loss: 0.00012845343735534698, Min w: 0.9117664694786072\n",
      "Iteration 940, Loss: 0.00010787676728796214, Min w: 0.9108627438545227\n",
      "Iteration 950, Loss: 0.0001849323307396844, Min w: 0.8397412896156311\n",
      "Iteration 960, Loss: 0.0001946073753060773, Min w: 0.8496262431144714\n",
      "Iteration 970, Loss: 8.777553011896089e-05, Min w: 0.9251798987388611\n",
      "Iteration 980, Loss: 0.00015799838001839817, Min w: 0.8879725337028503\n",
      "Iteration 990, Loss: 0.00027168268570676446, Min w: 0.7894680500030518\n",
      "Iteration 1000, Loss: 0.0001522220263723284, Min w: 0.88787841796875\n",
      "Iteration 1010, Loss: 0.00024537084391340613, Min w: 0.7999969720840454\n",
      "Iteration 1020, Loss: 0.00013744598254561424, Min w: 0.883363664150238\n",
      "Iteration 1030, Loss: 5.6135682825697586e-05, Min w: 0.9657474160194397\n",
      "Iteration 1040, Loss: 0.0001237604155903682, Min w: 0.9052348136901855\n",
      "Iteration 1050, Loss: 0.0001634023938095197, Min w: 0.8502085208892822\n",
      "Iteration 1060, Loss: 0.00010568532889010385, Min w: 0.9218948483467102\n",
      "Iteration 1070, Loss: 0.0001190362818306312, Min w: 0.9230203628540039\n",
      "Iteration 1080, Loss: 4.6738390665268525e-05, Min w: 0.9619472622871399\n",
      "Iteration 1090, Loss: 6.288647273322567e-05, Min w: 0.9450897574424744\n",
      "Iteration 1100, Loss: 0.0001515939657110721, Min w: 0.8706596493721008\n",
      "Iteration 1110, Loss: 7.592539623146877e-05, Min w: 0.9393719434738159\n",
      "Iteration 1120, Loss: 0.00014969482435844839, Min w: 0.8742163181304932\n",
      "Iteration 1130, Loss: 0.00014612730592489243, Min w: 0.8640229105949402\n",
      "Iteration 1140, Loss: 0.00016068296099547297, Min w: 0.8854671716690063\n",
      "Iteration 1150, Loss: 0.00015213260485325009, Min w: 0.8866536021232605\n",
      "Iteration 1160, Loss: 0.00011093570356024429, Min w: 0.9061360955238342\n",
      "Iteration 1170, Loss: 0.00012181840429548174, Min w: 0.8927499055862427\n",
      "Iteration 1180, Loss: 8.692558185430244e-05, Min w: 0.9307372570037842\n",
      "Iteration 1190, Loss: 9.544308704789728e-05, Min w: 0.9317572116851807\n",
      "Iteration 1200, Loss: 0.00013639593089465052, Min w: 0.9006883502006531\n",
      "Iteration 1210, Loss: 0.00015406633610837162, Min w: 0.8713414669036865\n",
      "Iteration 1220, Loss: 0.00014629789802711457, Min w: 0.8855422139167786\n",
      "Iteration 1230, Loss: 8.468068699585274e-05, Min w: 0.9354466795921326\n",
      "Iteration 1240, Loss: 4.396713848109357e-05, Min w: 0.9660466909408569\n",
      "Iteration 0, Loss: 0.00025248152087442577, Min w: 0.7836354374885559\n",
      "Iteration 10, Loss: 0.00016846555809024721, Min w: 0.8631165623664856\n",
      "Iteration 20, Loss: 3.6752848245669156e-05, Min w: 0.9693689942359924\n",
      "Iteration 30, Loss: 0.00012225481623318046, Min w: 0.9001143574714661\n",
      "Iteration 40, Loss: 6.713796756230295e-05, Min w: 0.949840784072876\n",
      "Iteration 50, Loss: 0.00017133897927124053, Min w: 0.8746514320373535\n",
      "Iteration 60, Loss: 4.034891753690317e-05, Min w: 0.9705594778060913\n",
      "Iteration 70, Loss: 0.00012051449448335916, Min w: 0.9095499515533447\n",
      "Iteration 80, Loss: 4.35640977229923e-05, Min w: 0.9637091159820557\n",
      "Iteration 90, Loss: 2.7593889171839692e-05, Min w: 0.9788421988487244\n",
      "Iteration 100, Loss: 0.00010243233555229381, Min w: 0.9196208119392395\n",
      "Iteration 110, Loss: 0.00024458012194372714, Min w: 0.8003016710281372\n",
      "Iteration 120, Loss: 1.924773823702708e-05, Min w: 0.9869094491004944\n",
      "Iteration 130, Loss: 0.00014455837663263083, Min w: 0.8945233225822449\n",
      "Iteration 140, Loss: 0.00022808559879194945, Min w: 0.8527066707611084\n",
      "Iteration 150, Loss: 0.0001421396154910326, Min w: 0.8809435963630676\n",
      "Iteration 160, Loss: 8.641042222734541e-05, Min w: 0.9326743483543396\n",
      "Iteration 170, Loss: 0.00016114304889924824, Min w: 0.8648576140403748\n",
      "Iteration 180, Loss: 5.7978410040959716e-05, Min w: 0.94802325963974\n",
      "Iteration 190, Loss: 0.00016731313371565193, Min w: 0.8716039061546326\n",
      "Iteration 200, Loss: 0.00017696224676910788, Min w: 0.8966068625450134\n",
      "Iteration 210, Loss: 0.00019802515453193337, Min w: 0.8705528974533081\n",
      "Iteration 220, Loss: 0.00013050739653408527, Min w: 0.8884192705154419\n",
      "Iteration 230, Loss: 7.863188511691988e-05, Min w: 0.9335120916366577\n",
      "Iteration 240, Loss: 0.0002026277215918526, Min w: 0.8436360955238342\n",
      "Iteration 250, Loss: 8.749301196075976e-05, Min w: 0.9294323325157166\n",
      "Iteration 260, Loss: 8.20473360363394e-05, Min w: 0.937664270401001\n",
      "Iteration 270, Loss: 9.506309288553894e-05, Min w: 0.9372994899749756\n",
      "Iteration 280, Loss: 4.950840229867026e-05, Min w: 0.9657520651817322\n",
      "Iteration 290, Loss: 0.00024116643180605024, Min w: 0.7945215106010437\n",
      "Iteration 300, Loss: 0.0001187735833809711, Min w: 0.897867739200592\n",
      "Iteration 310, Loss: 2.1774249034933746e-05, Min w: 0.984776496887207\n",
      "Iteration 320, Loss: 0.00028875365387648344, Min w: 0.8006896376609802\n",
      "Iteration 330, Loss: 0.00025896221632137895, Min w: 0.781732976436615\n",
      "Iteration 340, Loss: 0.0001604778371984139, Min w: 0.8654770851135254\n",
      "Iteration 350, Loss: 0.00019166251877322793, Min w: 0.851532518863678\n",
      "Iteration 360, Loss: 0.00019104070088360459, Min w: 0.864425539970398\n",
      "Iteration 370, Loss: 0.00021639732585754246, Min w: 0.8315920829772949\n",
      "Iteration 380, Loss: 1.7630427464609966e-05, Min w: 0.9879671931266785\n",
      "Iteration 390, Loss: 0.000248881260631606, Min w: 0.7919677495956421\n",
      "Iteration 400, Loss: 0.00019557449559215456, Min w: 0.8574153780937195\n",
      "Iteration 410, Loss: 5.276218507788144e-05, Min w: 0.9617696404457092\n",
      "Iteration 420, Loss: 0.00013221779954619706, Min w: 0.9084922075271606\n",
      "Iteration 430, Loss: 9.118521847994998e-05, Min w: 0.9239575862884521\n",
      "Iteration 440, Loss: 3.255582487327047e-05, Min w: 0.9726373553276062\n",
      "Iteration 450, Loss: 0.0001369363017147407, Min w: 0.8925679326057434\n",
      "Iteration 460, Loss: 0.00022992439335212111, Min w: 0.8331707715988159\n",
      "Iteration 470, Loss: 0.0002283488865941763, Min w: 0.8422933220863342\n",
      "Iteration 480, Loss: 0.0001508119166828692, Min w: 0.8923685550689697\n",
      "Iteration 490, Loss: 0.00011929633183171973, Min w: 0.9107250571250916\n",
      "Iteration 500, Loss: 0.00010329522774554789, Min w: 0.9153614640235901\n",
      "Iteration 510, Loss: 0.00016775022959336638, Min w: 0.8616734743118286\n",
      "Iteration 520, Loss: 0.00013034070434514433, Min w: 0.8900824785232544\n",
      "Iteration 530, Loss: 4.9299487727694213e-05, Min w: 0.9639972448348999\n",
      "Iteration 540, Loss: 0.00016810253146104515, Min w: 0.867983341217041\n",
      "Iteration 550, Loss: 0.00017804818344302475, Min w: 0.8585646152496338\n",
      "Iteration 560, Loss: 0.0001633537613088265, Min w: 0.8739410638809204\n",
      "Iteration 570, Loss: 0.00014731301052961498, Min w: 0.8930559158325195\n",
      "Iteration 580, Loss: 3.02676999126561e-05, Min w: 0.981415867805481\n",
      "Iteration 590, Loss: 0.00022977286425884813, Min w: 0.830700695514679\n",
      "Iteration 600, Loss: 0.0002491040504537523, Min w: 0.7946746945381165\n",
      "Iteration 610, Loss: 0.00013962772209197283, Min w: 0.8868715167045593\n",
      "Iteration 620, Loss: 0.000232222635531798, Min w: 0.8142563104629517\n",
      "Iteration 630, Loss: 0.00011429246660554782, Min w: 0.9103447198867798\n",
      "Iteration 640, Loss: 0.00012663194502238184, Min w: 0.9086766839027405\n",
      "Iteration 650, Loss: 0.0001270289212698117, Min w: 0.9043399095535278\n",
      "Iteration 660, Loss: 0.0001350013044429943, Min w: 0.8918790817260742\n",
      "Iteration 670, Loss: 2.451424006721936e-05, Min w: 0.9804933071136475\n",
      "Iteration 680, Loss: 8.430615707766265e-05, Min w: 0.9281075596809387\n",
      "Iteration 690, Loss: 2.0297135051805526e-05, Min w: 0.9862832427024841\n",
      "Iteration 700, Loss: 6.346353620756418e-05, Min w: 0.9420384168624878\n",
      "Iteration 710, Loss: 9.787435556063429e-05, Min w: 0.9178412556648254\n",
      "Iteration 720, Loss: 9.067611972568557e-05, Min w: 0.9254308342933655\n",
      "Iteration 730, Loss: 0.00013740520807914436, Min w: 0.8986555933952332\n",
      "Iteration 740, Loss: 0.00018463605374563485, Min w: 0.8564155101776123\n",
      "Iteration 750, Loss: 0.0001253079535672441, Min w: 0.8866503238677979\n",
      "Iteration 760, Loss: 0.00011666692444123328, Min w: 0.9284929633140564\n",
      "Iteration 770, Loss: 4.369593079900369e-05, Min w: 0.9634371995925903\n",
      "Iteration 780, Loss: 5.94282646488864e-05, Min w: 0.9621961116790771\n",
      "Iteration 790, Loss: 0.00018215819727629423, Min w: 0.8609854578971863\n",
      "Iteration 800, Loss: 7.72042985772714e-05, Min w: 0.9448263049125671\n",
      "Iteration 810, Loss: 4.3008782085962594e-05, Min w: 0.9642673134803772\n",
      "Iteration 820, Loss: 0.0002439789241179824, Min w: 0.798521101474762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  38%|███▊      | 9/24 [13:53<23:22, 93.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 830, Loss: 2.460457108099945e-05, Min w: 0.98591148853302\n",
      "Early break at iteration 831 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 5832, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.006286154872085241, 'L2_avg': 0.007528699463495971, 'End_point_L1_avg': 0.006930347969925992, 'End_point_L2_avg': 0.006930449126698773}\n",
      "Iteration 0, Loss: 0.004806247074157, Min w: 0.0\n",
      "Iteration 10, Loss: 0.002670090878382325, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0022841012105345726, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002661567647010088, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0021152645349502563, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0020188563503324986, Min w: 0.0\n",
      "Iteration 60, Loss: 0.00253834156319499, Min w: 6.266748188085702e-13\n",
      "Iteration 70, Loss: 0.0024873234797269106, Min w: 6.239517468438037e-21\n",
      "Iteration 80, Loss: 0.0024270520079880953, Min w: 1.2640410886888276e-06\n",
      "Iteration 90, Loss: 0.0022007713560014963, Min w: 9.866542487311037e-42\n",
      "Iteration 100, Loss: 0.002094374969601631, Min w: 6.815658551015608e-17\n",
      "Iteration 110, Loss: 0.0023681495804339647, Min w: 1.587662623592223e-08\n",
      "Iteration 120, Loss: 0.0023069470189511776, Min w: 6.193892293953917e-28\n",
      "Iteration 130, Loss: 0.002009686781093478, Min w: 2.599559593363665e-06\n",
      "Iteration 140, Loss: 0.0020391843281686306, Min w: 7.2901291437880716e-40\n",
      "Iteration 150, Loss: 0.002139309886842966, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002216034336015582, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0021484214812517166, Min w: 2.002190947758553e-12\n",
      "Iteration 180, Loss: 0.002066821325570345, Min w: 1.446424733828058e-30\n",
      "Iteration 190, Loss: 0.002055518329143524, Min w: 5.465064010866787e-44\n",
      "Iteration 200, Loss: 0.0020119177643209696, Min w: 4.1394356636155096e-42\n",
      "Iteration 210, Loss: 0.0021581691689789295, Min w: 0.007682815659791231\n",
      "Iteration 220, Loss: 0.0020246566273272038, Min w: 9.990683974558934e-11\n",
      "Iteration 230, Loss: 0.0020554037764668465, Min w: 2.3498100537038394e-25\n",
      "Iteration 240, Loss: 0.0018736333586275578, Min w: 0.03282219544053078\n",
      "Iteration 250, Loss: 0.0017589008202776313, Min w: 0.00535567756742239\n",
      "Iteration 260, Loss: 0.0016839972231537104, Min w: 0.042112015187740326\n",
      "Iteration 270, Loss: 0.0017056589713320136, Min w: 0.08802001923322678\n",
      "Iteration 280, Loss: 0.0018323492258787155, Min w: 0.006648130249232054\n",
      "Iteration 290, Loss: 0.001997393788769841, Min w: 0.008690831251442432\n",
      "Iteration 300, Loss: 0.0013282278086990118, Min w: 0.2411072701215744\n",
      "Iteration 310, Loss: 0.0017346636159345508, Min w: 0.0911329984664917\n",
      "Iteration 320, Loss: 0.0014248930383473635, Min w: 0.14713923633098602\n",
      "Iteration 330, Loss: 0.001974864164367318, Min w: 1.2447399777570922e-09\n",
      "Iteration 340, Loss: 0.0016602871473878622, Min w: 0.001868113991804421\n",
      "Iteration 350, Loss: 0.0013417414156720042, Min w: 0.046606581658124924\n",
      "Iteration 360, Loss: 0.001551876775920391, Min w: 0.15210388600826263\n",
      "Iteration 370, Loss: 0.0013176532229408622, Min w: 0.28984805941581726\n",
      "Iteration 380, Loss: 0.0009377641836181283, Min w: 0.41832080483436584\n",
      "Iteration 390, Loss: 0.0011884750565513968, Min w: 0.3063565492630005\n",
      "Iteration 400, Loss: 0.0010969566646963358, Min w: 0.4513395428657532\n",
      "Iteration 410, Loss: 0.0010175291681662202, Min w: 0.4083128571510315\n",
      "Iteration 420, Loss: 0.0010436070151627064, Min w: 0.4190710783004761\n",
      "Iteration 430, Loss: 0.0008894582279026508, Min w: 0.49871566891670227\n",
      "Iteration 440, Loss: 0.0007727004704065621, Min w: 0.4894340932369232\n",
      "Iteration 450, Loss: 0.0009351623593829572, Min w: 0.499470055103302\n",
      "Iteration 460, Loss: 0.000841665780171752, Min w: 0.4976195991039276\n",
      "Iteration 470, Loss: 0.0008510549087077379, Min w: 0.5276098251342773\n",
      "Iteration 480, Loss: 0.0007899283082224429, Min w: 0.5089786052703857\n",
      "Iteration 490, Loss: 0.000719941861461848, Min w: 0.5671182870864868\n",
      "Iteration 500, Loss: 0.000772124738432467, Min w: 0.5410513877868652\n",
      "Iteration 510, Loss: 0.0007263845764100552, Min w: 0.5354249477386475\n",
      "Iteration 520, Loss: 0.000726481550373137, Min w: 0.5528392791748047\n",
      "Iteration 530, Loss: 0.0007775537669658661, Min w: 0.5660035014152527\n",
      "Iteration 540, Loss: 0.0008748364052735269, Min w: 0.5641844868659973\n",
      "Iteration 550, Loss: 0.0006756855873391032, Min w: 0.6181069612503052\n",
      "Iteration 560, Loss: 0.0006953688571229577, Min w: 0.6053944826126099\n",
      "Iteration 570, Loss: 0.0007702317088842392, Min w: 0.6106523871421814\n",
      "Iteration 580, Loss: 0.0007341370219364762, Min w: 0.6326611042022705\n",
      "Iteration 590, Loss: 0.0006219433853402734, Min w: 0.6349905133247375\n",
      "Iteration 600, Loss: 0.0005183998146094382, Min w: 0.6425397396087646\n",
      "Iteration 610, Loss: 0.0006057003047317266, Min w: 0.6356316208839417\n",
      "Iteration 620, Loss: 0.0008608479402028024, Min w: 0.5293967723846436\n",
      "Iteration 630, Loss: 0.000476759800221771, Min w: 0.6859326958656311\n",
      "Iteration 640, Loss: 0.000674207229167223, Min w: 0.6338616609573364\n",
      "Iteration 650, Loss: 0.0006119039608165622, Min w: 0.6524161696434021\n",
      "Iteration 660, Loss: 0.0005496618105098605, Min w: 0.6757869124412537\n",
      "Iteration 670, Loss: 0.00059349654475227, Min w: 0.6407753229141235\n",
      "Iteration 680, Loss: 0.0004886751412414014, Min w: 0.6792433857917786\n",
      "Iteration 690, Loss: 0.0004743019235320389, Min w: 0.7246356010437012\n",
      "Iteration 700, Loss: 0.0005070563638582826, Min w: 0.7079998850822449\n",
      "Iteration 710, Loss: 0.0006670614238828421, Min w: 0.6535919308662415\n",
      "Iteration 720, Loss: 0.0004901049542240798, Min w: 0.7252720594406128\n",
      "Iteration 730, Loss: 0.0006836123066022992, Min w: 0.6200862526893616\n",
      "Iteration 740, Loss: 0.0006561659392900765, Min w: 0.6396446228027344\n",
      "Iteration 750, Loss: 0.0004009816038887948, Min w: 0.7706703543663025\n",
      "Iteration 760, Loss: 0.0006087361834943295, Min w: 0.6444482803344727\n",
      "Iteration 770, Loss: 0.0007570510497316718, Min w: 0.6009397506713867\n",
      "Iteration 780, Loss: 0.00043625006219372153, Min w: 0.7557084560394287\n",
      "Iteration 790, Loss: 0.0005333465524017811, Min w: 0.7262194156646729\n",
      "Iteration 800, Loss: 0.0004858255560975522, Min w: 0.7466089725494385\n",
      "Iteration 810, Loss: 0.000342788000125438, Min w: 0.7753853797912598\n",
      "Iteration 820, Loss: 0.0004015099839307368, Min w: 0.7642630934715271\n",
      "Iteration 830, Loss: 0.00031405952177010477, Min w: 0.794714629650116\n",
      "Iteration 840, Loss: 0.00032030261354520917, Min w: 0.7866883277893066\n",
      "Iteration 850, Loss: 0.00033377655199728906, Min w: 0.7754803895950317\n",
      "Iteration 860, Loss: 0.0005301017081364989, Min w: 0.6754276156425476\n",
      "Iteration 870, Loss: 0.00040883058682084084, Min w: 0.7771821022033691\n",
      "Iteration 880, Loss: 0.0005182860768400133, Min w: 0.7202590107917786\n",
      "Iteration 890, Loss: 0.00046380163985304534, Min w: 0.7577553987503052\n",
      "Iteration 900, Loss: 0.0004444357182364911, Min w: 0.7644715905189514\n",
      "Iteration 910, Loss: 0.0005288340034894645, Min w: 0.7292680740356445\n",
      "Iteration 920, Loss: 0.00032753997948020697, Min w: 0.8188825845718384\n",
      "Iteration 930, Loss: 0.0005937036476098001, Min w: 0.6691994667053223\n",
      "Iteration 940, Loss: 0.00026246256311424077, Min w: 0.8344881534576416\n",
      "Iteration 950, Loss: 0.00039945749449543655, Min w: 0.7922691106796265\n",
      "Iteration 960, Loss: 0.00036107402411289513, Min w: 0.8007678389549255\n",
      "Iteration 970, Loss: 0.0005071471678093076, Min w: 0.7280371189117432\n",
      "Iteration 980, Loss: 0.0003290044842287898, Min w: 0.8166483044624329\n",
      "Iteration 990, Loss: 0.0002517839602660388, Min w: 0.8467097282409668\n",
      "Iteration 1000, Loss: 0.0003929712693206966, Min w: 0.7670415639877319\n",
      "Iteration 1010, Loss: 0.0003522161568980664, Min w: 0.806742787361145\n",
      "Iteration 1020, Loss: 0.0003747694136109203, Min w: 0.7830781936645508\n",
      "Iteration 1030, Loss: 0.0003293889749329537, Min w: 0.8250248432159424\n",
      "Iteration 1040, Loss: 0.00037246986175887287, Min w: 0.7754939794540405\n",
      "Iteration 1050, Loss: 0.0005735423765145242, Min w: 0.6497163772583008\n",
      "Iteration 1060, Loss: 0.0004354817501734942, Min w: 0.7274450063705444\n",
      "Iteration 1070, Loss: 0.0005248127272352576, Min w: 0.6760976314544678\n",
      "Iteration 1080, Loss: 0.0003771263000089675, Min w: 0.8030974864959717\n",
      "Iteration 1090, Loss: 0.0002701946650631726, Min w: 0.8542024493217468\n",
      "Iteration 1100, Loss: 0.0002614784170873463, Min w: 0.8630527853965759\n",
      "Iteration 1110, Loss: 0.0002479205431882292, Min w: 0.8491560816764832\n",
      "Iteration 1120, Loss: 0.0006380686536431313, Min w: 0.619354248046875\n",
      "Iteration 1130, Loss: 0.00045856248470954597, Min w: 0.73909592628479\n",
      "Iteration 1140, Loss: 0.00029037275817245245, Min w: 0.8223944306373596\n",
      "Iteration 1150, Loss: 0.00024078809656202793, Min w: 0.8695884346961975\n",
      "Iteration 1160, Loss: 0.0003427285992074758, Min w: 0.8004477024078369\n",
      "Iteration 1170, Loss: 0.0004262378206476569, Min w: 0.7338736653327942\n",
      "Iteration 1180, Loss: 0.000296471465844661, Min w: 0.8319613933563232\n",
      "Iteration 1190, Loss: 0.00029580070986412466, Min w: 0.8411209583282471\n",
      "Iteration 1200, Loss: 0.0003369318146724254, Min w: 0.789189875125885\n",
      "Iteration 1210, Loss: 0.00035049396683461964, Min w: 0.8119375705718994\n",
      "Iteration 1220, Loss: 0.00044780835742130876, Min w: 0.7099445462226868\n",
      "Iteration 1230, Loss: 0.0002482215058989823, Min w: 0.8687322735786438\n",
      "Iteration 1240, Loss: 0.00029028652352280915, Min w: 0.8218237161636353\n",
      "Iteration 0, Loss: 0.00024650819250382483, Min w: 0.8535032868385315\n",
      "Iteration 10, Loss: 0.00018316824571229517, Min w: 0.88725346326828\n",
      "Iteration 20, Loss: 0.00017614435637369752, Min w: 0.889468252658844\n",
      "Iteration 30, Loss: 0.00018016535614151508, Min w: 0.8983101844787598\n",
      "Iteration 40, Loss: 0.0003345141594763845, Min w: 0.8037270307540894\n",
      "Iteration 50, Loss: 0.00035041323280893266, Min w: 0.7689209580421448\n",
      "Iteration 60, Loss: 0.00019945602980442345, Min w: 0.8891968131065369\n",
      "Iteration 70, Loss: 0.00024507686612196267, Min w: 0.8661196827888489\n",
      "Iteration 80, Loss: 0.00018088628712575883, Min w: 0.9035081267356873\n",
      "Iteration 90, Loss: 0.00023715032148174942, Min w: 0.8684706091880798\n",
      "Iteration 100, Loss: 0.00017863439279608428, Min w: 0.9072127938270569\n",
      "Iteration 110, Loss: 0.00021858024410903454, Min w: 0.8873433470726013\n",
      "Iteration 120, Loss: 0.00031726909219287336, Min w: 0.8018409013748169\n",
      "Iteration 130, Loss: 0.0003758070233743638, Min w: 0.7600305080413818\n",
      "Iteration 140, Loss: 0.0003905904304701835, Min w: 0.7723954916000366\n",
      "Iteration 150, Loss: 0.0002506582241039723, Min w: 0.8264676332473755\n",
      "Iteration 160, Loss: 0.00027207907987758517, Min w: 0.8222712874412537\n",
      "Iteration 170, Loss: 0.00016048658289946616, Min w: 0.9141557216644287\n",
      "Iteration 180, Loss: 0.00045430369209498167, Min w: 0.7035540342330933\n",
      "Iteration 190, Loss: 0.00035086384741589427, Min w: 0.7622880935668945\n",
      "Iteration 200, Loss: 0.0002318959159310907, Min w: 0.8617559671401978\n",
      "Iteration 210, Loss: 0.0004461441421881318, Min w: 0.7457904815673828\n",
      "Iteration 220, Loss: 0.00031440111342817545, Min w: 0.8141789436340332\n",
      "Iteration 230, Loss: 0.00030004626023583114, Min w: 0.7925226092338562\n",
      "Iteration 240, Loss: 0.00028086401289328933, Min w: 0.8155558705329895\n",
      "Iteration 250, Loss: 0.00020004934049211442, Min w: 0.8901352882385254\n",
      "Iteration 260, Loss: 0.0001595284411450848, Min w: 0.9068833589553833\n",
      "Iteration 270, Loss: 0.00042290802230127156, Min w: 0.7111578583717346\n",
      "Iteration 280, Loss: 0.0003027535567525774, Min w: 0.8092333078384399\n",
      "Iteration 290, Loss: 0.00023842892551328987, Min w: 0.842100203037262\n",
      "Iteration 300, Loss: 0.0002133381785824895, Min w: 0.8554033041000366\n",
      "Iteration 310, Loss: 0.00022455502767115831, Min w: 0.8610101938247681\n",
      "Iteration 320, Loss: 0.00028860493330284953, Min w: 0.8211889863014221\n",
      "Iteration 330, Loss: 0.00020749428949784487, Min w: 0.8833620548248291\n",
      "Iteration 340, Loss: 0.0002703361969906837, Min w: 0.8240264654159546\n",
      "Iteration 350, Loss: 0.00013721206050831825, Min w: 0.9196227192878723\n",
      "Iteration 360, Loss: 0.00020661168673541397, Min w: 0.8622804284095764\n",
      "Iteration 370, Loss: 0.00017051206668838859, Min w: 0.9053757190704346\n",
      "Iteration 380, Loss: 0.00014740462938789278, Min w: 0.9031302332878113\n",
      "Iteration 390, Loss: 0.00030607188818976283, Min w: 0.7824423909187317\n",
      "Iteration 400, Loss: 0.00018201276543550193, Min w: 0.8742034435272217\n",
      "Iteration 410, Loss: 0.0002561163855716586, Min w: 0.8231242299079895\n",
      "Iteration 420, Loss: 0.0002182093885494396, Min w: 0.844714879989624\n",
      "Iteration 430, Loss: 0.00018614486907608807, Min w: 0.8787747621536255\n",
      "Iteration 440, Loss: 0.000653955910820514, Min w: 0.5515577793121338\n",
      "Iteration 450, Loss: 0.0004860637418460101, Min w: 0.592190146446228\n",
      "Iteration 460, Loss: 0.00013698289694730192, Min w: 0.9101763963699341\n",
      "Iteration 470, Loss: 0.00010872608982026577, Min w: 0.9371228814125061\n",
      "Iteration 480, Loss: 0.00012248699204064906, Min w: 0.9353755712509155\n",
      "Iteration 490, Loss: 0.00012393452925607562, Min w: 0.9315264225006104\n",
      "Iteration 500, Loss: 0.0001805608335416764, Min w: 0.8681074976921082\n",
      "Iteration 510, Loss: 0.00029995868680998683, Min w: 0.795486330986023\n",
      "Iteration 520, Loss: 0.00018806956359185278, Min w: 0.8653607368469238\n",
      "Iteration 530, Loss: 0.00015228027768898755, Min w: 0.9086667895317078\n",
      "Iteration 540, Loss: 8.897568477550521e-05, Min w: 0.9518824219703674\n",
      "Iteration 550, Loss: 9.263031097361818e-05, Min w: 0.9456825852394104\n",
      "Iteration 560, Loss: 9.413499356014654e-05, Min w: 0.9471638798713684\n",
      "Iteration 570, Loss: 0.00020837063493672758, Min w: 0.8784709572792053\n",
      "Iteration 580, Loss: 0.00027572683757171035, Min w: 0.797306478023529\n",
      "Iteration 590, Loss: 0.00010791858221637085, Min w: 0.9349371194839478\n",
      "Iteration 600, Loss: 9.177980973618105e-05, Min w: 0.9461149573326111\n",
      "Iteration 610, Loss: 0.00031905394280329347, Min w: 0.7602847814559937\n",
      "Iteration 620, Loss: 0.0002025372232310474, Min w: 0.8441853523254395\n",
      "Iteration 630, Loss: 0.0003140088520012796, Min w: 0.7967671155929565\n",
      "Iteration 640, Loss: 0.00022105364769231528, Min w: 0.8481407165527344\n",
      "Iteration 650, Loss: 0.00016511576541233808, Min w: 0.9050033092498779\n",
      "Iteration 660, Loss: 0.00016662635607644916, Min w: 0.8792681097984314\n",
      "Iteration 670, Loss: 0.00028577755438163877, Min w: 0.7986222505569458\n",
      "Iteration 680, Loss: 0.00017986515013035387, Min w: 0.8694059252738953\n",
      "Iteration 690, Loss: 0.00019222614355385303, Min w: 0.8503528237342834\n",
      "Iteration 700, Loss: 0.00022720305423717946, Min w: 0.8218293786048889\n",
      "Iteration 710, Loss: 0.00030640437034890056, Min w: 0.7621518969535828\n",
      "Iteration 720, Loss: 0.0002647773362696171, Min w: 0.7957674264907837\n",
      "Iteration 730, Loss: 0.00019822541798930615, Min w: 0.8588659167289734\n",
      "Iteration 740, Loss: 0.00012391783820930868, Min w: 0.925257682800293\n",
      "Iteration 750, Loss: 6.47772685624659e-05, Min w: 0.9658409357070923\n",
      "Iteration 760, Loss: 0.00015224727394524962, Min w: 0.8883820176124573\n",
      "Iteration 770, Loss: 0.0001588126615388319, Min w: 0.8882468938827515\n",
      "Iteration 780, Loss: 0.00016511599824298173, Min w: 0.8848038911819458\n",
      "Iteration 790, Loss: 0.0002706470841076225, Min w: 0.7883846759796143\n",
      "Iteration 800, Loss: 0.00019903149222955108, Min w: 0.8646989464759827\n",
      "Iteration 810, Loss: 0.00021209826809354126, Min w: 0.8321211338043213\n",
      "Iteration 820, Loss: 0.00026827724650502205, Min w: 0.7905975580215454\n",
      "Iteration 830, Loss: 0.00021694018505513668, Min w: 0.8374567031860352\n",
      "Iteration 840, Loss: 0.00017515472427476197, Min w: 0.8720405697822571\n",
      "Iteration 850, Loss: 0.0002920408733189106, Min w: 0.7915354371070862\n",
      "Iteration 860, Loss: 0.0002785551769193262, Min w: 0.7804346084594727\n",
      "Iteration 870, Loss: 0.00023746260558255017, Min w: 0.814008355140686\n",
      "Iteration 880, Loss: 0.00021713289606850594, Min w: 0.8234691619873047\n",
      "Iteration 890, Loss: 9.692138701211661e-05, Min w: 0.9489541053771973\n",
      "Iteration 900, Loss: 0.00010125675908057019, Min w: 0.9298534989356995\n",
      "Iteration 910, Loss: 5.9243633586447686e-05, Min w: 0.9631297588348389\n",
      "Iteration 920, Loss: 0.00012867421901319176, Min w: 0.9100581407546997\n",
      "Iteration 930, Loss: 0.0001953219762071967, Min w: 0.8574099540710449\n",
      "Iteration 940, Loss: 0.00013699372357223183, Min w: 0.8953385353088379\n",
      "Iteration 950, Loss: 0.000148708451888524, Min w: 0.8910163640975952\n",
      "Iteration 960, Loss: 9.345899161417037e-05, Min w: 0.9348173141479492\n",
      "Iteration 970, Loss: 0.00016437104204669595, Min w: 0.87660813331604\n",
      "Iteration 980, Loss: 0.00013550663425121456, Min w: 0.8954135775566101\n",
      "Iteration 990, Loss: 0.00018272425222676247, Min w: 0.8691257834434509\n",
      "Iteration 1000, Loss: 0.00025384887703694403, Min w: 0.8008350133895874\n",
      "Iteration 1010, Loss: 0.0002274605940328911, Min w: 0.8256810307502747\n",
      "Iteration 1020, Loss: 0.0001977104548132047, Min w: 0.8471937775611877\n",
      "Iteration 1030, Loss: 0.0001855810114648193, Min w: 0.852212131023407\n",
      "Iteration 1040, Loss: 0.0002981322759296745, Min w: 0.7605255842208862\n",
      "Iteration 1050, Loss: 0.00027202331693843007, Min w: 0.7897152304649353\n",
      "Iteration 1060, Loss: 0.0002890156756620854, Min w: 0.7943013310432434\n",
      "Iteration 1070, Loss: 4.4000767957186326e-05, Min w: 0.9764426946640015\n",
      "Iteration 1080, Loss: 5.984961899230257e-05, Min w: 0.9634108543395996\n",
      "Iteration 1090, Loss: 7.135422492865473e-05, Min w: 0.9519054889678955\n",
      "Iteration 1100, Loss: 6.849590863566846e-05, Min w: 0.9471914768218994\n",
      "Iteration 1110, Loss: 0.00022171394084580243, Min w: 0.819780170917511\n",
      "Iteration 1120, Loss: 9.609664266463369e-05, Min w: 0.9248484969139099\n",
      "Iteration 1130, Loss: 0.00011886109132319689, Min w: 0.9175119400024414\n",
      "Iteration 1140, Loss: 4.94386549689807e-05, Min w: 0.9697343707084656\n",
      "Iteration 1150, Loss: 0.0003088197554461658, Min w: 0.7398821711540222\n",
      "Iteration 1160, Loss: 0.0003581488272175193, Min w: 0.7332060933113098\n",
      "Iteration 1170, Loss: 0.0002871789038181305, Min w: 0.7579140663146973\n",
      "Iteration 1180, Loss: 0.00042755925096571445, Min w: 0.6589470505714417\n",
      "Iteration 1190, Loss: 8.393594907829538e-05, Min w: 0.9360973238945007\n",
      "Iteration 1200, Loss: 0.00034061900805681944, Min w: 0.7145868539810181\n",
      "Iteration 1210, Loss: 0.00041087885620072484, Min w: 0.7587533593177795\n",
      "Iteration 1220, Loss: 0.00011674227425828576, Min w: 0.9055936932563782\n",
      "Iteration 1230, Loss: 0.00012099208834115416, Min w: 0.8919351696968079\n",
      "Iteration 1240, Loss: 0.00010062140063382685, Min w: 0.9403704404830933\n",
      "Iteration 0, Loss: 0.0001582899858476594, Min w: 0.9051436185836792\n",
      "Iteration 10, Loss: 0.00030858436366543174, Min w: 0.7592537999153137\n",
      "Iteration 20, Loss: 0.0001123742331401445, Min w: 0.93357253074646\n",
      "Iteration 30, Loss: 0.00030581458122469485, Min w: 0.7441150546073914\n",
      "Iteration 40, Loss: 0.00024363465490750968, Min w: 0.8023542761802673\n",
      "Iteration 50, Loss: 3.7161942600505427e-05, Min w: 0.9804567694664001\n",
      "Iteration 60, Loss: 0.0003106131625827402, Min w: 0.7479872107505798\n",
      "Iteration 70, Loss: 0.00012374998186714947, Min w: 0.9047172665596008\n",
      "Iteration 80, Loss: 0.0002808850258588791, Min w: 0.7606844305992126\n",
      "Iteration 90, Loss: 7.128407742129639e-05, Min w: 0.9467200636863708\n",
      "Iteration 100, Loss: 4.8981768486555666e-05, Min w: 0.9706109166145325\n",
      "Iteration 110, Loss: 0.00016592795145697892, Min w: 0.8646574020385742\n",
      "Iteration 120, Loss: 0.0001748581271385774, Min w: 0.8707078099250793\n",
      "Iteration 130, Loss: 0.0002390638692304492, Min w: 0.7962466478347778\n",
      "Iteration 140, Loss: 6.108718662289903e-05, Min w: 0.9552067518234253\n",
      "Iteration 150, Loss: 9.014659735839814e-05, Min w: 0.9393939971923828\n",
      "Iteration 160, Loss: 0.0001038788104779087, Min w: 0.9206969141960144\n",
      "Iteration 170, Loss: 7.758117862977087e-05, Min w: 0.9421358704566956\n",
      "Iteration 180, Loss: 0.00011265019566053525, Min w: 0.9160221219062805\n",
      "Iteration 190, Loss: 0.00020547166059259325, Min w: 0.8462241291999817\n",
      "Iteration 200, Loss: 9.036831761477515e-05, Min w: 0.9339145421981812\n",
      "Iteration 210, Loss: 3.536613075993955e-05, Min w: 0.9757272601127625\n",
      "Iteration 220, Loss: 0.00019569869618862867, Min w: 0.8398836851119995\n",
      "Iteration 230, Loss: 0.0001680815330473706, Min w: 0.8741922378540039\n",
      "Iteration 240, Loss: 4.567699215840548e-05, Min w: 0.975723922252655\n",
      "Iteration 250, Loss: 5.2586179663194343e-05, Min w: 0.9719693660736084\n",
      "Iteration 260, Loss: 7.895730959717184e-05, Min w: 0.955628514289856\n",
      "Iteration 270, Loss: 0.0002006491122301668, Min w: 0.838587760925293\n",
      "Iteration 280, Loss: 0.00015192742284853011, Min w: 0.8974947333335876\n",
      "Iteration 290, Loss: 0.00027415246586315334, Min w: 0.7892712950706482\n",
      "Iteration 300, Loss: 0.00020841590594500303, Min w: 0.8507518768310547\n",
      "Iteration 310, Loss: 0.00020731640688609332, Min w: 0.8423565030097961\n",
      "Iteration 320, Loss: 0.00021871001808904111, Min w: 0.8202705383300781\n",
      "Iteration 330, Loss: 0.00010703435691539198, Min w: 0.9274864792823792\n",
      "Iteration 340, Loss: 0.00020090372709091753, Min w: 0.8519524931907654\n",
      "Iteration 350, Loss: 0.00016279806732200086, Min w: 0.8704542517662048\n",
      "Iteration 360, Loss: 0.0001132363686338067, Min w: 0.9131811261177063\n",
      "Iteration 370, Loss: 0.00015060206351336092, Min w: 0.8892632126808167\n",
      "Iteration 380, Loss: 8.760270429775119e-05, Min w: 0.936910092830658\n",
      "Iteration 390, Loss: 0.00011614341201493517, Min w: 0.8982443809509277\n",
      "Iteration 400, Loss: 5.8528556110104546e-05, Min w: 0.9577941298484802\n",
      "Iteration 410, Loss: 3.5580331314122304e-05, Min w: 0.9763355851173401\n",
      "Iteration 420, Loss: 0.0001541685633128509, Min w: 0.8686792254447937\n",
      "Iteration 430, Loss: 0.00020209229842294008, Min w: 0.8522262573242188\n",
      "Iteration 440, Loss: 0.0002000712265726179, Min w: 0.8461819291114807\n",
      "Iteration 450, Loss: 7.644770812476054e-05, Min w: 0.9422358870506287\n",
      "Iteration 460, Loss: 0.00019459010218270123, Min w: 0.8495075106620789\n",
      "Iteration 470, Loss: 0.00015131288091652095, Min w: 0.8904061317443848\n",
      "Iteration 480, Loss: 0.00023119038087315857, Min w: 0.8141581416130066\n",
      "Iteration 490, Loss: 0.00012984876229893416, Min w: 0.9013264775276184\n",
      "Iteration 500, Loss: 4.7629157052142546e-05, Min w: 0.9638776183128357\n",
      "Iteration 510, Loss: 3.0190940378815867e-05, Min w: 0.9781780242919922\n",
      "Iteration 520, Loss: 0.00014889190788380802, Min w: 0.8823807239532471\n",
      "Iteration 530, Loss: 7.958307833177969e-05, Min w: 0.9434471726417542\n",
      "Iteration 540, Loss: 0.00017411344742868096, Min w: 0.8512418866157532\n",
      "Iteration 550, Loss: 0.00017807546828407794, Min w: 0.8680434226989746\n",
      "Iteration 560, Loss: 8.650351810501888e-05, Min w: 0.9313234686851501\n",
      "Iteration 570, Loss: 3.6809964512940496e-05, Min w: 0.9769359827041626\n",
      "Iteration 580, Loss: 8.850271842675284e-05, Min w: 0.9260633587837219\n",
      "Iteration 590, Loss: 0.0001723896129988134, Min w: 0.8569185733795166\n",
      "Iteration 600, Loss: 0.0002574213140178472, Min w: 0.8229268789291382\n",
      "Iteration 610, Loss: 0.00018458484555594623, Min w: 0.8371773362159729\n",
      "Iteration 620, Loss: 0.00018254233873449266, Min w: 0.8771390318870544\n",
      "Iteration 630, Loss: 0.0001050887003657408, Min w: 0.9209338426589966\n",
      "Iteration 640, Loss: 6.638378545176238e-05, Min w: 0.9526908993721008\n",
      "Iteration 650, Loss: 0.00011703444761224091, Min w: 0.9022067785263062\n",
      "Iteration 660, Loss: 0.00017435610061511397, Min w: 0.8653626441955566\n",
      "Iteration 670, Loss: 7.800766616128385e-05, Min w: 0.9426918625831604\n",
      "Iteration 680, Loss: 5.603495810646564e-05, Min w: 0.9598223567008972\n",
      "Iteration 690, Loss: 0.0003229142748750746, Min w: 0.736954391002655\n",
      "Iteration 700, Loss: 0.00029368200921453536, Min w: 0.7629491686820984\n",
      "Iteration 710, Loss: 0.00032128169550560415, Min w: 0.7619588971138\n",
      "Iteration 720, Loss: 3.0276361940195784e-05, Min w: 0.9779081344604492\n",
      "Iteration 730, Loss: 0.00010539052891544998, Min w: 0.9157378673553467\n",
      "Iteration 740, Loss: 0.00012648111442103982, Min w: 0.905229926109314\n",
      "Iteration 750, Loss: 2.5852832550299354e-05, Min w: 0.9806508421897888\n",
      "Iteration 760, Loss: 3.1563224183628336e-05, Min w: 0.977811872959137\n",
      "Iteration 770, Loss: 0.0002449368475936353, Min w: 0.8099658489227295\n",
      "Iteration 780, Loss: 0.00014206423657014966, Min w: 0.8940843343734741\n",
      "Iteration 790, Loss: 0.00024272840528283268, Min w: 0.813422441482544\n",
      "Iteration 800, Loss: 0.00024174453574232757, Min w: 0.8079284429550171\n",
      "Iteration 810, Loss: 0.00023493150365538895, Min w: 0.8257800936698914\n",
      "Iteration 820, Loss: 0.00021599821047857404, Min w: 0.8303017616271973\n",
      "Iteration 830, Loss: 0.00019647751469165087, Min w: 0.8415107131004333\n",
      "Iteration 840, Loss: 0.0001068140336428769, Min w: 0.9108622074127197\n",
      "Iteration 850, Loss: 0.00012354558566585183, Min w: 0.9011642932891846\n",
      "Iteration 860, Loss: 0.00022923684446141124, Min w: 0.8113962411880493\n",
      "Iteration 870, Loss: 0.00014936305524315685, Min w: 0.9067723751068115\n",
      "Iteration 880, Loss: 5.301757846609689e-05, Min w: 0.9568187594413757\n",
      "Iteration 890, Loss: 0.00023853855964262038, Min w: 0.8119622468948364\n",
      "Iteration 900, Loss: 0.00019524870731402189, Min w: 0.8761967420578003\n",
      "Iteration 910, Loss: 0.00012781609257217497, Min w: 0.8827876448631287\n",
      "Iteration 920, Loss: 9.901567682391033e-05, Min w: 0.9179220199584961\n",
      "Iteration 930, Loss: 4.7692177759017795e-05, Min w: 0.9722445607185364\n",
      "Iteration 940, Loss: 2.8303715225774795e-05, Min w: 0.9796165823936462\n",
      "Iteration 950, Loss: 2.30707046284806e-05, Min w: 0.9865432977676392\n",
      "Iteration 960, Loss: 9.996013977797702e-05, Min w: 0.9201059937477112\n",
      "Iteration 970, Loss: 0.00016422841872554272, Min w: 0.8835159540176392\n",
      "Iteration 980, Loss: 1.709979733277578e-05, Min w: 0.9890526533126831\n",
      "Early break at iteration 982 --------------------------------\n",
      "Iteration 0, Loss: 1.8934433683170937e-05, Min w: 0.9898729920387268\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.977652391360607e-05, Min w: 0.9885943531990051\n",
      "Iteration 10, Loss: 0.0001549660664750263, Min w: 0.8610554933547974\n",
      "Iteration 20, Loss: 0.0001257146504940465, Min w: 0.9021809697151184\n",
      "Iteration 30, Loss: 0.00013504616799764335, Min w: 0.8914141654968262\n",
      "Iteration 40, Loss: 0.0001407953241141513, Min w: 0.8817445039749146\n",
      "Iteration 50, Loss: 0.00022362575691659003, Min w: 0.8419241309165955\n",
      "Iteration 60, Loss: 0.00018783340055961162, Min w: 0.8581734299659729\n",
      "Iteration 70, Loss: 0.0001152205586549826, Min w: 0.9042884111404419\n",
      "Iteration 80, Loss: 5.925181903876364e-05, Min w: 0.9568571448326111\n",
      "Iteration 90, Loss: 0.00019553878519218415, Min w: 0.8396540284156799\n",
      "Iteration 100, Loss: 0.0001874516747193411, Min w: 0.857089102268219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  42%|████▏     | 10/24 [14:56<19:37, 84.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110, Loss: 0.00013619044329971075, Min w: 0.8810370564460754\n",
      "Early break at iteration 114 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 3600, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.007088549043221757, 'L2_avg': 0.00821950044920023, 'End_point_L1_avg': 0.005563011443597463, 'End_point_L2_avg': 0.007231974560832231}\n",
      "Iteration 0, Loss: 0.0012474816758185625, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0008123827283270657, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005836181226186454, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000541079614777118, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000529219105374068, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005421860842034221, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005488375318236649, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005734646692872047, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005475376383401453, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005186852067708969, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005897448281757534, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0004991582245565951, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005074301734566689, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005332348519004881, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005196872516535223, Min w: 7.835920882657945e-40\n",
      "Iteration 150, Loss: 0.0005106404423713684, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005158254643902183, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005210824892856181, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005050215986557305, Min w: 6.833812267020281e-15\n",
      "Iteration 190, Loss: 0.0005196246202103794, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005228085210546851, Min w: 5.9279946893888756e-30\n",
      "Iteration 210, Loss: 0.0004990147426724434, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005015442729927599, Min w: 7.551389159028956e-24\n",
      "Iteration 230, Loss: 0.0005269432440400124, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005194981349632144, Min w: 1.943771414265393e-24\n",
      "Iteration 250, Loss: 0.000495280371978879, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0005068429745733738, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0004946372355334461, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0005076828529126942, Min w: 0.0\n",
      "Iteration 290, Loss: 0.000496216060128063, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004984541446901858, Min w: 4.989173679227632e-13\n",
      "Iteration 310, Loss: 0.0004968971479684114, Min w: 2.684722133494688e-08\n",
      "Iteration 320, Loss: 0.0005112423677928746, Min w: 1.0963872544317939e-33\n",
      "Iteration 330, Loss: 0.0005262490594759583, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000502353475894779, Min w: 1.0800447238142962e-32\n",
      "Iteration 350, Loss: 0.0005073630600236356, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0005083154537715018, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0005389709840528667, Min w: 4.28797330083394e-43\n",
      "Iteration 380, Loss: 0.0005141112487763166, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005298029282130301, Min w: 7.493191304253381e-40\n",
      "Iteration 400, Loss: 0.0005171390948817134, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005072631756775081, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005409368895925581, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0005066448356956244, Min w: 2.890095937494129e-17\n",
      "Iteration 440, Loss: 0.000496186432428658, Min w: 3.3018593826976417e-13\n",
      "Iteration 450, Loss: 0.000512095692101866, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005271814297884703, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005132562364451587, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000496729975566268, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0005025285063311458, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0005183885805308819, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005362615920603275, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0005135360988788307, Min w: 5.572248401106692e-33\n",
      "Iteration 530, Loss: 0.0005037813680246472, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005384476389735937, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005201747408136725, Min w: 2.802596928649634e-45\n",
      "Iteration 560, Loss: 0.0004977199132554233, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0005273076822049916, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0005118659464642406, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005311304121278226, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0005064164870418608, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005022870027460158, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0005198644939810038, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0005158042185939848, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005262594786472619, Min w: 0.0\n",
      "Iteration 650, Loss: 0.000501466856803745, Min w: 5.680423165885357e-31\n",
      "Iteration 660, Loss: 0.0005002020043320954, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0005082897841930389, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0004942079540342093, Min w: 0.0\n",
      "Iteration 690, Loss: 0.000496273918543011, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0005013936897739768, Min w: 0.0\n",
      "Iteration 710, Loss: 0.00044517978676594794, Min w: 4.484155085839415e-44\n",
      "Iteration 720, Loss: 0.0005028244922868907, Min w: 1.547737236703382e-38\n",
      "Iteration 730, Loss: 0.0005150422803126276, Min w: 2.8267909639393405e-31\n",
      "Iteration 740, Loss: 0.0005221363971941173, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0005055979709140956, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0005224243504926562, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0004976734635420144, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0005047123413532972, Min w: 4.1636588621329906e-10\n",
      "Iteration 790, Loss: 0.0005036322982050478, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0004981472156941891, Min w: 2.1720126197034665e-41\n",
      "Iteration 810, Loss: 0.0005016218055970967, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0005000440869480371, Min w: 9.7686656996577e-20\n",
      "Iteration 830, Loss: 0.0005036257789470255, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0005136035033501685, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0005065181758254766, Min w: 3.2003995094035965e-17\n",
      "Iteration 860, Loss: 0.0005128488992340863, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0005039134994149208, Min w: 2.37379959856624e-41\n",
      "Iteration 880, Loss: 0.0005044477293267846, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0005045198486186564, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0005121084395796061, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0005046926671639085, Min w: 4.542143352311236e-19\n",
      "Iteration 920, Loss: 0.0004958957433700562, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005067958263680339, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0005018111551180482, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0004955250187776983, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0004888203111477196, Min w: 3.0157039219091425e-28\n",
      "Iteration 970, Loss: 0.0004982120008207858, Min w: 9.377372975905018e-07\n",
      "Iteration 980, Loss: 0.00041199548286385834, Min w: 0.01083290483802557\n",
      "Iteration 990, Loss: 0.0005328247789293528, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0005151794175617397, Min w: 8.954297187035581e-43\n",
      "Iteration 1010, Loss: 0.0005087234312668443, Min w: 1.5392269390111937e-26\n",
      "Iteration 1020, Loss: 0.0004999790689907968, Min w: 4.847091388099542e-42\n",
      "Iteration 1030, Loss: 0.0004985805135220289, Min w: 2.5347008921354086e-39\n",
      "Iteration 1040, Loss: 0.000502575421705842, Min w: 8.628568785460841e-23\n",
      "Iteration 1050, Loss: 0.0004970444715581834, Min w: 1.7476993718901213e-07\n",
      "Iteration 1060, Loss: 0.0004966866108588874, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0004989917506463826, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.00044457451440393925, Min w: 8.189888831111602e-06\n",
      "Iteration 1090, Loss: 0.0005123022710904479, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0005027761217206717, Min w: 1.0102626688784972e-18\n",
      "Iteration 1110, Loss: 0.0005045565776526928, Min w: 2.8227680609616e-11\n",
      "Iteration 1120, Loss: 0.0004997311043553054, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0005149974022060633, Min w: 2.3988581235897914e-14\n",
      "Iteration 1140, Loss: 0.0004891661810688674, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0004941265215165913, Min w: 0.001019932795315981\n",
      "Iteration 1160, Loss: 0.0005012073088437319, Min w: 5.958296908964055e-33\n",
      "Iteration 1170, Loss: 0.0005026533617638052, Min w: 3.220828468312019e-39\n",
      "Iteration 1180, Loss: 0.0005072136991657317, Min w: 4.374692070996389e-05\n",
      "Iteration 1190, Loss: 0.0004985715495422482, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0005104737938381732, Min w: 3.783516788757879e-08\n",
      "Iteration 1210, Loss: 0.0004995035706087947, Min w: 5.403257498530603e-19\n",
      "Iteration 1220, Loss: 0.0004999842494726181, Min w: 1.437808848646346e-24\n",
      "Iteration 1230, Loss: 0.0004993825568817556, Min w: 2.521119313314557e-05\n",
      "Iteration 1240, Loss: 0.0004998689400963485, Min w: 8.910090547320504e-13\n",
      "Iteration 0, Loss: 0.0004575034836307168, Min w: 1.5680505019617588e-22\n",
      "Iteration 10, Loss: 0.0005004474078305066, Min w: 3.820470415721866e-12\n",
      "Iteration 20, Loss: 0.0005112640792503953, Min w: 2.055992774471737e-18\n",
      "Iteration 30, Loss: 0.0004952703020535409, Min w: 5.510925579154979e-32\n",
      "Iteration 40, Loss: 0.0004989106091670692, Min w: 4.306772438411237e-17\n",
      "Iteration 50, Loss: 0.0005023775156587362, Min w: 1.3457545300354923e-08\n",
      "Iteration 60, Loss: 0.0005063079879619181, Min w: 7.932944970153029e-18\n",
      "Iteration 70, Loss: 0.0005179960862733424, Min w: 5.850974050876666e-17\n",
      "Iteration 80, Loss: 0.0005038365488871932, Min w: 1.7039192174571728e-25\n",
      "Iteration 90, Loss: 0.000509944511577487, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005001129466108978, Min w: 3.011860207625512e-23\n",
      "Iteration 110, Loss: 0.0005034440546296537, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005133273079991341, Min w: 3.960606560119325e-28\n",
      "Iteration 130, Loss: 0.0005092934588901699, Min w: 2.792638082588228e-12\n",
      "Iteration 140, Loss: 0.00049759162357077, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0004960280493833125, Min w: 1.5585538578377135e-18\n",
      "Iteration 160, Loss: 0.0004937857738696039, Min w: 1.9454313360256492e-07\n",
      "Iteration 170, Loss: 0.0004976443597115576, Min w: 9.844030565741083e-15\n",
      "Iteration 180, Loss: 0.0004955024342052639, Min w: 2.5802451238622947e-21\n",
      "Iteration 190, Loss: 0.0004738162679132074, Min w: 5.224968235850724e-10\n",
      "Iteration 200, Loss: 0.0005009688320569694, Min w: 6.691200167151002e-42\n",
      "Iteration 210, Loss: 0.0005004779668524861, Min w: 1.6026676067003196e-20\n",
      "Iteration 220, Loss: 0.0004941836232319474, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005029657040722668, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004739388532470912, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004345237684901804, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0004976971540600061, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00050751818343997, Min w: 1.1789603265725797e-26\n",
      "Iteration 280, Loss: 0.000502059468999505, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005071634659543633, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0005017974763177335, Min w: 2.1019476964872256e-43\n",
      "Iteration 310, Loss: 0.0005024102283641696, Min w: 3.913776391623024e-21\n",
      "Iteration 320, Loss: 0.0004993326147086918, Min w: 4.2623166552058964e-32\n",
      "Iteration 330, Loss: 0.0005010685999877751, Min w: 3.5357004616990275e-25\n",
      "Iteration 340, Loss: 0.0004997492069378495, Min w: 0.0001238443801412359\n",
      "Iteration 350, Loss: 0.0005028799641877413, Min w: 1.2333556582283099e-17\n",
      "Iteration 360, Loss: 0.0005040739779360592, Min w: 3.1432423330812753e-10\n",
      "Iteration 370, Loss: 0.0004983723047189415, Min w: 1.4583582822261243e-12\n",
      "Iteration 380, Loss: 0.0005045378929935396, Min w: 1.6097525737520865e-14\n",
      "Iteration 390, Loss: 0.0004972354508936405, Min w: 2.219500980391162e-24\n",
      "Iteration 400, Loss: 0.0004984475090168417, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004641780979000032, Min w: 2.31881137123335e-19\n",
      "Iteration 420, Loss: 0.0004977253847755492, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004995429771952331, Min w: 5.684863610730707e-17\n",
      "Iteration 440, Loss: 0.00044728454668074846, Min w: 0.00625131418928504\n",
      "Iteration 450, Loss: 0.0004689512134063989, Min w: 0.000598604790866375\n",
      "Iteration 460, Loss: 0.0005004850099794567, Min w: 1.6981030392874563e-35\n",
      "Iteration 470, Loss: 0.0004814809071831405, Min w: 5.9625483117997646e-05\n",
      "Iteration 480, Loss: 0.00042412540642544627, Min w: 0.0002647630753926933\n",
      "Iteration 490, Loss: 0.0004963603569194674, Min w: 0.011344989761710167\n",
      "Iteration 500, Loss: 0.0005042232223786414, Min w: 1.3817400201787677e-07\n",
      "Iteration 510, Loss: 0.0005051580956205726, Min w: 6.083012426969436e-15\n",
      "Iteration 520, Loss: 0.0005005247076041996, Min w: 2.374640377644835e-41\n",
      "Iteration 530, Loss: 0.0005052573978900909, Min w: 4.4128953963218365e-12\n",
      "Iteration 540, Loss: 0.0004979164223186672, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0004979289951734245, Min w: 1.663177787264814e-26\n",
      "Iteration 560, Loss: 0.0004955205949954689, Min w: 1.201015570739092e-28\n",
      "Iteration 570, Loss: 0.0004969478468410671, Min w: 1.3369001408136683e-06\n",
      "Iteration 580, Loss: 0.00042689754627645016, Min w: 0.0007186903385445476\n",
      "Iteration 590, Loss: 0.000355605676304549, Min w: 0.004758863709867001\n",
      "Iteration 600, Loss: 0.00039264303632080555, Min w: 0.021951666101813316\n",
      "Iteration 610, Loss: 0.00046389742055907845, Min w: 7.703779942858091e-07\n",
      "Iteration 620, Loss: 0.0005000156234018505, Min w: 7.577313226647675e-06\n",
      "Iteration 630, Loss: 0.0004689881461672485, Min w: 0.0009398063994012773\n",
      "Iteration 640, Loss: 0.000497722125146538, Min w: 0.00013447424862533808\n",
      "Iteration 650, Loss: 0.0005002336110919714, Min w: 1.1645812092453411e-10\n",
      "Iteration 660, Loss: 0.000500946247484535, Min w: 3.495296594623928e-39\n",
      "Iteration 670, Loss: 0.0005016978248022497, Min w: 6.532783913826279e-07\n",
      "Iteration 680, Loss: 0.0004970747977495193, Min w: 4.731438765087637e-12\n",
      "Iteration 690, Loss: 0.00048770004650577903, Min w: 5.149188291397877e-05\n",
      "Iteration 700, Loss: 0.0004926897236146033, Min w: 0.0022681960836052895\n",
      "Iteration 710, Loss: 0.0004946542321704328, Min w: 2.4802277039270848e-05\n",
      "Iteration 720, Loss: 0.0004978313809260726, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0005074887885712087, Min w: 3.6502995044429554e-06\n",
      "Iteration 740, Loss: 0.0004873299039900303, Min w: 1.8223753617263583e-09\n",
      "Iteration 750, Loss: 0.0004978394717909396, Min w: 0.00010878918692469597\n",
      "Iteration 760, Loss: 0.0004970966256223619, Min w: 4.6743047992538436e-29\n",
      "Iteration 770, Loss: 0.00050476094475016, Min w: 2.98775743041348e-25\n",
      "Iteration 780, Loss: 0.0004999812226742506, Min w: 6.5577985750020495e-12\n",
      "Iteration 790, Loss: 0.0005063240532763302, Min w: 8.385990137287097e-18\n",
      "Iteration 800, Loss: 0.0005037926603108644, Min w: 2.8164541879260874e-11\n",
      "Iteration 810, Loss: 0.0005022788536734879, Min w: 9.292776459042032e-36\n",
      "Iteration 820, Loss: 0.0005021434044465423, Min w: 3.526356236643742e-23\n",
      "Iteration 830, Loss: 0.0004934006137773395, Min w: 0.004947272129356861\n",
      "Iteration 840, Loss: 0.0004869069089181721, Min w: 2.3271281548910977e-15\n",
      "Iteration 850, Loss: 0.0004956253687851131, Min w: 1.4748061712838156e-12\n",
      "Iteration 860, Loss: 0.0004961819504387677, Min w: 0.0\n",
      "Iteration 870, Loss: 0.00047950257430784404, Min w: 1.1253002440980708e-07\n",
      "Iteration 880, Loss: 0.00048362388042733073, Min w: 0.0006285861600190401\n",
      "Iteration 890, Loss: 0.0004978377837687731, Min w: 4.6560286182106836e-10\n",
      "Iteration 900, Loss: 0.0004851254925597459, Min w: 1.5922752254482475e-06\n",
      "Iteration 910, Loss: 0.0004950115690007806, Min w: 5.726910524755757e-19\n",
      "Iteration 920, Loss: 0.0005056638037785888, Min w: 4.666939119389891e-17\n",
      "Iteration 930, Loss: 0.0005036861984990537, Min w: 3.0148485704456496e-12\n",
      "Iteration 940, Loss: 0.0005042285774834454, Min w: 1.8441087790514593e-42\n",
      "Iteration 950, Loss: 0.0004962901002727449, Min w: 0.0002949741028714925\n",
      "Iteration 960, Loss: 0.000504028401337564, Min w: 4.6005212847688675e-21\n",
      "Iteration 970, Loss: 0.0005015538772568107, Min w: 4.717895968024026e-19\n",
      "Iteration 980, Loss: 0.0005023254780098796, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0004986888379789889, Min w: 6.160850170999765e-05\n",
      "Iteration 1000, Loss: 0.00045564366155304015, Min w: 0.018145207315683365\n",
      "Iteration 1010, Loss: 0.000494263949804008, Min w: 7.402570917358631e-11\n",
      "Iteration 1020, Loss: 0.0004941241932101548, Min w: 3.8902942553573766e-14\n",
      "Iteration 1030, Loss: 0.00046853013918735087, Min w: 0.0002950314956251532\n",
      "Iteration 1040, Loss: 0.0004965645493939519, Min w: 2.2742584204760163e-10\n",
      "Iteration 1050, Loss: 0.0005009411834180355, Min w: 2.970432398858615e-14\n",
      "Iteration 1060, Loss: 0.0005027303122915328, Min w: 1.332218794058843e-38\n",
      "Iteration 1070, Loss: 0.0004961076192557812, Min w: 1.1009012451657085e-10\n",
      "Iteration 1080, Loss: 0.0004985980340279639, Min w: 7.709056504268119e-09\n",
      "Iteration 1090, Loss: 0.0004947706474922597, Min w: 5.7481092802236233e-11\n",
      "Iteration 1100, Loss: 0.00048678411985747516, Min w: 0.004869166761636734\n",
      "Iteration 1110, Loss: 0.000492079125251621, Min w: 6.677153880948013e-25\n",
      "Iteration 1120, Loss: 0.00047399854520335793, Min w: 0.0003481806779745966\n",
      "Iteration 1130, Loss: 0.0004930016002617776, Min w: 1.1198981516386974e-33\n",
      "Iteration 1140, Loss: 0.0004979269579052925, Min w: 7.56985522530604e-22\n",
      "Iteration 1150, Loss: 0.00047264769091270864, Min w: 4.291305231163278e-07\n",
      "Iteration 1160, Loss: 0.0004819151072297245, Min w: 0.011340332217514515\n",
      "Iteration 1170, Loss: 0.00042330133146606386, Min w: 0.015201027505099773\n",
      "Iteration 1180, Loss: 0.00048031649203039706, Min w: 0.018515238538384438\n",
      "Iteration 1190, Loss: 0.0004646173620130867, Min w: 0.0009922367753461003\n",
      "Iteration 1200, Loss: 0.0004960740334354341, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0005003723781555891, Min w: 1.0905283439311916e-15\n",
      "Iteration 1220, Loss: 0.0004960547084920108, Min w: 1.401298464324817e-45\n",
      "Iteration 1230, Loss: 0.0005010819295421243, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0004926137626171112, Min w: 2.007853050489672e-10\n",
      "Iteration 0, Loss: 0.0005011638859286904, Min w: 1.62467086742022e-16\n",
      "Iteration 10, Loss: 0.000495673215482384, Min w: 5.0682894687063354e-18\n",
      "Iteration 20, Loss: 0.0004992733593098819, Min w: 1.401298464324817e-45\n",
      "Iteration 30, Loss: 0.0004873569996561855, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000495517102535814, Min w: 9.825650131836742e-37\n",
      "Iteration 50, Loss: 0.0004975646734237671, Min w: 3.7347774371902063e-37\n",
      "Iteration 60, Loss: 0.0004962398670613766, Min w: 0.0\n",
      "Iteration 70, Loss: 0.000497703324072063, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00048630303354002535, Min w: 2.2604868864795382e-34\n",
      "Iteration 90, Loss: 0.00048732091090641916, Min w: 0.006192869506776333\n",
      "Iteration 100, Loss: 0.00040637707570567727, Min w: 0.050481200218200684\n",
      "Iteration 110, Loss: 0.00048447318840771914, Min w: 1.016967758005194e-06\n",
      "Iteration 120, Loss: 0.00045021375990472734, Min w: 0.027301032096147537\n",
      "Iteration 130, Loss: 0.0004923023516312242, Min w: 3.0388304719797254e-12\n",
      "Iteration 140, Loss: 0.00042951363138854504, Min w: 0.09221645444631577\n",
      "Iteration 150, Loss: 0.000489078345708549, Min w: 0.010901949368417263\n",
      "Iteration 160, Loss: 0.00046622022637166083, Min w: 0.0065637254156172276\n",
      "Iteration 170, Loss: 0.0004931757575832307, Min w: 0.0\n",
      "Iteration 180, Loss: 0.000499171728733927, Min w: 1.219657767622229e-30\n",
      "Iteration 190, Loss: 0.0004946308326907456, Min w: 8.256797887551057e-14\n",
      "Iteration 200, Loss: 0.0004961280501447618, Min w: 4.3745357837574504e-21\n",
      "Iteration 210, Loss: 0.0004939892678521574, Min w: 4.086494836858407e-16\n",
      "Iteration 220, Loss: 0.0004951798473484814, Min w: 2.802596928649634e-44\n",
      "Iteration 230, Loss: 0.0004880838969256729, Min w: 0.0035038581117987633\n",
      "Iteration 240, Loss: 0.00036544198519550264, Min w: 0.001143716392107308\n",
      "Iteration 250, Loss: 0.00037830675137229264, Min w: 0.018955139443278313\n",
      "Iteration 260, Loss: 0.0004975030315108597, Min w: 2.1234860980712256e-08\n",
      "Iteration 270, Loss: 0.0004917033365927637, Min w: 8.749299951205103e-08\n",
      "Iteration 280, Loss: 0.0004947121487930417, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0004961742088198662, Min w: 0.0008018709486350417\n",
      "Iteration 300, Loss: 0.0004935267497785389, Min w: 1.0137746198068953e-09\n",
      "Iteration 310, Loss: 0.000353202223777771, Min w: 0.041356027126312256\n",
      "Iteration 320, Loss: 0.0003830294299405068, Min w: 0.02390516735613346\n",
      "Iteration 330, Loss: 0.0004658853868022561, Min w: 0.001354208099655807\n",
      "Iteration 340, Loss: 0.0004969752044416964, Min w: 2.6891859202961266e-38\n",
      "Iteration 350, Loss: 0.0004928070120513439, Min w: 6.315534761824892e-10\n",
      "Iteration 360, Loss: 0.0004932518932037055, Min w: 7.132132464870239e-24\n",
      "Iteration 370, Loss: 0.000494168431032449, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0004963980172760785, Min w: 1.6857039781825733e-06\n",
      "Iteration 390, Loss: 0.0004969678702764213, Min w: 9.101144640620037e-31\n",
      "Iteration 400, Loss: 0.0004963428946211934, Min w: 3.275296330684796e-05\n",
      "Iteration 410, Loss: 0.0004940713406540453, Min w: 0.00023603915178682655\n",
      "Iteration 420, Loss: 0.0004947829875163734, Min w: 5.047260387414099e-10\n",
      "Iteration 430, Loss: 0.0004994729533791542, Min w: 2.8602746798660206e-13\n",
      "Iteration 440, Loss: 0.00045687766396440566, Min w: 3.738296427968635e-08\n",
      "Iteration 450, Loss: 0.00047458859626203775, Min w: 0.003527330467477441\n",
      "Iteration 460, Loss: 0.00041363658965565264, Min w: 0.11780064553022385\n",
      "Iteration 470, Loss: 0.0004955788026563823, Min w: 2.0220568626611364e-18\n",
      "Iteration 480, Loss: 0.0004884417285211384, Min w: 1.0461571929923363e-12\n",
      "Iteration 490, Loss: 0.0004935073666274548, Min w: 4.779792561748764e-07\n",
      "Iteration 500, Loss: 0.0004996245843358338, Min w: 1.5801785435698434e-09\n",
      "Iteration 510, Loss: 0.0004945600521750748, Min w: 3.7309364374919166e-20\n",
      "Iteration 520, Loss: 0.0004939125501550734, Min w: 1.6572682852711296e-06\n",
      "Iteration 530, Loss: 0.0004976221825927496, Min w: 2.776422858658071e-16\n",
      "Iteration 540, Loss: 0.0004968575085513294, Min w: 1.2708393935284353e-22\n",
      "Iteration 550, Loss: 0.0005008691805414855, Min w: 6.651820513070561e-06\n",
      "Iteration 560, Loss: 0.0004928399575874209, Min w: 2.659425870335754e-17\n",
      "Iteration 570, Loss: 0.00044802515185438097, Min w: 7.564102881378598e-13\n",
      "Iteration 580, Loss: 0.0004974208422936499, Min w: 3.0656544345966685e-17\n",
      "Iteration 590, Loss: 0.0004950925358571112, Min w: 4.675752336424921e-07\n",
      "Iteration 600, Loss: 0.0004973809700459242, Min w: 4.46158219960871e-13\n",
      "Iteration 610, Loss: 0.0004937146441079676, Min w: 1.18230502721417e-06\n",
      "Iteration 620, Loss: 0.0004970459267497063, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0004941498045809567, Min w: 2.797922619502194e-15\n",
      "Iteration 640, Loss: 0.0004973072791472077, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0004932925803586841, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0004926921101287007, Min w: 2.33451841191723e-10\n",
      "Iteration 670, Loss: 0.0004964249674230814, Min w: 1.4336684588507203e-41\n",
      "Iteration 680, Loss: 0.000494074949529022, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0004938680795021355, Min w: 8.940795669332147e-05\n",
      "Iteration 700, Loss: 0.00046213160385377705, Min w: 0.009782375767827034\n",
      "Iteration 710, Loss: 0.0004550343146547675, Min w: 6.76077036132483e-07\n",
      "Iteration 720, Loss: 0.0004902096698060632, Min w: 0.0014748628018423915\n",
      "Iteration 730, Loss: 0.0004930947907269001, Min w: 2.1956695414497367e-16\n",
      "Iteration 740, Loss: 0.00045436539221554995, Min w: 0.008508105762302876\n",
      "Iteration 750, Loss: 0.0004964392865076661, Min w: 2.6173771774356732e-24\n",
      "Iteration 760, Loss: 0.0004910017014481127, Min w: 0.006135441362857819\n",
      "Iteration 770, Loss: 0.0004954660544171929, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0004871304554399103, Min w: 0.008494116365909576\n",
      "Iteration 790, Loss: 0.0004917236510664225, Min w: 1.7782276700017974e-05\n",
      "Iteration 800, Loss: 0.0003757431113626808, Min w: 0.21225152909755707\n",
      "Iteration 810, Loss: 0.0003031890082638711, Min w: 0.1174655333161354\n",
      "Iteration 820, Loss: 0.0004953635507263243, Min w: 5.497086385730654e-05\n",
      "Iteration 830, Loss: 0.0004970018635503948, Min w: 4.8298476329478035e-09\n",
      "Iteration 840, Loss: 0.00047458024346269667, Min w: 4.034354219584202e-07\n",
      "Iteration 850, Loss: 0.0004948943387717009, Min w: 5.277169334985204e-25\n",
      "Iteration 860, Loss: 0.00046178363845683634, Min w: 8.000161955123986e-08\n",
      "Iteration 870, Loss: 0.0004921660874970257, Min w: 0.002854440128430724\n",
      "Iteration 880, Loss: 0.00046404270688071847, Min w: 0.00040102360071614385\n",
      "Iteration 890, Loss: 0.00037550469278357923, Min w: 0.0626179650425911\n",
      "Iteration 900, Loss: 0.0004933446180075407, Min w: 3.961665424867533e-05\n",
      "Iteration 910, Loss: 0.0004959048819728196, Min w: 3.129330070805736e-05\n",
      "Iteration 920, Loss: 0.00048684264766052365, Min w: 3.162726747163447e-10\n",
      "Iteration 930, Loss: 0.0005005999701097608, Min w: 1.5413464104705173e-28\n",
      "Iteration 940, Loss: 0.00049329933244735, Min w: 0.000764135445933789\n",
      "Iteration 950, Loss: 0.0004997652722522616, Min w: 1.3663947987533004e-15\n",
      "Iteration 960, Loss: 0.00047623872524127364, Min w: 4.606154155740571e-15\n",
      "Iteration 970, Loss: 0.0004972332390025258, Min w: 2.765231617741429e-22\n",
      "Iteration 980, Loss: 0.0004951546434313059, Min w: 2.063163279542729e-13\n",
      "Iteration 990, Loss: 0.0004968005232512951, Min w: 1.2899974101037953e-27\n",
      "Iteration 1000, Loss: 0.000499197281897068, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0004718222771771252, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0004956468474119902, Min w: 1.3107012220361924e-13\n",
      "Iteration 1030, Loss: 0.000494522275403142, Min w: 0.0006011580117046833\n",
      "Iteration 1040, Loss: 0.0003874820831697434, Min w: 0.00524506438523531\n",
      "Iteration 1050, Loss: 0.0004930885042995214, Min w: 0.0003844044404104352\n",
      "Iteration 1060, Loss: 0.000493512605316937, Min w: 0.00012334861094132066\n",
      "Iteration 1070, Loss: 0.0004943842650391161, Min w: 2.422834228490909e-21\n",
      "Iteration 1080, Loss: 0.0004951648879796267, Min w: 4.0017028368311e-05\n",
      "Iteration 1090, Loss: 0.0004963570972904563, Min w: 7.526664017894358e-22\n",
      "Iteration 1100, Loss: 0.0004957838100381196, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0004955764743499458, Min w: 7.641158994308418e-17\n",
      "Iteration 1120, Loss: 0.000496228167321533, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0004945697728544474, Min w: 4.719790550807923e-32\n",
      "Iteration 1140, Loss: 0.0004947645356878638, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0004951094160787761, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0004944581887684762, Min w: 1.401298464324817e-45\n",
      "Iteration 1170, Loss: 0.0004943047533743083, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0004917213809676468, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0004943181411363184, Min w: 7.567011707354012e-44\n",
      "Iteration 1200, Loss: 0.00043844114406965673, Min w: 0.0007186567527242005\n",
      "Iteration 1210, Loss: 0.00043860162259079516, Min w: 0.014614098705351353\n",
      "Iteration 1220, Loss: 0.0004175509384367615, Min w: 0.02275078371167183\n",
      "Iteration 1230, Loss: 0.0003826903994195163, Min w: 0.08240003883838654\n",
      "Iteration 1240, Loss: 0.0003039446019101888, Min w: 0.1728401482105255\n",
      "Iteration 0, Loss: 0.0003166346868965775, Min w: 0.16667546331882477\n",
      "Iteration 10, Loss: 0.00031313265208154917, Min w: 0.1968076080083847\n",
      "Iteration 20, Loss: 0.00027722070808522403, Min w: 0.19964386522769928\n",
      "Iteration 30, Loss: 0.0002503613941371441, Min w: 0.25996971130371094\n",
      "Iteration 40, Loss: 0.00026841284125111997, Min w: 0.28145885467529297\n",
      "Iteration 50, Loss: 0.00026505073765292764, Min w: 0.3182423412799835\n",
      "Iteration 60, Loss: 0.00029974273638799787, Min w: 0.3185471296310425\n",
      "Iteration 70, Loss: 0.0003031528030987829, Min w: 0.30545535683631897\n",
      "Iteration 80, Loss: 0.0002612537646200508, Min w: 0.3582563102245331\n",
      "Iteration 90, Loss: 0.0002328613045392558, Min w: 0.3952464461326599\n",
      "Iteration 100, Loss: 0.00023705820785835385, Min w: 0.40214020013809204\n",
      "Iteration 110, Loss: 0.0002881366526708007, Min w: 0.36995500326156616\n",
      "Iteration 120, Loss: 0.0002722115896176547, Min w: 0.3843945264816284\n",
      "Iteration 130, Loss: 0.000284989713691175, Min w: 0.40326929092407227\n",
      "Iteration 140, Loss: 0.0002677392621990293, Min w: 0.41349291801452637\n",
      "Iteration 150, Loss: 0.0002530826604925096, Min w: 0.414014607667923\n",
      "Iteration 160, Loss: 0.0002460315590724349, Min w: 0.42979222536087036\n",
      "Iteration 170, Loss: 0.00021412510250229388, Min w: 0.4642191231250763\n",
      "Iteration 180, Loss: 0.00022639504459220916, Min w: 0.45859819650650024\n",
      "Iteration 190, Loss: 0.00021055633260402828, Min w: 0.45228686928749084\n",
      "Iteration 200, Loss: 0.0002291143755428493, Min w: 0.44696706533432007\n",
      "Iteration 210, Loss: 0.00024771137395873666, Min w: 0.4175352454185486\n",
      "Iteration 220, Loss: 0.0002387517160968855, Min w: 0.3976359963417053\n",
      "Iteration 230, Loss: 0.00022123388771433383, Min w: 0.5028873682022095\n",
      "Iteration 240, Loss: 0.00020497391233220696, Min w: 0.4807669222354889\n",
      "Iteration 250, Loss: 0.00019069247355218977, Min w: 0.5170008540153503\n",
      "Iteration 260, Loss: 0.000201668226509355, Min w: 0.5207272171974182\n",
      "Iteration 270, Loss: 0.00020597456023097038, Min w: 0.5290918946266174\n",
      "Iteration 280, Loss: 0.00019962753867730498, Min w: 0.5079320073127747\n",
      "Iteration 290, Loss: 0.00021826985175721347, Min w: 0.5069345831871033\n",
      "Iteration 300, Loss: 0.00025354826357215643, Min w: 0.39737895131111145\n",
      "Iteration 310, Loss: 0.0002398260257905349, Min w: 0.47283652424812317\n",
      "Iteration 320, Loss: 0.0002373158495174721, Min w: 0.46358001232147217\n",
      "Iteration 330, Loss: 0.0002176024136133492, Min w: 0.4669056236743927\n",
      "Iteration 340, Loss: 0.00018635606102179736, Min w: 0.5655708312988281\n",
      "Iteration 350, Loss: 0.00020473235053941607, Min w: 0.515656054019928\n",
      "Iteration 360, Loss: 0.00018649487174116075, Min w: 0.5469221472740173\n",
      "Iteration 370, Loss: 0.00018971441022586077, Min w: 0.48973655700683594\n",
      "Iteration 380, Loss: 0.00018073440878652036, Min w: 0.5299746990203857\n",
      "Iteration 390, Loss: 0.00018633947183843702, Min w: 0.5191525220870972\n",
      "Iteration 400, Loss: 0.00020898625371046364, Min w: 0.5543627738952637\n",
      "Iteration 410, Loss: 0.0002094032970489934, Min w: 0.5541911125183105\n",
      "Iteration 420, Loss: 0.00020213343668729067, Min w: 0.5242319703102112\n",
      "Iteration 430, Loss: 0.00020397700427565724, Min w: 0.5341252684593201\n",
      "Iteration 440, Loss: 0.00019304166198708117, Min w: 0.5495813488960266\n",
      "Iteration 450, Loss: 0.00017437958740629256, Min w: 0.5750483870506287\n",
      "Iteration 460, Loss: 0.0001614218926988542, Min w: 0.566777765750885\n",
      "Iteration 470, Loss: 0.0001677636319072917, Min w: 0.5657492876052856\n",
      "Iteration 480, Loss: 0.00017082793056033552, Min w: 0.5653372406959534\n",
      "Iteration 490, Loss: 0.00015711024752818048, Min w: 0.5897448658943176\n",
      "Iteration 500, Loss: 0.0001515494514023885, Min w: 0.5740503072738647\n",
      "Iteration 510, Loss: 0.0001763099862728268, Min w: 0.5467965006828308\n",
      "Iteration 520, Loss: 0.00015986600192263722, Min w: 0.5702683329582214\n",
      "Iteration 530, Loss: 0.00014221719175111502, Min w: 0.5860636234283447\n",
      "Iteration 540, Loss: 0.00016063483781181276, Min w: 0.5917444825172424\n",
      "Iteration 550, Loss: 0.00016156960919033736, Min w: 0.5846906304359436\n",
      "Iteration 560, Loss: 0.00016055752348620445, Min w: 0.5776174664497375\n",
      "Iteration 570, Loss: 0.00016871078696567565, Min w: 0.5829139947891235\n",
      "Iteration 580, Loss: 0.00017023412510752678, Min w: 0.5632513761520386\n",
      "Iteration 590, Loss: 0.0001385688956361264, Min w: 0.5988661050796509\n",
      "Iteration 600, Loss: 0.00020399363711476326, Min w: 0.48186546564102173\n",
      "Iteration 610, Loss: 0.00019501420320011675, Min w: 0.5226293206214905\n",
      "Iteration 620, Loss: 0.00015979625459294766, Min w: 0.5995096564292908\n",
      "Iteration 630, Loss: 0.0001640443515498191, Min w: 0.5965679883956909\n",
      "Iteration 640, Loss: 0.0001912168663693592, Min w: 0.5639787316322327\n",
      "Iteration 650, Loss: 0.00016398831212427467, Min w: 0.6096782684326172\n",
      "Iteration 660, Loss: 0.00016913712897803634, Min w: 0.5947292447090149\n",
      "Iteration 670, Loss: 0.00015474148676730692, Min w: 0.6011756658554077\n",
      "Iteration 680, Loss: 0.0001519610668765381, Min w: 0.5905141234397888\n",
      "Iteration 690, Loss: 0.00014286694931797683, Min w: 0.6275962591171265\n",
      "Iteration 700, Loss: 0.00014444995031226426, Min w: 0.6131102442741394\n",
      "Iteration 710, Loss: 0.0001516172051196918, Min w: 0.6157249808311462\n",
      "Iteration 720, Loss: 0.00015192052524071187, Min w: 0.6107203364372253\n",
      "Iteration 730, Loss: 0.00013675169611815363, Min w: 0.6262559294700623\n",
      "Iteration 740, Loss: 0.00015912034723442048, Min w: 0.6245394945144653\n",
      "Iteration 750, Loss: 0.00015401124255731702, Min w: 0.6308212280273438\n",
      "Iteration 760, Loss: 0.00017656564887147397, Min w: 0.5801610946655273\n",
      "Iteration 770, Loss: 0.000195264263311401, Min w: 0.5458904504776001\n",
      "Iteration 780, Loss: 0.00016056075401138514, Min w: 0.6058986783027649\n",
      "Iteration 790, Loss: 0.00016037802561186254, Min w: 0.6163385510444641\n",
      "Iteration 800, Loss: 0.00015530317614320666, Min w: 0.6172801852226257\n",
      "Iteration 810, Loss: 0.00016589504957664758, Min w: 0.6031127572059631\n",
      "Iteration 820, Loss: 0.0001558618969283998, Min w: 0.6292209029197693\n",
      "Iteration 830, Loss: 0.00016894243890419602, Min w: 0.5888289213180542\n",
      "Iteration 840, Loss: 0.00016169475566130131, Min w: 0.6187365651130676\n",
      "Iteration 850, Loss: 0.00016814391710795462, Min w: 0.5805463790893555\n",
      "Iteration 860, Loss: 0.00018814638315234333, Min w: 0.5925642848014832\n",
      "Iteration 870, Loss: 0.00011989667837042361, Min w: 0.642596960067749\n",
      "Iteration 880, Loss: 0.00013705161109101027, Min w: 0.6135814785957336\n",
      "Iteration 890, Loss: 0.00015775025531183928, Min w: 0.6178941130638123\n",
      "Iteration 900, Loss: 0.00016557071649003774, Min w: 0.6129624843597412\n",
      "Iteration 910, Loss: 0.00016004391363821924, Min w: 0.6261996626853943\n",
      "Iteration 920, Loss: 0.00016433677228633314, Min w: 0.6138304471969604\n",
      "Iteration 930, Loss: 0.0001465052191633731, Min w: 0.6424253582954407\n",
      "Iteration 940, Loss: 0.00014335002924781293, Min w: 0.639789342880249\n",
      "Iteration 950, Loss: 0.00012810173211619258, Min w: 0.6552329063415527\n",
      "Iteration 960, Loss: 0.00012537733709905297, Min w: 0.6726725697517395\n",
      "Iteration 970, Loss: 0.00013399077579379082, Min w: 0.6578537225723267\n",
      "Iteration 980, Loss: 0.00013299121928866953, Min w: 0.6405919790267944\n",
      "Iteration 990, Loss: 0.0001495858741691336, Min w: 0.6238304376602173\n",
      "Iteration 1000, Loss: 0.00012519927986431867, Min w: 0.6578137874603271\n",
      "Iteration 1010, Loss: 0.00014899627421982586, Min w: 0.62044358253479\n",
      "Iteration 1020, Loss: 0.00013623543782159686, Min w: 0.656568706035614\n",
      "Iteration 1030, Loss: 0.0001460491184843704, Min w: 0.6605556011199951\n",
      "Iteration 1040, Loss: 0.00015509521472267807, Min w: 0.6329726576805115\n",
      "Iteration 1050, Loss: 0.00015589869872201234, Min w: 0.6243806481361389\n",
      "Iteration 1060, Loss: 0.00015377523959614336, Min w: 0.6461338996887207\n",
      "Iteration 1070, Loss: 0.00011883742263307795, Min w: 0.6680468320846558\n",
      "Iteration 1080, Loss: 0.00014176168770063668, Min w: 0.6572040319442749\n",
      "Iteration 1090, Loss: 0.00012953912664670497, Min w: 0.6648544073104858\n",
      "Iteration 1100, Loss: 0.00012944484478794038, Min w: 0.6687420010566711\n",
      "Iteration 1110, Loss: 0.0001367700460832566, Min w: 0.6551409363746643\n",
      "Iteration 1120, Loss: 0.00013138275244273245, Min w: 0.6763269901275635\n",
      "Iteration 1130, Loss: 0.000126736267702654, Min w: 0.681962251663208\n",
      "Iteration 1140, Loss: 0.00013780064182356, Min w: 0.6816905736923218\n",
      "Iteration 1150, Loss: 0.00014284074131865054, Min w: 0.6682943105697632\n",
      "Iteration 1160, Loss: 0.00013248484174255282, Min w: 0.6846169829368591\n",
      "Iteration 1170, Loss: 0.00014121827553026378, Min w: 0.6803633570671082\n",
      "Iteration 1180, Loss: 0.00015094441187102348, Min w: 0.6668537855148315\n",
      "Iteration 1190, Loss: 0.0001418075116816908, Min w: 0.6762617826461792\n",
      "Iteration 1200, Loss: 0.00014689132513012737, Min w: 0.6734108924865723\n",
      "Iteration 1210, Loss: 0.00014163240848574787, Min w: 0.6833528876304626\n",
      "Iteration 1220, Loss: 0.00015142168558668345, Min w: 0.6657664179801941\n",
      "Iteration 1230, Loss: 0.000151754793478176, Min w: 0.6850149035453796\n",
      "Iteration 1240, Loss: 0.00013607823348138481, Min w: 0.6955093741416931\n",
      "Iteration 0, Loss: 0.00011694337445078418, Min w: 0.7058032155036926\n",
      "Iteration 10, Loss: 0.00013435850269161165, Min w: 0.6907009482383728\n",
      "Iteration 20, Loss: 0.00011020519741578028, Min w: 0.725513219833374\n",
      "Iteration 30, Loss: 0.00011531075870152563, Min w: 0.7156157493591309\n",
      "Iteration 40, Loss: 0.00014082039706408978, Min w: 0.7010852694511414\n",
      "Iteration 50, Loss: 0.0001282036246266216, Min w: 0.7111098170280457\n",
      "Iteration 60, Loss: 0.00014176212425809354, Min w: 0.7011041641235352\n",
      "Iteration 70, Loss: 0.00012786111619789153, Min w: 0.7153715491294861\n",
      "Iteration 80, Loss: 0.00013743629097007215, Min w: 0.7068018913269043\n",
      "Iteration 90, Loss: 0.00012406423047650605, Min w: 0.7266059517860413\n",
      "Iteration 100, Loss: 0.00011456936044851318, Min w: 0.7323588132858276\n",
      "Iteration 110, Loss: 0.00013817752187605947, Min w: 0.7150391936302185\n",
      "Iteration 120, Loss: 0.0001274036621907726, Min w: 0.7190710306167603\n",
      "Iteration 130, Loss: 0.00014350528363138437, Min w: 0.6980435848236084\n",
      "Iteration 140, Loss: 0.0001450871059205383, Min w: 0.6889633536338806\n",
      "Iteration 150, Loss: 0.000146283651702106, Min w: 0.6918427348136902\n",
      "Iteration 160, Loss: 0.00014869938604533672, Min w: 0.6794629693031311\n",
      "Iteration 170, Loss: 0.00012817846436519176, Min w: 0.6923413872718811\n",
      "Iteration 180, Loss: 0.00013173389015719295, Min w: 0.7280899286270142\n",
      "Iteration 190, Loss: 0.00014070032921154052, Min w: 0.6909976601600647\n",
      "Iteration 200, Loss: 0.00011263485794188455, Min w: 0.7449985146522522\n",
      "Iteration 210, Loss: 0.00011425990669522434, Min w: 0.7520030736923218\n",
      "Iteration 220, Loss: 0.00011641652963589877, Min w: 0.755420982837677\n",
      "Iteration 230, Loss: 0.00011454702325863764, Min w: 0.7647868990898132\n",
      "Iteration 240, Loss: 9.83401041594334e-05, Min w: 0.7749761343002319\n",
      "Iteration 250, Loss: 8.755156159168109e-05, Min w: 0.7932484149932861\n",
      "Iteration 260, Loss: 8.48655981826596e-05, Min w: 0.7916474938392639\n",
      "Iteration 270, Loss: 9.999221219914034e-05, Min w: 0.7890148162841797\n",
      "Iteration 280, Loss: 9.25729182199575e-05, Min w: 0.7985371351242065\n",
      "Iteration 290, Loss: 8.874473860487342e-05, Min w: 0.7950234413146973\n",
      "Iteration 300, Loss: 9.940080781234428e-05, Min w: 0.7955361604690552\n",
      "Iteration 310, Loss: 0.00010889746772591025, Min w: 0.7605524659156799\n",
      "Iteration 320, Loss: 7.000521145528182e-05, Min w: 0.8109681010246277\n",
      "Iteration 330, Loss: 6.405467865988612e-05, Min w: 0.8221256136894226\n",
      "Iteration 340, Loss: 0.0001241232530446723, Min w: 0.7334728240966797\n",
      "Iteration 350, Loss: 8.995470852823928e-05, Min w: 0.8103386759757996\n",
      "Iteration 360, Loss: 0.00010157618817174807, Min w: 0.7514678239822388\n",
      "Iteration 370, Loss: 0.00010641552216839045, Min w: 0.777746319770813\n",
      "Iteration 380, Loss: 0.00011974306835327297, Min w: 0.7368897199630737\n",
      "Iteration 390, Loss: 0.00010834609565790743, Min w: 0.7655985951423645\n",
      "Iteration 400, Loss: 8.362398511962965e-05, Min w: 0.8104380369186401\n",
      "Iteration 410, Loss: 0.00010119328362634405, Min w: 0.7780559659004211\n",
      "Iteration 420, Loss: 9.982139454223216e-05, Min w: 0.7797242403030396\n",
      "Iteration 430, Loss: 8.692419214639813e-05, Min w: 0.8071118593215942\n",
      "Iteration 440, Loss: 8.052916382439435e-05, Min w: 0.8346811532974243\n",
      "Iteration 450, Loss: 6.946524081286043e-05, Min w: 0.8340916037559509\n",
      "Iteration 460, Loss: 8.063331915764138e-05, Min w: 0.8241475224494934\n",
      "Iteration 470, Loss: 0.00010042060603154823, Min w: 0.7671447992324829\n",
      "Iteration 480, Loss: 8.596752741141245e-05, Min w: 0.822528064250946\n",
      "Iteration 490, Loss: 7.971454760991037e-05, Min w: 0.8367915749549866\n",
      "Iteration 500, Loss: 8.570927457185462e-05, Min w: 0.8180739879608154\n",
      "Iteration 510, Loss: 8.234227425418794e-05, Min w: 0.8196613788604736\n",
      "Iteration 520, Loss: 9.630295244278386e-05, Min w: 0.7860525846481323\n",
      "Iteration 530, Loss: 9.89353793556802e-05, Min w: 0.784572422504425\n",
      "Iteration 540, Loss: 9.379539551446214e-05, Min w: 0.770461916923523\n",
      "Iteration 550, Loss: 0.00010638569801812991, Min w: 0.7696875929832458\n",
      "Iteration 560, Loss: 0.00010029902477981523, Min w: 0.75909823179245\n",
      "Iteration 570, Loss: 7.812580588506535e-05, Min w: 0.8305721879005432\n",
      "Iteration 580, Loss: 8.433542097918689e-05, Min w: 0.8257825374603271\n",
      "Iteration 590, Loss: 7.432285929098725e-05, Min w: 0.8385956287384033\n",
      "Iteration 600, Loss: 7.373898552032188e-05, Min w: 0.8304736614227295\n",
      "Iteration 610, Loss: 9.416202374268323e-05, Min w: 0.7993783950805664\n",
      "Iteration 620, Loss: 6.840794958407059e-05, Min w: 0.8588963150978088\n",
      "Iteration 630, Loss: 7.764982001390308e-05, Min w: 0.8194951415061951\n",
      "Iteration 640, Loss: 9.323315316578373e-05, Min w: 0.8017407655715942\n",
      "Iteration 650, Loss: 0.00010343894973630086, Min w: 0.7712605595588684\n",
      "Iteration 660, Loss: 9.959024464478716e-05, Min w: 0.7464723587036133\n",
      "Iteration 670, Loss: 8.901327237254009e-05, Min w: 0.8057146072387695\n",
      "Iteration 680, Loss: 6.134330033091828e-05, Min w: 0.8578175902366638\n",
      "Iteration 690, Loss: 4.973467002855614e-05, Min w: 0.8785617351531982\n",
      "Iteration 700, Loss: 5.607743878499605e-05, Min w: 0.8687248229980469\n",
      "Iteration 710, Loss: 7.522657688241452e-05, Min w: 0.8300923705101013\n",
      "Iteration 720, Loss: 4.704721141024493e-05, Min w: 0.885779857635498\n",
      "Iteration 730, Loss: 7.061805081320927e-05, Min w: 0.8314553499221802\n",
      "Iteration 740, Loss: 9.305302955908701e-05, Min w: 0.7768434882164001\n",
      "Iteration 750, Loss: 0.00014868201105855405, Min w: 0.6732921004295349\n",
      "Iteration 760, Loss: 8.856417116476223e-05, Min w: 0.7584431171417236\n",
      "Iteration 770, Loss: 9.240688086720183e-05, Min w: 0.7851756811141968\n",
      "Iteration 780, Loss: 7.620910764671862e-05, Min w: 0.8157801032066345\n",
      "Iteration 790, Loss: 0.0001433661236660555, Min w: 0.5608664155006409\n",
      "Iteration 800, Loss: 0.0004898920888081193, Min w: 3.82177825365296e-33\n",
      "Iteration 810, Loss: 0.000491365441121161, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0004902244545519352, Min w: 1.2891237929579802e-05\n",
      "Iteration 830, Loss: 0.00042411513277329504, Min w: 0.00875110737979412\n",
      "Iteration 840, Loss: 0.00046895325067453086, Min w: 0.0003015274996869266\n",
      "Iteration 850, Loss: 0.00048743505612947047, Min w: 0.0001609648606972769\n",
      "Iteration 860, Loss: 0.0004290143260732293, Min w: 1.2622407666640356e-05\n",
      "Iteration 870, Loss: 0.00045955440145917237, Min w: 0.023804454132914543\n",
      "Iteration 880, Loss: 0.00046394183300435543, Min w: 1.6110018202943445e-15\n",
      "Iteration 890, Loss: 0.000495954358484596, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0004990107263438404, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0005021144170314074, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0004911570576950908, Min w: 6.34544014554983e-11\n",
      "Iteration 930, Loss: 0.0004948682035319507, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0004751602828036994, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00048129050992429256, Min w: 8.542047726223245e-05\n",
      "Iteration 960, Loss: 0.0004915769677609205, Min w: 2.929718027452795e-21\n",
      "Iteration 970, Loss: 0.0004882722860202193, Min w: 1.3595870262950172e-10\n",
      "Iteration 980, Loss: 0.0004906442482024431, Min w: 2.638034276591612e-18\n",
      "Iteration 990, Loss: 0.0004102418606635183, Min w: 0.050567641854286194\n",
      "Iteration 1000, Loss: 0.0004905204405076802, Min w: 2.0986743159284726e-12\n",
      "Iteration 1010, Loss: 0.0004979994846507907, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0004911323776468635, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0004912051954306662, Min w: 7.41957639357141e-26\n",
      "Iteration 1040, Loss: 0.0004809315432794392, Min w: 5.105027867102763e-08\n",
      "Iteration 1050, Loss: 0.0004210598417557776, Min w: 0.004506916739046574\n",
      "Iteration 1060, Loss: 0.0004910335992462933, Min w: 2.0871260449084605e-12\n",
      "Iteration 1070, Loss: 0.00043705335701815784, Min w: 3.9589674753788206e-17\n",
      "Iteration 1080, Loss: 0.0004872861609328538, Min w: 3.9205434632094693e-07\n",
      "Iteration 1090, Loss: 0.0004902721848338842, Min w: 2.3699420704847768e-15\n",
      "Iteration 1100, Loss: 0.00045928743202239275, Min w: 3.442560014832452e-08\n",
      "Iteration 1110, Loss: 0.0004912345320917666, Min w: 6.991086041237965e-14\n",
      "Iteration 1120, Loss: 0.0004903310327790678, Min w: 0.0004801551403943449\n",
      "Iteration 1130, Loss: 0.00046659400686621666, Min w: 0.002954405965283513\n",
      "Iteration 1140, Loss: 0.0004348598013166338, Min w: 3.098865272477269e-05\n",
      "Iteration 1150, Loss: 0.00033825155696831644, Min w: 0.30248674750328064\n",
      "Iteration 1160, Loss: 0.00035062897950410843, Min w: 0.03052688017487526\n",
      "Iteration 1170, Loss: 0.0004897465114481747, Min w: 1.0185553037445061e-05\n",
      "Iteration 1180, Loss: 0.0004287322226446122, Min w: 0.010504930280148983\n",
      "Iteration 1190, Loss: 0.0003688822907861322, Min w: 0.004989903420209885\n",
      "Iteration 1200, Loss: 0.0004898927290923893, Min w: 1.0479254342499189e-05\n",
      "Iteration 1210, Loss: 0.000490129052195698, Min w: 0.0018573302077129483\n",
      "Iteration 1220, Loss: 0.0004914540331810713, Min w: 1.518188244391261e-13\n",
      "Iteration 1230, Loss: 0.0004936970653943717, Min w: 2.448890086270694e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  46%|████▌     | 11/24 [16:48<20:04, 92.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.0004334482946433127, Min w: 0.10593351721763611\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04401138186330576, 'L2_avg': 0.06239417975289806, 'End_point_L1_avg': 0.01190272302349747, 'End_point_L2_avg': 0.015600304034445985}\n",
      "Iteration 0, Loss: 0.0015105848433449864, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0008178377756848931, Min w: 2.8033698883859863e-16\n",
      "Iteration 20, Loss: 0.0007740936707705259, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008241397445090115, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007189212483353913, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005292645073495805, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005266536609269679, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005635962006635964, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005724742659367621, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005416464991867542, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005973086808808148, Min w: 3.9398038817908675e-39\n",
      "Iteration 110, Loss: 0.0005541404825635254, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005352915613912046, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005452663172036409, Min w: 6.40074495142362e-12\n",
      "Iteration 140, Loss: 0.0005467800074256957, Min w: 0.0\n",
      "Iteration 150, Loss: 0.000504529569298029, Min w: 2.0412312101490198e-25\n",
      "Iteration 160, Loss: 0.0005034658242948353, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005319874617271125, Min w: 1.2076347218424243e-22\n",
      "Iteration 180, Loss: 0.0005177086568437517, Min w: 4.854574321899037e-40\n",
      "Iteration 190, Loss: 0.0005122747388668358, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005265083163976669, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005114093073643744, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005573572125285864, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004943893873132765, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005116247339174151, Min w: 2.8101886359602814e-17\n",
      "Iteration 250, Loss: 0.0005057486123405397, Min w: 6.5941421780735254e-06\n",
      "Iteration 260, Loss: 0.0005057029775343835, Min w: 3.821438720675741e-20\n",
      "Iteration 270, Loss: 0.000520705827511847, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0005286095547489822, Min w: 4.79904716399574e-36\n",
      "Iteration 290, Loss: 0.0005257724551483989, Min w: 0.0\n",
      "Iteration 300, Loss: 0.000588073511607945, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0004976083873771131, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005036601796746254, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005167931085452437, Min w: 0.0007821587496437132\n",
      "Iteration 340, Loss: 0.0005138101987540722, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0005237889126874506, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0005237623699940741, Min w: 0.0\n",
      "Iteration 370, Loss: 0.000570522213820368, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0004948127898387611, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005007841973565519, Min w: 7.434503275086785e-27\n",
      "Iteration 400, Loss: 0.0005282143247313797, Min w: 6.551786718001331e-15\n",
      "Iteration 410, Loss: 0.0004993182956241071, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005163020105101168, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0005566951003856957, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0005226543289609253, Min w: 0.0\n",
      "Iteration 450, Loss: 0.000502460403367877, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005387534038163722, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005131966900080442, Min w: 1.0637148751850305e-23\n",
      "Iteration 480, Loss: 0.0005705815274268389, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0004974547191523015, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0005137483822181821, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005889915628358722, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0005167736089788377, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000502286187838763, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005427952855825424, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0004937210469506681, Min w: 4.5038515732320665e-29\n",
      "Iteration 560, Loss: 0.000533286773134023, Min w: 0.0\n",
      "Iteration 570, Loss: 0.000517520122230053, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0005390425794757903, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005341982468962669, Min w: 0.0\n",
      "Iteration 600, Loss: 0.000507279415614903, Min w: 9.865141188846712e-43\n",
      "Iteration 610, Loss: 0.0005468724993988872, Min w: 0.0\n",
      "Iteration 620, Loss: 0.000461140793049708, Min w: 7.02403777570642e-20\n",
      "Iteration 630, Loss: 0.0005223399493843317, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005220120656304061, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0005338806658983231, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0004959921352565289, Min w: 1.3546555491638057e-22\n",
      "Iteration 670, Loss: 0.0005116838146932423, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0004933981108479202, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005110904457978904, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0004974017501808703, Min w: 1.2630043188806009e-40\n",
      "Iteration 710, Loss: 0.0005042065167799592, Min w: 1.7196055124438958e-38\n",
      "Iteration 720, Loss: 0.0005043147830292583, Min w: 3.1781835225531744e-25\n",
      "Iteration 730, Loss: 0.0005065840668976307, Min w: 1.545498971855519e-11\n",
      "Iteration 740, Loss: 0.0004983949474990368, Min w: 1.8450345418141723e-10\n",
      "Iteration 750, Loss: 0.0004991929745301604, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0005047527374699712, Min w: 8.746442432957319e-24\n",
      "Iteration 770, Loss: 0.0005111698992550373, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0005059364484623075, Min w: 4.203895392974451e-45\n",
      "Iteration 790, Loss: 0.0005242636543698609, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0005499774706549942, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005079287220723927, Min w: 3.925911408815551e-39\n",
      "Iteration 820, Loss: 0.0005082824500277638, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0005170780932530761, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0004956654738634825, Min w: 0.0\n",
      "Iteration 850, Loss: 0.000504021649248898, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0004958895733579993, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0005211796960793436, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0004960314254276454, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0005076362867839634, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0004973646719008684, Min w: 1.0795076155477106e-20\n",
      "Iteration 910, Loss: 0.0005192664102651179, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0005123409209772944, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005215879064053297, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0005275714211165905, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0005215439014136791, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0004930267459712923, Min w: 1.0611188577119846e-12\n",
      "Iteration 970, Loss: 0.0005061218980699778, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0005011173780076206, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0005201146122999489, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0005054922658018768, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0005131448269821703, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0004966059932485223, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0004714218666777015, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0005108682089485228, Min w: 7.141957025780243e-10\n",
      "Iteration 1050, Loss: 0.0005071269697509706, Min w: 8.407790785948902e-45\n",
      "Iteration 1060, Loss: 0.0005176603444851935, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0005005268030799925, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0005160332657396793, Min w: 7.029279201521959e-16\n",
      "Iteration 1090, Loss: 0.0005068531027063727, Min w: 4.203895392974451e-45\n",
      "Iteration 1100, Loss: 0.0005140120629221201, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0005205729976296425, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0005243033519946039, Min w: 3.197631902095267e-23\n",
      "Iteration 1130, Loss: 0.0005267615197226405, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0005165451439097524, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0005044644349254668, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0004964934196323156, Min w: 4.336026204754262e-09\n",
      "Iteration 1170, Loss: 0.0005123397568240762, Min w: 4.298689598864407e-28\n",
      "Iteration 1180, Loss: 0.0004936138866469264, Min w: 0.00025949577684514225\n",
      "Iteration 1190, Loss: 0.0005171956727281213, Min w: 1.2230389830828212e-32\n",
      "Iteration 1200, Loss: 0.0005111440550535917, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0005105445743538439, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.000504288705997169, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0005269151879474521, Min w: 7.006492321624085e-45\n",
      "Iteration 1240, Loss: 0.000520592846442014, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0005153227830305696, Min w: 2.4916859714831963e-31\n",
      "Iteration 10, Loss: 0.0004958044737577438, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005046157748438418, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0005040208343416452, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000545765389688313, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0004949988797307014, Min w: 3.501312844281301e-18\n",
      "Iteration 60, Loss: 0.0005052107735536993, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0004996046773158014, Min w: 3.3366014062779716e-29\n",
      "Iteration 80, Loss: 0.0005048014572821558, Min w: 1.7217320234449995e-12\n",
      "Iteration 90, Loss: 0.0004993171314708889, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005079896072857082, Min w: 1.2115348724250907e-09\n",
      "Iteration 110, Loss: 0.0004979266668669879, Min w: 1.430776591247584e-26\n",
      "Iteration 120, Loss: 0.0005031829932704568, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005174390389584005, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005063297576270998, Min w: 2.735440516397572e-26\n",
      "Iteration 150, Loss: 0.00048461882397532463, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0004954357864335179, Min w: 4.3596748433571975e-10\n",
      "Iteration 170, Loss: 0.0005026639555580914, Min w: 3.424178995903304e-11\n",
      "Iteration 180, Loss: 0.0005012673791497946, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005038934759795666, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0004974531475454569, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005051945918239653, Min w: 6.20336941313656e-22\n",
      "Iteration 220, Loss: 0.0004965876578353345, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00047573057236149907, Min w: 5.586605174994817e-29\n",
      "Iteration 240, Loss: 0.0004882921930402517, Min w: 0.025807591155171394\n",
      "Iteration 250, Loss: 0.0005143621820025146, Min w: 3.425788297830754e-21\n",
      "Iteration 260, Loss: 0.0005137728294357657, Min w: 1.5413938797080273e-20\n",
      "Iteration 270, Loss: 0.0005047944723628461, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0005187033675611019, Min w: 1.401298464324817e-45\n",
      "Iteration 290, Loss: 0.0005084701115265489, Min w: 9.960899936638495e-16\n",
      "Iteration 300, Loss: 0.0005107371835038066, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005166065529920161, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005113619263283908, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005016315262764692, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0004983277758583426, Min w: 0.0\n",
      "Iteration 350, Loss: 0.00047821830958127975, Min w: 5.0631269204151815e-34\n",
      "Iteration 360, Loss: 0.0004973715404048562, Min w: 0.00016579290968365967\n",
      "Iteration 370, Loss: 0.000512645288836211, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005118088447488844, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005324399680830538, Min w: 8.064707519811943e-38\n",
      "Iteration 400, Loss: 0.000534833176061511, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005077696987427771, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005109884077683091, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004978981451131403, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0004967083805240691, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0004889407427981496, Min w: 0.003069220343604684\n",
      "Iteration 460, Loss: 0.0005011989269405603, Min w: 6.281418457228495e-40\n",
      "Iteration 470, Loss: 0.0004991847672499716, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0005013016634620726, Min w: 6.5333086380086965e-18\n",
      "Iteration 490, Loss: 0.0005043059354647994, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0005252856644801795, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005059700924903154, Min w: 4.220016827339061e-36\n",
      "Iteration 520, Loss: 0.000496783119160682, Min w: 2.5081374381009205e-30\n",
      "Iteration 530, Loss: 0.000495511048939079, Min w: 5.66926023657408e-36\n",
      "Iteration 540, Loss: 0.0004988869768567383, Min w: 6.778392665100717e-34\n",
      "Iteration 550, Loss: 0.0005117955734021962, Min w: 1.5234967937161022e-24\n",
      "Iteration 560, Loss: 0.0005109583726152778, Min w: 8.696833361828194e-17\n",
      "Iteration 570, Loss: 0.0004726879415102303, Min w: 6.406415961804426e-37\n",
      "Iteration 580, Loss: 0.0004974957555532455, Min w: 4.416224646192009e-18\n",
      "Iteration 590, Loss: 0.0005116836982779205, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0005142381996847689, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005105831078253686, Min w: 6.473791956759922e-33\n",
      "Iteration 620, Loss: 0.000512548431288451, Min w: 0.0\n",
      "Iteration 630, Loss: 0.000499045243486762, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005331289139576256, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0004940234939567745, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0004970650188624859, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0004717299889307469, Min w: 0.0\n",
      "Iteration 680, Loss: 0.00048358747153542936, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00048562101437710226, Min w: 9.540851111672646e-19\n",
      "Iteration 700, Loss: 0.0005030938191339374, Min w: 7.837778010921297e-24\n",
      "Iteration 710, Loss: 0.0005015151691623032, Min w: 1.135402235196532e-31\n",
      "Iteration 720, Loss: 0.0005012848996557295, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0005029318854212761, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0005037885857746005, Min w: 1.5414283107572988e-43\n",
      "Iteration 750, Loss: 0.0004430933331605047, Min w: 4.793435135538134e-19\n",
      "Iteration 760, Loss: 0.000505321950186044, Min w: 1.561397411364851e-08\n",
      "Iteration 770, Loss: 0.0005065625300630927, Min w: 3.9074275057718666e-18\n",
      "Iteration 780, Loss: 0.0005172971286810935, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0005215780111029744, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0005015730857849121, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005041573313064873, Min w: 0.0\n",
      "Iteration 820, Loss: 0.000503763381857425, Min w: 8.112750310021099e-23\n",
      "Iteration 830, Loss: 0.000504524796269834, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0005008492153137922, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0004991349414922297, Min w: 1.7975912752297326e-39\n",
      "Iteration 860, Loss: 0.0004998234217055142, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0005030914908275008, Min w: 1.4776982215899806e-34\n",
      "Iteration 880, Loss: 0.0005088633042760193, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0005047571030445397, Min w: 1.401298464324817e-45\n",
      "Iteration 900, Loss: 0.0005023347912356257, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0004986930289305747, Min w: 3.2565633318881737e-06\n",
      "Iteration 920, Loss: 0.0005036747897975147, Min w: 9.326380756425663e-19\n",
      "Iteration 930, Loss: 0.000509349163621664, Min w: 2.1087101323904858e-34\n",
      "Iteration 940, Loss: 0.0005006407736800611, Min w: 1.0124381404746803e-41\n",
      "Iteration 950, Loss: 0.0005115973181091249, Min w: 3.03365359453751e-23\n",
      "Iteration 960, Loss: 0.0004951099399477243, Min w: 0.0\n",
      "Iteration 970, Loss: 0.000492830527946353, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0005062400014139712, Min w: 6.612936766085807e-20\n",
      "Iteration 990, Loss: 0.0004950868315063417, Min w: 3.308433929614452e-17\n",
      "Iteration 1000, Loss: 0.0004944775719195604, Min w: 2.1177963821187393e-40\n",
      "Iteration 1010, Loss: 0.0004254492814652622, Min w: 1.7207420113362487e-14\n",
      "Iteration 1020, Loss: 0.0005077884998172522, Min w: 4.499287383268805e-20\n",
      "Iteration 1030, Loss: 0.0005001377430744469, Min w: 1.0318377164147931e-39\n",
      "Iteration 1040, Loss: 0.0005128629854880273, Min w: 5.3469179788554323e-17\n",
      "Iteration 1050, Loss: 0.0005092047504149377, Min w: 6.826252815603391e-16\n",
      "Iteration 1060, Loss: 0.0005106013850308955, Min w: 9.825884958070277e-35\n",
      "Iteration 1070, Loss: 0.0005117501132190228, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0004936268087476492, Min w: 4.698166833350115e-08\n",
      "Iteration 1090, Loss: 0.000460562645457685, Min w: 3.1008575156372953e-13\n",
      "Iteration 1100, Loss: 0.000495829910505563, Min w: 8.47948164743876e-23\n",
      "Iteration 1110, Loss: 0.0004977126372978091, Min w: 3.12760843187409e-33\n",
      "Iteration 1120, Loss: 0.0004974111216142774, Min w: 0.0001964685070561245\n",
      "Iteration 1130, Loss: 0.0004968148423358798, Min w: 4.482303666009102e-06\n",
      "Iteration 1140, Loss: 0.0004983771941624582, Min w: 4.576292212732369e-06\n",
      "Iteration 1150, Loss: 0.0004996434436179698, Min w: 4.331841410021298e-06\n",
      "Iteration 1160, Loss: 0.0004922880907543004, Min w: 0.008552816696465015\n",
      "Iteration 1170, Loss: 0.0005079664988443255, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0004611751064658165, Min w: 1.0208854257024798e-18\n",
      "Iteration 1190, Loss: 0.0005027736187912524, Min w: 3.0244343980192453e-22\n",
      "Iteration 1200, Loss: 0.0004951743176206946, Min w: 0.0021346232388168573\n",
      "Iteration 1210, Loss: 0.0005033320630900562, Min w: 1.2681898238478349e-38\n",
      "Iteration 1220, Loss: 0.000504294759593904, Min w: 2.211910405596603e-17\n",
      "Iteration 1230, Loss: 0.0005041997064836323, Min w: 3.2119592592023515e-16\n",
      "Iteration 1240, Loss: 0.0005016453796997666, Min w: 5.3123224782553815e-42\n",
      "Iteration 0, Loss: 0.0005141504225321114, Min w: 1.3929748021723753e-08\n",
      "Iteration 10, Loss: 0.0004994715563952923, Min w: 2.8020014007805786e-16\n",
      "Iteration 20, Loss: 0.0005043129785917699, Min w: 1.202696348045231e-31\n",
      "Iteration 30, Loss: 0.0005097010871395469, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0004942051600664854, Min w: 3.749594731927708e-11\n",
      "Iteration 50, Loss: 0.0004966845735907555, Min w: 2.082771644040804e-08\n",
      "Iteration 60, Loss: 0.0004936194163747132, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0004910005372948945, Min w: 2.3216379572337472e-24\n",
      "Iteration 80, Loss: 0.0005009423475712538, Min w: 1.3329494063694328e-14\n",
      "Iteration 90, Loss: 0.0004962206585332751, Min w: 2.126275043756948e-15\n",
      "Iteration 100, Loss: 0.0005017934599891305, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0004984733532182872, Min w: 1.4648341971237435e-27\n",
      "Iteration 120, Loss: 0.0005064898286946118, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005003572441637516, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0004978994256816804, Min w: 1.657124822562403e-13\n",
      "Iteration 150, Loss: 0.0004780193557962775, Min w: 0.0\n",
      "Iteration 160, Loss: 0.00048572130617685616, Min w: 0.008431021124124527\n",
      "Iteration 170, Loss: 0.0004938357742503285, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0004949404974468052, Min w: 2.1006238970500135e-09\n",
      "Iteration 190, Loss: 0.0004985154373571277, Min w: 5.41547029442313e-09\n",
      "Iteration 200, Loss: 0.0005005124839954078, Min w: 1.0706457808450114e-19\n",
      "Iteration 210, Loss: 0.000499789894092828, Min w: 1.7714182831696235e-05\n",
      "Iteration 220, Loss: 0.0004746044578496367, Min w: 1.3363327111548529e-10\n",
      "Iteration 230, Loss: 0.0005004186532460153, Min w: 8.062184600476918e-12\n",
      "Iteration 240, Loss: 0.0004998833173885942, Min w: 7.006492321624085e-43\n",
      "Iteration 250, Loss: 0.00045920786214992404, Min w: 2.917430386162323e-08\n",
      "Iteration 260, Loss: 0.0005054783541709185, Min w: 1.266209581629596e-09\n",
      "Iteration 270, Loss: 0.0004991502501070499, Min w: 1.7879416418509209e-06\n",
      "Iteration 280, Loss: 0.0004964696709066629, Min w: 9.105148140444927e-14\n",
      "Iteration 290, Loss: 0.0004940071376040578, Min w: 6.0217396821826696e-05\n",
      "Iteration 300, Loss: 0.00034470055834390223, Min w: 0.04224557802081108\n",
      "Iteration 310, Loss: 0.0004966263077221811, Min w: 7.796537637716483e-09\n",
      "Iteration 320, Loss: 0.0004930646391585469, Min w: 0.004104109015315771\n",
      "Iteration 330, Loss: 0.0004966396372765303, Min w: 1.4408013157662936e-05\n",
      "Iteration 340, Loss: 0.0005009933956898749, Min w: 1.845854909041885e-36\n",
      "Iteration 350, Loss: 0.00047009618720039725, Min w: 0.00015464906755369157\n",
      "Iteration 360, Loss: 0.000497572822496295, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0004958267672918737, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005044809659011662, Min w: 1.0562171970374123e-10\n",
      "Iteration 390, Loss: 0.0004935981705784798, Min w: 1.1745097253879067e-05\n",
      "Iteration 400, Loss: 0.0004729263891931623, Min w: 0.020013783127069473\n",
      "Iteration 410, Loss: 0.00048747577238827944, Min w: 0.006762025877833366\n",
      "Iteration 420, Loss: 0.0004987157299183309, Min w: 1.7731553259101723e-13\n",
      "Iteration 430, Loss: 0.00044277601409703493, Min w: 0.07958783209323883\n",
      "Iteration 440, Loss: 0.0005007512518204749, Min w: 1.8757482393993996e-05\n",
      "Iteration 450, Loss: 0.0005028282757848501, Min w: 1.841484631448509e-09\n",
      "Iteration 460, Loss: 0.0004984117695130408, Min w: 4.124434838104207e-08\n",
      "Iteration 470, Loss: 0.0004948883433826268, Min w: 4.331016878467153e-09\n",
      "Iteration 480, Loss: 0.0004754341207444668, Min w: 0.030785653740167618\n",
      "Iteration 490, Loss: 0.0004952893941663206, Min w: 1.2221755273808445e-33\n",
      "Iteration 500, Loss: 0.0005022912519052625, Min w: 3.665924726547937e-21\n",
      "Iteration 510, Loss: 0.000488115445477888, Min w: 0.016460197046399117\n",
      "Iteration 520, Loss: 0.00047486467519775033, Min w: 0.017218777909874916\n",
      "Iteration 530, Loss: 0.000500035414006561, Min w: 1.401298464324817e-45\n",
      "Iteration 540, Loss: 0.0004982579266652465, Min w: 5.014498538624679e-11\n",
      "Iteration 550, Loss: 0.0005044060526415706, Min w: 4.470904713116397e-08\n",
      "Iteration 560, Loss: 0.0004963178071193397, Min w: 2.80671629018586e-33\n",
      "Iteration 570, Loss: 0.000497101282235235, Min w: 1.1519994349018938e-29\n",
      "Iteration 580, Loss: 0.00048395554767921567, Min w: 0.0010879598557949066\n",
      "Iteration 590, Loss: 0.0004943893873132765, Min w: 4.408231159275207e-25\n",
      "Iteration 600, Loss: 0.0004956074408255517, Min w: 2.4100052087305812e-06\n",
      "Iteration 610, Loss: 0.0004943515523336828, Min w: 9.849230764302774e-08\n",
      "Iteration 620, Loss: 0.0004789645900018513, Min w: 3.902226580976276e-06\n",
      "Iteration 630, Loss: 0.0004920497303828597, Min w: 0.0002486981393303722\n",
      "Iteration 640, Loss: 0.0004128567816223949, Min w: 0.02648870088160038\n",
      "Iteration 650, Loss: 0.0004956376506015658, Min w: 0.00020265889179427177\n",
      "Iteration 660, Loss: 0.00045748191769234836, Min w: 0.0012821212876588106\n",
      "Iteration 670, Loss: 0.0004727969935629517, Min w: 0.038044486194849014\n",
      "Iteration 680, Loss: 0.000491167011205107, Min w: 0.00029865559190511703\n",
      "Iteration 690, Loss: 0.0004241064307279885, Min w: 0.08656439185142517\n",
      "Iteration 700, Loss: 0.0004962872480973601, Min w: 5.672146305706234e-14\n",
      "Iteration 710, Loss: 0.0004995979834347963, Min w: 3.286862693130388e-08\n",
      "Iteration 720, Loss: 0.0005063874996267259, Min w: 9.403996957636107e-37\n",
      "Iteration 730, Loss: 0.0005008133593946695, Min w: 3.3486328447907e-06\n",
      "Iteration 740, Loss: 0.0005015776259824634, Min w: 3.7233969669167603e-22\n",
      "Iteration 750, Loss: 0.0004998463555239141, Min w: 9.218630775331474e-36\n",
      "Iteration 760, Loss: 0.000500656955409795, Min w: 6.209997065322959e-15\n",
      "Iteration 770, Loss: 0.0004951808368787169, Min w: 0.0001780685706762597\n",
      "Iteration 780, Loss: 0.0003586065722629428, Min w: 0.016825584694743156\n",
      "Iteration 790, Loss: 0.0004955657059326768, Min w: 3.0855841714182946e-27\n",
      "Iteration 800, Loss: 0.0004960289807058871, Min w: 3.510449015648059e-32\n",
      "Iteration 810, Loss: 0.0004999140510335565, Min w: 1.8114311221516057e-28\n",
      "Iteration 820, Loss: 0.0004938350175507367, Min w: 6.899370055180043e-05\n",
      "Iteration 830, Loss: 0.0004956266493536532, Min w: 5.577587782254062e-25\n",
      "Iteration 840, Loss: 0.0004962730454280972, Min w: 3.040814399325048e-15\n",
      "Iteration 850, Loss: 0.0004953548777848482, Min w: 3.940146366317929e-26\n",
      "Iteration 860, Loss: 0.0004946074332110584, Min w: 8.162256310437224e-17\n",
      "Iteration 870, Loss: 0.0004965286352671683, Min w: 3.2194349408598555e-09\n",
      "Iteration 880, Loss: 0.00050309335347265, Min w: 6.237418280604413e-30\n",
      "Iteration 890, Loss: 0.0004985487321391702, Min w: 1.3129262773214046e-38\n",
      "Iteration 900, Loss: 0.0004923953674733639, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0004944524844177067, Min w: 4.849471145198218e-21\n",
      "Iteration 920, Loss: 0.0004984785337001085, Min w: 0.00014605173782911152\n",
      "Iteration 930, Loss: 0.0004959257785230875, Min w: 6.452798186014053e-29\n",
      "Iteration 940, Loss: 0.0004914106102660298, Min w: 0.005330083426088095\n",
      "Iteration 950, Loss: 0.0004972394090145826, Min w: 1.8679123525711105e-10\n",
      "Iteration 960, Loss: 0.00047104927944019437, Min w: 1.5783818696490926e-07\n",
      "Iteration 970, Loss: 0.000493968662340194, Min w: 3.1322069657745066e-32\n",
      "Iteration 980, Loss: 0.0004977434291504323, Min w: 8.585751475891795e-16\n",
      "Iteration 990, Loss: 0.0004976660129614174, Min w: 5.872344903066948e-19\n",
      "Iteration 1000, Loss: 0.0005015248898416758, Min w: 3.992187220984258e-40\n",
      "Iteration 1010, Loss: 0.0004959411453455687, Min w: 4.854701529666272e-09\n",
      "Iteration 1020, Loss: 0.0004944142419844866, Min w: 1.7591666889271432e-19\n",
      "Iteration 1030, Loss: 0.0004894717130810022, Min w: 1.3652363961558223e-10\n",
      "Iteration 1040, Loss: 0.0004933883901685476, Min w: 1.627517121960409e-06\n",
      "Iteration 1050, Loss: 0.0004904748639091849, Min w: 5.1304143156016835e-09\n",
      "Iteration 1060, Loss: 0.0004963574465364218, Min w: 7.387511276619877e-21\n",
      "Iteration 1070, Loss: 0.0004935688921250403, Min w: 5.834096588530379e-19\n",
      "Iteration 1080, Loss: 0.0004933158634230494, Min w: 1.0651847404119508e-08\n",
      "Iteration 1090, Loss: 0.0004979539662599564, Min w: 2.6293556091086523e-13\n",
      "Iteration 1100, Loss: 0.0004897636245004833, Min w: 6.335057027803205e-32\n",
      "Iteration 1110, Loss: 0.00048820258234627545, Min w: 9.550149115966633e-09\n",
      "Iteration 1120, Loss: 0.0004990973975509405, Min w: 1.3071647493671226e-15\n",
      "Iteration 1130, Loss: 0.00044814401189796627, Min w: 1.0151643181448202e-27\n",
      "Iteration 1140, Loss: 0.0004928488051518798, Min w: 1.390754039709563e-10\n",
      "Iteration 1150, Loss: 0.0004898174083791673, Min w: 7.4261437131534e-19\n",
      "Iteration 1160, Loss: 0.00049725262215361, Min w: 5.913476798014017e-06\n",
      "Iteration 1170, Loss: 0.0004982571117579937, Min w: 3.780132118883383e-35\n",
      "Iteration 1180, Loss: 0.0004982702666893601, Min w: 3.107028234694553e-08\n",
      "Iteration 1190, Loss: 0.000496722524985671, Min w: 2.0643524578645156e-07\n",
      "Iteration 1200, Loss: 0.0004828493983950466, Min w: 2.749109626165591e-06\n",
      "Iteration 1210, Loss: 0.0004875177110079676, Min w: 0.004740414675325155\n",
      "Iteration 1220, Loss: 0.0003203574160579592, Min w: 0.018615154549479485\n",
      "Iteration 1230, Loss: 0.00037160381907597184, Min w: 0.0078027271665632725\n",
      "Iteration 1240, Loss: 0.000325740227708593, Min w: 0.06388029456138611\n",
      "Iteration 0, Loss: 0.0003562594356480986, Min w: 0.06417618691921234\n",
      "Iteration 10, Loss: 0.0004645606386475265, Min w: 0.044345561414957047\n",
      "Iteration 20, Loss: 0.00036081846337765455, Min w: 0.01610947959125042\n",
      "Iteration 30, Loss: 0.00030410883482545614, Min w: 0.0867287665605545\n",
      "Iteration 40, Loss: 0.0004344398039393127, Min w: 0.10874967277050018\n",
      "Iteration 50, Loss: 0.0003396677493583411, Min w: 0.1447112262248993\n",
      "Iteration 60, Loss: 0.000300982384942472, Min w: 0.16716943681240082\n",
      "Iteration 70, Loss: 0.0003683243121486157, Min w: 0.1512327939271927\n",
      "Iteration 80, Loss: 0.0002631993847899139, Min w: 0.19091060757637024\n",
      "Iteration 90, Loss: 0.00037522902130149305, Min w: 0.16811047494411469\n",
      "Iteration 100, Loss: 0.0004210451152175665, Min w: 0.1460530012845993\n",
      "Iteration 110, Loss: 0.00042662801570259035, Min w: 0.13752152025699615\n",
      "Iteration 120, Loss: 0.000279237370705232, Min w: 0.24562160670757294\n",
      "Iteration 130, Loss: 0.0002646936336532235, Min w: 0.26834410429000854\n",
      "Iteration 140, Loss: 0.00037099013570696115, Min w: 0.21527083218097687\n",
      "Iteration 150, Loss: 0.0003275217313785106, Min w: 0.22140169143676758\n",
      "Iteration 160, Loss: 0.0004947423003613949, Min w: 4.6391133423639985e-07\n",
      "Iteration 170, Loss: 0.00048605617485009134, Min w: 0.005060110706835985\n",
      "Iteration 180, Loss: 0.0004960458027198911, Min w: 5.275793135695039e-09\n",
      "Iteration 190, Loss: 0.0005051605403423309, Min w: 7.6070427894592285e-06\n",
      "Iteration 200, Loss: 0.0004964951076544821, Min w: 2.5415575422016445e-08\n",
      "Iteration 210, Loss: 0.0004478931368794292, Min w: 0.0010762270539999008\n",
      "Iteration 220, Loss: 0.0005040578544139862, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004969022702425718, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005040683900006115, Min w: 1.0461842510161948e-25\n",
      "Iteration 250, Loss: 0.00042905693408101797, Min w: 0.06941276043653488\n",
      "Iteration 260, Loss: 0.0003922891628462821, Min w: 0.07732821255922318\n",
      "Iteration 270, Loss: 0.0003226530971005559, Min w: 0.1171756237745285\n",
      "Iteration 280, Loss: 0.0004843441129196435, Min w: 0.00026798926410265267\n",
      "Iteration 290, Loss: 0.0004494672466535121, Min w: 0.02410099282860756\n",
      "Iteration 300, Loss: 0.00047832130803726614, Min w: 0.029474373906850815\n",
      "Iteration 310, Loss: 0.0004937266930937767, Min w: 3.6350655818750965e-10\n",
      "Iteration 320, Loss: 0.00048696386511437595, Min w: 0.010893532074987888\n",
      "Iteration 330, Loss: 0.0004963556420989335, Min w: 2.1651189413378347e-13\n",
      "Iteration 340, Loss: 0.0005003682454116642, Min w: 1.466738581257232e-06\n",
      "Iteration 350, Loss: 0.000500179361552, Min w: 1.6050198947681338e-09\n",
      "Iteration 360, Loss: 0.00047084075049497187, Min w: 0.022561553865671158\n",
      "Iteration 370, Loss: 0.0004944473039358854, Min w: 5.3250918058031786e-34\n",
      "Iteration 380, Loss: 0.0004878735344391316, Min w: 3.9388206993992116e-35\n",
      "Iteration 390, Loss: 0.000455803849035874, Min w: 7.58300984671223e-06\n",
      "Iteration 400, Loss: 0.0004809112870134413, Min w: 0.000675300310831517\n",
      "Iteration 410, Loss: 0.00037690383032895625, Min w: 0.09870089590549469\n",
      "Iteration 420, Loss: 0.0002572732337284833, Min w: 0.2247152179479599\n",
      "Iteration 430, Loss: 0.0004583403351716697, Min w: 0.03424527868628502\n",
      "Iteration 440, Loss: 0.00048455383512191474, Min w: 0.011311526410281658\n",
      "Iteration 450, Loss: 0.0004603851994033903, Min w: 0.018671918660402298\n",
      "Iteration 460, Loss: 0.0004213212232571095, Min w: 0.09733682125806808\n",
      "Iteration 470, Loss: 0.00047838949831202626, Min w: 3.413741069380194e-06\n",
      "Iteration 480, Loss: 0.00048247791710309684, Min w: 0.010929735377430916\n",
      "Iteration 490, Loss: 0.00046076407306827605, Min w: 0.034408193081617355\n",
      "Iteration 500, Loss: 0.0004052941221743822, Min w: 0.17662741243839264\n",
      "Iteration 510, Loss: 0.00029663415625691414, Min w: 0.20863030850887299\n",
      "Iteration 520, Loss: 0.00028787192422896624, Min w: 0.20751509070396423\n",
      "Iteration 530, Loss: 0.00022835697745904326, Min w: 0.290265291929245\n",
      "Iteration 540, Loss: 0.0002608968352433294, Min w: 0.3021872043609619\n",
      "Iteration 550, Loss: 0.0002233741688542068, Min w: 0.31230369210243225\n",
      "Iteration 560, Loss: 0.0003066358622163534, Min w: 0.2880932688713074\n",
      "Iteration 570, Loss: 0.00021511627710424364, Min w: 0.34820041060447693\n",
      "Iteration 580, Loss: 0.0003285881248302758, Min w: 0.3428221046924591\n",
      "Iteration 590, Loss: 0.0002667892549652606, Min w: 0.3611442744731903\n",
      "Iteration 600, Loss: 0.00022242343402467668, Min w: 0.3916836082935333\n",
      "Iteration 610, Loss: 0.00030349608277902007, Min w: 0.3845382034778595\n",
      "Iteration 620, Loss: 0.00020877363567706198, Min w: 0.4105653762817383\n",
      "Iteration 630, Loss: 0.00022225201246328652, Min w: 0.4412274658679962\n",
      "Iteration 640, Loss: 0.00026045343838632107, Min w: 0.39944544434547424\n",
      "Iteration 650, Loss: 0.0002237127482658252, Min w: 0.45026132464408875\n",
      "Iteration 660, Loss: 0.00024762668181210756, Min w: 0.40775004029273987\n",
      "Iteration 670, Loss: 0.0002145034959539771, Min w: 0.43083977699279785\n",
      "Iteration 680, Loss: 0.00024270283756777644, Min w: 0.41671985387802124\n",
      "Iteration 690, Loss: 0.0002196409914176911, Min w: 0.4424034357070923\n",
      "Iteration 700, Loss: 0.00019262335263192654, Min w: 0.4539199769496918\n",
      "Iteration 710, Loss: 0.00019410153618082404, Min w: 0.4584784507751465\n",
      "Iteration 720, Loss: 0.00021308248688001186, Min w: 0.449614554643631\n",
      "Iteration 730, Loss: 0.00022578073549084365, Min w: 0.4710032641887665\n",
      "Iteration 740, Loss: 0.00019548271666280925, Min w: 0.473224937915802\n",
      "Iteration 750, Loss: 0.0002006397262448445, Min w: 0.47143396735191345\n",
      "Iteration 760, Loss: 0.00023217915440909564, Min w: 0.47578197717666626\n",
      "Iteration 770, Loss: 0.0001926440017996356, Min w: 0.47394511103630066\n",
      "Iteration 780, Loss: 0.00021409356850199401, Min w: 0.47554144263267517\n",
      "Iteration 790, Loss: 0.00019265664741396904, Min w: 0.4884880781173706\n",
      "Iteration 800, Loss: 0.00019252669881097972, Min w: 0.49017199873924255\n",
      "Iteration 810, Loss: 0.00019870429241564125, Min w: 0.4853324592113495\n",
      "Iteration 820, Loss: 0.00020999836851842701, Min w: 0.42189332842826843\n",
      "Iteration 830, Loss: 0.00020880938973277807, Min w: 0.47016027569770813\n",
      "Iteration 840, Loss: 0.00024821225088089705, Min w: 0.36633166670799255\n",
      "Iteration 850, Loss: 0.00020218949066475034, Min w: 0.46546006202697754\n",
      "Iteration 860, Loss: 0.00018519340665079653, Min w: 0.4853261113166809\n",
      "Iteration 870, Loss: 0.00018325986457057297, Min w: 0.4852171242237091\n",
      "Iteration 880, Loss: 0.00017280687461607158, Min w: 0.5113241076469421\n",
      "Iteration 890, Loss: 0.00020276228315196931, Min w: 0.46426865458488464\n",
      "Iteration 900, Loss: 0.00017436347843613476, Min w: 0.5093792080879211\n",
      "Iteration 910, Loss: 0.0001939848152687773, Min w: 0.488362580537796\n",
      "Iteration 920, Loss: 0.00016557442722842097, Min w: 0.5130952596664429\n",
      "Iteration 930, Loss: 0.00018602830823510885, Min w: 0.5021843314170837\n",
      "Iteration 940, Loss: 0.0001847880776040256, Min w: 0.4886627793312073\n",
      "Iteration 950, Loss: 0.00017505887080915272, Min w: 0.5355475544929504\n",
      "Iteration 960, Loss: 0.00017005152767524123, Min w: 0.5315002202987671\n",
      "Iteration 970, Loss: 0.00017992337234318256, Min w: 0.4996922016143799\n",
      "Iteration 980, Loss: 0.00017631113587412983, Min w: 0.5173765420913696\n",
      "Iteration 990, Loss: 0.00017480531823821366, Min w: 0.5236458778381348\n",
      "Iteration 1000, Loss: 0.00019763024465646595, Min w: 0.49078822135925293\n",
      "Iteration 1010, Loss: 0.00019215326756238937, Min w: 0.4971545338630676\n",
      "Iteration 1020, Loss: 0.00020885633421130478, Min w: 0.4916794002056122\n",
      "Iteration 1030, Loss: 0.0001859675976447761, Min w: 0.48786479234695435\n",
      "Iteration 1040, Loss: 0.00019126445113215595, Min w: 0.5068119168281555\n",
      "Iteration 1050, Loss: 0.00019797711865976453, Min w: 0.5099440217018127\n",
      "Iteration 1060, Loss: 0.00018770094902720302, Min w: 0.509445309638977\n",
      "Iteration 1070, Loss: 0.00016883319767657667, Min w: 0.5237186551094055\n",
      "Iteration 1080, Loss: 0.00016806302301120013, Min w: 0.5153516530990601\n",
      "Iteration 1090, Loss: 0.0001738782157190144, Min w: 0.5105339884757996\n",
      "Iteration 1100, Loss: 0.00018520132289268076, Min w: 0.520855724811554\n",
      "Iteration 1110, Loss: 0.00019212097686249763, Min w: 0.48440390825271606\n",
      "Iteration 1120, Loss: 0.00017003074754029512, Min w: 0.5402395129203796\n",
      "Iteration 1130, Loss: 0.00014672722318209708, Min w: 0.5585852861404419\n",
      "Iteration 1140, Loss: 0.0001470879215048626, Min w: 0.5723784565925598\n",
      "Iteration 1150, Loss: 0.0001729940267978236, Min w: 0.5578672885894775\n",
      "Iteration 1160, Loss: 0.00018192519200965762, Min w: 0.5386234521865845\n",
      "Iteration 1170, Loss: 0.00016819978191051632, Min w: 0.5743716359138489\n",
      "Iteration 1180, Loss: 0.0001387308002449572, Min w: 0.5774588584899902\n",
      "Iteration 1190, Loss: 0.0001619415415916592, Min w: 0.5737999081611633\n",
      "Iteration 1200, Loss: 0.00017379739438183606, Min w: 0.5860039591789246\n",
      "Iteration 1210, Loss: 0.00017902681429404765, Min w: 0.5800330638885498\n",
      "Iteration 1220, Loss: 0.00017208995996043086, Min w: 0.5504034161567688\n",
      "Iteration 1230, Loss: 0.00016972057346720248, Min w: 0.5662094950675964\n",
      "Iteration 1240, Loss: 0.00016924776718951762, Min w: 0.588733434677124\n",
      "Iteration 0, Loss: 0.0001760609884513542, Min w: 0.5726949572563171\n",
      "Iteration 10, Loss: 0.00015978753799572587, Min w: 0.5736337304115295\n",
      "Iteration 20, Loss: 0.00014537121751345694, Min w: 0.5956594347953796\n",
      "Iteration 30, Loss: 0.00015519688895437866, Min w: 0.5925557613372803\n",
      "Iteration 40, Loss: 0.00014305725926533341, Min w: 0.6129528284072876\n",
      "Iteration 50, Loss: 0.00013945777027402073, Min w: 0.6120257377624512\n",
      "Iteration 60, Loss: 0.00014954412472434342, Min w: 0.5888752341270447\n",
      "Iteration 70, Loss: 0.00015898146375548095, Min w: 0.5803008079528809\n",
      "Iteration 80, Loss: 0.0001864252844825387, Min w: 0.5892268419265747\n",
      "Iteration 90, Loss: 0.00019202353723812848, Min w: 0.5825011134147644\n",
      "Iteration 100, Loss: 0.0001814802672015503, Min w: 0.5564864873886108\n",
      "Iteration 110, Loss: 0.0001381886686431244, Min w: 0.608374834060669\n",
      "Iteration 120, Loss: 0.00013977994967717677, Min w: 0.6047014594078064\n",
      "Iteration 130, Loss: 0.00013704758021049201, Min w: 0.6103816628456116\n",
      "Iteration 140, Loss: 0.000133554931380786, Min w: 0.6269207000732422\n",
      "Iteration 150, Loss: 0.0001440852356608957, Min w: 0.6287361979484558\n",
      "Iteration 160, Loss: 0.00015626332606188953, Min w: 0.59922856092453\n",
      "Iteration 170, Loss: 0.00016048359975684434, Min w: 0.6215240955352783\n",
      "Iteration 180, Loss: 0.0001617804227862507, Min w: 0.6106188893318176\n",
      "Iteration 190, Loss: 0.00016280887939501554, Min w: 0.5803874135017395\n",
      "Iteration 200, Loss: 0.0001228008040925488, Min w: 0.6391220688819885\n",
      "Iteration 210, Loss: 0.0001374321145704016, Min w: 0.6167476773262024\n",
      "Iteration 220, Loss: 0.00013611318718176335, Min w: 0.6386918425559998\n",
      "Iteration 230, Loss: 0.00014292108244262636, Min w: 0.6230974197387695\n",
      "Iteration 240, Loss: 0.00018002309661824256, Min w: 0.6280897855758667\n",
      "Iteration 250, Loss: 0.00016865872021298856, Min w: 0.5593258738517761\n",
      "Iteration 260, Loss: 0.00014323642244562507, Min w: 0.6420218348503113\n",
      "Iteration 270, Loss: 0.00017293931159656495, Min w: 0.6163405179977417\n",
      "Iteration 280, Loss: 0.00015870911011006683, Min w: 0.6234162449836731\n",
      "Iteration 290, Loss: 0.00016456304001621902, Min w: 0.6341266632080078\n",
      "Iteration 300, Loss: 0.00016905464872252196, Min w: 0.6119646430015564\n",
      "Iteration 310, Loss: 0.00015583664935547858, Min w: 0.6465739607810974\n",
      "Iteration 320, Loss: 0.00015998980961740017, Min w: 0.625997006893158\n",
      "Iteration 330, Loss: 0.00015652012370992452, Min w: 0.6476492881774902\n",
      "Iteration 340, Loss: 0.0001572401961311698, Min w: 0.6473509669303894\n",
      "Iteration 350, Loss: 0.00012507227074820548, Min w: 0.6734795570373535\n",
      "Iteration 360, Loss: 0.0001640585105633363, Min w: 0.6522640585899353\n",
      "Iteration 370, Loss: 0.00017853455210570246, Min w: 0.6274427771568298\n",
      "Iteration 380, Loss: 0.0001493865711381659, Min w: 0.6614944934844971\n",
      "Iteration 390, Loss: 0.0001435599260730669, Min w: 0.6649543046951294\n",
      "Iteration 400, Loss: 0.0001747690257616341, Min w: 0.6374374628067017\n",
      "Iteration 410, Loss: 0.0001464666420361027, Min w: 0.6625508069992065\n",
      "Iteration 420, Loss: 0.00015792758495081216, Min w: 0.658016562461853\n",
      "Iteration 430, Loss: 0.00016004632925614715, Min w: 0.66201251745224\n",
      "Iteration 440, Loss: 0.0001321138843195513, Min w: 0.6958090662956238\n",
      "Iteration 450, Loss: 0.00012284130207262933, Min w: 0.7043092846870422\n",
      "Iteration 460, Loss: 0.00013919798948336393, Min w: 0.6861953139305115\n",
      "Iteration 470, Loss: 0.00015937061107251793, Min w: 0.6760004758834839\n",
      "Iteration 480, Loss: 0.00015112893015611917, Min w: 0.6844239830970764\n",
      "Iteration 490, Loss: 0.00012515387788880616, Min w: 0.7052525877952576\n",
      "Iteration 500, Loss: 0.00013951737491879612, Min w: 0.6932206153869629\n",
      "Iteration 510, Loss: 0.00014149198250379413, Min w: 0.68587327003479\n",
      "Iteration 520, Loss: 0.00012488233915064484, Min w: 0.7233756184577942\n",
      "Iteration 530, Loss: 0.00012226762191858143, Min w: 0.7264050841331482\n",
      "Iteration 540, Loss: 0.00011586263281060383, Min w: 0.7495778799057007\n",
      "Iteration 550, Loss: 0.00014705286594107747, Min w: 0.6656506657600403\n",
      "Iteration 560, Loss: 0.00014414604811463505, Min w: 0.6964737176895142\n",
      "Iteration 570, Loss: 0.0001421591150574386, Min w: 0.7105646133422852\n",
      "Iteration 580, Loss: 0.00013688094622921199, Min w: 0.7085769176483154\n",
      "Iteration 590, Loss: 0.00011474843631731346, Min w: 0.7539249658584595\n",
      "Iteration 600, Loss: 0.00012589653488248587, Min w: 0.7300231456756592\n",
      "Iteration 610, Loss: 0.00012526889622677118, Min w: 0.7436052560806274\n",
      "Iteration 620, Loss: 0.00014106255548540503, Min w: 0.6970226168632507\n",
      "Iteration 630, Loss: 0.00010865496005862951, Min w: 0.7557450532913208\n",
      "Iteration 640, Loss: 0.00010653812933014706, Min w: 0.7682818174362183\n",
      "Iteration 650, Loss: 0.00013491914432961494, Min w: 0.719363272190094\n",
      "Iteration 660, Loss: 0.00014941435074433684, Min w: 0.6651683449745178\n",
      "Iteration 670, Loss: 0.00010957573249470443, Min w: 0.76060950756073\n",
      "Iteration 680, Loss: 0.00011134357191622257, Min w: 0.7739410996437073\n",
      "Iteration 690, Loss: 0.00010721122816903517, Min w: 0.7818392515182495\n",
      "Iteration 700, Loss: 0.0001018125913105905, Min w: 0.771350622177124\n",
      "Iteration 710, Loss: 0.00010756712435977533, Min w: 0.7822405099868774\n",
      "Iteration 720, Loss: 0.0001292344240937382, Min w: 0.7163755893707275\n",
      "Iteration 730, Loss: 0.0001238341210409999, Min w: 0.7409711480140686\n",
      "Iteration 740, Loss: 0.00012123106716899201, Min w: 0.7502356171607971\n",
      "Iteration 750, Loss: 9.535047865938395e-05, Min w: 0.8010344505310059\n",
      "Iteration 760, Loss: 0.00011198218999197707, Min w: 0.7521898746490479\n",
      "Iteration 770, Loss: 0.00010117033525602892, Min w: 0.7919486165046692\n",
      "Iteration 780, Loss: 0.00011315740266581997, Min w: 0.7565494179725647\n",
      "Iteration 790, Loss: 0.00012886672629974782, Min w: 0.6920091509819031\n",
      "Iteration 800, Loss: 0.0001242230791831389, Min w: 0.7192447185516357\n",
      "Iteration 810, Loss: 0.00010483910591574386, Min w: 0.7769277095794678\n",
      "Iteration 820, Loss: 9.063009929377586e-05, Min w: 0.8027889728546143\n",
      "Iteration 830, Loss: 0.00011288144014542922, Min w: 0.7270730137825012\n",
      "Iteration 840, Loss: 0.00011941781122004613, Min w: 0.7549810409545898\n",
      "Iteration 850, Loss: 0.00010415364522486925, Min w: 0.7529348731040955\n",
      "Iteration 860, Loss: 9.339519601780921e-05, Min w: 0.785334050655365\n",
      "Iteration 870, Loss: 9.652974404161796e-05, Min w: 0.7775651812553406\n",
      "Iteration 880, Loss: 0.00010213077621301636, Min w: 0.7527343034744263\n",
      "Iteration 890, Loss: 0.00011699567403411493, Min w: 0.7225490808486938\n",
      "Iteration 900, Loss: 0.00011418896610848606, Min w: 0.7283724546432495\n",
      "Iteration 910, Loss: 0.0001427924435120076, Min w: 0.5921249389648438\n",
      "Iteration 920, Loss: 0.00013704239972867072, Min w: 0.7121943831443787\n",
      "Iteration 930, Loss: 6.964364729356021e-05, Min w: 0.8254493474960327\n",
      "Iteration 940, Loss: 0.0001926558034028858, Min w: 0.4689285159111023\n",
      "Iteration 950, Loss: 0.0004291421500965953, Min w: 0.06206469237804413\n",
      "Iteration 960, Loss: 0.0004903243971057236, Min w: 6.588590650835613e-08\n",
      "Iteration 970, Loss: 0.0004908920964226127, Min w: 2.6905955816105218e-20\n",
      "Iteration 980, Loss: 0.0004950601723976433, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0004944023676216602, Min w: 6.9633404902035e-21\n",
      "Iteration 1000, Loss: 0.00046186885447241366, Min w: 5.175612861161248e-25\n",
      "Iteration 1010, Loss: 0.0004920657374896109, Min w: 3.215966521868761e-32\n",
      "Iteration 1020, Loss: 0.00048094664816744626, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.00038645853055641055, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0004898590850643814, Min w: 0.0009185257367789745\n",
      "Iteration 1050, Loss: 0.000486017728690058, Min w: 0.00020902119285892695\n",
      "Iteration 1060, Loss: 0.0004932883311994374, Min w: 3.3197689042197e-09\n",
      "Iteration 1070, Loss: 0.0004948914865963161, Min w: 3.840000886157213e-07\n",
      "Iteration 1080, Loss: 0.0005080004339106381, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0004957534256391227, Min w: 2.463014666595944e-38\n",
      "Iteration 1100, Loss: 0.0004847076197620481, Min w: 6.401797511833328e-15\n",
      "Iteration 1110, Loss: 0.000493785017170012, Min w: 2.061437776035291e-08\n",
      "Iteration 1120, Loss: 0.0004923602100461721, Min w: 1.8578495245593623e-29\n",
      "Iteration 1130, Loss: 0.00046591050340794027, Min w: 2.3099275080000803e-21\n",
      "Iteration 1140, Loss: 0.0004897821345366538, Min w: 2.171981261511746e-09\n",
      "Iteration 1150, Loss: 0.0004997571231797338, Min w: 1.3270296457156018e-42\n",
      "Iteration 1160, Loss: 0.0003951912513002753, Min w: 0.10648784786462784\n",
      "Iteration 1170, Loss: 0.00039264268707484007, Min w: 9.415830390935298e-06\n",
      "Iteration 1180, Loss: 0.0004048824484925717, Min w: 5.837729744051501e-10\n",
      "Iteration 1190, Loss: 0.00048751727445051074, Min w: 3.0647439416497946e-05\n",
      "Iteration 1200, Loss: 0.0004907998372800648, Min w: 6.718638407198707e-35\n",
      "Iteration 1210, Loss: 0.0004937076009809971, Min w: 1.48697943633729e-24\n",
      "Iteration 1220, Loss: 0.0004988177679479122, Min w: 1.5515967399792885e-09\n",
      "Iteration 1230, Loss: 0.0004900872590951622, Min w: 0.00048710222472436726\n",
      "Iteration 1240, Loss: 0.0005032883491367102, Min w: 1.0898808522341596e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  50%|█████     | 12/24 [18:46<20:03, 100.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.12851030800057459, 'L2_avg': 0.135917240937764, 'End_point_L1_avg': 0.0965087133884605, 'End_point_L2_avg': 0.09737138033473348}\n",
      "Iteration 0, Loss: 0.005818175617605448, Min w: 1.5345441004404304e-24\n",
      "Iteration 10, Loss: 0.005223029758781195, Min w: 3.6878439719323295e-38\n",
      "Iteration 20, Loss: 0.004960284102708101, Min w: 3.592518210865831e-32\n",
      "Iteration 30, Loss: 0.004460134543478489, Min w: 2.470487839868942e-29\n",
      "Iteration 40, Loss: 0.0042091310024261475, Min w: 7.59390787435185e-25\n",
      "Iteration 50, Loss: 0.0038636631797999144, Min w: 8.808067962883258e-20\n",
      "Iteration 60, Loss: 0.0036550324875861406, Min w: 6.425523778188648e-17\n",
      "Iteration 70, Loss: 0.0032807234674692154, Min w: 6.478576355939403e-13\n",
      "Iteration 80, Loss: 0.003098367480561137, Min w: 7.297392135008351e-10\n",
      "Iteration 90, Loss: 0.002926231361925602, Min w: 1.6265938711512717e-06\n",
      "Iteration 100, Loss: 0.002602526918053627, Min w: 0.00017946229490917176\n",
      "Iteration 110, Loss: 0.0023895204067230225, Min w: 0.0007352878456003964\n",
      "Iteration 120, Loss: 0.002238604472950101, Min w: 0.0006295667844824493\n",
      "Iteration 130, Loss: 0.002244015922769904, Min w: 0.0003305566788185388\n",
      "Iteration 140, Loss: 0.002075748983770609, Min w: 0.00027822499396279454\n",
      "Iteration 150, Loss: 0.0020738544408231974, Min w: 0.00010061950160888955\n",
      "Iteration 160, Loss: 0.0019303036388009787, Min w: 2.3865177354309708e-05\n",
      "Iteration 170, Loss: 0.0019251598278060555, Min w: 4.03188687414513e-06\n",
      "Iteration 180, Loss: 0.0018946562195196748, Min w: 2.822091573762009e-06\n",
      "Iteration 190, Loss: 0.0018459584098309278, Min w: 6.019718057359569e-05\n",
      "Iteration 200, Loss: 0.001799704390577972, Min w: 0.00016996997874230146\n",
      "Iteration 210, Loss: 0.0017503165872767568, Min w: 0.00040423322934657335\n",
      "Iteration 220, Loss: 0.001789871254004538, Min w: 0.0027598522137850523\n",
      "Iteration 230, Loss: 0.0016447978559881449, Min w: 0.013437733985483646\n",
      "Iteration 240, Loss: 0.0015846941387280822, Min w: 0.03686335310339928\n",
      "Iteration 250, Loss: 0.0014318537432700396, Min w: 0.09380535781383514\n",
      "Iteration 260, Loss: 0.0014542642747983336, Min w: 0.10526348650455475\n",
      "Iteration 270, Loss: 0.0014352096477523446, Min w: 0.1535986065864563\n",
      "Iteration 280, Loss: 0.0013774798717349768, Min w: 0.18269966542720795\n",
      "Iteration 290, Loss: 0.00143395084887743, Min w: 0.18622152507305145\n",
      "Iteration 300, Loss: 0.0013334318064153194, Min w: 0.1921294778585434\n",
      "Iteration 310, Loss: 0.0013323338935151696, Min w: 0.23196914792060852\n",
      "Iteration 320, Loss: 0.0012363801943138242, Min w: 0.25620895624160767\n",
      "Iteration 330, Loss: 0.0012103073531761765, Min w: 0.290437251329422\n",
      "Iteration 340, Loss: 0.0012512278044596314, Min w: 0.2813018560409546\n",
      "Iteration 350, Loss: 0.0011569351190701127, Min w: 0.300322026014328\n",
      "Iteration 360, Loss: 0.001180492457933724, Min w: 0.2850402295589447\n",
      "Iteration 370, Loss: 0.0011436165077611804, Min w: 0.30369192361831665\n",
      "Iteration 380, Loss: 0.0010764027247205377, Min w: 0.36013299226760864\n",
      "Iteration 390, Loss: 0.0011128161568194628, Min w: 0.3473200798034668\n",
      "Iteration 400, Loss: 0.0010998385259881616, Min w: 0.359235018491745\n",
      "Iteration 410, Loss: 0.001053521758876741, Min w: 0.3930790424346924\n",
      "Iteration 420, Loss: 0.0010117024648934603, Min w: 0.36360201239585876\n",
      "Iteration 430, Loss: 0.0010495813330635428, Min w: 0.3881906569004059\n",
      "Iteration 440, Loss: 0.001028244849294424, Min w: 0.4078766703605652\n",
      "Iteration 450, Loss: 0.0009615257731638849, Min w: 0.40371179580688477\n",
      "Iteration 460, Loss: 0.0010042674839496613, Min w: 0.39426490664482117\n",
      "Iteration 470, Loss: 0.0009176912717521191, Min w: 0.42709362506866455\n",
      "Iteration 480, Loss: 0.0009277169010601938, Min w: 0.4242236912250519\n",
      "Iteration 490, Loss: 0.0009680268703959882, Min w: 0.4244979918003082\n",
      "Iteration 500, Loss: 0.0009070034138858318, Min w: 0.4414738416671753\n",
      "Iteration 510, Loss: 0.0008653431432321668, Min w: 0.4564738869667053\n",
      "Iteration 520, Loss: 0.0008798125199973583, Min w: 0.4473361074924469\n",
      "Iteration 530, Loss: 0.0008764601079747081, Min w: 0.4738962650299072\n",
      "Iteration 540, Loss: 0.0008633128018118441, Min w: 0.4642689526081085\n",
      "Iteration 550, Loss: 0.0008289170218631625, Min w: 0.501488208770752\n",
      "Iteration 560, Loss: 0.000839493062812835, Min w: 0.4846855401992798\n",
      "Iteration 570, Loss: 0.0008067588205449283, Min w: 0.5117107033729553\n",
      "Iteration 580, Loss: 0.0008262521005235612, Min w: 0.49278536438941956\n",
      "Iteration 590, Loss: 0.0007623102865181863, Min w: 0.5355885028839111\n",
      "Iteration 600, Loss: 0.0007631828775629401, Min w: 0.5034287571907043\n",
      "Iteration 610, Loss: 0.0007687981706112623, Min w: 0.5112782120704651\n",
      "Iteration 620, Loss: 0.0007700980640947819, Min w: 0.5103845000267029\n",
      "Iteration 630, Loss: 0.0007389775128103793, Min w: 0.5457726716995239\n",
      "Iteration 640, Loss: 0.0007411201950162649, Min w: 0.5484017729759216\n",
      "Iteration 650, Loss: 0.0007852595881558955, Min w: 0.525143027305603\n",
      "Iteration 660, Loss: 0.000715698697604239, Min w: 0.551539957523346\n",
      "Iteration 670, Loss: 0.0007128622964955866, Min w: 0.5652582049369812\n",
      "Iteration 680, Loss: 0.0007346833008341491, Min w: 0.5582553744316101\n",
      "Iteration 690, Loss: 0.0006640314240939915, Min w: 0.5864440202713013\n",
      "Iteration 700, Loss: 0.000686958315782249, Min w: 0.5882794260978699\n",
      "Iteration 710, Loss: 0.0006752798217348754, Min w: 0.5979380011558533\n",
      "Iteration 720, Loss: 0.0006903860485181212, Min w: 0.5847641825675964\n",
      "Iteration 730, Loss: 0.0006486860802397132, Min w: 0.5891459584236145\n",
      "Iteration 740, Loss: 0.0006577742169611156, Min w: 0.599214494228363\n",
      "Iteration 750, Loss: 0.0006428660708479583, Min w: 0.611037015914917\n",
      "Iteration 760, Loss: 0.0006527777295559645, Min w: 0.5967074036598206\n",
      "Iteration 770, Loss: 0.0006127619999460876, Min w: 0.628861665725708\n",
      "Iteration 780, Loss: 0.000584733032155782, Min w: 0.6308302283287048\n",
      "Iteration 790, Loss: 0.0006440579891204834, Min w: 0.6185317039489746\n",
      "Iteration 800, Loss: 0.0005922680720686913, Min w: 0.6353118419647217\n",
      "Iteration 810, Loss: 0.0006195821915753186, Min w: 0.6117590069770813\n",
      "Iteration 820, Loss: 0.0006412210641428828, Min w: 0.6303288340568542\n",
      "Iteration 830, Loss: 0.000622314924839884, Min w: 0.6336382627487183\n",
      "Iteration 840, Loss: 0.0005641235038638115, Min w: 0.6431682109832764\n",
      "Iteration 850, Loss: 0.0005511129274964333, Min w: 0.6618771553039551\n",
      "Iteration 860, Loss: 0.0005395106272771955, Min w: 0.6803420186042786\n",
      "Iteration 870, Loss: 0.0005707722157239914, Min w: 0.665241003036499\n",
      "Iteration 880, Loss: 0.0005635593552142382, Min w: 0.6550531983375549\n",
      "Iteration 890, Loss: 0.000534913910087198, Min w: 0.6705532073974609\n",
      "Iteration 900, Loss: 0.0005265679792501032, Min w: 0.6724663972854614\n",
      "Iteration 910, Loss: 0.0005156031693331897, Min w: 0.681285560131073\n",
      "Iteration 920, Loss: 0.0005016268114559352, Min w: 0.6762847304344177\n",
      "Iteration 930, Loss: 0.000505613861605525, Min w: 0.6825650334358215\n",
      "Iteration 940, Loss: 0.0005040172254666686, Min w: 0.6970997452735901\n",
      "Iteration 950, Loss: 0.000504347204696387, Min w: 0.679118812084198\n",
      "Iteration 960, Loss: 0.0005178170977160335, Min w: 0.6893875002861023\n",
      "Iteration 970, Loss: 0.0004863463109359145, Min w: 0.6953201293945312\n",
      "Iteration 980, Loss: 0.00047301442828029394, Min w: 0.704897403717041\n",
      "Iteration 990, Loss: 0.0004643922147806734, Min w: 0.7134084701538086\n",
      "Iteration 1000, Loss: 0.0005043298006057739, Min w: 0.6920772194862366\n",
      "Iteration 1010, Loss: 0.00047232970246113837, Min w: 0.7205185890197754\n",
      "Iteration 1020, Loss: 0.0004805584321729839, Min w: 0.7029189467430115\n",
      "Iteration 1030, Loss: 0.0004752274544443935, Min w: 0.7047826647758484\n",
      "Iteration 1040, Loss: 0.00046621361980214715, Min w: 0.7221969962120056\n",
      "Iteration 1050, Loss: 0.0003935732238460332, Min w: 0.7560945749282837\n",
      "Iteration 1060, Loss: 0.000437092618085444, Min w: 0.7250851988792419\n",
      "Iteration 1070, Loss: 0.00045663543278351426, Min w: 0.7274061441421509\n",
      "Iteration 1080, Loss: 0.000442374061094597, Min w: 0.7296897768974304\n",
      "Iteration 1090, Loss: 0.00042368590948171914, Min w: 0.7393940091133118\n",
      "Iteration 1100, Loss: 0.00043314340291544795, Min w: 0.7289676666259766\n",
      "Iteration 1110, Loss: 0.00040290740435011685, Min w: 0.7545249462127686\n",
      "Iteration 1120, Loss: 0.0004128823638893664, Min w: 0.7453610897064209\n",
      "Iteration 1130, Loss: 0.00039415041101165116, Min w: 0.7586828470230103\n",
      "Iteration 1140, Loss: 0.0003978352469857782, Min w: 0.7410919070243835\n",
      "Iteration 1150, Loss: 0.00039784147520549595, Min w: 0.7573673129081726\n",
      "Iteration 1160, Loss: 0.00039523676969110966, Min w: 0.7542522549629211\n",
      "Iteration 1170, Loss: 0.0003943219780921936, Min w: 0.7562365531921387\n",
      "Iteration 1180, Loss: 0.000405342347221449, Min w: 0.7372087240219116\n",
      "Iteration 1190, Loss: 0.00036725582322105765, Min w: 0.7679523825645447\n",
      "Iteration 1200, Loss: 0.0003709593147505075, Min w: 0.7663668990135193\n",
      "Iteration 1210, Loss: 0.0003639889182522893, Min w: 0.7784231305122375\n",
      "Iteration 1220, Loss: 0.00036060326965525746, Min w: 0.7819342613220215\n",
      "Iteration 1230, Loss: 0.00034736606176011264, Min w: 0.7824006676673889\n",
      "Iteration 1240, Loss: 0.00035940020461566746, Min w: 0.7844505906105042\n",
      "Iteration 0, Loss: 0.00036520505091175437, Min w: 0.7827353477478027\n",
      "Iteration 10, Loss: 0.0003754471836145967, Min w: 0.7674486637115479\n",
      "Iteration 20, Loss: 0.0003687281860038638, Min w: 0.7833030819892883\n",
      "Iteration 30, Loss: 0.0003849453933071345, Min w: 0.7656393051147461\n",
      "Iteration 40, Loss: 0.00034580545616336167, Min w: 0.7925213575363159\n",
      "Iteration 50, Loss: 0.0003372684004716575, Min w: 0.7894545793533325\n",
      "Iteration 60, Loss: 0.0003284005797468126, Min w: 0.8047218322753906\n",
      "Iteration 70, Loss: 0.0003404171147849411, Min w: 0.7975187301635742\n",
      "Iteration 80, Loss: 0.0003290025924798101, Min w: 0.7985150814056396\n",
      "Iteration 90, Loss: 0.0003580077027436346, Min w: 0.7997445464134216\n",
      "Iteration 100, Loss: 0.00033267855178564787, Min w: 0.7966229915618896\n",
      "Iteration 110, Loss: 0.00030789902666583657, Min w: 0.8138411045074463\n",
      "Iteration 120, Loss: 0.0003209553542546928, Min w: 0.8125839233398438\n",
      "Iteration 130, Loss: 0.00033069989876821637, Min w: 0.8055822849273682\n",
      "Iteration 140, Loss: 0.00031755364034324884, Min w: 0.8099666237831116\n",
      "Iteration 150, Loss: 0.00032740741153247654, Min w: 0.8096884489059448\n",
      "Iteration 160, Loss: 0.0003029076033271849, Min w: 0.8135590553283691\n",
      "Iteration 170, Loss: 0.000311870506266132, Min w: 0.8107336163520813\n",
      "Iteration 180, Loss: 0.00028791019576601684, Min w: 0.8332507014274597\n",
      "Iteration 190, Loss: 0.0003234642499592155, Min w: 0.8018686175346375\n",
      "Iteration 200, Loss: 0.00028681615367531776, Min w: 0.8219830989837646\n",
      "Iteration 210, Loss: 0.0002932627685368061, Min w: 0.8279663920402527\n",
      "Iteration 220, Loss: 0.0002975710085593164, Min w: 0.8234419226646423\n",
      "Iteration 230, Loss: 0.00028367474442347884, Min w: 0.8302792310714722\n",
      "Iteration 240, Loss: 0.00027814178611151874, Min w: 0.828252375125885\n",
      "Iteration 250, Loss: 0.0002877602819353342, Min w: 0.8295149207115173\n",
      "Iteration 260, Loss: 0.00027134385891258717, Min w: 0.8275207877159119\n",
      "Iteration 270, Loss: 0.0002641411847434938, Min w: 0.839540958404541\n",
      "Iteration 280, Loss: 0.0002754170272964984, Min w: 0.8324761390686035\n",
      "Iteration 290, Loss: 0.0002727495739236474, Min w: 0.8355187773704529\n",
      "Iteration 300, Loss: 0.00025582569651305676, Min w: 0.8444035649299622\n",
      "Iteration 310, Loss: 0.00026680060545913875, Min w: 0.8414995074272156\n",
      "Iteration 320, Loss: 0.00025100517086684704, Min w: 0.8499637246131897\n",
      "Iteration 330, Loss: 0.0002754954621195793, Min w: 0.8349586725234985\n",
      "Iteration 340, Loss: 0.00027878681430593133, Min w: 0.8364622592926025\n",
      "Iteration 350, Loss: 0.00027546932687982917, Min w: 0.839712917804718\n",
      "Iteration 360, Loss: 0.00026312764384783804, Min w: 0.8398392200469971\n",
      "Iteration 370, Loss: 0.00023986544692888856, Min w: 0.8480201959609985\n",
      "Iteration 380, Loss: 0.00025593445752747357, Min w: 0.8416257500648499\n",
      "Iteration 390, Loss: 0.00023944700660649687, Min w: 0.8527780771255493\n",
      "Iteration 400, Loss: 0.00026127422461286187, Min w: 0.8511609435081482\n",
      "Iteration 410, Loss: 0.00028174827457405627, Min w: 0.8454887866973877\n",
      "Iteration 420, Loss: 0.00024210363335441798, Min w: 0.8497387170791626\n",
      "Iteration 430, Loss: 0.0002245658979518339, Min w: 0.8689959645271301\n",
      "Iteration 440, Loss: 0.00023255230917129666, Min w: 0.8574379086494446\n",
      "Iteration 450, Loss: 0.00023311644326895475, Min w: 0.8573066592216492\n",
      "Iteration 460, Loss: 0.00022988890123087913, Min w: 0.8576803207397461\n",
      "Iteration 470, Loss: 0.0002267157833557576, Min w: 0.8612433671951294\n",
      "Iteration 480, Loss: 0.00023581627465318888, Min w: 0.8561540842056274\n",
      "Iteration 490, Loss: 0.0002420317177893594, Min w: 0.84934401512146\n",
      "Iteration 500, Loss: 0.00023696006974205375, Min w: 0.8598687052726746\n",
      "Iteration 510, Loss: 0.0002089192857965827, Min w: 0.8724792003631592\n",
      "Iteration 520, Loss: 0.00023548562603536993, Min w: 0.857549250125885\n",
      "Iteration 530, Loss: 0.0002464558056090027, Min w: 0.8521701693534851\n",
      "Iteration 540, Loss: 0.00022216788784135133, Min w: 0.8647106885910034\n",
      "Iteration 550, Loss: 0.00020924812997691333, Min w: 0.8808901309967041\n",
      "Iteration 560, Loss: 0.00022147731215227395, Min w: 0.8655183911323547\n",
      "Iteration 570, Loss: 0.0002198797883465886, Min w: 0.8756691813468933\n",
      "Iteration 580, Loss: 0.00019787777273450047, Min w: 0.8826581835746765\n",
      "Iteration 590, Loss: 0.00021585436479654163, Min w: 0.869324266910553\n",
      "Iteration 600, Loss: 0.0002130512148141861, Min w: 0.8734177947044373\n",
      "Iteration 610, Loss: 0.00019623333355411887, Min w: 0.8796476125717163\n",
      "Iteration 620, Loss: 0.00019685621373355389, Min w: 0.8752418756484985\n",
      "Iteration 630, Loss: 0.00023191008949652314, Min w: 0.8707572817802429\n",
      "Iteration 640, Loss: 0.00020503629639279097, Min w: 0.8726058602333069\n",
      "Iteration 650, Loss: 0.0002008954470511526, Min w: 0.8814066052436829\n",
      "Iteration 660, Loss: 0.00022010925749782473, Min w: 0.8660538792610168\n",
      "Iteration 670, Loss: 0.00021843519061803818, Min w: 0.8651489019393921\n",
      "Iteration 680, Loss: 0.0001880945492302999, Min w: 0.8879669308662415\n",
      "Iteration 690, Loss: 0.00021039774583186954, Min w: 0.8725364804267883\n",
      "Iteration 700, Loss: 0.0002012659824686125, Min w: 0.8733507394790649\n",
      "Iteration 710, Loss: 0.00018817778618540615, Min w: 0.8854102492332458\n",
      "Iteration 720, Loss: 0.0002081368293147534, Min w: 0.879931628704071\n",
      "Iteration 730, Loss: 0.00020879512885585427, Min w: 0.8784217834472656\n",
      "Iteration 740, Loss: 0.0001941743539646268, Min w: 0.8850268721580505\n",
      "Iteration 750, Loss: 0.00019332101510372013, Min w: 0.8825773000717163\n",
      "Iteration 760, Loss: 0.00018810403707902879, Min w: 0.8870763182640076\n",
      "Iteration 770, Loss: 0.0001758035214152187, Min w: 0.8920828700065613\n",
      "Iteration 780, Loss: 0.00021412430214695632, Min w: 0.8734130263328552\n",
      "Iteration 790, Loss: 0.00017977879906538874, Min w: 0.885239839553833\n",
      "Iteration 800, Loss: 0.00018684180395212024, Min w: 0.8897590637207031\n",
      "Iteration 810, Loss: 0.00018925526819657534, Min w: 0.8839726448059082\n",
      "Iteration 820, Loss: 0.0001739626022754237, Min w: 0.8903321027755737\n",
      "Iteration 830, Loss: 0.00018417042156215757, Min w: 0.8857423067092896\n",
      "Iteration 840, Loss: 0.0001766924251569435, Min w: 0.8959767818450928\n",
      "Iteration 850, Loss: 0.00016698328545317054, Min w: 0.9028555154800415\n",
      "Iteration 860, Loss: 0.00017823926464188844, Min w: 0.8966060280799866\n",
      "Iteration 870, Loss: 0.00018450597417540848, Min w: 0.8849706649780273\n",
      "Iteration 880, Loss: 0.00016987799608614296, Min w: 0.8904980421066284\n",
      "Iteration 890, Loss: 0.00016792176757007837, Min w: 0.9018985629081726\n",
      "Iteration 900, Loss: 0.0001763134787324816, Min w: 0.8932054042816162\n",
      "Iteration 910, Loss: 0.0001643547002458945, Min w: 0.8958562612533569\n",
      "Iteration 920, Loss: 0.0001755392731865868, Min w: 0.8963004350662231\n",
      "Iteration 930, Loss: 0.0001665617455728352, Min w: 0.8998106718063354\n",
      "Iteration 940, Loss: 0.00017674529226496816, Min w: 0.8939676880836487\n",
      "Iteration 950, Loss: 0.00016551472072023898, Min w: 0.8953098058700562\n",
      "Iteration 960, Loss: 0.00015833057113923132, Min w: 0.9017342925071716\n",
      "Iteration 970, Loss: 0.00017357846081722528, Min w: 0.9045872092247009\n",
      "Iteration 980, Loss: 0.00017358537297695875, Min w: 0.89334636926651\n",
      "Iteration 990, Loss: 0.00017171689250972122, Min w: 0.8940688967704773\n",
      "Iteration 1000, Loss: 0.00016454826982226223, Min w: 0.9048333764076233\n",
      "Iteration 1010, Loss: 0.0001773110416252166, Min w: 0.9016210436820984\n",
      "Iteration 1020, Loss: 0.00015600149345118552, Min w: 0.9050670266151428\n",
      "Iteration 1030, Loss: 0.0001495655596954748, Min w: 0.9119993448257446\n",
      "Iteration 1040, Loss: 0.00016218122618738562, Min w: 0.9027711153030396\n",
      "Iteration 1050, Loss: 0.0001723420573398471, Min w: 0.898098886013031\n",
      "Iteration 1060, Loss: 0.00014874720363877714, Min w: 0.913855254650116\n",
      "Iteration 1070, Loss: 0.00016106343537103385, Min w: 0.8999713659286499\n",
      "Iteration 1080, Loss: 0.00017002741515170783, Min w: 0.9025061726570129\n",
      "Iteration 1090, Loss: 0.00015920252189971507, Min w: 0.9033543467521667\n",
      "Iteration 1100, Loss: 0.00016463450447190553, Min w: 0.8976228833198547\n",
      "Iteration 1110, Loss: 0.00014741344784852117, Min w: 0.9200379848480225\n",
      "Iteration 1120, Loss: 0.00014680949971079826, Min w: 0.9188528656959534\n",
      "Iteration 1130, Loss: 0.00015295085904654115, Min w: 0.909841001033783\n",
      "Iteration 1140, Loss: 0.00017188166384585202, Min w: 0.9072068333625793\n",
      "Iteration 1150, Loss: 0.0001455391466151923, Min w: 0.9093323945999146\n",
      "Iteration 1160, Loss: 0.000151676096720621, Min w: 0.9113967418670654\n",
      "Iteration 1170, Loss: 0.00016168579168152064, Min w: 0.9074226021766663\n",
      "Iteration 1180, Loss: 0.00015409027400892228, Min w: 0.9147976636886597\n",
      "Iteration 1190, Loss: 0.00015105934289749712, Min w: 0.9170636534690857\n",
      "Iteration 1200, Loss: 0.0001512371381977573, Min w: 0.9051016569137573\n",
      "Iteration 1210, Loss: 0.00014762200589757413, Min w: 0.911308228969574\n",
      "Iteration 1220, Loss: 0.00016432521806564182, Min w: 0.9068500995635986\n",
      "Iteration 1230, Loss: 0.00014612142695114017, Min w: 0.9138484001159668\n",
      "Iteration 1240, Loss: 0.00014759303303435445, Min w: 0.909807562828064\n",
      "Iteration 0, Loss: 0.00014953767822589725, Min w: 0.9102516770362854\n",
      "Iteration 10, Loss: 0.000136068687424995, Min w: 0.9183587431907654\n",
      "Iteration 20, Loss: 0.0001230664929607883, Min w: 0.9264558553695679\n",
      "Iteration 30, Loss: 0.00015041684673633426, Min w: 0.91133713722229\n",
      "Iteration 40, Loss: 0.0001540173398097977, Min w: 0.9067600965499878\n",
      "Iteration 50, Loss: 0.00013488833792507648, Min w: 0.9162716269493103\n",
      "Iteration 60, Loss: 0.00014485485735349357, Min w: 0.9186376929283142\n",
      "Iteration 70, Loss: 0.00012747263826895505, Min w: 0.9236979484558105\n",
      "Iteration 80, Loss: 0.00013627838052343577, Min w: 0.9172167181968689\n",
      "Iteration 90, Loss: 0.00014302496856544167, Min w: 0.9158133268356323\n",
      "Iteration 100, Loss: 0.00012730735761579126, Min w: 0.9253268837928772\n",
      "Iteration 110, Loss: 0.00014842848759144545, Min w: 0.9064398407936096\n",
      "Iteration 120, Loss: 0.00013062963262200356, Min w: 0.920444667339325\n",
      "Iteration 130, Loss: 0.00014308665413409472, Min w: 0.9145261645317078\n",
      "Iteration 140, Loss: 0.00013942427176516503, Min w: 0.9226191639900208\n",
      "Iteration 150, Loss: 0.00014056492364034057, Min w: 0.9256293773651123\n",
      "Iteration 160, Loss: 0.0001345633645541966, Min w: 0.9218049645423889\n",
      "Iteration 170, Loss: 0.00013143022079020739, Min w: 0.9231752753257751\n",
      "Iteration 180, Loss: 0.00012336332292761654, Min w: 0.9245098233222961\n",
      "Iteration 190, Loss: 0.00013684808800462633, Min w: 0.9249839782714844\n",
      "Iteration 200, Loss: 0.00014575390378013253, Min w: 0.9201195240020752\n",
      "Iteration 210, Loss: 0.0001221714774146676, Min w: 0.9274961948394775\n",
      "Iteration 220, Loss: 0.00012208563566673547, Min w: 0.9243149161338806\n",
      "Iteration 230, Loss: 0.00013168129953555763, Min w: 0.9209750294685364\n",
      "Iteration 240, Loss: 0.00014247452782001346, Min w: 0.9231001138687134\n",
      "Iteration 250, Loss: 0.000138831848744303, Min w: 0.919647216796875\n",
      "Iteration 260, Loss: 0.00012560684990603477, Min w: 0.9287892580032349\n",
      "Iteration 270, Loss: 0.00013092927110847086, Min w: 0.9238173961639404\n",
      "Iteration 280, Loss: 0.00012488345964811742, Min w: 0.9246775507926941\n",
      "Iteration 290, Loss: 0.00012543382763396949, Min w: 0.9270930886268616\n",
      "Iteration 300, Loss: 0.00013027754903305322, Min w: 0.9242331981658936\n",
      "Iteration 310, Loss: 0.00012887550110463053, Min w: 0.9228152632713318\n",
      "Iteration 320, Loss: 0.00013394426787272096, Min w: 0.9240745902061462\n",
      "Iteration 330, Loss: 0.00013157003559172153, Min w: 0.9289893507957458\n",
      "Iteration 340, Loss: 0.00011168320634169504, Min w: 0.9303812384605408\n",
      "Iteration 350, Loss: 0.00012167306704213843, Min w: 0.9305588006973267\n",
      "Iteration 360, Loss: 0.00012515288835857064, Min w: 0.93120938539505\n",
      "Iteration 370, Loss: 0.0001234378869412467, Min w: 0.9275369644165039\n",
      "Iteration 380, Loss: 0.00013074421440251172, Min w: 0.9229549765586853\n",
      "Iteration 390, Loss: 0.00012127951777074486, Min w: 0.9294355511665344\n",
      "Iteration 400, Loss: 0.00011775082384701818, Min w: 0.9286845326423645\n",
      "Iteration 410, Loss: 0.00011952985369134694, Min w: 0.9324802160263062\n",
      "Iteration 420, Loss: 0.00011843087850138545, Min w: 0.9272368550300598\n",
      "Iteration 430, Loss: 0.00012148894893471152, Min w: 0.9280611872673035\n",
      "Iteration 440, Loss: 0.00011548272595973685, Min w: 0.9302746653556824\n",
      "Iteration 450, Loss: 0.00011583629384404048, Min w: 0.9289933443069458\n",
      "Iteration 460, Loss: 0.00011843586980830878, Min w: 0.9331559538841248\n",
      "Iteration 470, Loss: 0.0001277017581742257, Min w: 0.917755663394928\n",
      "Iteration 480, Loss: 0.00011356695176800713, Min w: 0.9349616765975952\n",
      "Iteration 490, Loss: 0.00011337357136653736, Min w: 0.9317912459373474\n",
      "Iteration 500, Loss: 0.00011447191354818642, Min w: 0.9326696991920471\n",
      "Iteration 510, Loss: 0.0001121432360378094, Min w: 0.9313008785247803\n",
      "Iteration 520, Loss: 0.00011571691720746458, Min w: 0.932496190071106\n",
      "Iteration 530, Loss: 0.00010980496153933927, Min w: 0.9353502988815308\n",
      "Iteration 540, Loss: 0.0001101383168133907, Min w: 0.9331330060958862\n",
      "Iteration 550, Loss: 0.00011202254972886294, Min w: 0.9349144697189331\n",
      "Iteration 560, Loss: 0.00011313369759591296, Min w: 0.9351697564125061\n",
      "Iteration 570, Loss: 0.00010744022438302636, Min w: 0.9350563287734985\n",
      "Iteration 580, Loss: 0.00011420470400480554, Min w: 0.9330248832702637\n",
      "Iteration 590, Loss: 0.00011482914123916999, Min w: 0.9348329305648804\n",
      "Iteration 600, Loss: 0.00011794975580414757, Min w: 0.9323524832725525\n",
      "Iteration 610, Loss: 0.00012034660176141188, Min w: 0.9311752915382385\n",
      "Iteration 620, Loss: 0.00011037645163014531, Min w: 0.9358376264572144\n",
      "Iteration 630, Loss: 0.00010854625725187361, Min w: 0.9346214532852173\n",
      "Iteration 640, Loss: 0.0001084795076167211, Min w: 0.9354897141456604\n",
      "Iteration 650, Loss: 0.00010616461804602295, Min w: 0.936680793762207\n",
      "Iteration 660, Loss: 0.00011347857798682526, Min w: 0.9382595419883728\n",
      "Iteration 670, Loss: 0.0001226160820806399, Min w: 0.9368463754653931\n",
      "Iteration 680, Loss: 0.00010499906056793407, Min w: 0.935932457447052\n",
      "Iteration 690, Loss: 9.227290138369426e-05, Min w: 0.9443797469139099\n",
      "Iteration 700, Loss: 0.00010878154716920108, Min w: 0.937949538230896\n",
      "Iteration 710, Loss: 0.00010614841448841617, Min w: 0.9379473924636841\n",
      "Iteration 720, Loss: 9.798890096135437e-05, Min w: 0.9411708116531372\n",
      "Iteration 730, Loss: 9.775494254427031e-05, Min w: 0.9413366913795471\n",
      "Iteration 740, Loss: 9.959306044038385e-05, Min w: 0.9386278390884399\n",
      "Iteration 750, Loss: 0.00010167645086767152, Min w: 0.9383671879768372\n",
      "Iteration 760, Loss: 0.00010688116162782535, Min w: 0.9419093728065491\n",
      "Iteration 770, Loss: 0.00010415486030979082, Min w: 0.9372926950454712\n",
      "Iteration 780, Loss: 0.00011238663864787668, Min w: 0.9358622431755066\n",
      "Iteration 790, Loss: 9.620067430660129e-05, Min w: 0.9433967471122742\n",
      "Iteration 800, Loss: 0.00010318936256226152, Min w: 0.936133623123169\n",
      "Iteration 810, Loss: 9.928725194185972e-05, Min w: 0.9393640160560608\n",
      "Iteration 820, Loss: 9.671239968156442e-05, Min w: 0.9436025023460388\n",
      "Iteration 830, Loss: 9.632291039451957e-05, Min w: 0.9427370429039001\n",
      "Iteration 840, Loss: 0.00011330471170367673, Min w: 0.934212863445282\n",
      "Iteration 850, Loss: 9.721097740111873e-05, Min w: 0.9420424103736877\n",
      "Iteration 860, Loss: 9.18995137908496e-05, Min w: 0.9452918171882629\n",
      "Iteration 870, Loss: 9.966710058506578e-05, Min w: 0.9413673877716064\n",
      "Iteration 880, Loss: 0.00011078076931880787, Min w: 0.9405105113983154\n",
      "Iteration 890, Loss: 0.00010367437062086537, Min w: 0.9355496168136597\n",
      "Iteration 900, Loss: 0.00010484807717148215, Min w: 0.9437075853347778\n",
      "Iteration 910, Loss: 0.00010550641309237108, Min w: 0.9378411173820496\n",
      "Iteration 920, Loss: 0.00010682755237212405, Min w: 0.9437749981880188\n",
      "Iteration 930, Loss: 9.37289441935718e-05, Min w: 0.9425253868103027\n",
      "Iteration 940, Loss: 0.00010069998825201765, Min w: 0.9451504945755005\n",
      "Iteration 950, Loss: 9.388838952872902e-05, Min w: 0.9431269764900208\n",
      "Iteration 960, Loss: 0.00010300741996616125, Min w: 0.9468706250190735\n",
      "Iteration 970, Loss: 0.0001219047189806588, Min w: 0.9341413974761963\n",
      "Iteration 980, Loss: 8.72217133291997e-05, Min w: 0.9490929245948792\n",
      "Iteration 990, Loss: 9.361889533465728e-05, Min w: 0.9432570934295654\n",
      "Iteration 1000, Loss: 8.801680087344721e-05, Min w: 0.949582576751709\n",
      "Iteration 1010, Loss: 9.079422306967899e-05, Min w: 0.9454807043075562\n",
      "Iteration 1020, Loss: 9.293347102357075e-05, Min w: 0.9424277544021606\n",
      "Iteration 1030, Loss: 8.334392623510212e-05, Min w: 0.9509797096252441\n",
      "Iteration 1040, Loss: 9.341386612504721e-05, Min w: 0.9457511901855469\n",
      "Iteration 1050, Loss: 8.430075104115531e-05, Min w: 0.9505470395088196\n",
      "Iteration 1060, Loss: 8.301623165607452e-05, Min w: 0.9477618932723999\n",
      "Iteration 1070, Loss: 7.974706386448815e-05, Min w: 0.9492369890213013\n",
      "Iteration 1080, Loss: 9.23633633647114e-05, Min w: 0.9481074213981628\n",
      "Iteration 1090, Loss: 8.407328277826309e-05, Min w: 0.9499750137329102\n",
      "Iteration 1100, Loss: 8.384152897633612e-05, Min w: 0.9482455253601074\n",
      "Iteration 1110, Loss: 9.793884237296879e-05, Min w: 0.9444481134414673\n",
      "Iteration 1120, Loss: 9.551468974677846e-05, Min w: 0.9498095512390137\n",
      "Iteration 1130, Loss: 8.16451502032578e-05, Min w: 0.9533918499946594\n",
      "Iteration 1140, Loss: 0.00010079891217174008, Min w: 0.9455862045288086\n",
      "Iteration 1150, Loss: 8.690324466442689e-05, Min w: 0.9485671520233154\n",
      "Iteration 1160, Loss: 9.893727110465989e-05, Min w: 0.9480453133583069\n",
      "Iteration 1170, Loss: 7.647577876923606e-05, Min w: 0.9528146982192993\n",
      "Iteration 1180, Loss: 8.42544759507291e-05, Min w: 0.9509596228599548\n",
      "Iteration 1190, Loss: 9.208553092321381e-05, Min w: 0.9480611085891724\n",
      "Iteration 1200, Loss: 8.696596341906115e-05, Min w: 0.9482623338699341\n",
      "Iteration 1210, Loss: 8.624526526546106e-05, Min w: 0.9492262601852417\n",
      "Iteration 1220, Loss: 8.136340329656377e-05, Min w: 0.9503222703933716\n",
      "Iteration 1230, Loss: 0.00011467305012047291, Min w: 0.9380528330802917\n",
      "Iteration 1240, Loss: 8.523719588993117e-05, Min w: 0.9499821066856384\n",
      "Iteration 0, Loss: 8.18304906715639e-05, Min w: 0.9490212202072144\n",
      "Iteration 10, Loss: 8.480282849632204e-05, Min w: 0.9508199691772461\n",
      "Iteration 20, Loss: 8.545601303922012e-05, Min w: 0.9488694071769714\n",
      "Iteration 30, Loss: 8.58462299220264e-05, Min w: 0.9479915499687195\n",
      "Iteration 40, Loss: 8.727246313355863e-05, Min w: 0.94761723279953\n",
      "Iteration 50, Loss: 0.00010016586020356044, Min w: 0.948143482208252\n",
      "Iteration 60, Loss: 0.0001031642168527469, Min w: 0.9440339207649231\n",
      "Iteration 70, Loss: 8.34489255794324e-05, Min w: 0.9520272612571716\n",
      "Iteration 80, Loss: 8.533352229278535e-05, Min w: 0.953624963760376\n",
      "Iteration 90, Loss: 0.0001000420525087975, Min w: 0.9487463235855103\n",
      "Iteration 100, Loss: 7.068849663482979e-05, Min w: 0.9551398754119873\n",
      "Iteration 110, Loss: 9.061802848009393e-05, Min w: 0.9525573253631592\n",
      "Iteration 120, Loss: 9.069035877473652e-05, Min w: 0.9493045210838318\n",
      "Iteration 130, Loss: 7.539238868048415e-05, Min w: 0.9556490778923035\n",
      "Iteration 140, Loss: 7.544118125224486e-05, Min w: 0.9580570459365845\n",
      "Iteration 150, Loss: 7.987254502950236e-05, Min w: 0.9520705938339233\n",
      "Iteration 160, Loss: 7.851194095565006e-05, Min w: 0.9549171328544617\n",
      "Iteration 170, Loss: 7.756322884233668e-05, Min w: 0.951678991317749\n",
      "Iteration 180, Loss: 7.971993181854486e-05, Min w: 0.9531949758529663\n",
      "Iteration 190, Loss: 8.833163155941293e-05, Min w: 0.9506756663322449\n",
      "Iteration 200, Loss: 8.14033774076961e-05, Min w: 0.9515700936317444\n",
      "Iteration 210, Loss: 7.513142190873623e-05, Min w: 0.9564059376716614\n",
      "Iteration 220, Loss: 7.313147216336802e-05, Min w: 0.9556818604469299\n",
      "Iteration 230, Loss: 7.631002517882735e-05, Min w: 0.9542480111122131\n",
      "Iteration 240, Loss: 8.342498767888173e-05, Min w: 0.9548352956771851\n",
      "Iteration 250, Loss: 7.626526348758489e-05, Min w: 0.9574992060661316\n",
      "Iteration 260, Loss: 8.009651355678216e-05, Min w: 0.9523189663887024\n",
      "Iteration 270, Loss: 8.171439549187198e-05, Min w: 0.9535161256790161\n",
      "Iteration 280, Loss: 8.646788046462461e-05, Min w: 0.9543899297714233\n",
      "Iteration 290, Loss: 7.56349036237225e-05, Min w: 0.9567981362342834\n",
      "Iteration 300, Loss: 8.44244787003845e-05, Min w: 0.9557574987411499\n",
      "Iteration 310, Loss: 7.299677963601425e-05, Min w: 0.9582985043525696\n",
      "Iteration 320, Loss: 7.688109326409176e-05, Min w: 0.9525005221366882\n",
      "Iteration 330, Loss: 7.114359323168173e-05, Min w: 0.95842045545578\n",
      "Iteration 340, Loss: 7.963288226164877e-05, Min w: 0.9562273621559143\n",
      "Iteration 350, Loss: 6.79837612551637e-05, Min w: 0.9605131149291992\n",
      "Iteration 360, Loss: 7.290023495443165e-05, Min w: 0.9570693373680115\n",
      "Iteration 370, Loss: 7.457251194864511e-05, Min w: 0.9597963690757751\n",
      "Iteration 380, Loss: 7.572718459414318e-05, Min w: 0.9550597071647644\n",
      "Iteration 390, Loss: 7.532379822805524e-05, Min w: 0.9609782099723816\n",
      "Iteration 400, Loss: 6.82593890815042e-05, Min w: 0.9586659073829651\n",
      "Iteration 410, Loss: 7.160283712437376e-05, Min w: 0.9589442014694214\n",
      "Iteration 420, Loss: 7.204118446679786e-05, Min w: 0.957248866558075\n",
      "Iteration 430, Loss: 6.841470167273656e-05, Min w: 0.9578386545181274\n",
      "Iteration 440, Loss: 7.346498023252934e-05, Min w: 0.9588011503219604\n",
      "Iteration 450, Loss: 7.930528954602778e-05, Min w: 0.9588577151298523\n",
      "Iteration 460, Loss: 6.907924398547038e-05, Min w: 0.9626408815383911\n",
      "Iteration 470, Loss: 7.242956780828536e-05, Min w: 0.9574042558670044\n",
      "Iteration 480, Loss: 6.402335566235706e-05, Min w: 0.9608075618743896\n",
      "Iteration 490, Loss: 6.553752609761432e-05, Min w: 0.961993932723999\n",
      "Iteration 500, Loss: 7.489490963052958e-05, Min w: 0.9600063562393188\n",
      "Iteration 510, Loss: 6.650969589827582e-05, Min w: 0.9582205414772034\n",
      "Iteration 520, Loss: 7.682770228711888e-05, Min w: 0.9581105709075928\n",
      "Iteration 530, Loss: 6.775308429496363e-05, Min w: 0.960536003112793\n",
      "Iteration 540, Loss: 6.632057193201035e-05, Min w: 0.9605299830436707\n",
      "Iteration 550, Loss: 6.666185072390363e-05, Min w: 0.9566936492919922\n",
      "Iteration 560, Loss: 7.258655386976898e-05, Min w: 0.9589416980743408\n",
      "Iteration 570, Loss: 6.623558147111908e-05, Min w: 0.9625509977340698\n",
      "Iteration 580, Loss: 6.698141805827618e-05, Min w: 0.9603915214538574\n",
      "Iteration 590, Loss: 7.651693158550188e-05, Min w: 0.9591785073280334\n",
      "Iteration 600, Loss: 6.812752690166235e-05, Min w: 0.9588426947593689\n",
      "Iteration 610, Loss: 6.727322761435062e-05, Min w: 0.9619495272636414\n",
      "Iteration 620, Loss: 7.015134178800508e-05, Min w: 0.9577698707580566\n",
      "Iteration 630, Loss: 7.098323840182275e-05, Min w: 0.9589627385139465\n",
      "Iteration 640, Loss: 7.708781777182594e-05, Min w: 0.9575867652893066\n",
      "Iteration 650, Loss: 7.632072811247781e-05, Min w: 0.9582783579826355\n",
      "Iteration 660, Loss: 7.178453233791515e-05, Min w: 0.9613380432128906\n",
      "Iteration 670, Loss: 6.290154851740226e-05, Min w: 0.962842583656311\n",
      "Iteration 680, Loss: 7.903744699433446e-05, Min w: 0.9569785594940186\n",
      "Iteration 690, Loss: 7.132082828320563e-05, Min w: 0.9605953693389893\n",
      "Iteration 700, Loss: 7.425186049658805e-05, Min w: 0.9596113562583923\n",
      "Iteration 710, Loss: 6.980993930483237e-05, Min w: 0.961448073387146\n",
      "Iteration 720, Loss: 6.068890434107743e-05, Min w: 0.9649085402488708\n",
      "Iteration 730, Loss: 6.243921961868182e-05, Min w: 0.9618237614631653\n",
      "Iteration 740, Loss: 7.094389002304524e-05, Min w: 0.9634273052215576\n",
      "Iteration 750, Loss: 6.338689854601398e-05, Min w: 0.9633678793907166\n",
      "Iteration 760, Loss: 6.360845145536587e-05, Min w: 0.9620963931083679\n",
      "Iteration 770, Loss: 7.184439891716465e-05, Min w: 0.96173095703125\n",
      "Iteration 780, Loss: 6.265160482143983e-05, Min w: 0.9653010368347168\n",
      "Iteration 790, Loss: 6.997189484536648e-05, Min w: 0.9634319543838501\n",
      "Iteration 800, Loss: 6.587133975699544e-05, Min w: 0.9620403051376343\n",
      "Iteration 810, Loss: 6.183248478919268e-05, Min w: 0.9662122130393982\n",
      "Iteration 820, Loss: 5.957431858405471e-05, Min w: 0.9650956988334656\n",
      "Iteration 830, Loss: 6.437114643631503e-05, Min w: 0.9610239267349243\n",
      "Iteration 840, Loss: 5.974330997560173e-05, Min w: 0.9654244184494019\n",
      "Iteration 850, Loss: 6.508857768494636e-05, Min w: 0.96305251121521\n",
      "Iteration 860, Loss: 6.053272954886779e-05, Min w: 0.9632827639579773\n",
      "Iteration 870, Loss: 6.733596819685772e-05, Min w: 0.9640198945999146\n",
      "Iteration 880, Loss: 6.848038174211979e-05, Min w: 0.9641092419624329\n",
      "Iteration 890, Loss: 5.82980464969296e-05, Min w: 0.9681204557418823\n",
      "Iteration 900, Loss: 6.677829514956102e-05, Min w: 0.9641690850257874\n",
      "Iteration 910, Loss: 6.187718827277422e-05, Min w: 0.9663853049278259\n",
      "Iteration 920, Loss: 5.9443802456371486e-05, Min w: 0.9669784307479858\n",
      "Iteration 930, Loss: 5.6010154366958886e-05, Min w: 0.9669225215911865\n",
      "Iteration 940, Loss: 5.7522207498550415e-05, Min w: 0.9675469398498535\n",
      "Iteration 950, Loss: 6.587690586457029e-05, Min w: 0.9625487923622131\n",
      "Iteration 960, Loss: 7.08715379005298e-05, Min w: 0.9628454446792603\n",
      "Iteration 970, Loss: 6.2392013205681e-05, Min w: 0.9680401682853699\n",
      "Iteration 980, Loss: 5.6718239648034796e-05, Min w: 0.9654253125190735\n",
      "Iteration 990, Loss: 6.973509152885526e-05, Min w: 0.9630089998245239\n",
      "Iteration 1000, Loss: 6.431498331949115e-05, Min w: 0.9636337161064148\n",
      "Iteration 1010, Loss: 5.670843165717088e-05, Min w: 0.9665802121162415\n",
      "Iteration 1020, Loss: 5.5824384617153555e-05, Min w: 0.9686233401298523\n",
      "Iteration 1030, Loss: 5.991914076730609e-05, Min w: 0.9624431133270264\n",
      "Iteration 1040, Loss: 6.564871000591666e-05, Min w: 0.9599071741104126\n",
      "Iteration 1050, Loss: 6.462752935476601e-05, Min w: 0.9660391807556152\n",
      "Iteration 1060, Loss: 5.7847253629006445e-05, Min w: 0.9652407169342041\n",
      "Iteration 1070, Loss: 5.5484877520939335e-05, Min w: 0.9647793769836426\n",
      "Iteration 1080, Loss: 5.652644904330373e-05, Min w: 0.9675721526145935\n",
      "Iteration 1090, Loss: 5.851404421264306e-05, Min w: 0.9687086343765259\n",
      "Iteration 1100, Loss: 6.967825174797326e-05, Min w: 0.9620612859725952\n",
      "Iteration 1110, Loss: 7.534574979217723e-05, Min w: 0.9607935547828674\n",
      "Iteration 1120, Loss: 5.9167217841604725e-05, Min w: 0.9661590456962585\n",
      "Iteration 1130, Loss: 5.537305696634576e-05, Min w: 0.9692162871360779\n",
      "Iteration 1140, Loss: 5.8576602896209806e-05, Min w: 0.9682157039642334\n",
      "Iteration 1150, Loss: 6.042935638106428e-05, Min w: 0.9681730270385742\n",
      "Iteration 1160, Loss: 5.902436896576546e-05, Min w: 0.9672096371650696\n",
      "Iteration 1170, Loss: 5.575075920205563e-05, Min w: 0.9673835635185242\n",
      "Iteration 1180, Loss: 6.730064342264086e-05, Min w: 0.9638497233390808\n",
      "Iteration 1190, Loss: 5.8650693972595036e-05, Min w: 0.9682325124740601\n",
      "Iteration 1200, Loss: 5.826785127283074e-05, Min w: 0.9663794636726379\n",
      "Iteration 1210, Loss: 5.724910079152323e-05, Min w: 0.9690178632736206\n",
      "Iteration 1220, Loss: 5.276545925880782e-05, Min w: 0.9691673517227173\n",
      "Iteration 1230, Loss: 5.075929220765829e-05, Min w: 0.972395658493042\n",
      "Iteration 1240, Loss: 6.20118371443823e-05, Min w: 0.9677149057388306\n",
      "Iteration 0, Loss: 6.0012112953700125e-05, Min w: 0.965927243232727\n",
      "Iteration 10, Loss: 6.03212793066632e-05, Min w: 0.9667123556137085\n",
      "Iteration 20, Loss: 5.5937340221134946e-05, Min w: 0.9707441926002502\n",
      "Iteration 30, Loss: 5.011792018194683e-05, Min w: 0.9722525477409363\n",
      "Iteration 40, Loss: 6.016480256221257e-05, Min w: 0.968366801738739\n",
      "Iteration 50, Loss: 5.6843993661459535e-05, Min w: 0.9672393798828125\n",
      "Iteration 60, Loss: 4.8287482059095055e-05, Min w: 0.972063422203064\n",
      "Iteration 70, Loss: 5.325572783476673e-05, Min w: 0.9695765376091003\n",
      "Iteration 80, Loss: 5.305661034071818e-05, Min w: 0.96881103515625\n",
      "Iteration 90, Loss: 5.8269819419365376e-05, Min w: 0.9680743217468262\n",
      "Iteration 100, Loss: 8.145392348524183e-05, Min w: 0.9490741491317749\n",
      "Iteration 110, Loss: 6.265617412282154e-05, Min w: 0.9665366411209106\n",
      "Iteration 120, Loss: 5.3042593208374456e-05, Min w: 0.9707221388816833\n",
      "Iteration 130, Loss: 5.7458822993794456e-05, Min w: 0.9697446227073669\n",
      "Iteration 140, Loss: 5.260386024019681e-05, Min w: 0.9709461331367493\n",
      "Iteration 150, Loss: 5.581326695391908e-05, Min w: 0.9686239957809448\n",
      "Iteration 160, Loss: 5.395684274844825e-05, Min w: 0.9696849584579468\n",
      "Iteration 170, Loss: 5.859606244484894e-05, Min w: 0.9689387083053589\n",
      "Iteration 180, Loss: 8.604668983025476e-05, Min w: 0.9441384673118591\n",
      "Iteration 190, Loss: 5.2721148676937446e-05, Min w: 0.9699282646179199\n",
      "Iteration 200, Loss: 5.392509774537757e-05, Min w: 0.9695923924446106\n",
      "Iteration 210, Loss: 5.500379847944714e-05, Min w: 0.9706839919090271\n",
      "Iteration 220, Loss: 5.279708784655668e-05, Min w: 0.9700810313224792\n",
      "Iteration 230, Loss: 5.3967498388374224e-05, Min w: 0.968498706817627\n",
      "Iteration 240, Loss: 5.148745549377054e-05, Min w: 0.9699966907501221\n",
      "Iteration 250, Loss: 5.269213215797208e-05, Min w: 0.9723110795021057\n",
      "Iteration 260, Loss: 5.1466184231685475e-05, Min w: 0.9704275727272034\n",
      "Iteration 270, Loss: 4.845437433687039e-05, Min w: 0.9719218015670776\n",
      "Iteration 280, Loss: 4.899269333691336e-05, Min w: 0.9709855914115906\n",
      "Iteration 290, Loss: 5.8185949455946684e-05, Min w: 0.9683946967124939\n",
      "Iteration 300, Loss: 5.285818042466417e-05, Min w: 0.9698418378829956\n",
      "Iteration 310, Loss: 6.441745790652931e-05, Min w: 0.9656729698181152\n",
      "Iteration 320, Loss: 5.0671122153289616e-05, Min w: 0.9703933596611023\n",
      "Iteration 330, Loss: 5.275619332678616e-05, Min w: 0.9703037738800049\n",
      "Iteration 340, Loss: 5.122279981151223e-05, Min w: 0.9716007709503174\n",
      "Iteration 350, Loss: 4.792499021277763e-05, Min w: 0.9742192029953003\n",
      "Iteration 360, Loss: 4.818808156414889e-05, Min w: 0.9718865156173706\n",
      "Iteration 370, Loss: 6.0924907302251086e-05, Min w: 0.9646621346473694\n",
      "Iteration 380, Loss: 5.92343567404896e-05, Min w: 0.9685731530189514\n",
      "Iteration 390, Loss: 5.283969221636653e-05, Min w: 0.9717276096343994\n",
      "Iteration 400, Loss: 4.927281042910181e-05, Min w: 0.9727197885513306\n",
      "Iteration 410, Loss: 5.152634184923954e-05, Min w: 0.9713981747627258\n",
      "Iteration 420, Loss: 5.051585321780294e-05, Min w: 0.9713807702064514\n",
      "Iteration 430, Loss: 7.555045885965228e-05, Min w: 0.9540715217590332\n",
      "Iteration 440, Loss: 5.3247076721163467e-05, Min w: 0.9719294309616089\n",
      "Iteration 450, Loss: 4.9449881771579385e-05, Min w: 0.9725597500801086\n",
      "Iteration 460, Loss: 4.773912223754451e-05, Min w: 0.9730907082557678\n",
      "Iteration 470, Loss: 4.891044955002144e-05, Min w: 0.9723922610282898\n",
      "Iteration 480, Loss: 5.006913488614373e-05, Min w: 0.9712435007095337\n",
      "Iteration 490, Loss: 4.3402436858741567e-05, Min w: 0.9757208824157715\n",
      "Iteration 500, Loss: 4.693182199844159e-05, Min w: 0.9750904440879822\n",
      "Iteration 510, Loss: 4.887302566203289e-05, Min w: 0.9745152592658997\n",
      "Iteration 520, Loss: 5.095648157293908e-05, Min w: 0.9733421206474304\n",
      "Iteration 530, Loss: 4.574282866087742e-05, Min w: 0.9748809933662415\n",
      "Iteration 540, Loss: 4.7111749154282734e-05, Min w: 0.9733374714851379\n",
      "Iteration 550, Loss: 4.7891746362438425e-05, Min w: 0.9727899432182312\n",
      "Iteration 560, Loss: 5.093433355796151e-05, Min w: 0.9737426042556763\n",
      "Iteration 570, Loss: 5.283353311824612e-05, Min w: 0.9715949296951294\n",
      "Iteration 580, Loss: 6.031472366885282e-05, Min w: 0.969071090221405\n",
      "Iteration 590, Loss: 4.952267772750929e-05, Min w: 0.9746093153953552\n",
      "Iteration 600, Loss: 4.390926187625155e-05, Min w: 0.9769234657287598\n",
      "Iteration 610, Loss: 5.032154149375856e-05, Min w: 0.970747172832489\n",
      "Iteration 620, Loss: 5.9825666539836675e-05, Min w: 0.9681109189987183\n",
      "Iteration 630, Loss: 4.670648559113033e-05, Min w: 0.9723138809204102\n",
      "Iteration 640, Loss: 5.129353667143732e-05, Min w: 0.9734195470809937\n",
      "Iteration 650, Loss: 5.263778439257294e-05, Min w: 0.9727501273155212\n",
      "Iteration 660, Loss: 4.80822563986294e-05, Min w: 0.974182665348053\n",
      "Iteration 670, Loss: 4.957392593496479e-05, Min w: 0.9743879437446594\n",
      "Iteration 680, Loss: 5.6127351854229346e-05, Min w: 0.9710515737533569\n",
      "Iteration 690, Loss: 4.21939002990257e-05, Min w: 0.9764599204063416\n",
      "Iteration 700, Loss: 4.541310772765428e-05, Min w: 0.9762322902679443\n",
      "Iteration 710, Loss: 4.4583350245375186e-05, Min w: 0.9755672812461853\n",
      "Iteration 720, Loss: 4.570511737256311e-05, Min w: 0.9759995937347412\n",
      "Iteration 730, Loss: 4.6585504605900496e-05, Min w: 0.9757371544837952\n",
      "Iteration 740, Loss: 4.874055230175145e-05, Min w: 0.9738557934761047\n",
      "Iteration 750, Loss: 4.631802221410908e-05, Min w: 0.9761109352111816\n",
      "Iteration 760, Loss: 4.767828795593232e-05, Min w: 0.9755125641822815\n",
      "Iteration 770, Loss: 5.004334889235906e-05, Min w: 0.9728595614433289\n",
      "Iteration 780, Loss: 4.587575313053094e-05, Min w: 0.9765347838401794\n",
      "Iteration 790, Loss: 6.615553866140544e-05, Min w: 0.9600515961647034\n",
      "Iteration 800, Loss: 4.978278957423754e-05, Min w: 0.9740228056907654\n",
      "Iteration 810, Loss: 5.3698342526331544e-05, Min w: 0.9714535474777222\n",
      "Iteration 820, Loss: 4.8327536205761135e-05, Min w: 0.9738780856132507\n",
      "Iteration 830, Loss: 4.456946044228971e-05, Min w: 0.9762666821479797\n",
      "Iteration 840, Loss: 4.451797576621175e-05, Min w: 0.9757758378982544\n",
      "Iteration 850, Loss: 4.446964157978073e-05, Min w: 0.9767425656318665\n",
      "Iteration 860, Loss: 3.8513066101586446e-05, Min w: 0.9791085720062256\n",
      "Iteration 870, Loss: 4.8786765546537936e-05, Min w: 0.9735747575759888\n",
      "Iteration 880, Loss: 4.504860771703534e-05, Min w: 0.9762551188468933\n",
      "Iteration 890, Loss: 5.585776671068743e-05, Min w: 0.9692413210868835\n",
      "Iteration 900, Loss: 5.963450894341804e-05, Min w: 0.9647647738456726\n",
      "Iteration 910, Loss: 3.880807707901113e-05, Min w: 0.9794089794158936\n",
      "Iteration 920, Loss: 5.0676451792242005e-05, Min w: 0.9734748601913452\n",
      "Iteration 930, Loss: 4.244138108333573e-05, Min w: 0.9770270586013794\n",
      "Iteration 940, Loss: 4.1190320189343765e-05, Min w: 0.9756565093994141\n",
      "Iteration 950, Loss: 4.273064769222401e-05, Min w: 0.9762392640113831\n",
      "Iteration 960, Loss: 4.495267057791352e-05, Min w: 0.9768637418746948\n",
      "Iteration 970, Loss: 4.198216265649535e-05, Min w: 0.9777929186820984\n",
      "Iteration 980, Loss: 4.7619174438295886e-05, Min w: 0.9741131663322449\n",
      "Iteration 990, Loss: 4.7350695240311325e-05, Min w: 0.9738720059394836\n",
      "Iteration 1000, Loss: 5.3475981985684484e-05, Min w: 0.9698519706726074\n",
      "Iteration 1010, Loss: 5.180039443075657e-05, Min w: 0.9720981121063232\n",
      "Iteration 1020, Loss: 4.5972214138600975e-05, Min w: 0.9754156470298767\n",
      "Iteration 1030, Loss: 5.712169877369888e-05, Min w: 0.9648771286010742\n",
      "Iteration 1040, Loss: 4.540482041193172e-05, Min w: 0.976178765296936\n",
      "Iteration 1050, Loss: 4.029678530059755e-05, Min w: 0.9787353277206421\n",
      "Iteration 1060, Loss: 4.4761367462342605e-05, Min w: 0.9766535758972168\n",
      "Iteration 1070, Loss: 5.058146416558884e-05, Min w: 0.973344087600708\n",
      "Iteration 1080, Loss: 4.15404538216535e-05, Min w: 0.9782485365867615\n",
      "Iteration 1090, Loss: 4.033022923977114e-05, Min w: 0.9792530536651611\n",
      "Iteration 1100, Loss: 3.9493348594987765e-05, Min w: 0.9791451096534729\n",
      "Iteration 1110, Loss: 3.853534144582227e-05, Min w: 0.9786669611930847\n",
      "Iteration 1120, Loss: 3.9483493310399354e-05, Min w: 0.9794222712516785\n",
      "Iteration 1130, Loss: 4.216575689497404e-05, Min w: 0.9778270125389099\n",
      "Iteration 1140, Loss: 4.062849620822817e-05, Min w: 0.9789835810661316\n",
      "Iteration 1150, Loss: 5.3124229452805594e-05, Min w: 0.9679363369941711\n",
      "Iteration 1160, Loss: 5.781976869911887e-05, Min w: 0.9650601744651794\n",
      "Iteration 1170, Loss: 4.345470733824186e-05, Min w: 0.9774187207221985\n",
      "Iteration 1180, Loss: 5.0516275223344564e-05, Min w: 0.9691429138183594\n",
      "Iteration 1190, Loss: 4.096165866940282e-05, Min w: 0.9783363938331604\n",
      "Iteration 1200, Loss: 4.2536641558399424e-05, Min w: 0.9765585064888\n",
      "Iteration 1210, Loss: 5.049509127275087e-05, Min w: 0.9695625305175781\n",
      "Iteration 1220, Loss: 3.801758793997578e-05, Min w: 0.9787691831588745\n",
      "Iteration 1230, Loss: 4.6616190957138315e-05, Min w: 0.9733470678329468\n",
      "Iteration 1240, Loss: 4.187134254607372e-05, Min w: 0.978408694267273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  54%|█████▍    | 13/24 [20:33<18:46, 102.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.012804444453650456, 'L2_avg': 0.01491081924782299, 'End_point_L1_avg': 0.01192350224999824, 'End_point_L2_avg': 0.011926692409303085}\n",
      "Iteration 0, Loss: 0.003989763557910919, Min w: 0.0\n",
      "Iteration 10, Loss: 0.003396827494725585, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0031225739512592554, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0032700698357075453, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0032215930987149477, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002917063655331731, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0022729176562279463, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002112716669216752, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001959409797564149, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0018338336376473308, Min w: 0.0\n",
      "Iteration 100, Loss: 0.001777155790477991, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0017042207764461637, Min w: 0.0\n",
      "Iteration 120, Loss: 0.001672244630753994, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0016299174167215824, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0015353993512690067, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0016190913738682866, Min w: 0.0\n",
      "Iteration 160, Loss: 0.001537651871331036, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0016195145435631275, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0017011462477967143, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0017678560689091682, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0018567064544185996, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0018503356259316206, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0017456758068874478, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0016029960243031383, Min w: 0.0\n",
      "Iteration 240, Loss: 0.001584916259162128, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0015276182675734162, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0014661716995760798, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00152665248606354, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0015873117372393608, Min w: 1.5380494999001188e-38\n",
      "Iteration 290, Loss: 0.001488073030486703, Min w: 3.8684420703640074e-30\n",
      "Iteration 300, Loss: 0.0014697634615004063, Min w: 2.319287008163504e-21\n",
      "Iteration 310, Loss: 0.0014498436357825994, Min w: 1.0291677313969613e-13\n",
      "Iteration 320, Loss: 0.0015696478076279163, Min w: 6.370968890223594e-07\n",
      "Iteration 330, Loss: 0.001478638150729239, Min w: 0.0765547826886177\n",
      "Iteration 340, Loss: 0.0013462028000503778, Min w: 0.13850349187850952\n",
      "Iteration 350, Loss: 0.0013348849024623632, Min w: 0.18566378951072693\n",
      "Iteration 360, Loss: 0.0012716402998194098, Min w: 0.20885993540287018\n",
      "Iteration 370, Loss: 0.0011939455289393663, Min w: 0.24287225306034088\n",
      "Iteration 380, Loss: 0.0012010436039417982, Min w: 0.2424386888742447\n",
      "Iteration 390, Loss: 0.0011595854302868247, Min w: 0.2581254839897156\n",
      "Iteration 400, Loss: 0.0011562525760382414, Min w: 0.26515376567840576\n",
      "Iteration 410, Loss: 0.0011624179314821959, Min w: 0.2554435133934021\n",
      "Iteration 420, Loss: 0.001147999195381999, Min w: 0.2857726812362671\n",
      "Iteration 430, Loss: 0.0011019660159945488, Min w: 0.31031450629234314\n",
      "Iteration 440, Loss: 0.0011272658593952656, Min w: 0.3007087707519531\n",
      "Iteration 450, Loss: 0.0010975589975714684, Min w: 0.3171147108078003\n",
      "Iteration 460, Loss: 0.0010310265934094787, Min w: 0.35259467363357544\n",
      "Iteration 470, Loss: 0.0010429034009575844, Min w: 0.3404010236263275\n",
      "Iteration 480, Loss: 0.0010370684321969748, Min w: 0.34843263030052185\n",
      "Iteration 490, Loss: 0.001019840594381094, Min w: 0.3495378792285919\n",
      "Iteration 500, Loss: 0.001001283642835915, Min w: 0.3681783080101013\n",
      "Iteration 510, Loss: 0.0009785190923139453, Min w: 0.3773634731769562\n",
      "Iteration 520, Loss: 0.000984303536824882, Min w: 0.38520148396492004\n",
      "Iteration 530, Loss: 0.0009601576603017747, Min w: 0.3878042995929718\n",
      "Iteration 540, Loss: 0.0009057176648639143, Min w: 0.4090802073478699\n",
      "Iteration 550, Loss: 0.0009534033597446978, Min w: 0.39300355315208435\n",
      "Iteration 560, Loss: 0.0009556630393490195, Min w: 0.38377654552459717\n",
      "Iteration 570, Loss: 0.0009265253902412951, Min w: 0.3992135226726532\n",
      "Iteration 580, Loss: 0.0008802193333394825, Min w: 0.43094930052757263\n",
      "Iteration 590, Loss: 0.0008872355101630092, Min w: 0.42532989382743835\n",
      "Iteration 600, Loss: 0.0008531804196536541, Min w: 0.4379352331161499\n",
      "Iteration 610, Loss: 0.0008891371544450521, Min w: 0.4525372385978699\n",
      "Iteration 620, Loss: 0.0008523399010300636, Min w: 0.4558458924293518\n",
      "Iteration 630, Loss: 0.0008409165893681347, Min w: 0.44341838359832764\n",
      "Iteration 640, Loss: 0.0008720894693396986, Min w: 0.4572533965110779\n",
      "Iteration 650, Loss: 0.0008584869792684913, Min w: 0.4655683934688568\n",
      "Iteration 660, Loss: 0.0008358726627193391, Min w: 0.4596951901912689\n",
      "Iteration 670, Loss: 0.0007872896967455745, Min w: 0.48202651739120483\n",
      "Iteration 680, Loss: 0.0008084260625764728, Min w: 0.4970988929271698\n",
      "Iteration 690, Loss: 0.0007889823173172772, Min w: 0.4881751835346222\n",
      "Iteration 700, Loss: 0.0008200801094062626, Min w: 0.4691261053085327\n",
      "Iteration 710, Loss: 0.0008014166378416121, Min w: 0.503312349319458\n",
      "Iteration 720, Loss: 0.0007820110768079758, Min w: 0.4878343939781189\n",
      "Iteration 730, Loss: 0.0007681678398512304, Min w: 0.5137290358543396\n",
      "Iteration 740, Loss: 0.0007636225200258195, Min w: 0.5139957070350647\n",
      "Iteration 750, Loss: 0.000758740003220737, Min w: 0.5003727674484253\n",
      "Iteration 760, Loss: 0.0007610631291754544, Min w: 0.5129579305648804\n",
      "Iteration 770, Loss: 0.0007530447328463197, Min w: 0.5255113840103149\n",
      "Iteration 780, Loss: 0.0007321015582419932, Min w: 0.5009595155715942\n",
      "Iteration 790, Loss: 0.0007638639654032886, Min w: 0.5062611103057861\n",
      "Iteration 800, Loss: 0.0007213688804768026, Min w: 0.536732017993927\n",
      "Iteration 810, Loss: 0.0007486401009373367, Min w: 0.5122025012969971\n",
      "Iteration 820, Loss: 0.0007460879860445857, Min w: 0.4972675144672394\n",
      "Iteration 830, Loss: 0.0007163318223319948, Min w: 0.5363066792488098\n",
      "Iteration 840, Loss: 0.0006923585315234959, Min w: 0.5438820123672485\n",
      "Iteration 850, Loss: 0.0007268820190802217, Min w: 0.5330522656440735\n",
      "Iteration 860, Loss: 0.0006804211880080402, Min w: 0.5494793057441711\n",
      "Iteration 870, Loss: 0.0006899849395267665, Min w: 0.5509347319602966\n",
      "Iteration 880, Loss: 0.0006673979805782437, Min w: 0.553854763507843\n",
      "Iteration 890, Loss: 0.0006933494587428868, Min w: 0.5489310622215271\n",
      "Iteration 900, Loss: 0.0006700210506096482, Min w: 0.5706238150596619\n",
      "Iteration 910, Loss: 0.000698590069077909, Min w: 0.5656854510307312\n",
      "Iteration 920, Loss: 0.0006875548860989511, Min w: 0.5597206354141235\n",
      "Iteration 930, Loss: 0.0006289355806075037, Min w: 0.5813475847244263\n",
      "Iteration 940, Loss: 0.000646761036477983, Min w: 0.5605992674827576\n",
      "Iteration 950, Loss: 0.00064572918927297, Min w: 0.5841830968856812\n",
      "Iteration 960, Loss: 0.0006086318753659725, Min w: 0.5785824656486511\n",
      "Iteration 970, Loss: 0.0006409253692254424, Min w: 0.5682976245880127\n",
      "Iteration 980, Loss: 0.0006491262465715408, Min w: 0.6036807894706726\n",
      "Iteration 990, Loss: 0.0006210284773260355, Min w: 0.59597247838974\n",
      "Iteration 1000, Loss: 0.0006131864502094686, Min w: 0.588036835193634\n",
      "Iteration 1010, Loss: 0.0005996614345349371, Min w: 0.6101056337356567\n",
      "Iteration 1020, Loss: 0.0006205174722708762, Min w: 0.6074525713920593\n",
      "Iteration 1030, Loss: 0.0005871074972674251, Min w: 0.6105302572250366\n",
      "Iteration 1040, Loss: 0.0006000648136250675, Min w: 0.6155382990837097\n",
      "Iteration 1050, Loss: 0.0005771609721705317, Min w: 0.6128367185592651\n",
      "Iteration 1060, Loss: 0.0005914443754591048, Min w: 0.6098729372024536\n",
      "Iteration 1070, Loss: 0.0006008822238072753, Min w: 0.6081883311271667\n",
      "Iteration 1080, Loss: 0.000563268200494349, Min w: 0.6343492269515991\n",
      "Iteration 1090, Loss: 0.0006024641334079206, Min w: 0.6155327558517456\n",
      "Iteration 1100, Loss: 0.000543726549949497, Min w: 0.637395441532135\n",
      "Iteration 1110, Loss: 0.0005617804126814008, Min w: 0.6250848174095154\n",
      "Iteration 1120, Loss: 0.0005489542963914573, Min w: 0.6416478157043457\n",
      "Iteration 1130, Loss: 0.000563393346965313, Min w: 0.6352885961532593\n",
      "Iteration 1140, Loss: 0.0005523294094018638, Min w: 0.6442566514015198\n",
      "Iteration 1150, Loss: 0.0005231626564636827, Min w: 0.6464593410491943\n",
      "Iteration 1160, Loss: 0.0005665956414304674, Min w: 0.6493820548057556\n",
      "Iteration 1170, Loss: 0.0005337154725566506, Min w: 0.6471083164215088\n",
      "Iteration 1180, Loss: 0.0005358478520065546, Min w: 0.6532334685325623\n",
      "Iteration 1190, Loss: 0.0005215434357523918, Min w: 0.6528295278549194\n",
      "Iteration 1200, Loss: 0.0005009102751500905, Min w: 0.6686911582946777\n",
      "Iteration 1210, Loss: 0.0005093947984278202, Min w: 0.6607186198234558\n",
      "Iteration 1220, Loss: 0.000513858743943274, Min w: 0.6683145761489868\n",
      "Iteration 1230, Loss: 0.0005238884477876127, Min w: 0.6514301300048828\n",
      "Iteration 1240, Loss: 0.0004870338016189635, Min w: 0.688407301902771\n",
      "Iteration 0, Loss: 0.0004941545194014907, Min w: 0.6733890771865845\n",
      "Iteration 10, Loss: 0.0004869067925028503, Min w: 0.6804348826408386\n",
      "Iteration 20, Loss: 0.0004731415829155594, Min w: 0.680870771408081\n",
      "Iteration 30, Loss: 0.0004798267036676407, Min w: 0.6786108613014221\n",
      "Iteration 40, Loss: 0.00048707585665397346, Min w: 0.6842320561408997\n",
      "Iteration 50, Loss: 0.00048386756679974496, Min w: 0.6803516149520874\n",
      "Iteration 60, Loss: 0.00046021552407182753, Min w: 0.6977394819259644\n",
      "Iteration 70, Loss: 0.00046615549945272505, Min w: 0.6840491890907288\n",
      "Iteration 80, Loss: 0.00044481834629550576, Min w: 0.6985583901405334\n",
      "Iteration 90, Loss: 0.0004496852634474635, Min w: 0.7021903395652771\n",
      "Iteration 100, Loss: 0.00044234617962501943, Min w: 0.7050145268440247\n",
      "Iteration 110, Loss: 0.0004434210422914475, Min w: 0.7082512378692627\n",
      "Iteration 120, Loss: 0.00044346286449581385, Min w: 0.7162540555000305\n",
      "Iteration 130, Loss: 0.0004402359772939235, Min w: 0.7141441702842712\n",
      "Iteration 140, Loss: 0.000434027606388554, Min w: 0.7053462266921997\n",
      "Iteration 150, Loss: 0.0004278091946616769, Min w: 0.7184669971466064\n",
      "Iteration 160, Loss: 0.0004392368718981743, Min w: 0.7153444886207581\n",
      "Iteration 170, Loss: 0.00041946189594455063, Min w: 0.716886579990387\n",
      "Iteration 180, Loss: 0.00042439610115252435, Min w: 0.7281643152236938\n",
      "Iteration 190, Loss: 0.00043237089994363487, Min w: 0.7267431616783142\n",
      "Iteration 200, Loss: 0.00048702527419663966, Min w: 0.7221965193748474\n",
      "Iteration 210, Loss: 0.00042097855475731194, Min w: 0.7323430776596069\n",
      "Iteration 220, Loss: 0.00038126789149828255, Min w: 0.7370932102203369\n",
      "Iteration 230, Loss: 0.0003912314714398235, Min w: 0.7385221719741821\n",
      "Iteration 240, Loss: 0.00041445193346589804, Min w: 0.7320864796638489\n",
      "Iteration 250, Loss: 0.00039258573087863624, Min w: 0.7419301271438599\n",
      "Iteration 260, Loss: 0.00044458158663474023, Min w: 0.7434014081954956\n",
      "Iteration 270, Loss: 0.00039234801079146564, Min w: 0.7447226643562317\n",
      "Iteration 280, Loss: 0.0003828844055533409, Min w: 0.7485629320144653\n",
      "Iteration 290, Loss: 0.00039690418634563684, Min w: 0.744884192943573\n",
      "Iteration 300, Loss: 0.0003798803372774273, Min w: 0.7553941011428833\n",
      "Iteration 310, Loss: 0.00036259341868571937, Min w: 0.7642881274223328\n",
      "Iteration 320, Loss: 0.00035508035216480494, Min w: 0.7618098855018616\n",
      "Iteration 330, Loss: 0.00038375670555979013, Min w: 0.7666770219802856\n",
      "Iteration 340, Loss: 0.0003645843535196036, Min w: 0.7604785561561584\n",
      "Iteration 350, Loss: 0.0003390696074347943, Min w: 0.7670606970787048\n",
      "Iteration 360, Loss: 0.0003364525327924639, Min w: 0.7771620154380798\n",
      "Iteration 370, Loss: 0.00034321643761359155, Min w: 0.7865518927574158\n",
      "Iteration 380, Loss: 0.00035589950857684016, Min w: 0.7722290754318237\n",
      "Iteration 390, Loss: 0.0003631743893492967, Min w: 0.7656066417694092\n",
      "Iteration 400, Loss: 0.0003334991924930364, Min w: 0.7874931693077087\n",
      "Iteration 410, Loss: 0.0003537866286933422, Min w: 0.7728239297866821\n",
      "Iteration 420, Loss: 0.00036314650787971914, Min w: 0.7679466605186462\n",
      "Iteration 430, Loss: 0.0003394655941519886, Min w: 0.7859985828399658\n",
      "Iteration 440, Loss: 0.00033438618993386626, Min w: 0.7966568470001221\n",
      "Iteration 450, Loss: 0.0003180222993250936, Min w: 0.794992208480835\n",
      "Iteration 460, Loss: 0.00034464136115275323, Min w: 0.780070424079895\n",
      "Iteration 470, Loss: 0.00035575064248405397, Min w: 0.7887865900993347\n",
      "Iteration 480, Loss: 0.00031968671828508377, Min w: 0.7933820486068726\n",
      "Iteration 490, Loss: 0.00031066162046045065, Min w: 0.8049213290214539\n",
      "Iteration 500, Loss: 0.00036709895357489586, Min w: 0.7831845879554749\n",
      "Iteration 510, Loss: 0.00036001147236675024, Min w: 0.784679651260376\n",
      "Iteration 520, Loss: 0.00033043898292817175, Min w: 0.8054273724555969\n",
      "Iteration 530, Loss: 0.0003026057092938572, Min w: 0.8038690686225891\n",
      "Iteration 540, Loss: 0.0003131140547338873, Min w: 0.8022634387016296\n",
      "Iteration 550, Loss: 0.00029886746779084206, Min w: 0.8032928109169006\n",
      "Iteration 560, Loss: 0.00031381985172629356, Min w: 0.8039252161979675\n",
      "Iteration 570, Loss: 0.00030099318246357143, Min w: 0.8076522946357727\n",
      "Iteration 580, Loss: 0.00031360273715108633, Min w: 0.7994778752326965\n",
      "Iteration 590, Loss: 0.0002815320622175932, Min w: 0.8163303136825562\n",
      "Iteration 600, Loss: 0.00030231010168790817, Min w: 0.8139263987541199\n",
      "Iteration 610, Loss: 0.0002742280485108495, Min w: 0.8278829455375671\n",
      "Iteration 620, Loss: 0.0002900274994317442, Min w: 0.8161712288856506\n",
      "Iteration 630, Loss: 0.00029021449154242873, Min w: 0.8244983553886414\n",
      "Iteration 640, Loss: 0.00027533952379599214, Min w: 0.8260059356689453\n",
      "Iteration 650, Loss: 0.0002872038458008319, Min w: 0.8212857842445374\n",
      "Iteration 660, Loss: 0.00028141570510342717, Min w: 0.8234447240829468\n",
      "Iteration 670, Loss: 0.00027522729942575097, Min w: 0.8319348096847534\n",
      "Iteration 680, Loss: 0.00028275587828829885, Min w: 0.8200876116752625\n",
      "Iteration 690, Loss: 0.00027242163196206093, Min w: 0.8250434994697571\n",
      "Iteration 700, Loss: 0.00027725304244086146, Min w: 0.8251780867576599\n",
      "Iteration 710, Loss: 0.00027320795925334096, Min w: 0.8410301208496094\n",
      "Iteration 720, Loss: 0.00026722540496848524, Min w: 0.8398510217666626\n",
      "Iteration 730, Loss: 0.00028251527692191303, Min w: 0.8292389512062073\n",
      "Iteration 740, Loss: 0.00029277874273248017, Min w: 0.8255211114883423\n",
      "Iteration 750, Loss: 0.0002940670237876475, Min w: 0.8296524286270142\n",
      "Iteration 760, Loss: 0.0002768446283880621, Min w: 0.8414385318756104\n",
      "Iteration 770, Loss: 0.0002551133802626282, Min w: 0.8462725877761841\n",
      "Iteration 780, Loss: 0.00025588649441488087, Min w: 0.8448331952095032\n",
      "Iteration 790, Loss: 0.00024350553576368839, Min w: 0.8463707566261292\n",
      "Iteration 800, Loss: 0.0002516849199309945, Min w: 0.8375950455665588\n",
      "Iteration 810, Loss: 0.0002579441061243415, Min w: 0.8322911262512207\n",
      "Iteration 820, Loss: 0.00025912944693118334, Min w: 0.8401028513908386\n",
      "Iteration 830, Loss: 0.0002470511244609952, Min w: 0.8387712836265564\n",
      "Iteration 840, Loss: 0.0002483978169038892, Min w: 0.8535829186439514\n",
      "Iteration 850, Loss: 0.00024367492005694658, Min w: 0.8509769439697266\n",
      "Iteration 860, Loss: 0.0002448670275043696, Min w: 0.8550131916999817\n",
      "Iteration 870, Loss: 0.00025756238028407097, Min w: 0.8501110672950745\n",
      "Iteration 880, Loss: 0.00023628251801710576, Min w: 0.8555690050125122\n",
      "Iteration 890, Loss: 0.00022159828222356737, Min w: 0.8580121994018555\n",
      "Iteration 900, Loss: 0.00022783460735809058, Min w: 0.8516709208488464\n",
      "Iteration 910, Loss: 0.0002450099273119122, Min w: 0.8518655896186829\n",
      "Iteration 920, Loss: 0.0002483955177012831, Min w: 0.8520500659942627\n",
      "Iteration 930, Loss: 0.0002265276270918548, Min w: 0.860736608505249\n",
      "Iteration 940, Loss: 0.00025003377231769264, Min w: 0.850787878036499\n",
      "Iteration 950, Loss: 0.00024820194812491536, Min w: 0.843151867389679\n",
      "Iteration 960, Loss: 0.0002527193573769182, Min w: 0.8571572303771973\n",
      "Iteration 970, Loss: 0.00022259756224229932, Min w: 0.8720371127128601\n",
      "Iteration 980, Loss: 0.00023867326672188938, Min w: 0.8512356281280518\n",
      "Iteration 990, Loss: 0.00023479929950553924, Min w: 0.8641743659973145\n",
      "Iteration 1000, Loss: 0.00024035129172261804, Min w: 0.8636226058006287\n",
      "Iteration 1010, Loss: 0.00022799154976382852, Min w: 0.8622082471847534\n",
      "Iteration 1020, Loss: 0.00021713750902563334, Min w: 0.86630779504776\n",
      "Iteration 1030, Loss: 0.00022785717737860978, Min w: 0.8695209622383118\n",
      "Iteration 1040, Loss: 0.00022677404922433197, Min w: 0.8527077436447144\n",
      "Iteration 1050, Loss: 0.00020529641187749803, Min w: 0.8745002746582031\n",
      "Iteration 1060, Loss: 0.0002109485794790089, Min w: 0.8700807690620422\n",
      "Iteration 1070, Loss: 0.00020315934671089053, Min w: 0.8743645548820496\n",
      "Iteration 1080, Loss: 0.00020918497466482222, Min w: 0.865531861782074\n",
      "Iteration 1090, Loss: 0.0002197111607529223, Min w: 0.8760423064231873\n",
      "Iteration 1100, Loss: 0.00020120594126638025, Min w: 0.8802420496940613\n",
      "Iteration 1110, Loss: 0.00021459817071445286, Min w: 0.8707101941108704\n",
      "Iteration 1120, Loss: 0.0001979602238861844, Min w: 0.8820366859436035\n",
      "Iteration 1130, Loss: 0.00020266608044039458, Min w: 0.8754175901412964\n",
      "Iteration 1140, Loss: 0.00019007224182132632, Min w: 0.8803330659866333\n",
      "Iteration 1150, Loss: 0.00020996472449041903, Min w: 0.8797210454940796\n",
      "Iteration 1160, Loss: 0.00018149155948776752, Min w: 0.8908048272132874\n",
      "Iteration 1170, Loss: 0.0002094245865009725, Min w: 0.8832266926765442\n",
      "Iteration 1180, Loss: 0.00019532277656253427, Min w: 0.8831223845481873\n",
      "Iteration 1190, Loss: 0.00019622761465143412, Min w: 0.8881997466087341\n",
      "Iteration 1200, Loss: 0.00020275772840250283, Min w: 0.8746954798698425\n",
      "Iteration 1210, Loss: 0.0002077317622024566, Min w: 0.8844533562660217\n",
      "Iteration 1220, Loss: 0.0001858648902270943, Min w: 0.891393780708313\n",
      "Iteration 1230, Loss: 0.00019547835108824074, Min w: 0.8838534951210022\n",
      "Iteration 1240, Loss: 0.00019276408420410007, Min w: 0.8878583908081055\n",
      "Iteration 0, Loss: 0.00018062209710478783, Min w: 0.8967147469520569\n",
      "Iteration 10, Loss: 0.00018873147200793028, Min w: 0.8829355835914612\n",
      "Iteration 20, Loss: 0.00018599045870359987, Min w: 0.8872427940368652\n",
      "Iteration 30, Loss: 0.0001963140966836363, Min w: 0.8825433254241943\n",
      "Iteration 40, Loss: 0.00018466410983819515, Min w: 0.8946570754051208\n",
      "Iteration 50, Loss: 0.00016827290528453887, Min w: 0.8971200585365295\n",
      "Iteration 60, Loss: 0.0001772990362951532, Min w: 0.8961385488510132\n",
      "Iteration 70, Loss: 0.00017752137500792742, Min w: 0.8991216421127319\n",
      "Iteration 80, Loss: 0.00017928342276718467, Min w: 0.8947765827178955\n",
      "Iteration 90, Loss: 0.00019075073942076415, Min w: 0.895967960357666\n",
      "Iteration 100, Loss: 0.00018934525724034756, Min w: 0.8943533301353455\n",
      "Iteration 110, Loss: 0.00018456652469467372, Min w: 0.8981339931488037\n",
      "Iteration 120, Loss: 0.00018220102356281132, Min w: 0.8891367316246033\n",
      "Iteration 130, Loss: 0.00016078833141364157, Min w: 0.902894139289856\n",
      "Iteration 140, Loss: 0.0002358775382163003, Min w: 0.8611001372337341\n",
      "Iteration 150, Loss: 0.00018624331278260797, Min w: 0.9013224244117737\n",
      "Iteration 160, Loss: 0.00017070396279450506, Min w: 0.9022496342658997\n",
      "Iteration 170, Loss: 0.00017527844465803355, Min w: 0.8936811685562134\n",
      "Iteration 180, Loss: 0.0001634502550587058, Min w: 0.9056164622306824\n",
      "Iteration 190, Loss: 0.00016146073176059872, Min w: 0.9051290154457092\n",
      "Iteration 200, Loss: 0.00016448491078335792, Min w: 0.908478319644928\n",
      "Iteration 210, Loss: 0.00015473533130716532, Min w: 0.9125080108642578\n",
      "Iteration 220, Loss: 0.0001514388422947377, Min w: 0.9082021713256836\n",
      "Iteration 230, Loss: 0.0001516707707196474, Min w: 0.9087880253791809\n",
      "Iteration 240, Loss: 0.00015633906878065318, Min w: 0.9069327116012573\n",
      "Iteration 250, Loss: 0.00015593929856549948, Min w: 0.9046547412872314\n",
      "Iteration 260, Loss: 0.00016138688079081476, Min w: 0.9045361280441284\n",
      "Iteration 270, Loss: 0.00019291699572931975, Min w: 0.8973246812820435\n",
      "Iteration 280, Loss: 0.00016076798783615232, Min w: 0.9024850726127625\n",
      "Iteration 290, Loss: 0.00015903262828942388, Min w: 0.9064436554908752\n",
      "Iteration 300, Loss: 0.00014765828382223845, Min w: 0.9108377695083618\n",
      "Iteration 310, Loss: 0.00014627263590227813, Min w: 0.9137386083602905\n",
      "Iteration 320, Loss: 0.00016475949087180197, Min w: 0.9047978520393372\n",
      "Iteration 330, Loss: 0.00015362743579316884, Min w: 0.9086948037147522\n",
      "Iteration 340, Loss: 0.0001553450565552339, Min w: 0.9055967330932617\n",
      "Iteration 350, Loss: 0.0001449447008781135, Min w: 0.9151559472084045\n",
      "Iteration 360, Loss: 0.00013992399908602238, Min w: 0.9187493920326233\n",
      "Iteration 370, Loss: 0.00014602542796637863, Min w: 0.915833592414856\n",
      "Iteration 380, Loss: 0.00014231959357857704, Min w: 0.9179373979568481\n",
      "Iteration 390, Loss: 0.00015347606677096337, Min w: 0.9082724452018738\n",
      "Iteration 400, Loss: 0.0001401624031132087, Min w: 0.9170864820480347\n",
      "Iteration 410, Loss: 0.00013076022150926292, Min w: 0.9213303327560425\n",
      "Iteration 420, Loss: 0.0001528992288513109, Min w: 0.9131727814674377\n",
      "Iteration 430, Loss: 0.00014561746502295136, Min w: 0.9196240901947021\n",
      "Iteration 440, Loss: 0.0001424799847882241, Min w: 0.9126866459846497\n",
      "Iteration 450, Loss: 0.00014616003318224102, Min w: 0.9214462041854858\n",
      "Iteration 460, Loss: 0.00014415234909392893, Min w: 0.9136320948600769\n",
      "Iteration 470, Loss: 0.00014260980242397636, Min w: 0.9205411076545715\n",
      "Iteration 480, Loss: 0.00013398996088653803, Min w: 0.9138033390045166\n",
      "Iteration 490, Loss: 0.00012570850958582014, Min w: 0.9251962900161743\n",
      "Iteration 500, Loss: 0.0001277221745112911, Min w: 0.9253674745559692\n",
      "Iteration 510, Loss: 0.0001484970562160015, Min w: 0.9168846607208252\n",
      "Iteration 520, Loss: 0.0001407194067724049, Min w: 0.9182785153388977\n",
      "Iteration 530, Loss: 0.00013928592670708895, Min w: 0.9207257628440857\n",
      "Iteration 540, Loss: 0.00013224802387412637, Min w: 0.9246155023574829\n",
      "Iteration 550, Loss: 0.00014276820002123713, Min w: 0.9148576855659485\n",
      "Iteration 560, Loss: 0.00013662521087098867, Min w: 0.9129577875137329\n",
      "Iteration 570, Loss: 0.00014241512690205127, Min w: 0.9181777834892273\n",
      "Iteration 580, Loss: 0.00012877855624537915, Min w: 0.9211651682853699\n",
      "Iteration 590, Loss: 0.0001314040127908811, Min w: 0.9264945983886719\n",
      "Iteration 600, Loss: 0.00016341000446118414, Min w: 0.9139804244041443\n",
      "Iteration 610, Loss: 0.00012207044346723706, Min w: 0.9229371547698975\n",
      "Iteration 620, Loss: 0.00014283880591392517, Min w: 0.9215701818466187\n",
      "Iteration 630, Loss: 0.0001367507502436638, Min w: 0.9236241579055786\n",
      "Iteration 640, Loss: 0.00014020639355294406, Min w: 0.9155260324478149\n",
      "Iteration 650, Loss: 0.0001355696440441534, Min w: 0.9272343516349792\n",
      "Iteration 660, Loss: 0.00012476209667511284, Min w: 0.9228948354721069\n",
      "Iteration 670, Loss: 0.00016903088544495404, Min w: 0.912143349647522\n",
      "Iteration 680, Loss: 0.0001400733890477568, Min w: 0.9187819957733154\n",
      "Iteration 690, Loss: 0.00014384898531716317, Min w: 0.9120444059371948\n",
      "Iteration 700, Loss: 0.00013082344958093017, Min w: 0.9209243655204773\n",
      "Iteration 710, Loss: 0.0001257382973562926, Min w: 0.9234985113143921\n",
      "Iteration 720, Loss: 0.0001227637258125469, Min w: 0.9324562549591064\n",
      "Iteration 730, Loss: 0.00013224298891145736, Min w: 0.9203365445137024\n",
      "Iteration 740, Loss: 0.00011695510329445824, Min w: 0.9294337034225464\n",
      "Iteration 750, Loss: 0.00012263051758054644, Min w: 0.9280666708946228\n",
      "Iteration 760, Loss: 0.00011394120519980788, Min w: 0.927582323551178\n",
      "Iteration 770, Loss: 0.00013295013923197985, Min w: 0.9314531683921814\n",
      "Iteration 780, Loss: 0.00011953832290600985, Min w: 0.929369330406189\n",
      "Iteration 790, Loss: 0.00012357215746305883, Min w: 0.9225121736526489\n",
      "Iteration 800, Loss: 0.00013739780115429312, Min w: 0.9164982438087463\n",
      "Iteration 810, Loss: 0.00013384647900238633, Min w: 0.924112856388092\n",
      "Iteration 820, Loss: 0.00013726158067584038, Min w: 0.9237995147705078\n",
      "Iteration 830, Loss: 0.00012876000255346298, Min w: 0.9276489615440369\n",
      "Iteration 840, Loss: 0.00011712827836163342, Min w: 0.9322370886802673\n",
      "Iteration 850, Loss: 0.00011984032607870176, Min w: 0.9260856509208679\n",
      "Iteration 860, Loss: 0.0001159700914286077, Min w: 0.929244339466095\n",
      "Iteration 870, Loss: 0.00010940804349957034, Min w: 0.9273583292961121\n",
      "Iteration 880, Loss: 0.0001120440720114857, Min w: 0.931076169013977\n",
      "Iteration 890, Loss: 0.00011927874584216624, Min w: 0.9345382452011108\n",
      "Iteration 900, Loss: 0.00011293650459265336, Min w: 0.9285820722579956\n",
      "Iteration 910, Loss: 0.00011712382547557354, Min w: 0.9297046661376953\n",
      "Iteration 920, Loss: 0.00011361559154465795, Min w: 0.9293956756591797\n",
      "Iteration 930, Loss: 0.00011950953921768814, Min w: 0.9280655384063721\n",
      "Iteration 940, Loss: 0.00014233119145501405, Min w: 0.9227904081344604\n",
      "Iteration 950, Loss: 0.00010806829232024029, Min w: 0.935126781463623\n",
      "Iteration 960, Loss: 0.00011608351633185521, Min w: 0.934569239616394\n",
      "Iteration 970, Loss: 0.00010749309876700863, Min w: 0.9363029599189758\n",
      "Iteration 980, Loss: 0.00010942558583337814, Min w: 0.9329370856285095\n",
      "Iteration 990, Loss: 0.00011504394205985591, Min w: 0.9279683232307434\n",
      "Iteration 1000, Loss: 0.00011178380373166874, Min w: 0.9352962970733643\n",
      "Iteration 1010, Loss: 0.00010379327432019636, Min w: 0.9349175095558167\n",
      "Iteration 1020, Loss: 0.00011414552864152938, Min w: 0.9305784106254578\n",
      "Iteration 1030, Loss: 0.00012138731108279899, Min w: 0.9313328862190247\n",
      "Iteration 1040, Loss: 0.00010486229439266026, Min w: 0.9362378716468811\n",
      "Iteration 1050, Loss: 0.00011005203850800171, Min w: 0.9385107159614563\n",
      "Iteration 1060, Loss: 0.00010468268010299653, Min w: 0.9339649081230164\n",
      "Iteration 1070, Loss: 0.00010519511124584824, Min w: 0.9355321526527405\n",
      "Iteration 1080, Loss: 0.00011099415860371664, Min w: 0.9310661554336548\n",
      "Iteration 1090, Loss: 0.00010477390605956316, Min w: 0.936405599117279\n",
      "Iteration 1100, Loss: 0.00010210094478679821, Min w: 0.934769332408905\n",
      "Iteration 1110, Loss: 0.00010786193888634443, Min w: 0.9375147819519043\n",
      "Iteration 1120, Loss: 9.95633308775723e-05, Min w: 0.9381181001663208\n",
      "Iteration 1130, Loss: 9.87887178780511e-05, Min w: 0.9412676095962524\n",
      "Iteration 1140, Loss: 0.00010313841630704701, Min w: 0.9354207515716553\n",
      "Iteration 1150, Loss: 0.00010392763215349987, Min w: 0.938502848148346\n",
      "Iteration 1160, Loss: 0.0001038222253555432, Min w: 0.9354569315910339\n",
      "Iteration 1170, Loss: 0.00012807789607904851, Min w: 0.9342806339263916\n",
      "Iteration 1180, Loss: 9.70745604718104e-05, Min w: 0.9382691979408264\n",
      "Iteration 1190, Loss: 0.00011657007416943088, Min w: 0.939486026763916\n",
      "Iteration 1200, Loss: 9.803481225389987e-05, Min w: 0.9410900473594666\n",
      "Iteration 1210, Loss: 0.00010645336442394182, Min w: 0.9386886358261108\n",
      "Iteration 1220, Loss: 0.00010365580237703398, Min w: 0.935355007648468\n",
      "Iteration 1230, Loss: 0.00010438931349199265, Min w: 0.9403395056724548\n",
      "Iteration 1240, Loss: 0.00010806626232806593, Min w: 0.9352819919586182\n",
      "Iteration 0, Loss: 0.0001006693419185467, Min w: 0.9441035985946655\n",
      "Iteration 10, Loss: 9.734648483572528e-05, Min w: 0.9383730888366699\n",
      "Iteration 20, Loss: 0.00011246580834267661, Min w: 0.9308526515960693\n",
      "Iteration 30, Loss: 9.990922262659296e-05, Min w: 0.9391289353370667\n",
      "Iteration 40, Loss: 0.00010735356045188382, Min w: 0.9373247623443604\n",
      "Iteration 50, Loss: 0.0001039014823618345, Min w: 0.9386885762214661\n",
      "Iteration 60, Loss: 0.00010295365063939244, Min w: 0.9376998543739319\n",
      "Iteration 70, Loss: 0.00010456841118866578, Min w: 0.9354166984558105\n",
      "Iteration 80, Loss: 9.266301640309393e-05, Min w: 0.9416316747665405\n",
      "Iteration 90, Loss: 9.838551341090351e-05, Min w: 0.9396491050720215\n",
      "Iteration 100, Loss: 0.00011209700460312888, Min w: 0.9341321587562561\n",
      "Iteration 110, Loss: 9.535341814626008e-05, Min w: 0.943592369556427\n",
      "Iteration 120, Loss: 0.00011333973816363141, Min w: 0.9373176693916321\n",
      "Iteration 130, Loss: 9.780954133020714e-05, Min w: 0.9415239095687866\n",
      "Iteration 140, Loss: 9.47555381571874e-05, Min w: 0.9406694173812866\n",
      "Iteration 150, Loss: 9.14648044272326e-05, Min w: 0.9475990533828735\n",
      "Iteration 160, Loss: 9.753894846653566e-05, Min w: 0.9390402436256409\n",
      "Iteration 170, Loss: 9.884042083285749e-05, Min w: 0.944706916809082\n",
      "Iteration 180, Loss: 8.813961176201701e-05, Min w: 0.9405887126922607\n",
      "Iteration 190, Loss: 9.246751869795844e-05, Min w: 0.9454926252365112\n",
      "Iteration 200, Loss: 9.540697647025809e-05, Min w: 0.9383649826049805\n",
      "Iteration 210, Loss: 9.530815441394225e-05, Min w: 0.9431254863739014\n",
      "Iteration 220, Loss: 9.30396345211193e-05, Min w: 0.9434874653816223\n",
      "Iteration 230, Loss: 0.00012744338891934603, Min w: 0.9284459948539734\n",
      "Iteration 240, Loss: 9.527133079245687e-05, Min w: 0.9405116438865662\n",
      "Iteration 250, Loss: 9.419168782187626e-05, Min w: 0.9448580741882324\n",
      "Iteration 260, Loss: 8.501517731929198e-05, Min w: 0.9495270252227783\n",
      "Iteration 270, Loss: 9.594117727829143e-05, Min w: 0.9431498050689697\n",
      "Iteration 280, Loss: 9.037004201672971e-05, Min w: 0.9475316405296326\n",
      "Iteration 290, Loss: 9.522642358206213e-05, Min w: 0.9461865425109863\n",
      "Iteration 300, Loss: 0.00010331685189157724, Min w: 0.9424102902412415\n",
      "Iteration 310, Loss: 8.922476990846917e-05, Min w: 0.9422231316566467\n",
      "Iteration 320, Loss: 8.69579307618551e-05, Min w: 0.9462929368019104\n",
      "Iteration 330, Loss: 8.656322461320087e-05, Min w: 0.9452345371246338\n",
      "Iteration 340, Loss: 9.683852113084868e-05, Min w: 0.9442935585975647\n",
      "Iteration 350, Loss: 0.00011293494026176631, Min w: 0.9416934847831726\n",
      "Iteration 360, Loss: 0.00010315481631550938, Min w: 0.9427632689476013\n",
      "Iteration 370, Loss: 0.00010660513362381607, Min w: 0.9402048587799072\n",
      "Iteration 380, Loss: 8.519963739672676e-05, Min w: 0.9477795362472534\n",
      "Iteration 390, Loss: 8.256020373664796e-05, Min w: 0.9493581652641296\n",
      "Iteration 400, Loss: 9.429698548046872e-05, Min w: 0.9442643523216248\n",
      "Iteration 410, Loss: 8.332314610015601e-05, Min w: 0.9505616426467896\n",
      "Iteration 420, Loss: 0.00012932735262438655, Min w: 0.9312766194343567\n",
      "Iteration 430, Loss: 8.639345469418913e-05, Min w: 0.9469624757766724\n",
      "Iteration 440, Loss: 8.633712423034012e-05, Min w: 0.9483960866928101\n",
      "Iteration 450, Loss: 7.882680074544623e-05, Min w: 0.9504344463348389\n",
      "Iteration 460, Loss: 8.432652975898236e-05, Min w: 0.9445187449455261\n",
      "Iteration 470, Loss: 7.857272430555895e-05, Min w: 0.9515617489814758\n",
      "Iteration 480, Loss: 7.486989488825202e-05, Min w: 0.951156497001648\n",
      "Iteration 490, Loss: 8.823873940855265e-05, Min w: 0.9473233819007874\n",
      "Iteration 500, Loss: 0.00010413235577289015, Min w: 0.9462836384773254\n",
      "Iteration 510, Loss: 8.419364166911691e-05, Min w: 0.951011598110199\n",
      "Iteration 520, Loss: 9.458627027925104e-05, Min w: 0.9431091547012329\n",
      "Iteration 530, Loss: 8.371031435672194e-05, Min w: 0.9494454264640808\n",
      "Iteration 540, Loss: 8.120189158944413e-05, Min w: 0.9494993090629578\n",
      "Iteration 550, Loss: 8.08387267170474e-05, Min w: 0.9483116865158081\n",
      "Iteration 560, Loss: 8.987401815829799e-05, Min w: 0.9473366141319275\n",
      "Iteration 570, Loss: 9.360865806229413e-05, Min w: 0.9487549066543579\n",
      "Iteration 580, Loss: 8.732462447369471e-05, Min w: 0.9482953548431396\n",
      "Iteration 590, Loss: 8.6449712398462e-05, Min w: 0.9428383111953735\n",
      "Iteration 600, Loss: 7.851512054912746e-05, Min w: 0.9541375041007996\n",
      "Iteration 610, Loss: 8.914406498661265e-05, Min w: 0.946380615234375\n",
      "Iteration 620, Loss: 8.025505667319521e-05, Min w: 0.9517913460731506\n",
      "Iteration 630, Loss: 8.308980613946915e-05, Min w: 0.953231155872345\n",
      "Iteration 640, Loss: 7.58233800297603e-05, Min w: 0.951174259185791\n",
      "Iteration 650, Loss: 8.499481191392988e-05, Min w: 0.9502289891242981\n",
      "Iteration 660, Loss: 8.401878585573286e-05, Min w: 0.9475870132446289\n",
      "Iteration 670, Loss: 7.323827594518661e-05, Min w: 0.9549650549888611\n",
      "Iteration 680, Loss: 8.02819849923253e-05, Min w: 0.9499918222427368\n",
      "Iteration 690, Loss: 7.549401925643906e-05, Min w: 0.9519495368003845\n",
      "Iteration 700, Loss: 7.763037865515798e-05, Min w: 0.9490559697151184\n",
      "Iteration 710, Loss: 7.972207095008343e-05, Min w: 0.9528974890708923\n",
      "Iteration 720, Loss: 8.759557385928929e-05, Min w: 0.9506494998931885\n",
      "Iteration 730, Loss: 7.686526805628091e-05, Min w: 0.9542444944381714\n",
      "Iteration 740, Loss: 7.881120836827904e-05, Min w: 0.9506159424781799\n",
      "Iteration 750, Loss: 7.645965524716303e-05, Min w: 0.9539253115653992\n",
      "Iteration 760, Loss: 9.271356975659728e-05, Min w: 0.9462564587593079\n",
      "Iteration 770, Loss: 8.440770034212619e-05, Min w: 0.9477296471595764\n",
      "Iteration 780, Loss: 7.61995543143712e-05, Min w: 0.9520648717880249\n",
      "Iteration 790, Loss: 7.638856186531484e-05, Min w: 0.9532199501991272\n",
      "Iteration 800, Loss: 7.30274259694852e-05, Min w: 0.9551600217819214\n",
      "Iteration 810, Loss: 8.511549094691873e-05, Min w: 0.9469873905181885\n",
      "Iteration 820, Loss: 8.429625449934974e-05, Min w: 0.9553463459014893\n",
      "Iteration 830, Loss: 8.232372783822939e-05, Min w: 0.9513475298881531\n",
      "Iteration 840, Loss: 7.611035107402131e-05, Min w: 0.9532650709152222\n",
      "Iteration 850, Loss: 7.07073777448386e-05, Min w: 0.9573269486427307\n",
      "Iteration 860, Loss: 7.785767957102507e-05, Min w: 0.9532265663146973\n",
      "Iteration 870, Loss: 7.725023169768974e-05, Min w: 0.9576728940010071\n",
      "Iteration 880, Loss: 8.162100857589394e-05, Min w: 0.9531949758529663\n",
      "Iteration 890, Loss: 7.94905427028425e-05, Min w: 0.9526053071022034\n",
      "Iteration 900, Loss: 7.187413575593382e-05, Min w: 0.9564887285232544\n",
      "Iteration 910, Loss: 8.423117833444849e-05, Min w: 0.9502772092819214\n",
      "Iteration 920, Loss: 7.137868669815361e-05, Min w: 0.9548721313476562\n",
      "Iteration 930, Loss: 6.820273119956255e-05, Min w: 0.9583548307418823\n",
      "Iteration 940, Loss: 7.54508946556598e-05, Min w: 0.9551518559455872\n",
      "Iteration 950, Loss: 6.82217869325541e-05, Min w: 0.9558648467063904\n",
      "Iteration 960, Loss: 6.999890320003033e-05, Min w: 0.9535592198371887\n",
      "Iteration 970, Loss: 7.249988266266882e-05, Min w: 0.9564528465270996\n",
      "Iteration 980, Loss: 7.669898332096636e-05, Min w: 0.9548648595809937\n",
      "Iteration 990, Loss: 7.82776769483462e-05, Min w: 0.9487032890319824\n",
      "Iteration 1000, Loss: 7.354284753091633e-05, Min w: 0.9542493224143982\n",
      "Iteration 1010, Loss: 6.962838961044326e-05, Min w: 0.9560471177101135\n",
      "Iteration 1020, Loss: 8.154879469657317e-05, Min w: 0.9573798775672913\n",
      "Iteration 1030, Loss: 8.120742131723091e-05, Min w: 0.9563784003257751\n",
      "Iteration 1040, Loss: 7.474618905689567e-05, Min w: 0.9503704309463501\n",
      "Iteration 1050, Loss: 6.826030585216358e-05, Min w: 0.9588163495063782\n",
      "Iteration 1060, Loss: 8.471048931824043e-05, Min w: 0.9529169201850891\n",
      "Iteration 1070, Loss: 7.72550847614184e-05, Min w: 0.9562708139419556\n",
      "Iteration 1080, Loss: 8.007956785149872e-05, Min w: 0.9548190832138062\n",
      "Iteration 1090, Loss: 7.591342728119344e-05, Min w: 0.9532530903816223\n",
      "Iteration 1100, Loss: 6.959587335586548e-05, Min w: 0.9581750631332397\n",
      "Iteration 1110, Loss: 7.675910455873236e-05, Min w: 0.9542660713195801\n",
      "Iteration 1120, Loss: 6.81314486428164e-05, Min w: 0.9591599106788635\n",
      "Iteration 1130, Loss: 7.093659223755822e-05, Min w: 0.9549818634986877\n",
      "Iteration 1140, Loss: 8.56590922921896e-05, Min w: 0.9513158202171326\n",
      "Iteration 1150, Loss: 6.8945977545809e-05, Min w: 0.9594951868057251\n",
      "Iteration 1160, Loss: 6.453428795794025e-05, Min w: 0.9580054879188538\n",
      "Iteration 1170, Loss: 6.931839743629098e-05, Min w: 0.9570751190185547\n",
      "Iteration 1180, Loss: 6.620017666136846e-05, Min w: 0.9603797793388367\n",
      "Iteration 1190, Loss: 7.189447933342308e-05, Min w: 0.9560407996177673\n",
      "Iteration 1200, Loss: 7.100087532307953e-05, Min w: 0.9581446051597595\n",
      "Iteration 1210, Loss: 7.826518412912264e-05, Min w: 0.95838463306427\n",
      "Iteration 1220, Loss: 7.097763591445982e-05, Min w: 0.9538610577583313\n",
      "Iteration 1230, Loss: 8.040832472033799e-05, Min w: 0.9562231302261353\n",
      "Iteration 1240, Loss: 6.529464008053765e-05, Min w: 0.9599231481552124\n",
      "Iteration 0, Loss: 6.963546911720186e-05, Min w: 0.9595743417739868\n",
      "Iteration 10, Loss: 7.710004865657538e-05, Min w: 0.9596323370933533\n",
      "Iteration 20, Loss: 7.464044028893113e-05, Min w: 0.9606739282608032\n",
      "Iteration 30, Loss: 6.736838258802891e-05, Min w: 0.9592027068138123\n",
      "Iteration 40, Loss: 6.869510980322957e-05, Min w: 0.9583401083946228\n",
      "Iteration 50, Loss: 6.524717173306271e-05, Min w: 0.9586325883865356\n",
      "Iteration 60, Loss: 6.708457658533007e-05, Min w: 0.9584081768989563\n",
      "Iteration 70, Loss: 6.326824950519949e-05, Min w: 0.9614296555519104\n",
      "Iteration 80, Loss: 6.663017848040909e-05, Min w: 0.9595566391944885\n",
      "Iteration 90, Loss: 6.4287924033124e-05, Min w: 0.9625545740127563\n",
      "Iteration 100, Loss: 6.622757791774347e-05, Min w: 0.9593394994735718\n",
      "Iteration 110, Loss: 7.633788482053205e-05, Min w: 0.9598292112350464\n",
      "Iteration 120, Loss: 6.88251166138798e-05, Min w: 0.9566665291786194\n",
      "Iteration 130, Loss: 6.934451084816828e-05, Min w: 0.9598276019096375\n",
      "Iteration 140, Loss: 6.652712181676179e-05, Min w: 0.962110161781311\n",
      "Iteration 150, Loss: 7.3386931035202e-05, Min w: 0.9585480690002441\n",
      "Iteration 160, Loss: 6.200955976964906e-05, Min w: 0.9592800140380859\n",
      "Iteration 170, Loss: 6.422719161491841e-05, Min w: 0.9605737924575806\n",
      "Iteration 180, Loss: 6.0906520957360044e-05, Min w: 0.9590766429901123\n",
      "Iteration 190, Loss: 6.879919965285808e-05, Min w: 0.9604879021644592\n",
      "Iteration 200, Loss: 6.975305586820468e-05, Min w: 0.9591968059539795\n",
      "Iteration 210, Loss: 6.606732495129108e-05, Min w: 0.9601492881774902\n",
      "Iteration 220, Loss: 6.361267878673971e-05, Min w: 0.960223376750946\n",
      "Iteration 230, Loss: 9.048691572388634e-05, Min w: 0.9526135921478271\n",
      "Iteration 240, Loss: 6.723090336890891e-05, Min w: 0.9636319279670715\n",
      "Iteration 250, Loss: 5.6370354286627844e-05, Min w: 0.9630780220031738\n",
      "Iteration 260, Loss: 6.407699402188882e-05, Min w: 0.959075391292572\n",
      "Iteration 270, Loss: 6.36912664049305e-05, Min w: 0.9607465863227844\n",
      "Iteration 280, Loss: 6.668176501989365e-05, Min w: 0.9587963819503784\n",
      "Iteration 290, Loss: 6.19906495558098e-05, Min w: 0.9618405699729919\n",
      "Iteration 300, Loss: 5.9120797232026234e-05, Min w: 0.9617655277252197\n",
      "Iteration 310, Loss: 6.355457298923284e-05, Min w: 0.9588155150413513\n",
      "Iteration 320, Loss: 6.539728201460093e-05, Min w: 0.9619218707084656\n",
      "Iteration 330, Loss: 6.408670014934614e-05, Min w: 0.9587070345878601\n",
      "Iteration 340, Loss: 7.520622602896765e-05, Min w: 0.9588490128517151\n",
      "Iteration 350, Loss: 9.273596515413374e-05, Min w: 0.9483465552330017\n",
      "Iteration 360, Loss: 9.871619840851054e-05, Min w: 0.9438575506210327\n",
      "Iteration 370, Loss: 6.22938823653385e-05, Min w: 0.963118851184845\n",
      "Iteration 380, Loss: 6.14114323980175e-05, Min w: 0.9620515704154968\n",
      "Iteration 390, Loss: 6.310734897851944e-05, Min w: 0.9609723091125488\n",
      "Iteration 400, Loss: 5.7751974964048713e-05, Min w: 0.9640786647796631\n",
      "Iteration 410, Loss: 6.036241757101379e-05, Min w: 0.9629247188568115\n",
      "Iteration 420, Loss: 6.80933371768333e-05, Min w: 0.9633994102478027\n",
      "Iteration 430, Loss: 5.73951328988187e-05, Min w: 0.9648643136024475\n",
      "Iteration 440, Loss: 5.7728029787540436e-05, Min w: 0.9649440050125122\n",
      "Iteration 450, Loss: 6.824786396464333e-05, Min w: 0.9638791084289551\n",
      "Iteration 460, Loss: 6.27582921879366e-05, Min w: 0.9611403942108154\n",
      "Iteration 470, Loss: 6.076687714084983e-05, Min w: 0.9659814238548279\n",
      "Iteration 480, Loss: 5.896860966458917e-05, Min w: 0.963626503944397\n",
      "Iteration 490, Loss: 5.82945576752536e-05, Min w: 0.9636631608009338\n",
      "Iteration 500, Loss: 5.82390530325938e-05, Min w: 0.9638223648071289\n",
      "Iteration 510, Loss: 6.960200698813424e-05, Min w: 0.9621630907058716\n",
      "Iteration 520, Loss: 8.510540646966547e-05, Min w: 0.9549981355667114\n",
      "Iteration 530, Loss: 6.558648601640016e-05, Min w: 0.9601929783821106\n",
      "Iteration 540, Loss: 5.6148794101318344e-05, Min w: 0.963038980960846\n",
      "Iteration 550, Loss: 5.6455402955180034e-05, Min w: 0.9670374393463135\n",
      "Iteration 560, Loss: 5.3508105338551104e-05, Min w: 0.9671124815940857\n",
      "Iteration 570, Loss: 5.835545380250551e-05, Min w: 0.9636714458465576\n",
      "Iteration 580, Loss: 6.0300131735857576e-05, Min w: 0.9649956822395325\n",
      "Iteration 590, Loss: 5.800720100523904e-05, Min w: 0.9652625918388367\n",
      "Iteration 600, Loss: 6.952935655135661e-05, Min w: 0.9591094255447388\n",
      "Iteration 610, Loss: 6.954360287636518e-05, Min w: 0.9641605615615845\n",
      "Iteration 620, Loss: 5.7201963500119746e-05, Min w: 0.9654658436775208\n",
      "Iteration 630, Loss: 8.394069300265983e-05, Min w: 0.9518033266067505\n",
      "Iteration 640, Loss: 6.56558622722514e-05, Min w: 0.9635080695152283\n",
      "Iteration 650, Loss: 5.667805453413166e-05, Min w: 0.9671717286109924\n",
      "Iteration 660, Loss: 7.282027945620939e-05, Min w: 0.9625231623649597\n",
      "Iteration 670, Loss: 6.404284067684785e-05, Min w: 0.9631578922271729\n",
      "Iteration 680, Loss: 6.28503694315441e-05, Min w: 0.9663727879524231\n",
      "Iteration 690, Loss: 5.2666797273559496e-05, Min w: 0.966502845287323\n",
      "Iteration 700, Loss: 5.6901597417891026e-05, Min w: 0.9656319618225098\n",
      "Iteration 710, Loss: 5.564041202887893e-05, Min w: 0.9676034450531006\n",
      "Iteration 720, Loss: 6.749569001840428e-05, Min w: 0.9616656303405762\n",
      "Iteration 730, Loss: 6.331905751721933e-05, Min w: 0.9601808190345764\n",
      "Iteration 740, Loss: 6.125575600890443e-05, Min w: 0.9646271467208862\n",
      "Iteration 750, Loss: 5.796968616778031e-05, Min w: 0.968064546585083\n",
      "Iteration 760, Loss: 5.834323019371368e-05, Min w: 0.9648677110671997\n",
      "Iteration 770, Loss: 5.963376315776259e-05, Min w: 0.9655436873435974\n",
      "Iteration 780, Loss: 6.104486965341493e-05, Min w: 0.9616553783416748\n",
      "Iteration 790, Loss: 6.699281220789999e-05, Min w: 0.9640573859214783\n",
      "Iteration 800, Loss: 5.4342206567525864e-05, Min w: 0.9671242237091064\n",
      "Iteration 810, Loss: 5.6552220485173166e-05, Min w: 0.969679057598114\n",
      "Iteration 820, Loss: 5.705617513740435e-05, Min w: 0.9644637703895569\n",
      "Iteration 830, Loss: 5.568420237977989e-05, Min w: 0.9662030339241028\n",
      "Iteration 840, Loss: 5.247793160378933e-05, Min w: 0.9681769013404846\n",
      "Iteration 850, Loss: 5.974869054625742e-05, Min w: 0.9661405682563782\n",
      "Iteration 860, Loss: 5.287999374559149e-05, Min w: 0.9648657441139221\n",
      "Iteration 870, Loss: 5.5635198805248365e-05, Min w: 0.9656550884246826\n",
      "Iteration 880, Loss: 6.303482223302126e-05, Min w: 0.9622342586517334\n",
      "Iteration 890, Loss: 5.1097005780320615e-05, Min w: 0.9683928489685059\n",
      "Iteration 900, Loss: 5.096711902297102e-05, Min w: 0.9695287942886353\n",
      "Iteration 910, Loss: 5.432649777503684e-05, Min w: 0.9670735597610474\n",
      "Iteration 920, Loss: 5.11663529323414e-05, Min w: 0.9689913988113403\n",
      "Iteration 930, Loss: 5.870206223335117e-05, Min w: 0.9679325819015503\n",
      "Iteration 940, Loss: 5.491120828082785e-05, Min w: 0.9673474431037903\n",
      "Iteration 950, Loss: 5.588542626355775e-05, Min w: 0.9663115739822388\n",
      "Iteration 960, Loss: 5.212464020587504e-05, Min w: 0.9685204029083252\n",
      "Iteration 970, Loss: 7.340438605751842e-05, Min w: 0.9614401459693909\n",
      "Iteration 980, Loss: 5.625173434964381e-05, Min w: 0.9656400084495544\n",
      "Iteration 990, Loss: 6.191694410517812e-05, Min w: 0.9671971797943115\n",
      "Iteration 1000, Loss: 5.37453597644344e-05, Min w: 0.9687382578849792\n",
      "Iteration 1010, Loss: 6.311020842986181e-05, Min w: 0.9652823209762573\n",
      "Iteration 1020, Loss: 4.891969729214907e-05, Min w: 0.9709480404853821\n",
      "Iteration 1030, Loss: 4.942719533573836e-05, Min w: 0.9688626527786255\n",
      "Iteration 1040, Loss: 6.016240149619989e-05, Min w: 0.9669944047927856\n",
      "Iteration 1050, Loss: 5.01487375004217e-05, Min w: 0.9713114500045776\n",
      "Iteration 1060, Loss: 5.1878279919037595e-05, Min w: 0.9668865203857422\n",
      "Iteration 1070, Loss: 5.007880099583417e-05, Min w: 0.9681780338287354\n",
      "Iteration 1080, Loss: 5.3677074902225286e-05, Min w: 0.9660701155662537\n",
      "Iteration 1090, Loss: 5.5219148634932935e-05, Min w: 0.9622292518615723\n",
      "Iteration 1100, Loss: 5.317022078088485e-05, Min w: 0.9701518416404724\n",
      "Iteration 1110, Loss: 6.032617966411635e-05, Min w: 0.9680930972099304\n",
      "Iteration 1120, Loss: 5.602656165137887e-05, Min w: 0.96908038854599\n",
      "Iteration 1130, Loss: 5.601065277005546e-05, Min w: 0.9687712788581848\n",
      "Iteration 1140, Loss: 5.560482895816676e-05, Min w: 0.9687796831130981\n",
      "Iteration 1150, Loss: 4.689305569627322e-05, Min w: 0.9688714146614075\n",
      "Iteration 1160, Loss: 5.1840041123796254e-05, Min w: 0.9704570174217224\n",
      "Iteration 1170, Loss: 5.217919169808738e-05, Min w: 0.9684435725212097\n",
      "Iteration 1180, Loss: 5.0205977458972484e-05, Min w: 0.9704664945602417\n",
      "Iteration 1190, Loss: 5.586174665950239e-05, Min w: 0.9665881991386414\n",
      "Iteration 1200, Loss: 4.805056596524082e-05, Min w: 0.9714876413345337\n",
      "Iteration 1210, Loss: 5.004342892789282e-05, Min w: 0.9696881771087646\n",
      "Iteration 1220, Loss: 5.7240155001636595e-05, Min w: 0.9695026278495789\n",
      "Iteration 1230, Loss: 5.916641021030955e-05, Min w: 0.9681452512741089\n",
      "Iteration 1240, Loss: 4.974377225153148e-05, Min w: 0.9701154232025146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  58%|█████▊    | 14/24 [22:23<17:27, 104.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.014895085277788704, 'L2_avg': 0.01756555349662738, 'End_point_L1_avg': 0.011561108803731589, 'End_point_L2_avg': 0.011945334476165264}\n",
      "Iteration 0, Loss: 0.00120619498193264, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0009698161156848073, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009281196398660541, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0009700169903226197, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009359903633594513, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0009056367562152445, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007918124902062118, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007171364850364625, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00064985326025635, Min w: 0.0\n",
      "Iteration 90, Loss: 0.000625800050329417, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006111075053922832, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005948219331912696, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005796469049528241, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005648267106153071, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005507309106178582, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005344465607777238, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005229313392192125, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005105289164930582, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0004984289407730103, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0004921053186990321, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0004847751115448773, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0004805114003829658, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0004637280944734812, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004600658139679581, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004534890176728368, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004490165156312287, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00044057914055883884, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00043269232264719903, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00043030333472415805, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00043052382534369826, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004251983773428947, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0004146561841480434, Min w: 0.0\n",
      "Iteration 320, Loss: 0.00041361735202372074, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00041341071482747793, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00040209601866081357, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004176463990006596, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004228333418723196, Min w: 0.0\n",
      "Iteration 370, Loss: 0.00039146936614997685, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0003865181643050164, Min w: 0.0\n",
      "Iteration 390, Loss: 0.00039599291631020606, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0003990968980360776, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004083735984750092, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004035716410726309, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0003998418396804482, Min w: 0.0\n",
      "Iteration 440, Loss: 0.00042873152415268123, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00043630486470647156, Min w: 0.0\n",
      "Iteration 460, Loss: 0.00043592139263637364, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00040980317862704396, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0004048850096296519, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0003783598367590457, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004082082014065236, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00038115415372885764, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00038722780300304294, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0003699880908243358, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0003823519800789654, Min w: 0.0\n",
      "Iteration 550, Loss: 0.00035921187372878194, Min w: 0.0\n",
      "Iteration 560, Loss: 0.000379643082851544, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0003614331944845617, Min w: 0.0\n",
      "Iteration 580, Loss: 0.000346432818332687, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0003609363338910043, Min w: 0.0\n",
      "Iteration 600, Loss: 0.00034533473080955446, Min w: 0.0\n",
      "Iteration 610, Loss: 0.00035202986327931285, Min w: 0.0\n",
      "Iteration 620, Loss: 0.00034242679248563945, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0003450518997851759, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00034292563213966787, Min w: 0.0\n",
      "Iteration 650, Loss: 0.00033542056917212903, Min w: 0.0\n",
      "Iteration 660, Loss: 0.00033183666528202593, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0003357457753736526, Min w: 0.0\n",
      "Iteration 680, Loss: 0.00032900762744247913, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0003265978302806616, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0003388790355529636, Min w: 0.0\n",
      "Iteration 710, Loss: 0.00033441142295487225, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0003324279678054154, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0003335515211801976, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0003362339048180729, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0003435804392211139, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0003408174670767039, Min w: 5.463203086506163e-39\n",
      "Iteration 770, Loss: 0.00033673676080070436, Min w: 1.8011703090757074e-29\n",
      "Iteration 780, Loss: 0.0003435071848798543, Min w: 2.551226634387847e-20\n",
      "Iteration 790, Loss: 0.000352861185092479, Min w: 1.3364001745508336e-12\n",
      "Iteration 800, Loss: 0.00034957416937686503, Min w: 4.030346758554515e-07\n",
      "Iteration 810, Loss: 0.00035171530907973647, Min w: 0.0009278205689042807\n",
      "Iteration 820, Loss: 0.0003542648337315768, Min w: 0.0032812554854899645\n",
      "Iteration 830, Loss: 0.00036024293513037264, Min w: 2.8274565920582972e-05\n",
      "Iteration 840, Loss: 0.00035434323945082724, Min w: 1.277430897062004e-06\n",
      "Iteration 850, Loss: 0.0003492803662084043, Min w: 1.5863035969232442e-06\n",
      "Iteration 860, Loss: 0.0003475811972748488, Min w: 1.8022584526988794e-06\n",
      "Iteration 870, Loss: 0.0003487352223601192, Min w: 2.1078807549201883e-05\n",
      "Iteration 880, Loss: 0.0003495780110824853, Min w: 0.00018142176850233227\n",
      "Iteration 890, Loss: 0.0003525191859807819, Min w: 0.004790133330971003\n",
      "Iteration 900, Loss: 0.0003460338630247861, Min w: 0.019678574055433273\n",
      "Iteration 910, Loss: 0.0003539421013556421, Min w: 0.03077525645494461\n",
      "Iteration 920, Loss: 0.00034837215207517147, Min w: 0.032862693071365356\n",
      "Iteration 930, Loss: 0.0003422066802158952, Min w: 0.026583600789308548\n",
      "Iteration 940, Loss: 0.0003409516648389399, Min w: 0.030389290302991867\n",
      "Iteration 950, Loss: 0.0003403369046282023, Min w: 0.027418062090873718\n",
      "Iteration 960, Loss: 0.00033888136385940015, Min w: 0.03228456526994705\n",
      "Iteration 970, Loss: 0.0003504182386677712, Min w: 0.03528381139039993\n",
      "Iteration 980, Loss: 0.00033913215156644583, Min w: 0.03664909675717354\n",
      "Iteration 990, Loss: 0.000342868355801329, Min w: 0.037893716245889664\n",
      "Iteration 1000, Loss: 0.00033577854628674686, Min w: 0.04309289902448654\n",
      "Iteration 1010, Loss: 0.00033169271773658693, Min w: 0.04513105750083923\n",
      "Iteration 1020, Loss: 0.0003330242761876434, Min w: 0.04644934460520744\n",
      "Iteration 1030, Loss: 0.0003346427110955119, Min w: 0.05598762631416321\n",
      "Iteration 1040, Loss: 0.0003346365410834551, Min w: 0.05862598866224289\n",
      "Iteration 1050, Loss: 0.00032482578535564244, Min w: 0.06953130662441254\n",
      "Iteration 1060, Loss: 0.00032434260356239974, Min w: 0.07216744124889374\n",
      "Iteration 1070, Loss: 0.0003187946858815849, Min w: 0.08051712065935135\n",
      "Iteration 1080, Loss: 0.0003117226588074118, Min w: 0.0931139811873436\n",
      "Iteration 1090, Loss: 0.0003148831019643694, Min w: 0.0973832756280899\n",
      "Iteration 1100, Loss: 0.0003153835714329034, Min w: 0.10284629464149475\n",
      "Iteration 1110, Loss: 0.0003104157221969217, Min w: 0.10618908703327179\n",
      "Iteration 1120, Loss: 0.0003089449892286211, Min w: 0.11242920905351639\n",
      "Iteration 1130, Loss: 0.00033109888317994773, Min w: 0.11920256912708282\n",
      "Iteration 1140, Loss: 0.00030754838371649384, Min w: 0.12394080311059952\n",
      "Iteration 1150, Loss: 0.0003035339468624443, Min w: 0.13930882513523102\n",
      "Iteration 1160, Loss: 0.00029776975861750543, Min w: 0.14658202230930328\n",
      "Iteration 1170, Loss: 0.00028815658879466355, Min w: 0.17318832874298096\n",
      "Iteration 1180, Loss: 0.000291623204248026, Min w: 0.15814828872680664\n",
      "Iteration 1190, Loss: 0.00028675945941358805, Min w: 0.17627327144145966\n",
      "Iteration 1200, Loss: 0.00028955700690858066, Min w: 0.1722969263792038\n",
      "Iteration 1210, Loss: 0.00028924187063239515, Min w: 0.17950646579265594\n",
      "Iteration 1220, Loss: 0.0002896399237215519, Min w: 0.18683405220508575\n",
      "Iteration 1230, Loss: 0.0002914941287599504, Min w: 0.18909864127635956\n",
      "Iteration 1240, Loss: 0.00028255750657990575, Min w: 0.20947924256324768\n",
      "Iteration 0, Loss: 0.00027765746926888824, Min w: 0.20189915597438812\n",
      "Iteration 10, Loss: 0.0002749341947492212, Min w: 0.20913344621658325\n",
      "Iteration 20, Loss: 0.0002721145865507424, Min w: 0.21737949550151825\n",
      "Iteration 30, Loss: 0.0002668591041583568, Min w: 0.22579969465732574\n",
      "Iteration 40, Loss: 0.0002699259202927351, Min w: 0.22635844349861145\n",
      "Iteration 50, Loss: 0.0002701609337236732, Min w: 0.22497513890266418\n",
      "Iteration 60, Loss: 0.00026339603937231004, Min w: 0.2373514622449875\n",
      "Iteration 70, Loss: 0.0002644440974108875, Min w: 0.24898646771907806\n",
      "Iteration 80, Loss: 0.0002701414923649281, Min w: 0.25011324882507324\n",
      "Iteration 90, Loss: 0.0002602090244181454, Min w: 0.24980835616588593\n",
      "Iteration 100, Loss: 0.00025764023303054273, Min w: 0.25619304180145264\n",
      "Iteration 110, Loss: 0.00025094079319387674, Min w: 0.26975011825561523\n",
      "Iteration 120, Loss: 0.0002592201344668865, Min w: 0.2723239064216614\n",
      "Iteration 130, Loss: 0.0002606575144454837, Min w: 0.2744279205799103\n",
      "Iteration 140, Loss: 0.0002538755361456424, Min w: 0.26910707354545593\n",
      "Iteration 150, Loss: 0.0002653727715369314, Min w: 0.27071377635002136\n",
      "Iteration 160, Loss: 0.00024959418806247413, Min w: 0.2833479344844818\n",
      "Iteration 170, Loss: 0.00024279119679704309, Min w: 0.2941391170024872\n",
      "Iteration 180, Loss: 0.00024720848887227476, Min w: 0.28972944617271423\n",
      "Iteration 190, Loss: 0.00024478763225488365, Min w: 0.2962174415588379\n",
      "Iteration 200, Loss: 0.00024829088943079114, Min w: 0.2923455238342285\n",
      "Iteration 210, Loss: 0.00024365521676372737, Min w: 0.30078649520874023\n",
      "Iteration 220, Loss: 0.0002378049975959584, Min w: 0.30242496728897095\n",
      "Iteration 230, Loss: 0.00023608125047758222, Min w: 0.3110146224498749\n",
      "Iteration 240, Loss: 0.00024123665934894234, Min w: 0.3013063669204712\n",
      "Iteration 250, Loss: 0.0002323889930266887, Min w: 0.3152140974998474\n",
      "Iteration 260, Loss: 0.00024136167485266924, Min w: 0.3034624457359314\n",
      "Iteration 270, Loss: 0.00023304873320739716, Min w: 0.3127613067626953\n",
      "Iteration 280, Loss: 0.000227874523261562, Min w: 0.3345987796783447\n",
      "Iteration 290, Loss: 0.0002281981724081561, Min w: 0.3312661945819855\n",
      "Iteration 300, Loss: 0.0002277380262967199, Min w: 0.3309597074985504\n",
      "Iteration 310, Loss: 0.00023126571613829583, Min w: 0.3239077925682068\n",
      "Iteration 320, Loss: 0.00022460681793745607, Min w: 0.3367493152618408\n",
      "Iteration 330, Loss: 0.00022915242880117148, Min w: 0.33746176958084106\n",
      "Iteration 340, Loss: 0.00022088820696808398, Min w: 0.3543683588504791\n",
      "Iteration 350, Loss: 0.00022666298900730908, Min w: 0.35164061188697815\n",
      "Iteration 360, Loss: 0.00021938132704235613, Min w: 0.35919368267059326\n",
      "Iteration 370, Loss: 0.00022278721735347062, Min w: 0.3544451594352722\n",
      "Iteration 380, Loss: 0.0002161322336178273, Min w: 0.36327919363975525\n",
      "Iteration 390, Loss: 0.00021565938368439674, Min w: 0.3594071865081787\n",
      "Iteration 400, Loss: 0.00021722671226598322, Min w: 0.3749772012233734\n",
      "Iteration 410, Loss: 0.00021708729036618024, Min w: 0.3668133318424225\n",
      "Iteration 420, Loss: 0.00021073210518807173, Min w: 0.38402172923088074\n",
      "Iteration 430, Loss: 0.00021082331659272313, Min w: 0.37875357270240784\n",
      "Iteration 440, Loss: 0.00021219422342255712, Min w: 0.3837835192680359\n",
      "Iteration 450, Loss: 0.00021377000666689128, Min w: 0.37926948070526123\n",
      "Iteration 460, Loss: 0.00021068124624434859, Min w: 0.38634544610977173\n",
      "Iteration 470, Loss: 0.0002077118115266785, Min w: 0.3916366696357727\n",
      "Iteration 480, Loss: 0.00020424278045538813, Min w: 0.4002741277217865\n",
      "Iteration 490, Loss: 0.0002050851471722126, Min w: 0.39893049001693726\n",
      "Iteration 500, Loss: 0.00021706077677663416, Min w: 0.3868672847747803\n",
      "Iteration 510, Loss: 0.00020587211474776268, Min w: 0.40870025753974915\n",
      "Iteration 520, Loss: 0.00020768819376826286, Min w: 0.40214475989341736\n",
      "Iteration 530, Loss: 0.00020247316570021212, Min w: 0.4115569293498993\n",
      "Iteration 540, Loss: 0.00019654451170936227, Min w: 0.4209538996219635\n",
      "Iteration 550, Loss: 0.00019818672444671392, Min w: 0.41551151871681213\n",
      "Iteration 560, Loss: 0.00019573108875192702, Min w: 0.42020562291145325\n",
      "Iteration 570, Loss: 0.0001938561035785824, Min w: 0.42895743250846863\n",
      "Iteration 580, Loss: 0.0001911254512378946, Min w: 0.4256189465522766\n",
      "Iteration 590, Loss: 0.00020490233146119863, Min w: 0.4243147671222687\n",
      "Iteration 600, Loss: 0.00019383232574909925, Min w: 0.43177565932273865\n",
      "Iteration 610, Loss: 0.00019127802806906402, Min w: 0.42889276146888733\n",
      "Iteration 620, Loss: 0.0001906261604744941, Min w: 0.4386512041091919\n",
      "Iteration 630, Loss: 0.00018958791042678058, Min w: 0.43612658977508545\n",
      "Iteration 640, Loss: 0.00018959972658194602, Min w: 0.4365198314189911\n",
      "Iteration 650, Loss: 0.0001874728041002527, Min w: 0.4409816265106201\n",
      "Iteration 660, Loss: 0.00020134706574026495, Min w: 0.43920037150382996\n",
      "Iteration 670, Loss: 0.00018693320453166962, Min w: 0.43706798553466797\n",
      "Iteration 680, Loss: 0.00019712203356903046, Min w: 0.4474032521247864\n",
      "Iteration 690, Loss: 0.00018884414748754352, Min w: 0.43959134817123413\n",
      "Iteration 700, Loss: 0.00019142335804644972, Min w: 0.45607808232307434\n",
      "Iteration 710, Loss: 0.00019519348279573023, Min w: 0.44422125816345215\n",
      "Iteration 720, Loss: 0.0001883078512037173, Min w: 0.4533538818359375\n",
      "Iteration 730, Loss: 0.0001807141088647768, Min w: 0.46875718235969543\n",
      "Iteration 740, Loss: 0.00018071630620397627, Min w: 0.46514052152633667\n",
      "Iteration 750, Loss: 0.00018056722183246166, Min w: 0.46285587549209595\n",
      "Iteration 760, Loss: 0.00017704804486129433, Min w: 0.47288429737091064\n",
      "Iteration 770, Loss: 0.0001802956685423851, Min w: 0.47229039669036865\n",
      "Iteration 780, Loss: 0.00017974157526623458, Min w: 0.4639204740524292\n",
      "Iteration 790, Loss: 0.0001797369768610224, Min w: 0.47532933950424194\n",
      "Iteration 800, Loss: 0.00018251346773467958, Min w: 0.4799279272556305\n",
      "Iteration 810, Loss: 0.0001746404595905915, Min w: 0.4880225658416748\n",
      "Iteration 820, Loss: 0.0001766584609868005, Min w: 0.48304781317710876\n",
      "Iteration 830, Loss: 0.00017230535740964115, Min w: 0.4835028648376465\n",
      "Iteration 840, Loss: 0.0001703296002233401, Min w: 0.4971073567867279\n",
      "Iteration 850, Loss: 0.0001736883568810299, Min w: 0.48882848024368286\n",
      "Iteration 860, Loss: 0.00017022571410052478, Min w: 0.4913053512573242\n",
      "Iteration 870, Loss: 0.00016701185086276382, Min w: 0.49740731716156006\n",
      "Iteration 880, Loss: 0.00016741578292567283, Min w: 0.49797746539115906\n",
      "Iteration 890, Loss: 0.00016791561210993677, Min w: 0.5043318271636963\n",
      "Iteration 900, Loss: 0.00018145237118005753, Min w: 0.48311224579811096\n",
      "Iteration 910, Loss: 0.00018074743275064975, Min w: 0.5006911158561707\n",
      "Iteration 920, Loss: 0.0001703344314591959, Min w: 0.5020360350608826\n",
      "Iteration 930, Loss: 0.0001718933053780347, Min w: 0.5026705265045166\n",
      "Iteration 940, Loss: 0.000172501037013717, Min w: 0.506960928440094\n",
      "Iteration 950, Loss: 0.00016889747348614037, Min w: 0.5050901770591736\n",
      "Iteration 960, Loss: 0.00016878337191883475, Min w: 0.5078189969062805\n",
      "Iteration 970, Loss: 0.00017604418098926544, Min w: 0.5086756348609924\n",
      "Iteration 980, Loss: 0.00016571719606872648, Min w: 0.5141371488571167\n",
      "Iteration 990, Loss: 0.0001624398719286546, Min w: 0.5103005170822144\n",
      "Iteration 1000, Loss: 0.00017643190221861005, Min w: 0.5231977105140686\n",
      "Iteration 1010, Loss: 0.00015739037189632654, Min w: 0.5347322225570679\n",
      "Iteration 1020, Loss: 0.0001577445218572393, Min w: 0.5308861136436462\n",
      "Iteration 1030, Loss: 0.0001614934008102864, Min w: 0.5407301187515259\n",
      "Iteration 1040, Loss: 0.0001578579394845292, Min w: 0.5311999320983887\n",
      "Iteration 1050, Loss: 0.00015597895253449678, Min w: 0.5405713319778442\n",
      "Iteration 1060, Loss: 0.00015961940516717732, Min w: 0.5271554589271545\n",
      "Iteration 1070, Loss: 0.00015070510562509298, Min w: 0.5586116909980774\n",
      "Iteration 1080, Loss: 0.00016040989430621266, Min w: 0.5369685888290405\n",
      "Iteration 1090, Loss: 0.00015994695422705263, Min w: 0.544693112373352\n",
      "Iteration 1100, Loss: 0.00015409513434860855, Min w: 0.5508148670196533\n",
      "Iteration 1110, Loss: 0.00015632068971171975, Min w: 0.5416666865348816\n",
      "Iteration 1120, Loss: 0.00015358086966443807, Min w: 0.5548548102378845\n",
      "Iteration 1130, Loss: 0.00015159574104472995, Min w: 0.5585696697235107\n",
      "Iteration 1140, Loss: 0.0001512660237494856, Min w: 0.5545920133590698\n",
      "Iteration 1150, Loss: 0.00015330837049987167, Min w: 0.5678329467773438\n",
      "Iteration 1160, Loss: 0.0001565278071211651, Min w: 0.5560399293899536\n",
      "Iteration 1170, Loss: 0.0001467900292482227, Min w: 0.5670483112335205\n",
      "Iteration 1180, Loss: 0.00014669759548269212, Min w: 0.5582572221755981\n",
      "Iteration 1190, Loss: 0.00014552584616467357, Min w: 0.5677127838134766\n",
      "Iteration 1200, Loss: 0.00014779904449824244, Min w: 0.5719282031059265\n",
      "Iteration 1210, Loss: 0.00014697745791636407, Min w: 0.5649511218070984\n",
      "Iteration 1220, Loss: 0.0001565839338582009, Min w: 0.564619243144989\n",
      "Iteration 1230, Loss: 0.00014181036385707557, Min w: 0.5819857120513916\n",
      "Iteration 1240, Loss: 0.00014693589764647186, Min w: 0.5753114819526672\n",
      "Iteration 0, Loss: 0.00014479925448540598, Min w: 0.5716598629951477\n",
      "Iteration 10, Loss: 0.00014336862659547478, Min w: 0.5834247469902039\n",
      "Iteration 20, Loss: 0.0001454135199310258, Min w: 0.5874664783477783\n",
      "Iteration 30, Loss: 0.00013708544429391623, Min w: 0.5957816243171692\n",
      "Iteration 40, Loss: 0.0001420222979504615, Min w: 0.5862277150154114\n",
      "Iteration 50, Loss: 0.00014326610835269094, Min w: 0.5828869938850403\n",
      "Iteration 60, Loss: 0.00014296294830273837, Min w: 0.5935149192810059\n",
      "Iteration 70, Loss: 0.0001404549111612141, Min w: 0.5895863175392151\n",
      "Iteration 80, Loss: 0.00013507950643543154, Min w: 0.6044048070907593\n",
      "Iteration 90, Loss: 0.0001354340638499707, Min w: 0.6059763431549072\n",
      "Iteration 100, Loss: 0.00013442545605357736, Min w: 0.6105248928070068\n",
      "Iteration 110, Loss: 0.00013850345567334443, Min w: 0.605729341506958\n",
      "Iteration 120, Loss: 0.0001459625200368464, Min w: 0.6009505391120911\n",
      "Iteration 130, Loss: 0.00013860271428711712, Min w: 0.6097717881202698\n",
      "Iteration 140, Loss: 0.0001316703564953059, Min w: 0.6195130348205566\n",
      "Iteration 150, Loss: 0.0001371261168969795, Min w: 0.6044490933418274\n",
      "Iteration 160, Loss: 0.00012829953629989177, Min w: 0.6251824498176575\n",
      "Iteration 170, Loss: 0.0001352975086774677, Min w: 0.6166238188743591\n",
      "Iteration 180, Loss: 0.0001353145926259458, Min w: 0.6161121129989624\n",
      "Iteration 190, Loss: 0.0001306849007960409, Min w: 0.6256470084190369\n",
      "Iteration 200, Loss: 0.00014353287406265736, Min w: 0.6155315637588501\n",
      "Iteration 210, Loss: 0.0001335826382273808, Min w: 0.6191461086273193\n",
      "Iteration 220, Loss: 0.00012699670332949609, Min w: 0.6361516714096069\n",
      "Iteration 230, Loss: 0.0001298559654969722, Min w: 0.6314572095870972\n",
      "Iteration 240, Loss: 0.0001254034141311422, Min w: 0.6344389319419861\n",
      "Iteration 250, Loss: 0.0001275255053769797, Min w: 0.637503445148468\n",
      "Iteration 260, Loss: 0.0001300135481869802, Min w: 0.6373317837715149\n",
      "Iteration 270, Loss: 0.00012705125845968723, Min w: 0.6358243227005005\n",
      "Iteration 280, Loss: 0.00012666379916481674, Min w: 0.651865541934967\n",
      "Iteration 290, Loss: 0.0001238956319866702, Min w: 0.6412006616592407\n",
      "Iteration 300, Loss: 0.00013059296179562807, Min w: 0.6432929039001465\n",
      "Iteration 310, Loss: 0.00012493846588768065, Min w: 0.6430485248565674\n",
      "Iteration 320, Loss: 0.000121549419418443, Min w: 0.6518403887748718\n",
      "Iteration 330, Loss: 0.00012583690113388002, Min w: 0.6590027213096619\n",
      "Iteration 340, Loss: 0.0001256010145880282, Min w: 0.6473639607429504\n",
      "Iteration 350, Loss: 0.00013250464689917862, Min w: 0.6503234505653381\n",
      "Iteration 360, Loss: 0.00011927283776458353, Min w: 0.6591382026672363\n",
      "Iteration 370, Loss: 0.00012373895151540637, Min w: 0.6586993336677551\n",
      "Iteration 380, Loss: 0.00012133784912293777, Min w: 0.6612370610237122\n",
      "Iteration 390, Loss: 0.00011555361561477184, Min w: 0.6707308888435364\n",
      "Iteration 400, Loss: 0.00012737861834466457, Min w: 0.6520516872406006\n",
      "Iteration 410, Loss: 0.00011796037142630666, Min w: 0.6636242270469666\n",
      "Iteration 420, Loss: 0.00011767828254960477, Min w: 0.6720044016838074\n",
      "Iteration 430, Loss: 0.00011863561667269096, Min w: 0.6675793528556824\n",
      "Iteration 440, Loss: 0.00011747366806957871, Min w: 0.6657329797744751\n",
      "Iteration 450, Loss: 0.0001141207612818107, Min w: 0.679642915725708\n",
      "Iteration 460, Loss: 0.00011576107499422505, Min w: 0.675897479057312\n",
      "Iteration 470, Loss: 0.00011521064880071208, Min w: 0.6788724660873413\n",
      "Iteration 480, Loss: 0.00011997400724794716, Min w: 0.6746247410774231\n",
      "Iteration 490, Loss: 0.00012712503666989505, Min w: 0.6691421866416931\n",
      "Iteration 500, Loss: 0.00011273357085883617, Min w: 0.6820306777954102\n",
      "Iteration 510, Loss: 0.00011302337952656671, Min w: 0.6807863116264343\n",
      "Iteration 520, Loss: 0.00011431265011196956, Min w: 0.6801607608795166\n",
      "Iteration 530, Loss: 0.00011460991663625464, Min w: 0.6874632239341736\n",
      "Iteration 540, Loss: 0.00013039211626164615, Min w: 0.6812841892242432\n",
      "Iteration 550, Loss: 0.0001090192818082869, Min w: 0.6911870241165161\n",
      "Iteration 560, Loss: 0.00011074372741859406, Min w: 0.6937428712844849\n",
      "Iteration 570, Loss: 0.00011122172873001546, Min w: 0.6907185912132263\n",
      "Iteration 580, Loss: 0.0001151246833615005, Min w: 0.690049409866333\n",
      "Iteration 590, Loss: 0.0001131105309468694, Min w: 0.6919676065444946\n",
      "Iteration 600, Loss: 0.00010698792902985588, Min w: 0.7052515149116516\n",
      "Iteration 610, Loss: 0.0001118408763431944, Min w: 0.6991528868675232\n",
      "Iteration 620, Loss: 0.0001092173479264602, Min w: 0.7028573155403137\n",
      "Iteration 630, Loss: 0.00010652895434759557, Min w: 0.7052294015884399\n",
      "Iteration 640, Loss: 0.00011405345139792189, Min w: 0.698056697845459\n",
      "Iteration 650, Loss: 0.00010551267041591927, Min w: 0.7078949213027954\n",
      "Iteration 660, Loss: 0.00010833112901309505, Min w: 0.7072446942329407\n",
      "Iteration 670, Loss: 0.00010778398427646607, Min w: 0.7201283574104309\n",
      "Iteration 680, Loss: 0.00011811064905487001, Min w: 0.7058605551719666\n",
      "Iteration 690, Loss: 0.00010515707253944129, Min w: 0.7141724824905396\n",
      "Iteration 700, Loss: 0.00010234446381218731, Min w: 0.7078847289085388\n",
      "Iteration 710, Loss: 0.0001196910161525011, Min w: 0.7067804932594299\n",
      "Iteration 720, Loss: 0.00010284801828674972, Min w: 0.7203510403633118\n",
      "Iteration 730, Loss: 0.00010446128726471215, Min w: 0.7173650860786438\n",
      "Iteration 740, Loss: 0.00010795325943036005, Min w: 0.7156729698181152\n",
      "Iteration 750, Loss: 0.00010206283332081512, Min w: 0.7224276661872864\n",
      "Iteration 760, Loss: 0.00010565274715190753, Min w: 0.721391499042511\n",
      "Iteration 770, Loss: 9.940333984559402e-05, Min w: 0.7251930236816406\n",
      "Iteration 780, Loss: 0.00010044682130683213, Min w: 0.7279714941978455\n",
      "Iteration 790, Loss: 0.00010204038699157536, Min w: 0.7255029678344727\n",
      "Iteration 800, Loss: 0.00010847187513718382, Min w: 0.7252102494239807\n",
      "Iteration 810, Loss: 9.992676496040076e-05, Min w: 0.7282297015190125\n",
      "Iteration 820, Loss: 0.00010448394459672272, Min w: 0.7261980772018433\n",
      "Iteration 830, Loss: 0.00010298803681507707, Min w: 0.7315359115600586\n",
      "Iteration 840, Loss: 0.0001069901481969282, Min w: 0.7310406565666199\n",
      "Iteration 850, Loss: 0.00010365901835029945, Min w: 0.7321235537528992\n",
      "Iteration 860, Loss: 9.654294262873009e-05, Min w: 0.7383562922477722\n",
      "Iteration 870, Loss: 9.673112072050571e-05, Min w: 0.7415861487388611\n",
      "Iteration 880, Loss: 9.640575444791466e-05, Min w: 0.7412052750587463\n",
      "Iteration 890, Loss: 9.768555901246145e-05, Min w: 0.7437890768051147\n",
      "Iteration 900, Loss: 9.497329301666468e-05, Min w: 0.7433106899261475\n",
      "Iteration 910, Loss: 9.560937905916944e-05, Min w: 0.7392962574958801\n",
      "Iteration 920, Loss: 9.631809371057898e-05, Min w: 0.7433252334594727\n",
      "Iteration 930, Loss: 9.354633220937103e-05, Min w: 0.74875807762146\n",
      "Iteration 940, Loss: 9.364739526063204e-05, Min w: 0.7484883069992065\n",
      "Iteration 950, Loss: 9.53162889345549e-05, Min w: 0.7461222410202026\n",
      "Iteration 960, Loss: 0.00010214263602392748, Min w: 0.7499539852142334\n",
      "Iteration 970, Loss: 9.229288843926042e-05, Min w: 0.75152987241745\n",
      "Iteration 980, Loss: 9.139521716861054e-05, Min w: 0.752432644367218\n",
      "Iteration 990, Loss: 8.868818258633837e-05, Min w: 0.7636751532554626\n",
      "Iteration 1000, Loss: 9.077915456146002e-05, Min w: 0.7552242875099182\n",
      "Iteration 1010, Loss: 9.958253212971613e-05, Min w: 0.747874915599823\n",
      "Iteration 1020, Loss: 9.854629024630412e-05, Min w: 0.7562174797058105\n",
      "Iteration 1030, Loss: 0.00010620487591950223, Min w: 0.7527862787246704\n",
      "Iteration 1040, Loss: 9.362649143440649e-05, Min w: 0.7562353610992432\n",
      "Iteration 1050, Loss: 9.764354763319716e-05, Min w: 0.7618594765663147\n",
      "Iteration 1060, Loss: 8.969835471361876e-05, Min w: 0.7636495232582092\n",
      "Iteration 1070, Loss: 9.615478484192863e-05, Min w: 0.7619757652282715\n",
      "Iteration 1080, Loss: 9.493462857790291e-05, Min w: 0.7597246766090393\n",
      "Iteration 1090, Loss: 9.10819653654471e-05, Min w: 0.7685015797615051\n",
      "Iteration 1100, Loss: 8.750760753173381e-05, Min w: 0.7645763754844666\n",
      "Iteration 1110, Loss: 8.658909791847691e-05, Min w: 0.7712547779083252\n",
      "Iteration 1120, Loss: 8.46221373649314e-05, Min w: 0.775886058807373\n",
      "Iteration 1130, Loss: 9.326138388132676e-05, Min w: 0.7666521072387695\n",
      "Iteration 1140, Loss: 0.00010132426541531458, Min w: 0.763003945350647\n",
      "Iteration 1150, Loss: 9.56466028583236e-05, Min w: 0.7687965631484985\n",
      "Iteration 1160, Loss: 8.588608761783689e-05, Min w: 0.7798330783843994\n",
      "Iteration 1170, Loss: 8.390293805859983e-05, Min w: 0.7782405018806458\n",
      "Iteration 1180, Loss: 8.670743409311399e-05, Min w: 0.7713639140129089\n",
      "Iteration 1190, Loss: 9.073289402294904e-05, Min w: 0.771635115146637\n",
      "Iteration 1200, Loss: 8.268449892057106e-05, Min w: 0.783707857131958\n",
      "Iteration 1210, Loss: 8.430235175183043e-05, Min w: 0.7780851721763611\n",
      "Iteration 1220, Loss: 8.46513721626252e-05, Min w: 0.7820627689361572\n",
      "Iteration 1230, Loss: 9.555033466313034e-05, Min w: 0.7772302627563477\n",
      "Iteration 1240, Loss: 8.95750054041855e-05, Min w: 0.7865103483200073\n",
      "Iteration 0, Loss: 8.046982111409307e-05, Min w: 0.7882451415061951\n",
      "Iteration 10, Loss: 8.10428464319557e-05, Min w: 0.7910709977149963\n",
      "Iteration 20, Loss: 8.564336894778535e-05, Min w: 0.7844778895378113\n",
      "Iteration 30, Loss: 7.76477754698135e-05, Min w: 0.7951447367668152\n",
      "Iteration 40, Loss: 7.82242786954157e-05, Min w: 0.7927359938621521\n",
      "Iteration 50, Loss: 8.071902993833646e-05, Min w: 0.7918029427528381\n",
      "Iteration 60, Loss: 7.847633969504386e-05, Min w: 0.7958091497421265\n",
      "Iteration 70, Loss: 7.760486187180504e-05, Min w: 0.7926205396652222\n",
      "Iteration 80, Loss: 7.672166248084977e-05, Min w: 0.7973536849021912\n",
      "Iteration 90, Loss: 7.516768528148532e-05, Min w: 0.803963303565979\n",
      "Iteration 100, Loss: 7.6519965659827e-05, Min w: 0.7970637679100037\n",
      "Iteration 110, Loss: 7.499106868635863e-05, Min w: 0.8050640821456909\n",
      "Iteration 120, Loss: 7.729205390205607e-05, Min w: 0.7958396673202515\n",
      "Iteration 130, Loss: 7.482385262846947e-05, Min w: 0.8006322383880615\n",
      "Iteration 140, Loss: 7.62264899094589e-05, Min w: 0.8022862672805786\n",
      "Iteration 150, Loss: 8.499493560520932e-05, Min w: 0.7952613234519958\n",
      "Iteration 160, Loss: 7.786984497215599e-05, Min w: 0.8042383790016174\n",
      "Iteration 170, Loss: 7.70240294514224e-05, Min w: 0.8038410544395447\n",
      "Iteration 180, Loss: 8.905972208594903e-05, Min w: 0.793570339679718\n",
      "Iteration 190, Loss: 7.45813304092735e-05, Min w: 0.8128608465194702\n",
      "Iteration 200, Loss: 7.484827074222267e-05, Min w: 0.8113946318626404\n",
      "Iteration 210, Loss: 7.880224438849837e-05, Min w: 0.806325376033783\n",
      "Iteration 220, Loss: 7.475094753317535e-05, Min w: 0.8092026114463806\n",
      "Iteration 230, Loss: 7.22884651622735e-05, Min w: 0.812587559223175\n",
      "Iteration 240, Loss: 7.188499148469418e-05, Min w: 0.8140779733657837\n",
      "Iteration 250, Loss: 7.16062422725372e-05, Min w: 0.8189349174499512\n",
      "Iteration 260, Loss: 7.10155873093754e-05, Min w: 0.8155915141105652\n",
      "Iteration 270, Loss: 7.097389607224613e-05, Min w: 0.815350353717804\n",
      "Iteration 280, Loss: 7.072203879943117e-05, Min w: 0.816379725933075\n",
      "Iteration 290, Loss: 7.518483471358195e-05, Min w: 0.8190776109695435\n",
      "Iteration 300, Loss: 7.406137592624873e-05, Min w: 0.8211549520492554\n",
      "Iteration 310, Loss: 7.375951099675149e-05, Min w: 0.8192294836044312\n",
      "Iteration 320, Loss: 7.027864921838045e-05, Min w: 0.8231085538864136\n",
      "Iteration 330, Loss: 6.95482813171111e-05, Min w: 0.8219251036643982\n",
      "Iteration 340, Loss: 6.997066520852968e-05, Min w: 0.8270048499107361\n",
      "Iteration 350, Loss: 6.986032531131059e-05, Min w: 0.8221457600593567\n",
      "Iteration 360, Loss: 9.433613013243303e-05, Min w: 0.8047980666160583\n",
      "Iteration 370, Loss: 7.1100534114521e-05, Min w: 0.825129508972168\n",
      "Iteration 380, Loss: 6.758517702110112e-05, Min w: 0.8284283876419067\n",
      "Iteration 390, Loss: 6.595077138626948e-05, Min w: 0.8300268650054932\n",
      "Iteration 400, Loss: 6.639366620220244e-05, Min w: 0.8365788459777832\n",
      "Iteration 410, Loss: 6.812917126808316e-05, Min w: 0.8313541412353516\n",
      "Iteration 420, Loss: 6.503163604065776e-05, Min w: 0.832703709602356\n",
      "Iteration 430, Loss: 6.476278940681368e-05, Min w: 0.834014892578125\n",
      "Iteration 440, Loss: 6.644595850957558e-05, Min w: 0.8320801854133606\n",
      "Iteration 450, Loss: 6.84001061017625e-05, Min w: 0.8381445407867432\n",
      "Iteration 460, Loss: 6.580062472494319e-05, Min w: 0.833810031414032\n",
      "Iteration 470, Loss: 6.557361484738067e-05, Min w: 0.8426120281219482\n",
      "Iteration 480, Loss: 6.694725743727759e-05, Min w: 0.8402178287506104\n",
      "Iteration 490, Loss: 7.138888031477109e-05, Min w: 0.8346612453460693\n",
      "Iteration 500, Loss: 7.33173728804104e-05, Min w: 0.8322246074676514\n",
      "Iteration 510, Loss: 6.645216490142047e-05, Min w: 0.8393430709838867\n",
      "Iteration 520, Loss: 8.258422894869e-05, Min w: 0.8306130766868591\n",
      "Iteration 530, Loss: 6.289150769589469e-05, Min w: 0.8437511920928955\n",
      "Iteration 540, Loss: 6.928512448212132e-05, Min w: 0.841129720211029\n",
      "Iteration 550, Loss: 6.461896555265412e-05, Min w: 0.8459514379501343\n",
      "Iteration 560, Loss: 5.901108306716196e-05, Min w: 0.853065550327301\n",
      "Iteration 570, Loss: 6.306060095084831e-05, Min w: 0.8428436517715454\n",
      "Iteration 580, Loss: 6.105354259489104e-05, Min w: 0.8479977250099182\n",
      "Iteration 590, Loss: 6.197894981596619e-05, Min w: 0.852355420589447\n",
      "Iteration 600, Loss: 6.0848426073789597e-05, Min w: 0.8468654155731201\n",
      "Iteration 610, Loss: 6.54139366815798e-05, Min w: 0.847565233707428\n",
      "Iteration 620, Loss: 5.8424280723556876e-05, Min w: 0.8570336103439331\n",
      "Iteration 630, Loss: 6.21705548837781e-05, Min w: 0.8547940254211426\n",
      "Iteration 640, Loss: 6.692613533232361e-05, Min w: 0.8502576351165771\n",
      "Iteration 650, Loss: 6.215186294866726e-05, Min w: 0.8558153510093689\n",
      "Iteration 660, Loss: 6.020085493219085e-05, Min w: 0.8538262248039246\n",
      "Iteration 670, Loss: 5.745932867284864e-05, Min w: 0.8615877628326416\n",
      "Iteration 680, Loss: 5.9526624681893736e-05, Min w: 0.8576046228408813\n",
      "Iteration 690, Loss: 5.8889367210213095e-05, Min w: 0.8574840426445007\n",
      "Iteration 700, Loss: 5.919611066929065e-05, Min w: 0.8564543724060059\n",
      "Iteration 710, Loss: 6.0514423239510506e-05, Min w: 0.8591485619544983\n",
      "Iteration 720, Loss: 6.414203380700201e-05, Min w: 0.8579340577125549\n",
      "Iteration 730, Loss: 5.75153753743507e-05, Min w: 0.8631187081336975\n",
      "Iteration 740, Loss: 5.590611181105487e-05, Min w: 0.8620702624320984\n",
      "Iteration 750, Loss: 5.608588980976492e-05, Min w: 0.8651917576789856\n",
      "Iteration 760, Loss: 5.6610024330439046e-05, Min w: 0.8643043041229248\n",
      "Iteration 770, Loss: 5.602177043328993e-05, Min w: 0.864594042301178\n",
      "Iteration 780, Loss: 5.513189535122365e-05, Min w: 0.8666191101074219\n",
      "Iteration 790, Loss: 5.371433508116752e-05, Min w: 0.8710846304893494\n",
      "Iteration 800, Loss: 5.630749728879891e-05, Min w: 0.8688192963600159\n",
      "Iteration 810, Loss: 5.762906221207231e-05, Min w: 0.8691551089286804\n",
      "Iteration 820, Loss: 7.028430263744667e-05, Min w: 0.8563820719718933\n",
      "Iteration 830, Loss: 6.115033465903252e-05, Min w: 0.8647089004516602\n",
      "Iteration 840, Loss: 5.2698760555358604e-05, Min w: 0.8712787628173828\n",
      "Iteration 850, Loss: 5.4841064411448315e-05, Min w: 0.8744744658470154\n",
      "Iteration 860, Loss: 5.1881332183256745e-05, Min w: 0.8743711113929749\n",
      "Iteration 870, Loss: 5.16475920449011e-05, Min w: 0.8769183158874512\n",
      "Iteration 880, Loss: 6.483684410341084e-05, Min w: 0.8669244647026062\n",
      "Iteration 890, Loss: 5.917574526392855e-05, Min w: 0.8653561472892761\n",
      "Iteration 900, Loss: 5.4898355301702395e-05, Min w: 0.8767279386520386\n",
      "Iteration 910, Loss: 5.9050646086689085e-05, Min w: 0.869674801826477\n",
      "Iteration 920, Loss: 5.265362051432021e-05, Min w: 0.8790027499198914\n",
      "Iteration 930, Loss: 5.0862112402683124e-05, Min w: 0.8781386017799377\n",
      "Iteration 940, Loss: 5.186404086998664e-05, Min w: 0.880572497844696\n",
      "Iteration 950, Loss: 5.558580596698448e-05, Min w: 0.875295877456665\n",
      "Iteration 960, Loss: 5.120491186971776e-05, Min w: 0.8811016082763672\n",
      "Iteration 970, Loss: 5.047789454692975e-05, Min w: 0.8789864182472229\n",
      "Iteration 980, Loss: 5.444250564323738e-05, Min w: 0.8794627785682678\n",
      "Iteration 990, Loss: 5.307322498993017e-05, Min w: 0.8822445273399353\n",
      "Iteration 1000, Loss: 4.9734499043552205e-05, Min w: 0.8860565423965454\n",
      "Iteration 1010, Loss: 4.7559744416503236e-05, Min w: 0.8886942267417908\n",
      "Iteration 1020, Loss: 4.977052958565764e-05, Min w: 0.8857017159461975\n",
      "Iteration 1030, Loss: 4.9714835768099874e-05, Min w: 0.886525571346283\n",
      "Iteration 1040, Loss: 5.189015428186394e-05, Min w: 0.8865194320678711\n",
      "Iteration 1050, Loss: 4.925549364998005e-05, Min w: 0.8885892629623413\n",
      "Iteration 1060, Loss: 5.28778437001165e-05, Min w: 0.8835553526878357\n",
      "Iteration 1070, Loss: 4.8618258006172255e-05, Min w: 0.8879066705703735\n",
      "Iteration 1080, Loss: 4.845461808145046e-05, Min w: 0.888837993144989\n",
      "Iteration 1090, Loss: 5.2755724027520046e-05, Min w: 0.8876794576644897\n",
      "Iteration 1100, Loss: 4.606657239492051e-05, Min w: 0.893363356590271\n",
      "Iteration 1110, Loss: 4.679046105593443e-05, Min w: 0.8919802308082581\n",
      "Iteration 1120, Loss: 4.885619637207128e-05, Min w: 0.8914353251457214\n",
      "Iteration 1130, Loss: 5.1777005865005776e-05, Min w: 0.8898965120315552\n",
      "Iteration 1140, Loss: 4.74204498459585e-05, Min w: 0.8930501341819763\n",
      "Iteration 1150, Loss: 4.748021819978021e-05, Min w: 0.893468976020813\n",
      "Iteration 1160, Loss: 4.6790879423497245e-05, Min w: 0.8949141502380371\n",
      "Iteration 1170, Loss: 4.657918179873377e-05, Min w: 0.9000914692878723\n",
      "Iteration 1180, Loss: 4.3994990846840665e-05, Min w: 0.9013041257858276\n",
      "Iteration 1190, Loss: 4.4621065171668306e-05, Min w: 0.9001445770263672\n",
      "Iteration 1200, Loss: 4.446799721335992e-05, Min w: 0.9011335968971252\n",
      "Iteration 1210, Loss: 4.68532343802508e-05, Min w: 0.8986035585403442\n",
      "Iteration 1220, Loss: 4.97317778354045e-05, Min w: 0.8972864151000977\n",
      "Iteration 1230, Loss: 4.504461321630515e-05, Min w: 0.9005803465843201\n",
      "Iteration 1240, Loss: 4.6215904148994014e-05, Min w: 0.9034680724143982\n",
      "Iteration 0, Loss: 4.333829929237254e-05, Min w: 0.9024583101272583\n",
      "Iteration 10, Loss: 4.533270839601755e-05, Min w: 0.8974541425704956\n",
      "Iteration 20, Loss: 4.7110570449149236e-05, Min w: 0.8974526524543762\n",
      "Iteration 30, Loss: 4.9219903303310275e-05, Min w: 0.8991252779960632\n",
      "Iteration 40, Loss: 4.5659140596399084e-05, Min w: 0.899186909198761\n",
      "Iteration 50, Loss: 4.689852721639909e-05, Min w: 0.9043307900428772\n",
      "Iteration 60, Loss: 4.4011150748701766e-05, Min w: 0.9022870063781738\n",
      "Iteration 70, Loss: 4.656446253648028e-05, Min w: 0.9042568802833557\n",
      "Iteration 80, Loss: 4.418464959599078e-05, Min w: 0.9064144492149353\n",
      "Iteration 90, Loss: 4.450477354112081e-05, Min w: 0.9012123942375183\n",
      "Iteration 100, Loss: 4.312299279263243e-05, Min w: 0.9035689234733582\n",
      "Iteration 110, Loss: 4.677582182921469e-05, Min w: 0.9012461304664612\n",
      "Iteration 120, Loss: 5.463394700200297e-05, Min w: 0.8790684938430786\n",
      "Iteration 130, Loss: 4.1481693187961355e-05, Min w: 0.9070877432823181\n",
      "Iteration 140, Loss: 4.3195526814088225e-05, Min w: 0.9065566062927246\n",
      "Iteration 150, Loss: 5.0402679335093126e-05, Min w: 0.8892242312431335\n",
      "Iteration 160, Loss: 4.729243300971575e-05, Min w: 0.9019486308097839\n",
      "Iteration 170, Loss: 4.8299367335857823e-05, Min w: 0.896253764629364\n",
      "Iteration 180, Loss: 4.601969340001233e-05, Min w: 0.9037588834762573\n",
      "Iteration 190, Loss: 4.0674334741197526e-05, Min w: 0.9125731587409973\n",
      "Iteration 200, Loss: 4.036928294226527e-05, Min w: 0.9120907783508301\n",
      "Iteration 210, Loss: 3.973137791035697e-05, Min w: 0.9120813608169556\n",
      "Iteration 220, Loss: 4.164963684161194e-05, Min w: 0.9135019779205322\n",
      "Iteration 230, Loss: 4.845084549742751e-05, Min w: 0.8940476775169373\n",
      "Iteration 240, Loss: 4.4074971810914576e-05, Min w: 0.9079322218894958\n",
      "Iteration 250, Loss: 4.07479346904438e-05, Min w: 0.9145157933235168\n",
      "Iteration 260, Loss: 3.8785674405517057e-05, Min w: 0.915580153465271\n",
      "Iteration 270, Loss: 4.339507722761482e-05, Min w: 0.9088487029075623\n",
      "Iteration 280, Loss: 4.472948421607725e-05, Min w: 0.9058423042297363\n",
      "Iteration 290, Loss: 4.536900814855471e-05, Min w: 0.9032570123672485\n",
      "Iteration 300, Loss: 5.234428681433201e-05, Min w: 0.8789122104644775\n",
      "Iteration 310, Loss: 3.747533628484234e-05, Min w: 0.9180356860160828\n",
      "Iteration 320, Loss: 4.2926068999804556e-05, Min w: 0.9108666777610779\n",
      "Iteration 330, Loss: 4.104293111595325e-05, Min w: 0.9147866368293762\n",
      "Iteration 340, Loss: 4.483578959479928e-05, Min w: 0.9034123420715332\n",
      "Iteration 350, Loss: 4.88583609694615e-05, Min w: 0.8881402611732483\n",
      "Iteration 360, Loss: 4.28029743488878e-05, Min w: 0.9057205319404602\n",
      "Iteration 370, Loss: 4.0224836993729696e-05, Min w: 0.9159534573554993\n",
      "Iteration 380, Loss: 3.812842260231264e-05, Min w: 0.920360267162323\n",
      "Iteration 390, Loss: 3.782805288210511e-05, Min w: 0.9205175638198853\n",
      "Iteration 400, Loss: 3.6085606552660465e-05, Min w: 0.9246116280555725\n",
      "Iteration 410, Loss: 3.6457386158872396e-05, Min w: 0.9229551553726196\n",
      "Iteration 420, Loss: 3.792460120166652e-05, Min w: 0.9223010540008545\n",
      "Iteration 430, Loss: 3.724820271600038e-05, Min w: 0.9233563542366028\n",
      "Iteration 440, Loss: 3.689485674840398e-05, Min w: 0.922244668006897\n",
      "Iteration 450, Loss: 3.634303720900789e-05, Min w: 0.9234147667884827\n",
      "Iteration 460, Loss: 3.7098438042448834e-05, Min w: 0.9235010743141174\n",
      "Iteration 470, Loss: 3.7211993912933394e-05, Min w: 0.9214177131652832\n",
      "Iteration 480, Loss: 3.819412813754752e-05, Min w: 0.9206670522689819\n",
      "Iteration 490, Loss: 3.927823490812443e-05, Min w: 0.9144817590713501\n",
      "Iteration 500, Loss: 3.6629309761337936e-05, Min w: 0.9247955679893494\n",
      "Iteration 510, Loss: 3.5716853744816035e-05, Min w: 0.9267356991767883\n",
      "Iteration 520, Loss: 3.507034489302896e-05, Min w: 0.9282775521278381\n",
      "Iteration 530, Loss: 3.590531923691742e-05, Min w: 0.9249445796012878\n",
      "Iteration 540, Loss: 3.757063313969411e-05, Min w: 0.9222540259361267\n",
      "Iteration 550, Loss: 4.649101902032271e-05, Min w: 0.8897418975830078\n",
      "Iteration 560, Loss: 3.6979388823965564e-05, Min w: 0.9210686087608337\n",
      "Iteration 570, Loss: 3.633746018749662e-05, Min w: 0.9234619736671448\n",
      "Iteration 580, Loss: 3.405151073820889e-05, Min w: 0.9288575053215027\n",
      "Iteration 590, Loss: 3.3269803680013865e-05, Min w: 0.9315879940986633\n",
      "Iteration 600, Loss: 3.45018197549507e-05, Min w: 0.9285174012184143\n",
      "Iteration 610, Loss: 3.817321339738555e-05, Min w: 0.9170407056808472\n",
      "Iteration 620, Loss: 3.44511863659136e-05, Min w: 0.9278267621994019\n",
      "Iteration 630, Loss: 3.438373460085131e-05, Min w: 0.927582859992981\n",
      "Iteration 640, Loss: 3.2403266231995076e-05, Min w: 0.9334876537322998\n",
      "Iteration 650, Loss: 3.4210581361548975e-05, Min w: 0.9284166097640991\n",
      "Iteration 660, Loss: 3.5223398299422115e-05, Min w: 0.9268640875816345\n",
      "Iteration 670, Loss: 3.392179496586323e-05, Min w: 0.9305635690689087\n",
      "Iteration 680, Loss: 3.332951746415347e-05, Min w: 0.9307975769042969\n",
      "Iteration 690, Loss: 3.2350755645893514e-05, Min w: 0.9338089823722839\n",
      "Iteration 700, Loss: 3.4547610994195566e-05, Min w: 0.925074577331543\n",
      "Iteration 710, Loss: 3.398541593924165e-05, Min w: 0.9269475936889648\n",
      "Iteration 720, Loss: 3.5671710065798834e-05, Min w: 0.9201304316520691\n",
      "Iteration 730, Loss: 4.164897109149024e-05, Min w: 0.901439905166626\n",
      "Iteration 740, Loss: 3.2394236768595874e-05, Min w: 0.9311382174491882\n",
      "Iteration 750, Loss: 3.2553125492995605e-05, Min w: 0.9331077933311462\n",
      "Iteration 760, Loss: 5.76282363908831e-05, Min w: 0.847565233707428\n",
      "Iteration 770, Loss: 3.3241369237657636e-05, Min w: 0.9295258522033691\n",
      "Iteration 780, Loss: 3.6252764402888715e-05, Min w: 0.9167178869247437\n",
      "Iteration 790, Loss: 3.4289390896447e-05, Min w: 0.9247928857803345\n",
      "Iteration 800, Loss: 3.09237620967906e-05, Min w: 0.9358819723129272\n",
      "Iteration 810, Loss: 3.8053662137826905e-05, Min w: 0.9105814695358276\n",
      "Iteration 820, Loss: 3.450116855674423e-05, Min w: 0.9240784049034119\n",
      "Iteration 830, Loss: 3.505280983517878e-05, Min w: 0.9233254194259644\n",
      "Iteration 840, Loss: 3.0449245969066396e-05, Min w: 0.9368028044700623\n",
      "Iteration 850, Loss: 3.54336152668111e-05, Min w: 0.9206048846244812\n",
      "Iteration 860, Loss: 3.119689063169062e-05, Min w: 0.9338089823722839\n",
      "Iteration 870, Loss: 3.118082895525731e-05, Min w: 0.9341731071472168\n",
      "Iteration 880, Loss: 3.0783550755586475e-05, Min w: 0.9361596703529358\n",
      "Iteration 890, Loss: 3.4314445656491444e-05, Min w: 0.923546552658081\n",
      "Iteration 900, Loss: 4.341565363574773e-05, Min w: 0.8920160531997681\n",
      "Iteration 910, Loss: 3.2850850402610376e-05, Min w: 0.9293168783187866\n",
      "Iteration 920, Loss: 2.9857130357413553e-05, Min w: 0.9371008276939392\n",
      "Iteration 930, Loss: 3.1180097721517086e-05, Min w: 0.9332207441329956\n",
      "Iteration 940, Loss: 3.664720861706883e-05, Min w: 0.9168118238449097\n",
      "Iteration 950, Loss: 3.7594316381728277e-05, Min w: 0.9125427007675171\n",
      "Iteration 960, Loss: 4.053108932566829e-05, Min w: 0.9010317921638489\n",
      "Iteration 970, Loss: 3.80955716536846e-05, Min w: 0.9098427891731262\n",
      "Iteration 980, Loss: 3.254893817938864e-05, Min w: 0.9289827942848206\n",
      "Iteration 990, Loss: 3.232863309676759e-05, Min w: 0.9284663200378418\n",
      "Iteration 1000, Loss: 3.050799023185391e-05, Min w: 0.9356018900871277\n",
      "Iteration 1010, Loss: 3.8779635360697284e-05, Min w: 0.9042167663574219\n",
      "Iteration 1020, Loss: 3.85999956051819e-05, Min w: 0.9085187911987305\n",
      "Iteration 1030, Loss: 4.038664701511152e-05, Min w: 0.8982434272766113\n",
      "Iteration 1040, Loss: 2.986983054142911e-05, Min w: 0.9321856498718262\n",
      "Iteration 1050, Loss: 3.57754179276526e-05, Min w: 0.9169528484344482\n",
      "Iteration 1060, Loss: 3.531063339323737e-05, Min w: 0.9164419770240784\n",
      "Iteration 1070, Loss: 3.177175676682964e-05, Min w: 0.9279033541679382\n",
      "Iteration 1080, Loss: 3.149858821416274e-05, Min w: 0.9284328818321228\n",
      "Iteration 1090, Loss: 3.1377367122331634e-05, Min w: 0.9306811094284058\n",
      "Iteration 1100, Loss: 2.8674941859208047e-05, Min w: 0.9374865889549255\n",
      "Iteration 1110, Loss: 2.9214568712632172e-05, Min w: 0.9351205229759216\n",
      "Iteration 1120, Loss: 3.0316930860863067e-05, Min w: 0.9357060790061951\n",
      "Iteration 1130, Loss: 2.8522457796498202e-05, Min w: 0.9384044408798218\n",
      "Iteration 1140, Loss: 2.7538158974493854e-05, Min w: 0.9392797946929932\n",
      "Iteration 1150, Loss: 3.134018334094435e-05, Min w: 0.9275636076927185\n",
      "Iteration 1160, Loss: 2.9265182092785835e-05, Min w: 0.9350841641426086\n",
      "Iteration 1170, Loss: 2.778565431071911e-05, Min w: 0.9395982027053833\n",
      "Iteration 1180, Loss: 2.841473360604141e-05, Min w: 0.9376150965690613\n",
      "Iteration 1190, Loss: 4.1079390939557925e-05, Min w: 0.8945915699005127\n",
      "Iteration 1200, Loss: 2.8112561267334968e-05, Min w: 0.9395168423652649\n",
      "Iteration 1210, Loss: 3.1474897696170956e-05, Min w: 0.9244505763053894\n",
      "Iteration 1220, Loss: 2.7538841095520183e-05, Min w: 0.9395051598548889\n",
      "Iteration 1230, Loss: 2.784312891890295e-05, Min w: 0.9398761987686157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  62%|██████▎   | 15/24 [24:11<15:51, 105.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 2.638865407789126e-05, Min w: 0.9426653981208801\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.020835677399298258, 'L2_avg': 0.03312388001278822, 'End_point_L1_avg': 0.006457692935952183, 'End_point_L2_avg': 0.007825245428836726}\n",
      "Iteration 0, Loss: 0.0012010085629299283, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010595900239422917, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009568635723553598, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008523728465661407, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007995758787728846, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007843908970244229, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007484704838134348, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007394247804768384, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006084289052523673, Min w: 0.0\n",
      "Iteration 90, Loss: 0.000544972310308367, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0004930589930154383, Min w: 0.0\n",
      "Iteration 110, Loss: 0.00048032632912509143, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0004728330532088876, Min w: 0.0\n",
      "Iteration 130, Loss: 0.00046108398237265646, Min w: 0.0\n",
      "Iteration 140, Loss: 0.00045081519056111574, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00045239643077366054, Min w: 0.0\n",
      "Iteration 160, Loss: 0.00044731880188919604, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0004434247384779155, Min w: 0.0\n",
      "Iteration 180, Loss: 0.00042304565431550145, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0004264111921656877, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0004308714997023344, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0004260302521288395, Min w: 0.0\n",
      "Iteration 220, Loss: 0.00043080878094770014, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004257730324752629, Min w: 0.0\n",
      "Iteration 240, Loss: 0.00044073144090361893, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004448811523616314, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00043503238703124225, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00043663106043823063, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00043355574598535895, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0004225907614454627, Min w: 0.0\n",
      "Iteration 300, Loss: 0.00042361277155578136, Min w: 0.0\n",
      "Iteration 310, Loss: 0.00041083223186433315, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0004098558274563402, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0003961715556215495, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00040064926724880934, Min w: 0.0\n",
      "Iteration 350, Loss: 0.00039573933463543653, Min w: 0.0\n",
      "Iteration 360, Loss: 0.00039689161349087954, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0003869336796924472, Min w: 0.0\n",
      "Iteration 380, Loss: 0.00037872715620324016, Min w: 0.0\n",
      "Iteration 390, Loss: 0.00036374773480929434, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0003689719014801085, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0003544744977261871, Min w: 0.0\n",
      "Iteration 420, Loss: 0.00035340196336619556, Min w: 0.0\n",
      "Iteration 430, Loss: 0.00034576727193780243, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0003639936912804842, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0003470375086180866, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0003476839337963611, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00034276567748747766, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000341375038260594, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0003493912809062749, Min w: 0.0\n",
      "Iteration 500, Loss: 0.00035111309261992574, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00034308547037653625, Min w: 0.0\n",
      "Iteration 520, Loss: 0.000342128099873662, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000347404828062281, Min w: 0.0\n",
      "Iteration 540, Loss: 0.00035001515061594546, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0003500384045764804, Min w: 0.0\n",
      "Iteration 560, Loss: 0.00035258152638562024, Min w: 1.2051166793193427e-43\n",
      "Iteration 570, Loss: 0.00036056971293874085, Min w: 1.7388154683239094e-29\n",
      "Iteration 580, Loss: 0.00035961720277555287, Min w: 2.020799961720362e-18\n",
      "Iteration 590, Loss: 0.0003626729594543576, Min w: 4.247952656299958e-09\n",
      "Iteration 600, Loss: 0.0003718240768648684, Min w: 0.0005946917808614671\n",
      "Iteration 610, Loss: 0.00037847348721697927, Min w: 0.00025543515221215785\n",
      "Iteration 620, Loss: 0.00038554109050892293, Min w: 2.8835773768776107e-09\n",
      "Iteration 630, Loss: 0.00038641379796899855, Min w: 1.3429710121748428e-10\n",
      "Iteration 640, Loss: 0.0003780638216994703, Min w: 4.7455275264951524e-09\n",
      "Iteration 650, Loss: 0.00037483422784134746, Min w: 3.8335866747729597e-07\n",
      "Iteration 660, Loss: 0.00037177506601437926, Min w: 3.464275141595863e-05\n",
      "Iteration 670, Loss: 0.0003778959217015654, Min w: 0.006452732719480991\n",
      "Iteration 680, Loss: 0.00037587821134366095, Min w: 0.02325085550546646\n",
      "Iteration 690, Loss: 0.0003775304649025202, Min w: 0.02332892268896103\n",
      "Iteration 700, Loss: 0.00037622026866301894, Min w: 0.02761763148009777\n",
      "Iteration 710, Loss: 0.00036690483102574944, Min w: 0.04011908918619156\n",
      "Iteration 720, Loss: 0.00036994947004131973, Min w: 0.0601782463490963\n",
      "Iteration 730, Loss: 0.00037175367469899356, Min w: 0.07992865890264511\n",
      "Iteration 740, Loss: 0.0003547650121618062, Min w: 0.1124168336391449\n",
      "Iteration 750, Loss: 0.00034478044835850596, Min w: 0.15096868574619293\n",
      "Iteration 760, Loss: 0.0003388046461623162, Min w: 0.174566388130188\n",
      "Iteration 770, Loss: 0.00033473290386609733, Min w: 0.18371424078941345\n",
      "Iteration 780, Loss: 0.0003322104166727513, Min w: 0.19217254221439362\n",
      "Iteration 790, Loss: 0.0003304809797555208, Min w: 0.19311437010765076\n",
      "Iteration 800, Loss: 0.00032394248410128057, Min w: 0.20106305181980133\n",
      "Iteration 810, Loss: 0.00031882020994089544, Min w: 0.2065238505601883\n",
      "Iteration 820, Loss: 0.0003130165860056877, Min w: 0.22580336034297943\n",
      "Iteration 830, Loss: 0.00032040008227340877, Min w: 0.2286296933889389\n",
      "Iteration 840, Loss: 0.00031213878537528217, Min w: 0.22881992161273956\n",
      "Iteration 850, Loss: 0.00032390785054303706, Min w: 0.23346863687038422\n",
      "Iteration 860, Loss: 0.0003020566946361214, Min w: 0.24140635132789612\n",
      "Iteration 870, Loss: 0.00030178771703504026, Min w: 0.25178173184394836\n",
      "Iteration 880, Loss: 0.00030017609242349863, Min w: 0.248063325881958\n",
      "Iteration 890, Loss: 0.00029990883194841444, Min w: 0.261891633272171\n",
      "Iteration 900, Loss: 0.0003009231004398316, Min w: 0.26610755920410156\n",
      "Iteration 910, Loss: 0.0002899342798627913, Min w: 0.27993136644363403\n",
      "Iteration 920, Loss: 0.0002893054625019431, Min w: 0.27775633335113525\n",
      "Iteration 930, Loss: 0.0002895657962653786, Min w: 0.28410065174102783\n",
      "Iteration 940, Loss: 0.0002816572377923876, Min w: 0.2877565622329712\n",
      "Iteration 950, Loss: 0.00028917097370140254, Min w: 0.2867727279663086\n",
      "Iteration 960, Loss: 0.0002836477942764759, Min w: 0.3110111951828003\n",
      "Iteration 970, Loss: 0.0002763705560937524, Min w: 0.3141377568244934\n",
      "Iteration 980, Loss: 0.00027126612258143723, Min w: 0.2959081530570984\n",
      "Iteration 990, Loss: 0.0002640065213199705, Min w: 0.32804208993911743\n",
      "Iteration 1000, Loss: 0.0002613582764752209, Min w: 0.33392655849456787\n",
      "Iteration 1010, Loss: 0.0002638075966387987, Min w: 0.3291640281677246\n",
      "Iteration 1020, Loss: 0.00027013238286599517, Min w: 0.33844274282455444\n",
      "Iteration 1030, Loss: 0.00025797501439228654, Min w: 0.34322693943977356\n",
      "Iteration 1040, Loss: 0.0002529977064114064, Min w: 0.3486018478870392\n",
      "Iteration 1050, Loss: 0.0002561363799031824, Min w: 0.34618476033210754\n",
      "Iteration 1060, Loss: 0.0002535939565859735, Min w: 0.34870070219039917\n",
      "Iteration 1070, Loss: 0.0002477777888998389, Min w: 0.36521467566490173\n",
      "Iteration 1080, Loss: 0.00024290176224894822, Min w: 0.3733888268470764\n",
      "Iteration 1090, Loss: 0.00023966061417013407, Min w: 0.3791135847568512\n",
      "Iteration 1100, Loss: 0.00023777411843184382, Min w: 0.3807767629623413\n",
      "Iteration 1110, Loss: 0.00024665927048772573, Min w: 0.3679810166358948\n",
      "Iteration 1120, Loss: 0.0002435031783534214, Min w: 0.3866066038608551\n",
      "Iteration 1130, Loss: 0.00024123663024511188, Min w: 0.3775767385959625\n",
      "Iteration 1140, Loss: 0.00023214372049551457, Min w: 0.3918988108634949\n",
      "Iteration 1150, Loss: 0.00024782319087535143, Min w: 0.39823657274246216\n",
      "Iteration 1160, Loss: 0.00023193169909063727, Min w: 0.3950918912887573\n",
      "Iteration 1170, Loss: 0.0002250759134767577, Min w: 0.4058375656604767\n",
      "Iteration 1180, Loss: 0.00022240732505451888, Min w: 0.40771305561065674\n",
      "Iteration 1190, Loss: 0.00022351578809320927, Min w: 0.4029395580291748\n",
      "Iteration 1200, Loss: 0.0002197559952037409, Min w: 0.42368045449256897\n",
      "Iteration 1210, Loss: 0.00021334124903660268, Min w: 0.4247042238712311\n",
      "Iteration 1220, Loss: 0.00023576675448566675, Min w: 0.41929304599761963\n",
      "Iteration 1230, Loss: 0.00021087375353090465, Min w: 0.439513236284256\n",
      "Iteration 1240, Loss: 0.00020865014812443405, Min w: 0.4420742392539978\n",
      "Iteration 0, Loss: 0.00020974795916117728, Min w: 0.43670764565467834\n",
      "Iteration 10, Loss: 0.0002092106587952003, Min w: 0.4459550678730011\n",
      "Iteration 20, Loss: 0.00020768764079548419, Min w: 0.4433771073818207\n",
      "Iteration 30, Loss: 0.00022180976520758122, Min w: 0.4374776780605316\n",
      "Iteration 40, Loss: 0.00021309967269189656, Min w: 0.4535520374774933\n",
      "Iteration 50, Loss: 0.00020390693680383265, Min w: 0.4534657299518585\n",
      "Iteration 60, Loss: 0.0002003667614189908, Min w: 0.46094176173210144\n",
      "Iteration 70, Loss: 0.00019514566520228982, Min w: 0.4735758900642395\n",
      "Iteration 80, Loss: 0.0001939903449965641, Min w: 0.4706152677536011\n",
      "Iteration 90, Loss: 0.00019778234127443284, Min w: 0.47260668873786926\n",
      "Iteration 100, Loss: 0.0001944489049492404, Min w: 0.4811975359916687\n",
      "Iteration 110, Loss: 0.00019848323427140713, Min w: 0.4856973886489868\n",
      "Iteration 120, Loss: 0.00019463397620711476, Min w: 0.4862256646156311\n",
      "Iteration 130, Loss: 0.00018601413466967642, Min w: 0.4884452521800995\n",
      "Iteration 140, Loss: 0.00018087640637531877, Min w: 0.505383312702179\n",
      "Iteration 150, Loss: 0.00018081908638123423, Min w: 0.5051025152206421\n",
      "Iteration 160, Loss: 0.00017767118697520345, Min w: 0.5081864595413208\n",
      "Iteration 170, Loss: 0.0001840216718846932, Min w: 0.5103217959403992\n",
      "Iteration 180, Loss: 0.00017415013280697167, Min w: 0.524313747882843\n",
      "Iteration 190, Loss: 0.00018478362471796572, Min w: 0.5140972137451172\n",
      "Iteration 200, Loss: 0.0001747024361975491, Min w: 0.5237152576446533\n",
      "Iteration 210, Loss: 0.00016999748186208308, Min w: 0.5271888375282288\n",
      "Iteration 220, Loss: 0.00017004762776196003, Min w: 0.5337919592857361\n",
      "Iteration 230, Loss: 0.00017304149514529854, Min w: 0.5469328165054321\n",
      "Iteration 240, Loss: 0.00016457022866234183, Min w: 0.5463371872901917\n",
      "Iteration 250, Loss: 0.00017834398022387177, Min w: 0.5273160338401794\n",
      "Iteration 260, Loss: 0.0001650880294619128, Min w: 0.549169659614563\n",
      "Iteration 270, Loss: 0.00016081439389381558, Min w: 0.5548251271247864\n",
      "Iteration 280, Loss: 0.00015753376646898687, Min w: 0.5579559803009033\n",
      "Iteration 290, Loss: 0.00017022014071699232, Min w: 0.5555300116539001\n",
      "Iteration 300, Loss: 0.00015496264677494764, Min w: 0.5639859437942505\n",
      "Iteration 310, Loss: 0.00015692698070779443, Min w: 0.5701579451560974\n",
      "Iteration 320, Loss: 0.00016156650963239372, Min w: 0.5720982551574707\n",
      "Iteration 330, Loss: 0.00015210380661301315, Min w: 0.577475905418396\n",
      "Iteration 340, Loss: 0.00014863497926853597, Min w: 0.5824770927429199\n",
      "Iteration 350, Loss: 0.00014934527280274779, Min w: 0.5918113589286804\n",
      "Iteration 360, Loss: 0.00015479126886930317, Min w: 0.5884128212928772\n",
      "Iteration 370, Loss: 0.00015588762471452355, Min w: 0.581903338432312\n",
      "Iteration 380, Loss: 0.00015147315571084619, Min w: 0.5880602598190308\n",
      "Iteration 390, Loss: 0.00016082757792901248, Min w: 0.5910782217979431\n",
      "Iteration 400, Loss: 0.00014499321696348488, Min w: 0.6058477759361267\n",
      "Iteration 410, Loss: 0.00014172933879308403, Min w: 0.6015064716339111\n",
      "Iteration 420, Loss: 0.00013974368630442768, Min w: 0.6119052767753601\n",
      "Iteration 430, Loss: 0.00013674615183845162, Min w: 0.6146714091300964\n",
      "Iteration 440, Loss: 0.00013737590052187443, Min w: 0.6127741932868958\n",
      "Iteration 450, Loss: 0.0001395336294081062, Min w: 0.619285523891449\n",
      "Iteration 460, Loss: 0.00014165045286063105, Min w: 0.6185389757156372\n",
      "Iteration 470, Loss: 0.000133264169562608, Min w: 0.638018012046814\n",
      "Iteration 480, Loss: 0.00013649181346409023, Min w: 0.6331830620765686\n",
      "Iteration 490, Loss: 0.00012974008859600872, Min w: 0.6319130659103394\n",
      "Iteration 500, Loss: 0.00013765583571512252, Min w: 0.6393622756004333\n",
      "Iteration 510, Loss: 0.00013855464931111783, Min w: 0.6287752389907837\n",
      "Iteration 520, Loss: 0.00013564438268076628, Min w: 0.6379283666610718\n",
      "Iteration 530, Loss: 0.0001255422248505056, Min w: 0.645072340965271\n",
      "Iteration 540, Loss: 0.000124517988297157, Min w: 0.6548261046409607\n",
      "Iteration 550, Loss: 0.0001244318118551746, Min w: 0.6523172855377197\n",
      "Iteration 560, Loss: 0.0001425675000064075, Min w: 0.6459871530532837\n",
      "Iteration 570, Loss: 0.0001211862763739191, Min w: 0.6614948511123657\n",
      "Iteration 580, Loss: 0.000120385957416147, Min w: 0.6601579785346985\n",
      "Iteration 590, Loss: 0.0001179592072730884, Min w: 0.6715478301048279\n",
      "Iteration 600, Loss: 0.00011793536395998672, Min w: 0.6663188934326172\n",
      "Iteration 610, Loss: 0.00011622576857917011, Min w: 0.6770296096801758\n",
      "Iteration 620, Loss: 0.00011617552809184417, Min w: 0.6720190048217773\n",
      "Iteration 630, Loss: 0.00011620716395555064, Min w: 0.67765873670578\n",
      "Iteration 640, Loss: 0.00011699472815962508, Min w: 0.6753628849983215\n",
      "Iteration 650, Loss: 0.00011529745097504929, Min w: 0.6824080944061279\n",
      "Iteration 660, Loss: 0.00011265050125075504, Min w: 0.6816685199737549\n",
      "Iteration 670, Loss: 0.00011237111903028563, Min w: 0.6905645728111267\n",
      "Iteration 680, Loss: 0.00011140599963255227, Min w: 0.6874452233314514\n",
      "Iteration 690, Loss: 0.00010871008998947218, Min w: 0.6974472403526306\n",
      "Iteration 700, Loss: 0.00011310906120343134, Min w: 0.6940472722053528\n",
      "Iteration 710, Loss: 0.00011167179036419839, Min w: 0.6991350054740906\n",
      "Iteration 720, Loss: 0.00010781338642118499, Min w: 0.6989917755126953\n",
      "Iteration 730, Loss: 0.00010607811418594792, Min w: 0.7106767892837524\n",
      "Iteration 740, Loss: 0.00011013325274689123, Min w: 0.7080068588256836\n",
      "Iteration 750, Loss: 0.0001276779075851664, Min w: 0.7000754475593567\n",
      "Iteration 760, Loss: 0.00010375629062764347, Min w: 0.7082231640815735\n",
      "Iteration 770, Loss: 0.00010316434054402635, Min w: 0.7177302241325378\n",
      "Iteration 780, Loss: 0.00010437177843414247, Min w: 0.7173978686332703\n",
      "Iteration 790, Loss: 0.00010052080324385315, Min w: 0.7236309051513672\n",
      "Iteration 800, Loss: 0.00010126591951120645, Min w: 0.722894549369812\n",
      "Iteration 810, Loss: 9.83644713414833e-05, Min w: 0.7274702787399292\n",
      "Iteration 820, Loss: 9.73496280494146e-05, Min w: 0.7294812798500061\n",
      "Iteration 830, Loss: 9.991059050662443e-05, Min w: 0.7215911149978638\n",
      "Iteration 840, Loss: 9.774246427696198e-05, Min w: 0.7349938750267029\n",
      "Iteration 850, Loss: 9.851784125203267e-05, Min w: 0.7335926294326782\n",
      "Iteration 860, Loss: 0.00010439186735311523, Min w: 0.7299736738204956\n",
      "Iteration 870, Loss: 0.00011193192040082067, Min w: 0.7228379845619202\n",
      "Iteration 880, Loss: 0.00010021556227002293, Min w: 0.7367525696754456\n",
      "Iteration 890, Loss: 9.401138959219679e-05, Min w: 0.7486563920974731\n",
      "Iteration 900, Loss: 0.00010069115523947403, Min w: 0.7385253310203552\n",
      "Iteration 910, Loss: 9.526119538350031e-05, Min w: 0.7474650740623474\n",
      "Iteration 920, Loss: 9.959018643712625e-05, Min w: 0.7469986081123352\n",
      "Iteration 930, Loss: 8.952776261139661e-05, Min w: 0.753386378288269\n",
      "Iteration 940, Loss: 8.94615295692347e-05, Min w: 0.7589784264564514\n",
      "Iteration 950, Loss: 9.497650898993015e-05, Min w: 0.7527180314064026\n",
      "Iteration 960, Loss: 0.00010167778964387253, Min w: 0.7471510171890259\n",
      "Iteration 970, Loss: 8.812484884401783e-05, Min w: 0.7601888179779053\n",
      "Iteration 980, Loss: 9.262951789423823e-05, Min w: 0.7557927966117859\n",
      "Iteration 990, Loss: 9.032366506289691e-05, Min w: 0.7617704272270203\n",
      "Iteration 1000, Loss: 8.682256884640083e-05, Min w: 0.7706801295280457\n",
      "Iteration 1010, Loss: 9.237850463250652e-05, Min w: 0.7674039006233215\n",
      "Iteration 1020, Loss: 8.475883805658668e-05, Min w: 0.7675806879997253\n",
      "Iteration 1030, Loss: 8.417770004598424e-05, Min w: 0.7768881916999817\n",
      "Iteration 1040, Loss: 8.407866698689759e-05, Min w: 0.7751815319061279\n",
      "Iteration 1050, Loss: 8.735191659070551e-05, Min w: 0.7732640504837036\n",
      "Iteration 1060, Loss: 9.028015483636409e-05, Min w: 0.7754740118980408\n",
      "Iteration 1070, Loss: 8.327212708536536e-05, Min w: 0.7796810865402222\n",
      "Iteration 1080, Loss: 8.308622636832297e-05, Min w: 0.7789243459701538\n",
      "Iteration 1090, Loss: 8.170379442162812e-05, Min w: 0.7835410833358765\n",
      "Iteration 1100, Loss: 7.839773024898022e-05, Min w: 0.7859905958175659\n",
      "Iteration 1110, Loss: 8.548931509722024e-05, Min w: 0.7876441478729248\n",
      "Iteration 1120, Loss: 8.585810428485274e-05, Min w: 0.7874922156333923\n",
      "Iteration 1130, Loss: 8.247904042946175e-05, Min w: 0.7900140285491943\n",
      "Iteration 1140, Loss: 8.27600815682672e-05, Min w: 0.7916710376739502\n",
      "Iteration 1150, Loss: 8.748685650061816e-05, Min w: 0.7970389127731323\n",
      "Iteration 1160, Loss: 8.331977733178064e-05, Min w: 0.7899332046508789\n",
      "Iteration 1170, Loss: 8.998434350360185e-05, Min w: 0.7849019169807434\n",
      "Iteration 1180, Loss: 7.584739796584472e-05, Min w: 0.8001182675361633\n",
      "Iteration 1190, Loss: 7.495320460293442e-05, Min w: 0.8077848553657532\n",
      "Iteration 1200, Loss: 8.166044426616281e-05, Min w: 0.7984723448753357\n",
      "Iteration 1210, Loss: 7.298184209503233e-05, Min w: 0.808607280254364\n",
      "Iteration 1220, Loss: 8.958441321738064e-05, Min w: 0.7911460399627686\n",
      "Iteration 1230, Loss: 7.766216003801674e-05, Min w: 0.8054313659667969\n",
      "Iteration 1240, Loss: 7.341635500779375e-05, Min w: 0.8117809891700745\n",
      "Iteration 0, Loss: 8.149594941642135e-05, Min w: 0.80597323179245\n",
      "Iteration 10, Loss: 7.216326775960624e-05, Min w: 0.8150978684425354\n",
      "Iteration 20, Loss: 7.559621008113027e-05, Min w: 0.8115523457527161\n",
      "Iteration 30, Loss: 6.792699423385784e-05, Min w: 0.8179020285606384\n",
      "Iteration 40, Loss: 6.993629358476028e-05, Min w: 0.8191096186637878\n",
      "Iteration 50, Loss: 7.025449303910136e-05, Min w: 0.8189648389816284\n",
      "Iteration 60, Loss: 6.815865344833583e-05, Min w: 0.8216407895088196\n",
      "Iteration 70, Loss: 7.036765600787476e-05, Min w: 0.8239682912826538\n",
      "Iteration 80, Loss: 6.786113954149187e-05, Min w: 0.8260255455970764\n",
      "Iteration 90, Loss: 6.788139580748975e-05, Min w: 0.8232840299606323\n",
      "Iteration 100, Loss: 6.798943650210276e-05, Min w: 0.8268847465515137\n",
      "Iteration 110, Loss: 6.751624459866434e-05, Min w: 0.8263607621192932\n",
      "Iteration 120, Loss: 6.585132359759882e-05, Min w: 0.828892707824707\n",
      "Iteration 130, Loss: 7.868871762184426e-05, Min w: 0.816974401473999\n",
      "Iteration 140, Loss: 6.828621553722769e-05, Min w: 0.8285393714904785\n",
      "Iteration 150, Loss: 6.684497930109501e-05, Min w: 0.8304588794708252\n",
      "Iteration 160, Loss: 6.4717503846623e-05, Min w: 0.8345567584037781\n",
      "Iteration 170, Loss: 8.504444122081622e-05, Min w: 0.8169244527816772\n",
      "Iteration 180, Loss: 7.652785279788077e-05, Min w: 0.8289308547973633\n",
      "Iteration 190, Loss: 6.947795191081241e-05, Min w: 0.8354108929634094\n",
      "Iteration 200, Loss: 6.486651545856148e-05, Min w: 0.8379004001617432\n",
      "Iteration 210, Loss: 6.168075924506411e-05, Min w: 0.8411881923675537\n",
      "Iteration 220, Loss: 6.159215263323858e-05, Min w: 0.8420953154563904\n",
      "Iteration 230, Loss: 6.169194966787472e-05, Min w: 0.8450976610183716\n",
      "Iteration 240, Loss: 6.64063700241968e-05, Min w: 0.840265691280365\n",
      "Iteration 250, Loss: 7.244773587444797e-05, Min w: 0.8357628583908081\n",
      "Iteration 260, Loss: 6.157475581858307e-05, Min w: 0.8485389947891235\n",
      "Iteration 270, Loss: 6.734005728503689e-05, Min w: 0.8446754813194275\n",
      "Iteration 280, Loss: 6.51762165944092e-05, Min w: 0.845180869102478\n",
      "Iteration 290, Loss: 5.962838986306451e-05, Min w: 0.8478941321372986\n",
      "Iteration 300, Loss: 6.282416870817542e-05, Min w: 0.8444015979766846\n",
      "Iteration 310, Loss: 6.101654071244411e-05, Min w: 0.8472962379455566\n",
      "Iteration 320, Loss: 5.8794936194317415e-05, Min w: 0.8528385758399963\n",
      "Iteration 330, Loss: 5.917702947044745e-05, Min w: 0.8543289303779602\n",
      "Iteration 340, Loss: 5.7496552472002804e-05, Min w: 0.8558204174041748\n",
      "Iteration 350, Loss: 5.602699820883572e-05, Min w: 0.8572392463684082\n",
      "Iteration 360, Loss: 5.616146881948225e-05, Min w: 0.8587868213653564\n",
      "Iteration 370, Loss: 5.541795690078288e-05, Min w: 0.8582398891448975\n",
      "Iteration 380, Loss: 6.478581053670496e-05, Min w: 0.8542254567146301\n",
      "Iteration 390, Loss: 6.215718167368323e-05, Min w: 0.8552204370498657\n",
      "Iteration 400, Loss: 5.580910510616377e-05, Min w: 0.860002875328064\n",
      "Iteration 410, Loss: 5.77210339542944e-05, Min w: 0.8605445623397827\n",
      "Iteration 420, Loss: 6.246370321605355e-05, Min w: 0.8571810722351074\n",
      "Iteration 430, Loss: 5.495919322129339e-05, Min w: 0.8621697425842285\n",
      "Iteration 440, Loss: 5.4371415899368e-05, Min w: 0.8640735149383545\n",
      "Iteration 450, Loss: 5.435326966107823e-05, Min w: 0.8652754426002502\n",
      "Iteration 460, Loss: 5.676929504261352e-05, Min w: 0.8595923185348511\n",
      "Iteration 470, Loss: 5.385360782383941e-05, Min w: 0.8691175580024719\n",
      "Iteration 480, Loss: 5.277696982375346e-05, Min w: 0.8684095144271851\n",
      "Iteration 490, Loss: 5.29194985574577e-05, Min w: 0.8672501444816589\n",
      "Iteration 500, Loss: 5.319022966432385e-05, Min w: 0.8677935600280762\n",
      "Iteration 510, Loss: 5.508787580765784e-05, Min w: 0.8672555088996887\n",
      "Iteration 520, Loss: 6.290925375651568e-05, Min w: 0.8583400249481201\n",
      "Iteration 530, Loss: 6.167073297547176e-05, Min w: 0.8639134168624878\n",
      "Iteration 540, Loss: 5.160887667443603e-05, Min w: 0.8718982338905334\n",
      "Iteration 550, Loss: 5.503308057086542e-05, Min w: 0.8702961802482605\n",
      "Iteration 560, Loss: 5.069790859124623e-05, Min w: 0.8750799894332886\n",
      "Iteration 570, Loss: 5.0594331696629524e-05, Min w: 0.8741317987442017\n",
      "Iteration 580, Loss: 6.64483814034611e-05, Min w: 0.8621301651000977\n",
      "Iteration 590, Loss: 5.976744432700798e-05, Min w: 0.8688132762908936\n",
      "Iteration 600, Loss: 5.0760223530232906e-05, Min w: 0.8757057785987854\n",
      "Iteration 610, Loss: 5.480089384946041e-05, Min w: 0.87627112865448\n",
      "Iteration 620, Loss: 5.1924536819569767e-05, Min w: 0.8726195096969604\n",
      "Iteration 630, Loss: 5.345495083020069e-05, Min w: 0.878795862197876\n",
      "Iteration 640, Loss: 5.4261072364170104e-05, Min w: 0.8757819533348083\n",
      "Iteration 650, Loss: 5.427495125331916e-05, Min w: 0.8762009143829346\n",
      "Iteration 660, Loss: 5.9471734857652336e-05, Min w: 0.8688012361526489\n",
      "Iteration 670, Loss: 4.753446773975156e-05, Min w: 0.8815916776657104\n",
      "Iteration 680, Loss: 4.779372102348134e-05, Min w: 0.8808736801147461\n",
      "Iteration 690, Loss: 4.7999212256399915e-05, Min w: 0.8831233382225037\n",
      "Iteration 700, Loss: 4.769275619764812e-05, Min w: 0.8840912580490112\n",
      "Iteration 710, Loss: 4.759682997246273e-05, Min w: 0.8818740844726562\n",
      "Iteration 720, Loss: 4.6253418986452743e-05, Min w: 0.8848628997802734\n",
      "Iteration 730, Loss: 4.759971852763556e-05, Min w: 0.882801353931427\n",
      "Iteration 740, Loss: 4.68515936518088e-05, Min w: 0.8844872117042542\n",
      "Iteration 750, Loss: 5.956762834102847e-05, Min w: 0.8773840069770813\n",
      "Iteration 760, Loss: 8.026338036870584e-05, Min w: 0.8145859241485596\n",
      "Iteration 770, Loss: 4.87547367811203e-05, Min w: 0.8858104944229126\n",
      "Iteration 780, Loss: 4.7613535571144894e-05, Min w: 0.886226236820221\n",
      "Iteration 790, Loss: 5.280293771647848e-05, Min w: 0.880420446395874\n",
      "Iteration 800, Loss: 5.3294748795451596e-05, Min w: 0.8825562000274658\n",
      "Iteration 810, Loss: 4.3978467147098854e-05, Min w: 0.8928026556968689\n",
      "Iteration 820, Loss: 4.765517223859206e-05, Min w: 0.8897132873535156\n",
      "Iteration 830, Loss: 4.4014966988470405e-05, Min w: 0.8896976113319397\n",
      "Iteration 840, Loss: 4.512578743742779e-05, Min w: 0.8911035060882568\n",
      "Iteration 850, Loss: 4.4214772060513496e-05, Min w: 0.894275963306427\n",
      "Iteration 860, Loss: 4.557423744699918e-05, Min w: 0.8906692266464233\n",
      "Iteration 870, Loss: 5.604538455372676e-05, Min w: 0.8803737163543701\n",
      "Iteration 880, Loss: 4.3319927499396726e-05, Min w: 0.8951978087425232\n",
      "Iteration 890, Loss: 4.295592589187436e-05, Min w: 0.895836353302002\n",
      "Iteration 900, Loss: 4.3169897253392264e-05, Min w: 0.895992636680603\n",
      "Iteration 910, Loss: 4.333045581006445e-05, Min w: 0.894969642162323\n",
      "Iteration 920, Loss: 4.2414816562086344e-05, Min w: 0.8983625769615173\n",
      "Iteration 930, Loss: 5.1136008551111445e-05, Min w: 0.8923823237419128\n",
      "Iteration 940, Loss: 4.3144016672158614e-05, Min w: 0.894206702709198\n",
      "Iteration 950, Loss: 4.190740219200961e-05, Min w: 0.9006063342094421\n",
      "Iteration 960, Loss: 4.2570180085022e-05, Min w: 0.8995521068572998\n",
      "Iteration 970, Loss: 4.294642712920904e-05, Min w: 0.8991488814353943\n",
      "Iteration 980, Loss: 5.940684786764905e-05, Min w: 0.8701909780502319\n",
      "Iteration 990, Loss: 5.3152270993450657e-05, Min w: 0.889028012752533\n",
      "Iteration 1000, Loss: 4.071836519869976e-05, Min w: 0.9008612036705017\n",
      "Iteration 1010, Loss: 4.1943902033381164e-05, Min w: 0.9001342058181763\n",
      "Iteration 1020, Loss: 4.4289488869253546e-05, Min w: 0.8995262384414673\n",
      "Iteration 1030, Loss: 4.5227316149976104e-05, Min w: 0.8975890278816223\n",
      "Iteration 1040, Loss: 5.4133241064846516e-05, Min w: 0.8874690532684326\n",
      "Iteration 1050, Loss: 3.9229256799444556e-05, Min w: 0.9026245474815369\n",
      "Iteration 1060, Loss: 3.906915299012326e-05, Min w: 0.9070546627044678\n",
      "Iteration 1070, Loss: 4.942175655742176e-05, Min w: 0.8965913653373718\n",
      "Iteration 1080, Loss: 4.857476596953347e-05, Min w: 0.8984566926956177\n",
      "Iteration 1090, Loss: 4.0078444726532325e-05, Min w: 0.9062808752059937\n",
      "Iteration 1100, Loss: 4.335272024036385e-05, Min w: 0.9041101932525635\n",
      "Iteration 1110, Loss: 3.794884469243698e-05, Min w: 0.9086505770683289\n",
      "Iteration 1120, Loss: 4.806606375495903e-05, Min w: 0.8967363238334656\n",
      "Iteration 1130, Loss: 4.259281558915973e-05, Min w: 0.9082977771759033\n",
      "Iteration 1140, Loss: 3.959484456572682e-05, Min w: 0.905101478099823\n",
      "Iteration 1150, Loss: 4.3244250264251605e-05, Min w: 0.9023783802986145\n",
      "Iteration 1160, Loss: 3.88424341508653e-05, Min w: 0.9061947464942932\n",
      "Iteration 1170, Loss: 3.8798283640062436e-05, Min w: 0.90870201587677\n",
      "Iteration 1180, Loss: 4.036544487462379e-05, Min w: 0.9082857966423035\n",
      "Iteration 1190, Loss: 4.065361281391233e-05, Min w: 0.9094774127006531\n",
      "Iteration 1200, Loss: 4.727610939880833e-05, Min w: 0.900779128074646\n",
      "Iteration 1210, Loss: 4.575368438963778e-05, Min w: 0.906091570854187\n",
      "Iteration 1220, Loss: 3.814732554019429e-05, Min w: 0.910791277885437\n",
      "Iteration 1230, Loss: 3.775546792894602e-05, Min w: 0.9109210968017578\n",
      "Iteration 1240, Loss: 3.9805734559195116e-05, Min w: 0.9098182916641235\n",
      "Iteration 0, Loss: 4.04302918468602e-05, Min w: 0.9084029793739319\n",
      "Iteration 10, Loss: 3.6899604310747236e-05, Min w: 0.9113461375236511\n",
      "Iteration 20, Loss: 3.70900597772561e-05, Min w: 0.9113275408744812\n",
      "Iteration 30, Loss: 3.5865436075255275e-05, Min w: 0.9140191674232483\n",
      "Iteration 40, Loss: 6.983977800700814e-05, Min w: 0.8312115669250488\n",
      "Iteration 50, Loss: 4.08782871090807e-05, Min w: 0.9132278561592102\n",
      "Iteration 60, Loss: 3.655240288935602e-05, Min w: 0.9150378704071045\n",
      "Iteration 70, Loss: 3.7377310945885256e-05, Min w: 0.916143536567688\n",
      "Iteration 80, Loss: 3.579189797164872e-05, Min w: 0.914956271648407\n",
      "Iteration 90, Loss: 4.819538298761472e-05, Min w: 0.8957598805427551\n",
      "Iteration 100, Loss: 3.97033327317331e-05, Min w: 0.9124349355697632\n",
      "Iteration 110, Loss: 3.578204268706031e-05, Min w: 0.9169949293136597\n",
      "Iteration 120, Loss: 3.500180901028216e-05, Min w: 0.9192018508911133\n",
      "Iteration 130, Loss: 3.433816891629249e-05, Min w: 0.9181686043739319\n",
      "Iteration 140, Loss: 3.498375735944137e-05, Min w: 0.9146332740783691\n",
      "Iteration 150, Loss: 3.697951979120262e-05, Min w: 0.9157813191413879\n",
      "Iteration 160, Loss: 4.355834244051948e-05, Min w: 0.908486545085907\n",
      "Iteration 170, Loss: 3.57032404281199e-05, Min w: 0.9160113334655762\n",
      "Iteration 180, Loss: 3.683022077893838e-05, Min w: 0.9166761636734009\n",
      "Iteration 190, Loss: 3.410450153751299e-05, Min w: 0.9189891219139099\n",
      "Iteration 200, Loss: 3.524201747495681e-05, Min w: 0.9199673533439636\n",
      "Iteration 210, Loss: 3.4651297028176486e-05, Min w: 0.9180834889411926\n",
      "Iteration 220, Loss: 3.5190449125366285e-05, Min w: 0.9200729727745056\n",
      "Iteration 230, Loss: 4.7412388084921986e-05, Min w: 0.8959938287734985\n",
      "Iteration 240, Loss: 4.669967165682465e-05, Min w: 0.9001089334487915\n",
      "Iteration 250, Loss: 3.491281677270308e-05, Min w: 0.9214468002319336\n",
      "Iteration 260, Loss: 4.038074257550761e-05, Min w: 0.9129579067230225\n",
      "Iteration 270, Loss: 4.427301973919384e-05, Min w: 0.9040547609329224\n",
      "Iteration 280, Loss: 3.610830754041672e-05, Min w: 0.9239777326583862\n",
      "Iteration 290, Loss: 3.242421371396631e-05, Min w: 0.9229450821876526\n",
      "Iteration 300, Loss: 3.438494240981527e-05, Min w: 0.920961856842041\n",
      "Iteration 310, Loss: 3.2778276363387704e-05, Min w: 0.9224785566329956\n",
      "Iteration 320, Loss: 3.706509596668184e-05, Min w: 0.9197375774383545\n",
      "Iteration 330, Loss: 3.211259900126606e-05, Min w: 0.9234257340431213\n",
      "Iteration 340, Loss: 3.5276385460747406e-05, Min w: 0.9214382767677307\n",
      "Iteration 350, Loss: 3.231912342016585e-05, Min w: 0.9271790385246277\n",
      "Iteration 360, Loss: 3.3212174457730725e-05, Min w: 0.9236155152320862\n",
      "Iteration 370, Loss: 3.932759864255786e-05, Min w: 0.9172587990760803\n",
      "Iteration 380, Loss: 3.4731820051092654e-05, Min w: 0.9241188764572144\n",
      "Iteration 390, Loss: 3.345133154653013e-05, Min w: 0.9270063638687134\n",
      "Iteration 400, Loss: 3.1076586310518906e-05, Min w: 0.9274535775184631\n",
      "Iteration 410, Loss: 3.51350026903674e-05, Min w: 0.9224854111671448\n",
      "Iteration 420, Loss: 3.278867734479718e-05, Min w: 0.926440417766571\n",
      "Iteration 430, Loss: 3.023345925612375e-05, Min w: 0.9281032085418701\n",
      "Iteration 440, Loss: 3.152267527184449e-05, Min w: 0.929574191570282\n",
      "Iteration 450, Loss: 3.325985016999766e-05, Min w: 0.9251305460929871\n",
      "Iteration 460, Loss: 3.151717100990936e-05, Min w: 0.9277640581130981\n",
      "Iteration 470, Loss: 3.3776930649764836e-05, Min w: 0.9273666739463806\n",
      "Iteration 480, Loss: 4.0203023672802374e-05, Min w: 0.9125540256500244\n",
      "Iteration 490, Loss: 3.732860568561591e-05, Min w: 0.9236586689949036\n",
      "Iteration 500, Loss: 3.594764712033793e-05, Min w: 0.9258204698562622\n",
      "Iteration 510, Loss: 5.2439398132264614e-05, Min w: 0.8750938773155212\n",
      "Iteration 520, Loss: 3.301819378975779e-05, Min w: 0.9311801791191101\n",
      "Iteration 530, Loss: 3.192595249856822e-05, Min w: 0.9298298358917236\n",
      "Iteration 540, Loss: 3.117437881883234e-05, Min w: 0.9295693635940552\n",
      "Iteration 550, Loss: 3.2216783438343555e-05, Min w: 0.9274733662605286\n",
      "Iteration 560, Loss: 3.149401891278103e-05, Min w: 0.9312713742256165\n",
      "Iteration 570, Loss: 3.075210770475678e-05, Min w: 0.9311731457710266\n",
      "Iteration 580, Loss: 3.337065572850406e-05, Min w: 0.9304559230804443\n",
      "Iteration 590, Loss: 3.971647674916312e-05, Min w: 0.9143592119216919\n",
      "Iteration 600, Loss: 4.266342511982657e-05, Min w: 0.904502272605896\n",
      "Iteration 610, Loss: 3.7581572541967034e-05, Min w: 0.9203296899795532\n",
      "Iteration 620, Loss: 2.8606031264644116e-05, Min w: 0.9332459568977356\n",
      "Iteration 630, Loss: 3.152332647005096e-05, Min w: 0.9315868616104126\n",
      "Iteration 640, Loss: 3.072109757340513e-05, Min w: 0.9321152567863464\n",
      "Iteration 650, Loss: 3.158589606755413e-05, Min w: 0.9320011734962463\n",
      "Iteration 660, Loss: 2.9771117624477483e-05, Min w: 0.9324443340301514\n",
      "Iteration 670, Loss: 2.8636446586460806e-05, Min w: 0.9349376559257507\n",
      "Iteration 680, Loss: 2.819805740728043e-05, Min w: 0.9345963597297668\n",
      "Iteration 690, Loss: 2.8278829631744884e-05, Min w: 0.93236243724823\n",
      "Iteration 700, Loss: 2.8616392228286713e-05, Min w: 0.9359108805656433\n",
      "Iteration 710, Loss: 2.9094144338159822e-05, Min w: 0.9339998364448547\n",
      "Iteration 720, Loss: 2.7834361389977857e-05, Min w: 0.9367054104804993\n",
      "Iteration 730, Loss: 2.726636921579484e-05, Min w: 0.9367337226867676\n",
      "Iteration 740, Loss: 3.24019456456881e-05, Min w: 0.9328070282936096\n",
      "Iteration 750, Loss: 3.874400135828182e-05, Min w: 0.9138721823692322\n",
      "Iteration 760, Loss: 2.6949150196742266e-05, Min w: 0.9368776679039001\n",
      "Iteration 770, Loss: 2.7612681151367724e-05, Min w: 0.9364631175994873\n",
      "Iteration 780, Loss: 2.671691618161276e-05, Min w: 0.9381797313690186\n",
      "Iteration 790, Loss: 3.724085399881005e-05, Min w: 0.9158113598823547\n",
      "Iteration 800, Loss: 3.850796929327771e-05, Min w: 0.9150048494338989\n",
      "Iteration 810, Loss: 4.617371814674698e-05, Min w: 0.8888188600540161\n",
      "Iteration 820, Loss: 2.8568587367772125e-05, Min w: 0.9380685687065125\n",
      "Iteration 830, Loss: 2.6800484192790464e-05, Min w: 0.9373922348022461\n",
      "Iteration 840, Loss: 2.8361682780086994e-05, Min w: 0.9362125396728516\n",
      "Iteration 850, Loss: 2.8017615477438085e-05, Min w: 0.9386491775512695\n",
      "Iteration 860, Loss: 2.667585613380652e-05, Min w: 0.9383101463317871\n",
      "Iteration 870, Loss: 2.625039269332774e-05, Min w: 0.9388044476509094\n",
      "Iteration 880, Loss: 2.7153118935530074e-05, Min w: 0.9389178156852722\n",
      "Iteration 890, Loss: 2.5646544600022025e-05, Min w: 0.9413356184959412\n",
      "Iteration 900, Loss: 4.103370520169847e-05, Min w: 0.909101665019989\n",
      "Iteration 910, Loss: 2.621236490085721e-05, Min w: 0.9395847916603088\n",
      "Iteration 920, Loss: 2.579515967227053e-05, Min w: 0.9413047432899475\n",
      "Iteration 930, Loss: 4.089399953954853e-05, Min w: 0.9051396250724792\n",
      "Iteration 940, Loss: 3.3988697396125644e-05, Min w: 0.9293932914733887\n",
      "Iteration 950, Loss: 3.325615398352966e-05, Min w: 0.9259570837020874\n",
      "Iteration 960, Loss: 3.1346833566203713e-05, Min w: 0.9355844855308533\n",
      "Iteration 970, Loss: 2.7285790565656498e-05, Min w: 0.9407694935798645\n",
      "Iteration 980, Loss: 2.8485252187238075e-05, Min w: 0.9407727122306824\n",
      "Iteration 990, Loss: 2.6049472580780275e-05, Min w: 0.941657304763794\n",
      "Iteration 1000, Loss: 2.6012132366304286e-05, Min w: 0.9418027400970459\n",
      "Iteration 1010, Loss: 2.5188268409692682e-05, Min w: 0.9420642256736755\n",
      "Iteration 1020, Loss: 2.716725975915324e-05, Min w: 0.9414927959442139\n",
      "Iteration 1030, Loss: 4.319916115491651e-05, Min w: 0.8960990309715271\n",
      "Iteration 1040, Loss: 4.566819916362874e-05, Min w: 0.8854014873504639\n",
      "Iteration 1050, Loss: 2.7835334549308755e-05, Min w: 0.9429872632026672\n",
      "Iteration 1060, Loss: 2.5072928110603243e-05, Min w: 0.9435805678367615\n",
      "Iteration 1070, Loss: 2.6080930183525197e-05, Min w: 0.9419670104980469\n",
      "Iteration 1080, Loss: 2.7089012291980907e-05, Min w: 0.9418138265609741\n",
      "Iteration 1090, Loss: 2.6138875909964554e-05, Min w: 0.9452604651451111\n",
      "Iteration 1100, Loss: 2.545325151004363e-05, Min w: 0.9437834024429321\n",
      "Iteration 1110, Loss: 2.516916356398724e-05, Min w: 0.9449523687362671\n",
      "Iteration 1120, Loss: 2.803760980896186e-05, Min w: 0.9409933686256409\n",
      "Iteration 1130, Loss: 2.764839882729575e-05, Min w: 0.9432303309440613\n",
      "Iteration 1140, Loss: 2.539204797358252e-05, Min w: 0.9433901309967041\n",
      "Iteration 1150, Loss: 2.558029882493429e-05, Min w: 0.947124719619751\n",
      "Iteration 1160, Loss: 2.6182424335274845e-05, Min w: 0.9443167448043823\n",
      "Iteration 1170, Loss: 2.3378357582259923e-05, Min w: 0.9477307796478271\n",
      "Iteration 1180, Loss: 2.8191145247546956e-05, Min w: 0.9415088295936584\n",
      "Iteration 1190, Loss: 2.5987243134295568e-05, Min w: 0.9451946020126343\n",
      "Iteration 1200, Loss: 2.6648465791367926e-05, Min w: 0.9423384666442871\n",
      "Iteration 1210, Loss: 2.7081494408776052e-05, Min w: 0.9437674283981323\n",
      "Iteration 1220, Loss: 4.2631072574295104e-05, Min w: 0.8917855024337769\n",
      "Iteration 1230, Loss: 4.241288479533978e-05, Min w: 0.8961086869239807\n",
      "Iteration 1240, Loss: 2.6286790671292692e-05, Min w: 0.9460651278495789\n",
      "Iteration 0, Loss: 3.0843293643556535e-05, Min w: 0.9292483329772949\n",
      "Iteration 10, Loss: 2.315231722604949e-05, Min w: 0.9478963017463684\n",
      "Iteration 20, Loss: 2.6990746846422553e-05, Min w: 0.9420051574707031\n",
      "Iteration 30, Loss: 2.4030885469983332e-05, Min w: 0.9474505186080933\n",
      "Iteration 40, Loss: 2.3478854927816428e-05, Min w: 0.9477646350860596\n",
      "Iteration 50, Loss: 2.2546129912370816e-05, Min w: 0.9500423073768616\n",
      "Iteration 60, Loss: 2.660130303411279e-05, Min w: 0.944331705570221\n",
      "Iteration 70, Loss: 2.3436612536897883e-05, Min w: 0.949918270111084\n",
      "Iteration 80, Loss: 2.3009795768302865e-05, Min w: 0.9461627006530762\n",
      "Iteration 90, Loss: 2.269105243613012e-05, Min w: 0.9500681161880493\n",
      "Iteration 100, Loss: 2.4097405912471004e-05, Min w: 0.9480232000350952\n",
      "Iteration 110, Loss: 2.380500518484041e-05, Min w: 0.9487922191619873\n",
      "Iteration 120, Loss: 4.5277476601768285e-05, Min w: 0.88325035572052\n",
      "Iteration 130, Loss: 2.595288424345199e-05, Min w: 0.9451579451560974\n",
      "Iteration 140, Loss: 3.326167643535882e-05, Min w: 0.9236634373664856\n",
      "Iteration 150, Loss: 2.363882595091127e-05, Min w: 0.948625922203064\n",
      "Iteration 160, Loss: 2.1693924281862564e-05, Min w: 0.9512556791305542\n",
      "Iteration 170, Loss: 2.7207135644857772e-05, Min w: 0.9431708455085754\n",
      "Iteration 180, Loss: 2.356831646466162e-05, Min w: 0.9480897784233093\n",
      "Iteration 190, Loss: 2.43516424234258e-05, Min w: 0.9480615854263306\n",
      "Iteration 200, Loss: 2.2375237676897086e-05, Min w: 0.9513252377510071\n",
      "Iteration 210, Loss: 2.4469187337672338e-05, Min w: 0.947145402431488\n",
      "Iteration 220, Loss: 2.3357162717729807e-05, Min w: 0.9503892064094543\n",
      "Iteration 230, Loss: 2.3681448510615155e-05, Min w: 0.9472842216491699\n",
      "Iteration 240, Loss: 2.142607991117984e-05, Min w: 0.9532093405723572\n",
      "Iteration 250, Loss: 2.1713347450713627e-05, Min w: 0.952083170413971\n",
      "Iteration 260, Loss: 2.7148538720211945e-05, Min w: 0.9437280893325806\n",
      "Iteration 270, Loss: 2.900963409047108e-05, Min w: 0.9329314827919006\n",
      "Iteration 280, Loss: 2.6965815777657554e-05, Min w: 0.9384627938270569\n",
      "Iteration 290, Loss: 2.219276393589098e-05, Min w: 0.9515289664268494\n",
      "Iteration 300, Loss: 2.5527459001750685e-05, Min w: 0.9458396434783936\n",
      "Iteration 310, Loss: 2.1825218937010504e-05, Min w: 0.9517413377761841\n",
      "Iteration 320, Loss: 2.174296423618216e-05, Min w: 0.9520251154899597\n",
      "Iteration 330, Loss: 2.492453313607257e-05, Min w: 0.9469771385192871\n",
      "Iteration 340, Loss: 2.115671850333456e-05, Min w: 0.9534083008766174\n",
      "Iteration 350, Loss: 2.08635647140909e-05, Min w: 0.9531969428062439\n",
      "Iteration 360, Loss: 2.309424598934129e-05, Min w: 0.9527418613433838\n",
      "Iteration 370, Loss: 2.492820203769952e-05, Min w: 0.9473358392715454\n",
      "Iteration 380, Loss: 2.4884229787858203e-05, Min w: 0.9457735419273376\n",
      "Iteration 390, Loss: 2.1248517441563308e-05, Min w: 0.9527647495269775\n",
      "Iteration 400, Loss: 2.240256071672775e-05, Min w: 0.9534124732017517\n",
      "Iteration 410, Loss: 2.0922925614286214e-05, Min w: 0.9551944732666016\n",
      "Iteration 420, Loss: 2.6273150069755502e-05, Min w: 0.9419443607330322\n",
      "Iteration 430, Loss: 2.4976498025353067e-05, Min w: 0.9472060203552246\n",
      "Iteration 440, Loss: 2.3784024961059913e-05, Min w: 0.9504324793815613\n",
      "Iteration 450, Loss: 2.0761990526807494e-05, Min w: 0.9531556963920593\n",
      "Iteration 460, Loss: 2.8527216272777878e-05, Min w: 0.9337304830551147\n",
      "Iteration 470, Loss: 2.371716618654318e-05, Min w: 0.9500751495361328\n",
      "Iteration 480, Loss: 2.5519388145767152e-05, Min w: 0.9451196789741516\n",
      "Iteration 490, Loss: 2.0857687559328042e-05, Min w: 0.9546521902084351\n",
      "Iteration 500, Loss: 2.8449341698433273e-05, Min w: 0.9338958859443665\n",
      "Iteration 510, Loss: 3.4943921491503716e-05, Min w: 0.9116589426994324\n",
      "Iteration 520, Loss: 2.396526724623982e-05, Min w: 0.9494420289993286\n",
      "Iteration 530, Loss: 2.1928432033746503e-05, Min w: 0.9550708532333374\n",
      "Iteration 540, Loss: 2.9534361601690762e-05, Min w: 0.9297828674316406\n",
      "Iteration 550, Loss: 1.9599099687184207e-05, Min w: 0.9570733904838562\n",
      "Iteration 560, Loss: 2.0021603631903417e-05, Min w: 0.9566459059715271\n",
      "Iteration 570, Loss: 2.0610945284715854e-05, Min w: 0.9556127190589905\n",
      "Iteration 580, Loss: 2.0007937564514577e-05, Min w: 0.9549698829650879\n",
      "Iteration 590, Loss: 3.150777047267184e-05, Min w: 0.9241735935211182\n",
      "Iteration 600, Loss: 3.986836600233801e-05, Min w: 0.8955544233322144\n",
      "Iteration 610, Loss: 3.1710042094346136e-05, Min w: 0.9218515157699585\n",
      "Iteration 620, Loss: 2.177380520151928e-05, Min w: 0.9535245299339294\n",
      "Iteration 630, Loss: 2.036300065810792e-05, Min w: 0.9559046626091003\n",
      "Iteration 640, Loss: 2.8542133804876357e-05, Min w: 0.9305397272109985\n",
      "Iteration 650, Loss: 1.9910226910724305e-05, Min w: 0.9583864212036133\n",
      "Iteration 660, Loss: 2.232926999568008e-05, Min w: 0.9534339904785156\n",
      "Iteration 670, Loss: 2.3110940674087033e-05, Min w: 0.951219379901886\n",
      "Iteration 680, Loss: 2.0469289665925317e-05, Min w: 0.9579877853393555\n",
      "Iteration 690, Loss: 2.407223655609414e-05, Min w: 0.9476462006568909\n",
      "Iteration 700, Loss: 2.2295278540696017e-05, Min w: 0.9525682330131531\n",
      "Iteration 710, Loss: 2.124920138157904e-05, Min w: 0.9557084441184998\n",
      "Iteration 720, Loss: 2.057247911579907e-05, Min w: 0.9573177695274353\n",
      "Iteration 730, Loss: 1.8702809029491618e-05, Min w: 0.9586576819419861\n",
      "Iteration 740, Loss: 2.3754857465974055e-05, Min w: 0.9494457840919495\n",
      "Iteration 750, Loss: 1.896838512038812e-05, Min w: 0.9589685797691345\n",
      "Iteration 760, Loss: 2.2611628082813695e-05, Min w: 0.9523130655288696\n",
      "Iteration 770, Loss: 3.044778532057535e-05, Min w: 0.922471284866333\n",
      "Iteration 780, Loss: 2.030937685049139e-05, Min w: 0.9576647281646729\n",
      "Iteration 790, Loss: 3.0128292564768344e-05, Min w: 0.9230051636695862\n",
      "Iteration 800, Loss: 2.2881025870447047e-05, Min w: 0.9504382610321045\n",
      "Iteration 810, Loss: 1.9813460312434472e-05, Min w: 0.9587212800979614\n",
      "Iteration 820, Loss: 1.90469127119286e-05, Min w: 0.9604097008705139\n",
      "Iteration 830, Loss: 2.0294421119615436e-05, Min w: 0.9579677581787109\n",
      "Iteration 840, Loss: 2.277225212310441e-05, Min w: 0.9504176378250122\n",
      "Iteration 850, Loss: 1.9316943507874385e-05, Min w: 0.9593993425369263\n",
      "Iteration 860, Loss: 2.135523573087994e-05, Min w: 0.9561951756477356\n",
      "Iteration 870, Loss: 2.6086083380505443e-05, Min w: 0.9390242099761963\n",
      "Iteration 880, Loss: 2.2068483303883113e-05, Min w: 0.9544187188148499\n",
      "Iteration 890, Loss: 2.583541026979219e-05, Min w: 0.9412338137626648\n",
      "Iteration 900, Loss: 2.1201291019679047e-05, Min w: 0.955584704875946\n",
      "Iteration 910, Loss: 2.6220977815683e-05, Min w: 0.9360842108726501\n",
      "Iteration 920, Loss: 2.405312261544168e-05, Min w: 0.9458968639373779\n",
      "Iteration 930, Loss: 3.0257480830186978e-05, Min w: 0.9218115210533142\n",
      "Iteration 940, Loss: 1.7727483282214962e-05, Min w: 0.9619227051734924\n",
      "Iteration 950, Loss: 1.7730813851812854e-05, Min w: 0.9614633321762085\n",
      "Iteration 960, Loss: 2.0779600163223222e-05, Min w: 0.9537719488143921\n",
      "Iteration 970, Loss: 1.7774991647456773e-05, Min w: 0.9614377021789551\n",
      "Iteration 980, Loss: 1.7685528291622177e-05, Min w: 0.9621755480766296\n",
      "Iteration 990, Loss: 1.821245314204134e-05, Min w: 0.9616053104400635\n",
      "Iteration 1000, Loss: 2.1377079974627122e-05, Min w: 0.9529693722724915\n",
      "Iteration 1010, Loss: 2.392152055108454e-05, Min w: 0.9443861842155457\n",
      "Iteration 1020, Loss: 1.8280790754943155e-05, Min w: 0.9620200395584106\n",
      "Iteration 1030, Loss: 2.0968042008462362e-05, Min w: 0.9570388197898865\n",
      "Iteration 1040, Loss: 2.8408227080944926e-05, Min w: 0.9250314235687256\n",
      "Iteration 1050, Loss: 1.7699194359011017e-05, Min w: 0.9631360173225403\n",
      "Iteration 1060, Loss: 2.0186571418889798e-05, Min w: 0.9582230448722839\n",
      "Iteration 1070, Loss: 1.761934436217416e-05, Min w: 0.9627990126609802\n",
      "Iteration 1080, Loss: 1.8224069208372384e-05, Min w: 0.9617937207221985\n",
      "Iteration 1090, Loss: 2.5081701096496545e-05, Min w: 0.9413578510284424\n",
      "Iteration 1100, Loss: 1.836370756791439e-05, Min w: 0.9622208476066589\n",
      "Iteration 1110, Loss: 2.128458072547801e-05, Min w: 0.952282190322876\n",
      "Iteration 1120, Loss: 3.0501538276439533e-05, Min w: 0.9192460179328918\n",
      "Iteration 1130, Loss: 1.8407818060950376e-05, Min w: 0.9608618021011353\n",
      "Iteration 1140, Loss: 1.755172161210794e-05, Min w: 0.963661253452301\n",
      "Iteration 1150, Loss: 2.366703665757086e-05, Min w: 0.945953905582428\n",
      "Iteration 1160, Loss: 1.728591632854659e-05, Min w: 0.9629765152931213\n",
      "Iteration 1170, Loss: 1.7047579603968188e-05, Min w: 0.9638736248016357\n",
      "Iteration 1180, Loss: 2.1754982299171388e-05, Min w: 0.9479448199272156\n",
      "Iteration 1190, Loss: 3.054341868846677e-05, Min w: 0.9231463670730591\n",
      "Iteration 1200, Loss: 2.1037709302618168e-05, Min w: 0.9518744945526123\n",
      "Iteration 1210, Loss: 2.5076720703509636e-05, Min w: 0.9400920867919922\n",
      "Iteration 1220, Loss: 1.791468821465969e-05, Min w: 0.9630345702171326\n",
      "Iteration 1230, Loss: 1.8849754269467667e-05, Min w: 0.960703432559967\n",
      "Iteration 1240, Loss: 1.794893978512846e-05, Min w: 0.9622796773910522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  67%|██████▋   | 16/24 [25:54<13:59, 104.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.01375296165756025, 'L2_avg': 0.019622610917231678, 'End_point_L1_avg': 0.008302940572035698, 'End_point_L2_avg': 0.008304682355149211}\n",
      "Iteration 0, Loss: 0.0055044409818947315, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00300575140863657, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002309794770553708, Min w: 2.212650275168886e-42\n",
      "Iteration 30, Loss: 0.002267254050821066, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0023092220071703196, Min w: 1.4995168749878078e-39\n",
      "Iteration 50, Loss: 0.0023474248591810465, Min w: 0.002229335019364953\n",
      "Iteration 60, Loss: 0.0025265440344810486, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0021364924032241106, Min w: 7.719811660582276e-13\n",
      "Iteration 80, Loss: 0.002036489313468337, Min w: 5.231727300269995e-07\n",
      "Iteration 90, Loss: 0.0018929338548332453, Min w: 3.73570667672532e-13\n",
      "Iteration 100, Loss: 0.0020832782611250877, Min w: 3.572320096014384e-17\n",
      "Iteration 110, Loss: 0.0020902245305478573, Min w: 6.375476004905067e-06\n",
      "Iteration 120, Loss: 0.0020337654277682304, Min w: 3.9394726627506316e-06\n",
      "Iteration 130, Loss: 0.0022669630125164986, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002066347049549222, Min w: 5.992723161715101e-16\n",
      "Iteration 150, Loss: 0.0017662387108430266, Min w: 2.045384747704283e-26\n",
      "Iteration 160, Loss: 0.0020328438840806484, Min w: 4.826837943035753e-31\n",
      "Iteration 170, Loss: 0.002053178148344159, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0020089594181627035, Min w: 3.663487223093398e-05\n",
      "Iteration 190, Loss: 0.0015922143356874585, Min w: 0.000756211404222995\n",
      "Iteration 200, Loss: 0.0020220065489411354, Min w: 1.5509875659311593e-31\n",
      "Iteration 210, Loss: 0.002086930675432086, Min w: 1.290420000672407e-13\n",
      "Iteration 220, Loss: 0.0021563733462244272, Min w: 3.7443165972275705e-13\n",
      "Iteration 230, Loss: 0.00213632476516068, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002256913110613823, Min w: 1.3872854796815689e-43\n",
      "Iteration 250, Loss: 0.00207627029158175, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0020221380982548, Min w: 1.3124148035698058e-13\n",
      "Iteration 270, Loss: 0.002067124005407095, Min w: 9.687829011228999e-11\n",
      "Iteration 280, Loss: 0.001505643711425364, Min w: 4.408734093885869e-05\n",
      "Iteration 290, Loss: 0.001762837520800531, Min w: 0.10915469378232956\n",
      "Iteration 300, Loss: 0.002012411365285516, Min w: 1.0910590350179996e-26\n",
      "Iteration 310, Loss: 0.002109920373186469, Min w: 4.5829115804943605e-31\n",
      "Iteration 320, Loss: 0.002084610052406788, Min w: 2.4867620595614426e-05\n",
      "Iteration 330, Loss: 0.0019554144237190485, Min w: 1.671789141255431e-05\n",
      "Iteration 340, Loss: 0.0018801215337589383, Min w: 0.031052833423018456\n",
      "Iteration 350, Loss: 0.001966668525710702, Min w: 2.563698142665771e-10\n",
      "Iteration 360, Loss: 0.001767072593793273, Min w: 0.07374439388513565\n",
      "Iteration 370, Loss: 0.0012518566800281405, Min w: 0.29576388001441956\n",
      "Iteration 380, Loss: 0.0012357659870758653, Min w: 0.29277920722961426\n",
      "Iteration 390, Loss: 0.0020039703231304884, Min w: 6.2248513010843e-09\n",
      "Iteration 400, Loss: 0.0019940966740250587, Min w: 0.00029655167600139976\n",
      "Iteration 410, Loss: 0.001972678815945983, Min w: 6.680129164231373e-19\n",
      "Iteration 420, Loss: 0.0021406663581728935, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0019725761376321316, Min w: 7.53261630848101e-09\n",
      "Iteration 440, Loss: 0.0018727434799075127, Min w: 4.307046472945553e-12\n",
      "Iteration 450, Loss: 0.0018693039892241359, Min w: 1.6681334500390221e-06\n",
      "Iteration 460, Loss: 0.0020090106409043074, Min w: 3.2590845452652183e-22\n",
      "Iteration 470, Loss: 0.002053439151495695, Min w: 0.0\n",
      "Iteration 480, Loss: 0.002104073530063033, Min w: 1.2403891140032744e-27\n",
      "Iteration 490, Loss: 0.0020895437337458134, Min w: 4.710456664724916e-07\n",
      "Iteration 500, Loss: 0.002125023165717721, Min w: 3.702730837055763e-15\n",
      "Iteration 510, Loss: 0.001847900333814323, Min w: 1.3149322532516813e-14\n",
      "Iteration 520, Loss: 0.0019882055930793285, Min w: 6.32062888559679e-15\n",
      "Iteration 530, Loss: 0.001990028191357851, Min w: 4.804267518920824e-06\n",
      "Iteration 540, Loss: 0.00200660084374249, Min w: 7.546212960063414e-11\n",
      "Iteration 550, Loss: 0.0020047060679644346, Min w: 1.6907948747757473e-06\n",
      "Iteration 560, Loss: 0.0020745161455124617, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002060176804661751, Min w: 1.554337265353771e-27\n",
      "Iteration 580, Loss: 0.0020505778957158327, Min w: 8.26732218683901e-07\n",
      "Iteration 590, Loss: 0.002037503058090806, Min w: 6.5966495422948e-31\n",
      "Iteration 600, Loss: 0.001958012580871582, Min w: 1.4785058510824456e-06\n",
      "Iteration 610, Loss: 0.0019001316977664828, Min w: 0.0001344068004982546\n",
      "Iteration 620, Loss: 0.0016324378084391356, Min w: 0.0613003745675087\n",
      "Iteration 630, Loss: 0.0019329868955537677, Min w: 0.010777476243674755\n",
      "Iteration 640, Loss: 0.0019243216374889016, Min w: 0.000512118567712605\n",
      "Iteration 650, Loss: 0.0019937255419790745, Min w: 2.0447316273930483e-05\n",
      "Iteration 660, Loss: 0.0019936878234148026, Min w: 4.398793316795491e-05\n",
      "Iteration 670, Loss: 0.001906990073621273, Min w: 0.012443586252629757\n",
      "Iteration 680, Loss: 0.0019653679337352514, Min w: 0.001172129763290286\n",
      "Iteration 690, Loss: 0.0014758979668840766, Min w: 0.08168468624353409\n",
      "Iteration 700, Loss: 0.0011807202827185392, Min w: 0.2512279748916626\n",
      "Iteration 710, Loss: 0.0008760105120018125, Min w: 0.3467404246330261\n",
      "Iteration 720, Loss: 0.0009581486810930073, Min w: 0.3032360374927521\n",
      "Iteration 730, Loss: 0.0009779584361240268, Min w: 0.3605458438396454\n",
      "Iteration 740, Loss: 0.001065336400642991, Min w: 0.4657966196537018\n",
      "Iteration 750, Loss: 0.0007706147152930498, Min w: 0.48777711391448975\n",
      "Iteration 760, Loss: 0.0007238128455355763, Min w: 0.49081867933273315\n",
      "Iteration 770, Loss: 0.0007248919573612511, Min w: 0.478485643863678\n",
      "Iteration 780, Loss: 0.0011038726661354303, Min w: 0.43178313970565796\n",
      "Iteration 790, Loss: 0.0006805704906582832, Min w: 0.553631603717804\n",
      "Iteration 800, Loss: 0.0009855534881353378, Min w: 0.4650399088859558\n",
      "Iteration 810, Loss: 0.0010779526783153415, Min w: 0.44602662324905396\n",
      "Iteration 820, Loss: 0.0007544790860265493, Min w: 0.5405961275100708\n",
      "Iteration 830, Loss: 0.0008088380564004183, Min w: 0.532482922077179\n",
      "Iteration 840, Loss: 0.0007105536060407758, Min w: 0.5679530501365662\n",
      "Iteration 850, Loss: 0.0006919191800989211, Min w: 0.5970045328140259\n",
      "Iteration 860, Loss: 0.0006985538057051599, Min w: 0.5797857046127319\n",
      "Iteration 870, Loss: 0.000597660371568054, Min w: 0.6115490198135376\n",
      "Iteration 880, Loss: 0.0009874632814899087, Min w: 0.4376574158668518\n",
      "Iteration 890, Loss: 0.0008461803081445396, Min w: 0.5735358595848083\n",
      "Iteration 900, Loss: 0.0007099452195689082, Min w: 0.6217081546783447\n",
      "Iteration 910, Loss: 0.0005433264886960387, Min w: 0.6305738687515259\n",
      "Iteration 920, Loss: 0.0006651596049778163, Min w: 0.6300532221794128\n",
      "Iteration 930, Loss: 0.0006297043873928487, Min w: 0.6287391781806946\n",
      "Iteration 940, Loss: 0.0004885159432888031, Min w: 0.6690223813056946\n",
      "Iteration 950, Loss: 0.0008225281490013003, Min w: 0.5589061379432678\n",
      "Iteration 960, Loss: 0.0005107559263706207, Min w: 0.6525370478630066\n",
      "Iteration 970, Loss: 0.0006977730663493276, Min w: 0.6259876489639282\n",
      "Iteration 980, Loss: 0.0007561477832496166, Min w: 0.5910018086433411\n",
      "Iteration 990, Loss: 0.0007662875577807426, Min w: 0.6099183559417725\n",
      "Iteration 1000, Loss: 0.00043603836093097925, Min w: 0.7043752670288086\n",
      "Iteration 1010, Loss: 0.0006949829403311014, Min w: 0.622226893901825\n",
      "Iteration 1020, Loss: 0.0006513325497508049, Min w: 0.6605241298675537\n",
      "Iteration 1030, Loss: 0.0007257901015691459, Min w: 0.629227876663208\n",
      "Iteration 1040, Loss: 0.0005147082265466452, Min w: 0.7080820798873901\n",
      "Iteration 1050, Loss: 0.0004127288702875376, Min w: 0.735511064529419\n",
      "Iteration 1060, Loss: 0.0005227942019701004, Min w: 0.7142823338508606\n",
      "Iteration 1070, Loss: 0.0007035572198219597, Min w: 0.6047361493110657\n",
      "Iteration 1080, Loss: 0.0005791047005914152, Min w: 0.701757550239563\n",
      "Iteration 1090, Loss: 0.00048754856106825173, Min w: 0.7213025689125061\n",
      "Iteration 1100, Loss: 0.0004875634331256151, Min w: 0.7392141819000244\n",
      "Iteration 1110, Loss: 0.0003727745497599244, Min w: 0.7439391016960144\n",
      "Iteration 1120, Loss: 0.0007973899482749403, Min w: 0.527433454990387\n",
      "Iteration 1130, Loss: 0.00036743911914527416, Min w: 0.7959511280059814\n",
      "Iteration 1140, Loss: 0.0005885054124519229, Min w: 0.6711083054542542\n",
      "Iteration 1150, Loss: 0.0005984109593555331, Min w: 0.6674895882606506\n",
      "Iteration 1160, Loss: 0.0007598269148729742, Min w: 0.5322355628013611\n",
      "Iteration 1170, Loss: 0.00045347987907007337, Min w: 0.7606823444366455\n",
      "Iteration 1180, Loss: 0.0003378498659003526, Min w: 0.787004292011261\n",
      "Iteration 1190, Loss: 0.0004886020324192941, Min w: 0.7085970640182495\n",
      "Iteration 1200, Loss: 0.0006065988563932478, Min w: 0.6309049725532532\n",
      "Iteration 1210, Loss: 0.0006643355591222644, Min w: 0.5674180388450623\n",
      "Iteration 1220, Loss: 0.00045196464634500444, Min w: 0.7630853056907654\n",
      "Iteration 1230, Loss: 0.0004646576417144388, Min w: 0.753851592540741\n",
      "Iteration 1240, Loss: 0.0003289711894467473, Min w: 0.8300525546073914\n",
      "Iteration 0, Loss: 0.0004517050401773304, Min w: 0.7428165078163147\n",
      "Iteration 10, Loss: 0.0002972106740344316, Min w: 0.8252090811729431\n",
      "Iteration 20, Loss: 0.0006741523393429816, Min w: 0.6217383742332458\n",
      "Iteration 30, Loss: 0.00042666259105317295, Min w: 0.7704994082450867\n",
      "Iteration 40, Loss: 0.000293376506306231, Min w: 0.8390255570411682\n",
      "Iteration 50, Loss: 0.0005043463897891343, Min w: 0.7374629974365234\n",
      "Iteration 60, Loss: 0.000569110328797251, Min w: 0.6256062984466553\n",
      "Iteration 70, Loss: 0.0003235494077671319, Min w: 0.8347828388214111\n",
      "Iteration 80, Loss: 0.0004801909963134676, Min w: 0.7256186008453369\n",
      "Iteration 90, Loss: 0.00040979546611197293, Min w: 0.7665982246398926\n",
      "Iteration 100, Loss: 0.0004574318591039628, Min w: 0.7212226390838623\n",
      "Iteration 110, Loss: 0.0004880049673374742, Min w: 0.672624409198761\n",
      "Iteration 120, Loss: 0.0004232368082739413, Min w: 0.7728420495986938\n",
      "Iteration 130, Loss: 0.000335509714204818, Min w: 0.8260865211486816\n",
      "Iteration 140, Loss: 0.0004556231724563986, Min w: 0.7301886677742004\n",
      "Iteration 150, Loss: 0.0003699181543197483, Min w: 0.791765570640564\n",
      "Iteration 160, Loss: 0.00025060854386538267, Min w: 0.8624911308288574\n",
      "Iteration 170, Loss: 0.0002636370772961527, Min w: 0.8461507558822632\n",
      "Iteration 180, Loss: 0.00030038616387173533, Min w: 0.845982015132904\n",
      "Iteration 190, Loss: 0.0004545010451693088, Min w: 0.7115570306777954\n",
      "Iteration 200, Loss: 0.0002545058086980134, Min w: 0.8611961007118225\n",
      "Iteration 210, Loss: 0.0002761177602224052, Min w: 0.8452288508415222\n",
      "Iteration 220, Loss: 0.00037026419886387885, Min w: 0.7921526432037354\n",
      "Iteration 230, Loss: 0.00041907306876964867, Min w: 0.7640626430511475\n",
      "Iteration 240, Loss: 0.000464541808469221, Min w: 0.7345201373100281\n",
      "Iteration 250, Loss: 0.00038828319520689547, Min w: 0.798592746257782\n",
      "Iteration 260, Loss: 0.00036506203468889, Min w: 0.782231867313385\n",
      "Iteration 270, Loss: 0.0002310145937371999, Min w: 0.8709694147109985\n",
      "Iteration 280, Loss: 0.0004553152830339968, Min w: 0.7071686387062073\n",
      "Iteration 290, Loss: 0.00028475371073000133, Min w: 0.8325556516647339\n",
      "Iteration 300, Loss: 0.00019097983022220433, Min w: 0.8824238181114197\n",
      "Iteration 310, Loss: 0.0004319309373386204, Min w: 0.7551236748695374\n",
      "Iteration 320, Loss: 0.0002326172252651304, Min w: 0.8782925605773926\n",
      "Iteration 330, Loss: 0.00030062737641856074, Min w: 0.822693943977356\n",
      "Iteration 340, Loss: 0.0003098510787822306, Min w: 0.8219931721687317\n",
      "Iteration 350, Loss: 0.00020052013860549778, Min w: 0.8940331935882568\n",
      "Iteration 360, Loss: 0.0002364368410781026, Min w: 0.8787502646446228\n",
      "Iteration 370, Loss: 0.00021296153136063367, Min w: 0.8766562938690186\n",
      "Iteration 380, Loss: 0.00020870128355454654, Min w: 0.8796834945678711\n",
      "Iteration 390, Loss: 0.0003102582704741508, Min w: 0.817288875579834\n",
      "Iteration 400, Loss: 0.0002790685975924134, Min w: 0.8408496379852295\n",
      "Iteration 410, Loss: 0.0002204711636295542, Min w: 0.8802399635314941\n",
      "Iteration 420, Loss: 0.0004473204317037016, Min w: 0.745827853679657\n",
      "Iteration 430, Loss: 0.00027339349617250264, Min w: 0.8594990372657776\n",
      "Iteration 440, Loss: 0.00022461629123426974, Min w: 0.8836772441864014\n",
      "Iteration 450, Loss: 0.0003284572158008814, Min w: 0.8056621551513672\n",
      "Iteration 460, Loss: 0.0002401139645371586, Min w: 0.8764886260032654\n",
      "Iteration 470, Loss: 0.00016999807849060744, Min w: 0.9033308625221252\n",
      "Iteration 480, Loss: 0.00017077686788979918, Min w: 0.898414671421051\n",
      "Iteration 490, Loss: 0.00017682764155324548, Min w: 0.8892286419868469\n",
      "Iteration 500, Loss: 0.00015352359332609922, Min w: 0.9074144959449768\n",
      "Iteration 510, Loss: 0.0006195939495228231, Min w: 0.566251277923584\n",
      "Iteration 520, Loss: 0.0002992589434143156, Min w: 0.8083152174949646\n",
      "Iteration 530, Loss: 0.00027629805845208466, Min w: 0.8235758543014526\n",
      "Iteration 540, Loss: 0.00018315375200472772, Min w: 0.9013359546661377\n",
      "Iteration 550, Loss: 0.00015640610945411026, Min w: 0.9071308374404907\n",
      "Iteration 560, Loss: 0.00017346955428365618, Min w: 0.9048513770103455\n",
      "Iteration 570, Loss: 0.0002071799972327426, Min w: 0.8895782828330994\n",
      "Iteration 580, Loss: 0.0004767664067912847, Min w: 0.6639459133148193\n",
      "Iteration 590, Loss: 0.0004515247419476509, Min w: 0.7185714244842529\n",
      "Iteration 600, Loss: 0.000560784072149545, Min w: 0.6053765416145325\n",
      "Iteration 610, Loss: 0.0003228375280741602, Min w: 0.8046475052833557\n",
      "Iteration 620, Loss: 0.00028831689269281924, Min w: 0.834436297416687\n",
      "Iteration 630, Loss: 0.0002831480232998729, Min w: 0.823721170425415\n",
      "Iteration 640, Loss: 0.00031704199500381947, Min w: 0.7889068126678467\n",
      "Iteration 650, Loss: 0.0004090995935257524, Min w: 0.7049506902694702\n",
      "Iteration 660, Loss: 0.00027405985747464, Min w: 0.8124088048934937\n",
      "Iteration 670, Loss: 0.0002246185322292149, Min w: 0.8746174573898315\n",
      "Iteration 680, Loss: 0.00031052003032527864, Min w: 0.8002339601516724\n",
      "Iteration 690, Loss: 0.0001513162424089387, Min w: 0.9184958338737488\n",
      "Iteration 700, Loss: 0.00014001656381879002, Min w: 0.920319139957428\n",
      "Iteration 710, Loss: 0.00013480012421496212, Min w: 0.9181995391845703\n",
      "Iteration 720, Loss: 0.0002360390208195895, Min w: 0.8528603911399841\n",
      "Iteration 730, Loss: 0.0002256829902762547, Min w: 0.8731173276901245\n",
      "Iteration 740, Loss: 0.00022839149460196495, Min w: 0.8541873097419739\n",
      "Iteration 750, Loss: 0.0002752006403170526, Min w: 0.8112519383430481\n",
      "Iteration 760, Loss: 0.0003168994444422424, Min w: 0.7647711634635925\n",
      "Iteration 770, Loss: 0.0003991361299995333, Min w: 0.7343407869338989\n",
      "Iteration 780, Loss: 0.00018815815565176308, Min w: 0.9016566276550293\n",
      "Iteration 790, Loss: 0.00034116156166419387, Min w: 0.7692896723747253\n",
      "Iteration 800, Loss: 0.00047711931983940303, Min w: 0.6635681986808777\n",
      "Iteration 810, Loss: 0.00020269498054403812, Min w: 0.8729965090751648\n",
      "Iteration 820, Loss: 0.000429415114922449, Min w: 0.6706100702285767\n",
      "Iteration 830, Loss: 0.0004153536865487695, Min w: 0.69102942943573\n",
      "Iteration 840, Loss: 0.00036167664802633226, Min w: 0.7314614057540894\n",
      "Iteration 850, Loss: 0.00025149769498966634, Min w: 0.8437490463256836\n",
      "Iteration 860, Loss: 0.00013487035175785422, Min w: 0.9262576699256897\n",
      "Iteration 870, Loss: 0.00018154358258470893, Min w: 0.8964372873306274\n",
      "Iteration 880, Loss: 0.0002983658341690898, Min w: 0.7998852133750916\n",
      "Iteration 890, Loss: 0.0001671294157858938, Min w: 0.9067857265472412\n",
      "Iteration 900, Loss: 0.0003784244181588292, Min w: 0.74862140417099\n",
      "Iteration 910, Loss: 0.0001774381526047364, Min w: 0.9004697203636169\n",
      "Iteration 920, Loss: 0.00024468667106702924, Min w: 0.8466472625732422\n",
      "Iteration 930, Loss: 0.0002714543661568314, Min w: 0.8175091743469238\n",
      "Iteration 940, Loss: 0.000136057089548558, Min w: 0.9279399514198303\n",
      "Iteration 950, Loss: 0.00014649637159891427, Min w: 0.9153676629066467\n",
      "Iteration 960, Loss: 0.000164563549333252, Min w: 0.9133358597755432\n",
      "Iteration 970, Loss: 0.0002445162972435355, Min w: 0.8591262698173523\n",
      "Iteration 980, Loss: 0.00015567879017908126, Min w: 0.9000368714332581\n",
      "Iteration 990, Loss: 0.00021425717568490654, Min w: 0.8493629097938538\n",
      "Iteration 1000, Loss: 0.00015542017354164273, Min w: 0.9057728052139282\n",
      "Iteration 1010, Loss: 0.0002661273174453527, Min w: 0.8022363781929016\n",
      "Iteration 1020, Loss: 0.00019401901226956397, Min w: 0.8749497532844543\n",
      "Iteration 1030, Loss: 0.00024005257000681013, Min w: 0.8314499855041504\n",
      "Iteration 1040, Loss: 0.00018296488269697875, Min w: 0.8833860754966736\n",
      "Iteration 1050, Loss: 0.00020564482838381082, Min w: 0.8675723075866699\n",
      "Iteration 1060, Loss: 0.0001355748245259747, Min w: 0.9228168725967407\n",
      "Iteration 1070, Loss: 0.00041934370528906584, Min w: 0.6965972185134888\n",
      "Iteration 1080, Loss: 0.0004498897469602525, Min w: 0.6624677777290344\n",
      "Iteration 1090, Loss: 0.00016362483438570052, Min w: 0.8965921998023987\n",
      "Iteration 1100, Loss: 0.00023928516020532697, Min w: 0.8348312973976135\n",
      "Iteration 1110, Loss: 0.00023191854415927082, Min w: 0.8349069952964783\n",
      "Iteration 1120, Loss: 0.00020572928769979626, Min w: 0.866759717464447\n",
      "Iteration 1130, Loss: 0.00019652911578305066, Min w: 0.8630681037902832\n",
      "Iteration 1140, Loss: 0.00010173104237765074, Min w: 0.9436042904853821\n",
      "Iteration 1150, Loss: 0.00020741307525895536, Min w: 0.8524579405784607\n",
      "Iteration 1160, Loss: 8.889150194590911e-05, Min w: 0.9501861929893494\n",
      "Iteration 1170, Loss: 0.0001571441680425778, Min w: 0.89720618724823\n",
      "Iteration 1180, Loss: 0.00025662308325991035, Min w: 0.8206826448440552\n",
      "Iteration 1190, Loss: 0.0002473886706866324, Min w: 0.8134790658950806\n",
      "Iteration 1200, Loss: 0.00013804779155179858, Min w: 0.9203168749809265\n",
      "Iteration 1210, Loss: 0.00024393113562837243, Min w: 0.8420387506484985\n",
      "Iteration 1220, Loss: 0.0001580223033670336, Min w: 0.8913735151290894\n",
      "Iteration 1230, Loss: 0.00014717716840095818, Min w: 0.8994770050048828\n",
      "Iteration 1240, Loss: 0.00026014080503955483, Min w: 0.8224160075187683\n",
      "Iteration 0, Loss: 0.0002085802989313379, Min w: 0.8729996085166931\n",
      "Iteration 10, Loss: 0.00027459117700345814, Min w: 0.8134526610374451\n",
      "Iteration 20, Loss: 0.0002491301274858415, Min w: 0.8289111852645874\n",
      "Iteration 30, Loss: 0.00015378688112832606, Min w: 0.8864361643791199\n",
      "Iteration 40, Loss: 0.0002781398070510477, Min w: 0.8080943822860718\n",
      "Iteration 50, Loss: 0.00024378759553655982, Min w: 0.8225270509719849\n",
      "Iteration 60, Loss: 0.0002483468852005899, Min w: 0.8344637155532837\n",
      "Iteration 70, Loss: 0.0002835507330019027, Min w: 0.7970061302185059\n",
      "Iteration 80, Loss: 0.0002416465140413493, Min w: 0.833136260509491\n",
      "Iteration 90, Loss: 0.0001884588855318725, Min w: 0.8763555884361267\n",
      "Iteration 100, Loss: 0.0001510786678409204, Min w: 0.8976510763168335\n",
      "Iteration 110, Loss: 0.00014820134674664587, Min w: 0.8973626494407654\n",
      "Iteration 120, Loss: 0.0002541804569773376, Min w: 0.8189898729324341\n",
      "Iteration 130, Loss: 0.00025866046780720353, Min w: 0.7982057929039001\n",
      "Iteration 140, Loss: 7.562746031908318e-05, Min w: 0.9602742791175842\n",
      "Iteration 150, Loss: 0.00016611286264378577, Min w: 0.8733527660369873\n",
      "Iteration 160, Loss: 0.00014818254567217082, Min w: 0.9035823941230774\n",
      "Iteration 170, Loss: 0.0001563902187626809, Min w: 0.8994073867797852\n",
      "Iteration 180, Loss: 9.449820936424658e-05, Min w: 0.9379528164863586\n",
      "Iteration 190, Loss: 7.78032117523253e-05, Min w: 0.9565168023109436\n",
      "Iteration 200, Loss: 0.00010754520917544141, Min w: 0.9369083642959595\n",
      "Iteration 210, Loss: 8.441972750006244e-05, Min w: 0.9450079202651978\n",
      "Iteration 220, Loss: 0.0002141124859917909, Min w: 0.8435788750648499\n",
      "Iteration 230, Loss: 0.0002401398669462651, Min w: 0.8155257701873779\n",
      "Iteration 240, Loss: 0.0003056118148379028, Min w: 0.774813175201416\n",
      "Iteration 250, Loss: 0.0001473453885409981, Min w: 0.8948624730110168\n",
      "Iteration 260, Loss: 0.00012329364835750312, Min w: 0.9179461002349854\n",
      "Iteration 270, Loss: 0.0002992628433275968, Min w: 0.7614972591400146\n",
      "Iteration 280, Loss: 0.00032015034230425954, Min w: 0.7648254632949829\n",
      "Iteration 290, Loss: 0.0004463700170163065, Min w: 0.6748161315917969\n",
      "Iteration 300, Loss: 0.00010563471005298197, Min w: 0.9244316220283508\n",
      "Iteration 310, Loss: 0.0004282951704226434, Min w: 0.708712637424469\n",
      "Iteration 320, Loss: 0.00016590335872024298, Min w: 0.8906493186950684\n",
      "Iteration 330, Loss: 7.517669291701168e-05, Min w: 0.9506295919418335\n",
      "Iteration 340, Loss: 5.7500277762301266e-05, Min w: 0.9693809151649475\n",
      "Iteration 350, Loss: 0.0003090949321631342, Min w: 0.7647964954376221\n",
      "Iteration 360, Loss: 5.3801326430402696e-05, Min w: 0.9682121276855469\n",
      "Iteration 370, Loss: 0.000244749739067629, Min w: 0.817502498626709\n",
      "Iteration 380, Loss: 0.00016989544383250177, Min w: 0.8968284726142883\n",
      "Iteration 390, Loss: 0.00010948211274808273, Min w: 0.9336102604866028\n",
      "Iteration 400, Loss: 6.945759378140792e-05, Min w: 0.9588732719421387\n",
      "Iteration 410, Loss: 0.0003503277839627117, Min w: 0.7206000089645386\n",
      "Iteration 420, Loss: 6.086808207328431e-05, Min w: 0.9673203229904175\n",
      "Iteration 430, Loss: 0.0002687844098545611, Min w: 0.7910069823265076\n",
      "Iteration 440, Loss: 0.00036625584471039474, Min w: 0.715373158454895\n",
      "Iteration 450, Loss: 0.00018298007489647716, Min w: 0.8765987157821655\n",
      "Iteration 460, Loss: 5.4742879001423717e-05, Min w: 0.9716820120811462\n",
      "Iteration 470, Loss: 0.00016422192857135087, Min w: 0.8967381715774536\n",
      "Iteration 480, Loss: 0.0003172309370711446, Min w: 0.771837592124939\n",
      "Iteration 490, Loss: 0.0001686514005996287, Min w: 0.8888811469078064\n",
      "Iteration 500, Loss: 0.00025502254720777273, Min w: 0.8206440806388855\n",
      "Iteration 510, Loss: 0.00015099185111466795, Min w: 0.8914011716842651\n",
      "Iteration 520, Loss: 0.00014688356895931065, Min w: 0.9053492546081543\n",
      "Iteration 530, Loss: 0.00010080853826366365, Min w: 0.9337222576141357\n",
      "Iteration 540, Loss: 0.00020545467850752175, Min w: 0.832595944404602\n",
      "Iteration 550, Loss: 0.0002734172740019858, Min w: 0.8008747100830078\n",
      "Iteration 560, Loss: 0.000319112790748477, Min w: 0.7589133977890015\n",
      "Iteration 570, Loss: 0.00010632522025844082, Min w: 0.9264323115348816\n",
      "Iteration 580, Loss: 6.199564086273313e-05, Min w: 0.9573965668678284\n",
      "Iteration 590, Loss: 8.093657379504293e-05, Min w: 0.9491477608680725\n",
      "Iteration 600, Loss: 6.193874287419021e-05, Min w: 0.9667708277702332\n",
      "Iteration 610, Loss: 0.00022020428150426596, Min w: 0.8294482231140137\n",
      "Iteration 620, Loss: 0.00019822869217023253, Min w: 0.8580770492553711\n",
      "Iteration 630, Loss: 0.00020796334138140082, Min w: 0.8403335809707642\n",
      "Iteration 640, Loss: 9.984742064261809e-05, Min w: 0.9274822473526001\n",
      "Iteration 650, Loss: 6.548967212438583e-05, Min w: 0.9541335105895996\n",
      "Iteration 660, Loss: 0.00029789513791911304, Min w: 0.7705159187316895\n",
      "Iteration 670, Loss: 0.00020800148195121437, Min w: 0.841687798500061\n",
      "Iteration 680, Loss: 0.00015142105985432863, Min w: 0.8741858005523682\n",
      "Iteration 690, Loss: 6.278474029386416e-05, Min w: 0.9581269025802612\n",
      "Iteration 700, Loss: 0.00016969343414530158, Min w: 0.8801460862159729\n",
      "Iteration 710, Loss: 0.00020529722678475082, Min w: 0.8397907018661499\n",
      "Iteration 720, Loss: 0.0001923445233842358, Min w: 0.838995099067688\n",
      "Iteration 730, Loss: 0.00019830561359412968, Min w: 0.8647237420082092\n",
      "Iteration 740, Loss: 0.00021510965598281473, Min w: 0.8260087966918945\n",
      "Iteration 750, Loss: 0.0002063209394691512, Min w: 0.8425243496894836\n",
      "Iteration 760, Loss: 0.0002615985576994717, Min w: 0.8085924386978149\n",
      "Iteration 770, Loss: 0.00028563226805999875, Min w: 0.7748358845710754\n",
      "Iteration 780, Loss: 0.0002363118837820366, Min w: 0.8190851807594299\n",
      "Iteration 790, Loss: 0.0001409475225955248, Min w: 0.883746862411499\n",
      "Iteration 800, Loss: 0.0001952988823177293, Min w: 0.8614098429679871\n",
      "Iteration 810, Loss: 0.00024030789791140705, Min w: 0.7975870370864868\n",
      "Iteration 820, Loss: 0.0001953068858711049, Min w: 0.8613701462745667\n",
      "Iteration 830, Loss: 0.000193215993931517, Min w: 0.841683030128479\n",
      "Iteration 840, Loss: 0.00014140394341666251, Min w: 0.9094675183296204\n",
      "Iteration 850, Loss: 0.00022305845050141215, Min w: 0.8297121524810791\n",
      "Iteration 860, Loss: 0.00022022461052984, Min w: 0.8412017822265625\n",
      "Iteration 870, Loss: 0.00010992166789947078, Min w: 0.9181993007659912\n",
      "Iteration 880, Loss: 6.270543963182718e-05, Min w: 0.9543477296829224\n",
      "Iteration 890, Loss: 0.00010414121788926423, Min w: 0.9203705191612244\n",
      "Iteration 900, Loss: 0.00015475908003281802, Min w: 0.8787351846694946\n",
      "Iteration 910, Loss: 0.0002112138463417068, Min w: 0.8458755612373352\n",
      "Iteration 920, Loss: 0.00016956809849943966, Min w: 0.853082537651062\n",
      "Iteration 930, Loss: 4.240113412379287e-05, Min w: 0.9747991561889648\n",
      "Iteration 940, Loss: 0.0002874592610169202, Min w: 0.781639814376831\n",
      "Iteration 950, Loss: 0.0001702500885585323, Min w: 0.8584588170051575\n",
      "Iteration 960, Loss: 0.00015965984493959695, Min w: 0.8755775094032288\n",
      "Iteration 970, Loss: 7.897330942796543e-05, Min w: 0.9486903548240662\n",
      "Iteration 980, Loss: 0.00011959812400164083, Min w: 0.9047129154205322\n",
      "Iteration 990, Loss: 0.00015520564920734614, Min w: 0.8881636261940002\n",
      "Iteration 1000, Loss: 0.00010699159611249343, Min w: 0.9095045924186707\n",
      "Iteration 1010, Loss: 0.00026287033688277006, Min w: 0.7755280137062073\n",
      "Iteration 1020, Loss: 0.0002187005738960579, Min w: 0.823289692401886\n",
      "Iteration 1030, Loss: 0.00016742334992159158, Min w: 0.8770545721054077\n",
      "Iteration 1040, Loss: 0.0001304316392634064, Min w: 0.9157771468162537\n",
      "Iteration 1050, Loss: 8.265346696134657e-05, Min w: 0.9346345663070679\n",
      "Iteration 1060, Loss: 0.0001489653659518808, Min w: 0.890850841999054\n",
      "Iteration 1070, Loss: 0.00018860693671740592, Min w: 0.8554725050926208\n",
      "Iteration 1080, Loss: 0.0001310572843067348, Min w: 0.9173445105552673\n",
      "Iteration 1090, Loss: 8.48846830194816e-05, Min w: 0.9344399571418762\n",
      "Iteration 1100, Loss: 0.00020094715000595897, Min w: 0.8634874224662781\n",
      "Iteration 1110, Loss: 6.930167728569359e-05, Min w: 0.95661860704422\n",
      "Iteration 1120, Loss: 6.098292942624539e-05, Min w: 0.9619967937469482\n",
      "Iteration 1130, Loss: 0.00013050675624981523, Min w: 0.8937854766845703\n",
      "Iteration 1140, Loss: 5.090783815830946e-05, Min w: 0.9628751873970032\n",
      "Iteration 1150, Loss: 0.00012476871779654175, Min w: 0.9045765399932861\n",
      "Iteration 1160, Loss: 0.00012458708079066128, Min w: 0.9092792272567749\n",
      "Iteration 1170, Loss: 7.550632290076464e-05, Min w: 0.9437556266784668\n",
      "Iteration 1180, Loss: 8.805406832834706e-05, Min w: 0.9256353378295898\n",
      "Iteration 1190, Loss: 0.00011137238470837474, Min w: 0.9097246527671814\n",
      "Iteration 1200, Loss: 5.046306614531204e-05, Min w: 0.9693126082420349\n",
      "Iteration 1210, Loss: 0.000123261779663153, Min w: 0.9093669652938843\n",
      "Iteration 1220, Loss: 8.743964281165972e-05, Min w: 0.9425444006919861\n",
      "Iteration 1230, Loss: 0.00014660987653769553, Min w: 0.8730583786964417\n",
      "Iteration 1240, Loss: 0.00012855062959715724, Min w: 0.9028022289276123\n",
      "Iteration 0, Loss: 0.0001209721522172913, Min w: 0.9076490998268127\n",
      "Iteration 10, Loss: 0.0002306346141267568, Min w: 0.8357333540916443\n",
      "Iteration 20, Loss: 0.0001631765771890059, Min w: 0.8691112995147705\n",
      "Iteration 30, Loss: 0.00026309138047508895, Min w: 0.8096128106117249\n",
      "Iteration 40, Loss: 0.0001365894713671878, Min w: 0.8880099058151245\n",
      "Iteration 50, Loss: 0.00023236882407218218, Min w: 0.8199895024299622\n",
      "Iteration 60, Loss: 0.00017665144696366042, Min w: 0.8729634881019592\n",
      "Iteration 70, Loss: 0.00016381204477511346, Min w: 0.8520254492759705\n",
      "Iteration 80, Loss: 0.00014698276936542243, Min w: 0.9090614318847656\n",
      "Iteration 90, Loss: 0.00010636256774887443, Min w: 0.9218676686286926\n",
      "Iteration 100, Loss: 0.0001475638709962368, Min w: 0.8795422315597534\n",
      "Iteration 110, Loss: 0.00012735956988763064, Min w: 0.8985636830329895\n",
      "Iteration 120, Loss: 0.0002008787851082161, Min w: 0.835303544998169\n",
      "Iteration 130, Loss: 0.0001991172757698223, Min w: 0.8387049436569214\n",
      "Iteration 140, Loss: 0.00019204993441235274, Min w: 0.8514708280563354\n",
      "Iteration 150, Loss: 0.00022838475706521422, Min w: 0.8282139301300049\n",
      "Iteration 160, Loss: 0.000248794473009184, Min w: 0.7992134690284729\n",
      "Iteration 170, Loss: 0.00015326114953495562, Min w: 0.8917975425720215\n",
      "Iteration 180, Loss: 4.800612441613339e-05, Min w: 0.9700280427932739\n",
      "Iteration 190, Loss: 0.00017177512927446514, Min w: 0.8735846281051636\n",
      "Iteration 200, Loss: 0.00012241410149727017, Min w: 0.903221070766449\n",
      "Iteration 210, Loss: 0.00014413231110665947, Min w: 0.8847197890281677\n",
      "Iteration 220, Loss: 0.0002239709865534678, Min w: 0.8176890015602112\n",
      "Iteration 230, Loss: 0.0003884906764142215, Min w: 0.744610607624054\n",
      "Iteration 240, Loss: 0.0001384108909405768, Min w: 0.9059008359909058\n",
      "Iteration 250, Loss: 0.00020248199871275574, Min w: 0.8387928605079651\n",
      "Iteration 260, Loss: 0.00024373373889829963, Min w: 0.8228543996810913\n",
      "Iteration 270, Loss: 8.425294072367251e-05, Min w: 0.9445542693138123\n",
      "Iteration 280, Loss: 0.00017299293540418148, Min w: 0.8625733256340027\n",
      "Iteration 290, Loss: 0.00010449623368913308, Min w: 0.9159510135650635\n",
      "Iteration 300, Loss: 9.771755867404863e-05, Min w: 0.9300511479377747\n",
      "Iteration 310, Loss: 0.00012559334572870284, Min w: 0.8959251046180725\n",
      "Iteration 320, Loss: 0.0002214325068052858, Min w: 0.8437014818191528\n",
      "Iteration 330, Loss: 0.00018932743114419281, Min w: 0.8407583236694336\n",
      "Iteration 340, Loss: 9.132405102718621e-05, Min w: 0.9176172018051147\n",
      "Iteration 350, Loss: 0.0001073801759048365, Min w: 0.9143964648246765\n",
      "Iteration 360, Loss: 3.525754073052667e-05, Min w: 0.9797740578651428\n",
      "Iteration 370, Loss: 0.00015907560009509325, Min w: 0.8887614011764526\n",
      "Iteration 380, Loss: 0.0004275024402886629, Min w: 0.6758295297622681\n",
      "Iteration 390, Loss: 0.0005730013363063335, Min w: 0.6093677282333374\n",
      "Iteration 400, Loss: 5.416373096522875e-05, Min w: 0.9701212644577026\n",
      "Iteration 410, Loss: 0.000266873073996976, Min w: 0.8012076616287231\n",
      "Iteration 420, Loss: 0.0005864307167939842, Min w: 0.5977973937988281\n",
      "Iteration 430, Loss: 3.9480124542023987e-05, Min w: 0.9728665947914124\n",
      "Iteration 440, Loss: 3.0661562050227076e-05, Min w: 0.9817795157432556\n",
      "Iteration 450, Loss: 3.34432115778327e-05, Min w: 0.9790098071098328\n",
      "Iteration 460, Loss: 2.7598194719757885e-05, Min w: 0.9835535883903503\n",
      "Iteration 470, Loss: 0.0003496890712995082, Min w: 0.6962531805038452\n",
      "Iteration 480, Loss: 0.00025555293541401625, Min w: 0.8557243347167969\n",
      "Iteration 490, Loss: 0.00023310932738240808, Min w: 0.8705471754074097\n",
      "Iteration 500, Loss: 0.00023961601254995912, Min w: 0.8035408854484558\n",
      "Iteration 510, Loss: 0.00014226982602849603, Min w: 0.9069390892982483\n",
      "Iteration 520, Loss: 0.00024427336757071316, Min w: 0.8519334197044373\n",
      "Iteration 530, Loss: 0.0003718101361300796, Min w: 0.7713936567306519\n",
      "Iteration 540, Loss: 0.00012375626829452813, Min w: 0.9208537936210632\n",
      "Iteration 550, Loss: 6.26360924798064e-05, Min w: 0.961468517780304\n",
      "Iteration 560, Loss: 0.0004284257593099028, Min w: 0.6693741083145142\n",
      "Iteration 570, Loss: 4.225640441291034e-05, Min w: 0.9701194763183594\n",
      "Iteration 580, Loss: 8.955750672612339e-05, Min w: 0.9302161335945129\n",
      "Iteration 590, Loss: 2.440841490169987e-05, Min w: 0.9850345253944397\n",
      "Iteration 600, Loss: 0.00021302256209310144, Min w: 0.836147665977478\n",
      "Iteration 610, Loss: 0.00024502392625436187, Min w: 0.8109251260757446\n",
      "Iteration 620, Loss: 0.0001087392884073779, Min w: 0.9165122509002686\n",
      "Iteration 630, Loss: 0.00021495936380233616, Min w: 0.829967737197876\n",
      "Iteration 640, Loss: 0.00025837469729594886, Min w: 0.8014824986457825\n",
      "Iteration 650, Loss: 8.872269245330244e-05, Min w: 0.9337274432182312\n",
      "Iteration 660, Loss: 4.023790097562596e-05, Min w: 0.9720506072044373\n",
      "Iteration 670, Loss: 5.592267189058475e-05, Min w: 0.9576396942138672\n",
      "Iteration 680, Loss: 0.00019243097631260753, Min w: 0.8512698411941528\n",
      "Iteration 690, Loss: 0.00015414484369102865, Min w: 0.875516414642334\n",
      "Iteration 700, Loss: 0.00019746751058846712, Min w: 0.8409749865531921\n",
      "Iteration 710, Loss: 0.00018072777311317623, Min w: 0.8698951005935669\n",
      "Iteration 720, Loss: 0.00013227439194452018, Min w: 0.8933937549591064\n",
      "Iteration 730, Loss: 0.0001963068643817678, Min w: 0.8416383862495422\n",
      "Iteration 740, Loss: 0.00028581827064044774, Min w: 0.7719153165817261\n",
      "Iteration 750, Loss: 4.568227086565457e-05, Min w: 0.963934063911438\n",
      "Iteration 760, Loss: 8.371612057089806e-05, Min w: 0.9262295365333557\n",
      "Iteration 770, Loss: 3.038555951206945e-05, Min w: 0.9789996147155762\n",
      "Iteration 780, Loss: 0.00031754502560943365, Min w: 0.7691988945007324\n",
      "Iteration 790, Loss: 0.00030990547384135425, Min w: 0.7729576230049133\n",
      "Iteration 800, Loss: 2.1778547306894325e-05, Min w: 0.986491322517395\n",
      "Iteration 810, Loss: 6.532833504024893e-05, Min w: 0.957176923751831\n",
      "Iteration 820, Loss: 0.00011242230539210141, Min w: 0.9302566051483154\n",
      "Iteration 830, Loss: 5.988198608974926e-05, Min w: 0.9632241129875183\n",
      "Iteration 840, Loss: 0.00029877954511903226, Min w: 0.7938451766967773\n",
      "Iteration 850, Loss: 4.5367178245214745e-05, Min w: 0.9624822735786438\n",
      "Iteration 860, Loss: 0.00019438500748947263, Min w: 0.8623325824737549\n",
      "Iteration 870, Loss: 0.0001589460443938151, Min w: 0.859411895275116\n",
      "Iteration 880, Loss: 8.636358688818291e-05, Min w: 0.9471873044967651\n",
      "Iteration 890, Loss: 2.788911479001399e-05, Min w: 0.9826653003692627\n",
      "Iteration 900, Loss: 2.4880300770746544e-05, Min w: 0.9848222136497498\n",
      "Iteration 910, Loss: 0.00010464899969520047, Min w: 0.9156325459480286\n",
      "Iteration 920, Loss: 0.0003294510825071484, Min w: 0.7259705662727356\n",
      "Iteration 930, Loss: 0.00026776903541758657, Min w: 0.7867037653923035\n",
      "Iteration 940, Loss: 5.260017132968642e-05, Min w: 0.9599340558052063\n",
      "Iteration 950, Loss: 0.0002658330777194351, Min w: 0.803463876247406\n",
      "Iteration 960, Loss: 0.0003103911876678467, Min w: 0.7390323877334595\n",
      "Iteration 970, Loss: 0.0002744082303252071, Min w: 0.7846868634223938\n",
      "Iteration 980, Loss: 0.00038470045547001064, Min w: 0.6940402984619141\n",
      "Iteration 990, Loss: 0.00015619283658452332, Min w: 0.8725585341453552\n",
      "Iteration 1000, Loss: 0.0003155548474751413, Min w: 0.7558798789978027\n",
      "Iteration 1010, Loss: 7.616839138790965e-05, Min w: 0.9349502325057983\n",
      "Iteration 1020, Loss: 2.54935057455441e-05, Min w: 0.986018180847168\n",
      "Iteration 1030, Loss: 2.8779792046407238e-05, Min w: 0.979093611240387\n",
      "Iteration 1040, Loss: 0.00048274354776367545, Min w: 0.6030852794647217\n",
      "Iteration 1050, Loss: 0.000234186154557392, Min w: 0.792243480682373\n",
      "Iteration 1060, Loss: 0.0001706181647023186, Min w: 0.8713518977165222\n",
      "Iteration 1070, Loss: 0.00015279650688171387, Min w: 0.8754111528396606\n",
      "Iteration 1080, Loss: 0.00011013285984518006, Min w: 0.9209473133087158\n",
      "Iteration 1090, Loss: 7.930315041448921e-05, Min w: 0.9355908632278442\n",
      "Iteration 1100, Loss: 0.00020595667592715472, Min w: 0.8361305594444275\n",
      "Iteration 1110, Loss: 0.00012578196765389293, Min w: 0.9045827984809875\n",
      "Iteration 1120, Loss: 9.41774487728253e-05, Min w: 0.9254137277603149\n",
      "Iteration 1130, Loss: 0.00017127669707406312, Min w: 0.8489351868629456\n",
      "Iteration 1140, Loss: 0.00011899920355062932, Min w: 0.9071187973022461\n",
      "Iteration 1150, Loss: 3.544144055922516e-05, Min w: 0.9769749045372009\n",
      "Iteration 1160, Loss: 0.00013924509403295815, Min w: 0.8832243084907532\n",
      "Iteration 1170, Loss: 9.346782462671399e-05, Min w: 0.9168280959129333\n",
      "Iteration 1180, Loss: 0.00023119620163924992, Min w: 0.8258751630783081\n",
      "Iteration 1190, Loss: 9.486827912041917e-05, Min w: 0.923585057258606\n",
      "Iteration 1200, Loss: 0.00016145053086802363, Min w: 0.8614743947982788\n",
      "Iteration 1210, Loss: 0.00022789862123318017, Min w: 0.8198705911636353\n",
      "Iteration 1220, Loss: 0.00022018847812432796, Min w: 0.8373483419418335\n",
      "Iteration 1230, Loss: 5.863089609192684e-05, Min w: 0.9541445374488831\n",
      "Iteration 1240, Loss: 0.0001260321296285838, Min w: 0.8950374126434326\n",
      "Iteration 0, Loss: 0.0002809813595376909, Min w: 0.783850908279419\n",
      "Iteration 10, Loss: 0.00020805896201636642, Min w: 0.8384448885917664\n",
      "Iteration 20, Loss: 0.00014875292254146188, Min w: 0.8886830806732178\n",
      "Iteration 30, Loss: 0.00010925025708274916, Min w: 0.9227710366249084\n",
      "Iteration 40, Loss: 0.00022118484776001424, Min w: 0.822930634021759\n",
      "Iteration 50, Loss: 0.00016862322809174657, Min w: 0.8809104561805725\n",
      "Iteration 60, Loss: 0.00019536730542313308, Min w: 0.8367141485214233\n",
      "Iteration 70, Loss: 0.00032055750489234924, Min w: 0.7613400816917419\n",
      "Iteration 80, Loss: 1.8177808669861406e-05, Min w: 0.9885000586509705\n",
      "Iteration 90, Loss: 0.0001016136011458002, Min w: 0.9194141626358032\n",
      "Iteration 100, Loss: 0.00018813634233083576, Min w: 0.8448448181152344\n",
      "Iteration 110, Loss: 0.00019015367433894426, Min w: 0.8436455726623535\n",
      "Iteration 120, Loss: 7.982420356711373e-05, Min w: 0.9454460144042969\n",
      "Iteration 130, Loss: 3.6835397622780874e-05, Min w: 0.9722306132316589\n",
      "Iteration 140, Loss: 8.434256596956402e-05, Min w: 0.9229574799537659\n",
      "Iteration 150, Loss: 6.817888061050326e-05, Min w: 0.9461455941200256\n",
      "Iteration 160, Loss: 9.477310231886804e-05, Min w: 0.9346866011619568\n",
      "Iteration 170, Loss: 7.398892194032669e-05, Min w: 0.9409667253494263\n",
      "Iteration 180, Loss: 0.00011866899876622483, Min w: 0.9083928465843201\n",
      "Iteration 190, Loss: 0.00014174537500366569, Min w: 0.8787809014320374\n",
      "Iteration 200, Loss: 9.367100574309006e-05, Min w: 0.9249216318130493\n",
      "Iteration 210, Loss: 6.222435331437737e-05, Min w: 0.963726282119751\n",
      "Iteration 220, Loss: 0.00011627676576608792, Min w: 0.9176275134086609\n",
      "Iteration 230, Loss: 0.00024220383784268051, Min w: 0.809824526309967\n",
      "Iteration 240, Loss: 0.0001095045663532801, Min w: 0.9119634032249451\n",
      "Iteration 250, Loss: 0.0002904166467487812, Min w: 0.7864152789115906\n",
      "Iteration 260, Loss: 2.7607204174273647e-05, Min w: 0.9854292273521423\n",
      "Iteration 270, Loss: 0.00015086850908119231, Min w: 0.8777597546577454\n",
      "Iteration 280, Loss: 5.951143248239532e-05, Min w: 0.9571859240531921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  71%|███████   | 17/24 [27:35<12:06, 103.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 286 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 5287, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.007014827163767931, 'L2_avg': 0.008484641897111568, 'End_point_L1_avg': 0.0048869815377360504, 'End_point_L2_avg': 0.005122172735659829}\n",
      "Iteration 0, Loss: 0.006911437027156353, Min w: 0.0\n",
      "Iteration 10, Loss: 0.002730434760451317, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002334228716790676, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0025402442552149296, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0020777317695319653, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00238015060313046, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0024267854169011116, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002263810485601425, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00202353298664093, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002297064056620002, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002142304088920355, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0021987210493534803, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002378143137320876, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0021973515395075083, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0027202104683965445, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002035563113167882, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0020862568635493517, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0019290059572085738, Min w: 1.3826378494343595e-31\n",
      "Iteration 180, Loss: 0.001999886240810156, Min w: 9.113165010829157e-16\n",
      "Iteration 190, Loss: 0.002074142685160041, Min w: 0.0023267276119440794\n",
      "Iteration 200, Loss: 0.0020590180065482855, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0013944967649877071, Min w: 5.95093622740213e-40\n",
      "Iteration 220, Loss: 0.0021755550988018513, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0020418947096914053, Min w: 4.0720770312187225e-20\n",
      "Iteration 240, Loss: 0.0018752013565972447, Min w: 0.0\n",
      "Iteration 250, Loss: 0.001698830397799611, Min w: 0.14210326969623566\n",
      "Iteration 260, Loss: 0.0020462546963244677, Min w: 1.804059668941056e-40\n",
      "Iteration 270, Loss: 0.0020067135337740183, Min w: 2.2012294209616812e-07\n",
      "Iteration 280, Loss: 0.00198073941282928, Min w: 2.7454553521083857e-26\n",
      "Iteration 290, Loss: 0.002148934407159686, Min w: 3.440444800162368e-07\n",
      "Iteration 300, Loss: 0.0017789247212931514, Min w: 1.7519849393465847e-07\n",
      "Iteration 310, Loss: 0.0014083634596318007, Min w: 0.07813530415296555\n",
      "Iteration 320, Loss: 0.0020801504142582417, Min w: 8.916069380200675e-14\n",
      "Iteration 330, Loss: 0.001735038124024868, Min w: 0.07457448542118073\n",
      "Iteration 340, Loss: 0.0016489470144733787, Min w: 0.11382725089788437\n",
      "Iteration 350, Loss: 0.0014005289413034916, Min w: 0.270112007856369\n",
      "Iteration 360, Loss: 0.0016503938240930438, Min w: 3.9731181459501386e-05\n",
      "Iteration 370, Loss: 0.0019927930552512407, Min w: 9.236963138705005e-30\n",
      "Iteration 380, Loss: 0.001894716639071703, Min w: 0.014066892676055431\n",
      "Iteration 390, Loss: 0.0019876339938491583, Min w: 1.6354717445210554e-05\n",
      "Iteration 400, Loss: 0.0015598805621266365, Min w: 0.1433994174003601\n",
      "Iteration 410, Loss: 0.002007421338930726, Min w: 1.1823032552982227e-09\n",
      "Iteration 420, Loss: 0.002006545662879944, Min w: 2.445162726264092e-30\n",
      "Iteration 430, Loss: 0.001813580864109099, Min w: 0.0011166215408593416\n",
      "Iteration 440, Loss: 0.0016770224319770932, Min w: 0.010684899985790253\n",
      "Iteration 450, Loss: 0.0015304494882002473, Min w: 0.045691538602113724\n",
      "Iteration 460, Loss: 0.0008958036778494716, Min w: 0.4455920159816742\n",
      "Iteration 470, Loss: 0.0011420546798035502, Min w: 0.22812478244304657\n",
      "Iteration 480, Loss: 0.001998635707423091, Min w: 1.230275646982304e-13\n",
      "Iteration 490, Loss: 0.002003117697313428, Min w: 0.0\n",
      "Iteration 500, Loss: 0.001684809336438775, Min w: 3.925389527315026e-12\n",
      "Iteration 510, Loss: 0.0020308424718677998, Min w: 1.0396826656830469e-19\n",
      "Iteration 520, Loss: 0.0020842819940298796, Min w: 1.4142125210731528e-30\n",
      "Iteration 530, Loss: 0.002106413245201111, Min w: 3.777675772198563e-08\n",
      "Iteration 540, Loss: 0.00212637847289443, Min w: 2.8609639102228357e-08\n",
      "Iteration 550, Loss: 0.001857341849245131, Min w: 1.0257230178070675e-16\n",
      "Iteration 560, Loss: 0.001868008403107524, Min w: 2.4480973692675434e-08\n",
      "Iteration 570, Loss: 0.0015998658491298556, Min w: 0.04733441025018692\n",
      "Iteration 580, Loss: 0.0010897170286625624, Min w: 0.431861013174057\n",
      "Iteration 590, Loss: 0.0011125715682283044, Min w: 0.1378776729106903\n",
      "Iteration 600, Loss: 0.001991915749385953, Min w: 1.220495579601355e-11\n",
      "Iteration 610, Loss: 0.0019983656238764524, Min w: 0.0007066696998663247\n",
      "Iteration 620, Loss: 0.0020190374925732613, Min w: 1.5018704678223077e-23\n",
      "Iteration 630, Loss: 0.00205579143948853, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0020820805802941322, Min w: 3.164547443534893e-11\n",
      "Iteration 650, Loss: 0.0020580817945301533, Min w: 0.0055061690509319305\n",
      "Iteration 660, Loss: 0.0012780815595760942, Min w: 0.025570949539542198\n",
      "Iteration 670, Loss: 0.0011434352491050959, Min w: 0.16329874098300934\n",
      "Iteration 680, Loss: 0.00199116300791502, Min w: 8.880862878868356e-06\n",
      "Iteration 690, Loss: 0.0019955122843384743, Min w: 1.7106177665482392e-06\n",
      "Iteration 700, Loss: 0.0018267602426931262, Min w: 5.3331709708170916e-12\n",
      "Iteration 710, Loss: 0.0020273535046726465, Min w: 2.1452338060502192e-40\n",
      "Iteration 720, Loss: 0.002046019770205021, Min w: 1.599012254214417e-17\n",
      "Iteration 730, Loss: 0.0020202635787427425, Min w: 2.4893347495634725e-27\n",
      "Iteration 740, Loss: 0.0020126900635659695, Min w: 2.7755472919999136e-10\n",
      "Iteration 750, Loss: 0.002000967273488641, Min w: 3.178970555507316e-33\n",
      "Iteration 760, Loss: 0.0020303851924836636, Min w: 8.833921372186637e-10\n",
      "Iteration 770, Loss: 0.0020271947141736746, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002065827138721943, Min w: 1.7451780049437117e-18\n",
      "Iteration 790, Loss: 0.0020903386175632477, Min w: 5.341524820787097e-36\n",
      "Iteration 800, Loss: 0.002020959509536624, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0020991526544094086, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002013308461755514, Min w: 1.8529430740435132e-23\n",
      "Iteration 830, Loss: 0.0018562403274700046, Min w: 8.928483293857425e-05\n",
      "Iteration 840, Loss: 0.0019822847098112106, Min w: 3.7189466870060465e-26\n",
      "Iteration 850, Loss: 0.0019959036726504564, Min w: 3.802161328198981e-18\n",
      "Iteration 860, Loss: 0.002016079844906926, Min w: 1.49022486487087e-40\n",
      "Iteration 870, Loss: 0.0019936198368668556, Min w: 1.635228414897938e-07\n",
      "Iteration 880, Loss: 0.001993052428588271, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0020213276147842407, Min w: 1.8216880036222622e-44\n",
      "Iteration 900, Loss: 0.0020653377287089825, Min w: 2.2251240807236172e-05\n",
      "Iteration 910, Loss: 0.0020235024858266115, Min w: 2.6929014573795484e-12\n",
      "Iteration 920, Loss: 0.0019279660191386938, Min w: 1.405019929734408e-06\n",
      "Iteration 930, Loss: 0.001992907840758562, Min w: 1.2478531186973235e-29\n",
      "Iteration 940, Loss: 0.0019698282703757286, Min w: 1.5852559065790417e-13\n",
      "Iteration 950, Loss: 0.0015241430373862386, Min w: 2.9113297883576195e-10\n",
      "Iteration 960, Loss: 0.0013717905385419726, Min w: 0.16468743979930878\n",
      "Iteration 970, Loss: 0.0010623696725815535, Min w: 0.3531959056854248\n",
      "Iteration 980, Loss: 0.0010805573547258973, Min w: 0.38303154706954956\n",
      "Iteration 990, Loss: 0.000986568396911025, Min w: 0.4594418406486511\n",
      "Iteration 1000, Loss: 0.00175159249920398, Min w: 0.01453201100230217\n",
      "Iteration 1010, Loss: 0.0012248799903318286, Min w: 0.23570768535137177\n",
      "Iteration 1020, Loss: 0.0016843554330989718, Min w: 0.015675341710448265\n",
      "Iteration 1030, Loss: 0.0018287147395312786, Min w: 0.027943413704633713\n",
      "Iteration 1040, Loss: 0.0019378529395908117, Min w: 0.003498711157590151\n",
      "Iteration 1050, Loss: 0.0014217254938557744, Min w: 0.1459304541349411\n",
      "Iteration 1060, Loss: 0.0019451609114184976, Min w: 0.007104352116584778\n",
      "Iteration 1070, Loss: 0.001975822960957885, Min w: 1.9400797555135796e-06\n",
      "Iteration 1080, Loss: 0.001968767261132598, Min w: 2.79745038539921e-17\n",
      "Iteration 1090, Loss: 0.0019908768590539694, Min w: 4.941248860003845e-15\n",
      "Iteration 1100, Loss: 0.0020126383751630783, Min w: 4.331136491120269e-11\n",
      "Iteration 1110, Loss: 0.0019696627277880907, Min w: 0.004953763913363218\n",
      "Iteration 1120, Loss: 0.0020263087935745716, Min w: 5.654861183757021e-07\n",
      "Iteration 1130, Loss: 0.0020456796046346426, Min w: 2.6433241379679193e-17\n",
      "Iteration 1140, Loss: 0.001988806063309312, Min w: 1.7616168237509194e-20\n",
      "Iteration 1150, Loss: 0.001924449810758233, Min w: 2.006505039964527e-18\n",
      "Iteration 1160, Loss: 0.0020111710764467716, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0016804719343781471, Min w: 5.869599944974269e-12\n",
      "Iteration 1180, Loss: 0.0018937045242637396, Min w: 0.03984852880239487\n",
      "Iteration 1190, Loss: 0.001816428266465664, Min w: 0.003249485744163394\n",
      "Iteration 1200, Loss: 0.0010355974081903696, Min w: 0.43449583649635315\n",
      "Iteration 1210, Loss: 0.001062831375747919, Min w: 0.44484302401542664\n",
      "Iteration 1220, Loss: 0.0008671176619827747, Min w: 0.5543466210365295\n",
      "Iteration 1230, Loss: 0.0018176031298935413, Min w: 0.05404805392026901\n",
      "Iteration 1240, Loss: 0.0014109627809375525, Min w: 0.1512567698955536\n",
      "Iteration 0, Loss: 0.00152696727309376, Min w: 0.12652264535427094\n",
      "Iteration 10, Loss: 0.0010181282414123416, Min w: 0.423734575510025\n",
      "Iteration 20, Loss: 0.0009006293257698417, Min w: 0.5322133898735046\n",
      "Iteration 30, Loss: 0.0006506823119707406, Min w: 0.5833293795585632\n",
      "Iteration 40, Loss: 0.0005883911508135498, Min w: 0.6132434010505676\n",
      "Iteration 50, Loss: 0.0005473460187204182, Min w: 0.6075906157493591\n",
      "Iteration 60, Loss: 0.0005318170296959579, Min w: 0.619673490524292\n",
      "Iteration 70, Loss: 0.0005360968061722815, Min w: 0.6164810061454773\n",
      "Iteration 80, Loss: 0.0005273853894323111, Min w: 0.6256710290908813\n",
      "Iteration 90, Loss: 0.0005003424594178796, Min w: 0.643750786781311\n",
      "Iteration 100, Loss: 0.00048756925389170647, Min w: 0.6748278737068176\n",
      "Iteration 110, Loss: 0.00044478868949227035, Min w: 0.6772701740264893\n",
      "Iteration 120, Loss: 0.0004618438542820513, Min w: 0.6622369885444641\n",
      "Iteration 130, Loss: 0.0004482796648517251, Min w: 0.6737237572669983\n",
      "Iteration 140, Loss: 0.0004935212200507522, Min w: 0.675327718257904\n",
      "Iteration 150, Loss: 0.00038114513154141605, Min w: 0.7323728799819946\n",
      "Iteration 160, Loss: 0.0003770673356484622, Min w: 0.7321200966835022\n",
      "Iteration 170, Loss: 0.0004998660879209638, Min w: 0.7098958492279053\n",
      "Iteration 180, Loss: 0.0004094886826351285, Min w: 0.7162628173828125\n",
      "Iteration 190, Loss: 0.0005132693913765252, Min w: 0.7142497301101685\n",
      "Iteration 200, Loss: 0.0004018977633677423, Min w: 0.7233518958091736\n",
      "Iteration 210, Loss: 0.0005296854651533067, Min w: 0.7075377106666565\n",
      "Iteration 220, Loss: 0.0004890725249424577, Min w: 0.7278482913970947\n",
      "Iteration 230, Loss: 0.0004770008090417832, Min w: 0.72051602602005\n",
      "Iteration 240, Loss: 0.00034658689401112497, Min w: 0.7567602396011353\n",
      "Iteration 250, Loss: 0.0005131689831614494, Min w: 0.7321041226387024\n",
      "Iteration 260, Loss: 0.00039052433567121625, Min w: 0.7578439712524414\n",
      "Iteration 270, Loss: 0.00035583865246735513, Min w: 0.7617548108100891\n",
      "Iteration 280, Loss: 0.0004165837890468538, Min w: 0.738074541091919\n",
      "Iteration 290, Loss: 0.00032985283178277314, Min w: 0.7793164253234863\n",
      "Iteration 300, Loss: 0.0003992015845142305, Min w: 0.7725440859794617\n",
      "Iteration 310, Loss: 0.0005451765027828515, Min w: 0.7150233387947083\n",
      "Iteration 320, Loss: 0.00030439739930443466, Min w: 0.794891357421875\n",
      "Iteration 330, Loss: 0.0002936915843747556, Min w: 0.8044206500053406\n",
      "Iteration 340, Loss: 0.00037052223342470825, Min w: 0.8046007752418518\n",
      "Iteration 350, Loss: 0.000356950331479311, Min w: 0.7858560085296631\n",
      "Iteration 360, Loss: 0.00040963792707771063, Min w: 0.7910571694374084\n",
      "Iteration 370, Loss: 0.0004455900052562356, Min w: 0.7632443904876709\n",
      "Iteration 380, Loss: 0.0003819986595772207, Min w: 0.7869822978973389\n",
      "Iteration 390, Loss: 0.0004033413133583963, Min w: 0.7552760243415833\n",
      "Iteration 400, Loss: 0.00033970034564845264, Min w: 0.8070155382156372\n",
      "Iteration 410, Loss: 0.00028891910915262997, Min w: 0.8282590508460999\n",
      "Iteration 420, Loss: 0.0003012916131410748, Min w: 0.8110461831092834\n",
      "Iteration 430, Loss: 0.0002876820508390665, Min w: 0.8042780160903931\n",
      "Iteration 440, Loss: 0.00034407369093969464, Min w: 0.8220443725585938\n",
      "Iteration 450, Loss: 0.0004722838057205081, Min w: 0.7030016183853149\n",
      "Iteration 460, Loss: 0.00028674231725744903, Min w: 0.8025786280632019\n",
      "Iteration 470, Loss: 0.0002639738086145371, Min w: 0.8217719197273254\n",
      "Iteration 480, Loss: 0.0003818749391939491, Min w: 0.7912904024124146\n",
      "Iteration 490, Loss: 0.0004578719672281295, Min w: 0.7372127175331116\n",
      "Iteration 500, Loss: 0.00040134479058906436, Min w: 0.784326434135437\n",
      "Iteration 510, Loss: 0.00035210649366490543, Min w: 0.8046526312828064\n",
      "Iteration 520, Loss: 0.0002326090179849416, Min w: 0.8498311638832092\n",
      "Iteration 530, Loss: 0.00023060181410983205, Min w: 0.844448983669281\n",
      "Iteration 540, Loss: 0.00022608427389059216, Min w: 0.8493698239326477\n",
      "Iteration 550, Loss: 0.0003851325309369713, Min w: 0.7915094494819641\n",
      "Iteration 560, Loss: 0.00032321541220881045, Min w: 0.7982187271118164\n",
      "Iteration 570, Loss: 0.00022791810624767095, Min w: 0.8633751273155212\n",
      "Iteration 580, Loss: 0.0003299277159385383, Min w: 0.8181925415992737\n",
      "Iteration 590, Loss: 0.00030668795807287097, Min w: 0.7910282015800476\n",
      "Iteration 600, Loss: 0.0004257582186255604, Min w: 0.736565351486206\n",
      "Iteration 610, Loss: 0.0003144266956951469, Min w: 0.8277111053466797\n",
      "Iteration 620, Loss: 0.00020308408420532942, Min w: 0.8655278086662292\n",
      "Iteration 630, Loss: 0.00034858586150221527, Min w: 0.805280327796936\n",
      "Iteration 640, Loss: 0.00025093049043789506, Min w: 0.8564438819885254\n",
      "Iteration 650, Loss: 0.00037445517955347896, Min w: 0.7808132767677307\n",
      "Iteration 660, Loss: 0.0002514693478588015, Min w: 0.8532883524894714\n",
      "Iteration 670, Loss: 0.0002609702933114022, Min w: 0.8639152646064758\n",
      "Iteration 680, Loss: 0.00032623004517517984, Min w: 0.8261554837226868\n",
      "Iteration 690, Loss: 0.0002101510763168335, Min w: 0.8853757381439209\n",
      "Iteration 700, Loss: 0.00036435527727007866, Min w: 0.7618429660797119\n",
      "Iteration 710, Loss: 0.00020977533131372184, Min w: 0.8867868185043335\n",
      "Iteration 720, Loss: 0.00029811618151143193, Min w: 0.835411787033081\n",
      "Iteration 730, Loss: 0.00016747674089856446, Min w: 0.8904114365577698\n",
      "Iteration 740, Loss: 0.00022092116705607623, Min w: 0.874521017074585\n",
      "Iteration 750, Loss: 0.0002993676462210715, Min w: 0.8149969577789307\n",
      "Iteration 760, Loss: 0.00047907105181366205, Min w: 0.7171716690063477\n",
      "Iteration 770, Loss: 0.00020272927940823138, Min w: 0.8902302980422974\n",
      "Iteration 780, Loss: 0.0002911238116212189, Min w: 0.8257089257240295\n",
      "Iteration 790, Loss: 0.00022150564473122358, Min w: 0.8822652101516724\n",
      "Iteration 800, Loss: 0.00018892624939326197, Min w: 0.9013018012046814\n",
      "Iteration 810, Loss: 0.0002842509129550308, Min w: 0.8529806137084961\n",
      "Iteration 820, Loss: 0.0003135862643830478, Min w: 0.8035444617271423\n",
      "Iteration 830, Loss: 0.0003945775097236037, Min w: 0.750856876373291\n",
      "Iteration 840, Loss: 0.00028902379563078284, Min w: 0.8219940066337585\n",
      "Iteration 850, Loss: 0.0001691103825578466, Min w: 0.9051644206047058\n",
      "Iteration 860, Loss: 0.00014899052621331066, Min w: 0.9047685265541077\n",
      "Iteration 870, Loss: 0.00023841237998567522, Min w: 0.8526941537857056\n",
      "Iteration 880, Loss: 0.00027440101257525384, Min w: 0.8313217759132385\n",
      "Iteration 890, Loss: 0.00034557393519207835, Min w: 0.7921726703643799\n",
      "Iteration 900, Loss: 0.00019308965420350432, Min w: 0.8902602791786194\n",
      "Iteration 910, Loss: 0.0001392191625200212, Min w: 0.9151431918144226\n",
      "Iteration 920, Loss: 0.00023177229741122574, Min w: 0.8630985617637634\n",
      "Iteration 930, Loss: 0.0003023089957423508, Min w: 0.8260873556137085\n",
      "Iteration 940, Loss: 0.00013543525710701942, Min w: 0.9184467792510986\n",
      "Iteration 950, Loss: 0.00031147574190981686, Min w: 0.8080623149871826\n",
      "Iteration 960, Loss: 0.00039961663424037397, Min w: 0.7414726614952087\n",
      "Iteration 970, Loss: 0.00022820095182396472, Min w: 0.8498828411102295\n",
      "Iteration 980, Loss: 0.00012780568795278668, Min w: 0.9277224540710449\n",
      "Iteration 990, Loss: 0.00017153017688542604, Min w: 0.9075964689254761\n",
      "Iteration 1000, Loss: 0.00021076224220450968, Min w: 0.8730930089950562\n",
      "Iteration 1010, Loss: 0.0002682683989405632, Min w: 0.8192314505577087\n",
      "Iteration 1020, Loss: 0.00026761958724819124, Min w: 0.8527677655220032\n",
      "Iteration 1030, Loss: 0.00011833391181426123, Min w: 0.9253736734390259\n",
      "Iteration 1040, Loss: 0.000307764217723161, Min w: 0.7936961650848389\n",
      "Iteration 1050, Loss: 0.00026167536270804703, Min w: 0.8224648237228394\n",
      "Iteration 1060, Loss: 0.0001166748843388632, Min w: 0.9316124320030212\n",
      "Iteration 1070, Loss: 0.00012803722347598523, Min w: 0.9150669574737549\n",
      "Iteration 1080, Loss: 0.00011176364932907745, Min w: 0.93439120054245\n",
      "Iteration 1090, Loss: 0.00015246693510562181, Min w: 0.9144465327262878\n",
      "Iteration 1100, Loss: 0.00013692129869014025, Min w: 0.9259738922119141\n",
      "Iteration 1110, Loss: 0.00011551586067071185, Min w: 0.9348208904266357\n",
      "Iteration 1120, Loss: 0.00018380911205895245, Min w: 0.8891571164131165\n",
      "Iteration 1130, Loss: 0.00014585518511012197, Min w: 0.9251974821090698\n",
      "Iteration 1140, Loss: 0.00032759548048488796, Min w: 0.7858489751815796\n",
      "Iteration 1150, Loss: 0.00020360859343782067, Min w: 0.8836883306503296\n",
      "Iteration 1160, Loss: 0.00012066715135006234, Min w: 0.9326304793357849\n",
      "Iteration 1170, Loss: 0.0001431190175935626, Min w: 0.9237591028213501\n",
      "Iteration 1180, Loss: 0.00015900506696198136, Min w: 0.9051832556724548\n",
      "Iteration 1190, Loss: 0.00034617198980413377, Min w: 0.7386215329170227\n",
      "Iteration 1200, Loss: 0.00013686726742889732, Min w: 0.9146463871002197\n",
      "Iteration 1210, Loss: 9.991517435992137e-05, Min w: 0.945424497127533\n",
      "Iteration 1220, Loss: 0.0002188139915233478, Min w: 0.8601995706558228\n",
      "Iteration 1230, Loss: 0.00030979159055277705, Min w: 0.7767371535301208\n",
      "Iteration 1240, Loss: 0.0003159354964736849, Min w: 0.7959211468696594\n",
      "Iteration 0, Loss: 0.00010757717973319814, Min w: 0.9422269463539124\n",
      "Iteration 10, Loss: 0.00013200963439885527, Min w: 0.9185940623283386\n",
      "Iteration 20, Loss: 0.00020842977392021567, Min w: 0.8578100204467773\n",
      "Iteration 30, Loss: 0.00014594820095226169, Min w: 0.9058323502540588\n",
      "Iteration 40, Loss: 0.00012245240213815123, Min w: 0.9334078431129456\n",
      "Iteration 50, Loss: 0.00018083977920468897, Min w: 0.8850439190864563\n",
      "Iteration 60, Loss: 8.83775792317465e-05, Min w: 0.9486637115478516\n",
      "Iteration 70, Loss: 0.00016284147568512708, Min w: 0.8990135788917542\n",
      "Iteration 80, Loss: 0.00018511293455958366, Min w: 0.8684741854667664\n",
      "Iteration 90, Loss: 0.00010487648978596553, Min w: 0.9435060620307922\n",
      "Iteration 100, Loss: 0.0001621487463125959, Min w: 0.9072096347808838\n",
      "Iteration 110, Loss: 0.0002118728734785691, Min w: 0.8657077550888062\n",
      "Iteration 120, Loss: 0.00026639620773494244, Min w: 0.8201068043708801\n",
      "Iteration 130, Loss: 0.00031751900678500533, Min w: 0.7874384522438049\n",
      "Iteration 140, Loss: 0.00010885879601119086, Min w: 0.9379206299781799\n",
      "Iteration 150, Loss: 0.00017532522906549275, Min w: 0.8956255316734314\n",
      "Iteration 160, Loss: 9.180628694593906e-05, Min w: 0.9444637298583984\n",
      "Iteration 170, Loss: 0.00021897362603340298, Min w: 0.8462601900100708\n",
      "Iteration 180, Loss: 0.00016342231538146734, Min w: 0.8958654403686523\n",
      "Iteration 190, Loss: 0.00016852204862516373, Min w: 0.8950042128562927\n",
      "Iteration 200, Loss: 6.67124695610255e-05, Min w: 0.9622772932052612\n",
      "Iteration 210, Loss: 0.0001044841919792816, Min w: 0.934600830078125\n",
      "Iteration 220, Loss: 6.705934356432408e-05, Min w: 0.959618866443634\n",
      "Iteration 230, Loss: 7.156447099987417e-05, Min w: 0.9565352201461792\n",
      "Iteration 240, Loss: 7.421134068863466e-05, Min w: 0.9616178274154663\n",
      "Iteration 250, Loss: 0.00015964558406267315, Min w: 0.8932995200157166\n",
      "Iteration 260, Loss: 6.962063343962654e-05, Min w: 0.9611467123031616\n",
      "Iteration 270, Loss: 0.00010945366375381127, Min w: 0.9334096908569336\n",
      "Iteration 280, Loss: 0.00016212844639085233, Min w: 0.8764160871505737\n",
      "Iteration 290, Loss: 0.00016635913925711066, Min w: 0.8888329267501831\n",
      "Iteration 300, Loss: 0.00016172154573723674, Min w: 0.8781496286392212\n",
      "Iteration 310, Loss: 0.00010765473416540772, Min w: 0.9312822222709656\n",
      "Iteration 320, Loss: 0.00015048038039822131, Min w: 0.8975756168365479\n",
      "Iteration 330, Loss: 0.00020146720635239035, Min w: 0.8621972799301147\n",
      "Iteration 340, Loss: 0.00011821531370515004, Min w: 0.9306508898735046\n",
      "Iteration 350, Loss: 0.00023607803450431675, Min w: 0.8398296236991882\n",
      "Iteration 360, Loss: 0.0001955566112883389, Min w: 0.8570088744163513\n",
      "Iteration 370, Loss: 9.955783752957359e-05, Min w: 0.9362580180168152\n",
      "Iteration 380, Loss: 0.00010583988478174433, Min w: 0.9410870671272278\n",
      "Iteration 390, Loss: 8.659892773721367e-05, Min w: 0.9458280801773071\n",
      "Iteration 400, Loss: 0.0001156042271759361, Min w: 0.9307769536972046\n",
      "Iteration 410, Loss: 0.0001465253735659644, Min w: 0.908058762550354\n",
      "Iteration 420, Loss: 6.426138133974746e-05, Min w: 0.9657201170921326\n",
      "Iteration 430, Loss: 9.467738709645346e-05, Min w: 0.9461144804954529\n",
      "Iteration 440, Loss: 8.704634819878265e-05, Min w: 0.9514050483703613\n",
      "Iteration 450, Loss: 0.00016358500579372048, Min w: 0.8867267370223999\n",
      "Iteration 460, Loss: 0.00033585363416932523, Min w: 0.7515731453895569\n",
      "Iteration 470, Loss: 0.00014768913388252258, Min w: 0.902160108089447\n",
      "Iteration 480, Loss: 0.00012808172323275357, Min w: 0.9051128625869751\n",
      "Iteration 490, Loss: 0.000249891250859946, Min w: 0.8021789789199829\n",
      "Iteration 500, Loss: 5.637236245092936e-05, Min w: 0.9701331257820129\n",
      "Iteration 510, Loss: 5.8572615671437234e-05, Min w: 0.9692777991294861\n",
      "Iteration 520, Loss: 0.00023343504290096462, Min w: 0.8341138362884521\n",
      "Iteration 530, Loss: 5.503829015651718e-05, Min w: 0.9714208841323853\n",
      "Iteration 540, Loss: 6.449301145039499e-05, Min w: 0.9628558158874512\n",
      "Iteration 550, Loss: 0.00035418092738837004, Min w: 0.7322666645050049\n",
      "Iteration 560, Loss: 0.0001569214218761772, Min w: 0.8871099352836609\n",
      "Iteration 570, Loss: 6.464966281782836e-05, Min w: 0.9628036618232727\n",
      "Iteration 580, Loss: 8.054587669903412e-05, Min w: 0.9477691054344177\n",
      "Iteration 590, Loss: 5.65298723813612e-05, Min w: 0.9677411317825317\n",
      "Iteration 600, Loss: 6.602736539207399e-05, Min w: 0.9619413018226624\n",
      "Iteration 610, Loss: 0.0005901937838643789, Min w: 0.573898434638977\n",
      "Iteration 620, Loss: 5.4972322686808184e-05, Min w: 0.9699394106864929\n",
      "Iteration 630, Loss: 6.594771548407152e-05, Min w: 0.9618512988090515\n",
      "Iteration 640, Loss: 0.00013653721543960273, Min w: 0.901048481464386\n",
      "Iteration 650, Loss: 0.00019515147141646594, Min w: 0.854038417339325\n",
      "Iteration 660, Loss: 0.0002665181818883866, Min w: 0.7936139702796936\n",
      "Iteration 670, Loss: 5.846629210282117e-05, Min w: 0.9664582014083862\n",
      "Iteration 680, Loss: 0.00013263412984088063, Min w: 0.9045488238334656\n",
      "Iteration 690, Loss: 8.33252415759489e-05, Min w: 0.9474093317985535\n",
      "Iteration 700, Loss: 5.224511187407188e-05, Min w: 0.9719030261039734\n",
      "Iteration 710, Loss: 0.00022351156803779304, Min w: 0.818283200263977\n",
      "Iteration 720, Loss: 5.062368290964514e-05, Min w: 0.9728692770004272\n",
      "Iteration 730, Loss: 7.500805077143013e-05, Min w: 0.9569881558418274\n",
      "Iteration 740, Loss: 0.0001804176572477445, Min w: 0.8788583278656006\n",
      "Iteration 750, Loss: 0.00020825518004130572, Min w: 0.847216784954071\n",
      "Iteration 760, Loss: 4.2329476855229586e-05, Min w: 0.9779741168022156\n",
      "Iteration 770, Loss: 7.135078340070322e-05, Min w: 0.9543746113777161\n",
      "Iteration 780, Loss: 4.921187792206183e-05, Min w: 0.9727657437324524\n",
      "Iteration 790, Loss: 8.750766573939472e-05, Min w: 0.9426097869873047\n",
      "Iteration 800, Loss: 0.00012810570478904992, Min w: 0.9083016514778137\n",
      "Iteration 810, Loss: 5.904676072532311e-05, Min w: 0.967439591884613\n",
      "Iteration 820, Loss: 0.0001400037872372195, Min w: 0.909636378288269\n",
      "Iteration 830, Loss: 0.00019302837608847767, Min w: 0.8627925515174866\n",
      "Iteration 840, Loss: 0.00024927148479036987, Min w: 0.7982560992240906\n",
      "Iteration 850, Loss: 3.895755799021572e-05, Min w: 0.9788143038749695\n",
      "Iteration 860, Loss: 0.00025725518935360014, Min w: 0.806925892829895\n",
      "Iteration 870, Loss: 0.00025805181940086186, Min w: 0.8055899143218994\n",
      "Iteration 880, Loss: 0.00023482974211219698, Min w: 0.8094251155853271\n",
      "Iteration 890, Loss: 4.860839180764742e-05, Min w: 0.9711703062057495\n",
      "Iteration 900, Loss: 5.310485721565783e-05, Min w: 0.9655923247337341\n",
      "Iteration 910, Loss: 0.00014069357712287456, Min w: 0.9026444554328918\n",
      "Iteration 920, Loss: 0.0001100444351322949, Min w: 0.925639808177948\n",
      "Iteration 930, Loss: 0.00015728983271401376, Min w: 0.8849899768829346\n",
      "Iteration 940, Loss: 7.517835183534771e-05, Min w: 0.9438989162445068\n",
      "Iteration 950, Loss: 6.66966661810875e-05, Min w: 0.9582154750823975\n",
      "Iteration 960, Loss: 7.334190740948543e-05, Min w: 0.9564452171325684\n",
      "Iteration 970, Loss: 0.00018729270959738642, Min w: 0.85428786277771\n",
      "Iteration 980, Loss: 0.00012198246258776635, Min w: 0.9035715460777283\n",
      "Iteration 990, Loss: 5.3241787099977955e-05, Min w: 0.9683277606964111\n",
      "Iteration 1000, Loss: 5.260000398266129e-05, Min w: 0.9660089015960693\n",
      "Iteration 1010, Loss: 6.45699692540802e-05, Min w: 0.9573192000389099\n",
      "Iteration 1020, Loss: 9.092110849451274e-05, Min w: 0.9343996047973633\n",
      "Iteration 1030, Loss: 4.387331864563748e-05, Min w: 0.9774306416511536\n",
      "Iteration 1040, Loss: 0.00026839066413231194, Min w: 0.7820655107498169\n",
      "Iteration 1050, Loss: 0.00021578815358225256, Min w: 0.8417702913284302\n",
      "Iteration 1060, Loss: 0.0001746671332512051, Min w: 0.8658363819122314\n",
      "Iteration 1070, Loss: 0.00015446105680894107, Min w: 0.8835664987564087\n",
      "Iteration 1080, Loss: 0.00015478501154575497, Min w: 0.8749217987060547\n",
      "Iteration 1090, Loss: 4.972304668626748e-05, Min w: 0.9670863151550293\n",
      "Iteration 1100, Loss: 3.787644163821824e-05, Min w: 0.9777112007141113\n",
      "Iteration 1110, Loss: 4.201385672786273e-05, Min w: 0.9729268550872803\n",
      "Iteration 1120, Loss: 5.3328698413679376e-05, Min w: 0.969646155834198\n",
      "Iteration 1130, Loss: 0.00022452912526205182, Min w: 0.8275859355926514\n",
      "Iteration 1140, Loss: 0.00010226195445284247, Min w: 0.9320186376571655\n",
      "Iteration 1150, Loss: 9.136383596342057e-05, Min w: 0.9301621317863464\n",
      "Iteration 1160, Loss: 0.00018298217037227005, Min w: 0.8900437355041504\n",
      "Iteration 1170, Loss: 0.00011913866183022037, Min w: 0.9031395316123962\n",
      "Iteration 1180, Loss: 3.1059138564160094e-05, Min w: 0.9838196635246277\n",
      "Iteration 1190, Loss: 0.00024038013361860067, Min w: 0.8145933151245117\n",
      "Iteration 1200, Loss: 0.00022528723638970405, Min w: 0.8248358368873596\n",
      "Iteration 1210, Loss: 7.825588545529172e-05, Min w: 0.9380033016204834\n",
      "Iteration 1220, Loss: 0.00013116205809637904, Min w: 0.9132596850395203\n",
      "Iteration 1230, Loss: 0.00012351428449619561, Min w: 0.8972330093383789\n",
      "Iteration 1240, Loss: 8.046989387366921e-05, Min w: 0.9557601809501648\n",
      "Iteration 0, Loss: 0.00016669847536832094, Min w: 0.8604804873466492\n",
      "Iteration 10, Loss: 3.7232031900202855e-05, Min w: 0.978358805179596\n",
      "Iteration 20, Loss: 0.0001364276249660179, Min w: 0.9079396724700928\n",
      "Iteration 30, Loss: 5.423492984846234e-05, Min w: 0.9597194194793701\n",
      "Iteration 40, Loss: 7.734724931651726e-05, Min w: 0.9531826376914978\n",
      "Iteration 50, Loss: 0.00017402875528205186, Min w: 0.8638758063316345\n",
      "Iteration 60, Loss: 0.00027570081874728203, Min w: 0.7923136353492737\n",
      "Iteration 70, Loss: 0.0001888448023237288, Min w: 0.8402206301689148\n",
      "Iteration 80, Loss: 8.014082413865253e-05, Min w: 0.9566839337348938\n",
      "Iteration 90, Loss: 5.3716968977823853e-05, Min w: 0.9676359295845032\n",
      "Iteration 100, Loss: 9.48656743275933e-05, Min w: 0.9417819380760193\n",
      "Iteration 110, Loss: 0.00012870150385424495, Min w: 0.8945865631103516\n",
      "Iteration 120, Loss: 0.00014379335334524512, Min w: 0.9118547439575195\n",
      "Iteration 130, Loss: 8.255549619207159e-05, Min w: 0.9392407536506653\n",
      "Iteration 140, Loss: 0.00018352014012634754, Min w: 0.8485198020935059\n",
      "Iteration 150, Loss: 0.0002466404694132507, Min w: 0.7995403409004211\n",
      "Iteration 160, Loss: 0.0001337975263595581, Min w: 0.8914952874183655\n",
      "Iteration 170, Loss: 0.00012915812840219587, Min w: 0.89926677942276\n",
      "Iteration 180, Loss: 0.00018189121328759938, Min w: 0.8667331337928772\n",
      "Iteration 190, Loss: 3.6075660318601876e-05, Min w: 0.9810706377029419\n",
      "Iteration 200, Loss: 0.00018260958313476294, Min w: 0.8451804518699646\n",
      "Iteration 210, Loss: 8.024339331313968e-05, Min w: 0.9403197169303894\n",
      "Iteration 220, Loss: 4.338869621278718e-05, Min w: 0.9756457805633545\n",
      "Iteration 230, Loss: 0.00023625405447091907, Min w: 0.8204620480537415\n",
      "Iteration 240, Loss: 9.679608774604276e-05, Min w: 0.9324569702148438\n",
      "Iteration 250, Loss: 5.544385203393176e-05, Min w: 0.9585678577423096\n",
      "Iteration 260, Loss: 0.00034444467746652663, Min w: 0.757655143737793\n",
      "Iteration 270, Loss: 3.822765211225487e-05, Min w: 0.9762974381446838\n",
      "Iteration 280, Loss: 6.114297138992697e-05, Min w: 0.9560533165931702\n",
      "Iteration 290, Loss: 9.274326293962076e-05, Min w: 0.9279179573059082\n",
      "Iteration 300, Loss: 0.00013197834778111428, Min w: 0.8966390490531921\n",
      "Iteration 310, Loss: 4.571830868371762e-05, Min w: 0.9700449705123901\n",
      "Iteration 320, Loss: 0.0003268241707701236, Min w: 0.7575981020927429\n",
      "Iteration 330, Loss: 0.00025067475507967174, Min w: 0.7891411781311035\n",
      "Iteration 340, Loss: 0.00012226255785208195, Min w: 0.9216924905776978\n",
      "Iteration 350, Loss: 0.00010142600513063371, Min w: 0.9129798412322998\n",
      "Iteration 360, Loss: 8.988407353172079e-05, Min w: 0.9454764723777771\n",
      "Iteration 370, Loss: 9.286581189371645e-05, Min w: 0.9222214818000793\n",
      "Iteration 380, Loss: 0.0002446955186314881, Min w: 0.8278244137763977\n",
      "Iteration 390, Loss: 0.0002181417657993734, Min w: 0.8206014037132263\n",
      "Iteration 400, Loss: 0.00028085755184292793, Min w: 0.7592238187789917\n",
      "Iteration 410, Loss: 3.9400394598487765e-05, Min w: 0.9772523641586304\n",
      "Iteration 420, Loss: 6.465288606705144e-05, Min w: 0.9588158130645752\n",
      "Iteration 430, Loss: 0.0002638116420712322, Min w: 0.7786135077476501\n",
      "Iteration 440, Loss: 0.0001613020576769486, Min w: 0.8779738545417786\n",
      "Iteration 450, Loss: 7.352526881732047e-05, Min w: 0.9427440762519836\n",
      "Iteration 460, Loss: 4.210968836559914e-05, Min w: 0.9724501967430115\n",
      "Iteration 470, Loss: 7.5650452345144e-05, Min w: 0.9373904466629028\n",
      "Iteration 480, Loss: 8.205424819607288e-05, Min w: 0.9329610466957092\n",
      "Iteration 490, Loss: 0.0005616943235509098, Min w: 0.5723381638526917\n",
      "Iteration 500, Loss: 0.000367607397492975, Min w: 0.6977704763412476\n",
      "Iteration 510, Loss: 0.00020849106658715755, Min w: 0.856855034828186\n",
      "Iteration 520, Loss: 0.00013635872164741158, Min w: 0.9089710712432861\n",
      "Iteration 530, Loss: 7.33143460820429e-05, Min w: 0.9390144348144531\n",
      "Iteration 540, Loss: 0.0003863460442516953, Min w: 0.7190874814987183\n",
      "Iteration 550, Loss: 0.0007055620080791414, Min w: 0.4752584397792816\n",
      "Iteration 560, Loss: 0.00035669602220878005, Min w: 0.7262230515480042\n",
      "Iteration 570, Loss: 0.00013794419646728784, Min w: 0.9062047600746155\n",
      "Iteration 580, Loss: 0.0005024241982027888, Min w: 0.6049773097038269\n",
      "Iteration 590, Loss: 0.00045136307016946375, Min w: 0.6529412269592285\n",
      "Iteration 600, Loss: 7.992598693817854e-05, Min w: 0.9288721680641174\n",
      "Iteration 610, Loss: 0.00018979021115228534, Min w: 0.8425908088684082\n",
      "Iteration 620, Loss: 0.00017779732297640294, Min w: 0.8485689163208008\n",
      "Iteration 630, Loss: 3.599034243961796e-05, Min w: 0.9761496186256409\n",
      "Iteration 640, Loss: 0.0001330196828348562, Min w: 0.9065125584602356\n",
      "Iteration 650, Loss: 7.049644773360342e-05, Min w: 0.9447738528251648\n",
      "Iteration 660, Loss: 3.548376480466686e-05, Min w: 0.9788487553596497\n",
      "Iteration 670, Loss: 6.472961831605062e-05, Min w: 0.9590204954147339\n",
      "Iteration 680, Loss: 8.968457404989749e-05, Min w: 0.9288671016693115\n",
      "Iteration 690, Loss: 8.572835940867662e-05, Min w: 0.9323406219482422\n",
      "Iteration 700, Loss: 4.25271391577553e-05, Min w: 0.9688282608985901\n",
      "Iteration 710, Loss: 6.058885992388241e-05, Min w: 0.9553508758544922\n",
      "Iteration 720, Loss: 4.4134729250799865e-05, Min w: 0.9676797389984131\n",
      "Iteration 730, Loss: 5.7302786444779485e-05, Min w: 0.9579092860221863\n",
      "Iteration 740, Loss: 7.41014737286605e-05, Min w: 0.9435513615608215\n",
      "Iteration 750, Loss: 3.271512105129659e-05, Min w: 0.9790183901786804\n",
      "Iteration 760, Loss: 0.00010074742749566212, Min w: 0.9188525676727295\n",
      "Iteration 770, Loss: 2.339425373065751e-05, Min w: 0.9861291646957397\n",
      "Iteration 780, Loss: 0.00010784812911879271, Min w: 0.9185289740562439\n",
      "Iteration 790, Loss: 0.0001113486650865525, Min w: 0.9140840172767639\n",
      "Iteration 800, Loss: 3.1092436984181404e-05, Min w: 0.9792286157608032\n",
      "Iteration 810, Loss: 4.106461346964352e-05, Min w: 0.9700654745101929\n",
      "Iteration 820, Loss: 4.6030556404730305e-05, Min w: 0.9700784683227539\n",
      "Iteration 830, Loss: 6.557744927704334e-05, Min w: 0.9495862722396851\n",
      "Iteration 840, Loss: 5.5877935665193945e-05, Min w: 0.9553401470184326\n",
      "Iteration 850, Loss: 0.00018149116658605635, Min w: 0.8413575887680054\n",
      "Iteration 860, Loss: 6.0899903473909944e-05, Min w: 0.9569193720817566\n",
      "Iteration 870, Loss: 8.785701356828213e-05, Min w: 0.9213330745697021\n",
      "Iteration 880, Loss: 0.00010822418698808178, Min w: 0.9135271906852722\n",
      "Iteration 890, Loss: 0.0001668076147325337, Min w: 0.8683405518531799\n",
      "Iteration 900, Loss: 2.274074540764559e-05, Min w: 0.9861708879470825\n",
      "Iteration 910, Loss: 0.0001472174481023103, Min w: 0.8750665187835693\n",
      "Iteration 920, Loss: 9.491125092608854e-05, Min w: 0.9249060750007629\n",
      "Iteration 930, Loss: 0.00022538038319908082, Min w: 0.8303255438804626\n",
      "Iteration 940, Loss: 2.4817902158247307e-05, Min w: 0.9840688705444336\n",
      "Iteration 950, Loss: 0.00012751005124300718, Min w: 0.8990861177444458\n",
      "Iteration 960, Loss: 0.0001581101823830977, Min w: 0.8791995048522949\n",
      "Iteration 970, Loss: 0.00013658765237778425, Min w: 0.8879241943359375\n",
      "Iteration 980, Loss: 0.0001290052168769762, Min w: 0.8889867663383484\n",
      "Iteration 990, Loss: 0.00014477786317002028, Min w: 0.8884961009025574\n",
      "Iteration 1000, Loss: 0.00013837410369887948, Min w: 0.9019787311553955\n",
      "Iteration 1010, Loss: 0.00012045486073475331, Min w: 0.9202734231948853\n",
      "Iteration 1020, Loss: 6.824656156823039e-05, Min w: 0.9545056819915771\n",
      "Iteration 1030, Loss: 0.00022393764811567962, Min w: 0.8204720616340637\n",
      "Iteration 1040, Loss: 0.0001922027295222506, Min w: 0.8489317893981934\n",
      "Iteration 1050, Loss: 2.4444032533210702e-05, Min w: 0.9869744181632996\n",
      "Iteration 1060, Loss: 0.00021280627697706223, Min w: 0.8181186318397522\n",
      "Iteration 1070, Loss: 2.6887071726378053e-05, Min w: 0.983735978603363\n",
      "Iteration 1080, Loss: 0.00011633756366791204, Min w: 0.9068833589553833\n",
      "Iteration 1090, Loss: 2.5279221517848782e-05, Min w: 0.9860115647315979\n",
      "Iteration 1100, Loss: 0.00021235458552837372, Min w: 0.8472972512245178\n",
      "Iteration 1110, Loss: 0.0002206287463195622, Min w: 0.8311389684677124\n",
      "Iteration 1120, Loss: 6.288734584813938e-05, Min w: 0.9499272108078003\n",
      "Iteration 1130, Loss: 3.665851545520127e-05, Min w: 0.9809212684631348\n",
      "Iteration 1140, Loss: 9.644937381381169e-05, Min w: 0.9257123470306396\n",
      "Iteration 1150, Loss: 6.688533176202327e-05, Min w: 0.9461444616317749\n",
      "Iteration 1160, Loss: 9.659375791670755e-05, Min w: 0.9166551828384399\n",
      "Iteration 1170, Loss: 7.899041520431638e-05, Min w: 0.931308925151825\n",
      "Iteration 1180, Loss: 0.00012474332470446825, Min w: 0.8884419798851013\n",
      "Iteration 1190, Loss: 6.015642065904103e-05, Min w: 0.9559266567230225\n",
      "Iteration 1200, Loss: 0.0002047680172836408, Min w: 0.8542848229408264\n",
      "Iteration 1210, Loss: 0.00012066365889040753, Min w: 0.9152244329452515\n",
      "Iteration 1220, Loss: 3.930046659661457e-05, Min w: 0.9726542830467224\n",
      "Iteration 1230, Loss: 5.6915319873951375e-05, Min w: 0.9631797671318054\n",
      "Iteration 1240, Loss: 3.53693867509719e-05, Min w: 0.9771364331245422\n",
      "Iteration 0, Loss: 0.00018611669656820595, Min w: 0.8767333030700684\n",
      "Iteration 10, Loss: 8.176559640560299e-05, Min w: 0.9421395063400269\n",
      "Iteration 20, Loss: 3.071478204219602e-05, Min w: 0.9815662503242493\n",
      "Iteration 30, Loss: 0.00010667898459360003, Min w: 0.9244092106819153\n",
      "Iteration 40, Loss: 3.499043305055238e-05, Min w: 0.9793156385421753\n",
      "Iteration 50, Loss: 4.295292455935851e-05, Min w: 0.970690906047821\n",
      "Iteration 60, Loss: 0.0001749945367919281, Min w: 0.8419998288154602\n",
      "Iteration 70, Loss: 0.00012353752390481532, Min w: 0.8887456059455872\n",
      "Iteration 80, Loss: 8.07854812592268e-05, Min w: 0.9288841485977173\n",
      "Iteration 90, Loss: 5.1420411182334647e-05, Min w: 0.9574470520019531\n",
      "Iteration 100, Loss: 0.00020483194384723902, Min w: 0.8306915163993835\n",
      "Iteration 110, Loss: 0.0001432425924576819, Min w: 0.8853360414505005\n",
      "Iteration 120, Loss: 2.3952856281539425e-05, Min w: 0.9847368001937866\n",
      "Iteration 130, Loss: 0.0001995961501961574, Min w: 0.8234244585037231\n",
      "Iteration 140, Loss: 6.617126928176731e-05, Min w: 0.9444618821144104\n",
      "Iteration 150, Loss: 2.0090990801691078e-05, Min w: 0.986182451248169\n",
      "Iteration 160, Loss: 0.00013374941772781312, Min w: 0.8976103663444519\n",
      "Iteration 170, Loss: 0.00014663871843367815, Min w: 0.8771798014640808\n",
      "Iteration 180, Loss: 0.00019107350090052933, Min w: 0.823499858379364\n",
      "Iteration 190, Loss: 0.00019180914387106895, Min w: 0.8244535326957703\n",
      "Iteration 200, Loss: 0.00017576782556716353, Min w: 0.8354542851448059\n",
      "Iteration 210, Loss: 0.00013813175610266626, Min w: 0.8772794008255005\n",
      "Iteration 220, Loss: 4.055272802361287e-05, Min w: 0.9665284752845764\n",
      "Iteration 230, Loss: 0.00021626136731356382, Min w: 0.8324796557426453\n",
      "Iteration 240, Loss: 4.365009954199195e-05, Min w: 0.9689769148826599\n",
      "Iteration 250, Loss: 7.213978096842766e-05, Min w: 0.9609948992729187\n",
      "Iteration 260, Loss: 0.00015679262287449092, Min w: 0.8902440667152405\n",
      "Iteration 270, Loss: 9.138292080024257e-05, Min w: 0.9457152485847473\n",
      "Iteration 280, Loss: 0.0001494202297180891, Min w: 0.8859128355979919\n",
      "Iteration 290, Loss: 8.9733672211878e-05, Min w: 0.9240954518318176\n",
      "Iteration 300, Loss: 3.462722816038877e-05, Min w: 0.9799755811691284\n",
      "Iteration 310, Loss: 4.935059405397624e-05, Min w: 0.9657684564590454\n",
      "Iteration 320, Loss: 0.00022518770128954202, Min w: 0.8236303329467773\n",
      "Iteration 330, Loss: 0.00013187574222683907, Min w: 0.9130317568778992\n",
      "Iteration 340, Loss: 0.00011586867913138121, Min w: 0.918376088142395\n",
      "Iteration 350, Loss: 0.00013228811440058053, Min w: 0.8931589722633362\n",
      "Iteration 360, Loss: 0.0001747573696775362, Min w: 0.8721498847007751\n",
      "Iteration 370, Loss: 3.189275594195351e-05, Min w: 0.9754400253295898\n",
      "Iteration 380, Loss: 8.557847468182445e-05, Min w: 0.9299319386482239\n",
      "Iteration 390, Loss: 0.00023817563487682492, Min w: 0.8160035014152527\n",
      "Iteration 400, Loss: 4.198060923954472e-05, Min w: 0.9668002724647522\n",
      "Iteration 410, Loss: 4.6163266233634204e-05, Min w: 0.9664710760116577\n",
      "Iteration 420, Loss: 1.9326345864101313e-05, Min w: 0.9881009459495544\n",
      "Iteration 430, Loss: 0.0002476304944138974, Min w: 0.8639957308769226\n",
      "Iteration 440, Loss: 3.1646646675653756e-05, Min w: 0.9770904779434204\n",
      "Iteration 450, Loss: 7.18063602107577e-05, Min w: 0.960983157157898\n",
      "Iteration 460, Loss: 0.00119623017963022, Min w: 0.05930887907743454\n",
      "Iteration 470, Loss: 0.002026979112997651, Min w: 5.715092356695095e-06\n",
      "Iteration 480, Loss: 0.0020516840741038322, Min w: 1.353302877760143e-06\n",
      "Iteration 490, Loss: 0.002000285079702735, Min w: 4.858502176302482e-23\n",
      "Iteration 500, Loss: 0.001904255012050271, Min w: 2.5757206358555627e-14\n",
      "Iteration 510, Loss: 0.002122553065419197, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0021011177450418472, Min w: 6.754842982898518e-29\n",
      "Iteration 530, Loss: 0.0019868374802172184, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0020360625348985195, Min w: 5.1245050638010484e-21\n",
      "Iteration 550, Loss: 0.0020270796958357096, Min w: 3.374493609889506e-12\n",
      "Iteration 560, Loss: 0.002008395968005061, Min w: 1.8994622763557345e-08\n",
      "Iteration 570, Loss: 0.0017290095565840602, Min w: 3.1157147972749044e-09\n",
      "Iteration 580, Loss: 0.0019940168131142855, Min w: 0.00019163016986567527\n",
      "Iteration 590, Loss: 0.0019840002059936523, Min w: 1.703081336004816e-17\n",
      "Iteration 600, Loss: 0.0020288657397031784, Min w: 7.290549558127202e-17\n",
      "Iteration 610, Loss: 0.002026389120146632, Min w: 7.531028578533494e-11\n",
      "Iteration 620, Loss: 0.0017381367506459355, Min w: 0.0002910166804213077\n",
      "Iteration 630, Loss: 0.0010109192226082087, Min w: 0.47961992025375366\n",
      "Iteration 640, Loss: 0.001756748417392373, Min w: 0.019122034311294556\n",
      "Iteration 650, Loss: 0.0019598875660449266, Min w: 6.706923159072176e-05\n",
      "Iteration 660, Loss: 0.0020115950610488653, Min w: 5.4182139137992635e-05\n",
      "Iteration 670, Loss: 0.002073385287076235, Min w: 2.589130053820554e-05\n",
      "Iteration 680, Loss: 0.002118024742230773, Min w: 5.913807219601786e-16\n",
      "Iteration 690, Loss: 0.001994839869439602, Min w: 1.2525504081289834e-37\n",
      "Iteration 700, Loss: 0.00200927653349936, Min w: 1.0036473533738817e-27\n",
      "Iteration 710, Loss: 0.0019797736313194036, Min w: 4.2240325820452895e-11\n",
      "Iteration 720, Loss: 0.001979049062356353, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002016785554587841, Min w: 4.443330539176885e-25\n",
      "Iteration 740, Loss: 0.0019982499070465565, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002020652871578932, Min w: 3.1087014917829947e-07\n",
      "Iteration 760, Loss: 0.0021596956066787243, Min w: 6.660593949897438e-17\n",
      "Iteration 770, Loss: 0.0020705382339656353, Min w: 5.290491687934005e-18\n",
      "Iteration 780, Loss: 0.002002585446462035, Min w: 1.1824614354383515e-16\n",
      "Iteration 790, Loss: 0.002043982734903693, Min w: 9.421192004310797e-08\n",
      "Iteration 800, Loss: 0.002052011899650097, Min w: 2.630515621915762e-27\n",
      "Iteration 810, Loss: 0.0020266626961529255, Min w: 7.388850008283043e-06\n",
      "Iteration 820, Loss: 0.002015518257394433, Min w: 2.955858459204284e-24\n",
      "Iteration 830, Loss: 0.002008914016187191, Min w: 3.0267487803068187e-18\n",
      "Iteration 840, Loss: 0.002034706063568592, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0020216593984514475, Min w: 1.4367737902198918e-11\n",
      "Iteration 860, Loss: 0.0020245665218681097, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0020868058782070875, Min w: 1.2959743000973134e-10\n",
      "Iteration 880, Loss: 0.002010854659602046, Min w: 4.692141274617876e-26\n",
      "Iteration 890, Loss: 0.0019879969768226147, Min w: 1.0502504665055312e-05\n",
      "Iteration 900, Loss: 0.0019754329696297646, Min w: 2.5409334358794666e-11\n",
      "Iteration 910, Loss: 0.001969320233911276, Min w: 4.597460580146867e-17\n",
      "Iteration 920, Loss: 0.001992584438994527, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0019238911336287856, Min w: 2.400642574106858e-22\n",
      "Iteration 940, Loss: 0.0019957188051193953, Min w: 1.2260403822127305e-28\n",
      "Iteration 950, Loss: 0.001798282377421856, Min w: 9.777242978038306e-27\n",
      "Iteration 960, Loss: 0.001895295106805861, Min w: 6.149866749183275e-07\n",
      "Iteration 970, Loss: 0.0015262734377756715, Min w: 0.0164873618632555\n",
      "Iteration 980, Loss: 0.000581463216803968, Min w: 0.6173458099365234\n",
      "Iteration 990, Loss: 0.0015781832626089454, Min w: 0.05697587877511978\n",
      "Iteration 1000, Loss: 0.0019453561399132013, Min w: 0.004436910152435303\n",
      "Iteration 1010, Loss: 0.00196186825633049, Min w: 0.0025147907435894012\n",
      "Iteration 1020, Loss: 0.0017770176054909825, Min w: 1.9007135051651858e-05\n",
      "Iteration 1030, Loss: 0.0019678384996950626, Min w: 2.351271677358824e-10\n",
      "Iteration 1040, Loss: 0.002043325686827302, Min w: 3.8011894503142685e-05\n",
      "Iteration 1050, Loss: 0.002074118237942457, Min w: 3.7975139548507286e-06\n",
      "Iteration 1060, Loss: 0.00208872277289629, Min w: 3.284760263790607e-21\n",
      "Iteration 1070, Loss: 0.002132735913619399, Min w: 3.3258714792622213e-13\n",
      "Iteration 1080, Loss: 0.0020300657488405704, Min w: 3.485685687250388e-30\n",
      "Iteration 1090, Loss: 0.0021014604717493057, Min w: 1.5890724585443426e-42\n",
      "Iteration 1100, Loss: 0.001983978785574436, Min w: 2.1357216439810145e-07\n",
      "Iteration 1110, Loss: 0.002065178705379367, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0020647500641644, Min w: 1.2670859031601277e-14\n",
      "Iteration 1130, Loss: 0.0020608778577297926, Min w: 1.069807748019647e-36\n",
      "Iteration 1140, Loss: 0.002055184915661812, Min w: 1.2441424814824131e-06\n",
      "Iteration 1150, Loss: 0.0020311051048338413, Min w: 7.748818831032622e-08\n",
      "Iteration 1160, Loss: 0.0019757659174501896, Min w: 4.489324055612087e-06\n",
      "Iteration 1170, Loss: 0.001983257010579109, Min w: 1.0883881034317168e-15\n",
      "Iteration 1180, Loss: 0.002030332572758198, Min w: 0.0013502007350325584\n",
      "Iteration 1190, Loss: 0.0020538880489766598, Min w: 1.641065190114327e-16\n",
      "Iteration 1200, Loss: 0.002034221077337861, Min w: 7.761911773040975e-15\n",
      "Iteration 1210, Loss: 0.00199366407468915, Min w: 1.7216984504742072e-09\n",
      "Iteration 1220, Loss: 0.0019384687766432762, Min w: 2.525007064734656e-28\n",
      "Iteration 1230, Loss: 0.0020081764087080956, Min w: 0.00033127464121207595\n",
      "Iteration 1240, Loss: 0.00201268307864666, Min w: 4.051540338479507e-38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  75%|███████▌  | 18/24 [29:37<10:55, 109.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.12342041311430485, 'L2_avg': 0.1316886084972878, 'End_point_L1_avg': 0.1367248925658101, 'End_point_L2_avg': 0.14113026718949678}\n",
      "Iteration 0, Loss: 0.0013278719270601869, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006533138803206384, Min w: 2.483100878783576e-42\n",
      "Iteration 20, Loss: 0.0005976503598503768, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0006047514616511762, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005903561250306666, Min w: 0.0\n",
      "Iteration 50, Loss: 0.000544001639354974, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005625823396258056, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005837850621901453, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005079301190562546, Min w: 8.771751771122216e-13\n",
      "Iteration 90, Loss: 0.0005192551179789007, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005032598273828626, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000512471713591367, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005421116948127747, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005929487524554133, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005388158606365323, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005421708337962627, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005445361603051424, Min w: 0.0\n",
      "Iteration 170, Loss: 0.000540813198313117, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005234576528891921, Min w: 0.0\n",
      "Iteration 190, Loss: 0.000611158728133887, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0004957916680723429, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005121011636219919, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0004962921957485378, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005061132833361626, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004984521656297147, Min w: 8.874437090137134e-21\n",
      "Iteration 250, Loss: 0.00056694564409554, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0004958203644491732, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005051306798122823, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0005094521911814809, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005113863153383136, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004998297663405538, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005020141252316535, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0004998439108021557, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005106715252622962, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0005034029600210488, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0005104155279695988, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004956852062605321, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0005118510453030467, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005268433596938848, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005021535325795412, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005194090772420168, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004935096367262304, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0005125220050103962, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004949783906340599, Min w: 2.6221472998255916e-29\n",
      "Iteration 440, Loss: 0.0004980818484909832, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0005165286129340529, Min w: 0.0\n",
      "Iteration 460, Loss: 0.000507090357132256, Min w: 2.510960317254759e-31\n",
      "Iteration 470, Loss: 0.0005341352662071586, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0005444505368359387, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0005237911245785654, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004950675065629184, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005529150366783142, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0005209847004152834, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0005606918130069971, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005017414805479348, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0004978460492566228, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0005181000451557338, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0004952141316607594, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0005031729815527797, Min w: 6.302660403494543e-32\n",
      "Iteration 590, Loss: 0.0005277789896354079, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0004945046966895461, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005033006309531629, Min w: 2.566843899974927e-14\n",
      "Iteration 620, Loss: 0.000501690898090601, Min w: 8.382191367672931e-07\n",
      "Iteration 630, Loss: 0.0005115247913636267, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005127903423272073, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0005383607349358499, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0005236261058598757, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0005156261031515896, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0005092206411063671, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005091984639875591, Min w: 5.826859355937779e-22\n",
      "Iteration 700, Loss: 0.0004987667198292911, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0005111760692670941, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000502072973176837, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0005328140105120838, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0005167770432308316, Min w: 1.5254447495970428e-32\n",
      "Iteration 750, Loss: 0.0005059135146439075, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000534063670784235, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0004988143919035792, Min w: 6.438981241284318e-36\n",
      "Iteration 780, Loss: 0.0005120794521644711, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0005237404257059097, Min w: 2.5157035697769105e-18\n",
      "Iteration 800, Loss: 0.0004952029557898641, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005055487272329628, Min w: 5.177587802940309e-10\n",
      "Iteration 820, Loss: 0.000498610083013773, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0004993071197532117, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0005091981147415936, Min w: 4.046949964970072e-42\n",
      "Iteration 850, Loss: 0.0004987898282706738, Min w: 0.0\n",
      "Iteration 860, Loss: 0.00047995877685025334, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0004950474831275642, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0005034774076193571, Min w: 9.656313695394751e-31\n",
      "Iteration 890, Loss: 0.0005034063360653818, Min w: 6.871967669048903e-42\n",
      "Iteration 900, Loss: 0.0005110374768264592, Min w: 3.678408468852645e-42\n",
      "Iteration 910, Loss: 0.0005056832451373339, Min w: 3.541877119130176e-21\n",
      "Iteration 920, Loss: 0.0005062533891759813, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005341994110494852, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0005003463593311608, Min w: 8.109171364266205e-28\n",
      "Iteration 950, Loss: 0.0005160455475561321, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0004931524745188653, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0004949127323925495, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0004892376018688083, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0004837645392399281, Min w: 0.0006800183327868581\n",
      "Iteration 1000, Loss: 0.0004993399488739669, Min w: 0.00011551659554243088\n",
      "Iteration 1010, Loss: 0.0005043097771704197, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0005050476756878197, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0005103725707158446, Min w: 1.9175895152515604e-24\n",
      "Iteration 1040, Loss: 0.0004977170610800385, Min w: 7.163393142550767e-13\n",
      "Iteration 1050, Loss: 0.0005054560606367886, Min w: 1.9767286494731112e-13\n",
      "Iteration 1060, Loss: 0.0005191170494072139, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0005194419645704329, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0005206860369071364, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0005057776579633355, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0005001151585020125, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.000502829730976373, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0004931480507366359, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0004972238093614578, Min w: 1.6250858290774904e-41\n",
      "Iteration 1140, Loss: 0.000454194494523108, Min w: 2.5823535979324337e-35\n",
      "Iteration 1150, Loss: 0.0005043909186497331, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0005038134986534715, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0005058214883320034, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0005004348931834102, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0005028911982662976, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0005062188720330596, Min w: 5.61208522184201e-22\n",
      "Iteration 1210, Loss: 0.0005084200529381633, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0004970376030541956, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0004899281775578856, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.00046727684093639255, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0004970025620423257, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0004958920180797577, Min w: 3.319832196697037e-20\n",
      "Iteration 20, Loss: 0.0005036719376221299, Min w: 6.822602575538466e-25\n",
      "Iteration 30, Loss: 0.0005058395327068865, Min w: 0.0006381133571267128\n",
      "Iteration 40, Loss: 0.00047560009988956153, Min w: 0.010779918171465397\n",
      "Iteration 50, Loss: 0.0005124615854583681, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005095824017189443, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005117543623782694, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005101383430883288, Min w: 1.892783149300376e-26\n",
      "Iteration 90, Loss: 0.0005109352641738951, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005151623045094311, Min w: 6.987128395162935e-21\n",
      "Iteration 110, Loss: 0.0005059465183876455, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005124591407366097, Min w: 6.891471611678457e-26\n",
      "Iteration 130, Loss: 0.0005130861536599696, Min w: 4.594945757219193e-09\n",
      "Iteration 140, Loss: 0.0005012229084968567, Min w: 1.2218352036445542e-18\n",
      "Iteration 150, Loss: 0.000500220456160605, Min w: 9.785799669796641e-40\n",
      "Iteration 160, Loss: 0.0005122523871250451, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005087885074317455, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005058252136223018, Min w: 1.823385657113916e-18\n",
      "Iteration 190, Loss: 0.0005006014253012836, Min w: 0.0\n",
      "Iteration 200, Loss: 0.000496664026286453, Min w: 5.390479618228028e-09\n",
      "Iteration 210, Loss: 0.0004993696347810328, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005084351869300008, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004810438258573413, Min w: 2.926266082518919e-29\n",
      "Iteration 240, Loss: 0.0005061352858319879, Min w: 3.348263951956182e-39\n",
      "Iteration 250, Loss: 0.000495472049806267, Min w: 6.279691529146106e-14\n",
      "Iteration 260, Loss: 0.0004981012316420674, Min w: 6.6468008874664974e-09\n",
      "Iteration 270, Loss: 0.0005048971506766975, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00050138751976192, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005206701462157071, Min w: 1.2021021638972481e-20\n",
      "Iteration 300, Loss: 0.000497411354444921, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005025014979764819, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005014822236262262, Min w: 1.2102637990364044e-14\n",
      "Iteration 330, Loss: 0.000500208290759474, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00050584931159392, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004929828573949635, Min w: 1.4628125293090566e-20\n",
      "Iteration 360, Loss: 0.0005045807920396328, Min w: 5.975959704421794e-26\n",
      "Iteration 370, Loss: 0.000435368565376848, Min w: 2.4900147082304678e-15\n",
      "Iteration 380, Loss: 0.0004881020577158779, Min w: 0.01104672346264124\n",
      "Iteration 390, Loss: 0.00037961328052915633, Min w: 0.00237482413649559\n",
      "Iteration 400, Loss: 0.0005168606294319034, Min w: 3.0764347836050937e-23\n",
      "Iteration 410, Loss: 0.0005104078445583582, Min w: 1.3247301549004573e-21\n",
      "Iteration 420, Loss: 0.0004997455980628729, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004850502300541848, Min w: 1.1634429508530296e-35\n",
      "Iteration 440, Loss: 0.0005002944963052869, Min w: 0.0009550555841997266\n",
      "Iteration 450, Loss: 0.0004978792276233435, Min w: 1.1440997695899568e-05\n",
      "Iteration 460, Loss: 0.0005104935844428837, Min w: 0.0005510581540875137\n",
      "Iteration 470, Loss: 0.0005028689047321677, Min w: 1.497990737411235e-16\n",
      "Iteration 480, Loss: 0.00044495612382888794, Min w: 2.560592747613555e-06\n",
      "Iteration 490, Loss: 0.0005114703672006726, Min w: 7.311164608836407e-06\n",
      "Iteration 500, Loss: 0.00046825408935546875, Min w: 3.197688549023046e-18\n",
      "Iteration 510, Loss: 0.0004578856169246137, Min w: 2.263760290333039e-09\n",
      "Iteration 520, Loss: 0.0005057458183728158, Min w: 9.445211901493167e-08\n",
      "Iteration 530, Loss: 0.0005006692954339087, Min w: 5.190120972021361e-19\n",
      "Iteration 540, Loss: 0.000491788552608341, Min w: 0.0011478002415969968\n",
      "Iteration 550, Loss: 0.0005072135245427489, Min w: 2.1068956221210675e-24\n",
      "Iteration 560, Loss: 0.0005017256480641663, Min w: 3.4287980441027877e-12\n",
      "Iteration 570, Loss: 0.0004955505137331784, Min w: 0.001614212873391807\n",
      "Iteration 580, Loss: 0.0005012104520574212, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005042868433520198, Min w: 2.3131066329478006e-32\n",
      "Iteration 600, Loss: 0.0004998326767235994, Min w: 5.828774192195851e-06\n",
      "Iteration 610, Loss: 0.0004961207741871476, Min w: 1.8881677471549452e-11\n",
      "Iteration 620, Loss: 0.0004975158954039216, Min w: 0.0005882383557036519\n",
      "Iteration 630, Loss: 0.0005054393550381064, Min w: 4.5543248461399344e-07\n",
      "Iteration 640, Loss: 0.0005084684235043824, Min w: 8.1735435273852e-15\n",
      "Iteration 650, Loss: 0.0005063600256107748, Min w: 1.4528292170646814e-14\n",
      "Iteration 660, Loss: 0.0005042554694227874, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00050927116535604, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0004586044524330646, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005152921075932682, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0005020598764531314, Min w: 6.238862204632767e-10\n",
      "Iteration 710, Loss: 0.00046300922986119986, Min w: 1.881004027382005e-05\n",
      "Iteration 720, Loss: 0.0005000364617444575, Min w: 1.8252763124733395e-13\n",
      "Iteration 730, Loss: 0.0005043426062911749, Min w: 0.00018778719822876155\n",
      "Iteration 740, Loss: 0.0005049986066296697, Min w: 0.00028935266891494393\n",
      "Iteration 750, Loss: 0.0005053093191236258, Min w: 1.191750538721446e-14\n",
      "Iteration 760, Loss: 0.0005036877701058984, Min w: 3.242320872232085e-06\n",
      "Iteration 770, Loss: 0.00048747644177637994, Min w: 1.6443345884908922e-05\n",
      "Iteration 780, Loss: 0.0005046379519626498, Min w: 4.522317177196835e-17\n",
      "Iteration 790, Loss: 0.0005077037494629622, Min w: 1.0384524102846626e-05\n",
      "Iteration 800, Loss: 0.0005008206935599446, Min w: 1.0242654013836727e-07\n",
      "Iteration 810, Loss: 0.0005085913580842316, Min w: 9.769203675180638e-13\n",
      "Iteration 820, Loss: 0.0005015432252548635, Min w: 9.511220280386665e-37\n",
      "Iteration 830, Loss: 0.0005055023357272148, Min w: 4.203895392974451e-45\n",
      "Iteration 840, Loss: 0.0005029556923545897, Min w: 8.196728913389961e-07\n",
      "Iteration 850, Loss: 0.0005022178520448506, Min w: 1.2317906490529718e-16\n",
      "Iteration 860, Loss: 0.0004989471635781229, Min w: 2.2626072950141587e-28\n",
      "Iteration 870, Loss: 0.0004970751469954848, Min w: 2.2078184025599096e-20\n",
      "Iteration 880, Loss: 0.00050343171460554, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0004988139262422919, Min w: 2.003294197194805e-09\n",
      "Iteration 900, Loss: 0.0004975965712219477, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0005031514447182417, Min w: 9.668108175343469e-16\n",
      "Iteration 920, Loss: 0.0005015574861317873, Min w: 7.006492321624085e-45\n",
      "Iteration 930, Loss: 0.000496561813633889, Min w: 0.0007091389270499349\n",
      "Iteration 940, Loss: 0.000499685644172132, Min w: 0.00018864177400246263\n",
      "Iteration 950, Loss: 0.00047959230141714215, Min w: 0.01283686887472868\n",
      "Iteration 960, Loss: 0.0004957609926350415, Min w: 0.00936712697148323\n",
      "Iteration 970, Loss: 0.0005001808749511838, Min w: 2.5936922611435875e-05\n",
      "Iteration 980, Loss: 0.0004162519471719861, Min w: 0.0189969539642334\n",
      "Iteration 990, Loss: 0.00031883359770290554, Min w: 0.07559853792190552\n",
      "Iteration 1000, Loss: 0.0004960931255482137, Min w: 0.008649075403809547\n",
      "Iteration 1010, Loss: 0.0005023007979616523, Min w: 1.6118327506031704e-10\n",
      "Iteration 1020, Loss: 0.0005002430407330394, Min w: 0.002867186674848199\n",
      "Iteration 1030, Loss: 0.0005101042916066945, Min w: 3.6895009269954926e-10\n",
      "Iteration 1040, Loss: 0.0004971956950612366, Min w: 9.659361071237966e-18\n",
      "Iteration 1050, Loss: 0.0005051686894148588, Min w: 5.145133741280006e-07\n",
      "Iteration 1060, Loss: 0.0004831005644518882, Min w: 2.432655719530885e-06\n",
      "Iteration 1070, Loss: 0.0005038520903326571, Min w: 1.9995933891749304e-22\n",
      "Iteration 1080, Loss: 0.0004925145767629147, Min w: 1.4062861362169352e-33\n",
      "Iteration 1090, Loss: 0.0004985155537724495, Min w: 2.105317607569274e-27\n",
      "Iteration 1100, Loss: 0.0005064067663624883, Min w: 4.810097108641367e-41\n",
      "Iteration 1110, Loss: 0.0004950787406414747, Min w: 0.0005688060773536563\n",
      "Iteration 1120, Loss: 0.000491202634293586, Min w: 0.0010613033082336187\n",
      "Iteration 1130, Loss: 0.0004994258633814752, Min w: 9.436120845915105e-30\n",
      "Iteration 1140, Loss: 0.00047762933536432683, Min w: 0.007353600580245256\n",
      "Iteration 1150, Loss: 0.0005089004407636821, Min w: 1.0980017655021402e-35\n",
      "Iteration 1160, Loss: 0.0004993500770069659, Min w: 6.354744277720438e-29\n",
      "Iteration 1170, Loss: 0.0005019991658627987, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0004970302688889205, Min w: 1.8935377066640153e-15\n",
      "Iteration 1190, Loss: 0.0004976080963388085, Min w: 1.6765484833758393e-11\n",
      "Iteration 1200, Loss: 0.0005007877480238676, Min w: 0.00025804765755310655\n",
      "Iteration 1210, Loss: 0.00045373811735771596, Min w: 0.0033971669618040323\n",
      "Iteration 1220, Loss: 0.0005008330917917192, Min w: 5.296451027939082e-17\n",
      "Iteration 1230, Loss: 0.00045473905629478395, Min w: 6.772128108423203e-05\n",
      "Iteration 1240, Loss: 0.0004966296255588531, Min w: 3.714429297474453e-08\n",
      "Iteration 0, Loss: 0.0004906494868919253, Min w: 3.5653432788572414e-13\n",
      "Iteration 10, Loss: 0.000492049497552216, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0004853089922107756, Min w: 0.00036638297024182975\n",
      "Iteration 30, Loss: 0.00048618248547427356, Min w: 0.0032361859921365976\n",
      "Iteration 40, Loss: 0.0004988645086996257, Min w: 1.3520494043903694e-28\n",
      "Iteration 50, Loss: 0.0005011367029510438, Min w: 2.6689290777426322e-09\n",
      "Iteration 60, Loss: 0.0003508448717184365, Min w: 0.08584322780370712\n",
      "Iteration 70, Loss: 0.0004947010311298072, Min w: 0.004224132746458054\n",
      "Iteration 80, Loss: 0.0005026999861001968, Min w: 1.9222615335825845e-17\n",
      "Iteration 90, Loss: 0.0004995886120013893, Min w: 6.449822080727892e-21\n",
      "Iteration 100, Loss: 0.0004969700239598751, Min w: 3.642329168684101e-34\n",
      "Iteration 110, Loss: 0.0005014626076444983, Min w: 6.359484245876956e-07\n",
      "Iteration 120, Loss: 0.0004942419473081827, Min w: 2.1602312472168705e-07\n",
      "Iteration 130, Loss: 0.0004616141377482563, Min w: 0.009077934548258781\n",
      "Iteration 140, Loss: 0.0004978606593795121, Min w: 5.476949449523261e-11\n",
      "Iteration 150, Loss: 0.0004998347721993923, Min w: 4.444283482896161e-12\n",
      "Iteration 160, Loss: 0.0005000604433007538, Min w: 7.964178621477913e-06\n",
      "Iteration 170, Loss: 0.0004885880625806749, Min w: 2.8403873457633674e-17\n",
      "Iteration 180, Loss: 0.0004995923372916877, Min w: 6.773711006300952e-35\n",
      "Iteration 190, Loss: 0.000492336752358824, Min w: 0.0\n",
      "Iteration 200, Loss: 0.00047343887854367495, Min w: 1.8704537069424987e-05\n",
      "Iteration 210, Loss: 0.000500950962305069, Min w: 2.2796721168560907e-06\n",
      "Iteration 220, Loss: 0.0004495487955864519, Min w: 0.035031262785196304\n",
      "Iteration 230, Loss: 0.00033832190092653036, Min w: 0.06102598085999489\n",
      "Iteration 240, Loss: 0.0005005166749469936, Min w: 7.360157137545784e-17\n",
      "Iteration 250, Loss: 0.0004996391944587231, Min w: 8.185387559933588e-05\n",
      "Iteration 260, Loss: 0.0004969757865183055, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0004998723743483424, Min w: 6.451133000440075e-19\n",
      "Iteration 280, Loss: 0.0004584508715197444, Min w: 3.320538898639487e-14\n",
      "Iteration 290, Loss: 0.0004946067347191274, Min w: 7.032006692497816e-07\n",
      "Iteration 300, Loss: 0.0004710950015578419, Min w: 1.4146862570285634e-09\n",
      "Iteration 310, Loss: 0.0004842683265451342, Min w: 2.368277915441218e-16\n",
      "Iteration 320, Loss: 0.0004962146049365401, Min w: 1.5786359036391168e-13\n",
      "Iteration 330, Loss: 0.0004722576995845884, Min w: 0.04472791776061058\n",
      "Iteration 340, Loss: 0.0003915454726666212, Min w: 0.06146961823105812\n",
      "Iteration 350, Loss: 0.0004952577291987836, Min w: 0.0014853710308670998\n",
      "Iteration 360, Loss: 0.0004921357613056898, Min w: 1.5770515868213769e-26\n",
      "Iteration 370, Loss: 0.00046381683205254376, Min w: 0.035846296697854996\n",
      "Iteration 380, Loss: 0.00036255698068998754, Min w: 0.02106904238462448\n",
      "Iteration 390, Loss: 0.0004958539502695203, Min w: 9.541260624246206e-06\n",
      "Iteration 400, Loss: 0.0004956517368555069, Min w: 7.021710189292207e-06\n",
      "Iteration 410, Loss: 0.0004947741399519145, Min w: 9.503691056629467e-19\n",
      "Iteration 420, Loss: 0.0004931233124807477, Min w: 2.1621897701161225e-16\n",
      "Iteration 430, Loss: 0.0005016278009861708, Min w: 1.9960588737433227e-09\n",
      "Iteration 440, Loss: 0.0004999391385354102, Min w: 2.049973959332434e-22\n",
      "Iteration 450, Loss: 0.0005010848399251699, Min w: 4.380974694129236e-09\n",
      "Iteration 460, Loss: 0.0004995798808522522, Min w: 1.0223395678603174e-17\n",
      "Iteration 470, Loss: 0.000499777146615088, Min w: 3.376519496705937e-17\n",
      "Iteration 480, Loss: 0.0004957873024977744, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0004975964548066258, Min w: 4.046176439146017e-14\n",
      "Iteration 500, Loss: 0.0004945590626448393, Min w: 2.2969490198754272e-10\n",
      "Iteration 510, Loss: 0.0004949559224769473, Min w: 3.8834019733258174e-07\n",
      "Iteration 520, Loss: 0.0004977284115739167, Min w: 3.363116314379561e-44\n",
      "Iteration 530, Loss: 0.0004846790398005396, Min w: 7.37185291654896e-06\n",
      "Iteration 540, Loss: 0.0004933981108479202, Min w: 5.1743970424630985e-37\n",
      "Iteration 550, Loss: 0.000495856860652566, Min w: 1.1360718872310827e-06\n",
      "Iteration 560, Loss: 0.0004915760364383459, Min w: 5.204291028348962e-06\n",
      "Iteration 570, Loss: 0.0004967364366166294, Min w: 1.2449313271179535e-18\n",
      "Iteration 580, Loss: 0.0004942334489896894, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0004951299051754177, Min w: 1.3047530720775025e-12\n",
      "Iteration 600, Loss: 0.0004969791625626385, Min w: 8.921030314468226e-08\n",
      "Iteration 610, Loss: 0.00046702715917490423, Min w: 0.015413454733788967\n",
      "Iteration 620, Loss: 0.0004872731224168092, Min w: 4.681934351094219e-40\n",
      "Iteration 630, Loss: 0.00044092474854551256, Min w: 0.002658398821949959\n",
      "Iteration 640, Loss: 0.00032973341876640916, Min w: 0.016577837988734245\n",
      "Iteration 650, Loss: 0.000493164116051048, Min w: 0.0003685278061311692\n",
      "Iteration 660, Loss: 0.0004921024665236473, Min w: 0.0006318913074210286\n",
      "Iteration 670, Loss: 0.0004574906197376549, Min w: 0.02389061450958252\n",
      "Iteration 680, Loss: 0.00046898526488803327, Min w: 0.0034659295342862606\n",
      "Iteration 690, Loss: 0.0004957540077157319, Min w: 2.8209393154732254e-10\n",
      "Iteration 700, Loss: 0.0004361717728897929, Min w: 0.02486022561788559\n",
      "Iteration 710, Loss: 0.0004883144865743816, Min w: 0.006143887527287006\n",
      "Iteration 720, Loss: 0.00041372093255631626, Min w: 0.00853706430643797\n",
      "Iteration 730, Loss: 0.00037769522168673575, Min w: 0.11484964936971664\n",
      "Iteration 740, Loss: 0.0004935730248689651, Min w: 3.820349229499698e-05\n",
      "Iteration 750, Loss: 0.0004778418515343219, Min w: 7.859061952331103e-06\n",
      "Iteration 760, Loss: 0.00040924258064478636, Min w: 0.08389698714017868\n",
      "Iteration 770, Loss: 0.00038577840314246714, Min w: 0.07916980981826782\n",
      "Iteration 780, Loss: 0.000489352794829756, Min w: 0.002301247091963887\n",
      "Iteration 790, Loss: 0.0004846153315156698, Min w: 0.001537411822937429\n",
      "Iteration 800, Loss: 0.0004919978673569858, Min w: 0.00021833613573107868\n",
      "Iteration 810, Loss: 0.00047634614747948945, Min w: 4.221110066282563e-05\n",
      "Iteration 820, Loss: 0.0004939677310176194, Min w: 3.509129555823165e-06\n",
      "Iteration 830, Loss: 0.0004933796008117497, Min w: 6.4128009015547425e-21\n",
      "Iteration 840, Loss: 0.00047351018292829394, Min w: 0.0008143536979332566\n",
      "Iteration 850, Loss: 0.0004938515485264361, Min w: 3.9276443430935615e-08\n",
      "Iteration 860, Loss: 0.000494184554554522, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0004972210736013949, Min w: 0.000345319218467921\n",
      "Iteration 880, Loss: 0.0004915928584523499, Min w: 8.47928938705906e-15\n",
      "Iteration 890, Loss: 0.000466454861452803, Min w: 0.0016657973174005747\n",
      "Iteration 900, Loss: 0.0004951193695887923, Min w: 1.2514873021591074e-19\n",
      "Iteration 910, Loss: 0.0004940694780088961, Min w: 7.442303218141433e-09\n",
      "Iteration 920, Loss: 0.0004968085559085011, Min w: 1.1083066125819937e-14\n",
      "Iteration 930, Loss: 0.0004952390445396304, Min w: 0.0005724122747778893\n",
      "Iteration 940, Loss: 0.0004915586323477328, Min w: 3.684913826873526e-05\n",
      "Iteration 950, Loss: 0.0004984355182386935, Min w: 3.7573730434791048e-28\n",
      "Iteration 960, Loss: 0.0004683473380282521, Min w: 4.881128916167654e-06\n",
      "Iteration 970, Loss: 0.0004968066932633519, Min w: 1.5119999002832785e-11\n",
      "Iteration 980, Loss: 0.00048453238559886813, Min w: 0.00516428891569376\n",
      "Iteration 990, Loss: 0.000494050735142082, Min w: 1.4892079961279306e-27\n",
      "Iteration 1000, Loss: 0.0004878968757111579, Min w: 2.626884997880552e-05\n",
      "Iteration 1010, Loss: 0.000493523315526545, Min w: 1.8714233963244343e-34\n",
      "Iteration 1020, Loss: 0.0004942769883200526, Min w: 6.335713271837969e-16\n",
      "Iteration 1030, Loss: 0.0004930461291223764, Min w: 0.0005799459759145975\n",
      "Iteration 1040, Loss: 0.0004921280196867883, Min w: 2.0836796466028318e-06\n",
      "Iteration 1050, Loss: 0.0004919085185974836, Min w: 3.733038056452642e-06\n",
      "Iteration 1060, Loss: 0.0004941194783896208, Min w: 4.228804746382688e-26\n",
      "Iteration 1070, Loss: 0.000491056009195745, Min w: 0.0001832388516049832\n",
      "Iteration 1080, Loss: 0.00044449177221395075, Min w: 0.026376627385616302\n",
      "Iteration 1090, Loss: 0.00048692815471440554, Min w: 0.01277749054133892\n",
      "Iteration 1100, Loss: 0.0004949627909809351, Min w: 5.865860919622456e-16\n",
      "Iteration 1110, Loss: 0.0004915217868983746, Min w: 0.0017296699807047844\n",
      "Iteration 1120, Loss: 0.0004857287567574531, Min w: 7.503601227654144e-05\n",
      "Iteration 1130, Loss: 0.0004940126673318446, Min w: 5.950171402818597e-16\n",
      "Iteration 1140, Loss: 0.00048031777259893715, Min w: 2.351202255113094e-08\n",
      "Iteration 1150, Loss: 0.00047320270095951855, Min w: 1.2094373869523032e-37\n",
      "Iteration 1160, Loss: 0.0004941118531860411, Min w: 0.0001472783915232867\n",
      "Iteration 1170, Loss: 0.0004906307440251112, Min w: 2.0470628664392976e-11\n",
      "Iteration 1180, Loss: 0.0004916800535283983, Min w: 7.147906444515684e-08\n",
      "Iteration 1190, Loss: 0.0004883893998339772, Min w: 1.049505848465241e-25\n",
      "Iteration 1200, Loss: 0.000493390136398375, Min w: 1.0694480023776265e-11\n",
      "Iteration 1210, Loss: 0.0004966697888448834, Min w: 8.578202709795535e-13\n",
      "Iteration 1220, Loss: 0.00046322616981342435, Min w: 5.023895667507592e-20\n",
      "Iteration 1230, Loss: 0.0004936191835440695, Min w: 7.984558569873457e-10\n",
      "Iteration 1240, Loss: 0.000494074949529022, Min w: 5.407179703986742e-10\n",
      "Iteration 0, Loss: 0.0004952465533278883, Min w: 4.771666460394453e-13\n",
      "Iteration 10, Loss: 0.0004673683433793485, Min w: 1.0991684340264876e-17\n",
      "Iteration 20, Loss: 0.000493236759211868, Min w: 8.916335048070323e-08\n",
      "Iteration 30, Loss: 0.0004976509953849018, Min w: 8.631589480501134e-06\n",
      "Iteration 40, Loss: 0.0004931075964123011, Min w: 4.7476980414922185e-21\n",
      "Iteration 50, Loss: 0.0004895142046734691, Min w: 0.0004469362029340118\n",
      "Iteration 60, Loss: 0.0004945385735481977, Min w: 6.5517469921561045e-12\n",
      "Iteration 70, Loss: 0.0004917969927191734, Min w: 0.00011038155935239047\n",
      "Iteration 80, Loss: 0.0003883664612658322, Min w: 1.9869843015385413e-07\n",
      "Iteration 90, Loss: 0.00045377755304798484, Min w: 0.041206780821084976\n",
      "Iteration 100, Loss: 0.0004472077125683427, Min w: 0.03450728580355644\n",
      "Iteration 110, Loss: 0.0002756949688773602, Min w: 0.0994759052991867\n",
      "Iteration 120, Loss: 0.00030983128817752004, Min w: 0.10584686696529388\n",
      "Iteration 130, Loss: 0.0003335689543746412, Min w: 0.15404993295669556\n",
      "Iteration 140, Loss: 0.0003005923645105213, Min w: 0.19319657981395721\n",
      "Iteration 150, Loss: 0.0003058877191506326, Min w: 0.20272912085056305\n",
      "Iteration 160, Loss: 0.0003066537028644234, Min w: 0.21453511714935303\n",
      "Iteration 170, Loss: 0.0002875921200029552, Min w: 0.2427433729171753\n",
      "Iteration 180, Loss: 0.0002958441327791661, Min w: 0.25508761405944824\n",
      "Iteration 190, Loss: 0.0002684902574401349, Min w: 0.29044443368911743\n",
      "Iteration 200, Loss: 0.00025983600062318146, Min w: 0.30244603753089905\n",
      "Iteration 210, Loss: 0.0003197079640813172, Min w: 0.3106808364391327\n",
      "Iteration 220, Loss: 0.0003267069987487048, Min w: 0.3272702693939209\n",
      "Iteration 230, Loss: 0.00028043988277204335, Min w: 0.3948783874511719\n",
      "Iteration 240, Loss: 0.00026144078583456576, Min w: 0.3827800452709198\n",
      "Iteration 250, Loss: 0.0002590830554254353, Min w: 0.3870863914489746\n",
      "Iteration 260, Loss: 0.00023781128402333707, Min w: 0.416284441947937\n",
      "Iteration 270, Loss: 0.0002636675490066409, Min w: 0.3767675459384918\n",
      "Iteration 280, Loss: 0.00024284448591060936, Min w: 0.4370485544204712\n",
      "Iteration 290, Loss: 0.00022836470452602953, Min w: 0.43183669447898865\n",
      "Iteration 300, Loss: 0.00020715304708573967, Min w: 0.4496058225631714\n",
      "Iteration 310, Loss: 0.00021620074403472245, Min w: 0.47288253903388977\n",
      "Iteration 320, Loss: 0.00022085558157414198, Min w: 0.46354708075523376\n",
      "Iteration 330, Loss: 0.00021947361528873444, Min w: 0.4720824360847473\n",
      "Iteration 340, Loss: 0.00018384640861768275, Min w: 0.502918541431427\n",
      "Iteration 350, Loss: 0.00022693620121572167, Min w: 0.49911126494407654\n",
      "Iteration 360, Loss: 0.00019620165403466672, Min w: 0.5053097605705261\n",
      "Iteration 370, Loss: 0.00016779493307694793, Min w: 0.5221392512321472\n",
      "Iteration 380, Loss: 0.00019274548685643822, Min w: 0.4918772578239441\n",
      "Iteration 390, Loss: 0.00022696457745041698, Min w: 0.45076361298561096\n",
      "Iteration 400, Loss: 0.00020833952294196934, Min w: 0.502848744392395\n",
      "Iteration 410, Loss: 0.00017943706188816577, Min w: 0.5198444724082947\n",
      "Iteration 420, Loss: 0.00017870706506073475, Min w: 0.5568764805793762\n",
      "Iteration 430, Loss: 0.00019405932107474655, Min w: 0.5257771015167236\n",
      "Iteration 440, Loss: 0.00018304699915461242, Min w: 0.5367365479469299\n",
      "Iteration 450, Loss: 0.00017350082634948194, Min w: 0.5548079609870911\n",
      "Iteration 460, Loss: 0.00018431567877996713, Min w: 0.520086944103241\n",
      "Iteration 470, Loss: 0.00018167251255363226, Min w: 0.5349794626235962\n",
      "Iteration 480, Loss: 0.00021095889678690583, Min w: 0.502560019493103\n",
      "Iteration 490, Loss: 0.0002148892090190202, Min w: 0.5171589255332947\n",
      "Iteration 500, Loss: 0.00020883241086266935, Min w: 0.5305602550506592\n",
      "Iteration 510, Loss: 0.00016519242490176111, Min w: 0.5549376606941223\n",
      "Iteration 520, Loss: 0.00018917438865173608, Min w: 0.5096229314804077\n",
      "Iteration 530, Loss: 0.00014990678755566478, Min w: 0.582121729850769\n",
      "Iteration 540, Loss: 0.00016236878582276404, Min w: 0.5593101978302002\n",
      "Iteration 550, Loss: 0.0001704351307125762, Min w: 0.5593911409378052\n",
      "Iteration 560, Loss: 0.00020470899471547455, Min w: 0.5339377522468567\n",
      "Iteration 570, Loss: 0.00018095852283295244, Min w: 0.5429754257202148\n",
      "Iteration 580, Loss: 0.00017282203771173954, Min w: 0.5700841546058655\n",
      "Iteration 590, Loss: 0.00017418342758901417, Min w: 0.587226390838623\n",
      "Iteration 600, Loss: 0.00015392810746561736, Min w: 0.5804407000541687\n",
      "Iteration 610, Loss: 0.00017173938977066427, Min w: 0.5623233914375305\n",
      "Iteration 620, Loss: 0.00018113252008333802, Min w: 0.5696000456809998\n",
      "Iteration 630, Loss: 0.00015370572509709746, Min w: 0.5864720940589905\n",
      "Iteration 640, Loss: 0.00016592771862633526, Min w: 0.5908504724502563\n",
      "Iteration 650, Loss: 0.000161877425853163, Min w: 0.5985629558563232\n",
      "Iteration 660, Loss: 0.00016958558990154415, Min w: 0.5843015909194946\n",
      "Iteration 670, Loss: 0.00018073446699418128, Min w: 0.5730026364326477\n",
      "Iteration 680, Loss: 0.00017009579460136592, Min w: 0.5785024762153625\n",
      "Iteration 690, Loss: 0.00014763591752853245, Min w: 0.6142085790634155\n",
      "Iteration 700, Loss: 0.00014127687609288841, Min w: 0.5993244647979736\n",
      "Iteration 710, Loss: 0.00013332733942661434, Min w: 0.6379797458648682\n",
      "Iteration 720, Loss: 0.0001474695891374722, Min w: 0.5659154653549194\n",
      "Iteration 730, Loss: 0.00015781557885929942, Min w: 0.6287750601768494\n",
      "Iteration 740, Loss: 0.0001630986953387037, Min w: 0.5835444331169128\n",
      "Iteration 750, Loss: 0.00015175862063188106, Min w: 0.6173851490020752\n",
      "Iteration 760, Loss: 0.00017170606588479131, Min w: 0.5875029563903809\n",
      "Iteration 770, Loss: 0.0001762827014317736, Min w: 0.5867632031440735\n",
      "Iteration 780, Loss: 0.00015812626224942505, Min w: 0.6121703386306763\n",
      "Iteration 790, Loss: 0.000161439020303078, Min w: 0.6293337941169739\n",
      "Iteration 800, Loss: 0.0002058389800367877, Min w: 0.5800647139549255\n",
      "Iteration 810, Loss: 0.00017520667461212724, Min w: 0.6282010078430176\n",
      "Iteration 820, Loss: 0.00015910879301372916, Min w: 0.6203891634941101\n",
      "Iteration 830, Loss: 0.00013828258670400828, Min w: 0.6532468199729919\n",
      "Iteration 840, Loss: 0.00012712182069662958, Min w: 0.6705236434936523\n",
      "Iteration 850, Loss: 0.00013624313578475267, Min w: 0.6525157690048218\n",
      "Iteration 860, Loss: 0.00016204919666051865, Min w: 0.6471174359321594\n",
      "Iteration 870, Loss: 0.00015874026576057076, Min w: 0.6591167449951172\n",
      "Iteration 880, Loss: 0.00015289633302018046, Min w: 0.639216423034668\n",
      "Iteration 890, Loss: 0.00015702647215221077, Min w: 0.6494607925415039\n",
      "Iteration 900, Loss: 0.000149919927935116, Min w: 0.6453481912612915\n",
      "Iteration 910, Loss: 0.0001413298596162349, Min w: 0.6740067601203918\n",
      "Iteration 920, Loss: 0.00012598547618836164, Min w: 0.6695998311042786\n",
      "Iteration 930, Loss: 0.00015576250734739006, Min w: 0.6533219814300537\n",
      "Iteration 940, Loss: 0.00013681684504263103, Min w: 0.6778003573417664\n",
      "Iteration 950, Loss: 0.00014960924454499036, Min w: 0.6672817468643188\n",
      "Iteration 960, Loss: 0.00014589237980544567, Min w: 0.6830514669418335\n",
      "Iteration 970, Loss: 0.00014963017019908875, Min w: 0.6737812161445618\n",
      "Iteration 980, Loss: 0.00013912975555285811, Min w: 0.684010922908783\n",
      "Iteration 990, Loss: 0.0001370764512103051, Min w: 0.6948597431182861\n",
      "Iteration 1000, Loss: 0.00013862576452083886, Min w: 0.6823411583900452\n",
      "Iteration 1010, Loss: 0.00013550894800573587, Min w: 0.6959773898124695\n",
      "Iteration 1020, Loss: 0.00015103664190974087, Min w: 0.6790382266044617\n",
      "Iteration 1030, Loss: 0.0001396350417053327, Min w: 0.7028142809867859\n",
      "Iteration 1040, Loss: 0.00011385834659449756, Min w: 0.7151543498039246\n",
      "Iteration 1050, Loss: 0.00012025942851323634, Min w: 0.7124592065811157\n",
      "Iteration 1060, Loss: 0.00010733729868661612, Min w: 0.7300543189048767\n",
      "Iteration 1070, Loss: 0.00011154456296935678, Min w: 0.7253223657608032\n",
      "Iteration 1080, Loss: 0.00010330080840503797, Min w: 0.7385833263397217\n",
      "Iteration 1090, Loss: 0.00010352616664022207, Min w: 0.7339616417884827\n",
      "Iteration 1100, Loss: 9.627889812691137e-05, Min w: 0.7480082511901855\n",
      "Iteration 1110, Loss: 9.966913057724014e-05, Min w: 0.7554282546043396\n",
      "Iteration 1120, Loss: 8.900921238819137e-05, Min w: 0.7577821612358093\n",
      "Iteration 1130, Loss: 0.00013633629714604467, Min w: 0.7208764553070068\n",
      "Iteration 1140, Loss: 0.00012138323654653504, Min w: 0.73048996925354\n",
      "Iteration 1150, Loss: 0.00011055710638174787, Min w: 0.7504594326019287\n",
      "Iteration 1160, Loss: 0.0001020496929413639, Min w: 0.7499524354934692\n",
      "Iteration 1170, Loss: 9.941351891029626e-05, Min w: 0.7678442597389221\n",
      "Iteration 1180, Loss: 0.00012908861390314996, Min w: 0.7375443577766418\n",
      "Iteration 1190, Loss: 0.00012031425285385922, Min w: 0.7431412935256958\n",
      "Iteration 1200, Loss: 0.00012177040480310097, Min w: 0.7502225637435913\n",
      "Iteration 1210, Loss: 0.00010198054951615632, Min w: 0.7546741962432861\n",
      "Iteration 1220, Loss: 8.744939259486273e-05, Min w: 0.7807771563529968\n",
      "Iteration 1230, Loss: 9.616500028641894e-05, Min w: 0.7717397212982178\n",
      "Iteration 1240, Loss: 8.438445365754887e-05, Min w: 0.7883529663085938\n",
      "Iteration 0, Loss: 9.934716217685491e-05, Min w: 0.7796914577484131\n",
      "Iteration 10, Loss: 0.00011215751146664843, Min w: 0.7550749182701111\n",
      "Iteration 20, Loss: 0.00010541958181420341, Min w: 0.7766572833061218\n",
      "Iteration 30, Loss: 9.058436990017071e-05, Min w: 0.7970339059829712\n",
      "Iteration 40, Loss: 9.273770410800353e-05, Min w: 0.7871028780937195\n",
      "Iteration 50, Loss: 7.58496971684508e-05, Min w: 0.8057842254638672\n",
      "Iteration 60, Loss: 0.00010237860988127068, Min w: 0.7874256372451782\n",
      "Iteration 70, Loss: 0.00010704754095058888, Min w: 0.7644266486167908\n",
      "Iteration 80, Loss: 0.00010940861830022186, Min w: 0.770551860332489\n",
      "Iteration 90, Loss: 0.0001140339081757702, Min w: 0.7659338712692261\n",
      "Iteration 100, Loss: 0.00011887742584804073, Min w: 0.7340155243873596\n",
      "Iteration 110, Loss: 0.00012015089305350557, Min w: 0.7498427033424377\n",
      "Iteration 120, Loss: 0.0001217852404806763, Min w: 0.733207106590271\n",
      "Iteration 130, Loss: 8.852849714457989e-05, Min w: 0.8046867847442627\n",
      "Iteration 140, Loss: 0.00010062584624392912, Min w: 0.7783060669898987\n",
      "Iteration 150, Loss: 7.80274422140792e-05, Min w: 0.8234549164772034\n",
      "Iteration 160, Loss: 0.00010126012784894556, Min w: 0.7603201866149902\n",
      "Iteration 170, Loss: 0.00011035906209144741, Min w: 0.7302743792533875\n",
      "Iteration 180, Loss: 0.00010890327394008636, Min w: 0.7724002599716187\n",
      "Iteration 190, Loss: 9.252804738935083e-05, Min w: 0.7974658608436584\n",
      "Iteration 200, Loss: 9.095451969187707e-05, Min w: 0.8017008900642395\n",
      "Iteration 210, Loss: 9.442159353056923e-05, Min w: 0.7822589874267578\n",
      "Iteration 220, Loss: 9.981525363400578e-05, Min w: 0.7564489841461182\n",
      "Iteration 230, Loss: 0.00011306357919238508, Min w: 0.7098668217658997\n",
      "Iteration 240, Loss: 0.00010479217598913237, Min w: 0.7548006176948547\n",
      "Iteration 250, Loss: 9.615662565920502e-05, Min w: 0.7900298237800598\n",
      "Iteration 260, Loss: 0.00011834684846689925, Min w: 0.755090594291687\n",
      "Iteration 270, Loss: 0.00011001036909874529, Min w: 0.7220245599746704\n",
      "Iteration 280, Loss: 0.00010036712046712637, Min w: 0.7730162143707275\n",
      "Iteration 290, Loss: 8.723595965420827e-05, Min w: 0.8110032677650452\n",
      "Iteration 300, Loss: 0.00010020865738624707, Min w: 0.7609919309616089\n",
      "Iteration 310, Loss: 9.161826164927334e-05, Min w: 0.8060536980628967\n",
      "Iteration 320, Loss: 8.911763870855793e-05, Min w: 0.7905550599098206\n",
      "Iteration 330, Loss: 9.493123070569709e-05, Min w: 0.782908022403717\n",
      "Iteration 340, Loss: 8.376513869734481e-05, Min w: 0.8235347270965576\n",
      "Iteration 350, Loss: 8.962796709965914e-05, Min w: 0.7958272695541382\n",
      "Iteration 360, Loss: 8.894693019101396e-05, Min w: 0.7695510387420654\n",
      "Iteration 370, Loss: 0.00010522629600018263, Min w: 0.7240228056907654\n",
      "Iteration 380, Loss: 8.71727243065834e-05, Min w: 0.8127477169036865\n",
      "Iteration 390, Loss: 9.150942059932277e-05, Min w: 0.7934920787811279\n",
      "Iteration 400, Loss: 7.840919715818018e-05, Min w: 0.816519021987915\n",
      "Iteration 410, Loss: 7.343196193687618e-05, Min w: 0.8316425681114197\n",
      "Iteration 420, Loss: 6.694802868878469e-05, Min w: 0.8451261520385742\n",
      "Iteration 430, Loss: 8.857531065586954e-05, Min w: 0.7673031091690063\n",
      "Iteration 440, Loss: 9.417967521585524e-05, Min w: 0.7721735239028931\n",
      "Iteration 450, Loss: 0.00010714957170421258, Min w: 0.7568869590759277\n",
      "Iteration 460, Loss: 0.00011182948219357058, Min w: 0.6867923736572266\n",
      "Iteration 470, Loss: 7.321398152271286e-05, Min w: 0.8205729126930237\n",
      "Iteration 480, Loss: 9.757495718076825e-05, Min w: 0.7932309508323669\n",
      "Iteration 490, Loss: 9.414819942321628e-05, Min w: 0.7730818390846252\n",
      "Iteration 500, Loss: 7.419074972858652e-05, Min w: 0.8166374564170837\n",
      "Iteration 510, Loss: 7.512502634199336e-05, Min w: 0.8143087029457092\n",
      "Iteration 520, Loss: 9.315729403169826e-05, Min w: 0.7620852589607239\n",
      "Iteration 530, Loss: 9.463813330512494e-05, Min w: 0.768930196762085\n",
      "Iteration 540, Loss: 0.00011156708205817267, Min w: 0.6951189041137695\n",
      "Iteration 550, Loss: 0.0001046239776769653, Min w: 0.7281373143196106\n",
      "Iteration 560, Loss: 0.00010136188211617991, Min w: 0.7610840797424316\n",
      "Iteration 570, Loss: 6.011896766722202e-05, Min w: 0.8540226817131042\n",
      "Iteration 580, Loss: 6.0756876337109134e-05, Min w: 0.8476256132125854\n",
      "Iteration 590, Loss: 7.915862806839868e-05, Min w: 0.7862118482589722\n",
      "Iteration 600, Loss: 0.00011025038111256436, Min w: 0.7738841772079468\n",
      "Iteration 610, Loss: 0.00011778665066231042, Min w: 0.6254121661186218\n",
      "Iteration 620, Loss: 0.000101387886388693, Min w: 0.7773409485816956\n",
      "Iteration 630, Loss: 7.84078729338944e-05, Min w: 0.8092325329780579\n",
      "Iteration 640, Loss: 6.286890857154503e-05, Min w: 0.866791844367981\n",
      "Iteration 650, Loss: 6.09196831646841e-05, Min w: 0.8490727543830872\n",
      "Iteration 660, Loss: 7.341411401284859e-05, Min w: 0.8033508658409119\n",
      "Iteration 670, Loss: 7.48722450225614e-05, Min w: 0.8322144746780396\n",
      "Iteration 680, Loss: 7.2598981205374e-05, Min w: 0.8230336904525757\n",
      "Iteration 690, Loss: 6.571270932909101e-05, Min w: 0.8406654000282288\n",
      "Iteration 700, Loss: 5.009011510992423e-05, Min w: 0.8763511776924133\n",
      "Iteration 710, Loss: 6.157254392746836e-05, Min w: 0.8386829495429993\n",
      "Iteration 720, Loss: 8.265540964202955e-05, Min w: 0.782873809337616\n",
      "Iteration 730, Loss: 8.909700409276411e-05, Min w: 0.7752112150192261\n",
      "Iteration 740, Loss: 8.292574057122692e-05, Min w: 0.7711769938468933\n",
      "Iteration 750, Loss: 6.503260374302045e-05, Min w: 0.8317188024520874\n",
      "Iteration 760, Loss: 6.934892735444009e-05, Min w: 0.824169933795929\n",
      "Iteration 770, Loss: 6.890261283842847e-05, Min w: 0.8128328919410706\n",
      "Iteration 780, Loss: 7.201983680715784e-05, Min w: 0.8137900829315186\n",
      "Iteration 790, Loss: 0.0001025757665047422, Min w: 0.7150495052337646\n",
      "Iteration 800, Loss: 0.00010201890836469829, Min w: 0.6887608170509338\n",
      "Iteration 810, Loss: 5.93824552197475e-05, Min w: 0.8465880751609802\n",
      "Iteration 820, Loss: 6.356597441481426e-05, Min w: 0.8379248976707458\n",
      "Iteration 830, Loss: 7.994775660336018e-05, Min w: 0.7972069382667542\n",
      "Iteration 840, Loss: 7.976195047376677e-05, Min w: 0.7705782055854797\n",
      "Iteration 850, Loss: 7.860112236812711e-05, Min w: 0.7828443646430969\n",
      "Iteration 860, Loss: 5.9157271607546136e-05, Min w: 0.849086344242096\n",
      "Iteration 870, Loss: 6.09829330642242e-05, Min w: 0.8449028134346008\n",
      "Iteration 880, Loss: 6.548614328494295e-05, Min w: 0.8116814494132996\n",
      "Iteration 890, Loss: 6.177568138809875e-05, Min w: 0.8616978526115417\n",
      "Iteration 900, Loss: 7.80024056439288e-05, Min w: 0.7737431526184082\n",
      "Iteration 910, Loss: 7.626782462466508e-05, Min w: 0.7892882227897644\n",
      "Iteration 920, Loss: 7.682775321882218e-05, Min w: 0.7892704010009766\n",
      "Iteration 930, Loss: 5.366976256482303e-05, Min w: 0.8621616959571838\n",
      "Iteration 940, Loss: 5.7979275879915804e-05, Min w: 0.8583139181137085\n",
      "Iteration 950, Loss: 7.13294866727665e-05, Min w: 0.7859211564064026\n",
      "Iteration 960, Loss: 6.121186743257567e-05, Min w: 0.8587408661842346\n",
      "Iteration 970, Loss: 7.169905438786373e-05, Min w: 0.7958166599273682\n",
      "Iteration 980, Loss: 8.371447620447725e-05, Min w: 0.7829732894897461\n",
      "Iteration 990, Loss: 7.428388198604807e-05, Min w: 0.8045022487640381\n",
      "Iteration 1000, Loss: 6.640019273618236e-05, Min w: 0.8183689713478088\n",
      "Iteration 1010, Loss: 6.792303611291572e-05, Min w: 0.8396172523498535\n",
      "Iteration 1020, Loss: 4.201913543511182e-05, Min w: 0.8928815126419067\n",
      "Iteration 1030, Loss: 4.575110870064236e-05, Min w: 0.879956066608429\n",
      "Iteration 1040, Loss: 4.860999615630135e-05, Min w: 0.8661705255508423\n",
      "Iteration 1050, Loss: 2.876136750273872e-05, Min w: 0.9389748573303223\n",
      "Iteration 1060, Loss: 4.32134183938615e-05, Min w: 0.897458016872406\n",
      "Iteration 1070, Loss: 4.680229176301509e-05, Min w: 0.8673964142799377\n",
      "Iteration 1080, Loss: 6.753651541657746e-05, Min w: 0.8159819841384888\n",
      "Iteration 1090, Loss: 6.259055953705683e-05, Min w: 0.8289926648139954\n",
      "Iteration 1100, Loss: 4.879127300227992e-05, Min w: 0.8689119219779968\n",
      "Iteration 1110, Loss: 4.9732061597751454e-05, Min w: 0.8551113605499268\n",
      "Iteration 1120, Loss: 7.917435868876055e-05, Min w: 0.779797375202179\n",
      "Iteration 1130, Loss: 4.091188020538539e-05, Min w: 0.8953806757926941\n",
      "Iteration 1140, Loss: 5.7501103583490476e-05, Min w: 0.8486586809158325\n",
      "Iteration 1150, Loss: 7.206972077256069e-05, Min w: 0.8051329255104065\n",
      "Iteration 1160, Loss: 6.821972783654928e-05, Min w: 0.8007563948631287\n",
      "Iteration 1170, Loss: 7.163189729908481e-05, Min w: 0.7718693017959595\n",
      "Iteration 1180, Loss: 8.475824142806232e-05, Min w: 0.7766141295433044\n",
      "Iteration 1190, Loss: 7.514765457017347e-05, Min w: 0.8009423613548279\n",
      "Iteration 1200, Loss: 6.16933248238638e-05, Min w: 0.8218870759010315\n",
      "Iteration 1210, Loss: 5.933162537985481e-05, Min w: 0.8194666504859924\n",
      "Iteration 1220, Loss: 2.6210367650492117e-05, Min w: 0.9460830688476562\n",
      "Iteration 1230, Loss: 0.00010149015724891797, Min w: 0.6982836723327637\n",
      "Iteration 1240, Loss: 9.73732749116607e-05, Min w: 0.739477813243866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  79%|███████▉  | 19/24 [31:32<09:14, 110.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.022481241492512835, 'L2_avg': 0.037400666738126156, 'End_point_L1_avg': 0.01006261675635635, 'End_point_L2_avg': 0.010608858012994023}\n",
      "Iteration 0, Loss: 0.0009548419620841742, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0005756160244345665, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005562791484408081, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0005468908348120749, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005389000871218741, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005721431807614863, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005487672169692814, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005687053198926151, Min w: 0.0\n",
      "Iteration 80, Loss: 0.000540147302672267, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005239975289441645, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005337251932360232, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006263362593017519, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005858688964508474, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005096794338896871, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0004985613049939275, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005069653270766139, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005155696417205036, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005188042996451259, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005257712327875197, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005480021936818957, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005294703296385705, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005161485751159489, Min w: 0.0\n",
      "Iteration 220, Loss: 0.000511466059833765, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005450164899230003, Min w: 5.720560691813148e-10\n",
      "Iteration 240, Loss: 0.0005181084270589054, Min w: 8.498376757870574e-08\n",
      "Iteration 250, Loss: 0.0005189835210330784, Min w: 4.2724493387602536e-10\n",
      "Iteration 260, Loss: 0.0005242158658802509, Min w: 4.570680314265607e-13\n",
      "Iteration 270, Loss: 0.0005114327650517225, Min w: 1.7032051257746247e-24\n",
      "Iteration 280, Loss: 0.0005252130795270205, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005316287279129028, Min w: 2.7566242621901438e-09\n",
      "Iteration 300, Loss: 0.0005113592487759888, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0005013240734115243, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005193990655243397, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005035650683566928, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0005269606481306255, Min w: 4.6033952880623177e-23\n",
      "Iteration 350, Loss: 0.0005061638657934964, Min w: 9.099601280815328e-12\n",
      "Iteration 360, Loss: 0.0004911325522698462, Min w: 2.8862383260275237e-05\n",
      "Iteration 370, Loss: 0.0005175299593247473, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005134012899361551, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005058925598859787, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005203985492698848, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005461954278871417, Min w: 1.876187913516936e-30\n",
      "Iteration 420, Loss: 0.0005356190958991647, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0005452791810967028, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0005364821408875287, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0005026768776588142, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005105372401885688, Min w: 5.38496579064598e-40\n",
      "Iteration 470, Loss: 0.0004977586795575917, Min w: 2.331787429810106e-09\n",
      "Iteration 480, Loss: 0.0004991022287867963, Min w: 7.075676104778635e-34\n",
      "Iteration 490, Loss: 0.0005320385098457336, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004943342064507306, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0004943487583659589, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0004953441093675792, Min w: 1.6118894446959059e-27\n",
      "Iteration 530, Loss: 0.0004940630751661956, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005004635313525796, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005027106963098049, Min w: 2.1173928021621553e-14\n",
      "Iteration 560, Loss: 0.0004995876806788146, Min w: 1.0537797136354454e-15\n",
      "Iteration 570, Loss: 0.0005085867596790195, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0004857648746110499, Min w: 1.8448710079610464e-06\n",
      "Iteration 590, Loss: 0.0005025585414841771, Min w: 1.478369879862682e-42\n",
      "Iteration 600, Loss: 0.0005102292634546757, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0004983306280337274, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0005129442433826625, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0005022044642828405, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005160140572115779, Min w: 2.7120610365050732e-27\n",
      "Iteration 650, Loss: 0.0004938740166835487, Min w: 8.861550273957242e-13\n",
      "Iteration 660, Loss: 0.0004960401565767825, Min w: 1.1247250526758013e-11\n",
      "Iteration 670, Loss: 0.0004932790761813521, Min w: 6.718972273327156e-20\n",
      "Iteration 680, Loss: 0.0005135444807820022, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005318800103850663, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0004962856764905155, Min w: 0.0\n",
      "Iteration 710, Loss: 0.000501380069181323, Min w: 8.251267270625254e-15\n",
      "Iteration 720, Loss: 0.0005148887285031378, Min w: 4.6621199908086664e-42\n",
      "Iteration 730, Loss: 0.0004987780703231692, Min w: 3.6125474410293784e-42\n",
      "Iteration 740, Loss: 0.0005024992278777063, Min w: 2.752921702061832e-19\n",
      "Iteration 750, Loss: 0.00047740250010974705, Min w: 1.3872854796815689e-43\n",
      "Iteration 760, Loss: 0.0004884805530309677, Min w: 1.2461740149451346e-14\n",
      "Iteration 770, Loss: 0.0004997230134904385, Min w: 4.624284932271896e-44\n",
      "Iteration 780, Loss: 0.0004929872811771929, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0004882976063527167, Min w: 2.1442204956034772e-10\n",
      "Iteration 800, Loss: 0.0005048178718425333, Min w: 1.1663968602498148e-22\n",
      "Iteration 810, Loss: 0.0004994101473130286, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0005111838108859956, Min w: 8.877445313380443e-22\n",
      "Iteration 830, Loss: 0.000506969983689487, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0004986078711226583, Min w: 7.409993842480422e-13\n",
      "Iteration 850, Loss: 0.000494364183396101, Min w: 1.1827591410092394e-31\n",
      "Iteration 860, Loss: 0.0005047291633673012, Min w: 2.4111628231388852e-20\n",
      "Iteration 870, Loss: 0.0004555836785584688, Min w: 2.594800321276125e-07\n",
      "Iteration 880, Loss: 0.0005018601659685373, Min w: 1.727562017050932e-11\n",
      "Iteration 890, Loss: 0.0004970136797055602, Min w: 0.0001658621768001467\n",
      "Iteration 900, Loss: 0.0005009541637264192, Min w: 8.768467523623258e-05\n",
      "Iteration 910, Loss: 0.0004441979981493205, Min w: 1.4871689018036705e-06\n",
      "Iteration 920, Loss: 0.0005158645799383521, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005020209937356412, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0005148425116203725, Min w: 2.2420775429197073e-43\n",
      "Iteration 950, Loss: 0.0005026842700317502, Min w: 2.6966902225144184e-19\n",
      "Iteration 960, Loss: 0.0005084078875370324, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0004975575720891356, Min w: 1.5239875843171464e-21\n",
      "Iteration 980, Loss: 0.0005101141869090497, Min w: 0.0006174658192321658\n",
      "Iteration 990, Loss: 0.0005138278938829899, Min w: 2.4298195833855063e-12\n",
      "Iteration 1000, Loss: 0.000497354834806174, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0005008477601222694, Min w: 1.2835160129962562e-15\n",
      "Iteration 1020, Loss: 0.0005167623166926205, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0005085080047138035, Min w: 1.5799619735362727e-31\n",
      "Iteration 1040, Loss: 0.0004996256320737302, Min w: 4.783463886844114e-18\n",
      "Iteration 1050, Loss: 0.0005019004456698895, Min w: 1.7013799151754938e-06\n",
      "Iteration 1060, Loss: 0.0004964059335179627, Min w: 0.0018579147290438414\n",
      "Iteration 1070, Loss: 0.0005125368479639292, Min w: 5.0734928483496e-18\n",
      "Iteration 1080, Loss: 0.0005047672893851995, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0005148801719769835, Min w: 2.1538457684044943e-09\n",
      "Iteration 1100, Loss: 0.0004911031574010849, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0004855584120377898, Min w: 2.067937487915117e-10\n",
      "Iteration 1120, Loss: 0.0004948351415805519, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0004991466412320733, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0005004859413020313, Min w: 1.854821829113381e-18\n",
      "Iteration 1150, Loss: 0.0005090910126455128, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0005169677315279841, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0004957859055139124, Min w: 2.8576795919536452e-24\n",
      "Iteration 1180, Loss: 0.0004970860318280756, Min w: 1.0428062826897577e-16\n",
      "Iteration 1190, Loss: 0.0005003696423955262, Min w: 5.8896996369944505e-22\n",
      "Iteration 1200, Loss: 0.0004932461306452751, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0005039622774347663, Min w: 4.640305178313485e-27\n",
      "Iteration 1220, Loss: 0.0004857262538280338, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0004981826641596854, Min w: 9.709455480333418e-05\n",
      "Iteration 1240, Loss: 0.0004983427934348583, Min w: 5.295356118040218e-07\n",
      "Iteration 0, Loss: 0.0005010833265259862, Min w: 7.846577281002494e-23\n",
      "Iteration 10, Loss: 0.0005008502048440278, Min w: 1.214651344999887e-13\n",
      "Iteration 20, Loss: 0.0005086339660920203, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0005176700069569051, Min w: 1.077798639167255e-30\n",
      "Iteration 40, Loss: 0.0005209385417401791, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005129616474732757, Min w: 0.0\n",
      "Iteration 60, Loss: 0.000505271484144032, Min w: 9.127525296396996e-18\n",
      "Iteration 70, Loss: 0.0004976214258931577, Min w: 1.534208090431255e-12\n",
      "Iteration 80, Loss: 0.0005133127560839057, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005143124726600945, Min w: 1.244701770038853e-13\n",
      "Iteration 100, Loss: 0.0004993602633476257, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005033074994571507, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005202809697948396, Min w: 2.6018515822941913e-21\n",
      "Iteration 130, Loss: 0.00050493044545874, Min w: 1.8409044018271184e-36\n",
      "Iteration 140, Loss: 0.0004943558014929295, Min w: 2.1368728994275443e-05\n",
      "Iteration 150, Loss: 0.0004944506799802184, Min w: 8.777891191691367e-10\n",
      "Iteration 160, Loss: 0.0004819056484848261, Min w: 0.0033908889163285494\n",
      "Iteration 170, Loss: 0.0005003239493817091, Min w: 3.3071493987790745e-08\n",
      "Iteration 180, Loss: 0.0005036242655478418, Min w: 6.87308127210397e-22\n",
      "Iteration 190, Loss: 0.0005077949026599526, Min w: 1.0812558313977316e-11\n",
      "Iteration 200, Loss: 0.0005110016791149974, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0004990332527086139, Min w: 1.0369608636003646e-43\n",
      "Iteration 220, Loss: 0.0005042150733061135, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005000185337848961, Min w: 8.537747923640343e-22\n",
      "Iteration 240, Loss: 0.0005234801210463047, Min w: 1.4904630856098052e-40\n",
      "Iteration 250, Loss: 0.0004981007659807801, Min w: 1.6934645907795698e-09\n",
      "Iteration 260, Loss: 0.0005038278759457171, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005078000831417739, Min w: 9.532118318436476e-27\n",
      "Iteration 280, Loss: 0.0005196536658331752, Min w: 1.7102762522344759e-16\n",
      "Iteration 290, Loss: 0.0004930156283080578, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004748145001940429, Min w: 1.053767643415947e-15\n",
      "Iteration 310, Loss: 0.0004682506259996444, Min w: 3.4862652682932094e-05\n",
      "Iteration 320, Loss: 0.0004720653232652694, Min w: 0.01561472937464714\n",
      "Iteration 330, Loss: 0.0004985197447240353, Min w: 5.501882870178004e-36\n",
      "Iteration 340, Loss: 0.0004891256103292108, Min w: 3.299389152852515e-22\n",
      "Iteration 350, Loss: 0.0004984713741578162, Min w: 2.8252067352241284e-08\n",
      "Iteration 360, Loss: 0.0004895667661912739, Min w: 5.761078864452429e-05\n",
      "Iteration 370, Loss: 0.0004897654289379716, Min w: 0.01402333378791809\n",
      "Iteration 380, Loss: 0.0004990238230675459, Min w: 7.021714535558488e-18\n",
      "Iteration 390, Loss: 0.0005012965411879122, Min w: 9.331301405735557e-17\n",
      "Iteration 400, Loss: 0.0005065244040451944, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004973514005541801, Min w: 0.0\n",
      "Iteration 420, Loss: 0.000504082185216248, Min w: 5.483905442192854e-28\n",
      "Iteration 430, Loss: 0.000511473452206701, Min w: 0.0\n",
      "Iteration 440, Loss: 0.000517066684551537, Min w: 0.0\n",
      "Iteration 450, Loss: 0.000501030299346894, Min w: 9.206070572531644e-09\n",
      "Iteration 460, Loss: 0.000489475205540657, Min w: 9.818260141514317e-31\n",
      "Iteration 470, Loss: 0.0005001185345463455, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0005023067351430655, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0004979894729331136, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004921906511299312, Min w: 1.1154178438093493e-13\n",
      "Iteration 510, Loss: 0.0004943019011989236, Min w: 6.290899182204157e-05\n",
      "Iteration 520, Loss: 0.0004992879694327712, Min w: 2.814641183761532e-17\n",
      "Iteration 530, Loss: 0.0004978213110007346, Min w: 0.0024755853228271008\n",
      "Iteration 540, Loss: 0.0005038976087234914, Min w: 7.286816012350434e-34\n",
      "Iteration 550, Loss: 0.0005020300741307437, Min w: 5.715893621527357e-06\n",
      "Iteration 560, Loss: 0.0005057863309048116, Min w: 1.5871952190972214e-28\n",
      "Iteration 570, Loss: 0.0005078672547824681, Min w: 1.7970643068013355e-16\n",
      "Iteration 580, Loss: 0.0004926138208247721, Min w: 1.301662499574724e-13\n",
      "Iteration 590, Loss: 0.0004934436874464154, Min w: 5.584120685853122e-07\n",
      "Iteration 600, Loss: 0.00039592120447196066, Min w: 0.01710485853254795\n",
      "Iteration 610, Loss: 0.0005007412983104587, Min w: 4.344025239406933e-44\n",
      "Iteration 620, Loss: 0.0004980677040293813, Min w: 1.414354202332324e-13\n",
      "Iteration 630, Loss: 0.0004968048888258636, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0005046119331382215, Min w: 3.728037540895457e-07\n",
      "Iteration 650, Loss: 0.000498316076118499, Min w: 2.811816578185411e-11\n",
      "Iteration 660, Loss: 0.0004973962204530835, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0004961024387739599, Min w: 2.444426456804649e-07\n",
      "Iteration 680, Loss: 0.0004515743930824101, Min w: 1.3923663654338836e-12\n",
      "Iteration 690, Loss: 0.0004963300307281315, Min w: 2.814501385728363e-06\n",
      "Iteration 700, Loss: 0.0004952385788783431, Min w: 9.48372598941205e-06\n",
      "Iteration 710, Loss: 0.0004942906671203673, Min w: 2.802596928649634e-45\n",
      "Iteration 720, Loss: 0.000501577160321176, Min w: 9.540538660739867e-16\n",
      "Iteration 730, Loss: 0.0004770552914123982, Min w: 5.559012799633632e-36\n",
      "Iteration 740, Loss: 0.000497279514092952, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0005109013291075826, Min w: 1.508985536351204e-12\n",
      "Iteration 760, Loss: 0.0005049504688940942, Min w: 3.830192863178358e-14\n",
      "Iteration 770, Loss: 0.0004931709263473749, Min w: 6.259602280955789e-10\n",
      "Iteration 780, Loss: 0.0004942964878864586, Min w: 3.903028122920205e-09\n",
      "Iteration 790, Loss: 0.0004281540459487587, Min w: 0.00016207763110287488\n",
      "Iteration 800, Loss: 0.00046945776557549834, Min w: 0.013951720669865608\n",
      "Iteration 810, Loss: 0.0004995958297513425, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0004970060545019805, Min w: 0.0007776718121021986\n",
      "Iteration 830, Loss: 0.0004979952936992049, Min w: 4.233901673700302e-09\n",
      "Iteration 840, Loss: 0.0005005685961805284, Min w: 4.070937111822691e-38\n",
      "Iteration 850, Loss: 0.00047852686839178205, Min w: 4.187948945966191e-11\n",
      "Iteration 860, Loss: 0.0004736042465083301, Min w: 0.029500184580683708\n",
      "Iteration 870, Loss: 0.0003849398344755173, Min w: 0.028608903288841248\n",
      "Iteration 880, Loss: 0.0005003061378374696, Min w: 4.001442732715077e-09\n",
      "Iteration 890, Loss: 0.0004938874044455588, Min w: 9.466553005883052e-22\n",
      "Iteration 900, Loss: 0.0005020203534513712, Min w: 3.3203755265276413e-06\n",
      "Iteration 910, Loss: 0.0004994985647499561, Min w: 9.333077930287481e-14\n",
      "Iteration 920, Loss: 0.00048513326328247786, Min w: 1.9220907532258025e-08\n",
      "Iteration 930, Loss: 0.0004970119334757328, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0004933737800456583, Min w: 7.380653375387875e-32\n",
      "Iteration 950, Loss: 0.0004962878883816302, Min w: 2.2763420185682766e-32\n",
      "Iteration 960, Loss: 0.0004930453724227846, Min w: 0.001214877120219171\n",
      "Iteration 970, Loss: 0.00046012859093025327, Min w: 0.006963839288800955\n",
      "Iteration 980, Loss: 0.0004969902220182121, Min w: 1.4712149276618902e-09\n",
      "Iteration 990, Loss: 0.0004953807219862938, Min w: 0.0026221044827252626\n",
      "Iteration 1000, Loss: 0.0005103647126816213, Min w: 6.17571289107749e-32\n",
      "Iteration 1010, Loss: 0.0005070082261227071, Min w: 1.80194115184662e-09\n",
      "Iteration 1020, Loss: 0.0005069132894277573, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0004876284801866859, Min w: 0.0002665483916644007\n",
      "Iteration 1040, Loss: 0.00045735592721030116, Min w: 3.96415198338218e-05\n",
      "Iteration 1050, Loss: 0.00046229397412389517, Min w: 0.019883114844560623\n",
      "Iteration 1060, Loss: 0.0004604491114150733, Min w: 0.004204074386507273\n",
      "Iteration 1070, Loss: 0.0005102692521177232, Min w: 1.9478802877981018e-20\n",
      "Iteration 1080, Loss: 0.0005043702549301088, Min w: 1.6345545793619576e-13\n",
      "Iteration 1090, Loss: 0.0005121638532727957, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0005043311393819749, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0004938833299092948, Min w: 2.8849223357441112e-11\n",
      "Iteration 1120, Loss: 0.0004931377479806542, Min w: 1.401298464324817e-45\n",
      "Iteration 1130, Loss: 0.0005000231903977692, Min w: 2.354042649699295e-08\n",
      "Iteration 1140, Loss: 0.0004971968592144549, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0004949504509568214, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.000501087459269911, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.00051530433120206, Min w: 2.4031137865233865e-13\n",
      "Iteration 1180, Loss: 0.0004955942276865244, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0004858052125200629, Min w: 1.8087829414521498e-17\n",
      "Iteration 1200, Loss: 0.0004943326930515468, Min w: 0.00017790273705031723\n",
      "Iteration 1210, Loss: 0.0004907037364318967, Min w: 0.0004446606326382607\n",
      "Iteration 1220, Loss: 0.0004925908287987113, Min w: 0.0006681601516902447\n",
      "Iteration 1230, Loss: 0.00039824037230573595, Min w: 0.06620148569345474\n",
      "Iteration 1240, Loss: 0.0004827717784792185, Min w: 2.4064857484518143e-07\n",
      "Iteration 0, Loss: 0.0004939890932291746, Min w: 7.275829244646204e-12\n",
      "Iteration 10, Loss: 0.0004984610131941736, Min w: 1.1810200712357444e-14\n",
      "Iteration 20, Loss: 0.000501833506859839, Min w: 3.347252122719127e-33\n",
      "Iteration 30, Loss: 0.0004993233596906066, Min w: 3.662161253937877e-38\n",
      "Iteration 40, Loss: 0.0004980771336704493, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0004994600894860923, Min w: 5.885920006595824e-13\n",
      "Iteration 60, Loss: 0.0004971979651600122, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0004978462238796055, Min w: 1.4570206076314207e-05\n",
      "Iteration 80, Loss: 0.000496655993629247, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0004982704995200038, Min w: 2.3265862099271298e-38\n",
      "Iteration 100, Loss: 0.0005031069158576429, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0004992805188521743, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005026788567192852, Min w: 6.842898721162681e-35\n",
      "Iteration 130, Loss: 0.0005011470639146864, Min w: 3.2543056791012326e-12\n",
      "Iteration 140, Loss: 0.00047398440074175596, Min w: 0.03621819615364075\n",
      "Iteration 150, Loss: 0.0004766999918501824, Min w: 0.020527370274066925\n",
      "Iteration 160, Loss: 0.0004956567427143455, Min w: 3.0752600513880838e-24\n",
      "Iteration 170, Loss: 0.0005013294867239892, Min w: 3.7828019827657045e-08\n",
      "Iteration 180, Loss: 0.0004980029189027846, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005023174453526735, Min w: 1.4996049550040814e-36\n",
      "Iteration 200, Loss: 0.0005062269046902657, Min w: 2.1205275757552045e-08\n",
      "Iteration 210, Loss: 0.0004971688031218946, Min w: 1.3750877814621424e-34\n",
      "Iteration 220, Loss: 0.0004977009957656264, Min w: 6.360739737076046e-20\n",
      "Iteration 230, Loss: 0.0005085315206088126, Min w: 3.559877586667426e-05\n",
      "Iteration 240, Loss: 0.0004948534187860787, Min w: 5.031135125807035e-39\n",
      "Iteration 250, Loss: 0.0005009988672100008, Min w: 3.469702303249278e-10\n",
      "Iteration 260, Loss: 0.0004930972354486585, Min w: 1.401298464324817e-45\n",
      "Iteration 270, Loss: 0.0004907720140181482, Min w: 1.1426226631527925e-10\n",
      "Iteration 280, Loss: 0.0004923028172925115, Min w: 0.0007890006527304649\n",
      "Iteration 290, Loss: 0.0004952637827955186, Min w: 1.5155905202846043e-05\n",
      "Iteration 300, Loss: 0.0004963203682564199, Min w: 3.23432068398688e-05\n",
      "Iteration 310, Loss: 0.0004975522751919925, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005032871849834919, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005055993096902966, Min w: 8.749494184723261e-13\n",
      "Iteration 340, Loss: 0.0005014289636164904, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004924501990899444, Min w: 5.313258952810429e-07\n",
      "Iteration 360, Loss: 0.000465419638203457, Min w: 3.227507647807215e-07\n",
      "Iteration 370, Loss: 0.0004862337955273688, Min w: 0.0027322720270603895\n",
      "Iteration 380, Loss: 0.0004929141141474247, Min w: 1.645762131374795e-05\n",
      "Iteration 390, Loss: 0.0004086984263267368, Min w: 0.06868600845336914\n",
      "Iteration 400, Loss: 0.0004939408972859383, Min w: 9.59667848660084e-12\n",
      "Iteration 410, Loss: 0.00044754197006113827, Min w: 5.8537025324767455e-06\n",
      "Iteration 420, Loss: 0.0004952572635374963, Min w: 6.709312856401084e-06\n",
      "Iteration 430, Loss: 0.0004825587966479361, Min w: 0.02624448761343956\n",
      "Iteration 440, Loss: 0.0004953117459081113, Min w: 9.702174661600822e-38\n",
      "Iteration 450, Loss: 0.00044794954010285437, Min w: 0.01190935168415308\n",
      "Iteration 460, Loss: 0.00035206068423576653, Min w: 0.035700660198926926\n",
      "Iteration 470, Loss: 0.00047284155152738094, Min w: 0.000926655950024724\n",
      "Iteration 480, Loss: 0.0004981480888091028, Min w: 5.830348428034109e-15\n",
      "Iteration 490, Loss: 0.0004946301924064755, Min w: 0.002447929698973894\n",
      "Iteration 500, Loss: 0.000494149571750313, Min w: 8.602543675806373e-05\n",
      "Iteration 510, Loss: 0.00044188188621774316, Min w: 0.013753082603216171\n",
      "Iteration 520, Loss: 0.000497116707265377, Min w: 3.71126712609372e-25\n",
      "Iteration 530, Loss: 0.0005011935718357563, Min w: 1.536822833705584e-13\n",
      "Iteration 540, Loss: 0.000503208430018276, Min w: 1.1808388468426134e-12\n",
      "Iteration 550, Loss: 0.0004942325176671147, Min w: 2.71236153537302e-08\n",
      "Iteration 560, Loss: 0.0004954147734679282, Min w: 0.0\n",
      "Iteration 570, Loss: 0.00048125037574209273, Min w: 2.7170386601937935e-05\n",
      "Iteration 580, Loss: 0.0005028824089094996, Min w: 1.7033841164207532e-20\n",
      "Iteration 590, Loss: 0.0005055287037976086, Min w: 0.0\n",
      "Iteration 600, Loss: 0.000507025164552033, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005069541512057185, Min w: 0.00017742409545462579\n",
      "Iteration 620, Loss: 0.00038339855382218957, Min w: 0.022911489009857178\n",
      "Iteration 630, Loss: 0.0003844063903670758, Min w: 0.20081506669521332\n",
      "Iteration 640, Loss: 0.00045590888475999236, Min w: 0.0072000096552073956\n",
      "Iteration 650, Loss: 0.00045570687507279217, Min w: 0.034922607243061066\n",
      "Iteration 660, Loss: 0.0004613498749677092, Min w: 0.006325898692011833\n",
      "Iteration 670, Loss: 0.00048697442980483174, Min w: 0.009872177615761757\n",
      "Iteration 680, Loss: 0.0004954211181029677, Min w: 3.348542810350583e-41\n",
      "Iteration 690, Loss: 0.0004905625828541815, Min w: 1.9898925529560074e-06\n",
      "Iteration 700, Loss: 0.00048751250142231584, Min w: 0.0010614946950227022\n",
      "Iteration 710, Loss: 0.000498868350405246, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0005008977022953331, Min w: 2.6033842004835606e-05\n",
      "Iteration 730, Loss: 0.00044081249507144094, Min w: 0.07836135476827621\n",
      "Iteration 740, Loss: 0.000417554285377264, Min w: 0.07407108694314957\n",
      "Iteration 750, Loss: 0.00042879185639321804, Min w: 0.10226501524448395\n",
      "Iteration 760, Loss: 0.0004912399454042315, Min w: 5.605787464446621e-06\n",
      "Iteration 770, Loss: 0.0004943097592331469, Min w: 3.844375512374043e-11\n",
      "Iteration 780, Loss: 0.00047675141831859946, Min w: 0.009581715799868107\n",
      "Iteration 790, Loss: 0.0003741148975677788, Min w: 0.2364039570093155\n",
      "Iteration 800, Loss: 0.00034008934744633734, Min w: 0.19495192170143127\n",
      "Iteration 810, Loss: 0.0004072522569913417, Min w: 0.175685852766037\n",
      "Iteration 820, Loss: 0.0004995063645765185, Min w: 5.964480992437515e-11\n",
      "Iteration 830, Loss: 0.0005009673768654466, Min w: 0.00022135055041871965\n",
      "Iteration 840, Loss: 0.0004997220239602029, Min w: 1.9224826224167077e-16\n",
      "Iteration 850, Loss: 0.0005016322829760611, Min w: 2.699816142437529e-29\n",
      "Iteration 860, Loss: 0.0005004503182135522, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0004974720650352538, Min w: 1.5226509113353462e-41\n",
      "Iteration 880, Loss: 0.000495529908221215, Min w: 1.8164887649607664e-10\n",
      "Iteration 890, Loss: 0.00043234057375229895, Min w: 0.11671493202447891\n",
      "Iteration 900, Loss: 0.0004210763145238161, Min w: 0.035746775567531586\n",
      "Iteration 910, Loss: 0.00046619909699074924, Min w: 0.012700431048870087\n",
      "Iteration 920, Loss: 0.0004902329528704286, Min w: 6.05538189120125e-05\n",
      "Iteration 930, Loss: 0.0004940677317790687, Min w: 0.0007233434007503092\n",
      "Iteration 940, Loss: 0.0005024835118092597, Min w: 1.7709281818767408e-09\n",
      "Iteration 950, Loss: 0.0004967305576428771, Min w: 5.128781848646828e-16\n",
      "Iteration 960, Loss: 0.0005039640236645937, Min w: 3.4775762998429105e-12\n",
      "Iteration 970, Loss: 0.0005020946264266968, Min w: 1.401298464324817e-45\n",
      "Iteration 980, Loss: 0.0005059352261014283, Min w: 7.529092234047489e-18\n",
      "Iteration 990, Loss: 0.0005038019153289497, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0004990629968233407, Min w: 2.870833293311392e-10\n",
      "Iteration 1010, Loss: 0.0004955254262313247, Min w: 6.905155266896131e-26\n",
      "Iteration 1020, Loss: 0.0004948742571286857, Min w: 1.324181994277751e-06\n",
      "Iteration 1030, Loss: 0.0005033095367252827, Min w: 2.7299981564746723e-34\n",
      "Iteration 1040, Loss: 0.0005002946127206087, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0004923605010844767, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.000493324245326221, Min w: 1.6900019561591277e-17\n",
      "Iteration 1070, Loss: 0.0004876388411503285, Min w: 2.608608156151604e-05\n",
      "Iteration 1080, Loss: 0.0003344860451761633, Min w: 0.13179942965507507\n",
      "Iteration 1090, Loss: 0.0004536298511084169, Min w: 0.07727468758821487\n",
      "Iteration 1100, Loss: 0.000491332495585084, Min w: 0.005750671494752169\n",
      "Iteration 1110, Loss: 0.0004932997981086373, Min w: 0.00011324838851578534\n",
      "Iteration 1120, Loss: 0.0005012524779886007, Min w: 1.3088085921635594e-19\n",
      "Iteration 1130, Loss: 0.0004901434294879436, Min w: 8.657971193315461e-06\n",
      "Iteration 1140, Loss: 0.0005011283210478723, Min w: 1.2944822238119566e-21\n",
      "Iteration 1150, Loss: 0.0004996767966076732, Min w: 2.0541500792004008e-11\n",
      "Iteration 1160, Loss: 0.0005021647084504366, Min w: 3.7192408342864527e-28\n",
      "Iteration 1170, Loss: 0.0005016638315282762, Min w: 1.0321168832788663e-12\n",
      "Iteration 1180, Loss: 0.0005021017859689891, Min w: 3.0828566215145976e-44\n",
      "Iteration 1190, Loss: 0.00048801314551383257, Min w: 6.320325951492123e-08\n",
      "Iteration 1200, Loss: 0.0004991703317500651, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0005011882167309523, Min w: 2.0609167410007444e-25\n",
      "Iteration 1220, Loss: 0.00048087447066791356, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0004957396304234862, Min w: 3.1150232205317933e-18\n",
      "Iteration 1240, Loss: 0.0004844773793593049, Min w: 1.0108081369253341e-05\n",
      "Iteration 0, Loss: 0.0004983478575013578, Min w: 9.571021682445655e-14\n",
      "Iteration 10, Loss: 0.0004993191687390208, Min w: 7.96754479091162e-34\n",
      "Iteration 20, Loss: 0.0004918232443742454, Min w: 2.296225189157841e-11\n",
      "Iteration 30, Loss: 0.0004463929508347064, Min w: 0.0051999506540596485\n",
      "Iteration 40, Loss: 0.0004049855924677104, Min w: 0.0804818645119667\n",
      "Iteration 50, Loss: 0.00030197069281712174, Min w: 0.21104992926120758\n",
      "Iteration 60, Loss: 0.00027179683092981577, Min w: 0.16787287592887878\n",
      "Iteration 70, Loss: 0.000411203654948622, Min w: 0.15383155643939972\n",
      "Iteration 80, Loss: 0.0004963499959558249, Min w: 6.618755683910097e-16\n",
      "Iteration 90, Loss: 0.00048414181219413877, Min w: 6.713671609759331e-06\n",
      "Iteration 100, Loss: 0.0004415841249283403, Min w: 0.018543720245361328\n",
      "Iteration 110, Loss: 0.0004930589930154383, Min w: 0.00012676192272920161\n",
      "Iteration 120, Loss: 0.00048383991816081107, Min w: 1.3196465031839466e-09\n",
      "Iteration 130, Loss: 0.00041220159619115293, Min w: 0.01370304450392723\n",
      "Iteration 140, Loss: 0.00038716953713446856, Min w: 0.15074977278709412\n",
      "Iteration 150, Loss: 0.0004076663462910801, Min w: 0.11290472000837326\n",
      "Iteration 160, Loss: 0.00048634366248734295, Min w: 0.0001908351987367496\n",
      "Iteration 170, Loss: 0.00043993446161039174, Min w: 0.09809432923793793\n",
      "Iteration 180, Loss: 0.0003380032430868596, Min w: 0.2626315951347351\n",
      "Iteration 190, Loss: 0.00027375033823773265, Min w: 0.2934604585170746\n",
      "Iteration 200, Loss: 0.0003201131185051054, Min w: 0.24191413819789886\n",
      "Iteration 210, Loss: 0.00033667017123661935, Min w: 0.28459036350250244\n",
      "Iteration 220, Loss: 0.0003148757677990943, Min w: 0.31210821866989136\n",
      "Iteration 230, Loss: 0.00034319370752200484, Min w: 0.31658637523651123\n",
      "Iteration 240, Loss: 0.0003093091945629567, Min w: 0.326285183429718\n",
      "Iteration 250, Loss: 0.0003167739778291434, Min w: 0.3590838313102722\n",
      "Iteration 260, Loss: 0.00032580416882410645, Min w: 0.3134934902191162\n",
      "Iteration 270, Loss: 0.0003154642472509295, Min w: 0.36712339520454407\n",
      "Iteration 280, Loss: 0.0002797985216602683, Min w: 0.36778828501701355\n",
      "Iteration 290, Loss: 0.0002924921573139727, Min w: 0.37538838386535645\n",
      "Iteration 300, Loss: 0.0002725704980548471, Min w: 0.40826165676116943\n",
      "Iteration 310, Loss: 0.00028452277183532715, Min w: 0.4200751781463623\n",
      "Iteration 320, Loss: 0.0002669939713086933, Min w: 0.4021364748477936\n",
      "Iteration 330, Loss: 0.00026574142975732684, Min w: 0.3995867073535919\n",
      "Iteration 340, Loss: 0.0002459682000335306, Min w: 0.43055352568626404\n",
      "Iteration 350, Loss: 0.0002488106838427484, Min w: 0.43817847967147827\n",
      "Iteration 360, Loss: 0.00023138421238400042, Min w: 0.4565936326980591\n",
      "Iteration 370, Loss: 0.0002315513847861439, Min w: 0.46712857484817505\n",
      "Iteration 380, Loss: 0.0002250472316518426, Min w: 0.4623502790927887\n",
      "Iteration 390, Loss: 0.0002552993537392467, Min w: 0.4602012038230896\n",
      "Iteration 400, Loss: 0.0002686720108613372, Min w: 0.4198307394981384\n",
      "Iteration 410, Loss: 0.0002515791275072843, Min w: 0.44035500288009644\n",
      "Iteration 420, Loss: 0.0002511246129870415, Min w: 0.44690757989883423\n",
      "Iteration 430, Loss: 0.0002246446965727955, Min w: 0.45344117283821106\n",
      "Iteration 440, Loss: 0.00021721608936786652, Min w: 0.4485967457294464\n",
      "Iteration 450, Loss: 0.0002478430396877229, Min w: 0.42395803332328796\n",
      "Iteration 460, Loss: 0.00021329066657926887, Min w: 0.4789208471775055\n",
      "Iteration 470, Loss: 0.00020203036547172815, Min w: 0.5049313306808472\n",
      "Iteration 480, Loss: 0.00023200578289106488, Min w: 0.46108484268188477\n",
      "Iteration 490, Loss: 0.00021738174837082624, Min w: 0.47517481446266174\n",
      "Iteration 500, Loss: 0.00022494810400530696, Min w: 0.4794664680957794\n",
      "Iteration 510, Loss: 0.00022166050621308386, Min w: 0.4792366623878479\n",
      "Iteration 520, Loss: 0.00022736001119483262, Min w: 0.48804935812950134\n",
      "Iteration 530, Loss: 0.00021378890960477293, Min w: 0.49428364634513855\n",
      "Iteration 540, Loss: 0.00018257839838042855, Min w: 0.5222266316413879\n",
      "Iteration 550, Loss: 0.00021407296299003065, Min w: 0.48480281233787537\n",
      "Iteration 560, Loss: 0.00020443281391635537, Min w: 0.5112007260322571\n",
      "Iteration 570, Loss: 0.0001888758852146566, Min w: 0.5281765460968018\n",
      "Iteration 580, Loss: 0.0002181488962378353, Min w: 0.475289911031723\n",
      "Iteration 590, Loss: 0.000221509239054285, Min w: 0.47089558839797974\n",
      "Iteration 600, Loss: 0.00016468160902149975, Min w: 0.54442298412323\n",
      "Iteration 610, Loss: 0.00021229806588962674, Min w: 0.507414698600769\n",
      "Iteration 620, Loss: 0.00019369657093193382, Min w: 0.5279877781867981\n",
      "Iteration 630, Loss: 0.00021429173648357391, Min w: 0.5018302202224731\n",
      "Iteration 640, Loss: 0.00021951011149212718, Min w: 0.48719510436058044\n",
      "Iteration 650, Loss: 0.0001935678446898237, Min w: 0.5415251851081848\n",
      "Iteration 660, Loss: 0.00019063425133936107, Min w: 0.5446540713310242\n",
      "Iteration 670, Loss: 0.00018546852516010404, Min w: 0.5417489409446716\n",
      "Iteration 680, Loss: 0.00021239307534415275, Min w: 0.5113590359687805\n",
      "Iteration 690, Loss: 0.00018327633733861148, Min w: 0.5480254292488098\n",
      "Iteration 700, Loss: 0.00018753294716589153, Min w: 0.561496913433075\n",
      "Iteration 710, Loss: 0.000201785282115452, Min w: 0.5336527824401855\n",
      "Iteration 720, Loss: 0.00018498160352464765, Min w: 0.5342854261398315\n",
      "Iteration 730, Loss: 0.00016743832384236157, Min w: 0.5640624761581421\n",
      "Iteration 740, Loss: 0.0001791111280908808, Min w: 0.5225377082824707\n",
      "Iteration 750, Loss: 0.00019537322805263102, Min w: 0.5360038876533508\n",
      "Iteration 760, Loss: 0.0001957539061550051, Min w: 0.5490302443504333\n",
      "Iteration 770, Loss: 0.00018121872562915087, Min w: 0.5658130049705505\n",
      "Iteration 780, Loss: 0.0001754766853991896, Min w: 0.5694324970245361\n",
      "Iteration 790, Loss: 0.00019066297682002187, Min w: 0.5397377014160156\n",
      "Iteration 800, Loss: 0.00019232580962125212, Min w: 0.5572225451469421\n",
      "Iteration 810, Loss: 0.00018402768182568252, Min w: 0.5606802105903625\n",
      "Iteration 820, Loss: 0.00018417507817503065, Min w: 0.5741176605224609\n",
      "Iteration 830, Loss: 0.00015394178626593202, Min w: 0.5948426723480225\n",
      "Iteration 840, Loss: 0.00017049215966835618, Min w: 0.5722649693489075\n",
      "Iteration 850, Loss: 0.00019359157886356115, Min w: 0.552310049533844\n",
      "Iteration 860, Loss: 0.00019320314459037036, Min w: 0.5744997262954712\n",
      "Iteration 870, Loss: 0.00016215881623793393, Min w: 0.5644824504852295\n",
      "Iteration 880, Loss: 0.00014277789159677923, Min w: 0.6151422262191772\n",
      "Iteration 890, Loss: 0.00014579234994016588, Min w: 0.607804000377655\n",
      "Iteration 900, Loss: 0.0001575716451043263, Min w: 0.5728683471679688\n",
      "Iteration 910, Loss: 0.000193480693269521, Min w: 0.5797314643859863\n",
      "Iteration 920, Loss: 0.00017448286234866828, Min w: 0.5969167351722717\n",
      "Iteration 930, Loss: 0.00015956908464431763, Min w: 0.5981644988059998\n",
      "Iteration 940, Loss: 0.00018461834406480193, Min w: 0.5688377618789673\n",
      "Iteration 950, Loss: 0.00017344707157462835, Min w: 0.6100447773933411\n",
      "Iteration 960, Loss: 0.00015370863548014313, Min w: 0.6075809001922607\n",
      "Iteration 970, Loss: 0.0001684756571194157, Min w: 0.59172523021698\n",
      "Iteration 980, Loss: 0.00017957969976123422, Min w: 0.596471905708313\n",
      "Iteration 990, Loss: 0.00016510783461853862, Min w: 0.5859398245811462\n",
      "Iteration 1000, Loss: 0.00020832063455600291, Min w: 0.5786533355712891\n",
      "Iteration 1010, Loss: 0.00015695701586082578, Min w: 0.6153353452682495\n",
      "Iteration 1020, Loss: 0.00017582498549018055, Min w: 0.5610914826393127\n",
      "Iteration 1030, Loss: 0.00019118438649456948, Min w: 0.6164711713790894\n",
      "Iteration 1040, Loss: 0.00015618304314557463, Min w: 0.6065182089805603\n",
      "Iteration 1050, Loss: 0.00015929769142530859, Min w: 0.6305159330368042\n",
      "Iteration 1060, Loss: 0.00016391495591960847, Min w: 0.6082783341407776\n",
      "Iteration 1070, Loss: 0.00017998683324549347, Min w: 0.5908732414245605\n",
      "Iteration 1080, Loss: 0.00017130964261014014, Min w: 0.6165652871131897\n",
      "Iteration 1090, Loss: 0.00019035908917430788, Min w: 0.587292492389679\n",
      "Iteration 1100, Loss: 0.0001727748749544844, Min w: 0.5830329060554504\n",
      "Iteration 1110, Loss: 0.0001638090907363221, Min w: 0.6256705522537231\n",
      "Iteration 1120, Loss: 0.00016440606850665063, Min w: 0.6041626930236816\n",
      "Iteration 1130, Loss: 0.000157583795953542, Min w: 0.6317695379257202\n",
      "Iteration 1140, Loss: 0.00016124786634463817, Min w: 0.6168097853660583\n",
      "Iteration 1150, Loss: 0.0001733151002554223, Min w: 0.628302276134491\n",
      "Iteration 1160, Loss: 0.00016527283878531307, Min w: 0.6197674870491028\n",
      "Iteration 1170, Loss: 0.00015655036258976907, Min w: 0.6339665055274963\n",
      "Iteration 1180, Loss: 0.0001640144328121096, Min w: 0.637193500995636\n",
      "Iteration 1190, Loss: 0.00015238871856126934, Min w: 0.6627012491226196\n",
      "Iteration 1200, Loss: 0.00012932774552609771, Min w: 0.6622457504272461\n",
      "Iteration 1210, Loss: 0.00014958651445340365, Min w: 0.6371919512748718\n",
      "Iteration 1220, Loss: 0.00015300887753255665, Min w: 0.6553753614425659\n",
      "Iteration 1230, Loss: 0.00014802291116211563, Min w: 0.658333420753479\n",
      "Iteration 1240, Loss: 0.00014617317356169224, Min w: 0.6586776375770569\n",
      "Iteration 0, Loss: 0.00013306633627507836, Min w: 0.6590328812599182\n",
      "Iteration 10, Loss: 0.00012404756853356957, Min w: 0.6717075705528259\n",
      "Iteration 20, Loss: 0.00016547474660910666, Min w: 0.6647990942001343\n",
      "Iteration 30, Loss: 0.00013451128324959427, Min w: 0.6726361513137817\n",
      "Iteration 40, Loss: 0.00014257598377298564, Min w: 0.673541784286499\n",
      "Iteration 50, Loss: 0.00014067294250708073, Min w: 0.6704325079917908\n",
      "Iteration 60, Loss: 0.00016389517986681312, Min w: 0.6536433696746826\n",
      "Iteration 70, Loss: 0.00014436904166359454, Min w: 0.6752890944480896\n",
      "Iteration 80, Loss: 0.0001282860030187294, Min w: 0.6937422156333923\n",
      "Iteration 90, Loss: 0.00012585717195179313, Min w: 0.688766598701477\n",
      "Iteration 100, Loss: 0.00011816871847258881, Min w: 0.7051071524620056\n",
      "Iteration 110, Loss: 0.0001379751629428938, Min w: 0.6883237957954407\n",
      "Iteration 120, Loss: 0.00016400280583184212, Min w: 0.6559923887252808\n",
      "Iteration 130, Loss: 0.00013793515972793102, Min w: 0.6954150199890137\n",
      "Iteration 140, Loss: 0.0001599405804881826, Min w: 0.6548528075218201\n",
      "Iteration 150, Loss: 0.000137216760776937, Min w: 0.7054380178451538\n",
      "Iteration 160, Loss: 0.00012338111991994083, Min w: 0.698935329914093\n",
      "Iteration 170, Loss: 0.00013013731222599745, Min w: 0.7172963619232178\n",
      "Iteration 180, Loss: 0.00013241144188214093, Min w: 0.7010273337364197\n",
      "Iteration 190, Loss: 0.00014425406698137522, Min w: 0.7045528292655945\n",
      "Iteration 200, Loss: 0.00013141793897375464, Min w: 0.6950562596321106\n",
      "Iteration 210, Loss: 0.00014021825336385518, Min w: 0.6924034953117371\n",
      "Iteration 220, Loss: 0.00013035413576290011, Min w: 0.7048662900924683\n",
      "Iteration 230, Loss: 0.00012115230492781848, Min w: 0.736102283000946\n",
      "Iteration 240, Loss: 0.00013546663103625178, Min w: 0.7247356176376343\n",
      "Iteration 250, Loss: 0.00012966617941856384, Min w: 0.7180838584899902\n",
      "Iteration 260, Loss: 0.00012158160097897053, Min w: 0.7067129611968994\n",
      "Iteration 270, Loss: 0.00010726327309384942, Min w: 0.744134783744812\n",
      "Iteration 280, Loss: 0.00011495284707052633, Min w: 0.7474068403244019\n",
      "Iteration 290, Loss: 0.00013008319365326315, Min w: 0.7137346267700195\n",
      "Iteration 300, Loss: 0.00014328333782032132, Min w: 0.6724424362182617\n",
      "Iteration 310, Loss: 0.00013005841174162924, Min w: 0.7361326813697815\n",
      "Iteration 320, Loss: 0.00013146641140338033, Min w: 0.7278804779052734\n",
      "Iteration 330, Loss: 0.00011804411769844592, Min w: 0.7577080726623535\n",
      "Iteration 340, Loss: 0.0001075064719771035, Min w: 0.7707270979881287\n",
      "Iteration 350, Loss: 0.00012094451813027263, Min w: 0.746075451374054\n",
      "Iteration 360, Loss: 0.00013599811063613743, Min w: 0.7168260812759399\n",
      "Iteration 370, Loss: 0.0001260390126844868, Min w: 0.7437818646430969\n",
      "Iteration 380, Loss: 0.00010731279326137155, Min w: 0.7780894041061401\n",
      "Iteration 390, Loss: 0.00012588940444402397, Min w: 0.72971510887146\n",
      "Iteration 400, Loss: 0.0001125994385802187, Min w: 0.7714419960975647\n",
      "Iteration 410, Loss: 0.00012129345850553364, Min w: 0.7486234903335571\n",
      "Iteration 420, Loss: 0.00011457477376097813, Min w: 0.7189757823944092\n",
      "Iteration 430, Loss: 0.00011611218360485509, Min w: 0.7533360719680786\n",
      "Iteration 440, Loss: 0.00012327093281783164, Min w: 0.7042437791824341\n",
      "Iteration 450, Loss: 0.0001264277088921517, Min w: 0.6987721920013428\n",
      "Iteration 460, Loss: 0.00012118281301809475, Min w: 0.7173430919647217\n",
      "Iteration 470, Loss: 0.00010715928510762751, Min w: 0.7721768617630005\n",
      "Iteration 480, Loss: 0.00012905968469567597, Min w: 0.6987427473068237\n",
      "Iteration 490, Loss: 0.000107224790554028, Min w: 0.7762683033943176\n",
      "Iteration 500, Loss: 0.00012022304872516543, Min w: 0.7282244563102722\n",
      "Iteration 510, Loss: 0.00011329988046782091, Min w: 0.7636865377426147\n",
      "Iteration 520, Loss: 0.00010805635247379541, Min w: 0.7633123397827148\n",
      "Iteration 530, Loss: 0.00011171808728249744, Min w: 0.7345899343490601\n",
      "Iteration 540, Loss: 0.00012239509669598192, Min w: 0.7321815490722656\n",
      "Iteration 550, Loss: 0.00012044861068716273, Min w: 0.7021323442459106\n",
      "Iteration 560, Loss: 0.00010504855890758336, Min w: 0.7600875496864319\n",
      "Iteration 570, Loss: 0.00011982268915744498, Min w: 0.7295944094657898\n",
      "Iteration 580, Loss: 0.00010687635221984237, Min w: 0.7369109392166138\n",
      "Iteration 590, Loss: 0.00010681025742087513, Min w: 0.7748377919197083\n",
      "Iteration 600, Loss: 9.114233398577198e-05, Min w: 0.7904446721076965\n",
      "Iteration 610, Loss: 0.00010982953244820237, Min w: 0.7615377306938171\n",
      "Iteration 620, Loss: 0.0001043708180077374, Min w: 0.7599388957023621\n",
      "Iteration 630, Loss: 8.93132237251848e-05, Min w: 0.8025369048118591\n",
      "Iteration 640, Loss: 0.00011832069867523387, Min w: 0.7488231062889099\n",
      "Iteration 650, Loss: 0.00010927589755738154, Min w: 0.7652475833892822\n",
      "Iteration 660, Loss: 8.347829862032086e-05, Min w: 0.811720609664917\n",
      "Iteration 670, Loss: 9.896888514049351e-05, Min w: 0.7828937768936157\n",
      "Iteration 680, Loss: 0.0001245138846570626, Min w: 0.6806411743164062\n",
      "Iteration 690, Loss: 0.00010928494157269597, Min w: 0.742969810962677\n",
      "Iteration 700, Loss: 7.293944509001449e-05, Min w: 0.8451511859893799\n",
      "Iteration 710, Loss: 0.00010746787302196026, Min w: 0.7774162888526917\n",
      "Iteration 720, Loss: 9.789977048058063e-05, Min w: 0.772065281867981\n",
      "Iteration 730, Loss: 9.786256850929931e-05, Min w: 0.7523458003997803\n",
      "Iteration 740, Loss: 0.00012316218635533005, Min w: 0.7133989930152893\n",
      "Iteration 750, Loss: 0.00010119486978510395, Min w: 0.754385769367218\n",
      "Iteration 760, Loss: 0.00011330979032209143, Min w: 0.7432718873023987\n",
      "Iteration 770, Loss: 0.00010514500900171697, Min w: 0.7230547070503235\n",
      "Iteration 780, Loss: 7.278392149601132e-05, Min w: 0.8284251689910889\n",
      "Iteration 790, Loss: 0.00010386339272372425, Min w: 0.748650312423706\n",
      "Iteration 800, Loss: 8.072979107964784e-05, Min w: 0.8167524337768555\n",
      "Iteration 810, Loss: 8.327934483531862e-05, Min w: 0.7904008626937866\n",
      "Iteration 820, Loss: 0.00011087091115768999, Min w: 0.6979765892028809\n",
      "Iteration 830, Loss: 9.046358900377527e-05, Min w: 0.7910547256469727\n",
      "Iteration 840, Loss: 7.521080988226458e-05, Min w: 0.8145108222961426\n",
      "Iteration 850, Loss: 9.368701284984127e-05, Min w: 0.7496097683906555\n",
      "Iteration 860, Loss: 0.00010335724800825119, Min w: 0.711588978767395\n",
      "Iteration 870, Loss: 8.571021317038685e-05, Min w: 0.8237336277961731\n",
      "Iteration 880, Loss: 0.00010957704944303259, Min w: 0.6712112426757812\n",
      "Iteration 890, Loss: 0.0001125691705965437, Min w: 0.760370671749115\n",
      "Iteration 900, Loss: 7.492973236367106e-05, Min w: 0.8049802184104919\n",
      "Iteration 910, Loss: 8.886463183443993e-05, Min w: 0.7731379866600037\n",
      "Iteration 920, Loss: 9.703835530672222e-05, Min w: 0.731221616268158\n",
      "Iteration 930, Loss: 0.00010748396016424522, Min w: 0.7368521094322205\n",
      "Iteration 940, Loss: 8.442132821073756e-05, Min w: 0.7707396745681763\n",
      "Iteration 950, Loss: 7.179062231443822e-05, Min w: 0.8091872930526733\n",
      "Iteration 960, Loss: 0.00010208506864728406, Min w: 0.7279572486877441\n",
      "Iteration 970, Loss: 9.413008956471458e-05, Min w: 0.7633993029594421\n",
      "Iteration 980, Loss: 7.243465370265767e-05, Min w: 0.8398904204368591\n",
      "Iteration 990, Loss: 7.693911175010726e-05, Min w: 0.789350688457489\n",
      "Iteration 1000, Loss: 0.00011667236685752869, Min w: 0.7531231045722961\n",
      "Iteration 1010, Loss: 6.642059452133253e-05, Min w: 0.8506473898887634\n",
      "Iteration 1020, Loss: 7.239863043650985e-05, Min w: 0.8301241993904114\n",
      "Iteration 1030, Loss: 8.595612598583102e-05, Min w: 0.7859161496162415\n",
      "Iteration 1040, Loss: 9.099184535443783e-05, Min w: 0.7384118437767029\n",
      "Iteration 1050, Loss: 8.444934064755216e-05, Min w: 0.7884727120399475\n",
      "Iteration 1060, Loss: 7.200736581580713e-05, Min w: 0.8047670722007751\n",
      "Iteration 1070, Loss: 9.196404425892979e-05, Min w: 0.7382145524024963\n",
      "Iteration 1080, Loss: 7.12013861630112e-05, Min w: 0.8339784741401672\n",
      "Iteration 1090, Loss: 7.449747499777004e-05, Min w: 0.7957796454429626\n",
      "Iteration 1100, Loss: 8.324640657519922e-05, Min w: 0.7672067284584045\n",
      "Iteration 1110, Loss: 7.851256668800488e-05, Min w: 0.836661159992218\n",
      "Iteration 1120, Loss: 5.325732854544185e-05, Min w: 0.8640069961547852\n",
      "Iteration 1130, Loss: 3.998017200501636e-05, Min w: 0.91423100233078\n",
      "Iteration 1140, Loss: 6.988408858887851e-05, Min w: 0.8064713478088379\n",
      "Iteration 1150, Loss: 7.978461508173496e-05, Min w: 0.8157749772071838\n",
      "Iteration 1160, Loss: 8.470346801914275e-05, Min w: 0.7667235732078552\n",
      "Iteration 1170, Loss: 8.28537013148889e-05, Min w: 0.7908926010131836\n",
      "Iteration 1180, Loss: 8.061167318373919e-05, Min w: 0.754630446434021\n",
      "Iteration 1190, Loss: 8.383145177504048e-05, Min w: 0.8275634050369263\n",
      "Iteration 1200, Loss: 8.85360932443291e-05, Min w: 0.7333053946495056\n",
      "Iteration 1210, Loss: 9.071854583453387e-05, Min w: 0.7940351366996765\n",
      "Iteration 1220, Loss: 5.804076499771327e-05, Min w: 0.8434465527534485\n",
      "Iteration 1230, Loss: 4.652491770684719e-05, Min w: 0.8924844264984131\n",
      "Iteration 1240, Loss: 7.363333861576393e-05, Min w: 0.7873361706733704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  83%|████████▎ | 20/24 [33:30<07:32, 113.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.025391596359759076, 'L2_avg': 0.041967502515927145, 'End_point_L1_avg': 0.003580752322279819, 'End_point_L2_avg': 0.004068941604024352}\n",
      "Iteration 0, Loss: 0.003640442155301571, Min w: 3.859873884972928e-17\n",
      "Iteration 10, Loss: 0.003222382627427578, Min w: 1.020629738010665e-23\n",
      "Iteration 20, Loss: 0.003125101327896118, Min w: 6.719504064027116e-22\n",
      "Iteration 30, Loss: 0.002492110012099147, Min w: 1.8616748201555784e-20\n",
      "Iteration 40, Loss: 0.0021983052138239145, Min w: 1.3572783101969445e-14\n",
      "Iteration 50, Loss: 0.002278232481330633, Min w: 5.6099358014885525e-14\n",
      "Iteration 60, Loss: 0.002107698703184724, Min w: 4.285051588732991e-13\n",
      "Iteration 70, Loss: 0.0019135974580422044, Min w: 2.2790314557416536e-13\n",
      "Iteration 80, Loss: 0.001902200747281313, Min w: 4.0221985464494736e-11\n",
      "Iteration 90, Loss: 0.0018421815475448966, Min w: 1.2151109451963293e-08\n",
      "Iteration 100, Loss: 0.00190347945317626, Min w: 8.716628144611605e-06\n",
      "Iteration 110, Loss: 0.0017955162329599261, Min w: 0.0007585954153910279\n",
      "Iteration 120, Loss: 0.001827715546824038, Min w: 0.004142345394939184\n",
      "Iteration 130, Loss: 0.0017808657139539719, Min w: 0.0004403700295370072\n",
      "Iteration 140, Loss: 0.0016910333652049303, Min w: 0.00013589962327387184\n",
      "Iteration 150, Loss: 0.0016526958206668496, Min w: 0.0005518093821592629\n",
      "Iteration 160, Loss: 0.0016213124617934227, Min w: 0.0025226850993931293\n",
      "Iteration 170, Loss: 0.00157420733012259, Min w: 0.007192189339548349\n",
      "Iteration 180, Loss: 0.001535765710286796, Min w: 0.01644544117152691\n",
      "Iteration 190, Loss: 0.0015207380056381226, Min w: 0.04096762463450432\n",
      "Iteration 200, Loss: 0.0014263726770877838, Min w: 0.0733383521437645\n",
      "Iteration 210, Loss: 0.0013943492667749524, Min w: 0.08892695605754852\n",
      "Iteration 220, Loss: 0.0013866203371435404, Min w: 0.12371230125427246\n",
      "Iteration 230, Loss: 0.0013320189900696278, Min w: 0.1650276780128479\n",
      "Iteration 240, Loss: 0.001264831516891718, Min w: 0.19478988647460938\n",
      "Iteration 250, Loss: 0.0012277315836399794, Min w: 0.21694804728031158\n",
      "Iteration 260, Loss: 0.0012481025187298656, Min w: 0.21726275980472565\n",
      "Iteration 270, Loss: 0.001203211024403572, Min w: 0.24947239458560944\n",
      "Iteration 280, Loss: 0.0011498674284666777, Min w: 0.24744631350040436\n",
      "Iteration 290, Loss: 0.001103130867704749, Min w: 0.26930826902389526\n",
      "Iteration 300, Loss: 0.0010733804665505886, Min w: 0.3022056519985199\n",
      "Iteration 310, Loss: 0.0010587407741695642, Min w: 0.28565701842308044\n",
      "Iteration 320, Loss: 0.0010810253443196416, Min w: 0.2878124713897705\n",
      "Iteration 330, Loss: 0.0010137915378436446, Min w: 0.3231427073478699\n",
      "Iteration 340, Loss: 0.0010271909413859248, Min w: 0.31021904945373535\n",
      "Iteration 350, Loss: 0.000986161408945918, Min w: 0.3368632197380066\n",
      "Iteration 360, Loss: 0.0009521445608697832, Min w: 0.35800647735595703\n",
      "Iteration 370, Loss: 0.000958302291110158, Min w: 0.3790965676307678\n",
      "Iteration 380, Loss: 0.0009773664642125368, Min w: 0.3422185480594635\n",
      "Iteration 390, Loss: 0.0009197932085953653, Min w: 0.37984007596969604\n",
      "Iteration 400, Loss: 0.0008948107133619487, Min w: 0.39514943957328796\n",
      "Iteration 410, Loss: 0.0009267217246815562, Min w: 0.3781222105026245\n",
      "Iteration 420, Loss: 0.0008999460842460394, Min w: 0.3994183838367462\n",
      "Iteration 430, Loss: 0.0008586723706685007, Min w: 0.40543878078460693\n",
      "Iteration 440, Loss: 0.0008641491876915097, Min w: 0.41193175315856934\n",
      "Iteration 450, Loss: 0.000878434453625232, Min w: 0.40104594826698303\n",
      "Iteration 460, Loss: 0.0008326536044478416, Min w: 0.4354375898838043\n",
      "Iteration 470, Loss: 0.0007974916370585561, Min w: 0.4493222236633301\n",
      "Iteration 480, Loss: 0.0007935118628665805, Min w: 0.4537554085254669\n",
      "Iteration 490, Loss: 0.0007815773715265095, Min w: 0.45913466811180115\n",
      "Iteration 500, Loss: 0.0008069852483458817, Min w: 0.44745326042175293\n",
      "Iteration 510, Loss: 0.0007781179156154394, Min w: 0.46894827485084534\n",
      "Iteration 520, Loss: 0.0007237167446874082, Min w: 0.49978670477867126\n",
      "Iteration 530, Loss: 0.000727639242541045, Min w: 0.4852629005908966\n",
      "Iteration 540, Loss: 0.0007369298255071044, Min w: 0.4926025867462158\n",
      "Iteration 550, Loss: 0.0006916168495081365, Min w: 0.5246303081512451\n",
      "Iteration 560, Loss: 0.0007298606215044856, Min w: 0.5007840394973755\n",
      "Iteration 570, Loss: 0.0006813368527218699, Min w: 0.5353992581367493\n",
      "Iteration 580, Loss: 0.000690265151206404, Min w: 0.5215080380439758\n",
      "Iteration 590, Loss: 0.0006908957730047405, Min w: 0.526409924030304\n",
      "Iteration 600, Loss: 0.000689619337208569, Min w: 0.522262692451477\n",
      "Iteration 610, Loss: 0.0006707641878165305, Min w: 0.5323117971420288\n",
      "Iteration 620, Loss: 0.0006175175658427179, Min w: 0.5784556865692139\n",
      "Iteration 630, Loss: 0.0006011265213601291, Min w: 0.5714961886405945\n",
      "Iteration 640, Loss: 0.0006365971057675779, Min w: 0.5572669506072998\n",
      "Iteration 650, Loss: 0.0006240690127015114, Min w: 0.5670708417892456\n",
      "Iteration 660, Loss: 0.0006101428880356252, Min w: 0.5831234455108643\n",
      "Iteration 670, Loss: 0.0006162351928651333, Min w: 0.5641891360282898\n",
      "Iteration 680, Loss: 0.0006247046403586864, Min w: 0.5634915828704834\n",
      "Iteration 690, Loss: 0.0006037565181031823, Min w: 0.5867549180984497\n",
      "Iteration 700, Loss: 0.0005978065310046077, Min w: 0.5744729042053223\n",
      "Iteration 710, Loss: 0.0005770900170318782, Min w: 0.5851104855537415\n",
      "Iteration 720, Loss: 0.0005984800518490374, Min w: 0.5851160883903503\n",
      "Iteration 730, Loss: 0.0005379072390496731, Min w: 0.6285392642021179\n",
      "Iteration 740, Loss: 0.000546050607226789, Min w: 0.6204609870910645\n",
      "Iteration 750, Loss: 0.0005782190128229558, Min w: 0.6003841757774353\n",
      "Iteration 760, Loss: 0.0005682576447725296, Min w: 0.6247079372406006\n",
      "Iteration 770, Loss: 0.0005292582209222019, Min w: 0.6479007005691528\n",
      "Iteration 780, Loss: 0.0005231857066974044, Min w: 0.6414639353752136\n",
      "Iteration 790, Loss: 0.0005385810509324074, Min w: 0.637572169303894\n",
      "Iteration 800, Loss: 0.0005015336209908128, Min w: 0.6525081396102905\n",
      "Iteration 810, Loss: 0.0005283375503495336, Min w: 0.6516485214233398\n",
      "Iteration 820, Loss: 0.0005029700696468353, Min w: 0.6475790739059448\n",
      "Iteration 830, Loss: 0.000564095564186573, Min w: 0.6179035305976868\n",
      "Iteration 840, Loss: 0.0004920617793686688, Min w: 0.6614095568656921\n",
      "Iteration 850, Loss: 0.0004934887401759624, Min w: 0.6688879132270813\n",
      "Iteration 860, Loss: 0.00048532860819250345, Min w: 0.6761006116867065\n",
      "Iteration 870, Loss: 0.0004775409761350602, Min w: 0.674623966217041\n",
      "Iteration 880, Loss: 0.0004682308644987643, Min w: 0.6736196279525757\n",
      "Iteration 890, Loss: 0.0004817102162633091, Min w: 0.6632192730903625\n",
      "Iteration 900, Loss: 0.0004540366353467107, Min w: 0.6957787275314331\n",
      "Iteration 910, Loss: 0.00045071085332892835, Min w: 0.70540851354599\n",
      "Iteration 920, Loss: 0.00045919755939394236, Min w: 0.7039604783058167\n",
      "Iteration 930, Loss: 0.0004585533170029521, Min w: 0.7172199487686157\n",
      "Iteration 940, Loss: 0.0004667215689551085, Min w: 0.6946855783462524\n",
      "Iteration 950, Loss: 0.000409045722335577, Min w: 0.726513147354126\n",
      "Iteration 960, Loss: 0.0004128523578401655, Min w: 0.7120040059089661\n",
      "Iteration 970, Loss: 0.0004234270309098065, Min w: 0.714591920375824\n",
      "Iteration 980, Loss: 0.00039001143886707723, Min w: 0.729677140712738\n",
      "Iteration 990, Loss: 0.00040749265463091433, Min w: 0.7333191633224487\n",
      "Iteration 1000, Loss: 0.0004197094531264156, Min w: 0.7200992703437805\n",
      "Iteration 1010, Loss: 0.00041205986053682864, Min w: 0.735042929649353\n",
      "Iteration 1020, Loss: 0.00038106419378891587, Min w: 0.7487053275108337\n",
      "Iteration 1030, Loss: 0.0003778856771532446, Min w: 0.74209064245224\n",
      "Iteration 1040, Loss: 0.00040215038461610675, Min w: 0.7248520851135254\n",
      "Iteration 1050, Loss: 0.0003920972812920809, Min w: 0.7296175956726074\n",
      "Iteration 1060, Loss: 0.00037505687214434147, Min w: 0.7395762205123901\n",
      "Iteration 1070, Loss: 0.0003689165459945798, Min w: 0.7508442997932434\n",
      "Iteration 1080, Loss: 0.00036843851557932794, Min w: 0.7506134510040283\n",
      "Iteration 1090, Loss: 0.0003713846963364631, Min w: 0.7594818472862244\n",
      "Iteration 1100, Loss: 0.0003833765513263643, Min w: 0.7513776421546936\n",
      "Iteration 1110, Loss: 0.0003419619461055845, Min w: 0.7678585648536682\n",
      "Iteration 1120, Loss: 0.0003467203350737691, Min w: 0.7733364701271057\n",
      "Iteration 1130, Loss: 0.00036877335514873266, Min w: 0.7633031606674194\n",
      "Iteration 1140, Loss: 0.0003574935544747859, Min w: 0.7598469853401184\n",
      "Iteration 1150, Loss: 0.00033395877107977867, Min w: 0.7806378602981567\n",
      "Iteration 1160, Loss: 0.00032534392084926367, Min w: 0.78168785572052\n",
      "Iteration 1170, Loss: 0.0003191462892573327, Min w: 0.7905898094177246\n",
      "Iteration 1180, Loss: 0.0003267946594860405, Min w: 0.7863019704818726\n",
      "Iteration 1190, Loss: 0.0003259346995037049, Min w: 0.7892041802406311\n",
      "Iteration 1200, Loss: 0.0003240609366912395, Min w: 0.7855036854743958\n",
      "Iteration 1210, Loss: 0.0003252126625739038, Min w: 0.7804978489875793\n",
      "Iteration 1220, Loss: 0.0003342684358358383, Min w: 0.7893431782722473\n",
      "Iteration 1230, Loss: 0.00031357863917946815, Min w: 0.8024178743362427\n",
      "Iteration 1240, Loss: 0.0003130655095446855, Min w: 0.8029994964599609\n",
      "Iteration 0, Loss: 0.0003026230842806399, Min w: 0.8037728667259216\n",
      "Iteration 10, Loss: 0.0003164907975587994, Min w: 0.8056573271751404\n",
      "Iteration 20, Loss: 0.00034115288872271776, Min w: 0.7988064289093018\n",
      "Iteration 30, Loss: 0.0003065465425606817, Min w: 0.8051242828369141\n",
      "Iteration 40, Loss: 0.0002990771899931133, Min w: 0.8061684370040894\n",
      "Iteration 50, Loss: 0.0002815761254169047, Min w: 0.8132581114768982\n",
      "Iteration 60, Loss: 0.00028976984322071075, Min w: 0.811537504196167\n",
      "Iteration 70, Loss: 0.0002865056158043444, Min w: 0.8240155577659607\n",
      "Iteration 80, Loss: 0.0002914659562520683, Min w: 0.8088811635971069\n",
      "Iteration 90, Loss: 0.00027937328559346497, Min w: 0.8234728574752808\n",
      "Iteration 100, Loss: 0.0002828002907335758, Min w: 0.817578136920929\n",
      "Iteration 110, Loss: 0.00026747194351628423, Min w: 0.829562783241272\n",
      "Iteration 120, Loss: 0.00027652218705043197, Min w: 0.8222038149833679\n",
      "Iteration 130, Loss: 0.0002533449442125857, Min w: 0.834678590297699\n",
      "Iteration 140, Loss: 0.0002479385875631124, Min w: 0.8440250754356384\n",
      "Iteration 150, Loss: 0.00027648985269479454, Min w: 0.8228752613067627\n",
      "Iteration 160, Loss: 0.0002448269515298307, Min w: 0.8453070521354675\n",
      "Iteration 170, Loss: 0.0002544936432968825, Min w: 0.8358627557754517\n",
      "Iteration 180, Loss: 0.0002592015662230551, Min w: 0.8315249681472778\n",
      "Iteration 190, Loss: 0.0002450119936838746, Min w: 0.8381986021995544\n",
      "Iteration 200, Loss: 0.0002503883733879775, Min w: 0.8430560231208801\n",
      "Iteration 210, Loss: 0.0002425776910968125, Min w: 0.8461458086967468\n",
      "Iteration 220, Loss: 0.0002522894355934113, Min w: 0.8370037078857422\n",
      "Iteration 230, Loss: 0.00025157269556075335, Min w: 0.8370113372802734\n",
      "Iteration 240, Loss: 0.0002496926172170788, Min w: 0.8489432334899902\n",
      "Iteration 250, Loss: 0.00025437126168981194, Min w: 0.8501279354095459\n",
      "Iteration 260, Loss: 0.00026987347519025207, Min w: 0.8403688669204712\n",
      "Iteration 270, Loss: 0.00021757296053692698, Min w: 0.8564387559890747\n",
      "Iteration 280, Loss: 0.0002351824368815869, Min w: 0.8564066886901855\n",
      "Iteration 290, Loss: 0.0002251871774205938, Min w: 0.8619957566261292\n",
      "Iteration 300, Loss: 0.00022409879602491856, Min w: 0.8583964109420776\n",
      "Iteration 310, Loss: 0.0002321389620192349, Min w: 0.8617565035820007\n",
      "Iteration 320, Loss: 0.00023836374748498201, Min w: 0.8472792506217957\n",
      "Iteration 330, Loss: 0.00022502803767565638, Min w: 0.8557552695274353\n",
      "Iteration 340, Loss: 0.00021646438108291477, Min w: 0.8601070046424866\n",
      "Iteration 350, Loss: 0.00021702820959035307, Min w: 0.8600025773048401\n",
      "Iteration 360, Loss: 0.00021829122852068394, Min w: 0.8585355877876282\n",
      "Iteration 370, Loss: 0.00020653045794460922, Min w: 0.8717790842056274\n",
      "Iteration 380, Loss: 0.0002111468929797411, Min w: 0.8684507608413696\n",
      "Iteration 390, Loss: 0.00021531661332119256, Min w: 0.8723788261413574\n",
      "Iteration 400, Loss: 0.0002086236490868032, Min w: 0.8728946447372437\n",
      "Iteration 410, Loss: 0.00019629535381682217, Min w: 0.8807922005653381\n",
      "Iteration 420, Loss: 0.00020933651831001043, Min w: 0.8726686239242554\n",
      "Iteration 430, Loss: 0.00021332423784770072, Min w: 0.8759217262268066\n",
      "Iteration 440, Loss: 0.00019873537530656904, Min w: 0.8708973526954651\n",
      "Iteration 450, Loss: 0.00018954715051222593, Min w: 0.8852570652961731\n",
      "Iteration 460, Loss: 0.00021243392257019877, Min w: 0.8717215657234192\n",
      "Iteration 470, Loss: 0.00020339078037068248, Min w: 0.8755321502685547\n",
      "Iteration 480, Loss: 0.0001935865293489769, Min w: 0.8804466724395752\n",
      "Iteration 490, Loss: 0.0001941252121469006, Min w: 0.8796820044517517\n",
      "Iteration 500, Loss: 0.00018800667021423578, Min w: 0.8798224329948425\n",
      "Iteration 510, Loss: 0.000194727472262457, Min w: 0.8796624541282654\n",
      "Iteration 520, Loss: 0.00018996412109117955, Min w: 0.890139639377594\n",
      "Iteration 530, Loss: 0.0001986948773264885, Min w: 0.8876319527626038\n",
      "Iteration 540, Loss: 0.00018624859512783587, Min w: 0.8797694444656372\n",
      "Iteration 550, Loss: 0.0001956215564860031, Min w: 0.8812393546104431\n",
      "Iteration 560, Loss: 0.00017525156727060676, Min w: 0.8922305703163147\n",
      "Iteration 570, Loss: 0.00017478541121818125, Min w: 0.894473671913147\n",
      "Iteration 580, Loss: 0.00021229225967545062, Min w: 0.8816357851028442\n",
      "Iteration 590, Loss: 0.00018892002117354423, Min w: 0.886743426322937\n",
      "Iteration 600, Loss: 0.0001778704026946798, Min w: 0.8929434418678284\n",
      "Iteration 610, Loss: 0.0001837157178670168, Min w: 0.8906397223472595\n",
      "Iteration 620, Loss: 0.0001719678839435801, Min w: 0.8973824977874756\n",
      "Iteration 630, Loss: 0.00018649018602445722, Min w: 0.8941637277603149\n",
      "Iteration 640, Loss: 0.0001626334124011919, Min w: 0.8996478915214539\n",
      "Iteration 650, Loss: 0.00017509541066829115, Min w: 0.9001154899597168\n",
      "Iteration 660, Loss: 0.00017111738270614296, Min w: 0.8948628306388855\n",
      "Iteration 670, Loss: 0.00017110332555603236, Min w: 0.9019022583961487\n",
      "Iteration 680, Loss: 0.00021732466120738536, Min w: 0.8881781101226807\n",
      "Iteration 690, Loss: 0.00018292372988071293, Min w: 0.8958667516708374\n",
      "Iteration 700, Loss: 0.00016475650772918016, Min w: 0.907271146774292\n",
      "Iteration 710, Loss: 0.00016483485524076968, Min w: 0.9030928611755371\n",
      "Iteration 720, Loss: 0.00015423980948980898, Min w: 0.9073618054389954\n",
      "Iteration 730, Loss: 0.0001668289623921737, Min w: 0.9018430113792419\n",
      "Iteration 740, Loss: 0.00016138599312398583, Min w: 0.9127517938613892\n",
      "Iteration 750, Loss: 0.00016198675439227372, Min w: 0.9051231741905212\n",
      "Iteration 760, Loss: 0.00015038502169772983, Min w: 0.9103875160217285\n",
      "Iteration 770, Loss: 0.0001534492475911975, Min w: 0.9106380939483643\n",
      "Iteration 780, Loss: 0.00015898198762442917, Min w: 0.9087812304496765\n",
      "Iteration 790, Loss: 0.00016788435459602624, Min w: 0.9109299778938293\n",
      "Iteration 800, Loss: 0.0001471721043344587, Min w: 0.911872386932373\n",
      "Iteration 810, Loss: 0.00014743754582013935, Min w: 0.9096207022666931\n",
      "Iteration 820, Loss: 0.00015370280016213655, Min w: 0.9144337773323059\n",
      "Iteration 830, Loss: 0.00014546977763529867, Min w: 0.915915310382843\n",
      "Iteration 840, Loss: 0.00015087936480995268, Min w: 0.9125896692276001\n",
      "Iteration 850, Loss: 0.00014823478704784065, Min w: 0.9157521724700928\n",
      "Iteration 860, Loss: 0.0001384613278787583, Min w: 0.919942319393158\n",
      "Iteration 870, Loss: 0.0001505129475845024, Min w: 0.913812518119812\n",
      "Iteration 880, Loss: 0.0001629229518584907, Min w: 0.9068145751953125\n",
      "Iteration 890, Loss: 0.0001409599935868755, Min w: 0.9191057085990906\n",
      "Iteration 900, Loss: 0.0001457078760722652, Min w: 0.921329915523529\n",
      "Iteration 910, Loss: 0.00013710152416024357, Min w: 0.9180632829666138\n",
      "Iteration 920, Loss: 0.0001411994599038735, Min w: 0.9152228236198425\n",
      "Iteration 930, Loss: 0.00013449475227389485, Min w: 0.921749472618103\n",
      "Iteration 940, Loss: 0.00014120066771283746, Min w: 0.9188620448112488\n",
      "Iteration 950, Loss: 0.00013665232108905911, Min w: 0.9205697178840637\n",
      "Iteration 960, Loss: 0.00013520453649107367, Min w: 0.9260596632957458\n",
      "Iteration 970, Loss: 0.00014102220302447677, Min w: 0.9213060736656189\n",
      "Iteration 980, Loss: 0.00015227723633870482, Min w: 0.9216135144233704\n",
      "Iteration 990, Loss: 0.00015041534788906574, Min w: 0.9223440289497375\n",
      "Iteration 1000, Loss: 0.00012428421177901328, Min w: 0.9263848066329956\n",
      "Iteration 1010, Loss: 0.00013057260366622359, Min w: 0.9279297590255737\n",
      "Iteration 1020, Loss: 0.00012705895642284304, Min w: 0.930584728717804\n",
      "Iteration 1030, Loss: 0.00013958393537905067, Min w: 0.9215525984764099\n",
      "Iteration 1040, Loss: 0.0001243588194483891, Min w: 0.9290744066238403\n",
      "Iteration 1050, Loss: 0.00012824140139855444, Min w: 0.9297258257865906\n",
      "Iteration 1060, Loss: 0.00013337440032046288, Min w: 0.9223198890686035\n",
      "Iteration 1070, Loss: 0.00012030750804115087, Min w: 0.9301943778991699\n",
      "Iteration 1080, Loss: 0.0001267960760742426, Min w: 0.9247210621833801\n",
      "Iteration 1090, Loss: 0.000128034022054635, Min w: 0.9307880401611328\n",
      "Iteration 1100, Loss: 0.0001261077995877713, Min w: 0.9269977807998657\n",
      "Iteration 1110, Loss: 0.00013500887143891305, Min w: 0.9248436689376831\n",
      "Iteration 1120, Loss: 0.0001350736420135945, Min w: 0.9284284710884094\n",
      "Iteration 1130, Loss: 0.00011632587120402604, Min w: 0.9357489943504333\n",
      "Iteration 1140, Loss: 0.00012921130110044032, Min w: 0.9237518310546875\n",
      "Iteration 1150, Loss: 0.00011364158126525581, Min w: 0.9336863160133362\n",
      "Iteration 1160, Loss: 0.00011617359996307641, Min w: 0.931818962097168\n",
      "Iteration 1170, Loss: 0.00011819897190434858, Min w: 0.9311491847038269\n",
      "Iteration 1180, Loss: 0.00012144147331127897, Min w: 0.9365984797477722\n",
      "Iteration 1190, Loss: 0.00012174510629847646, Min w: 0.9300562143325806\n",
      "Iteration 1200, Loss: 0.00011427092249505222, Min w: 0.9326827526092529\n",
      "Iteration 1210, Loss: 0.00012583905481733382, Min w: 0.9343990683555603\n",
      "Iteration 1220, Loss: 0.00013105796824675053, Min w: 0.9325133562088013\n",
      "Iteration 1230, Loss: 0.00011748578253900632, Min w: 0.9355229139328003\n",
      "Iteration 1240, Loss: 0.00011499426909722388, Min w: 0.9378871321678162\n",
      "Iteration 0, Loss: 0.00012379803229123354, Min w: 0.9345359802246094\n",
      "Iteration 10, Loss: 0.00011577124678296968, Min w: 0.9327540993690491\n",
      "Iteration 20, Loss: 0.00011714512947946787, Min w: 0.9356138110160828\n",
      "Iteration 30, Loss: 0.00011746723612304777, Min w: 0.9381950497627258\n",
      "Iteration 40, Loss: 0.0001179204773507081, Min w: 0.936357319355011\n",
      "Iteration 50, Loss: 0.0001189558970509097, Min w: 0.9373794198036194\n",
      "Iteration 60, Loss: 0.0001117312494898215, Min w: 0.9371456503868103\n",
      "Iteration 70, Loss: 0.00010597272921586409, Min w: 0.9403518438339233\n",
      "Iteration 80, Loss: 0.00010710115020629019, Min w: 0.9384191036224365\n",
      "Iteration 90, Loss: 0.00010560514783719555, Min w: 0.9397252798080444\n",
      "Iteration 100, Loss: 0.00011135919339722022, Min w: 0.9417832493782043\n",
      "Iteration 110, Loss: 0.00010761064913822338, Min w: 0.9395040273666382\n",
      "Iteration 120, Loss: 0.00012675157631747425, Min w: 0.9314671754837036\n",
      "Iteration 130, Loss: 0.00010561297676758841, Min w: 0.9440453052520752\n",
      "Iteration 140, Loss: 9.748231968842447e-05, Min w: 0.9407525062561035\n",
      "Iteration 150, Loss: 9.332430636277422e-05, Min w: 0.9482266306877136\n",
      "Iteration 160, Loss: 0.00013884076906833798, Min w: 0.9287606477737427\n",
      "Iteration 170, Loss: 0.0001054349122568965, Min w: 0.9455950260162354\n",
      "Iteration 180, Loss: 0.00010799158917507157, Min w: 0.9412195086479187\n",
      "Iteration 190, Loss: 0.00010161097452510148, Min w: 0.9478064775466919\n",
      "Iteration 200, Loss: 0.00010385589848738164, Min w: 0.9431849122047424\n",
      "Iteration 210, Loss: 0.0001014625740936026, Min w: 0.9453837275505066\n",
      "Iteration 220, Loss: 0.00011497363448143005, Min w: 0.9401914477348328\n",
      "Iteration 230, Loss: 0.00011494752106955275, Min w: 0.9400214552879333\n",
      "Iteration 240, Loss: 0.00010989962902385741, Min w: 0.9425700902938843\n",
      "Iteration 250, Loss: 0.00010468914115335792, Min w: 0.9446658492088318\n",
      "Iteration 260, Loss: 0.00011135052773170173, Min w: 0.9393784999847412\n",
      "Iteration 270, Loss: 9.644158853916451e-05, Min w: 0.9487621188163757\n",
      "Iteration 280, Loss: 9.751105244504288e-05, Min w: 0.9418179988861084\n",
      "Iteration 290, Loss: 0.00011085769074270502, Min w: 0.9405153393745422\n",
      "Iteration 300, Loss: 0.00010620570537867025, Min w: 0.9446855783462524\n",
      "Iteration 310, Loss: 9.916021372191608e-05, Min w: 0.9469694495201111\n",
      "Iteration 320, Loss: 9.954864799510688e-05, Min w: 0.947660505771637\n",
      "Iteration 330, Loss: 9.45570063777268e-05, Min w: 0.9473947286605835\n",
      "Iteration 340, Loss: 0.00010747469787020236, Min w: 0.944445013999939\n",
      "Iteration 350, Loss: 0.00010203223064308986, Min w: 0.9474112391471863\n",
      "Iteration 360, Loss: 8.98312937351875e-05, Min w: 0.9540685415267944\n",
      "Iteration 370, Loss: 9.093192784348503e-05, Min w: 0.9480944871902466\n",
      "Iteration 380, Loss: 9.102751937462017e-05, Min w: 0.9485936760902405\n",
      "Iteration 390, Loss: 9.186132956529036e-05, Min w: 0.9512432217597961\n",
      "Iteration 400, Loss: 9.758720261743292e-05, Min w: 0.9463457465171814\n",
      "Iteration 410, Loss: 9.685717668617144e-05, Min w: 0.9491798877716064\n",
      "Iteration 420, Loss: 9.175802551908419e-05, Min w: 0.9523792862892151\n",
      "Iteration 430, Loss: 0.00010531592852203175, Min w: 0.9458004832267761\n",
      "Iteration 440, Loss: 9.293707989854738e-05, Min w: 0.9515976905822754\n",
      "Iteration 450, Loss: 0.00010159627709072083, Min w: 0.9456421732902527\n",
      "Iteration 460, Loss: 9.321816469309852e-05, Min w: 0.9507827162742615\n",
      "Iteration 470, Loss: 0.0001062729861587286, Min w: 0.9427198171615601\n",
      "Iteration 480, Loss: 0.00010705294698709622, Min w: 0.9403702020645142\n",
      "Iteration 490, Loss: 9.276579658035189e-05, Min w: 0.9524709582328796\n",
      "Iteration 500, Loss: 8.698468445800245e-05, Min w: 0.9529155492782593\n",
      "Iteration 510, Loss: 9.077110735233873e-05, Min w: 0.9512277841567993\n",
      "Iteration 520, Loss: 9.484386828262359e-05, Min w: 0.9508435726165771\n",
      "Iteration 530, Loss: 9.083608165383339e-05, Min w: 0.9524466395378113\n",
      "Iteration 540, Loss: 0.00010032700811279938, Min w: 0.9433461427688599\n",
      "Iteration 550, Loss: 9.314627823187038e-05, Min w: 0.9522672891616821\n",
      "Iteration 560, Loss: 9.648792183725163e-05, Min w: 0.9485957026481628\n",
      "Iteration 570, Loss: 9.127148950938135e-05, Min w: 0.9497525095939636\n",
      "Iteration 580, Loss: 8.46931361593306e-05, Min w: 0.956221342086792\n",
      "Iteration 590, Loss: 8.862618415150791e-05, Min w: 0.9546453356742859\n",
      "Iteration 600, Loss: 9.103377669816837e-05, Min w: 0.95304936170578\n",
      "Iteration 610, Loss: 8.586415060563013e-05, Min w: 0.9545373916625977\n",
      "Iteration 620, Loss: 8.826413250062615e-05, Min w: 0.9543675780296326\n",
      "Iteration 630, Loss: 9.460582805331796e-05, Min w: 0.9464207887649536\n",
      "Iteration 640, Loss: 9.815650264499709e-05, Min w: 0.9475991129875183\n",
      "Iteration 650, Loss: 0.00011643134348560125, Min w: 0.933582603931427\n",
      "Iteration 660, Loss: 9.998532186727971e-05, Min w: 0.9455019235610962\n",
      "Iteration 670, Loss: 8.324498048750684e-05, Min w: 0.9554927945137024\n",
      "Iteration 680, Loss: 8.498605893692002e-05, Min w: 0.953971803188324\n",
      "Iteration 690, Loss: 8.117472316371277e-05, Min w: 0.9576992392539978\n",
      "Iteration 700, Loss: 8.70986987138167e-05, Min w: 0.9536226987838745\n",
      "Iteration 710, Loss: 8.459993841825053e-05, Min w: 0.9562655687332153\n",
      "Iteration 720, Loss: 8.232615800807253e-05, Min w: 0.9556698203086853\n",
      "Iteration 730, Loss: 8.287527452921495e-05, Min w: 0.956377387046814\n",
      "Iteration 740, Loss: 0.00010389839007984847, Min w: 0.9393251538276672\n",
      "Iteration 750, Loss: 8.199744479497895e-05, Min w: 0.956730842590332\n",
      "Iteration 760, Loss: 8.625176997156814e-05, Min w: 0.9543707966804504\n",
      "Iteration 770, Loss: 8.917388186091557e-05, Min w: 0.9516100883483887\n",
      "Iteration 780, Loss: 0.0001035858440445736, Min w: 0.9416412711143494\n",
      "Iteration 790, Loss: 9.000144200399518e-05, Min w: 0.9533472657203674\n",
      "Iteration 800, Loss: 9.942910401150584e-05, Min w: 0.9476207494735718\n",
      "Iteration 810, Loss: 8.256707951659337e-05, Min w: 0.9555980563163757\n",
      "Iteration 820, Loss: 7.591659959871322e-05, Min w: 0.9592342376708984\n",
      "Iteration 830, Loss: 0.0001145348433055915, Min w: 0.929327130317688\n",
      "Iteration 840, Loss: 0.00010170058521907777, Min w: 0.9395596981048584\n",
      "Iteration 850, Loss: 7.393327541649342e-05, Min w: 0.9610822200775146\n",
      "Iteration 860, Loss: 7.682856812607497e-05, Min w: 0.9605458974838257\n",
      "Iteration 870, Loss: 7.544385152868927e-05, Min w: 0.9603891968727112\n",
      "Iteration 880, Loss: 8.260135655291378e-05, Min w: 0.9572013020515442\n",
      "Iteration 890, Loss: 7.862446364015341e-05, Min w: 0.957234263420105\n",
      "Iteration 900, Loss: 8.813800377538428e-05, Min w: 0.9519010782241821\n",
      "Iteration 910, Loss: 8.46932380227372e-05, Min w: 0.9529535174369812\n",
      "Iteration 920, Loss: 8.726853411644697e-05, Min w: 0.9523634314537048\n",
      "Iteration 930, Loss: 7.731963705737144e-05, Min w: 0.9589943289756775\n",
      "Iteration 940, Loss: 8.673445699969307e-05, Min w: 0.9520012736320496\n",
      "Iteration 950, Loss: 8.110957423923537e-05, Min w: 0.9567347168922424\n",
      "Iteration 960, Loss: 8.707210508873686e-05, Min w: 0.9526883363723755\n",
      "Iteration 970, Loss: 7.759957952657714e-05, Min w: 0.9595519304275513\n",
      "Iteration 980, Loss: 8.154020906658843e-05, Min w: 0.9539675712585449\n",
      "Iteration 990, Loss: 7.688836922170594e-05, Min w: 0.9604030847549438\n",
      "Iteration 1000, Loss: 7.660248229512945e-05, Min w: 0.9594767689704895\n",
      "Iteration 1010, Loss: 7.816926517989486e-05, Min w: 0.957640528678894\n",
      "Iteration 1020, Loss: 7.379317685263231e-05, Min w: 0.961137056350708\n",
      "Iteration 1030, Loss: 7.813676347723231e-05, Min w: 0.9553865194320679\n",
      "Iteration 1040, Loss: 7.246343011502177e-05, Min w: 0.9606289863586426\n",
      "Iteration 1050, Loss: 7.449198892572895e-05, Min w: 0.9616832137107849\n",
      "Iteration 1060, Loss: 7.081371586536989e-05, Min w: 0.9621022343635559\n",
      "Iteration 1070, Loss: 8.979882841231301e-05, Min w: 0.9469045996665955\n",
      "Iteration 1080, Loss: 7.145082054194063e-05, Min w: 0.9623009562492371\n",
      "Iteration 1090, Loss: 8.656177669763565e-05, Min w: 0.9522942304611206\n",
      "Iteration 1100, Loss: 6.99397423886694e-05, Min w: 0.9640799164772034\n",
      "Iteration 1110, Loss: 7.15520727680996e-05, Min w: 0.960729718208313\n",
      "Iteration 1120, Loss: 7.658969116164371e-05, Min w: 0.9587082862854004\n",
      "Iteration 1130, Loss: 0.00011290729162283242, Min w: 0.9291321635246277\n",
      "Iteration 1140, Loss: 7.004458893788978e-05, Min w: 0.9636996984481812\n",
      "Iteration 1150, Loss: 7.455555169144645e-05, Min w: 0.9597728848457336\n",
      "Iteration 1160, Loss: 6.743480480508879e-05, Min w: 0.9644274711608887\n",
      "Iteration 1170, Loss: 6.946644134586677e-05, Min w: 0.9643906950950623\n",
      "Iteration 1180, Loss: 7.470740820281208e-05, Min w: 0.9584027528762817\n",
      "Iteration 1190, Loss: 7.569834997411817e-05, Min w: 0.9598582983016968\n",
      "Iteration 1200, Loss: 6.946995563339442e-05, Min w: 0.9644379019737244\n",
      "Iteration 1210, Loss: 7.313121750485152e-05, Min w: 0.9613370895385742\n",
      "Iteration 1220, Loss: 8.43387606437318e-05, Min w: 0.9507917165756226\n",
      "Iteration 1230, Loss: 7.093850581441075e-05, Min w: 0.9617251753807068\n",
      "Iteration 1240, Loss: 7.127839489839971e-05, Min w: 0.9612348675727844\n",
      "Iteration 0, Loss: 8.180480654118583e-05, Min w: 0.9524598121643066\n",
      "Iteration 10, Loss: 7.242957508424297e-05, Min w: 0.9601745009422302\n",
      "Iteration 20, Loss: 7.441241905326024e-05, Min w: 0.956427812576294\n",
      "Iteration 30, Loss: 6.68426146148704e-05, Min w: 0.9657606482505798\n",
      "Iteration 40, Loss: 6.668332207482308e-05, Min w: 0.9633549451828003\n",
      "Iteration 50, Loss: 8.055249782046303e-05, Min w: 0.9547083377838135\n",
      "Iteration 60, Loss: 8.32545556477271e-05, Min w: 0.9511221647262573\n",
      "Iteration 70, Loss: 7.044449739623815e-05, Min w: 0.9639694690704346\n",
      "Iteration 80, Loss: 7.71360209910199e-05, Min w: 0.9586254358291626\n",
      "Iteration 90, Loss: 6.725522689521313e-05, Min w: 0.9646942615509033\n",
      "Iteration 100, Loss: 7.098553032847121e-05, Min w: 0.9615179896354675\n",
      "Iteration 110, Loss: 6.837062392150983e-05, Min w: 0.9620505571365356\n",
      "Iteration 120, Loss: 7.996176282176748e-05, Min w: 0.9515104293823242\n",
      "Iteration 130, Loss: 8.521664858562872e-05, Min w: 0.9476901888847351\n",
      "Iteration 140, Loss: 7.776214624755085e-05, Min w: 0.9545773863792419\n",
      "Iteration 150, Loss: 7.092174200806767e-05, Min w: 0.9611290693283081\n",
      "Iteration 160, Loss: 7.308867498068139e-05, Min w: 0.9598153233528137\n",
      "Iteration 170, Loss: 6.678033241769299e-05, Min w: 0.962296187877655\n",
      "Iteration 180, Loss: 7.811231625964865e-05, Min w: 0.9534034729003906\n",
      "Iteration 190, Loss: 6.435949035221711e-05, Min w: 0.9647692441940308\n",
      "Iteration 200, Loss: 6.382974970620126e-05, Min w: 0.9660567045211792\n",
      "Iteration 210, Loss: 6.62670936435461e-05, Min w: 0.9645056128501892\n",
      "Iteration 220, Loss: 7.097514753695577e-05, Min w: 0.9603220820426941\n",
      "Iteration 230, Loss: 6.008258060319349e-05, Min w: 0.9689120054244995\n",
      "Iteration 240, Loss: 6.580947956535965e-05, Min w: 0.964756190776825\n",
      "Iteration 250, Loss: 6.835852400399745e-05, Min w: 0.9631417393684387\n",
      "Iteration 260, Loss: 6.304647831711918e-05, Min w: 0.967635452747345\n",
      "Iteration 270, Loss: 6.315002974588424e-05, Min w: 0.9664645791053772\n",
      "Iteration 280, Loss: 6.883913010824472e-05, Min w: 0.9620412588119507\n",
      "Iteration 290, Loss: 6.652726005995646e-05, Min w: 0.9623794555664062\n",
      "Iteration 300, Loss: 6.780274998163804e-05, Min w: 0.9608304500579834\n",
      "Iteration 310, Loss: 7.587589789181948e-05, Min w: 0.9537155628204346\n",
      "Iteration 320, Loss: 8.090482151601464e-05, Min w: 0.9515674114227295\n",
      "Iteration 330, Loss: 6.929202208993956e-05, Min w: 0.9569069147109985\n",
      "Iteration 340, Loss: 6.601974018849432e-05, Min w: 0.9629343748092651\n",
      "Iteration 350, Loss: 7.443950016750023e-05, Min w: 0.9569658637046814\n",
      "Iteration 360, Loss: 6.57913988106884e-05, Min w: 0.962002694606781\n",
      "Iteration 370, Loss: 6.18032063357532e-05, Min w: 0.9661897420883179\n",
      "Iteration 380, Loss: 6.558970198966563e-05, Min w: 0.9648017287254333\n",
      "Iteration 390, Loss: 6.577397289220244e-05, Min w: 0.9619631171226501\n",
      "Iteration 400, Loss: 6.740311800967902e-05, Min w: 0.9611805081367493\n",
      "Iteration 410, Loss: 6.123440834926441e-05, Min w: 0.9659445285797119\n",
      "Iteration 420, Loss: 6.296880019363016e-05, Min w: 0.9638569951057434\n",
      "Iteration 430, Loss: 5.652818799717352e-05, Min w: 0.9695413112640381\n",
      "Iteration 440, Loss: 6.325951108010486e-05, Min w: 0.9660767912864685\n",
      "Iteration 450, Loss: 5.853400580235757e-05, Min w: 0.9676132202148438\n",
      "Iteration 460, Loss: 6.364566797856241e-05, Min w: 0.9621427655220032\n",
      "Iteration 470, Loss: 5.834878538735211e-05, Min w: 0.9666630029678345\n",
      "Iteration 480, Loss: 5.851275636814535e-05, Min w: 0.9688717126846313\n",
      "Iteration 490, Loss: 5.9973172028549016e-05, Min w: 0.9671342968940735\n",
      "Iteration 500, Loss: 6.0608279454754665e-05, Min w: 0.9644705057144165\n",
      "Iteration 510, Loss: 6.827055767644197e-05, Min w: 0.9612109661102295\n",
      "Iteration 520, Loss: 5.837330536451191e-05, Min w: 0.9679476618766785\n",
      "Iteration 530, Loss: 7.282605656655505e-05, Min w: 0.9583460688591003\n",
      "Iteration 540, Loss: 5.292790592648089e-05, Min w: 0.9714635610580444\n",
      "Iteration 550, Loss: 5.546006650547497e-05, Min w: 0.9699306488037109\n",
      "Iteration 560, Loss: 5.907315426156856e-05, Min w: 0.9671452045440674\n",
      "Iteration 570, Loss: 6.294094782788306e-05, Min w: 0.9631320238113403\n",
      "Iteration 580, Loss: 6.0731017583748326e-05, Min w: 0.9683178067207336\n",
      "Iteration 590, Loss: 5.559793862630613e-05, Min w: 0.9701735973358154\n",
      "Iteration 600, Loss: 5.901616532355547e-05, Min w: 0.9677456617355347\n",
      "Iteration 610, Loss: 5.515867451322265e-05, Min w: 0.969955563545227\n",
      "Iteration 620, Loss: 5.369213977246545e-05, Min w: 0.9708523750305176\n",
      "Iteration 630, Loss: 5.461485488922335e-05, Min w: 0.9701269268989563\n",
      "Iteration 640, Loss: 5.7417295465711504e-05, Min w: 0.9671213030815125\n",
      "Iteration 650, Loss: 5.7542234571883455e-05, Min w: 0.9699744582176208\n",
      "Iteration 660, Loss: 6.23309169895947e-05, Min w: 0.9639496207237244\n",
      "Iteration 670, Loss: 6.85423583490774e-05, Min w: 0.9603872895240784\n",
      "Iteration 680, Loss: 5.7062254199991e-05, Min w: 0.9685457944869995\n",
      "Iteration 690, Loss: 5.335004607331939e-05, Min w: 0.9705771207809448\n",
      "Iteration 700, Loss: 5.5575754231540486e-05, Min w: 0.9704758524894714\n",
      "Iteration 710, Loss: 5.380238508223556e-05, Min w: 0.9703093767166138\n",
      "Iteration 720, Loss: 6.1001737776678056e-05, Min w: 0.963005006313324\n",
      "Iteration 730, Loss: 5.5347918532788754e-05, Min w: 0.9708425402641296\n",
      "Iteration 740, Loss: 5.194338518776931e-05, Min w: 0.9707531332969666\n",
      "Iteration 750, Loss: 5.817828787257895e-05, Min w: 0.9657454490661621\n",
      "Iteration 760, Loss: 5.7266115618404e-05, Min w: 0.9684911966323853\n",
      "Iteration 770, Loss: 5.249435707810335e-05, Min w: 0.9702272415161133\n",
      "Iteration 780, Loss: 5.375991895562038e-05, Min w: 0.9705054759979248\n",
      "Iteration 790, Loss: 5.2281433454481885e-05, Min w: 0.9690766930580139\n",
      "Iteration 800, Loss: 5.149842763785273e-05, Min w: 0.9727448225021362\n",
      "Iteration 810, Loss: 5.973668521619402e-05, Min w: 0.9636916518211365\n",
      "Iteration 820, Loss: 5.4238906159298494e-05, Min w: 0.9693601727485657\n",
      "Iteration 830, Loss: 5.250291360425763e-05, Min w: 0.9687517881393433\n",
      "Iteration 840, Loss: 5.1429957238724455e-05, Min w: 0.97177654504776\n",
      "Iteration 850, Loss: 4.9586193199502304e-05, Min w: 0.9733404517173767\n",
      "Iteration 860, Loss: 6.313675839919597e-05, Min w: 0.963778555393219\n",
      "Iteration 870, Loss: 5.0487728003645316e-05, Min w: 0.9712053537368774\n",
      "Iteration 880, Loss: 6.0381378716556355e-05, Min w: 0.9634573459625244\n",
      "Iteration 890, Loss: 5.966358367004432e-05, Min w: 0.9636176228523254\n",
      "Iteration 900, Loss: 5.4006537538953125e-05, Min w: 0.9700102210044861\n",
      "Iteration 910, Loss: 4.943654130329378e-05, Min w: 0.9709503054618835\n",
      "Iteration 920, Loss: 5.1837250794051215e-05, Min w: 0.9708508253097534\n",
      "Iteration 930, Loss: 5.915487417951226e-05, Min w: 0.9687809348106384\n",
      "Iteration 940, Loss: 4.982125392416492e-05, Min w: 0.9738162159919739\n",
      "Iteration 950, Loss: 5.285741644911468e-05, Min w: 0.9697911143302917\n",
      "Iteration 960, Loss: 4.734818503493443e-05, Min w: 0.9737300276756287\n",
      "Iteration 970, Loss: 5.788348789792508e-05, Min w: 0.9662711024284363\n",
      "Iteration 980, Loss: 5.034087735111825e-05, Min w: 0.9713386297225952\n",
      "Iteration 990, Loss: 5.044966746936552e-05, Min w: 0.9721977114677429\n",
      "Iteration 1000, Loss: 6.499697337858379e-05, Min w: 0.9594259262084961\n",
      "Iteration 1010, Loss: 5.0854581786552444e-05, Min w: 0.9707199931144714\n",
      "Iteration 1020, Loss: 5.319813499227166e-05, Min w: 0.9702628254890442\n",
      "Iteration 1030, Loss: 6.225444667506963e-05, Min w: 0.9618819355964661\n",
      "Iteration 1040, Loss: 7.962941890582442e-05, Min w: 0.9451186656951904\n",
      "Iteration 1050, Loss: 4.92427971039433e-05, Min w: 0.971720814704895\n",
      "Iteration 1060, Loss: 5.769661220256239e-05, Min w: 0.966418445110321\n",
      "Iteration 1070, Loss: 6.718115037074313e-05, Min w: 0.95355224609375\n",
      "Iteration 1080, Loss: 5.419041553977877e-05, Min w: 0.9695398807525635\n",
      "Iteration 1090, Loss: 4.8180441808653995e-05, Min w: 0.9720824360847473\n",
      "Iteration 1100, Loss: 4.751999949803576e-05, Min w: 0.9746222496032715\n",
      "Iteration 1110, Loss: 4.8684418288758025e-05, Min w: 0.9732651114463806\n",
      "Iteration 1120, Loss: 4.756001362693496e-05, Min w: 0.9720786809921265\n",
      "Iteration 1130, Loss: 6.857039988972247e-05, Min w: 0.9538981914520264\n",
      "Iteration 1140, Loss: 4.956509656039998e-05, Min w: 0.9738982915878296\n",
      "Iteration 1150, Loss: 5.523289291886613e-05, Min w: 0.965965747833252\n",
      "Iteration 1160, Loss: 4.868198448093608e-05, Min w: 0.9720722436904907\n",
      "Iteration 1170, Loss: 6.498998118331656e-05, Min w: 0.9592182636260986\n",
      "Iteration 1180, Loss: 4.693260052590631e-05, Min w: 0.9730981588363647\n",
      "Iteration 1190, Loss: 4.8605059419060126e-05, Min w: 0.9711353182792664\n",
      "Iteration 1200, Loss: 4.363238622318022e-05, Min w: 0.9754316210746765\n",
      "Iteration 1210, Loss: 4.815978536498733e-05, Min w: 0.9732277989387512\n",
      "Iteration 1220, Loss: 4.7883553634164855e-05, Min w: 0.9722131490707397\n",
      "Iteration 1230, Loss: 4.754567635245621e-05, Min w: 0.972273588180542\n",
      "Iteration 1240, Loss: 5.596176197286695e-05, Min w: 0.966300368309021\n",
      "Iteration 0, Loss: 6.118073360994458e-05, Min w: 0.9601981043815613\n",
      "Iteration 10, Loss: 4.9004262109519914e-05, Min w: 0.9728466868400574\n",
      "Iteration 20, Loss: 4.8779547796584666e-05, Min w: 0.9718681573867798\n",
      "Iteration 30, Loss: 5.3486299293581396e-05, Min w: 0.9689521193504333\n",
      "Iteration 40, Loss: 5.338543633115478e-05, Min w: 0.9667878150939941\n",
      "Iteration 50, Loss: 4.909314520773478e-05, Min w: 0.9736552238464355\n",
      "Iteration 60, Loss: 4.7401066694874316e-05, Min w: 0.9717145562171936\n",
      "Iteration 70, Loss: 5.3851577831665054e-05, Min w: 0.9674925208091736\n",
      "Iteration 80, Loss: 5.6964207033161074e-05, Min w: 0.9640441536903381\n",
      "Iteration 90, Loss: 4.959396756021306e-05, Min w: 0.9723793268203735\n",
      "Iteration 100, Loss: 6.107877561589703e-05, Min w: 0.9601989984512329\n",
      "Iteration 110, Loss: 4.647386958822608e-05, Min w: 0.9738394021987915\n",
      "Iteration 120, Loss: 5.3683030273532495e-05, Min w: 0.967327892780304\n",
      "Iteration 130, Loss: 4.619416722562164e-05, Min w: 0.972297728061676\n",
      "Iteration 140, Loss: 4.821031689061783e-05, Min w: 0.9711810946464539\n",
      "Iteration 150, Loss: 4.513146268436685e-05, Min w: 0.9738584756851196\n",
      "Iteration 160, Loss: 4.804981290362775e-05, Min w: 0.9724155068397522\n",
      "Iteration 170, Loss: 5.1072038331767544e-05, Min w: 0.969209611415863\n",
      "Iteration 180, Loss: 4.4403674110071734e-05, Min w: 0.9746013879776001\n",
      "Iteration 190, Loss: 4.58945614809636e-05, Min w: 0.9742897152900696\n",
      "Iteration 200, Loss: 4.497701229411177e-05, Min w: 0.9739354848861694\n",
      "Iteration 210, Loss: 4.276977415429428e-05, Min w: 0.9776557087898254\n",
      "Iteration 220, Loss: 4.527383134700358e-05, Min w: 0.9727430939674377\n",
      "Iteration 230, Loss: 4.303827881813049e-05, Min w: 0.9754226803779602\n",
      "Iteration 240, Loss: 5.272767157293856e-05, Min w: 0.9685278534889221\n",
      "Iteration 250, Loss: 4.285199975129217e-05, Min w: 0.9747806787490845\n",
      "Iteration 260, Loss: 5.026612780056894e-05, Min w: 0.9695433378219604\n",
      "Iteration 270, Loss: 4.4601027184398845e-05, Min w: 0.9741144776344299\n",
      "Iteration 280, Loss: 4.431068737176247e-05, Min w: 0.9762378931045532\n",
      "Iteration 290, Loss: 5.16237887495663e-05, Min w: 0.9678110480308533\n",
      "Iteration 300, Loss: 5.961837086942978e-05, Min w: 0.9617560505867004\n",
      "Iteration 310, Loss: 4.2773961467901245e-05, Min w: 0.9765975475311279\n",
      "Iteration 320, Loss: 4.533072205958888e-05, Min w: 0.9726779460906982\n",
      "Iteration 330, Loss: 4.379013262223452e-05, Min w: 0.9751917719841003\n",
      "Iteration 340, Loss: 4.565774725051597e-05, Min w: 0.9723799824714661\n",
      "Iteration 350, Loss: 4.64893710159231e-05, Min w: 0.972337543964386\n",
      "Iteration 360, Loss: 5.119350680615753e-05, Min w: 0.9667757153511047\n",
      "Iteration 370, Loss: 3.9877813833300024e-05, Min w: 0.9772660136222839\n",
      "Iteration 380, Loss: 4.8465273721376434e-05, Min w: 0.9706643223762512\n",
      "Iteration 390, Loss: 4.3887026549782604e-05, Min w: 0.9740207195281982\n",
      "Iteration 400, Loss: 4.14642236137297e-05, Min w: 0.9750354290008545\n",
      "Iteration 410, Loss: 4.0633607568452135e-05, Min w: 0.9774975776672363\n",
      "Iteration 420, Loss: 4.198260648990981e-05, Min w: 0.9763836860656738\n",
      "Iteration 430, Loss: 5.272817361401394e-05, Min w: 0.9640774130821228\n",
      "Iteration 440, Loss: 4.225076554575935e-05, Min w: 0.9755458235740662\n",
      "Iteration 450, Loss: 3.8561429391847923e-05, Min w: 0.9768934845924377\n",
      "Iteration 460, Loss: 4.465842357603833e-05, Min w: 0.9735920429229736\n",
      "Iteration 470, Loss: 4.3209525756537914e-05, Min w: 0.9756977558135986\n",
      "Iteration 480, Loss: 4.5915785449324176e-05, Min w: 0.9725772142410278\n",
      "Iteration 490, Loss: 5.125003008288331e-05, Min w: 0.9682881236076355\n",
      "Iteration 500, Loss: 3.87171603506431e-05, Min w: 0.9781791567802429\n",
      "Iteration 510, Loss: 4.474043089430779e-05, Min w: 0.9754161834716797\n",
      "Iteration 520, Loss: 4.2256302549503744e-05, Min w: 0.9738881587982178\n",
      "Iteration 530, Loss: 3.9133978134486824e-05, Min w: 0.9785199165344238\n",
      "Iteration 540, Loss: 4.4305714254733175e-05, Min w: 0.9745776653289795\n",
      "Iteration 550, Loss: 4.026483293273486e-05, Min w: 0.9761483669281006\n",
      "Iteration 560, Loss: 3.9670725527685136e-05, Min w: 0.9770790338516235\n",
      "Iteration 570, Loss: 4.562558387988247e-05, Min w: 0.9699211716651917\n",
      "Iteration 580, Loss: 6.999572360655293e-05, Min w: 0.9536867737770081\n",
      "Iteration 590, Loss: 5.082256029709242e-05, Min w: 0.9673219323158264\n",
      "Iteration 600, Loss: 4.756616544909775e-05, Min w: 0.9695672392845154\n",
      "Iteration 610, Loss: 4.373638876131736e-05, Min w: 0.9738112092018127\n",
      "Iteration 620, Loss: 4.432087735040113e-05, Min w: 0.9731904864311218\n",
      "Iteration 630, Loss: 3.815380478044972e-05, Min w: 0.9780471920967102\n",
      "Iteration 640, Loss: 4.479522613110021e-05, Min w: 0.9733572602272034\n",
      "Iteration 650, Loss: 6.206145917531103e-05, Min w: 0.9559603929519653\n",
      "Iteration 660, Loss: 4.169215026195161e-05, Min w: 0.9752260446548462\n",
      "Iteration 670, Loss: 4.161498509347439e-05, Min w: 0.9752242565155029\n",
      "Iteration 680, Loss: 4.55521912954282e-05, Min w: 0.9727924466133118\n",
      "Iteration 690, Loss: 3.652203668025322e-05, Min w: 0.9778218865394592\n",
      "Iteration 700, Loss: 3.9166086935438216e-05, Min w: 0.9782437086105347\n",
      "Iteration 710, Loss: 5.0758888392010704e-05, Min w: 0.9683023691177368\n",
      "Iteration 720, Loss: 4.224551594234072e-05, Min w: 0.9742436408996582\n",
      "Iteration 730, Loss: 3.716404171427712e-05, Min w: 0.9793035387992859\n",
      "Iteration 740, Loss: 5.5423246521968395e-05, Min w: 0.9639638662338257\n",
      "Iteration 750, Loss: 3.830954301520251e-05, Min w: 0.9770045280456543\n",
      "Iteration 760, Loss: 3.8301252061501145e-05, Min w: 0.9773672223091125\n",
      "Iteration 770, Loss: 4.0852253732737154e-05, Min w: 0.9756169319152832\n",
      "Iteration 780, Loss: 3.6615063436329365e-05, Min w: 0.9776166081428528\n",
      "Iteration 790, Loss: 4.120666199014522e-05, Min w: 0.9750742316246033\n",
      "Iteration 800, Loss: 3.8483409298351035e-05, Min w: 0.9770596623420715\n",
      "Iteration 810, Loss: 4.254760278854519e-05, Min w: 0.9743528962135315\n",
      "Iteration 820, Loss: 4.157399234827608e-05, Min w: 0.9744439721107483\n",
      "Iteration 830, Loss: 3.632981315604411e-05, Min w: 0.9782636761665344\n",
      "Iteration 840, Loss: 3.9737988117849454e-05, Min w: 0.9760913252830505\n",
      "Iteration 850, Loss: 3.7615533074131235e-05, Min w: 0.9787993431091309\n",
      "Iteration 860, Loss: 5.8893645473290235e-05, Min w: 0.9652566909790039\n",
      "Iteration 870, Loss: 6.239490903681144e-05, Min w: 0.9565231204032898\n",
      "Iteration 880, Loss: 3.5774246498476714e-05, Min w: 0.9792260527610779\n",
      "Iteration 890, Loss: 3.769711474888027e-05, Min w: 0.9788112044334412\n",
      "Iteration 900, Loss: 3.3432119380449876e-05, Min w: 0.9805825352668762\n",
      "Iteration 910, Loss: 4.278232154319994e-05, Min w: 0.9742773175239563\n",
      "Iteration 920, Loss: 4.777077629114501e-05, Min w: 0.9692492485046387\n",
      "Iteration 930, Loss: 3.974599530920386e-05, Min w: 0.9755292534828186\n",
      "Iteration 940, Loss: 3.9838796510593966e-05, Min w: 0.9766926169395447\n",
      "Iteration 950, Loss: 6.754661444574594e-05, Min w: 0.9521827101707458\n",
      "Iteration 960, Loss: 3.9155518607003614e-05, Min w: 0.9768065214157104\n",
      "Iteration 970, Loss: 3.7143294321140274e-05, Min w: 0.9768088459968567\n",
      "Iteration 980, Loss: 3.8388927350752056e-05, Min w: 0.9756634831428528\n",
      "Iteration 990, Loss: 4.1796607547439635e-05, Min w: 0.9756733775138855\n",
      "Iteration 1000, Loss: 3.802478750003502e-05, Min w: 0.9774726629257202\n",
      "Iteration 1010, Loss: 5.027934821555391e-05, Min w: 0.9669926762580872\n",
      "Iteration 1020, Loss: 4.3907028157263994e-05, Min w: 0.9723019003868103\n",
      "Iteration 1030, Loss: 3.571846173144877e-05, Min w: 0.9798659682273865\n",
      "Iteration 1040, Loss: 3.610488056438044e-05, Min w: 0.9787894487380981\n",
      "Iteration 1050, Loss: 4.1387400415260345e-05, Min w: 0.974472165107727\n",
      "Iteration 1060, Loss: 3.8688056520186365e-05, Min w: 0.9762968420982361\n",
      "Iteration 1070, Loss: 3.239667785237543e-05, Min w: 0.9821205735206604\n",
      "Iteration 1080, Loss: 3.399656270630658e-05, Min w: 0.981291651725769\n",
      "Iteration 1090, Loss: 4.763453398481943e-05, Min w: 0.9687711596488953\n",
      "Iteration 1100, Loss: 4.519893627730198e-05, Min w: 0.9720344543457031\n",
      "Iteration 1110, Loss: 3.647140692919493e-05, Min w: 0.9785900712013245\n",
      "Iteration 1120, Loss: 3.589320840546861e-05, Min w: 0.9787261486053467\n",
      "Iteration 1130, Loss: 3.896337511832826e-05, Min w: 0.9778145551681519\n",
      "Iteration 1140, Loss: 3.862824814859778e-05, Min w: 0.977321207523346\n",
      "Iteration 1150, Loss: 3.7303532735677436e-05, Min w: 0.9785014986991882\n",
      "Iteration 1160, Loss: 3.6446130252443254e-05, Min w: 0.9775150418281555\n",
      "Iteration 1170, Loss: 5.8112545957555994e-05, Min w: 0.9596863389015198\n",
      "Iteration 1180, Loss: 3.5694301914190874e-05, Min w: 0.9776419401168823\n",
      "Iteration 1190, Loss: 3.733472112799063e-05, Min w: 0.9765630960464478\n",
      "Iteration 1200, Loss: 4.022502253064886e-05, Min w: 0.9751859307289124\n",
      "Iteration 1210, Loss: 3.602331707952544e-05, Min w: 0.9775062203407288\n",
      "Iteration 1220, Loss: 3.592288703657687e-05, Min w: 0.9785622954368591\n",
      "Iteration 1230, Loss: 3.2717292924644426e-05, Min w: 0.9809314608573914\n",
      "Iteration 1240, Loss: 3.4944147046189755e-05, Min w: 0.9799954295158386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  88%|████████▊ | 21/24 [35:32<05:46, 115.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.011368046023496507, 'L2_avg': 0.013121703770109572, 'End_point_L1_avg': 0.009603723934275298, 'End_point_L2_avg': 0.009621648546969565}\n",
      "Iteration 0, Loss: 0.004264162387698889, Min w: 0.0\n",
      "Iteration 10, Loss: 0.003916224464774132, Min w: 5.050810877665294e-15\n",
      "Iteration 20, Loss: 0.0033892602659761906, Min w: 2.4217200334434752e-33\n",
      "Iteration 30, Loss: 0.0031034215353429317, Min w: 2.1352651929827667e-37\n",
      "Iteration 40, Loss: 0.002887940499931574, Min w: 1.2365176759571653e-38\n",
      "Iteration 50, Loss: 0.0026333683636039495, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002504518022760749, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0023329216055572033, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0022111914586275816, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0021137185394763947, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002002038760110736, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0019251970807090402, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0018302096286788583, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0017584506422281265, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0016855098074302077, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0016670851036906242, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0016037215245887637, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0016097475308924913, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0015488038770854473, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0015874810051172972, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0016510491259396076, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0016774297691881657, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0015744654228910804, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0016024947399273515, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0014938885578885674, Min w: 3.700978902957832e-38\n",
      "Iteration 250, Loss: 0.0016085788374766707, Min w: 7.14936395421641e-27\n",
      "Iteration 260, Loss: 0.0014514913782477379, Min w: 5.102676866035025e-21\n",
      "Iteration 270, Loss: 0.001443820889107883, Min w: 1.6742099175656548e-14\n",
      "Iteration 280, Loss: 0.0014405756955966353, Min w: 5.338455719150481e-11\n",
      "Iteration 290, Loss: 0.0014639826258644462, Min w: 4.622281267074868e-06\n",
      "Iteration 300, Loss: 0.001399157801643014, Min w: 0.004223405383527279\n",
      "Iteration 310, Loss: 0.001396680367179215, Min w: 0.018246851861476898\n",
      "Iteration 320, Loss: 0.0014027925208210945, Min w: 0.014526481740176678\n",
      "Iteration 330, Loss: 0.0014104107394814491, Min w: 0.03076939284801483\n",
      "Iteration 340, Loss: 0.0013902693754062057, Min w: 0.051629286259412766\n",
      "Iteration 350, Loss: 0.0013637255178764462, Min w: 0.06572128087282181\n",
      "Iteration 360, Loss: 0.0013298604171723127, Min w: 0.09498221427202225\n",
      "Iteration 370, Loss: 0.0012938616564497352, Min w: 0.12083958834409714\n",
      "Iteration 380, Loss: 0.0012428835034370422, Min w: 0.15134799480438232\n",
      "Iteration 390, Loss: 0.001199383637867868, Min w: 0.1884467452764511\n",
      "Iteration 400, Loss: 0.0012034608516842127, Min w: 0.1872512549161911\n",
      "Iteration 410, Loss: 0.0011273720301687717, Min w: 0.24102157354354858\n",
      "Iteration 420, Loss: 0.0011094597866758704, Min w: 0.2601766884326935\n",
      "Iteration 430, Loss: 0.001094292034395039, Min w: 0.27202409505844116\n",
      "Iteration 440, Loss: 0.0010677038226276636, Min w: 0.28394463658332825\n",
      "Iteration 450, Loss: 0.001051706145517528, Min w: 0.28511843085289\n",
      "Iteration 460, Loss: 0.001044607488438487, Min w: 0.3075374662876129\n",
      "Iteration 470, Loss: 0.000979642616584897, Min w: 0.3403819799423218\n",
      "Iteration 480, Loss: 0.001023705000989139, Min w: 0.3152288794517517\n",
      "Iteration 490, Loss: 0.0009809816256165504, Min w: 0.3462536334991455\n",
      "Iteration 500, Loss: 0.0009415392414666712, Min w: 0.3539612889289856\n",
      "Iteration 510, Loss: 0.0008973173098638654, Min w: 0.39908772706985474\n",
      "Iteration 520, Loss: 0.000912019400857389, Min w: 0.37373626232147217\n",
      "Iteration 530, Loss: 0.0008815674809738994, Min w: 0.3957267999649048\n",
      "Iteration 540, Loss: 0.0008910802425816655, Min w: 0.39594733715057373\n",
      "Iteration 550, Loss: 0.0008539478294551373, Min w: 0.41484859585762024\n",
      "Iteration 560, Loss: 0.0008663063053973019, Min w: 0.4104536175727844\n",
      "Iteration 570, Loss: 0.0008423811523243785, Min w: 0.4257321357727051\n",
      "Iteration 580, Loss: 0.0008405331755056977, Min w: 0.42865774035453796\n",
      "Iteration 590, Loss: 0.0008164094761013985, Min w: 0.4290790259838104\n",
      "Iteration 600, Loss: 0.0008344551897607744, Min w: 0.42813265323638916\n",
      "Iteration 610, Loss: 0.0008253338746726513, Min w: 0.4331224262714386\n",
      "Iteration 620, Loss: 0.0007688687765039504, Min w: 0.45766782760620117\n",
      "Iteration 630, Loss: 0.0007775567355565727, Min w: 0.4766480624675751\n",
      "Iteration 640, Loss: 0.00075400376226753, Min w: 0.4771577715873718\n",
      "Iteration 650, Loss: 0.000762354873586446, Min w: 0.48087751865386963\n",
      "Iteration 660, Loss: 0.000747381302062422, Min w: 0.4865562319755554\n",
      "Iteration 670, Loss: 0.0007505384273827076, Min w: 0.48590758442878723\n",
      "Iteration 680, Loss: 0.0007519712671637535, Min w: 0.4800580143928528\n",
      "Iteration 690, Loss: 0.0007401304901577532, Min w: 0.4899655282497406\n",
      "Iteration 700, Loss: 0.000781682669185102, Min w: 0.48322439193725586\n",
      "Iteration 710, Loss: 0.000725340680219233, Min w: 0.5016087889671326\n",
      "Iteration 720, Loss: 0.00070957065327093, Min w: 0.5182693600654602\n",
      "Iteration 730, Loss: 0.0007216224912554026, Min w: 0.5279755592346191\n",
      "Iteration 740, Loss: 0.000679815944749862, Min w: 0.5204218626022339\n",
      "Iteration 750, Loss: 0.0006914904224686325, Min w: 0.537289559841156\n",
      "Iteration 760, Loss: 0.0007038919138722122, Min w: 0.5167196393013\n",
      "Iteration 770, Loss: 0.0007205248693935573, Min w: 0.525568962097168\n",
      "Iteration 780, Loss: 0.0006483857869170606, Min w: 0.5573319792747498\n",
      "Iteration 790, Loss: 0.0006456731935031712, Min w: 0.5562208294868469\n",
      "Iteration 800, Loss: 0.0006542225601151586, Min w: 0.5524123311042786\n",
      "Iteration 810, Loss: 0.0006812746287323534, Min w: 0.5291361212730408\n",
      "Iteration 820, Loss: 0.0006351287593133748, Min w: 0.5490708351135254\n",
      "Iteration 830, Loss: 0.0006955115823075175, Min w: 0.5448113083839417\n",
      "Iteration 840, Loss: 0.0006112107657827437, Min w: 0.5913960337638855\n",
      "Iteration 850, Loss: 0.00063498062081635, Min w: 0.5702270269393921\n",
      "Iteration 860, Loss: 0.0006422076839953661, Min w: 0.5646072030067444\n",
      "Iteration 870, Loss: 0.0005978858098387718, Min w: 0.5799446105957031\n",
      "Iteration 880, Loss: 0.0006339718820527196, Min w: 0.5643194913864136\n",
      "Iteration 890, Loss: 0.0005896767834201455, Min w: 0.5944980382919312\n",
      "Iteration 900, Loss: 0.0006147255771793425, Min w: 0.5793659687042236\n",
      "Iteration 910, Loss: 0.0005916024674661458, Min w: 0.5903259515762329\n",
      "Iteration 920, Loss: 0.000594691198784858, Min w: 0.5879937410354614\n",
      "Iteration 930, Loss: 0.000596291502006352, Min w: 0.5928662419319153\n",
      "Iteration 940, Loss: 0.0005841487436555326, Min w: 0.6068152189254761\n",
      "Iteration 950, Loss: 0.0005643501644954085, Min w: 0.6110535860061646\n",
      "Iteration 960, Loss: 0.0005554055096581578, Min w: 0.6106019020080566\n",
      "Iteration 970, Loss: 0.0005750905838795006, Min w: 0.6006997227668762\n",
      "Iteration 980, Loss: 0.0005563996965065598, Min w: 0.6281834244728088\n",
      "Iteration 990, Loss: 0.0005534380325116217, Min w: 0.6107089519500732\n",
      "Iteration 1000, Loss: 0.0005723973736166954, Min w: 0.6015564799308777\n",
      "Iteration 1010, Loss: 0.0005688061355613172, Min w: 0.6360903382301331\n",
      "Iteration 1020, Loss: 0.0005515110096894205, Min w: 0.6158397793769836\n",
      "Iteration 1030, Loss: 0.0005617925780825317, Min w: 0.6219483613967896\n",
      "Iteration 1040, Loss: 0.0005188900395296514, Min w: 0.6392083168029785\n",
      "Iteration 1050, Loss: 0.0004898228216916323, Min w: 0.6601297855377197\n",
      "Iteration 1060, Loss: 0.0005245918873697519, Min w: 0.6414684057235718\n",
      "Iteration 1070, Loss: 0.0005011399043723941, Min w: 0.656183123588562\n",
      "Iteration 1080, Loss: 0.0005215835408307612, Min w: 0.6367916464805603\n",
      "Iteration 1090, Loss: 0.0004907870898023248, Min w: 0.6513434648513794\n",
      "Iteration 1100, Loss: 0.0005008683074265718, Min w: 0.6749988198280334\n",
      "Iteration 1110, Loss: 0.0005139039712958038, Min w: 0.6678828001022339\n",
      "Iteration 1120, Loss: 0.0005023396224714816, Min w: 0.6546037197113037\n",
      "Iteration 1130, Loss: 0.0005287175881676376, Min w: 0.660664975643158\n",
      "Iteration 1140, Loss: 0.0004956303164362907, Min w: 0.6692315936088562\n",
      "Iteration 1150, Loss: 0.0004982584505341947, Min w: 0.6631070375442505\n",
      "Iteration 1160, Loss: 0.0004876009770669043, Min w: 0.6670083403587341\n",
      "Iteration 1170, Loss: 0.0004779504088219255, Min w: 0.6782283782958984\n",
      "Iteration 1180, Loss: 0.00045864764251746237, Min w: 0.6808468103408813\n",
      "Iteration 1190, Loss: 0.0004902052460238338, Min w: 0.6654487252235413\n",
      "Iteration 1200, Loss: 0.0004708301567006856, Min w: 0.6883962750434875\n",
      "Iteration 1210, Loss: 0.0004939339705742896, Min w: 0.6862411499023438\n",
      "Iteration 1220, Loss: 0.0004547970602288842, Min w: 0.699705183506012\n",
      "Iteration 1230, Loss: 0.0004653491487260908, Min w: 0.6973002552986145\n",
      "Iteration 1240, Loss: 0.00043628495768643916, Min w: 0.7022345662117004\n",
      "Iteration 0, Loss: 0.00046675605699419975, Min w: 0.6887909770011902\n",
      "Iteration 10, Loss: 0.00045095206587575376, Min w: 0.6910973787307739\n",
      "Iteration 20, Loss: 0.000451481289928779, Min w: 0.6931010484695435\n",
      "Iteration 30, Loss: 0.0004224397416692227, Min w: 0.7090269327163696\n",
      "Iteration 40, Loss: 0.0004477842594496906, Min w: 0.704247772693634\n",
      "Iteration 50, Loss: 0.0004200780240353197, Min w: 0.7186715602874756\n",
      "Iteration 60, Loss: 0.00042347339331172407, Min w: 0.7055686712265015\n",
      "Iteration 70, Loss: 0.0004220140690449625, Min w: 0.7126087546348572\n",
      "Iteration 80, Loss: 0.0004049275303259492, Min w: 0.734433114528656\n",
      "Iteration 90, Loss: 0.0004082427767571062, Min w: 0.7259608507156372\n",
      "Iteration 100, Loss: 0.00041283524478785694, Min w: 0.7228469252586365\n",
      "Iteration 110, Loss: 0.0004297215782571584, Min w: 0.7215052843093872\n",
      "Iteration 120, Loss: 0.00044059540960006416, Min w: 0.7219758629798889\n",
      "Iteration 130, Loss: 0.0004188805469311774, Min w: 0.7272607088088989\n",
      "Iteration 140, Loss: 0.0004125367559026927, Min w: 0.7190062999725342\n",
      "Iteration 150, Loss: 0.0004035165475215763, Min w: 0.73688143491745\n",
      "Iteration 160, Loss: 0.0003806382301263511, Min w: 0.7423025369644165\n",
      "Iteration 170, Loss: 0.0003828607441391796, Min w: 0.743045449256897\n",
      "Iteration 180, Loss: 0.0003837534168269485, Min w: 0.7478843927383423\n",
      "Iteration 190, Loss: 0.00038695725379511714, Min w: 0.7348705530166626\n",
      "Iteration 200, Loss: 0.0004076498153153807, Min w: 0.7260445952415466\n",
      "Iteration 210, Loss: 0.0003712459874805063, Min w: 0.7612348198890686\n",
      "Iteration 220, Loss: 0.0003801135753747076, Min w: 0.7534056305885315\n",
      "Iteration 230, Loss: 0.0003645658725872636, Min w: 0.7534336447715759\n",
      "Iteration 240, Loss: 0.00037017828435637057, Min w: 0.7634096741676331\n",
      "Iteration 250, Loss: 0.00037254876224324107, Min w: 0.7476728558540344\n",
      "Iteration 260, Loss: 0.0003763820859603584, Min w: 0.742239236831665\n",
      "Iteration 270, Loss: 0.0003742152184713632, Min w: 0.7553961873054504\n",
      "Iteration 280, Loss: 0.00035973291960544884, Min w: 0.7796951532363892\n",
      "Iteration 290, Loss: 0.0003712289035320282, Min w: 0.7762002944946289\n",
      "Iteration 300, Loss: 0.0003653111634775996, Min w: 0.7629106044769287\n",
      "Iteration 310, Loss: 0.00037319600232876837, Min w: 0.7700134515762329\n",
      "Iteration 320, Loss: 0.000373911956558004, Min w: 0.7692052721977234\n",
      "Iteration 330, Loss: 0.0003679480869323015, Min w: 0.758452832698822\n",
      "Iteration 340, Loss: 0.00035500962985679507, Min w: 0.7710570096969604\n",
      "Iteration 350, Loss: 0.00033564624027349055, Min w: 0.7808843851089478\n",
      "Iteration 360, Loss: 0.0003577771713025868, Min w: 0.7746360301971436\n",
      "Iteration 370, Loss: 0.00034965635859407485, Min w: 0.7842116951942444\n",
      "Iteration 380, Loss: 0.00034635563497431576, Min w: 0.7726362943649292\n",
      "Iteration 390, Loss: 0.00032424507662653923, Min w: 0.7968268394470215\n",
      "Iteration 400, Loss: 0.0003608768165577203, Min w: 0.7634265422821045\n",
      "Iteration 410, Loss: 0.0003264648257754743, Min w: 0.7896863222122192\n",
      "Iteration 420, Loss: 0.0003628392005339265, Min w: 0.7838462591171265\n",
      "Iteration 430, Loss: 0.00033151794923469424, Min w: 0.7824440598487854\n",
      "Iteration 440, Loss: 0.00033919120323844254, Min w: 0.7916569113731384\n",
      "Iteration 450, Loss: 0.00031536855385638773, Min w: 0.792595624923706\n",
      "Iteration 460, Loss: 0.0003569043765310198, Min w: 0.7877827286720276\n",
      "Iteration 470, Loss: 0.00033662503119558096, Min w: 0.7968865633010864\n",
      "Iteration 480, Loss: 0.0003289011656306684, Min w: 0.7875264883041382\n",
      "Iteration 490, Loss: 0.00033825033460743725, Min w: 0.7861511707305908\n",
      "Iteration 500, Loss: 0.00031960278283804655, Min w: 0.808391273021698\n",
      "Iteration 510, Loss: 0.00032301561441272497, Min w: 0.803578794002533\n",
      "Iteration 520, Loss: 0.00030725690885446966, Min w: 0.8055581450462341\n",
      "Iteration 530, Loss: 0.00034208004944957793, Min w: 0.7979432940483093\n",
      "Iteration 540, Loss: 0.00030256438185460865, Min w: 0.8076733946800232\n",
      "Iteration 550, Loss: 0.00033498628181405365, Min w: 0.7929060459136963\n",
      "Iteration 560, Loss: 0.0003006454207934439, Min w: 0.8141673803329468\n",
      "Iteration 570, Loss: 0.00030959537252783775, Min w: 0.8055505752563477\n",
      "Iteration 580, Loss: 0.0003149510594084859, Min w: 0.8089620471000671\n",
      "Iteration 590, Loss: 0.0003030424704775214, Min w: 0.7978244423866272\n",
      "Iteration 600, Loss: 0.0003223729436285794, Min w: 0.8036206960678101\n",
      "Iteration 610, Loss: 0.00028933165594935417, Min w: 0.8244165182113647\n",
      "Iteration 620, Loss: 0.00030690847779624164, Min w: 0.8052207827568054\n",
      "Iteration 630, Loss: 0.00027569220401346684, Min w: 0.8253008127212524\n",
      "Iteration 640, Loss: 0.00026320776669308543, Min w: 0.8330920934677124\n",
      "Iteration 650, Loss: 0.0002992584486491978, Min w: 0.8268688917160034\n",
      "Iteration 660, Loss: 0.00028777195257134736, Min w: 0.8128021359443665\n",
      "Iteration 670, Loss: 0.00028211346943862736, Min w: 0.8304435014724731\n",
      "Iteration 680, Loss: 0.00027971118106506765, Min w: 0.8324307799339294\n",
      "Iteration 690, Loss: 0.0002829232544172555, Min w: 0.8276833295822144\n",
      "Iteration 700, Loss: 0.00028944891528226435, Min w: 0.8347457647323608\n",
      "Iteration 710, Loss: 0.00028570956783369184, Min w: 0.8218028545379639\n",
      "Iteration 720, Loss: 0.0002759993658401072, Min w: 0.8207299113273621\n",
      "Iteration 730, Loss: 0.0002727119717746973, Min w: 0.8457223176956177\n",
      "Iteration 740, Loss: 0.0003093291015829891, Min w: 0.82796311378479\n",
      "Iteration 750, Loss: 0.000270954828010872, Min w: 0.8420074582099915\n",
      "Iteration 760, Loss: 0.00024383212439715862, Min w: 0.845102846622467\n",
      "Iteration 770, Loss: 0.0002831124875228852, Min w: 0.8394886255264282\n",
      "Iteration 780, Loss: 0.00025900942273437977, Min w: 0.8448938727378845\n",
      "Iteration 790, Loss: 0.000262608053162694, Min w: 0.8332952857017517\n",
      "Iteration 800, Loss: 0.00026017046184279025, Min w: 0.8385761380195618\n",
      "Iteration 810, Loss: 0.0002849237062036991, Min w: 0.8468652367591858\n",
      "Iteration 820, Loss: 0.0002909233153332025, Min w: 0.8389928936958313\n",
      "Iteration 830, Loss: 0.00026078757946379483, Min w: 0.8382344245910645\n",
      "Iteration 840, Loss: 0.00025481305783614516, Min w: 0.8530709147453308\n",
      "Iteration 850, Loss: 0.0002855505154002458, Min w: 0.8433745503425598\n",
      "Iteration 860, Loss: 0.00026815675664693117, Min w: 0.8492531180381775\n",
      "Iteration 870, Loss: 0.00026236067060381174, Min w: 0.8550277948379517\n",
      "Iteration 880, Loss: 0.00027454030350781977, Min w: 0.8389980792999268\n",
      "Iteration 890, Loss: 0.0002377391210757196, Min w: 0.8605440855026245\n",
      "Iteration 900, Loss: 0.00023695442359894514, Min w: 0.8614824414253235\n",
      "Iteration 910, Loss: 0.00024144815688487142, Min w: 0.8660224080085754\n",
      "Iteration 920, Loss: 0.00028062923229299486, Min w: 0.8430891036987305\n",
      "Iteration 930, Loss: 0.00025349759380333126, Min w: 0.8503967523574829\n",
      "Iteration 940, Loss: 0.00024552454124204814, Min w: 0.860556960105896\n",
      "Iteration 950, Loss: 0.00024590801331214607, Min w: 0.8578447699546814\n",
      "Iteration 960, Loss: 0.00022418871230911463, Min w: 0.8780258893966675\n",
      "Iteration 970, Loss: 0.00024054294044617563, Min w: 0.8638227581977844\n",
      "Iteration 980, Loss: 0.0002273630234412849, Min w: 0.8685774803161621\n",
      "Iteration 990, Loss: 0.00022693330538459122, Min w: 0.8717159032821655\n",
      "Iteration 1000, Loss: 0.00021566470968537033, Min w: 0.8705022931098938\n",
      "Iteration 1010, Loss: 0.00022565525432582945, Min w: 0.8734831213951111\n",
      "Iteration 1020, Loss: 0.00023610828793607652, Min w: 0.8767262697219849\n",
      "Iteration 1030, Loss: 0.00024030603526625782, Min w: 0.8634544014930725\n",
      "Iteration 1040, Loss: 0.00022811708913650364, Min w: 0.8649405837059021\n",
      "Iteration 1050, Loss: 0.00022383109899237752, Min w: 0.8755340576171875\n",
      "Iteration 1060, Loss: 0.00023746711667627096, Min w: 0.868902862071991\n",
      "Iteration 1070, Loss: 0.00025591286248527467, Min w: 0.8591447472572327\n",
      "Iteration 1080, Loss: 0.00022222510597202927, Min w: 0.8773779273033142\n",
      "Iteration 1090, Loss: 0.00022313656518235803, Min w: 0.8756709098815918\n",
      "Iteration 1100, Loss: 0.00022187740250956267, Min w: 0.876220703125\n",
      "Iteration 1110, Loss: 0.0002295509329997003, Min w: 0.877921998500824\n",
      "Iteration 1120, Loss: 0.0002247407246613875, Min w: 0.8719995617866516\n",
      "Iteration 1130, Loss: 0.00021060180733911693, Min w: 0.8784069418907166\n",
      "Iteration 1140, Loss: 0.0002070940099656582, Min w: 0.8841000199317932\n",
      "Iteration 1150, Loss: 0.00020795279124286026, Min w: 0.8825755715370178\n",
      "Iteration 1160, Loss: 0.0002188225626014173, Min w: 0.8743560910224915\n",
      "Iteration 1170, Loss: 0.0001971003075595945, Min w: 0.8893435597419739\n",
      "Iteration 1180, Loss: 0.00020000411313958466, Min w: 0.8842933177947998\n",
      "Iteration 1190, Loss: 0.00019215818610973656, Min w: 0.8922052979469299\n",
      "Iteration 1200, Loss: 0.00021983677288517356, Min w: 0.8837535977363586\n",
      "Iteration 1210, Loss: 0.00019636315118987113, Min w: 0.8842760920524597\n",
      "Iteration 1220, Loss: 0.00022196547070052475, Min w: 0.88094562292099\n",
      "Iteration 1230, Loss: 0.00021566062059719115, Min w: 0.8845880031585693\n",
      "Iteration 1240, Loss: 0.000201587172341533, Min w: 0.8926113247871399\n",
      "Iteration 0, Loss: 0.00019997934577986598, Min w: 0.891690194606781\n",
      "Iteration 10, Loss: 0.0002020927786361426, Min w: 0.8855153918266296\n",
      "Iteration 20, Loss: 0.0002010816242545843, Min w: 0.8891301155090332\n",
      "Iteration 30, Loss: 0.0002270389231853187, Min w: 0.8829538226127625\n",
      "Iteration 40, Loss: 0.00022513225849252194, Min w: 0.883023738861084\n",
      "Iteration 50, Loss: 0.00020160421263426542, Min w: 0.8870106935501099\n",
      "Iteration 60, Loss: 0.00020262533507775515, Min w: 0.8896660804748535\n",
      "Iteration 70, Loss: 0.00024899665731936693, Min w: 0.8667179346084595\n",
      "Iteration 80, Loss: 0.00019458477618172765, Min w: 0.8927934169769287\n",
      "Iteration 90, Loss: 0.0001916990295285359, Min w: 0.897967517375946\n",
      "Iteration 100, Loss: 0.00018217407341580838, Min w: 0.8972750902175903\n",
      "Iteration 110, Loss: 0.0001835034490795806, Min w: 0.9038161635398865\n",
      "Iteration 120, Loss: 0.000179776267032139, Min w: 0.8991994261741638\n",
      "Iteration 130, Loss: 0.00017780651978682727, Min w: 0.9056476950645447\n",
      "Iteration 140, Loss: 0.0001736060221446678, Min w: 0.9053207635879517\n",
      "Iteration 150, Loss: 0.00016312059597112238, Min w: 0.9060636162757874\n",
      "Iteration 160, Loss: 0.0001823904603952542, Min w: 0.9055672287940979\n",
      "Iteration 170, Loss: 0.00017176671826746315, Min w: 0.9057554602622986\n",
      "Iteration 180, Loss: 0.0001877185277407989, Min w: 0.8985702395439148\n",
      "Iteration 190, Loss: 0.00018186640227213502, Min w: 0.9018783569335938\n",
      "Iteration 200, Loss: 0.00017566667520441115, Min w: 0.9067109823226929\n",
      "Iteration 210, Loss: 0.00017623241001274437, Min w: 0.9002096652984619\n",
      "Iteration 220, Loss: 0.00017964400467462838, Min w: 0.9076555371284485\n",
      "Iteration 230, Loss: 0.00016958657943177968, Min w: 0.9014809131622314\n",
      "Iteration 240, Loss: 0.000177602720214054, Min w: 0.905935525894165\n",
      "Iteration 250, Loss: 0.00016775750555098057, Min w: 0.905606210231781\n",
      "Iteration 260, Loss: 0.00016488353139720857, Min w: 0.9152054786682129\n",
      "Iteration 270, Loss: 0.00017196097178384662, Min w: 0.905237078666687\n",
      "Iteration 280, Loss: 0.0001646485470701009, Min w: 0.9090020060539246\n",
      "Iteration 290, Loss: 0.00016486027743667364, Min w: 0.9066640138626099\n",
      "Iteration 300, Loss: 0.00016606472490821034, Min w: 0.9070255160331726\n",
      "Iteration 310, Loss: 0.0001820883626351133, Min w: 0.9060083031654358\n",
      "Iteration 320, Loss: 0.00014994425873737782, Min w: 0.9163390398025513\n",
      "Iteration 330, Loss: 0.00015665325918234885, Min w: 0.9113063216209412\n",
      "Iteration 340, Loss: 0.00016974288155324757, Min w: 0.9127068519592285\n",
      "Iteration 350, Loss: 0.00016103080997709185, Min w: 0.9133889675140381\n",
      "Iteration 360, Loss: 0.00015392845671158284, Min w: 0.9160459041595459\n",
      "Iteration 370, Loss: 0.0001493989839218557, Min w: 0.9145810008049011\n",
      "Iteration 380, Loss: 0.00016301727737300098, Min w: 0.9104073643684387\n",
      "Iteration 390, Loss: 0.00015369182801805437, Min w: 0.9129963517189026\n",
      "Iteration 400, Loss: 0.00016352008969988674, Min w: 0.9119778871536255\n",
      "Iteration 410, Loss: 0.0001624762371648103, Min w: 0.9142267107963562\n",
      "Iteration 420, Loss: 0.00017534272046759725, Min w: 0.9047964215278625\n",
      "Iteration 430, Loss: 0.0001480905048083514, Min w: 0.9224504828453064\n",
      "Iteration 440, Loss: 0.0001413776772096753, Min w: 0.9157217144966125\n",
      "Iteration 450, Loss: 0.0001515437033958733, Min w: 0.9186406135559082\n",
      "Iteration 460, Loss: 0.00015593280841130763, Min w: 0.9177777767181396\n",
      "Iteration 470, Loss: 0.000152652632095851, Min w: 0.9201385974884033\n",
      "Iteration 480, Loss: 0.00015847878239583224, Min w: 0.9114618897438049\n",
      "Iteration 490, Loss: 0.00015865678142290562, Min w: 0.9091988205909729\n",
      "Iteration 500, Loss: 0.0001448330731363967, Min w: 0.9211851358413696\n",
      "Iteration 510, Loss: 0.0001549670851090923, Min w: 0.9169082045555115\n",
      "Iteration 520, Loss: 0.0001385514042340219, Min w: 0.9232164025306702\n",
      "Iteration 530, Loss: 0.00013085876707918942, Min w: 0.9281922578811646\n",
      "Iteration 540, Loss: 0.0001468967238906771, Min w: 0.9128645062446594\n",
      "Iteration 550, Loss: 0.00014121374988462776, Min w: 0.9180628061294556\n",
      "Iteration 560, Loss: 0.00014724512584507465, Min w: 0.9185299277305603\n",
      "Iteration 570, Loss: 0.00013422974734567106, Min w: 0.9243549108505249\n",
      "Iteration 580, Loss: 0.00014786608517169952, Min w: 0.9229472279548645\n",
      "Iteration 590, Loss: 0.00014297571033239365, Min w: 0.9165164232254028\n",
      "Iteration 600, Loss: 0.00014164927415549755, Min w: 0.9247248768806458\n",
      "Iteration 610, Loss: 0.00014058708620723337, Min w: 0.9197709560394287\n",
      "Iteration 620, Loss: 0.00014110119082033634, Min w: 0.9237732887268066\n",
      "Iteration 630, Loss: 0.00014236362767405808, Min w: 0.9175391793251038\n",
      "Iteration 640, Loss: 0.0001395133585901931, Min w: 0.9257602095603943\n",
      "Iteration 650, Loss: 0.00013144619879312813, Min w: 0.9282704591751099\n",
      "Iteration 660, Loss: 0.00013215336366556585, Min w: 0.9250714778900146\n",
      "Iteration 670, Loss: 0.00013352278620004654, Min w: 0.9234403371810913\n",
      "Iteration 680, Loss: 0.00013822133769281209, Min w: 0.9241660237312317\n",
      "Iteration 690, Loss: 0.00012957026774529368, Min w: 0.9285480380058289\n",
      "Iteration 700, Loss: 0.00013466336531564593, Min w: 0.9263117909431458\n",
      "Iteration 710, Loss: 0.00012049523502355441, Min w: 0.9346233010292053\n",
      "Iteration 720, Loss: 0.00012973924458492547, Min w: 0.9319700598716736\n",
      "Iteration 730, Loss: 0.00012363065616227686, Min w: 0.9300220012664795\n",
      "Iteration 740, Loss: 0.0001302148011745885, Min w: 0.9280251264572144\n",
      "Iteration 750, Loss: 0.00011903961421921849, Min w: 0.9360377192497253\n",
      "Iteration 760, Loss: 0.00012768660963047296, Min w: 0.9274847507476807\n",
      "Iteration 770, Loss: 0.00013635568029712886, Min w: 0.9279971718788147\n",
      "Iteration 780, Loss: 0.00012882826558779925, Min w: 0.9305991530418396\n",
      "Iteration 790, Loss: 0.00012124199565732852, Min w: 0.9344197511672974\n",
      "Iteration 800, Loss: 0.00012224532838445157, Min w: 0.9353549480438232\n",
      "Iteration 810, Loss: 0.00011473814083728939, Min w: 0.9361398816108704\n",
      "Iteration 820, Loss: 0.0001257777912542224, Min w: 0.9322872161865234\n",
      "Iteration 830, Loss: 0.00013955430767964572, Min w: 0.9252968430519104\n",
      "Iteration 840, Loss: 0.00012643101217690855, Min w: 0.9292964935302734\n",
      "Iteration 850, Loss: 0.00012415953096933663, Min w: 0.9333407878875732\n",
      "Iteration 860, Loss: 0.0001240400888491422, Min w: 0.9325247406959534\n",
      "Iteration 870, Loss: 0.00010851523984456435, Min w: 0.9370526671409607\n",
      "Iteration 880, Loss: 0.00011592805094551295, Min w: 0.9306672215461731\n",
      "Iteration 890, Loss: 0.00010617652878863737, Min w: 0.9389529824256897\n",
      "Iteration 900, Loss: 0.00010482684592716396, Min w: 0.9434779286384583\n",
      "Iteration 910, Loss: 0.00011580847058212385, Min w: 0.9364490509033203\n",
      "Iteration 920, Loss: 0.00011652584362309426, Min w: 0.9342166781425476\n",
      "Iteration 930, Loss: 0.00011027176515199244, Min w: 0.9371618032455444\n",
      "Iteration 940, Loss: 0.00011804619862232357, Min w: 0.9334097504615784\n",
      "Iteration 950, Loss: 0.00010208599996985868, Min w: 0.9412794709205627\n",
      "Iteration 960, Loss: 0.00011452895705588162, Min w: 0.9325066804885864\n",
      "Iteration 970, Loss: 0.00011821032967418432, Min w: 0.9346520304679871\n",
      "Iteration 980, Loss: 0.0001204584987135604, Min w: 0.9347438812255859\n",
      "Iteration 990, Loss: 0.0001149588861153461, Min w: 0.9391194581985474\n",
      "Iteration 1000, Loss: 0.00011128636833745986, Min w: 0.9398722648620605\n",
      "Iteration 1010, Loss: 0.00010662279964890331, Min w: 0.9379382729530334\n",
      "Iteration 1020, Loss: 0.00010882971400860697, Min w: 0.9368389248847961\n",
      "Iteration 1030, Loss: 0.0001010304840747267, Min w: 0.9453917741775513\n",
      "Iteration 1040, Loss: 0.00010917083272943273, Min w: 0.937662661075592\n",
      "Iteration 1050, Loss: 0.00010527328413445503, Min w: 0.9421315789222717\n",
      "Iteration 1060, Loss: 0.00010739181016106158, Min w: 0.9404116272926331\n",
      "Iteration 1070, Loss: 0.00011124428419861943, Min w: 0.9404469728469849\n",
      "Iteration 1080, Loss: 0.00010307794582331553, Min w: 0.9405253529548645\n",
      "Iteration 1090, Loss: 0.00010205657599726692, Min w: 0.9412990212440491\n",
      "Iteration 1100, Loss: 0.00010590217425487936, Min w: 0.9396911859512329\n",
      "Iteration 1110, Loss: 0.00010491041757632047, Min w: 0.9388681054115295\n",
      "Iteration 1120, Loss: 0.000103591381048318, Min w: 0.9416785836219788\n",
      "Iteration 1130, Loss: 0.00010045057570096105, Min w: 0.9419823288917542\n",
      "Iteration 1140, Loss: 0.0001145346395787783, Min w: 0.9379453659057617\n",
      "Iteration 1150, Loss: 0.00010408247908344492, Min w: 0.9412389993667603\n",
      "Iteration 1160, Loss: 0.0001162593107437715, Min w: 0.9399889707565308\n",
      "Iteration 1170, Loss: 0.000117563693493139, Min w: 0.9390342831611633\n",
      "Iteration 1180, Loss: 0.00010442485654493794, Min w: 0.9449902772903442\n",
      "Iteration 1190, Loss: 9.53491689870134e-05, Min w: 0.9440099000930786\n",
      "Iteration 1200, Loss: 0.00010163263505091891, Min w: 0.9436287879943848\n",
      "Iteration 1210, Loss: 0.0001013682849588804, Min w: 0.9447067975997925\n",
      "Iteration 1220, Loss: 9.521905303699896e-05, Min w: 0.9469858407974243\n",
      "Iteration 1230, Loss: 9.14826596272178e-05, Min w: 0.9461697340011597\n",
      "Iteration 1240, Loss: 9.119154856307432e-05, Min w: 0.947102427482605\n",
      "Iteration 0, Loss: 9.623962978366762e-05, Min w: 0.9451804757118225\n",
      "Iteration 10, Loss: 9.937554568750784e-05, Min w: 0.9460397958755493\n",
      "Iteration 20, Loss: 0.00010241221025353298, Min w: 0.946444034576416\n",
      "Iteration 30, Loss: 9.906457853503525e-05, Min w: 0.9464871883392334\n",
      "Iteration 40, Loss: 8.812968007987365e-05, Min w: 0.9493551850318909\n",
      "Iteration 50, Loss: 9.382373536936939e-05, Min w: 0.9470984935760498\n",
      "Iteration 60, Loss: 9.784149006009102e-05, Min w: 0.9450621604919434\n",
      "Iteration 70, Loss: 9.66083534876816e-05, Min w: 0.94999098777771\n",
      "Iteration 80, Loss: 9.880907600745559e-05, Min w: 0.9490527510643005\n",
      "Iteration 90, Loss: 9.796550875762478e-05, Min w: 0.9480535387992859\n",
      "Iteration 100, Loss: 9.745869465405121e-05, Min w: 0.9463407397270203\n",
      "Iteration 110, Loss: 8.597080159233883e-05, Min w: 0.9509859085083008\n",
      "Iteration 120, Loss: 8.514367073075846e-05, Min w: 0.9508957862854004\n",
      "Iteration 130, Loss: 8.612063538748771e-05, Min w: 0.9497337937355042\n",
      "Iteration 140, Loss: 8.556293323636055e-05, Min w: 0.9520848989486694\n",
      "Iteration 150, Loss: 9.381229028804228e-05, Min w: 0.9479585289955139\n",
      "Iteration 160, Loss: 9.326289728051051e-05, Min w: 0.9507896304130554\n",
      "Iteration 170, Loss: 8.134542440529913e-05, Min w: 0.952242374420166\n",
      "Iteration 180, Loss: 8.110724593279883e-05, Min w: 0.9531767964363098\n",
      "Iteration 190, Loss: 9.474394755670801e-05, Min w: 0.9472861886024475\n",
      "Iteration 200, Loss: 9.016593685373664e-05, Min w: 0.9473955035209656\n",
      "Iteration 210, Loss: 8.599596912972629e-05, Min w: 0.9481334090232849\n",
      "Iteration 220, Loss: 8.558417903259397e-05, Min w: 0.9506847262382507\n",
      "Iteration 230, Loss: 8.769359556026757e-05, Min w: 0.9469426870346069\n",
      "Iteration 240, Loss: 0.00010358443250879645, Min w: 0.9377837777137756\n",
      "Iteration 250, Loss: 8.403282845392823e-05, Min w: 0.9526052474975586\n",
      "Iteration 260, Loss: 8.390828588744625e-05, Min w: 0.9529772400856018\n",
      "Iteration 270, Loss: 8.388043352169916e-05, Min w: 0.950543224811554\n",
      "Iteration 280, Loss: 8.903397974791005e-05, Min w: 0.9533079266548157\n",
      "Iteration 290, Loss: 8.449218876194209e-05, Min w: 0.9503355026245117\n",
      "Iteration 300, Loss: 8.557669207220897e-05, Min w: 0.9516392946243286\n",
      "Iteration 310, Loss: 9.322130063083023e-05, Min w: 0.9522566795349121\n",
      "Iteration 320, Loss: 8.862376853358e-05, Min w: 0.9471416473388672\n",
      "Iteration 330, Loss: 8.137553959386423e-05, Min w: 0.9548166394233704\n",
      "Iteration 340, Loss: 8.106933819362894e-05, Min w: 0.9526066780090332\n",
      "Iteration 350, Loss: 8.542201976524666e-05, Min w: 0.9557868838310242\n",
      "Iteration 360, Loss: 9.168009273707867e-05, Min w: 0.9524075984954834\n",
      "Iteration 370, Loss: 7.9113342508208e-05, Min w: 0.9544441103935242\n",
      "Iteration 380, Loss: 8.510579209541902e-05, Min w: 0.9523544311523438\n",
      "Iteration 390, Loss: 7.913834997452796e-05, Min w: 0.9539303779602051\n",
      "Iteration 400, Loss: 7.796984573360533e-05, Min w: 0.953379213809967\n",
      "Iteration 410, Loss: 7.953050953801721e-05, Min w: 0.9559873938560486\n",
      "Iteration 420, Loss: 8.43618472572416e-05, Min w: 0.955473780632019\n",
      "Iteration 430, Loss: 7.789611117914319e-05, Min w: 0.9544335603713989\n",
      "Iteration 440, Loss: 7.50451217754744e-05, Min w: 0.9555128812789917\n",
      "Iteration 450, Loss: 7.148354052333161e-05, Min w: 0.9561975002288818\n",
      "Iteration 460, Loss: 7.986876153154299e-05, Min w: 0.9521054625511169\n",
      "Iteration 470, Loss: 7.047111284919083e-05, Min w: 0.9570775628089905\n",
      "Iteration 480, Loss: 7.711256330367178e-05, Min w: 0.9544658064842224\n",
      "Iteration 490, Loss: 7.199771062005311e-05, Min w: 0.956730306148529\n",
      "Iteration 500, Loss: 7.856514275772497e-05, Min w: 0.9552211761474609\n",
      "Iteration 510, Loss: 7.785159687045962e-05, Min w: 0.9542299509048462\n",
      "Iteration 520, Loss: 7.626443402841687e-05, Min w: 0.9550758004188538\n",
      "Iteration 530, Loss: 0.00010194587230216712, Min w: 0.9407848119735718\n",
      "Iteration 540, Loss: 7.740849832771346e-05, Min w: 0.9537193775177002\n",
      "Iteration 550, Loss: 7.590439781779423e-05, Min w: 0.9564141035079956\n",
      "Iteration 560, Loss: 8.12810831121169e-05, Min w: 0.9581949710845947\n",
      "Iteration 570, Loss: 6.964038766454905e-05, Min w: 0.9597597718238831\n",
      "Iteration 580, Loss: 6.964751810301095e-05, Min w: 0.9586090445518494\n",
      "Iteration 590, Loss: 9.260133083444089e-05, Min w: 0.9465336799621582\n",
      "Iteration 600, Loss: 7.200049731181934e-05, Min w: 0.9596278667449951\n",
      "Iteration 610, Loss: 7.620592805324122e-05, Min w: 0.9601647853851318\n",
      "Iteration 620, Loss: 6.916864367667586e-05, Min w: 0.958503246307373\n",
      "Iteration 630, Loss: 6.625751848332584e-05, Min w: 0.9616090655326843\n",
      "Iteration 640, Loss: 9.353536734124646e-05, Min w: 0.9480234980583191\n",
      "Iteration 650, Loss: 7.051497959764674e-05, Min w: 0.9599913954734802\n",
      "Iteration 660, Loss: 8.313378202728927e-05, Min w: 0.9550244808197021\n",
      "Iteration 670, Loss: 7.45181241654791e-05, Min w: 0.9583070874214172\n",
      "Iteration 680, Loss: 6.884954927954823e-05, Min w: 0.9603226184844971\n",
      "Iteration 690, Loss: 6.921131716808304e-05, Min w: 0.9610461592674255\n",
      "Iteration 700, Loss: 7.533007737947628e-05, Min w: 0.9611337184906006\n",
      "Iteration 710, Loss: 7.059249037411064e-05, Min w: 0.9586833119392395\n",
      "Iteration 720, Loss: 7.155013008741662e-05, Min w: 0.9583196043968201\n",
      "Iteration 730, Loss: 7.511223520850763e-05, Min w: 0.954716145992279\n",
      "Iteration 740, Loss: 8.233218250097707e-05, Min w: 0.954370379447937\n",
      "Iteration 750, Loss: 7.688893674639985e-05, Min w: 0.9564030766487122\n",
      "Iteration 760, Loss: 8.725625229999423e-05, Min w: 0.953311026096344\n",
      "Iteration 770, Loss: 7.168937736423686e-05, Min w: 0.959991455078125\n",
      "Iteration 780, Loss: 6.594316073460504e-05, Min w: 0.9621394276618958\n",
      "Iteration 790, Loss: 6.993478018557653e-05, Min w: 0.9610327482223511\n",
      "Iteration 800, Loss: 6.36039549135603e-05, Min w: 0.9649180769920349\n",
      "Iteration 810, Loss: 6.343161658151075e-05, Min w: 0.9646309614181519\n",
      "Iteration 820, Loss: 6.743597623426467e-05, Min w: 0.9598712921142578\n",
      "Iteration 830, Loss: 6.862037116661668e-05, Min w: 0.9635409712791443\n",
      "Iteration 840, Loss: 6.193274020915851e-05, Min w: 0.9628666639328003\n",
      "Iteration 850, Loss: 6.475446571130306e-05, Min w: 0.9605402946472168\n",
      "Iteration 860, Loss: 7.535649638157338e-05, Min w: 0.9605579376220703\n",
      "Iteration 870, Loss: 6.3762825448066e-05, Min w: 0.9630681276321411\n",
      "Iteration 880, Loss: 8.828045974951237e-05, Min w: 0.953599750995636\n",
      "Iteration 890, Loss: 7.225082663353533e-05, Min w: 0.9591743350028992\n",
      "Iteration 900, Loss: 6.930700328666717e-05, Min w: 0.9625571966171265\n",
      "Iteration 910, Loss: 6.581281195394695e-05, Min w: 0.9608472585678101\n",
      "Iteration 920, Loss: 6.704709812765941e-05, Min w: 0.9637156128883362\n",
      "Iteration 930, Loss: 6.901234155520797e-05, Min w: 0.9602408409118652\n",
      "Iteration 940, Loss: 6.560766632901505e-05, Min w: 0.9635574817657471\n",
      "Iteration 950, Loss: 7.111365266609937e-05, Min w: 0.9603328108787537\n",
      "Iteration 960, Loss: 6.965739885345101e-05, Min w: 0.959934413433075\n",
      "Iteration 970, Loss: 6.918143481016159e-05, Min w: 0.9628331661224365\n",
      "Iteration 980, Loss: 6.624904199270532e-05, Min w: 0.9631524085998535\n",
      "Iteration 990, Loss: 8.43964735395275e-05, Min w: 0.9542837142944336\n",
      "Iteration 1000, Loss: 6.23082451056689e-05, Min w: 0.9652550220489502\n",
      "Iteration 1010, Loss: 6.797465903218836e-05, Min w: 0.9641174674034119\n",
      "Iteration 1020, Loss: 8.167057967511937e-05, Min w: 0.9562439918518066\n",
      "Iteration 1030, Loss: 5.925008008489385e-05, Min w: 0.9681485891342163\n",
      "Iteration 1040, Loss: 6.228415441000834e-05, Min w: 0.9627313613891602\n",
      "Iteration 1050, Loss: 5.848385990248062e-05, Min w: 0.9677668809890747\n",
      "Iteration 1060, Loss: 6.0651560488622636e-05, Min w: 0.9639861583709717\n",
      "Iteration 1070, Loss: 6.132758426247165e-05, Min w: 0.9634944200515747\n",
      "Iteration 1080, Loss: 6.743904668837786e-05, Min w: 0.9643751382827759\n",
      "Iteration 1090, Loss: 5.948850230197422e-05, Min w: 0.9668689370155334\n",
      "Iteration 1100, Loss: 6.281577225308865e-05, Min w: 0.9645776152610779\n",
      "Iteration 1110, Loss: 6.225266406545416e-05, Min w: 0.9639872312545776\n",
      "Iteration 1120, Loss: 5.8933786931447685e-05, Min w: 0.9642333984375\n",
      "Iteration 1130, Loss: 5.925574077991769e-05, Min w: 0.9655697345733643\n",
      "Iteration 1140, Loss: 6.417036638595164e-05, Min w: 0.9648586511611938\n",
      "Iteration 1150, Loss: 6.833259976701811e-05, Min w: 0.9631840586662292\n",
      "Iteration 1160, Loss: 6.913678225828335e-05, Min w: 0.9600698947906494\n",
      "Iteration 1170, Loss: 6.159273470984772e-05, Min w: 0.9664289951324463\n",
      "Iteration 1180, Loss: 6.610429409192875e-05, Min w: 0.9635698199272156\n",
      "Iteration 1190, Loss: 6.051025411579758e-05, Min w: 0.9660400152206421\n",
      "Iteration 1200, Loss: 6.398804544005543e-05, Min w: 0.9662989974021912\n",
      "Iteration 1210, Loss: 6.130799738457426e-05, Min w: 0.9637421369552612\n",
      "Iteration 1220, Loss: 5.890220563742332e-05, Min w: 0.9650753140449524\n",
      "Iteration 1230, Loss: 5.9089725255034864e-05, Min w: 0.9655737280845642\n",
      "Iteration 1240, Loss: 6.662718806182966e-05, Min w: 0.9627473950386047\n",
      "Iteration 0, Loss: 6.13621887168847e-05, Min w: 0.9660014510154724\n",
      "Iteration 10, Loss: 6.761255644960329e-05, Min w: 0.9637049436569214\n",
      "Iteration 20, Loss: 6.38194105704315e-05, Min w: 0.9643072485923767\n",
      "Iteration 30, Loss: 7.238086254801601e-05, Min w: 0.9604858756065369\n",
      "Iteration 40, Loss: 5.810894799651578e-05, Min w: 0.96563720703125\n",
      "Iteration 50, Loss: 7.323826139327139e-05, Min w: 0.9583475589752197\n",
      "Iteration 60, Loss: 6.360189581755549e-05, Min w: 0.9634471535682678\n",
      "Iteration 70, Loss: 5.980784408166073e-05, Min w: 0.9671869874000549\n",
      "Iteration 80, Loss: 6.382413994288072e-05, Min w: 0.9664915204048157\n",
      "Iteration 90, Loss: 5.566028266912326e-05, Min w: 0.9653444290161133\n",
      "Iteration 100, Loss: 7.901791104814038e-05, Min w: 0.9516674280166626\n",
      "Iteration 110, Loss: 5.409494769992307e-05, Min w: 0.9707545042037964\n",
      "Iteration 120, Loss: 5.997457992634736e-05, Min w: 0.9660024046897888\n",
      "Iteration 130, Loss: 5.853831680724397e-05, Min w: 0.9657518863677979\n",
      "Iteration 140, Loss: 4.947197885485366e-05, Min w: 0.971012532711029\n",
      "Iteration 150, Loss: 6.394268712028861e-05, Min w: 0.966786801815033\n",
      "Iteration 160, Loss: 5.668225639965385e-05, Min w: 0.9699923396110535\n",
      "Iteration 170, Loss: 5.411637539509684e-05, Min w: 0.9674499034881592\n",
      "Iteration 180, Loss: 5.5497574066976085e-05, Min w: 0.9661450386047363\n",
      "Iteration 190, Loss: 5.969039193587378e-05, Min w: 0.9636089205741882\n",
      "Iteration 200, Loss: 5.298698306432925e-05, Min w: 0.9707667827606201\n",
      "Iteration 210, Loss: 5.510676055564545e-05, Min w: 0.9690679311752319\n",
      "Iteration 220, Loss: 6.316465442068875e-05, Min w: 0.9642308354377747\n",
      "Iteration 230, Loss: 5.560394492931664e-05, Min w: 0.9685130715370178\n",
      "Iteration 240, Loss: 5.345067256712355e-05, Min w: 0.9669400453567505\n",
      "Iteration 250, Loss: 5.905169018660672e-05, Min w: 0.9677782654762268\n",
      "Iteration 260, Loss: 5.9783800679724663e-05, Min w: 0.9674389362335205\n",
      "Iteration 270, Loss: 5.4343407100532204e-05, Min w: 0.9683375954627991\n",
      "Iteration 280, Loss: 6.282868707785383e-05, Min w: 0.965892493724823\n",
      "Iteration 290, Loss: 6.649550778092816e-05, Min w: 0.9621976017951965\n",
      "Iteration 300, Loss: 6.065345223760232e-05, Min w: 0.9641543626785278\n",
      "Iteration 310, Loss: 5.9536196204135194e-05, Min w: 0.9683773517608643\n",
      "Iteration 320, Loss: 6.173904694151133e-05, Min w: 0.9676379561424255\n",
      "Iteration 330, Loss: 5.146896364749409e-05, Min w: 0.9703139662742615\n",
      "Iteration 340, Loss: 5.328667975845747e-05, Min w: 0.9709234833717346\n",
      "Iteration 350, Loss: 5.681212860508822e-05, Min w: 0.9669674038887024\n",
      "Iteration 360, Loss: 5.131520811119117e-05, Min w: 0.9698657393455505\n",
      "Iteration 370, Loss: 5.489982868311927e-05, Min w: 0.9687461256980896\n",
      "Iteration 380, Loss: 5.7239754823967814e-05, Min w: 0.9700281023979187\n",
      "Iteration 390, Loss: 5.2369621698744595e-05, Min w: 0.9689061641693115\n",
      "Iteration 400, Loss: 5.220266757532954e-05, Min w: 0.9710087776184082\n",
      "Iteration 410, Loss: 5.343529483070597e-05, Min w: 0.9689178466796875\n",
      "Iteration 420, Loss: 5.240174868959002e-05, Min w: 0.9698066711425781\n",
      "Iteration 430, Loss: 4.8578927817288786e-05, Min w: 0.9718133211135864\n",
      "Iteration 440, Loss: 5.679515015799552e-05, Min w: 0.970914363861084\n",
      "Iteration 450, Loss: 5.5474858527304605e-05, Min w: 0.9697862267494202\n",
      "Iteration 460, Loss: 5.21777146786917e-05, Min w: 0.9720160365104675\n",
      "Iteration 470, Loss: 5.067687379778363e-05, Min w: 0.9710474014282227\n",
      "Iteration 480, Loss: 6.593261059606448e-05, Min w: 0.9634914994239807\n",
      "Iteration 490, Loss: 4.877278843196109e-05, Min w: 0.9732177257537842\n",
      "Iteration 500, Loss: 5.4603642638539895e-05, Min w: 0.9714742302894592\n",
      "Iteration 510, Loss: 4.807527147931978e-05, Min w: 0.9722577333450317\n",
      "Iteration 520, Loss: 5.120092100696638e-05, Min w: 0.9709020853042603\n",
      "Iteration 530, Loss: 5.4526350140804425e-05, Min w: 0.9691170454025269\n",
      "Iteration 540, Loss: 5.199103179620579e-05, Min w: 0.9697846174240112\n",
      "Iteration 550, Loss: 5.111573409521952e-05, Min w: 0.9711478352546692\n",
      "Iteration 560, Loss: 5.366876575862989e-05, Min w: 0.9706556797027588\n",
      "Iteration 570, Loss: 6.523159390781075e-05, Min w: 0.9662033319473267\n",
      "Iteration 580, Loss: 6.295622006291524e-05, Min w: 0.9653955101966858\n",
      "Iteration 590, Loss: 4.890556738246232e-05, Min w: 0.9714989066123962\n",
      "Iteration 600, Loss: 5.055715155322105e-05, Min w: 0.9723432660102844\n",
      "Iteration 610, Loss: 5.252755363471806e-05, Min w: 0.9696021676063538\n",
      "Iteration 620, Loss: 4.712480949820019e-05, Min w: 0.9732440114021301\n",
      "Iteration 630, Loss: 6.583514914382249e-05, Min w: 0.9638411402702332\n",
      "Iteration 640, Loss: 4.7129484300967306e-05, Min w: 0.9725223779678345\n",
      "Iteration 650, Loss: 4.96516477141995e-05, Min w: 0.9710071682929993\n",
      "Iteration 660, Loss: 4.3977492168778554e-05, Min w: 0.9735257029533386\n",
      "Iteration 670, Loss: 4.903757508145645e-05, Min w: 0.971068263053894\n",
      "Iteration 680, Loss: 4.760477531817742e-05, Min w: 0.9730979800224304\n",
      "Iteration 690, Loss: 5.0680140702752396e-05, Min w: 0.9714736938476562\n",
      "Iteration 700, Loss: 5.63465291634202e-05, Min w: 0.9677982330322266\n",
      "Iteration 710, Loss: 5.150229117134586e-05, Min w: 0.973273515701294\n",
      "Iteration 720, Loss: 5.7389599533053115e-05, Min w: 0.9686598181724548\n",
      "Iteration 730, Loss: 6.248752470128238e-05, Min w: 0.9640334248542786\n",
      "Iteration 740, Loss: 4.885559610556811e-05, Min w: 0.9725905060768127\n",
      "Iteration 750, Loss: 4.8169396904995665e-05, Min w: 0.9723660945892334\n",
      "Iteration 760, Loss: 4.7386209189426154e-05, Min w: 0.973783552646637\n",
      "Iteration 770, Loss: 5.0325223128311336e-05, Min w: 0.9727929830551147\n",
      "Iteration 780, Loss: 4.563221227726899e-05, Min w: 0.9741066098213196\n",
      "Iteration 790, Loss: 4.502982119447552e-05, Min w: 0.9740487337112427\n",
      "Iteration 800, Loss: 5.461659748107195e-05, Min w: 0.9693551659584045\n",
      "Iteration 810, Loss: 4.8391644668299705e-05, Min w: 0.970751166343689\n",
      "Iteration 820, Loss: 5.154931568540633e-05, Min w: 0.9717176556587219\n",
      "Iteration 830, Loss: 4.6670829760842025e-05, Min w: 0.9715784788131714\n",
      "Iteration 840, Loss: 4.4810076360590756e-05, Min w: 0.9750041365623474\n",
      "Iteration 850, Loss: 4.590767275658436e-05, Min w: 0.9734382033348083\n",
      "Iteration 860, Loss: 4.7302110033342615e-05, Min w: 0.9720197916030884\n",
      "Iteration 870, Loss: 5.0316393753746524e-05, Min w: 0.9732950329780579\n",
      "Iteration 880, Loss: 5.7547615142539144e-05, Min w: 0.9692586064338684\n",
      "Iteration 890, Loss: 4.718171840067953e-05, Min w: 0.973517656326294\n",
      "Iteration 900, Loss: 4.72479805466719e-05, Min w: 0.9731118083000183\n",
      "Iteration 910, Loss: 4.736083428724669e-05, Min w: 0.9721834063529968\n",
      "Iteration 920, Loss: 5.86900205234997e-05, Min w: 0.9666560888290405\n",
      "Iteration 930, Loss: 4.9132453568745404e-05, Min w: 0.9739785194396973\n",
      "Iteration 940, Loss: 4.593494668370113e-05, Min w: 0.9735373854637146\n",
      "Iteration 950, Loss: 4.52031017630361e-05, Min w: 0.9737796783447266\n",
      "Iteration 960, Loss: 4.396377698867582e-05, Min w: 0.9753059148788452\n",
      "Iteration 970, Loss: 6.0649683291558176e-05, Min w: 0.9662679433822632\n",
      "Iteration 980, Loss: 5.882062396267429e-05, Min w: 0.9694444537162781\n",
      "Iteration 990, Loss: 4.1654744563857093e-05, Min w: 0.9748862981796265\n",
      "Iteration 1000, Loss: 4.5559954742202535e-05, Min w: 0.9762293100357056\n",
      "Iteration 1010, Loss: 4.520436777966097e-05, Min w: 0.9736760854721069\n",
      "Iteration 1020, Loss: 9.784464054973796e-05, Min w: 0.9370059370994568\n",
      "Iteration 1030, Loss: 6.566851516254246e-05, Min w: 0.9624041318893433\n",
      "Iteration 1040, Loss: 4.5932785724289715e-05, Min w: 0.9726213812828064\n",
      "Iteration 1050, Loss: 4.55090994364582e-05, Min w: 0.9753684401512146\n",
      "Iteration 1060, Loss: 5.1301438361406326e-05, Min w: 0.9721522927284241\n",
      "Iteration 1070, Loss: 4.4267137127462775e-05, Min w: 0.9772703051567078\n",
      "Iteration 1080, Loss: 5.157072519068606e-05, Min w: 0.9735901951789856\n",
      "Iteration 1090, Loss: 6.406438478734344e-05, Min w: 0.964445173740387\n",
      "Iteration 1100, Loss: 4.4542935938807204e-05, Min w: 0.9743801951408386\n",
      "Iteration 1110, Loss: 4.4411153794499114e-05, Min w: 0.9724693298339844\n",
      "Iteration 1120, Loss: 4.096711927559227e-05, Min w: 0.9774374961853027\n",
      "Iteration 1130, Loss: 4.355999772087671e-05, Min w: 0.9759896993637085\n",
      "Iteration 1140, Loss: 4.344568515080027e-05, Min w: 0.9769960045814514\n",
      "Iteration 1150, Loss: 4.40320472989697e-05, Min w: 0.9747849702835083\n",
      "Iteration 1160, Loss: 4.534327672445215e-05, Min w: 0.9738739728927612\n",
      "Iteration 1170, Loss: 4.310002987040207e-05, Min w: 0.9751188158988953\n",
      "Iteration 1180, Loss: 4.690808418672532e-05, Min w: 0.9713032841682434\n",
      "Iteration 1190, Loss: 4.6657947677886114e-05, Min w: 0.9754918217658997\n",
      "Iteration 1200, Loss: 4.48573955509346e-05, Min w: 0.974653422832489\n",
      "Iteration 1210, Loss: 4.855592123931274e-05, Min w: 0.9740900993347168\n",
      "Iteration 1220, Loss: 4.605486537911929e-05, Min w: 0.9723929166793823\n",
      "Iteration 1230, Loss: 4.7179448301903903e-05, Min w: 0.9756892919540405\n",
      "Iteration 1240, Loss: 4.228362740832381e-05, Min w: 0.9750936627388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  92%|█████████▏| 22/24 [37:37<03:56, 118.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013375291880962533, 'L2_avg': 0.015588054598986307, 'End_point_L1_avg': 0.010498257404548315, 'End_point_L2_avg': 0.010536608210774887}\n",
      "Iteration 0, Loss: 0.0012721898965537548, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010025150841102004, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0008662157342769206, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008502978598698974, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008645851048640907, Min w: 5.2400201048062245e-17\n",
      "Iteration 50, Loss: 0.0008956205565482378, Min w: 5.94270581311032e-32\n",
      "Iteration 60, Loss: 0.000849246047437191, Min w: 3.180876840002365e-32\n",
      "Iteration 70, Loss: 0.0008249204838648438, Min w: 2.6733691842695995e-40\n",
      "Iteration 80, Loss: 0.0007015261217020452, Min w: 1.401298464324817e-45\n",
      "Iteration 90, Loss: 0.0006168813561089337, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005797037156298757, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005651770625263453, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005575565155595541, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005417669308371842, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005295072332955897, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005209469818510115, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005100508569739759, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0004978426150046289, Min w: 0.0\n",
      "Iteration 180, Loss: 0.000492371036671102, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0004870207922067493, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0004762912285514176, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00047409787657670677, Min w: 0.0\n",
      "Iteration 220, Loss: 0.00046843060408718884, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00046387090696953237, Min w: 0.0\n",
      "Iteration 240, Loss: 0.00044698521378450096, Min w: 0.0\n",
      "Iteration 250, Loss: 0.00045624258928000927, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00045672565465793014, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00044624562724493444, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0004345618071965873, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0004403956118039787, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004299165739212185, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0004424793878570199, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0004498060152400285, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00042437235242687166, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00045620265882462263, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004762957105413079, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004454794980119914, Min w: 6.653332878749552e-39\n",
      "Iteration 370, Loss: 0.00044220752897672355, Min w: 1.921339874046145e-30\n",
      "Iteration 380, Loss: 0.00043352998909540474, Min w: 1.9220548192647332e-26\n",
      "Iteration 390, Loss: 0.000431329506682232, Min w: 9.672964964906217e-26\n",
      "Iteration 400, Loss: 0.0004288312920834869, Min w: 6.094136664005948e-23\n",
      "Iteration 410, Loss: 0.00043424704927019775, Min w: 6.610915908919378e-21\n",
      "Iteration 420, Loss: 0.00042533199302852154, Min w: 4.040883016343582e-19\n",
      "Iteration 430, Loss: 0.0004080897197127342, Min w: 2.038763636288023e-18\n",
      "Iteration 440, Loss: 0.0004279449349269271, Min w: 3.802364814629669e-18\n",
      "Iteration 450, Loss: 0.0003951437829528004, Min w: 8.63827757713781e-17\n",
      "Iteration 460, Loss: 0.00039934279629960656, Min w: 1.4418241150277003e-16\n",
      "Iteration 470, Loss: 0.00039611870306544006, Min w: 2.7892254969580236e-16\n",
      "Iteration 480, Loss: 0.00039769551949575543, Min w: 1.8271413350275925e-15\n",
      "Iteration 490, Loss: 0.00039130201912485063, Min w: 2.236508440908215e-16\n",
      "Iteration 500, Loss: 0.000386239611543715, Min w: 4.972313158069686e-16\n",
      "Iteration 510, Loss: 0.0003970298857893795, Min w: 2.0436079368273786e-17\n",
      "Iteration 520, Loss: 0.0003781320701818913, Min w: 1.148740484087511e-19\n",
      "Iteration 530, Loss: 0.0003843864833470434, Min w: 5.2212730785662484e-21\n",
      "Iteration 540, Loss: 0.00038938882062211633, Min w: 8.017368901312555e-25\n",
      "Iteration 550, Loss: 0.00038505991687998176, Min w: 1.6012189983578986e-28\n",
      "Iteration 560, Loss: 0.00038135453360155225, Min w: 1.7868422155967032e-34\n",
      "Iteration 570, Loss: 0.0003824584127869457, Min w: 1.8086559279040414e-41\n",
      "Iteration 580, Loss: 0.0003870597283821553, Min w: 0.0\n",
      "Iteration 590, Loss: 0.00039515458047389984, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0003962107584811747, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0003903520992025733, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0003904897312168032, Min w: 0.0\n",
      "Iteration 630, Loss: 0.00039150292286649346, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00038992377812974155, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0003930580278392881, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0003827358887065202, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00038291822420433164, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0003792795760091394, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00038214269443415105, Min w: 1.401298464324817e-45\n",
      "Iteration 700, Loss: 0.0003785630688071251, Min w: 3.730256512032663e-42\n",
      "Iteration 710, Loss: 0.0003791773342527449, Min w: 3.2327339000649227e-38\n",
      "Iteration 720, Loss: 0.0003814524970948696, Min w: 2.794780981763183e-34\n",
      "Iteration 730, Loss: 0.00037733526551164687, Min w: 1.8668760469378012e-32\n",
      "Iteration 740, Loss: 0.0003786911547649652, Min w: 8.51335725389814e-29\n",
      "Iteration 750, Loss: 0.00037607632111757994, Min w: 2.514802284183077e-25\n",
      "Iteration 760, Loss: 0.0003757255617529154, Min w: 1.337637200419983e-23\n",
      "Iteration 770, Loss: 0.0003871783264912665, Min w: 1.7411407431689935e-19\n",
      "Iteration 780, Loss: 0.0003709053562488407, Min w: 2.469645491525468e-17\n",
      "Iteration 790, Loss: 0.00037016739952377975, Min w: 7.683431629379022e-15\n",
      "Iteration 800, Loss: 0.0003727915172930807, Min w: 1.6947738785272337e-12\n",
      "Iteration 810, Loss: 0.00037200553924776614, Min w: 2.8804097995660527e-10\n",
      "Iteration 820, Loss: 0.0003700133238453418, Min w: 4.647524676215653e-08\n",
      "Iteration 830, Loss: 0.0003712786128744483, Min w: 3.603391405704315e-06\n",
      "Iteration 840, Loss: 0.0003729220770765096, Min w: 0.0001752254756866023\n",
      "Iteration 850, Loss: 0.0003814703959506005, Min w: 0.0025718961842358112\n",
      "Iteration 860, Loss: 0.0003733462071977556, Min w: 0.0270581915974617\n",
      "Iteration 870, Loss: 0.00036739761708304286, Min w: 0.03783750161528587\n",
      "Iteration 880, Loss: 0.00036459474358707666, Min w: 0.042715251445770264\n",
      "Iteration 890, Loss: 0.0003616972826421261, Min w: 0.038365330547094345\n",
      "Iteration 900, Loss: 0.0003592162684071809, Min w: 0.04442178085446358\n",
      "Iteration 910, Loss: 0.00035718997241929173, Min w: 0.04475715756416321\n",
      "Iteration 920, Loss: 0.00036067055771127343, Min w: 0.050217363983392715\n",
      "Iteration 930, Loss: 0.0003511168179102242, Min w: 0.054337192326784134\n",
      "Iteration 940, Loss: 0.0003621532814577222, Min w: 0.06124529987573624\n",
      "Iteration 950, Loss: 0.000349518028087914, Min w: 0.07461201399564743\n",
      "Iteration 960, Loss: 0.0003468292998149991, Min w: 0.08181960135698318\n",
      "Iteration 970, Loss: 0.0003515140269882977, Min w: 0.07501470297574997\n",
      "Iteration 980, Loss: 0.0003388301993254572, Min w: 0.08873701840639114\n",
      "Iteration 990, Loss: 0.0003407282929401845, Min w: 0.0877259373664856\n",
      "Iteration 1000, Loss: 0.0003525192732922733, Min w: 0.09303440153598785\n",
      "Iteration 1010, Loss: 0.0003334705834276974, Min w: 0.1094641238451004\n",
      "Iteration 1020, Loss: 0.000325376313412562, Min w: 0.10889676213264465\n",
      "Iteration 1030, Loss: 0.0003373752406332642, Min w: 0.11776924878358841\n",
      "Iteration 1040, Loss: 0.00033134580007754266, Min w: 0.11686195433139801\n",
      "Iteration 1050, Loss: 0.00032570335315540433, Min w: 0.11643710732460022\n",
      "Iteration 1060, Loss: 0.0003216669720131904, Min w: 0.12963896989822388\n",
      "Iteration 1070, Loss: 0.0003224879619665444, Min w: 0.13402369618415833\n",
      "Iteration 1080, Loss: 0.0003185394743923098, Min w: 0.13808973133563995\n",
      "Iteration 1090, Loss: 0.00031122821383178234, Min w: 0.1484866440296173\n",
      "Iteration 1100, Loss: 0.00031553697772324085, Min w: 0.14899156987667084\n",
      "Iteration 1110, Loss: 0.00030822260305285454, Min w: 0.15973877906799316\n",
      "Iteration 1120, Loss: 0.00030406026053242385, Min w: 0.16786395013332367\n",
      "Iteration 1130, Loss: 0.0003037170390598476, Min w: 0.16442808508872986\n",
      "Iteration 1140, Loss: 0.0003185211098752916, Min w: 0.16433538496494293\n",
      "Iteration 1150, Loss: 0.0003116553125437349, Min w: 0.17617760598659515\n",
      "Iteration 1160, Loss: 0.0003096441214438528, Min w: 0.1756616234779358\n",
      "Iteration 1170, Loss: 0.00029971651383675635, Min w: 0.18591740727424622\n",
      "Iteration 1180, Loss: 0.0002977598342113197, Min w: 0.18492582440376282\n",
      "Iteration 1190, Loss: 0.00030118724680505693, Min w: 0.19784626364707947\n",
      "Iteration 1200, Loss: 0.0002949373156297952, Min w: 0.19559454917907715\n",
      "Iteration 1210, Loss: 0.000300180894555524, Min w: 0.19904200732707977\n",
      "Iteration 1220, Loss: 0.00028913875576108694, Min w: 0.2080078125\n",
      "Iteration 1230, Loss: 0.00029038835782557726, Min w: 0.2052718997001648\n",
      "Iteration 1240, Loss: 0.0002892716438509524, Min w: 0.20998696982860565\n",
      "Iteration 0, Loss: 0.0002867748844437301, Min w: 0.2199428826570511\n",
      "Iteration 10, Loss: 0.0002853135229088366, Min w: 0.21731288731098175\n",
      "Iteration 20, Loss: 0.00029350040131248534, Min w: 0.22526578605175018\n",
      "Iteration 30, Loss: 0.00029742479091510177, Min w: 0.21768862009048462\n",
      "Iteration 40, Loss: 0.0002769721031654626, Min w: 0.23798781633377075\n",
      "Iteration 50, Loss: 0.00028144248062744737, Min w: 0.23642630875110626\n",
      "Iteration 60, Loss: 0.00027698659687303007, Min w: 0.24654148519039154\n",
      "Iteration 70, Loss: 0.00028074474539607763, Min w: 0.2432941198348999\n",
      "Iteration 80, Loss: 0.000274058838840574, Min w: 0.25103238224983215\n",
      "Iteration 90, Loss: 0.00027118794969283044, Min w: 0.25841832160949707\n",
      "Iteration 100, Loss: 0.0002704740909393877, Min w: 0.2611899673938751\n",
      "Iteration 110, Loss: 0.0002738524053711444, Min w: 0.2624501883983612\n",
      "Iteration 120, Loss: 0.00028327773907221854, Min w: 0.2558499574661255\n",
      "Iteration 130, Loss: 0.0002642599865794182, Min w: 0.2774474322795868\n",
      "Iteration 140, Loss: 0.00027598656015470624, Min w: 0.27575719356536865\n",
      "Iteration 150, Loss: 0.0002666802902240306, Min w: 0.29263898730278015\n",
      "Iteration 160, Loss: 0.0002603192115202546, Min w: 0.2838059961795807\n",
      "Iteration 170, Loss: 0.00025764558813534677, Min w: 0.29224729537963867\n",
      "Iteration 180, Loss: 0.00025538861518725753, Min w: 0.2971864938735962\n",
      "Iteration 190, Loss: 0.0002612106327433139, Min w: 0.30042847990989685\n",
      "Iteration 200, Loss: 0.0002546776086091995, Min w: 0.3081876039505005\n",
      "Iteration 210, Loss: 0.0002497034438420087, Min w: 0.32107028365135193\n",
      "Iteration 220, Loss: 0.0002543918672017753, Min w: 0.30178868770599365\n",
      "Iteration 230, Loss: 0.0002541948633734137, Min w: 0.3068099021911621\n",
      "Iteration 240, Loss: 0.00024618743918836117, Min w: 0.31574124097824097\n",
      "Iteration 250, Loss: 0.0002515239466447383, Min w: 0.3143477141857147\n",
      "Iteration 260, Loss: 0.0002536655229050666, Min w: 0.309416264295578\n",
      "Iteration 270, Loss: 0.0002429848536849022, Min w: 0.3332521617412567\n",
      "Iteration 280, Loss: 0.00024186137306969613, Min w: 0.3384944796562195\n",
      "Iteration 290, Loss: 0.00024420651607215405, Min w: 0.325048565864563\n",
      "Iteration 300, Loss: 0.00024595335707999766, Min w: 0.33480122685432434\n",
      "Iteration 310, Loss: 0.00023963583225850016, Min w: 0.3427957594394684\n",
      "Iteration 320, Loss: 0.00023905336274765432, Min w: 0.34917157888412476\n",
      "Iteration 330, Loss: 0.00023560499539598823, Min w: 0.3511696755886078\n",
      "Iteration 340, Loss: 0.00023628959024790674, Min w: 0.3526926636695862\n",
      "Iteration 350, Loss: 0.0002313237200723961, Min w: 0.36367350816726685\n",
      "Iteration 360, Loss: 0.00024345652491319925, Min w: 0.3560379147529602\n",
      "Iteration 370, Loss: 0.00022980646463111043, Min w: 0.36806973814964294\n",
      "Iteration 380, Loss: 0.00023622970911674201, Min w: 0.36812666058540344\n",
      "Iteration 390, Loss: 0.00022731666103936732, Min w: 0.37903305888175964\n",
      "Iteration 400, Loss: 0.00022405586787499487, Min w: 0.38876816630363464\n",
      "Iteration 410, Loss: 0.00023866872652433813, Min w: 0.37401384115219116\n",
      "Iteration 420, Loss: 0.00022408136283047497, Min w: 0.394336074590683\n",
      "Iteration 430, Loss: 0.00022863697085995227, Min w: 0.39297205209732056\n",
      "Iteration 440, Loss: 0.00022949329286348075, Min w: 0.39167144894599915\n",
      "Iteration 450, Loss: 0.0002205669297836721, Min w: 0.40045127272605896\n",
      "Iteration 460, Loss: 0.00021805673895869404, Min w: 0.4018748998641968\n",
      "Iteration 470, Loss: 0.00021479578572325408, Min w: 0.4079674482345581\n",
      "Iteration 480, Loss: 0.0002140810975106433, Min w: 0.417255699634552\n",
      "Iteration 490, Loss: 0.00021822536655236036, Min w: 0.40335777401924133\n",
      "Iteration 500, Loss: 0.00022789876675233245, Min w: 0.4083535671234131\n",
      "Iteration 510, Loss: 0.00020994678197894245, Min w: 0.43022117018699646\n",
      "Iteration 520, Loss: 0.00021055432443972677, Min w: 0.42536717653274536\n",
      "Iteration 530, Loss: 0.00020804587984457612, Min w: 0.42914748191833496\n",
      "Iteration 540, Loss: 0.00020803870575036854, Min w: 0.44341614842414856\n",
      "Iteration 550, Loss: 0.00021091257804073393, Min w: 0.4332994520664215\n",
      "Iteration 560, Loss: 0.00020995695376768708, Min w: 0.43194249272346497\n",
      "Iteration 570, Loss: 0.00020271402900107205, Min w: 0.4472039043903351\n",
      "Iteration 580, Loss: 0.00020116678206250072, Min w: 0.4541022777557373\n",
      "Iteration 590, Loss: 0.00020075018983334303, Min w: 0.4495103657245636\n",
      "Iteration 600, Loss: 0.00020729460811708122, Min w: 0.45717859268188477\n",
      "Iteration 610, Loss: 0.00019649950263556093, Min w: 0.4669153690338135\n",
      "Iteration 620, Loss: 0.00020402688824106008, Min w: 0.46305668354034424\n",
      "Iteration 630, Loss: 0.00020194801618345082, Min w: 0.47243770956993103\n",
      "Iteration 640, Loss: 0.0001943879178725183, Min w: 0.46565836668014526\n",
      "Iteration 650, Loss: 0.0002022145054070279, Min w: 0.4741826355457306\n",
      "Iteration 660, Loss: 0.0001980573870241642, Min w: 0.4772215783596039\n",
      "Iteration 670, Loss: 0.00018896149413194507, Min w: 0.49243661761283875\n",
      "Iteration 680, Loss: 0.00019543839152902365, Min w: 0.4848051965236664\n",
      "Iteration 690, Loss: 0.00018276742775924504, Min w: 0.5039368271827698\n",
      "Iteration 700, Loss: 0.0002004913694690913, Min w: 0.48192593455314636\n",
      "Iteration 710, Loss: 0.00018581091717351228, Min w: 0.49706345796585083\n",
      "Iteration 720, Loss: 0.0001915841712616384, Min w: 0.5004761815071106\n",
      "Iteration 730, Loss: 0.0001962351379916072, Min w: 0.48970919847488403\n",
      "Iteration 740, Loss: 0.0001796943979570642, Min w: 0.5136910080909729\n",
      "Iteration 750, Loss: 0.00018298611394129694, Min w: 0.5117631554603577\n",
      "Iteration 760, Loss: 0.0001809743989724666, Min w: 0.5104071497917175\n",
      "Iteration 770, Loss: 0.0001775753335095942, Min w: 0.5256187319755554\n",
      "Iteration 780, Loss: 0.00018462610023561865, Min w: 0.518463134765625\n",
      "Iteration 790, Loss: 0.0001753466494847089, Min w: 0.522045910358429\n",
      "Iteration 800, Loss: 0.0001740070292726159, Min w: 0.5300911068916321\n",
      "Iteration 810, Loss: 0.00018145983631256968, Min w: 0.5316677093505859\n",
      "Iteration 820, Loss: 0.0001716281840344891, Min w: 0.5348162651062012\n",
      "Iteration 830, Loss: 0.00016780372243374586, Min w: 0.54803866147995\n",
      "Iteration 840, Loss: 0.00017197114357259125, Min w: 0.5379689335823059\n",
      "Iteration 850, Loss: 0.0001764577318681404, Min w: 0.545799732208252\n",
      "Iteration 860, Loss: 0.00016796609270386398, Min w: 0.5462973117828369\n",
      "Iteration 870, Loss: 0.0001722541928756982, Min w: 0.5453526973724365\n",
      "Iteration 880, Loss: 0.0001651805214351043, Min w: 0.5632819533348083\n",
      "Iteration 890, Loss: 0.00016391284589190036, Min w: 0.5673182606697083\n",
      "Iteration 900, Loss: 0.00016539919306524098, Min w: 0.5618165731430054\n",
      "Iteration 910, Loss: 0.00016309820057358593, Min w: 0.5830238461494446\n",
      "Iteration 920, Loss: 0.00016161844541784376, Min w: 0.5699493885040283\n",
      "Iteration 930, Loss: 0.00016765912005212158, Min w: 0.5731271505355835\n",
      "Iteration 940, Loss: 0.00016225034778472036, Min w: 0.5710868239402771\n",
      "Iteration 950, Loss: 0.00015663683007005602, Min w: 0.5899319648742676\n",
      "Iteration 960, Loss: 0.0001606774312676862, Min w: 0.5831104516983032\n",
      "Iteration 970, Loss: 0.00015635546878911555, Min w: 0.5859054923057556\n",
      "Iteration 980, Loss: 0.00016874060383997858, Min w: 0.5790356993675232\n",
      "Iteration 990, Loss: 0.00015452125808224082, Min w: 0.5931055545806885\n",
      "Iteration 1000, Loss: 0.00015215099847409874, Min w: 0.5921059250831604\n",
      "Iteration 1010, Loss: 0.0001599476527189836, Min w: 0.5806741714477539\n",
      "Iteration 1020, Loss: 0.0001504443644080311, Min w: 0.6022996306419373\n",
      "Iteration 1030, Loss: 0.00016562001837883145, Min w: 0.5936540961265564\n",
      "Iteration 1040, Loss: 0.00015799586253706366, Min w: 0.6003032922744751\n",
      "Iteration 1050, Loss: 0.00015261601947713643, Min w: 0.6054261326789856\n",
      "Iteration 1060, Loss: 0.00014799501514062285, Min w: 0.6043029427528381\n",
      "Iteration 1070, Loss: 0.00014406029367819428, Min w: 0.6153145432472229\n",
      "Iteration 1080, Loss: 0.00013988719729240984, Min w: 0.6238121390342712\n",
      "Iteration 1090, Loss: 0.00014830805594101548, Min w: 0.609605073928833\n",
      "Iteration 1100, Loss: 0.0001603323471499607, Min w: 0.6119874119758606\n",
      "Iteration 1110, Loss: 0.0001383562048431486, Min w: 0.627219557762146\n",
      "Iteration 1120, Loss: 0.00013938589836470783, Min w: 0.6318939328193665\n",
      "Iteration 1130, Loss: 0.00014128562179394066, Min w: 0.6272606253623962\n",
      "Iteration 1140, Loss: 0.00013808476796839386, Min w: 0.6305506825447083\n",
      "Iteration 1150, Loss: 0.00015838444232940674, Min w: 0.6222440004348755\n",
      "Iteration 1160, Loss: 0.00013421337644103914, Min w: 0.6493269801139832\n",
      "Iteration 1170, Loss: 0.00013628473971039057, Min w: 0.6387826800346375\n",
      "Iteration 1180, Loss: 0.00013547114212997258, Min w: 0.6370086669921875\n",
      "Iteration 1190, Loss: 0.00013246001617517322, Min w: 0.6501755118370056\n",
      "Iteration 1200, Loss: 0.00013796317216474563, Min w: 0.6380623579025269\n",
      "Iteration 1210, Loss: 0.000132754459627904, Min w: 0.6456362009048462\n",
      "Iteration 1220, Loss: 0.00013479868357535452, Min w: 0.6469840407371521\n",
      "Iteration 1230, Loss: 0.00013499092892743647, Min w: 0.6473880410194397\n",
      "Iteration 1240, Loss: 0.00013056483294349164, Min w: 0.6508297324180603\n",
      "Iteration 0, Loss: 0.00012941809836775064, Min w: 0.6567353010177612\n",
      "Iteration 10, Loss: 0.00013685546582564712, Min w: 0.6556958556175232\n",
      "Iteration 20, Loss: 0.00012660722131840885, Min w: 0.6674058437347412\n",
      "Iteration 30, Loss: 0.0001270591892534867, Min w: 0.6633654236793518\n",
      "Iteration 40, Loss: 0.00013511540601029992, Min w: 0.6600813865661621\n",
      "Iteration 50, Loss: 0.0001280702417716384, Min w: 0.6712713837623596\n",
      "Iteration 60, Loss: 0.00012500885350164026, Min w: 0.6654444336891174\n",
      "Iteration 70, Loss: 0.0001240992860402912, Min w: 0.6737881898880005\n",
      "Iteration 80, Loss: 0.00011965006706304848, Min w: 0.6800277829170227\n",
      "Iteration 90, Loss: 0.00012271353625692427, Min w: 0.6892101764678955\n",
      "Iteration 100, Loss: 0.00012011562648694962, Min w: 0.6785733699798584\n",
      "Iteration 110, Loss: 0.00012699613580480218, Min w: 0.6750081181526184\n",
      "Iteration 120, Loss: 0.00012027237244183198, Min w: 0.6824238300323486\n",
      "Iteration 130, Loss: 0.0001249733759323135, Min w: 0.6745060682296753\n",
      "Iteration 140, Loss: 0.00011903804988833144, Min w: 0.692413866519928\n",
      "Iteration 150, Loss: 0.00012952614633832127, Min w: 0.6823977828025818\n",
      "Iteration 160, Loss: 0.00013023825886193663, Min w: 0.6821970343589783\n",
      "Iteration 170, Loss: 0.00011377767805242911, Min w: 0.6957585215568542\n",
      "Iteration 180, Loss: 0.00011505187285365537, Min w: 0.7003574967384338\n",
      "Iteration 190, Loss: 0.00011887794971698895, Min w: 0.6997467279434204\n",
      "Iteration 200, Loss: 0.00011883338447660208, Min w: 0.6939940452575684\n",
      "Iteration 210, Loss: 0.00011667117360047996, Min w: 0.6920269131660461\n",
      "Iteration 220, Loss: 0.0001151117539848201, Min w: 0.6981795430183411\n",
      "Iteration 230, Loss: 0.00011356214236002415, Min w: 0.7060073018074036\n",
      "Iteration 240, Loss: 0.00011724098294507712, Min w: 0.7005897760391235\n",
      "Iteration 250, Loss: 0.00011145171447424218, Min w: 0.7115533947944641\n",
      "Iteration 260, Loss: 0.00011108931357739493, Min w: 0.7089413404464722\n",
      "Iteration 270, Loss: 0.00011954709043493494, Min w: 0.6996429562568665\n",
      "Iteration 280, Loss: 0.00011130570783279836, Min w: 0.7116187214851379\n",
      "Iteration 290, Loss: 0.00011599718709476292, Min w: 0.7099341750144958\n",
      "Iteration 300, Loss: 0.00010995750926667824, Min w: 0.716228723526001\n",
      "Iteration 310, Loss: 0.00011319562327116728, Min w: 0.7156938314437866\n",
      "Iteration 320, Loss: 0.00010685693996492773, Min w: 0.7252927422523499\n",
      "Iteration 330, Loss: 0.00010698539699660614, Min w: 0.7214431762695312\n",
      "Iteration 340, Loss: 0.00010545328404987231, Min w: 0.7215927243232727\n",
      "Iteration 350, Loss: 0.00010738941637100652, Min w: 0.7215160727500916\n",
      "Iteration 360, Loss: 0.00011790604185080156, Min w: 0.7170671224594116\n",
      "Iteration 370, Loss: 0.00013420845789369196, Min w: 0.7049199938774109\n",
      "Iteration 380, Loss: 0.00010810909589054063, Min w: 0.7338656187057495\n",
      "Iteration 390, Loss: 0.00010246117017231882, Min w: 0.7316438555717468\n",
      "Iteration 400, Loss: 0.0001056328765116632, Min w: 0.7258722186088562\n",
      "Iteration 410, Loss: 0.00010117050260305405, Min w: 0.7369325757026672\n",
      "Iteration 420, Loss: 9.960105671780184e-05, Min w: 0.7383832335472107\n",
      "Iteration 430, Loss: 0.00010332408419344574, Min w: 0.7357437014579773\n",
      "Iteration 440, Loss: 0.00010221547563560307, Min w: 0.7382959723472595\n",
      "Iteration 450, Loss: 0.00010259702685289085, Min w: 0.7353084683418274\n",
      "Iteration 460, Loss: 0.00011970025661867112, Min w: 0.7245996594429016\n",
      "Iteration 470, Loss: 9.783264977158979e-05, Min w: 0.7448244690895081\n",
      "Iteration 480, Loss: 0.00011339156480971724, Min w: 0.7317612767219543\n",
      "Iteration 490, Loss: 0.00010223229037364945, Min w: 0.7487529516220093\n",
      "Iteration 500, Loss: 9.816201782086864e-05, Min w: 0.7425885200500488\n",
      "Iteration 510, Loss: 0.00010023464710684493, Min w: 0.740411639213562\n",
      "Iteration 520, Loss: 9.607001265976578e-05, Min w: 0.749761700630188\n",
      "Iteration 530, Loss: 0.0001016230380628258, Min w: 0.7389951944351196\n",
      "Iteration 540, Loss: 9.759212116478011e-05, Min w: 0.7534411549568176\n",
      "Iteration 550, Loss: 9.721894457470626e-05, Min w: 0.7563315033912659\n",
      "Iteration 560, Loss: 9.62920967140235e-05, Min w: 0.7546417117118835\n",
      "Iteration 570, Loss: 0.00010120693332282826, Min w: 0.7499514818191528\n",
      "Iteration 580, Loss: 9.307414438808337e-05, Min w: 0.760565459728241\n",
      "Iteration 590, Loss: 0.00010101525549544021, Min w: 0.7510982155799866\n",
      "Iteration 600, Loss: 0.00010090487921843305, Min w: 0.7470858097076416\n",
      "Iteration 610, Loss: 9.6374838904012e-05, Min w: 0.764262318611145\n",
      "Iteration 620, Loss: 0.00010422869672765955, Min w: 0.7603524327278137\n",
      "Iteration 630, Loss: 9.652969310991466e-05, Min w: 0.7597245573997498\n",
      "Iteration 640, Loss: 9.608292748453096e-05, Min w: 0.7609025239944458\n",
      "Iteration 650, Loss: 0.00010797735012602061, Min w: 0.7497661709785461\n",
      "Iteration 660, Loss: 9.386387682752684e-05, Min w: 0.7668945789337158\n",
      "Iteration 670, Loss: 9.428999328520149e-05, Min w: 0.7631606459617615\n",
      "Iteration 680, Loss: 8.96505662240088e-05, Min w: 0.7765457034111023\n",
      "Iteration 690, Loss: 8.993448864202946e-05, Min w: 0.7716188430786133\n",
      "Iteration 700, Loss: 8.856315253069624e-05, Min w: 0.7736403942108154\n",
      "Iteration 710, Loss: 9.100431634578854e-05, Min w: 0.7733853459358215\n",
      "Iteration 720, Loss: 9.5296127256006e-05, Min w: 0.7679460644721985\n",
      "Iteration 730, Loss: 8.85348636074923e-05, Min w: 0.7788040041923523\n",
      "Iteration 740, Loss: 9.292748291045427e-05, Min w: 0.7749103903770447\n",
      "Iteration 750, Loss: 9.823241998674348e-05, Min w: 0.7710480690002441\n",
      "Iteration 760, Loss: 8.730386616662145e-05, Min w: 0.7825183272361755\n",
      "Iteration 770, Loss: 9.356579539598897e-05, Min w: 0.7683221697807312\n",
      "Iteration 780, Loss: 8.843109389999881e-05, Min w: 0.7795733213424683\n",
      "Iteration 790, Loss: 9.532336116535589e-05, Min w: 0.7758309245109558\n",
      "Iteration 800, Loss: 0.00010000023758038878, Min w: 0.7677988409996033\n",
      "Iteration 810, Loss: 8.826001430861652e-05, Min w: 0.7780399322509766\n",
      "Iteration 820, Loss: 9.327276347903535e-05, Min w: 0.7771472334861755\n",
      "Iteration 830, Loss: 8.458265074295923e-05, Min w: 0.7877134680747986\n",
      "Iteration 840, Loss: 8.463185804430395e-05, Min w: 0.7914791703224182\n",
      "Iteration 850, Loss: 8.46008988446556e-05, Min w: 0.7908324599266052\n",
      "Iteration 860, Loss: 9.765909635461867e-05, Min w: 0.7822973132133484\n",
      "Iteration 870, Loss: 8.278879249701276e-05, Min w: 0.7950490713119507\n",
      "Iteration 880, Loss: 8.270284160971642e-05, Min w: 0.7890591621398926\n",
      "Iteration 890, Loss: 8.317758329212666e-05, Min w: 0.7937579154968262\n",
      "Iteration 900, Loss: 8.093133510556072e-05, Min w: 0.7968134880065918\n",
      "Iteration 910, Loss: 8.704383071744815e-05, Min w: 0.7879007458686829\n",
      "Iteration 920, Loss: 8.945725130615756e-05, Min w: 0.7816691994667053\n",
      "Iteration 930, Loss: 7.89104014984332e-05, Min w: 0.7962912917137146\n",
      "Iteration 940, Loss: 8.068638999247923e-05, Min w: 0.7979403138160706\n",
      "Iteration 950, Loss: 8.134506788337603e-05, Min w: 0.8002588152885437\n",
      "Iteration 960, Loss: 7.791965617798269e-05, Min w: 0.8081373572349548\n",
      "Iteration 970, Loss: 8.051276381593198e-05, Min w: 0.8047865629196167\n",
      "Iteration 980, Loss: 8.382118539884686e-05, Min w: 0.7968428730964661\n",
      "Iteration 990, Loss: 7.791241660015658e-05, Min w: 0.80355304479599\n",
      "Iteration 1000, Loss: 8.717454329598695e-05, Min w: 0.7971315979957581\n",
      "Iteration 1010, Loss: 8.046416041906923e-05, Min w: 0.8078702092170715\n",
      "Iteration 1020, Loss: 7.680497219553217e-05, Min w: 0.8085047602653503\n",
      "Iteration 1030, Loss: 7.609651947859675e-05, Min w: 0.8131392598152161\n",
      "Iteration 1040, Loss: 7.501702930312604e-05, Min w: 0.8115317821502686\n",
      "Iteration 1050, Loss: 7.793147960910574e-05, Min w: 0.8091318607330322\n",
      "Iteration 1060, Loss: 7.685050513828173e-05, Min w: 0.8100168704986572\n",
      "Iteration 1070, Loss: 7.620615360792726e-05, Min w: 0.8144568204879761\n",
      "Iteration 1080, Loss: 7.750299846520647e-05, Min w: 0.80742347240448\n",
      "Iteration 1090, Loss: 0.00010197374649578705, Min w: 0.7916353940963745\n",
      "Iteration 1100, Loss: 7.661362906219438e-05, Min w: 0.8127193450927734\n",
      "Iteration 1110, Loss: 7.881562487455085e-05, Min w: 0.814744770526886\n",
      "Iteration 1120, Loss: 8.620685548521578e-05, Min w: 0.8109685182571411\n",
      "Iteration 1130, Loss: 7.658454705961049e-05, Min w: 0.819979190826416\n",
      "Iteration 1140, Loss: 7.790880044922233e-05, Min w: 0.816870391368866\n",
      "Iteration 1150, Loss: 8.47005721880123e-05, Min w: 0.8116391897201538\n",
      "Iteration 1160, Loss: 7.220699626486748e-05, Min w: 0.82358717918396\n",
      "Iteration 1170, Loss: 7.672351057408378e-05, Min w: 0.8111305832862854\n",
      "Iteration 1180, Loss: 7.396761793643236e-05, Min w: 0.8202142119407654\n",
      "Iteration 1190, Loss: 8.454707858618349e-05, Min w: 0.810739278793335\n",
      "Iteration 1200, Loss: 7.845310756238177e-05, Min w: 0.822671115398407\n",
      "Iteration 1210, Loss: 7.206755981314927e-05, Min w: 0.8224567174911499\n",
      "Iteration 1220, Loss: 7.105075201252475e-05, Min w: 0.8243383169174194\n",
      "Iteration 1230, Loss: 8.490301115671173e-05, Min w: 0.8112886548042297\n",
      "Iteration 1240, Loss: 7.812293915776536e-05, Min w: 0.820264995098114\n",
      "Iteration 0, Loss: 7.279969577211887e-05, Min w: 0.8292412161827087\n",
      "Iteration 10, Loss: 7.296518742805347e-05, Min w: 0.8277648687362671\n",
      "Iteration 20, Loss: 7.626051228726283e-05, Min w: 0.8294646739959717\n",
      "Iteration 30, Loss: 7.039264164632186e-05, Min w: 0.831129252910614\n",
      "Iteration 40, Loss: 7.416433800244704e-05, Min w: 0.8250371813774109\n",
      "Iteration 50, Loss: 6.938642036402598e-05, Min w: 0.8311101794242859\n",
      "Iteration 60, Loss: 7.01878234394826e-05, Min w: 0.8308162689208984\n",
      "Iteration 70, Loss: 7.657513197045773e-05, Min w: 0.8301153779029846\n",
      "Iteration 80, Loss: 9.470035729464144e-05, Min w: 0.7979739308357239\n",
      "Iteration 90, Loss: 7.245880988193676e-05, Min w: 0.8280449509620667\n",
      "Iteration 100, Loss: 7.284119783435017e-05, Min w: 0.8286481499671936\n",
      "Iteration 110, Loss: 6.991977716097608e-05, Min w: 0.8337381482124329\n",
      "Iteration 120, Loss: 7.262997678481042e-05, Min w: 0.8344857692718506\n",
      "Iteration 130, Loss: 7.59949762141332e-05, Min w: 0.8339301943778992\n",
      "Iteration 140, Loss: 6.850268255220726e-05, Min w: 0.8382719159126282\n",
      "Iteration 150, Loss: 6.945047789486125e-05, Min w: 0.8350135087966919\n",
      "Iteration 160, Loss: 7.123146497178823e-05, Min w: 0.8311164379119873\n",
      "Iteration 170, Loss: 7.234590884763747e-05, Min w: 0.8360721468925476\n",
      "Iteration 180, Loss: 6.723539991071448e-05, Min w: 0.8416339755058289\n",
      "Iteration 190, Loss: 6.469401705544442e-05, Min w: 0.8455304503440857\n",
      "Iteration 200, Loss: 6.597195897484198e-05, Min w: 0.8437772393226624\n",
      "Iteration 210, Loss: 6.465662590926513e-05, Min w: 0.8452984690666199\n",
      "Iteration 220, Loss: 6.759043753845617e-05, Min w: 0.8456702828407288\n",
      "Iteration 230, Loss: 6.428475899156183e-05, Min w: 0.8460078835487366\n",
      "Iteration 240, Loss: 6.492969987448305e-05, Min w: 0.8451151847839355\n",
      "Iteration 250, Loss: 7.156693754950538e-05, Min w: 0.8360000848770142\n",
      "Iteration 260, Loss: 6.297785876085982e-05, Min w: 0.8496417999267578\n",
      "Iteration 270, Loss: 6.737629882991314e-05, Min w: 0.8415936231613159\n",
      "Iteration 280, Loss: 7.142793037928641e-05, Min w: 0.8441069722175598\n",
      "Iteration 290, Loss: 6.572131678694859e-05, Min w: 0.8497361540794373\n",
      "Iteration 300, Loss: 6.954614218557253e-05, Min w: 0.8496053218841553\n",
      "Iteration 310, Loss: 7.348810322582722e-05, Min w: 0.8429927229881287\n",
      "Iteration 320, Loss: 6.26582550466992e-05, Min w: 0.8543151617050171\n",
      "Iteration 330, Loss: 6.0680395108647645e-05, Min w: 0.8536580801010132\n",
      "Iteration 340, Loss: 7.47750309528783e-05, Min w: 0.8470805287361145\n",
      "Iteration 350, Loss: 6.350528565235436e-05, Min w: 0.8529981970787048\n",
      "Iteration 360, Loss: 6.547686643898487e-05, Min w: 0.8548735976219177\n",
      "Iteration 370, Loss: 6.740185926901177e-05, Min w: 0.8507643342018127\n",
      "Iteration 380, Loss: 6.100123573560268e-05, Min w: 0.8585680723190308\n",
      "Iteration 390, Loss: 6.192356522660702e-05, Min w: 0.855649471282959\n",
      "Iteration 400, Loss: 6.0547234170371667e-05, Min w: 0.8584610223770142\n",
      "Iteration 410, Loss: 6.151395791675895e-05, Min w: 0.8532703518867493\n",
      "Iteration 420, Loss: 6.4598694734741e-05, Min w: 0.8524253964424133\n",
      "Iteration 430, Loss: 6.353265780489892e-05, Min w: 0.8591340184211731\n",
      "Iteration 440, Loss: 5.878007141291164e-05, Min w: 0.8620282411575317\n",
      "Iteration 450, Loss: 6.266436685109511e-05, Min w: 0.8538955450057983\n",
      "Iteration 460, Loss: 5.8956215070793405e-05, Min w: 0.8648364543914795\n",
      "Iteration 470, Loss: 5.9685691667255014e-05, Min w: 0.8633468747138977\n",
      "Iteration 480, Loss: 8.56916667544283e-05, Min w: 0.805837869644165\n",
      "Iteration 490, Loss: 7.879505574237555e-05, Min w: 0.8347132205963135\n",
      "Iteration 500, Loss: 5.956242239335552e-05, Min w: 0.8627333641052246\n",
      "Iteration 510, Loss: 6.948298687348142e-05, Min w: 0.8540837168693542\n",
      "Iteration 520, Loss: 6.037638377165422e-05, Min w: 0.8640860915184021\n",
      "Iteration 530, Loss: 5.8500612794887275e-05, Min w: 0.8622164726257324\n",
      "Iteration 540, Loss: 5.9648002206813544e-05, Min w: 0.8625185489654541\n",
      "Iteration 550, Loss: 5.9432459238450974e-05, Min w: 0.8642937541007996\n",
      "Iteration 560, Loss: 6.285554263740778e-05, Min w: 0.8573127388954163\n",
      "Iteration 570, Loss: 5.6187858717748895e-05, Min w: 0.8696845173835754\n",
      "Iteration 580, Loss: 5.666220749844797e-05, Min w: 0.8690742254257202\n",
      "Iteration 590, Loss: 6.804490112699568e-05, Min w: 0.8565056324005127\n",
      "Iteration 600, Loss: 5.699486791854724e-05, Min w: 0.8685920834541321\n",
      "Iteration 610, Loss: 5.697248343494721e-05, Min w: 0.8718032836914062\n",
      "Iteration 620, Loss: 5.4737352911615744e-05, Min w: 0.8715441226959229\n",
      "Iteration 630, Loss: 5.454359052237123e-05, Min w: 0.8731394410133362\n",
      "Iteration 640, Loss: 5.565186438616365e-05, Min w: 0.8719612956047058\n",
      "Iteration 650, Loss: 5.745861562900245e-05, Min w: 0.8724006414413452\n",
      "Iteration 660, Loss: 5.579374192166142e-05, Min w: 0.8714452981948853\n",
      "Iteration 670, Loss: 5.490880357683636e-05, Min w: 0.8719136714935303\n",
      "Iteration 680, Loss: 5.431886893347837e-05, Min w: 0.8726001977920532\n",
      "Iteration 690, Loss: 5.837485514348373e-05, Min w: 0.8735042214393616\n",
      "Iteration 700, Loss: 5.76847160118632e-05, Min w: 0.8726035356521606\n",
      "Iteration 710, Loss: 6.966898945393041e-05, Min w: 0.8563278913497925\n",
      "Iteration 720, Loss: 6.352227501338348e-05, Min w: 0.8693177700042725\n",
      "Iteration 730, Loss: 5.82054526603315e-05, Min w: 0.8725501894950867\n",
      "Iteration 740, Loss: 5.242181941866875e-05, Min w: 0.8767269253730774\n",
      "Iteration 750, Loss: 5.394023537519388e-05, Min w: 0.8772169947624207\n",
      "Iteration 760, Loss: 6.273098551901057e-05, Min w: 0.8713442087173462\n",
      "Iteration 770, Loss: 5.6944718380691484e-05, Min w: 0.8783424496650696\n",
      "Iteration 780, Loss: 5.2978586609242484e-05, Min w: 0.8780295252799988\n",
      "Iteration 790, Loss: 5.245675492915325e-05, Min w: 0.8813631534576416\n",
      "Iteration 800, Loss: 5.28546042914968e-05, Min w: 0.8810500502586365\n",
      "Iteration 810, Loss: 6.250334263313562e-05, Min w: 0.8711130023002625\n",
      "Iteration 820, Loss: 6.1824444856029e-05, Min w: 0.8715534210205078\n",
      "Iteration 830, Loss: 5.304428486851975e-05, Min w: 0.8798912763595581\n",
      "Iteration 840, Loss: 5.94281118537765e-05, Min w: 0.8775339126586914\n",
      "Iteration 850, Loss: 5.553822120418772e-05, Min w: 0.8776357173919678\n",
      "Iteration 860, Loss: 5.6056702305795625e-05, Min w: 0.8794026374816895\n",
      "Iteration 870, Loss: 5.106033495394513e-05, Min w: 0.8845446109771729\n",
      "Iteration 880, Loss: 5.263689672574401e-05, Min w: 0.87872314453125\n",
      "Iteration 890, Loss: 5.2533552661770955e-05, Min w: 0.8842558264732361\n",
      "Iteration 900, Loss: 4.9636739277048036e-05, Min w: 0.8866206407546997\n",
      "Iteration 910, Loss: 4.9927763029700145e-05, Min w: 0.8866564035415649\n",
      "Iteration 920, Loss: 5.331284774001688e-05, Min w: 0.8806394934654236\n",
      "Iteration 930, Loss: 5.1655759307323024e-05, Min w: 0.8827515244483948\n",
      "Iteration 940, Loss: 5.42204943485558e-05, Min w: 0.8845881223678589\n",
      "Iteration 950, Loss: 5.004974445910193e-05, Min w: 0.881397545337677\n",
      "Iteration 960, Loss: 5.0531973101897165e-05, Min w: 0.8863165974617004\n",
      "Iteration 970, Loss: 5.5116037401603535e-05, Min w: 0.8829804062843323\n",
      "Iteration 980, Loss: 4.927784902974963e-05, Min w: 0.8872555494308472\n",
      "Iteration 990, Loss: 4.821350739803165e-05, Min w: 0.8901496529579163\n",
      "Iteration 1000, Loss: 5.1481369155226275e-05, Min w: 0.8880420327186584\n",
      "Iteration 1010, Loss: 5.3066909458721057e-05, Min w: 0.8905504941940308\n",
      "Iteration 1020, Loss: 6.0488604503916577e-05, Min w: 0.8681996464729309\n",
      "Iteration 1030, Loss: 4.9227670388063416e-05, Min w: 0.8879029154777527\n",
      "Iteration 1040, Loss: 4.978476499672979e-05, Min w: 0.8901286721229553\n",
      "Iteration 1050, Loss: 4.871644705417566e-05, Min w: 0.8906829953193665\n",
      "Iteration 1060, Loss: 6.036935519659892e-05, Min w: 0.8690360188484192\n",
      "Iteration 1070, Loss: 4.718678610515781e-05, Min w: 0.8932492136955261\n",
      "Iteration 1080, Loss: 5.856111238244921e-05, Min w: 0.8720108866691589\n",
      "Iteration 1090, Loss: 4.753114626510069e-05, Min w: 0.8946744799613953\n",
      "Iteration 1100, Loss: 4.973071918357164e-05, Min w: 0.8914420008659363\n",
      "Iteration 1110, Loss: 5.16117834195029e-05, Min w: 0.8896880745887756\n",
      "Iteration 1120, Loss: 4.6911380195524544e-05, Min w: 0.8969987630844116\n",
      "Iteration 1130, Loss: 4.559028457151726e-05, Min w: 0.8950175642967224\n",
      "Iteration 1140, Loss: 4.750840162159875e-05, Min w: 0.894820511341095\n",
      "Iteration 1150, Loss: 6.208023114595562e-05, Min w: 0.8632409572601318\n",
      "Iteration 1160, Loss: 4.772627289639786e-05, Min w: 0.8919900059700012\n",
      "Iteration 1170, Loss: 4.6828881750116125e-05, Min w: 0.8966610431671143\n",
      "Iteration 1180, Loss: 5.1704068027902395e-05, Min w: 0.8919897675514221\n",
      "Iteration 1190, Loss: 4.709933273261413e-05, Min w: 0.8947892189025879\n",
      "Iteration 1200, Loss: 4.5560544094769284e-05, Min w: 0.8974246978759766\n",
      "Iteration 1210, Loss: 4.538400025921874e-05, Min w: 0.8956180810928345\n",
      "Iteration 1220, Loss: 4.713013913715258e-05, Min w: 0.8980329632759094\n",
      "Iteration 1230, Loss: 4.789458034792915e-05, Min w: 0.8966230750083923\n",
      "Iteration 1240, Loss: 4.8135148972505704e-05, Min w: 0.8962182402610779\n",
      "Iteration 0, Loss: 4.322226595832035e-05, Min w: 0.9005183577537537\n",
      "Iteration 10, Loss: 5.196711208554916e-05, Min w: 0.8928804993629456\n",
      "Iteration 20, Loss: 5.022594996262342e-05, Min w: 0.8956089019775391\n",
      "Iteration 30, Loss: 4.7517489292658865e-05, Min w: 0.8979166150093079\n",
      "Iteration 40, Loss: 4.368838926893659e-05, Min w: 0.9025395512580872\n",
      "Iteration 50, Loss: 4.6836150431772694e-05, Min w: 0.8989527821540833\n",
      "Iteration 60, Loss: 5.075019726064056e-05, Min w: 0.8927868604660034\n",
      "Iteration 70, Loss: 4.380666359793395e-05, Min w: 0.90028977394104\n",
      "Iteration 80, Loss: 4.479629569686949e-05, Min w: 0.9010268449783325\n",
      "Iteration 90, Loss: 4.9224592657992616e-05, Min w: 0.8937491774559021\n",
      "Iteration 100, Loss: 4.5043696445645764e-05, Min w: 0.9032150506973267\n",
      "Iteration 110, Loss: 4.8377420171163976e-05, Min w: 0.9000601172447205\n",
      "Iteration 120, Loss: 4.5980119466548786e-05, Min w: 0.9029861092567444\n",
      "Iteration 130, Loss: 5.041780605097301e-05, Min w: 0.8956536054611206\n",
      "Iteration 140, Loss: 4.649203037843108e-05, Min w: 0.9048186540603638\n",
      "Iteration 150, Loss: 4.854146027355455e-05, Min w: 0.8993666172027588\n",
      "Iteration 160, Loss: 4.576975334202871e-05, Min w: 0.9031270146369934\n",
      "Iteration 170, Loss: 4.673860894399695e-05, Min w: 0.9040524363517761\n",
      "Iteration 180, Loss: 5.55807382625062e-05, Min w: 0.8737878203392029\n",
      "Iteration 190, Loss: 4.1630373743828386e-05, Min w: 0.9069486260414124\n",
      "Iteration 200, Loss: 4.6384211600525305e-05, Min w: 0.9004513621330261\n",
      "Iteration 210, Loss: 4.817652370547876e-05, Min w: 0.8997142314910889\n",
      "Iteration 220, Loss: 4.4855383748654276e-05, Min w: 0.9009716510772705\n",
      "Iteration 230, Loss: 4.241311035002582e-05, Min w: 0.9072086811065674\n",
      "Iteration 240, Loss: 4.5446337026078254e-05, Min w: 0.907193124294281\n",
      "Iteration 250, Loss: 4.436821836861782e-05, Min w: 0.9052210450172424\n",
      "Iteration 260, Loss: 4.539702058536932e-05, Min w: 0.9060484170913696\n",
      "Iteration 270, Loss: 5.3066625696374103e-05, Min w: 0.882249116897583\n",
      "Iteration 280, Loss: 4.6835997636662796e-05, Min w: 0.9030399322509766\n",
      "Iteration 290, Loss: 4.07178740715608e-05, Min w: 0.9118459224700928\n",
      "Iteration 300, Loss: 4.26901169703342e-05, Min w: 0.9074122905731201\n",
      "Iteration 310, Loss: 4.336379060987383e-05, Min w: 0.9080598950386047\n",
      "Iteration 320, Loss: 4.756440830533393e-05, Min w: 0.8989679217338562\n",
      "Iteration 330, Loss: 4.0716942748986185e-05, Min w: 0.9105760455131531\n",
      "Iteration 340, Loss: 4.228579928167164e-05, Min w: 0.9125402569770813\n",
      "Iteration 350, Loss: 3.879891664837487e-05, Min w: 0.9119137525558472\n",
      "Iteration 360, Loss: 4.1298735595773906e-05, Min w: 0.9133767485618591\n",
      "Iteration 370, Loss: 3.882007149513811e-05, Min w: 0.9134666919708252\n",
      "Iteration 380, Loss: 5.400724694482051e-05, Min w: 0.8785632252693176\n",
      "Iteration 390, Loss: 4.688895933213644e-05, Min w: 0.8999067544937134\n",
      "Iteration 400, Loss: 4.191582775092684e-05, Min w: 0.9099448919296265\n",
      "Iteration 410, Loss: 3.939718590117991e-05, Min w: 0.9125373959541321\n",
      "Iteration 420, Loss: 6.1048187490087e-05, Min w: 0.856969952583313\n",
      "Iteration 430, Loss: 3.997987732873298e-05, Min w: 0.9157789945602417\n",
      "Iteration 440, Loss: 3.78574914066121e-05, Min w: 0.9147223830223083\n",
      "Iteration 450, Loss: 3.7838955904589966e-05, Min w: 0.9172465205192566\n",
      "Iteration 460, Loss: 3.8176112866494805e-05, Min w: 0.9171034097671509\n",
      "Iteration 470, Loss: 3.829205525107682e-05, Min w: 0.9139825701713562\n",
      "Iteration 480, Loss: 4.3181767978239805e-05, Min w: 0.9109072685241699\n",
      "Iteration 490, Loss: 3.890976222464815e-05, Min w: 0.9171351790428162\n",
      "Iteration 500, Loss: 3.707838914124295e-05, Min w: 0.9176879525184631\n",
      "Iteration 510, Loss: 3.76559910364449e-05, Min w: 0.9146071672439575\n",
      "Iteration 520, Loss: 3.802353239734657e-05, Min w: 0.9148010015487671\n",
      "Iteration 530, Loss: 3.789135371334851e-05, Min w: 0.9163638353347778\n",
      "Iteration 540, Loss: 3.854136957670562e-05, Min w: 0.9189771413803101\n",
      "Iteration 550, Loss: 3.802195351454429e-05, Min w: 0.9151831865310669\n",
      "Iteration 560, Loss: 3.572056448319927e-05, Min w: 0.921715259552002\n",
      "Iteration 570, Loss: 4.140863165957853e-05, Min w: 0.9131291508674622\n",
      "Iteration 580, Loss: 4.366596112959087e-05, Min w: 0.9087933897972107\n",
      "Iteration 590, Loss: 4.0211376472143456e-05, Min w: 0.9159952402114868\n",
      "Iteration 600, Loss: 4.553316830424592e-05, Min w: 0.8977859616279602\n",
      "Iteration 610, Loss: 4.1780207538977265e-05, Min w: 0.912720263004303\n",
      "Iteration 620, Loss: 4.145987259107642e-05, Min w: 0.9113017916679382\n",
      "Iteration 630, Loss: 3.999846012447961e-05, Min w: 0.9170441627502441\n",
      "Iteration 640, Loss: 3.791806011577137e-05, Min w: 0.9176651239395142\n",
      "Iteration 650, Loss: 3.9904120058054104e-05, Min w: 0.9184202551841736\n",
      "Iteration 660, Loss: 3.653687963378616e-05, Min w: 0.9221188426017761\n",
      "Iteration 670, Loss: 4.4447115215007216e-05, Min w: 0.9023106098175049\n",
      "Iteration 680, Loss: 3.8460493669845164e-05, Min w: 0.9190405607223511\n",
      "Iteration 690, Loss: 3.583231955417432e-05, Min w: 0.9207528233528137\n",
      "Iteration 700, Loss: 3.581311830203049e-05, Min w: 0.9207408428192139\n",
      "Iteration 710, Loss: 3.6609533708542585e-05, Min w: 0.9201541543006897\n",
      "Iteration 720, Loss: 5.175970363779925e-05, Min w: 0.8783397078514099\n",
      "Iteration 730, Loss: 3.521337202982977e-05, Min w: 0.9239987730979919\n",
      "Iteration 740, Loss: 3.590363485272974e-05, Min w: 0.9240883588790894\n",
      "Iteration 750, Loss: 5.406569107435644e-05, Min w: 0.8679726123809814\n",
      "Iteration 760, Loss: 3.4840384614653885e-05, Min w: 0.924079418182373\n",
      "Iteration 770, Loss: 3.5719807783607394e-05, Min w: 0.9225207567214966\n",
      "Iteration 780, Loss: 4.398844612296671e-05, Min w: 0.9009789228439331\n",
      "Iteration 790, Loss: 4.293107849662192e-05, Min w: 0.9057701230049133\n",
      "Iteration 800, Loss: 3.9655878936173394e-05, Min w: 0.9170586466789246\n",
      "Iteration 810, Loss: 3.676501728477888e-05, Min w: 0.9234198331832886\n",
      "Iteration 820, Loss: 3.497475336189382e-05, Min w: 0.9230482578277588\n",
      "Iteration 830, Loss: 3.488310903776437e-05, Min w: 0.9234782457351685\n",
      "Iteration 840, Loss: 3.494577686069533e-05, Min w: 0.9241940379142761\n",
      "Iteration 850, Loss: 3.931266473955475e-05, Min w: 0.918759822845459\n",
      "Iteration 860, Loss: 3.8620608393102884e-05, Min w: 0.919165313243866\n",
      "Iteration 870, Loss: 4.4075510231778026e-05, Min w: 0.9057303071022034\n",
      "Iteration 880, Loss: 3.8994512578938156e-05, Min w: 0.9199743270874023\n",
      "Iteration 890, Loss: 3.666969496407546e-05, Min w: 0.9242425560951233\n",
      "Iteration 900, Loss: 3.363369614817202e-05, Min w: 0.9269520044326782\n",
      "Iteration 910, Loss: 3.425167597015388e-05, Min w: 0.9253434538841248\n",
      "Iteration 920, Loss: 3.361434937687591e-05, Min w: 0.9286201000213623\n",
      "Iteration 930, Loss: 3.423300222493708e-05, Min w: 0.9272157549858093\n",
      "Iteration 940, Loss: 3.6928518966306e-05, Min w: 0.9217777848243713\n",
      "Iteration 950, Loss: 3.8749836676288396e-05, Min w: 0.9180719256401062\n",
      "Iteration 960, Loss: 3.80128258257173e-05, Min w: 0.9216185808181763\n",
      "Iteration 970, Loss: 3.393897713976912e-05, Min w: 0.9290753602981567\n",
      "Iteration 980, Loss: 3.483835462247953e-05, Min w: 0.9262827038764954\n",
      "Iteration 990, Loss: 3.3692558645270765e-05, Min w: 0.9281682372093201\n",
      "Iteration 1000, Loss: 4.2705949454102665e-05, Min w: 0.9077037572860718\n",
      "Iteration 1010, Loss: 4.5842083636671305e-05, Min w: 0.8949880003929138\n",
      "Iteration 1020, Loss: 3.325298530398868e-05, Min w: 0.9284310936927795\n",
      "Iteration 1030, Loss: 4.334491313784383e-05, Min w: 0.9036170840263367\n",
      "Iteration 1040, Loss: 3.519952588248998e-05, Min w: 0.9273840188980103\n",
      "Iteration 1050, Loss: 4.123294638702646e-05, Min w: 0.9110704064369202\n",
      "Iteration 1060, Loss: 4.167980296188034e-05, Min w: 0.907724142074585\n",
      "Iteration 1070, Loss: 3.569250111468136e-05, Min w: 0.9256871938705444\n",
      "Iteration 1080, Loss: 3.7673038605134934e-05, Min w: 0.9209913611412048\n",
      "Iteration 1090, Loss: 3.5329223464941606e-05, Min w: 0.9250056147575378\n",
      "Iteration 1100, Loss: 3.310311149107292e-05, Min w: 0.9288327693939209\n",
      "Iteration 1110, Loss: 4.447755418368615e-05, Min w: 0.8986614942550659\n",
      "Iteration 1120, Loss: 3.4103617508662865e-05, Min w: 0.9276407361030579\n",
      "Iteration 1130, Loss: 3.965618088841438e-05, Min w: 0.9115777611732483\n",
      "Iteration 1140, Loss: 3.271173409302719e-05, Min w: 0.9301881194114685\n",
      "Iteration 1150, Loss: 3.4321397833991796e-05, Min w: 0.9289263486862183\n",
      "Iteration 1160, Loss: 3.8769416278228164e-05, Min w: 0.9164548516273499\n",
      "Iteration 1170, Loss: 3.188387199770659e-05, Min w: 0.9304479360580444\n",
      "Iteration 1180, Loss: 3.3472799259470776e-05, Min w: 0.9301813244819641\n",
      "Iteration 1190, Loss: 3.267977444920689e-05, Min w: 0.9327623248100281\n",
      "Iteration 1200, Loss: 3.50292248185724e-05, Min w: 0.9272162914276123\n",
      "Iteration 1210, Loss: 3.4243566915392876e-05, Min w: 0.929438054561615\n",
      "Iteration 1220, Loss: 3.241814556531608e-05, Min w: 0.9311319589614868\n",
      "Iteration 1230, Loss: 3.34068427036982e-05, Min w: 0.9303195476531982\n",
      "Iteration 1240, Loss: 3.718700827448629e-05, Min w: 0.9175447225570679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  96%|█████████▌| 23/24 [39:36<01:58, 118.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.021421414075338985, 'L2_avg': 0.03305104698643058, 'End_point_L1_avg': 0.010775242051464705, 'End_point_L2_avg': 0.01109145163272257}\n",
      "Iteration 0, Loss: 0.0012145015643909574, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0011400299845263362, Min w: 0.0\n",
      "Iteration 20, Loss: 0.001044045784510672, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0010354537516832352, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008822166710160673, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0008295721490867436, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007408090750686824, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007127388962544501, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006875749677419662, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006643875385634601, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006416441756300628, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006171083077788353, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006006876938045025, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005807358538731933, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005646304925903678, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005525298765860498, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0005369925056584179, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0005223890184424818, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005113203078508377, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0004993095062673092, Min w: 0.0\n",
      "Iteration 200, Loss: 0.000489718746393919, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0004823929339181632, Min w: 0.0\n",
      "Iteration 220, Loss: 0.00047594786155968904, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00046787955216132104, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004614192876033485, Min w: 0.0\n",
      "Iteration 250, Loss: 0.00044775742571800947, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0004471356514841318, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00043640690273605287, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0004295538819860667, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00042856516665779054, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0004198079404886812, Min w: 0.0\n",
      "Iteration 310, Loss: 0.00042298054904676974, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0004075872420798987, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00040467435610480607, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00039736530743539333, Min w: 0.0\n",
      "Iteration 350, Loss: 0.00040633167373016477, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0004023148212581873, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0003945613862015307, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0003966214426327497, Min w: 0.0\n",
      "Iteration 390, Loss: 0.00039711943827569485, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0003991243429481983, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0004053769225720316, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004004388174507767, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0004270220815669745, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0004205545410513878, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00042080297134816647, Min w: 0.0\n",
      "Iteration 460, Loss: 0.00039224905776791275, Min w: 0.0\n",
      "Iteration 470, Loss: 0.000399578275391832, Min w: 0.0\n",
      "Iteration 480, Loss: 0.00037788943154737353, Min w: 0.0\n",
      "Iteration 490, Loss: 0.00038301467429846525, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0004004421934951097, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0003836418327409774, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00036751991137862206, Min w: 0.0\n",
      "Iteration 530, Loss: 0.00035801148624159396, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0003519707533996552, Min w: 0.0\n",
      "Iteration 550, Loss: 0.00035358360037207603, Min w: 0.0\n",
      "Iteration 560, Loss: 0.00034278215025551617, Min w: 0.0\n",
      "Iteration 570, Loss: 0.00034874805714935064, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0003351258346810937, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0003383031871635467, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0003346636949572712, Min w: 0.0\n",
      "Iteration 610, Loss: 0.00033484326559118927, Min w: 0.0\n",
      "Iteration 620, Loss: 0.00034053451963700354, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0003344625874888152, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00033200631150975823, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0003308227751404047, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0003303252742625773, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00033385810093022883, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0003308440500404686, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00033600503229536116, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0003348402096889913, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0003413527156226337, Min w: 3.9906584043596795e-39\n",
      "Iteration 720, Loss: 0.0003406109753996134, Min w: 8.2461972549167e-31\n",
      "Iteration 730, Loss: 0.00033800784149207175, Min w: 9.116823829783438e-22\n",
      "Iteration 740, Loss: 0.00034233761834912, Min w: 5.047707560704791e-16\n",
      "Iteration 750, Loss: 0.0003434341633692384, Min w: 9.746172618951832e-11\n",
      "Iteration 760, Loss: 0.00034808789496310055, Min w: 2.5871455022752343e-07\n",
      "Iteration 770, Loss: 0.0003547325322870165, Min w: 2.3221066385303857e-06\n",
      "Iteration 780, Loss: 0.0003527269291225821, Min w: 3.4606755239252607e-09\n",
      "Iteration 790, Loss: 0.00036865161382593215, Min w: 2.764944768129387e-16\n",
      "Iteration 800, Loss: 0.0003582657082006335, Min w: 1.1876864224092467e-25\n",
      "Iteration 810, Loss: 0.00035542124533094466, Min w: 3.4009677153470774e-30\n",
      "Iteration 820, Loss: 0.0003548643726389855, Min w: 4.74675057251875e-31\n",
      "Iteration 830, Loss: 0.0003444541653152555, Min w: 8.98948772361961e-31\n",
      "Iteration 840, Loss: 0.00034487847005948424, Min w: 1.98298016469592e-30\n",
      "Iteration 850, Loss: 0.00034960982156917453, Min w: 6.68170158028866e-29\n",
      "Iteration 860, Loss: 0.0003479006700217724, Min w: 4.55832180725482e-26\n",
      "Iteration 870, Loss: 0.0003504968190100044, Min w: 3.634034488028962e-24\n",
      "Iteration 880, Loss: 0.00034573875018395483, Min w: 8.83086001614683e-24\n",
      "Iteration 890, Loss: 0.0003449810901656747, Min w: 8.80110579207814e-22\n",
      "Iteration 900, Loss: 0.00034496132866479456, Min w: 2.184921332346103e-19\n",
      "Iteration 910, Loss: 0.00034471970866434276, Min w: 2.377725914495156e-18\n",
      "Iteration 920, Loss: 0.00034713855711743236, Min w: 2.2707145429940996e-16\n",
      "Iteration 930, Loss: 0.0003587755491025746, Min w: 3.227867226166057e-15\n",
      "Iteration 940, Loss: 0.0003446448827162385, Min w: 2.2169283553016839e-13\n",
      "Iteration 950, Loss: 0.0003408765478525311, Min w: 4.025189469930579e-12\n",
      "Iteration 960, Loss: 0.00034395427792333066, Min w: 1.1847384184804355e-10\n",
      "Iteration 970, Loss: 0.0003419439308345318, Min w: 1.4722340013761936e-09\n",
      "Iteration 980, Loss: 0.00034347278415225446, Min w: 1.189210951935138e-08\n",
      "Iteration 990, Loss: 0.00033981891465373337, Min w: 2.0609709849850333e-07\n",
      "Iteration 1000, Loss: 0.00034757007961161435, Min w: 5.850153229403077e-06\n",
      "Iteration 1010, Loss: 0.0003420412540435791, Min w: 8.218545553972945e-05\n",
      "Iteration 1020, Loss: 0.00034058874007314444, Min w: 0.0007801298052072525\n",
      "Iteration 1030, Loss: 0.00034259853418916464, Min w: 0.010592688806355\n",
      "Iteration 1040, Loss: 0.0003585994418244809, Min w: 0.034110672771930695\n",
      "Iteration 1050, Loss: 0.0003214448515791446, Min w: 0.06835291534662247\n",
      "Iteration 1060, Loss: 0.00032581883715465665, Min w: 0.06844467669725418\n",
      "Iteration 1070, Loss: 0.0003227655543014407, Min w: 0.0738215446472168\n",
      "Iteration 1080, Loss: 0.00032314882264472544, Min w: 0.07104717940092087\n",
      "Iteration 1090, Loss: 0.00031728643807582557, Min w: 0.08244958519935608\n",
      "Iteration 1100, Loss: 0.00031785969622433186, Min w: 0.08647473901510239\n",
      "Iteration 1110, Loss: 0.00031668951851315796, Min w: 0.09085839986801147\n",
      "Iteration 1120, Loss: 0.0003148072864860296, Min w: 0.09700550138950348\n",
      "Iteration 1130, Loss: 0.00031579818460159004, Min w: 0.10045397281646729\n",
      "Iteration 1140, Loss: 0.00031141008366830647, Min w: 0.10750766098499298\n",
      "Iteration 1150, Loss: 0.0003098177840001881, Min w: 0.10579545050859451\n",
      "Iteration 1160, Loss: 0.00030511178192682564, Min w: 0.1166202500462532\n",
      "Iteration 1170, Loss: 0.00030795903876423836, Min w: 0.12112940102815628\n",
      "Iteration 1180, Loss: 0.0003105456999037415, Min w: 0.12181389331817627\n",
      "Iteration 1190, Loss: 0.0003016064001712948, Min w: 0.12804488837718964\n",
      "Iteration 1200, Loss: 0.0003004455065820366, Min w: 0.13415133953094482\n",
      "Iteration 1210, Loss: 0.00029744990752078593, Min w: 0.14112190902233124\n",
      "Iteration 1220, Loss: 0.0002984503225889057, Min w: 0.1373516172170639\n",
      "Iteration 1230, Loss: 0.00030555896228179336, Min w: 0.13999323546886444\n",
      "Iteration 1240, Loss: 0.0003036271664313972, Min w: 0.1451399177312851\n",
      "Iteration 0, Loss: 0.00029313110280781984, Min w: 0.15503552556037903\n",
      "Iteration 10, Loss: 0.00029184872983023524, Min w: 0.15646056830883026\n",
      "Iteration 20, Loss: 0.0003064327174797654, Min w: 0.15914936363697052\n",
      "Iteration 30, Loss: 0.00029398934566415846, Min w: 0.1710120141506195\n",
      "Iteration 40, Loss: 0.00028200456290505826, Min w: 0.1815604418516159\n",
      "Iteration 50, Loss: 0.000290428550215438, Min w: 0.17686399817466736\n",
      "Iteration 60, Loss: 0.00028110903804190457, Min w: 0.18408267199993134\n",
      "Iteration 70, Loss: 0.00028395612025633454, Min w: 0.18861129879951477\n",
      "Iteration 80, Loss: 0.0002801624359562993, Min w: 0.20634214580059052\n",
      "Iteration 90, Loss: 0.0002758046321105212, Min w: 0.20567797124385834\n",
      "Iteration 100, Loss: 0.00026710337260738015, Min w: 0.22731389105319977\n",
      "Iteration 110, Loss: 0.0002697032759897411, Min w: 0.22061505913734436\n",
      "Iteration 120, Loss: 0.00026681917370297015, Min w: 0.22694550454616547\n",
      "Iteration 130, Loss: 0.00026353696011938155, Min w: 0.23527581989765167\n",
      "Iteration 140, Loss: 0.0002613772521726787, Min w: 0.2525160014629364\n",
      "Iteration 150, Loss: 0.00026078225346282125, Min w: 0.24572041630744934\n",
      "Iteration 160, Loss: 0.0002596072154119611, Min w: 0.2484818696975708\n",
      "Iteration 170, Loss: 0.000262008688878268, Min w: 0.25643473863601685\n",
      "Iteration 180, Loss: 0.0002534961677156389, Min w: 0.26365816593170166\n",
      "Iteration 190, Loss: 0.0002534430241212249, Min w: 0.2771947383880615\n",
      "Iteration 200, Loss: 0.0002496494853403419, Min w: 0.2789798080921173\n",
      "Iteration 210, Loss: 0.00024533557007089257, Min w: 0.29204410314559937\n",
      "Iteration 220, Loss: 0.00024971997481770813, Min w: 0.283380389213562\n",
      "Iteration 230, Loss: 0.00024757414939813316, Min w: 0.3025148808956146\n",
      "Iteration 240, Loss: 0.00023801971110515296, Min w: 0.3146371841430664\n",
      "Iteration 250, Loss: 0.0002373948518652469, Min w: 0.3106047213077545\n",
      "Iteration 260, Loss: 0.0002373508468735963, Min w: 0.3196452856063843\n",
      "Iteration 270, Loss: 0.00023179077834356576, Min w: 0.3360278904438019\n",
      "Iteration 280, Loss: 0.0002324586093891412, Min w: 0.33136916160583496\n",
      "Iteration 290, Loss: 0.00023104484716895968, Min w: 0.3369734585285187\n",
      "Iteration 300, Loss: 0.00022963134688325226, Min w: 0.3455146849155426\n",
      "Iteration 310, Loss: 0.00022895591973792762, Min w: 0.3565693497657776\n",
      "Iteration 320, Loss: 0.00023969517496880144, Min w: 0.35677048563957214\n",
      "Iteration 330, Loss: 0.0002233385166618973, Min w: 0.36801838874816895\n",
      "Iteration 340, Loss: 0.0002265073562739417, Min w: 0.3673776090145111\n",
      "Iteration 350, Loss: 0.00021824738360010087, Min w: 0.3766692578792572\n",
      "Iteration 360, Loss: 0.00022088849800638855, Min w: 0.3764578700065613\n",
      "Iteration 370, Loss: 0.00021398272656369954, Min w: 0.3888760507106781\n",
      "Iteration 380, Loss: 0.00021232150902505964, Min w: 0.39073166251182556\n",
      "Iteration 390, Loss: 0.00022520254424307495, Min w: 0.39217278361320496\n",
      "Iteration 400, Loss: 0.00021131942048668861, Min w: 0.39998045563697815\n",
      "Iteration 410, Loss: 0.00021157618903089315, Min w: 0.40010350942611694\n",
      "Iteration 420, Loss: 0.00020319654140621424, Min w: 0.41950705647468567\n",
      "Iteration 430, Loss: 0.00020149777992628515, Min w: 0.41763371229171753\n",
      "Iteration 440, Loss: 0.00020205462351441383, Min w: 0.41836073994636536\n",
      "Iteration 450, Loss: 0.0002002074761549011, Min w: 0.431153804063797\n",
      "Iteration 460, Loss: 0.00020403458620421588, Min w: 0.4299984574317932\n",
      "Iteration 470, Loss: 0.00020272203255444765, Min w: 0.4418734312057495\n",
      "Iteration 480, Loss: 0.00019560905639082193, Min w: 0.4484782814979553\n",
      "Iteration 490, Loss: 0.000201300106709823, Min w: 0.4483315050601959\n",
      "Iteration 500, Loss: 0.00020654058607760817, Min w: 0.4452812373638153\n",
      "Iteration 510, Loss: 0.00018898784765042365, Min w: 0.46634867787361145\n",
      "Iteration 520, Loss: 0.0001886620302684605, Min w: 0.4656917452812195\n",
      "Iteration 530, Loss: 0.0001902555814012885, Min w: 0.45883023738861084\n",
      "Iteration 540, Loss: 0.00018348109733778983, Min w: 0.48163166642189026\n",
      "Iteration 550, Loss: 0.00018964047194458544, Min w: 0.4741995334625244\n",
      "Iteration 560, Loss: 0.0001899755880003795, Min w: 0.47534245252609253\n",
      "Iteration 570, Loss: 0.00018352239567320794, Min w: 0.48800012469291687\n",
      "Iteration 580, Loss: 0.00017848888819571584, Min w: 0.4924885034561157\n",
      "Iteration 590, Loss: 0.00017832625599112362, Min w: 0.49857771396636963\n",
      "Iteration 600, Loss: 0.0001802786428015679, Min w: 0.5003892183303833\n",
      "Iteration 610, Loss: 0.00017385924002155662, Min w: 0.5061384439468384\n",
      "Iteration 620, Loss: 0.00017292053962592036, Min w: 0.5099565982818604\n",
      "Iteration 630, Loss: 0.00018200014892499894, Min w: 0.5072476863861084\n",
      "Iteration 640, Loss: 0.00017280637985095382, Min w: 0.5163997411727905\n",
      "Iteration 650, Loss: 0.0001760628365445882, Min w: 0.5245597958564758\n",
      "Iteration 660, Loss: 0.0001673095248406753, Min w: 0.5278743505477905\n",
      "Iteration 670, Loss: 0.00016734577366150916, Min w: 0.5308448076248169\n",
      "Iteration 680, Loss: 0.00016516816685907543, Min w: 0.5369052290916443\n",
      "Iteration 690, Loss: 0.00016801785386633128, Min w: 0.5344600677490234\n",
      "Iteration 700, Loss: 0.00016260906704701483, Min w: 0.5418340563774109\n",
      "Iteration 710, Loss: 0.00016055892047006637, Min w: 0.5429017543792725\n",
      "Iteration 720, Loss: 0.00015694442845415324, Min w: 0.5561825633049011\n",
      "Iteration 730, Loss: 0.00016103677626233548, Min w: 0.5575917959213257\n",
      "Iteration 740, Loss: 0.00018267067207489163, Min w: 0.5404909253120422\n",
      "Iteration 750, Loss: 0.00015279927174560726, Min w: 0.5692231059074402\n",
      "Iteration 760, Loss: 0.00015378338866867125, Min w: 0.573664665222168\n",
      "Iteration 770, Loss: 0.00015143395285122097, Min w: 0.5708252191543579\n",
      "Iteration 780, Loss: 0.00015039564459584653, Min w: 0.5794453620910645\n",
      "Iteration 790, Loss: 0.00017089229368139058, Min w: 0.561703622341156\n",
      "Iteration 800, Loss: 0.00015403120778501034, Min w: 0.5850513577461243\n",
      "Iteration 810, Loss: 0.00014781027857679874, Min w: 0.580559492111206\n",
      "Iteration 820, Loss: 0.00014991585339885205, Min w: 0.5881938934326172\n",
      "Iteration 830, Loss: 0.00015367443847935647, Min w: 0.5765378475189209\n",
      "Iteration 840, Loss: 0.00015852443175390363, Min w: 0.5799415111541748\n",
      "Iteration 850, Loss: 0.00014447903959080577, Min w: 0.5948435068130493\n",
      "Iteration 860, Loss: 0.0001494745083618909, Min w: 0.5960699915885925\n",
      "Iteration 870, Loss: 0.00013948614650871605, Min w: 0.6061784625053406\n",
      "Iteration 880, Loss: 0.0001413421268807724, Min w: 0.6071652770042419\n",
      "Iteration 890, Loss: 0.000150879321154207, Min w: 0.6041247248649597\n",
      "Iteration 900, Loss: 0.0001356316643068567, Min w: 0.6147828102111816\n",
      "Iteration 910, Loss: 0.0001463427470298484, Min w: 0.6154966950416565\n",
      "Iteration 920, Loss: 0.0001345283817499876, Min w: 0.6182093024253845\n",
      "Iteration 930, Loss: 0.0001425944792572409, Min w: 0.616061270236969\n",
      "Iteration 940, Loss: 0.00013480604684446007, Min w: 0.6245287656784058\n",
      "Iteration 950, Loss: 0.00013176831998862326, Min w: 0.6251093745231628\n",
      "Iteration 960, Loss: 0.0001312552922172472, Min w: 0.6341702938079834\n",
      "Iteration 970, Loss: 0.0001302918972214684, Min w: 0.6319098472595215\n",
      "Iteration 980, Loss: 0.00013192994811106473, Min w: 0.6390559077262878\n",
      "Iteration 990, Loss: 0.00012936767598148435, Min w: 0.6411756277084351\n",
      "Iteration 1000, Loss: 0.00013574978220276535, Min w: 0.6359899640083313\n",
      "Iteration 1010, Loss: 0.00013118403148837388, Min w: 0.6441066265106201\n",
      "Iteration 1020, Loss: 0.00013138059875927866, Min w: 0.6431465148925781\n",
      "Iteration 1030, Loss: 0.0001238854747498408, Min w: 0.6542947888374329\n",
      "Iteration 1040, Loss: 0.00012453341332729906, Min w: 0.6523747444152832\n",
      "Iteration 1050, Loss: 0.00012452181545086205, Min w: 0.6548917889595032\n",
      "Iteration 1060, Loss: 0.00012198613694636151, Min w: 0.6598715782165527\n",
      "Iteration 1070, Loss: 0.00012277487257961184, Min w: 0.6581947803497314\n",
      "Iteration 1080, Loss: 0.00012000571587122977, Min w: 0.6661601066589355\n",
      "Iteration 1090, Loss: 0.0001392329577356577, Min w: 0.6568301320075989\n",
      "Iteration 1100, Loss: 0.00011907210864592344, Min w: 0.6690778732299805\n",
      "Iteration 1110, Loss: 0.0001200639599119313, Min w: 0.6700153946876526\n",
      "Iteration 1120, Loss: 0.00011949308827752247, Min w: 0.6780532002449036\n",
      "Iteration 1130, Loss: 0.00011711360275512561, Min w: 0.6700577139854431\n",
      "Iteration 1140, Loss: 0.00011773978621931747, Min w: 0.6825889945030212\n",
      "Iteration 1150, Loss: 0.00012840527051594108, Min w: 0.6770410537719727\n",
      "Iteration 1160, Loss: 0.00011604305473156273, Min w: 0.6831353306770325\n",
      "Iteration 1170, Loss: 0.00011537595855770633, Min w: 0.683437705039978\n",
      "Iteration 1180, Loss: 0.00011461385292932391, Min w: 0.6907826662063599\n",
      "Iteration 1190, Loss: 0.00011172439553774893, Min w: 0.6967435479164124\n",
      "Iteration 1200, Loss: 0.00011187153722858056, Min w: 0.690476655960083\n",
      "Iteration 1210, Loss: 0.00011121675925096497, Min w: 0.7043233513832092\n",
      "Iteration 1220, Loss: 0.0001167019217973575, Min w: 0.6919879913330078\n",
      "Iteration 1230, Loss: 0.00011457299842732027, Min w: 0.6981892585754395\n",
      "Iteration 1240, Loss: 0.00011778264888562262, Min w: 0.6907767057418823\n",
      "Iteration 0, Loss: 0.00010700527491280809, Min w: 0.7028415203094482\n",
      "Iteration 10, Loss: 0.00010914566519204527, Min w: 0.7049599289894104\n",
      "Iteration 20, Loss: 0.0001197761157527566, Min w: 0.699579119682312\n",
      "Iteration 30, Loss: 0.00010178732918575406, Min w: 0.7211323380470276\n",
      "Iteration 40, Loss: 0.00011540501145645976, Min w: 0.7103369235992432\n",
      "Iteration 50, Loss: 0.00010255716188112274, Min w: 0.7192835807800293\n",
      "Iteration 60, Loss: 0.00011298638128209859, Min w: 0.7132806181907654\n",
      "Iteration 70, Loss: 0.00010398616723250598, Min w: 0.7240171432495117\n",
      "Iteration 80, Loss: 0.0001097221247619018, Min w: 0.7222544550895691\n",
      "Iteration 90, Loss: 0.00010014174040406942, Min w: 0.730908215045929\n",
      "Iteration 100, Loss: 0.00010029360419139266, Min w: 0.727399468421936\n",
      "Iteration 110, Loss: 9.805408626561984e-05, Min w: 0.738713800907135\n",
      "Iteration 120, Loss: 0.00010457242024131119, Min w: 0.7301867008209229\n",
      "Iteration 130, Loss: 9.589963883627206e-05, Min w: 0.7366331815719604\n",
      "Iteration 140, Loss: 9.63211350608617e-05, Min w: 0.7403119802474976\n",
      "Iteration 150, Loss: 9.830567432800308e-05, Min w: 0.7319064736366272\n",
      "Iteration 160, Loss: 9.489624062553048e-05, Min w: 0.7389184236526489\n",
      "Iteration 170, Loss: 9.77944364422001e-05, Min w: 0.7389039397239685\n",
      "Iteration 180, Loss: 9.569259418640286e-05, Min w: 0.7428832650184631\n",
      "Iteration 190, Loss: 0.000103203667094931, Min w: 0.7407046556472778\n",
      "Iteration 200, Loss: 0.00010229814506601542, Min w: 0.7418099045753479\n",
      "Iteration 210, Loss: 9.363664139527828e-05, Min w: 0.7510047554969788\n",
      "Iteration 220, Loss: 0.00010736433614511043, Min w: 0.7408857345581055\n",
      "Iteration 230, Loss: 0.00010073772864416242, Min w: 0.7493520975112915\n",
      "Iteration 240, Loss: 9.478286665398628e-05, Min w: 0.7509681582450867\n",
      "Iteration 250, Loss: 8.916293154470623e-05, Min w: 0.7589071393013\n",
      "Iteration 260, Loss: 9.50940084294416e-05, Min w: 0.7543953061103821\n",
      "Iteration 270, Loss: 9.161059278994799e-05, Min w: 0.7618045210838318\n",
      "Iteration 280, Loss: 8.977387187769637e-05, Min w: 0.764134407043457\n",
      "Iteration 290, Loss: 9.466183109907433e-05, Min w: 0.7613204717636108\n",
      "Iteration 300, Loss: 9.914506517816335e-05, Min w: 0.7563652992248535\n",
      "Iteration 310, Loss: 8.610451186541468e-05, Min w: 0.766434371471405\n",
      "Iteration 320, Loss: 9.160069021163508e-05, Min w: 0.7659282684326172\n",
      "Iteration 330, Loss: 8.676129073137417e-05, Min w: 0.7660725712776184\n",
      "Iteration 340, Loss: 8.537927351426333e-05, Min w: 0.7757490873336792\n",
      "Iteration 350, Loss: 8.64771063788794e-05, Min w: 0.771574854850769\n",
      "Iteration 360, Loss: 8.489898027619347e-05, Min w: 0.7753198146820068\n",
      "Iteration 370, Loss: 8.34830425446853e-05, Min w: 0.779799222946167\n",
      "Iteration 380, Loss: 9.008636698126793e-05, Min w: 0.7745199799537659\n",
      "Iteration 390, Loss: 8.530028571840376e-05, Min w: 0.7798438668251038\n",
      "Iteration 400, Loss: 8.320604683831334e-05, Min w: 0.78230220079422\n",
      "Iteration 410, Loss: 8.333375444635749e-05, Min w: 0.784405529499054\n",
      "Iteration 420, Loss: 8.211609383579344e-05, Min w: 0.7848276495933533\n",
      "Iteration 430, Loss: 8.650286326883361e-05, Min w: 0.7816639542579651\n",
      "Iteration 440, Loss: 7.918322080513462e-05, Min w: 0.7900229096412659\n",
      "Iteration 450, Loss: 7.914745947346091e-05, Min w: 0.7922003865242004\n",
      "Iteration 460, Loss: 8.242997864726931e-05, Min w: 0.7864729762077332\n",
      "Iteration 470, Loss: 8.056936349021271e-05, Min w: 0.792121171951294\n",
      "Iteration 480, Loss: 8.164739119820297e-05, Min w: 0.7927835583686829\n",
      "Iteration 490, Loss: 7.634135545231402e-05, Min w: 0.7975137829780579\n",
      "Iteration 500, Loss: 7.61730334488675e-05, Min w: 0.7983075380325317\n",
      "Iteration 510, Loss: 7.995478517841548e-05, Min w: 0.7945342063903809\n",
      "Iteration 520, Loss: 7.622553675901145e-05, Min w: 0.7998500466346741\n",
      "Iteration 530, Loss: 8.010742749320343e-05, Min w: 0.7988022565841675\n",
      "Iteration 540, Loss: 8.050974429352209e-05, Min w: 0.8017492294311523\n",
      "Iteration 550, Loss: 7.51895277062431e-05, Min w: 0.8083315491676331\n",
      "Iteration 560, Loss: 7.659810944460332e-05, Min w: 0.8022736310958862\n",
      "Iteration 570, Loss: 7.68799873185344e-05, Min w: 0.8059494495391846\n",
      "Iteration 580, Loss: 7.507760892622173e-05, Min w: 0.806597888469696\n",
      "Iteration 590, Loss: 8.096372039290145e-05, Min w: 0.8023339509963989\n",
      "Iteration 600, Loss: 8.071189222391695e-05, Min w: 0.8040593862533569\n",
      "Iteration 610, Loss: 0.00010041661880677566, Min w: 0.7853568196296692\n",
      "Iteration 620, Loss: 8.036803046707064e-05, Min w: 0.7974574565887451\n",
      "Iteration 630, Loss: 7.05928323441185e-05, Min w: 0.8189453482627869\n",
      "Iteration 640, Loss: 7.021559576969594e-05, Min w: 0.8188695907592773\n",
      "Iteration 650, Loss: 6.996221782173961e-05, Min w: 0.8210433125495911\n",
      "Iteration 660, Loss: 7.469573756679893e-05, Min w: 0.8142319917678833\n",
      "Iteration 670, Loss: 7.055071182549e-05, Min w: 0.8198059797286987\n",
      "Iteration 680, Loss: 6.884232425363734e-05, Min w: 0.8236538171768188\n",
      "Iteration 690, Loss: 6.809982005506754e-05, Min w: 0.8256622552871704\n",
      "Iteration 700, Loss: 9.020152356242761e-05, Min w: 0.8051885366439819\n",
      "Iteration 710, Loss: 8.73875105753541e-05, Min w: 0.8143299221992493\n",
      "Iteration 720, Loss: 7.164220733102411e-05, Min w: 0.8210205435752869\n",
      "Iteration 730, Loss: 6.990958354435861e-05, Min w: 0.8243905305862427\n",
      "Iteration 740, Loss: 7.385401841020212e-05, Min w: 0.8236600756645203\n",
      "Iteration 750, Loss: 6.914485857123509e-05, Min w: 0.8288910984992981\n",
      "Iteration 760, Loss: 6.832263170508668e-05, Min w: 0.8274137377738953\n",
      "Iteration 770, Loss: 6.734440830769017e-05, Min w: 0.8312745094299316\n",
      "Iteration 780, Loss: 6.714370101690292e-05, Min w: 0.8319748044013977\n",
      "Iteration 790, Loss: 8.028683078009635e-05, Min w: 0.8150724172592163\n",
      "Iteration 800, Loss: 7.552847091574222e-05, Min w: 0.8245211839675903\n",
      "Iteration 810, Loss: 6.675739132333547e-05, Min w: 0.8365033864974976\n",
      "Iteration 820, Loss: 6.572633719770238e-05, Min w: 0.8378428816795349\n",
      "Iteration 830, Loss: 6.832617509644479e-05, Min w: 0.8349430561065674\n",
      "Iteration 840, Loss: 6.3805200625211e-05, Min w: 0.8392489552497864\n",
      "Iteration 850, Loss: 6.590868724742904e-05, Min w: 0.8369483351707458\n",
      "Iteration 860, Loss: 6.928678340045735e-05, Min w: 0.8388209342956543\n",
      "Iteration 870, Loss: 6.4367130107712e-05, Min w: 0.8381372690200806\n",
      "Iteration 880, Loss: 6.68039865558967e-05, Min w: 0.8402817845344543\n",
      "Iteration 890, Loss: 6.312044570222497e-05, Min w: 0.8434314131736755\n",
      "Iteration 900, Loss: 6.305067654466256e-05, Min w: 0.8390202522277832\n",
      "Iteration 910, Loss: 6.360290717566386e-05, Min w: 0.8421623706817627\n",
      "Iteration 920, Loss: 6.361837586155161e-05, Min w: 0.8451657891273499\n",
      "Iteration 930, Loss: 6.001762449159287e-05, Min w: 0.8500054478645325\n",
      "Iteration 940, Loss: 6.082508116378449e-05, Min w: 0.8479780554771423\n",
      "Iteration 950, Loss: 6.501388998003677e-05, Min w: 0.8486268520355225\n",
      "Iteration 960, Loss: 5.9712372603826225e-05, Min w: 0.8487808108329773\n",
      "Iteration 970, Loss: 5.96828613197431e-05, Min w: 0.8509328961372375\n",
      "Iteration 980, Loss: 5.8356697991257533e-05, Min w: 0.8557842373847961\n",
      "Iteration 990, Loss: 6.054841651348397e-05, Min w: 0.8502223491668701\n",
      "Iteration 1000, Loss: 5.964041338302195e-05, Min w: 0.8538143038749695\n",
      "Iteration 1010, Loss: 7.526526314904913e-05, Min w: 0.8373536467552185\n",
      "Iteration 1020, Loss: 6.0841022786917165e-05, Min w: 0.8546411395072937\n",
      "Iteration 1030, Loss: 6.0247606597840786e-05, Min w: 0.8490170836448669\n",
      "Iteration 1040, Loss: 5.999026325298473e-05, Min w: 0.8541871309280396\n",
      "Iteration 1050, Loss: 5.787926784250885e-05, Min w: 0.8576311469078064\n",
      "Iteration 1060, Loss: 5.999175846227445e-05, Min w: 0.8588882088661194\n",
      "Iteration 1070, Loss: 6.402299186447635e-05, Min w: 0.8563887476921082\n",
      "Iteration 1080, Loss: 6.446827319450676e-05, Min w: 0.8566001057624817\n",
      "Iteration 1090, Loss: 5.69366202398669e-05, Min w: 0.8614585399627686\n",
      "Iteration 1100, Loss: 5.544522718992084e-05, Min w: 0.8631510734558105\n",
      "Iteration 1110, Loss: 5.812483504996635e-05, Min w: 0.8573154211044312\n",
      "Iteration 1120, Loss: 6.370955816237256e-05, Min w: 0.8552069664001465\n",
      "Iteration 1130, Loss: 6.411629874492064e-05, Min w: 0.8562198877334595\n",
      "Iteration 1140, Loss: 5.386144403018989e-05, Min w: 0.8642836213111877\n",
      "Iteration 1150, Loss: 5.6851760746212676e-05, Min w: 0.8619053363800049\n",
      "Iteration 1160, Loss: 5.488048918778077e-05, Min w: 0.8668298125267029\n",
      "Iteration 1170, Loss: 5.59602485736832e-05, Min w: 0.8678356409072876\n",
      "Iteration 1180, Loss: 6.084576671128161e-05, Min w: 0.8584834933280945\n",
      "Iteration 1190, Loss: 6.43959574517794e-05, Min w: 0.8647814989089966\n",
      "Iteration 1200, Loss: 5.6292996305273846e-05, Min w: 0.8707939386367798\n",
      "Iteration 1210, Loss: 5.307017272571102e-05, Min w: 0.872269868850708\n",
      "Iteration 1220, Loss: 5.6562654208391905e-05, Min w: 0.8636272549629211\n",
      "Iteration 1230, Loss: 5.6161814427468926e-05, Min w: 0.8669608235359192\n",
      "Iteration 1240, Loss: 5.779987259302288e-05, Min w: 0.8650287389755249\n",
      "Iteration 0, Loss: 5.196168785914779e-05, Min w: 0.8705506324768066\n",
      "Iteration 10, Loss: 5.22312184330076e-05, Min w: 0.8748601675033569\n",
      "Iteration 20, Loss: 5.296136805554852e-05, Min w: 0.8723318576812744\n",
      "Iteration 30, Loss: 5.024506390327588e-05, Min w: 0.875751793384552\n",
      "Iteration 40, Loss: 5.329416671884246e-05, Min w: 0.8744868040084839\n",
      "Iteration 50, Loss: 5.133442391525023e-05, Min w: 0.8755045533180237\n",
      "Iteration 60, Loss: 5.601866723736748e-05, Min w: 0.8745310306549072\n",
      "Iteration 70, Loss: 4.9990383558906615e-05, Min w: 0.878317654132843\n",
      "Iteration 80, Loss: 5.047198646934703e-05, Min w: 0.877983033657074\n",
      "Iteration 90, Loss: 4.964331674273126e-05, Min w: 0.879037618637085\n",
      "Iteration 100, Loss: 5.0583897973410785e-05, Min w: 0.876517117023468\n",
      "Iteration 110, Loss: 5.030454121879302e-05, Min w: 0.8788996338844299\n",
      "Iteration 120, Loss: 4.890648779110052e-05, Min w: 0.8836430907249451\n",
      "Iteration 130, Loss: 5.309064363245852e-05, Min w: 0.8809490203857422\n",
      "Iteration 140, Loss: 5.388048884924501e-05, Min w: 0.8762946128845215\n",
      "Iteration 150, Loss: 4.926036490360275e-05, Min w: 0.8819090127944946\n",
      "Iteration 160, Loss: 5.03286937600933e-05, Min w: 0.8814775347709656\n",
      "Iteration 170, Loss: 5.172496094019152e-05, Min w: 0.8807456493377686\n",
      "Iteration 180, Loss: 5.7453959016129375e-05, Min w: 0.8748798370361328\n",
      "Iteration 190, Loss: 4.705382525571622e-05, Min w: 0.8848153352737427\n",
      "Iteration 200, Loss: 5.582877201959491e-05, Min w: 0.8819892406463623\n",
      "Iteration 210, Loss: 4.7014753363328055e-05, Min w: 0.8854789733886719\n",
      "Iteration 220, Loss: 4.786691351910122e-05, Min w: 0.8851639628410339\n",
      "Iteration 230, Loss: 5.402024544309825e-05, Min w: 0.8845880627632141\n",
      "Iteration 240, Loss: 4.5787095587002113e-05, Min w: 0.8899108171463013\n",
      "Iteration 250, Loss: 5.886441431357525e-05, Min w: 0.8770821690559387\n",
      "Iteration 260, Loss: 5.7604091125540435e-05, Min w: 0.8801857829093933\n",
      "Iteration 270, Loss: 5.921365664107725e-05, Min w: 0.8776223063468933\n",
      "Iteration 280, Loss: 5.45397779205814e-05, Min w: 0.8834474682807922\n",
      "Iteration 290, Loss: 4.5201846660347655e-05, Min w: 0.889534592628479\n",
      "Iteration 300, Loss: 5.3914085583528504e-05, Min w: 0.8864914178848267\n",
      "Iteration 310, Loss: 5.086996316094883e-05, Min w: 0.8879746198654175\n",
      "Iteration 320, Loss: 4.81507922813762e-05, Min w: 0.8900752663612366\n",
      "Iteration 330, Loss: 4.650870323530398e-05, Min w: 0.8951488137245178\n",
      "Iteration 340, Loss: 4.5215005229692906e-05, Min w: 0.89219069480896\n",
      "Iteration 350, Loss: 4.620199979399331e-05, Min w: 0.8900388479232788\n",
      "Iteration 360, Loss: 5.0187576562166214e-05, Min w: 0.8908896446228027\n",
      "Iteration 370, Loss: 4.756862108479254e-05, Min w: 0.8932819962501526\n",
      "Iteration 380, Loss: 5.4904798162169755e-05, Min w: 0.8872767686843872\n",
      "Iteration 390, Loss: 4.552993777906522e-05, Min w: 0.8962374329566956\n",
      "Iteration 400, Loss: 4.954058022121899e-05, Min w: 0.8922589421272278\n",
      "Iteration 410, Loss: 4.5007920562056825e-05, Min w: 0.8951465487480164\n",
      "Iteration 420, Loss: 4.680691927205771e-05, Min w: 0.8954540491104126\n",
      "Iteration 430, Loss: 4.6713961637578905e-05, Min w: 0.8938391804695129\n",
      "Iteration 440, Loss: 4.955457188771106e-05, Min w: 0.8926039338111877\n",
      "Iteration 450, Loss: 4.431545312399976e-05, Min w: 0.8987389206886292\n",
      "Iteration 460, Loss: 4.2300471250200644e-05, Min w: 0.8998665809631348\n",
      "Iteration 470, Loss: 5.072960630059242e-05, Min w: 0.8962745666503906\n",
      "Iteration 480, Loss: 4.5308774133445695e-05, Min w: 0.8995082974433899\n",
      "Iteration 490, Loss: 5.164035246707499e-05, Min w: 0.8908984065055847\n",
      "Iteration 500, Loss: 4.176455695414916e-05, Min w: 0.9051476716995239\n",
      "Iteration 510, Loss: 4.243036164552905e-05, Min w: 0.9016329646110535\n",
      "Iteration 520, Loss: 4.4633114157477394e-05, Min w: 0.8982963562011719\n",
      "Iteration 530, Loss: 4.3295785872032866e-05, Min w: 0.9003279805183411\n",
      "Iteration 540, Loss: 4.1916704503819346e-05, Min w: 0.9034057855606079\n",
      "Iteration 550, Loss: 4.5860448153689504e-05, Min w: 0.9007775783538818\n",
      "Iteration 560, Loss: 4.63273172499612e-05, Min w: 0.8980929255485535\n",
      "Iteration 570, Loss: 4.972206079401076e-05, Min w: 0.8953554630279541\n",
      "Iteration 580, Loss: 4.051441646879539e-05, Min w: 0.9051557183265686\n",
      "Iteration 590, Loss: 4.356690260465257e-05, Min w: 0.8994021415710449\n",
      "Iteration 600, Loss: 4.089386493433267e-05, Min w: 0.904610812664032\n",
      "Iteration 610, Loss: 4.347516005509533e-05, Min w: 0.9022036790847778\n",
      "Iteration 620, Loss: 6.195827154442668e-05, Min w: 0.8577836155891418\n",
      "Iteration 630, Loss: 4.0819715650286525e-05, Min w: 0.9050822854042053\n",
      "Iteration 640, Loss: 4.106492269784212e-05, Min w: 0.9070945382118225\n",
      "Iteration 650, Loss: 4.014293153886683e-05, Min w: 0.9067348837852478\n",
      "Iteration 660, Loss: 4.212068233755417e-05, Min w: 0.907258152961731\n",
      "Iteration 670, Loss: 6.222276715561748e-05, Min w: 0.8545988202095032\n",
      "Iteration 680, Loss: 3.822232611128129e-05, Min w: 0.9119417667388916\n",
      "Iteration 690, Loss: 4.923090818920173e-05, Min w: 0.8973561525344849\n",
      "Iteration 700, Loss: 4.8552374209975824e-05, Min w: 0.8999645709991455\n",
      "Iteration 710, Loss: 4.0055503632174805e-05, Min w: 0.9090215563774109\n",
      "Iteration 720, Loss: 3.9167865907074884e-05, Min w: 0.9089199900627136\n",
      "Iteration 730, Loss: 4.384766725706868e-05, Min w: 0.909888505935669\n",
      "Iteration 740, Loss: 3.897100759786554e-05, Min w: 0.912439227104187\n",
      "Iteration 750, Loss: 3.9110909710871056e-05, Min w: 0.9129804968833923\n",
      "Iteration 760, Loss: 4.091144000994973e-05, Min w: 0.9109234809875488\n",
      "Iteration 770, Loss: 4.282278678147122e-05, Min w: 0.9068440794944763\n",
      "Iteration 780, Loss: 3.8232854421949014e-05, Min w: 0.9105361700057983\n",
      "Iteration 790, Loss: 3.835041570710018e-05, Min w: 0.9125848412513733\n",
      "Iteration 800, Loss: 3.990613913629204e-05, Min w: 0.9117318391799927\n",
      "Iteration 810, Loss: 3.6586567148333415e-05, Min w: 0.9138875007629395\n",
      "Iteration 820, Loss: 3.924961492884904e-05, Min w: 0.9127696752548218\n",
      "Iteration 830, Loss: 3.764916255022399e-05, Min w: 0.9158350229263306\n",
      "Iteration 840, Loss: 3.897121496265754e-05, Min w: 0.9145948886871338\n",
      "Iteration 850, Loss: 3.550434848875739e-05, Min w: 0.9171035885810852\n",
      "Iteration 860, Loss: 4.131869718548842e-05, Min w: 0.9130665063858032\n",
      "Iteration 870, Loss: 3.955717693315819e-05, Min w: 0.9144930839538574\n",
      "Iteration 880, Loss: 4.028969124192372e-05, Min w: 0.9174622893333435\n",
      "Iteration 890, Loss: 4.864814764005132e-05, Min w: 0.8950214982032776\n",
      "Iteration 900, Loss: 3.819040648522787e-05, Min w: 0.9147648215293884\n",
      "Iteration 910, Loss: 3.623956217779778e-05, Min w: 0.9164090752601624\n",
      "Iteration 920, Loss: 4.0713377529755235e-05, Min w: 0.9130368828773499\n",
      "Iteration 930, Loss: 3.8066020351834595e-05, Min w: 0.9175640344619751\n",
      "Iteration 940, Loss: 3.776760786422528e-05, Min w: 0.9168052673339844\n",
      "Iteration 950, Loss: 3.5479846701491624e-05, Min w: 0.92032790184021\n",
      "Iteration 960, Loss: 3.695593113661744e-05, Min w: 0.9174616932868958\n",
      "Iteration 970, Loss: 3.4486442018533126e-05, Min w: 0.9222220182418823\n",
      "Iteration 980, Loss: 4.13941997976508e-05, Min w: 0.9137544631958008\n",
      "Iteration 990, Loss: 3.499832018860616e-05, Min w: 0.9209903478622437\n",
      "Iteration 1000, Loss: 3.4681546821957454e-05, Min w: 0.9201300740242004\n",
      "Iteration 1010, Loss: 3.927490615751594e-05, Min w: 0.9171377420425415\n",
      "Iteration 1020, Loss: 3.7784466258017346e-05, Min w: 0.9209176301956177\n",
      "Iteration 1030, Loss: 4.48604223493021e-05, Min w: 0.9067655801773071\n",
      "Iteration 1040, Loss: 4.421694393386133e-05, Min w: 0.9047579765319824\n",
      "Iteration 1050, Loss: 3.650756480055861e-05, Min w: 0.9202088117599487\n",
      "Iteration 1060, Loss: 3.4096236049663275e-05, Min w: 0.9237971901893616\n",
      "Iteration 1070, Loss: 3.363546420587227e-05, Min w: 0.9254040718078613\n",
      "Iteration 1080, Loss: 3.4249347663717344e-05, Min w: 0.923651933670044\n",
      "Iteration 1090, Loss: 3.9637201552977785e-05, Min w: 0.9176041483879089\n",
      "Iteration 1100, Loss: 4.7353685658890754e-05, Min w: 0.892650306224823\n",
      "Iteration 1110, Loss: 3.7605950637953356e-05, Min w: 0.9204888939857483\n",
      "Iteration 1120, Loss: 3.394839950487949e-05, Min w: 0.9225245118141174\n",
      "Iteration 1130, Loss: 3.368945181136951e-05, Min w: 0.925571620464325\n",
      "Iteration 1140, Loss: 3.3262513170484453e-05, Min w: 0.9250043630599976\n",
      "Iteration 1150, Loss: 3.6350411392049864e-05, Min w: 0.9213597774505615\n",
      "Iteration 1160, Loss: 3.290712265879847e-05, Min w: 0.9275453686714172\n",
      "Iteration 1170, Loss: 4.37767303083092e-05, Min w: 0.9066505432128906\n",
      "Iteration 1180, Loss: 4.713079397333786e-05, Min w: 0.8911302089691162\n",
      "Iteration 1190, Loss: 3.422158624744043e-05, Min w: 0.9259852170944214\n",
      "Iteration 1200, Loss: 4.700733188656159e-05, Min w: 0.8919203281402588\n",
      "Iteration 1210, Loss: 4.678502955357544e-05, Min w: 0.888122022151947\n",
      "Iteration 1220, Loss: 3.262498285039328e-05, Min w: 0.927463948726654\n",
      "Iteration 1230, Loss: 3.367727549630217e-05, Min w: 0.9243918657302856\n",
      "Iteration 1240, Loss: 3.2813273719511926e-05, Min w: 0.929075300693512\n",
      "Iteration 0, Loss: 4.512711529969238e-05, Min w: 0.8951587080955505\n",
      "Iteration 10, Loss: 3.988516255049035e-05, Min w: 0.9138896465301514\n",
      "Iteration 20, Loss: 3.451152588240802e-05, Min w: 0.9266197681427002\n",
      "Iteration 30, Loss: 3.1825726182432845e-05, Min w: 0.9296907782554626\n",
      "Iteration 40, Loss: 3.175760502927005e-05, Min w: 0.9289094805717468\n",
      "Iteration 50, Loss: 3.2030900911195204e-05, Min w: 0.9299260973930359\n",
      "Iteration 60, Loss: 3.196408579242416e-05, Min w: 0.9297138452529907\n",
      "Iteration 70, Loss: 3.255275441915728e-05, Min w: 0.9272555708885193\n",
      "Iteration 80, Loss: 3.0753253668081015e-05, Min w: 0.9313303232192993\n",
      "Iteration 90, Loss: 4.398232704261318e-05, Min w: 0.8951101899147034\n",
      "Iteration 100, Loss: 3.433622987358831e-05, Min w: 0.9288313984870911\n",
      "Iteration 110, Loss: 3.1037045118864626e-05, Min w: 0.9304589033126831\n",
      "Iteration 120, Loss: 3.556317096808925e-05, Min w: 0.9258427023887634\n",
      "Iteration 130, Loss: 3.1035069696372375e-05, Min w: 0.9319613575935364\n",
      "Iteration 140, Loss: 3.511172326398082e-05, Min w: 0.9271162152290344\n",
      "Iteration 150, Loss: 3.216508048353717e-05, Min w: 0.9317539930343628\n",
      "Iteration 160, Loss: 3.0387049264390953e-05, Min w: 0.9357077479362488\n",
      "Iteration 170, Loss: 3.197178375557996e-05, Min w: 0.9337362051010132\n",
      "Iteration 180, Loss: 4.666863242164254e-05, Min w: 0.8879755139350891\n",
      "Iteration 190, Loss: 3.079421730944887e-05, Min w: 0.9341163635253906\n",
      "Iteration 200, Loss: 3.115267099929042e-05, Min w: 0.9351110458374023\n",
      "Iteration 210, Loss: 4.210514816804789e-05, Min w: 0.9057840704917908\n",
      "Iteration 220, Loss: 2.9519009331124835e-05, Min w: 0.9368032813072205\n",
      "Iteration 230, Loss: 2.9836668545613065e-05, Min w: 0.9339156150817871\n",
      "Iteration 240, Loss: 3.193742304574698e-05, Min w: 0.9342659711837769\n",
      "Iteration 250, Loss: 3.1079875043360516e-05, Min w: 0.9330691695213318\n",
      "Iteration 260, Loss: 3.7233108741929755e-05, Min w: 0.9181175827980042\n",
      "Iteration 270, Loss: 3.382139766472392e-05, Min w: 0.9269381761550903\n",
      "Iteration 280, Loss: 3.717002255143598e-05, Min w: 0.918630063533783\n",
      "Iteration 290, Loss: 3.3015781809808686e-05, Min w: 0.9318491816520691\n",
      "Iteration 300, Loss: 2.938162833743263e-05, Min w: 0.9385247826576233\n",
      "Iteration 310, Loss: 3.0702693038620055e-05, Min w: 0.9363565444946289\n",
      "Iteration 320, Loss: 3.673310857266188e-05, Min w: 0.914638876914978\n",
      "Iteration 330, Loss: 2.8790516807930544e-05, Min w: 0.9360925555229187\n",
      "Iteration 340, Loss: 2.960787242045626e-05, Min w: 0.9369928240776062\n",
      "Iteration 350, Loss: 3.0749190045753494e-05, Min w: 0.9369581341743469\n",
      "Iteration 360, Loss: 3.1899366149445996e-05, Min w: 0.9319684505462646\n",
      "Iteration 370, Loss: 2.8299369660089724e-05, Min w: 0.939422070980072\n",
      "Iteration 380, Loss: 3.496931822155602e-05, Min w: 0.9228468537330627\n",
      "Iteration 390, Loss: 2.960284473374486e-05, Min w: 0.9362368583679199\n",
      "Iteration 400, Loss: 3.062859468627721e-05, Min w: 0.935880720615387\n",
      "Iteration 410, Loss: 3.256699346820824e-05, Min w: 0.932863175868988\n",
      "Iteration 420, Loss: 2.87791572191054e-05, Min w: 0.9402219653129578\n",
      "Iteration 430, Loss: 2.9079164960421622e-05, Min w: 0.9394012689590454\n",
      "Iteration 440, Loss: 3.06459805869963e-05, Min w: 0.9361040592193604\n",
      "Iteration 450, Loss: 2.939289333880879e-05, Min w: 0.9372982978820801\n",
      "Iteration 460, Loss: 3.0509894713759422e-05, Min w: 0.9365484714508057\n",
      "Iteration 470, Loss: 3.6919471313012764e-05, Min w: 0.9141464829444885\n",
      "Iteration 480, Loss: 4.218988397042267e-05, Min w: 0.8996468782424927\n",
      "Iteration 490, Loss: 3.015038419107441e-05, Min w: 0.9361568689346313\n",
      "Iteration 500, Loss: 2.7990863600280136e-05, Min w: 0.9401075839996338\n",
      "Iteration 510, Loss: 3.0128021535347216e-05, Min w: 0.9356303215026855\n",
      "Iteration 520, Loss: 2.978549491672311e-05, Min w: 0.9376505017280579\n",
      "Iteration 530, Loss: 2.7405654691392556e-05, Min w: 0.9431259632110596\n",
      "Iteration 540, Loss: 3.366751116118394e-05, Min w: 0.9247673749923706\n",
      "Iteration 550, Loss: 2.7359476007404737e-05, Min w: 0.9412437677383423\n",
      "Iteration 560, Loss: 2.8363880119286478e-05, Min w: 0.9410780072212219\n",
      "Iteration 570, Loss: 4.003288995590992e-05, Min w: 0.9036797881126404\n",
      "Iteration 580, Loss: 3.5283366742078215e-05, Min w: 0.9192336201667786\n",
      "Iteration 590, Loss: 2.7924863388761878e-05, Min w: 0.9424765110015869\n",
      "Iteration 600, Loss: 2.6928148145088926e-05, Min w: 0.9447609782218933\n",
      "Iteration 610, Loss: 3.1491174013353884e-05, Min w: 0.9332923293113708\n",
      "Iteration 620, Loss: 4.029118281323463e-05, Min w: 0.8993347883224487\n",
      "Iteration 630, Loss: 2.948620203824248e-05, Min w: 0.9352649450302124\n",
      "Iteration 640, Loss: 2.675327232282143e-05, Min w: 0.9427587389945984\n",
      "Iteration 650, Loss: 3.384738010936417e-05, Min w: 0.9255767464637756\n",
      "Iteration 660, Loss: 3.764463690458797e-05, Min w: 0.9095231890678406\n",
      "Iteration 670, Loss: 3.455294790910557e-05, Min w: 0.9209716320037842\n",
      "Iteration 680, Loss: 3.0387493097805418e-05, Min w: 0.9342495203018188\n",
      "Iteration 690, Loss: 2.7623003916232847e-05, Min w: 0.9419918656349182\n",
      "Iteration 700, Loss: 2.8360971555230208e-05, Min w: 0.9417718052864075\n",
      "Iteration 710, Loss: 3.1120882340474054e-05, Min w: 0.9295329451560974\n",
      "Iteration 720, Loss: 2.641841274453327e-05, Min w: 0.9445382952690125\n",
      "Iteration 730, Loss: 2.803769712045323e-05, Min w: 0.9417464733123779\n",
      "Iteration 740, Loss: 3.772396667045541e-05, Min w: 0.9094365835189819\n",
      "Iteration 750, Loss: 2.7650821721181273e-05, Min w: 0.9403733611106873\n",
      "Iteration 760, Loss: 2.9883720344514586e-05, Min w: 0.9343418478965759\n",
      "Iteration 770, Loss: 2.8338070478639565e-05, Min w: 0.9407302737236023\n",
      "Iteration 780, Loss: 2.691556073841639e-05, Min w: 0.9440305829048157\n",
      "Iteration 790, Loss: 2.886389847844839e-05, Min w: 0.9376399517059326\n",
      "Iteration 800, Loss: 2.853536352631636e-05, Min w: 0.9415627717971802\n",
      "Iteration 810, Loss: 3.014351023011841e-05, Min w: 0.9337881207466125\n",
      "Iteration 820, Loss: 2.6144405637751333e-05, Min w: 0.9463096857070923\n",
      "Iteration 830, Loss: 3.2310748792951927e-05, Min w: 0.9246891736984253\n",
      "Iteration 840, Loss: 3.212994852219708e-05, Min w: 0.928040623664856\n",
      "Iteration 850, Loss: 2.5309207558166236e-05, Min w: 0.9468055367469788\n",
      "Iteration 860, Loss: 2.56293969869148e-05, Min w: 0.9464781880378723\n",
      "Iteration 870, Loss: 2.5819756046985276e-05, Min w: 0.9454282522201538\n",
      "Iteration 880, Loss: 2.579664214863442e-05, Min w: 0.9466549754142761\n",
      "Iteration 890, Loss: 2.595950172690209e-05, Min w: 0.945476770401001\n",
      "Iteration 900, Loss: 3.265549457864836e-05, Min w: 0.9218243956565857\n",
      "Iteration 910, Loss: 2.567173032730352e-05, Min w: 0.9452242851257324\n",
      "Iteration 920, Loss: 2.596113881736528e-05, Min w: 0.944327712059021\n",
      "Iteration 930, Loss: 2.6136094675166532e-05, Min w: 0.9443824887275696\n",
      "Iteration 940, Loss: 2.643086736497935e-05, Min w: 0.9455288052558899\n",
      "Iteration 950, Loss: 2.8933980502188206e-05, Min w: 0.9361387491226196\n",
      "Iteration 960, Loss: 2.7507769118528813e-05, Min w: 0.9390649795532227\n",
      "Iteration 970, Loss: 2.9333228667383082e-05, Min w: 0.9363448619842529\n",
      "Iteration 980, Loss: 3.2321946491720155e-05, Min w: 0.922675371170044\n",
      "Iteration 990, Loss: 2.540046625654213e-05, Min w: 0.9472389221191406\n",
      "Iteration 1000, Loss: 2.5088154870900325e-05, Min w: 0.9480612277984619\n",
      "Iteration 1010, Loss: 2.9398230253718793e-05, Min w: 0.9311826229095459\n",
      "Iteration 1020, Loss: 2.5075140001717955e-05, Min w: 0.9475124478340149\n",
      "Iteration 1030, Loss: 2.9623381124110892e-05, Min w: 0.9321202635765076\n",
      "Iteration 1040, Loss: 4.239184636389837e-05, Min w: 0.8836978673934937\n",
      "Iteration 1050, Loss: 3.019810901605524e-05, Min w: 0.9343246817588806\n",
      "Iteration 1060, Loss: 2.610807860037312e-05, Min w: 0.9413109421730042\n",
      "Iteration 1070, Loss: 2.544211019994691e-05, Min w: 0.944377601146698\n",
      "Iteration 1080, Loss: 2.428235711704474e-05, Min w: 0.9489105939865112\n",
      "Iteration 1090, Loss: 2.5534318410791457e-05, Min w: 0.9457982182502747\n",
      "Iteration 1100, Loss: 2.676519397937227e-05, Min w: 0.9420859217643738\n",
      "Iteration 1110, Loss: 2.7705589673132636e-05, Min w: 0.9379046559333801\n",
      "Iteration 1120, Loss: 2.761130963335745e-05, Min w: 0.9374915957450867\n",
      "Iteration 1130, Loss: 2.8625661798287183e-05, Min w: 0.9341619610786438\n",
      "Iteration 1140, Loss: 2.757577021839097e-05, Min w: 0.9373112320899963\n",
      "Iteration 1150, Loss: 2.9331295081647113e-05, Min w: 0.9301828742027283\n",
      "Iteration 1160, Loss: 2.889867391786538e-05, Min w: 0.9306624531745911\n",
      "Iteration 1170, Loss: 3.2091844332171604e-05, Min w: 0.9226943850517273\n",
      "Iteration 1180, Loss: 2.9803873985656537e-05, Min w: 0.9305172562599182\n",
      "Iteration 1190, Loss: 2.3603408408234827e-05, Min w: 0.9495023488998413\n",
      "Iteration 1200, Loss: 2.7642639906844124e-05, Min w: 0.9353145956993103\n",
      "Iteration 1210, Loss: 2.366476292081643e-05, Min w: 0.9489684104919434\n",
      "Iteration 1220, Loss: 2.3918824808788486e-05, Min w: 0.949383020401001\n",
      "Iteration 1230, Loss: 2.277926614624448e-05, Min w: 0.9531084895133972\n",
      "Iteration 1240, Loss: 3.125310831819661e-05, Min w: 0.9230555295944214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP: 100%|██████████| 24/24 [41:31<00:00, 103.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.01728246454996065, 'L2_avg': 0.026195075354239577, 'End_point_L1_avg': 0.008409890396875527, 'End_point_L2_avg': 0.008998345645500283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.004056314472109079, Min w: 0.0009106809156946838\n",
      "Iteration 10, Loss: 0.0022064370568841696, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002079342259094119, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002183409407734871, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0019114474998787045, Min w: 2.1423500994044442e-12\n",
      "Iteration 50, Loss: 0.002166739199310541, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0023213576059788465, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0022299427073448896, Min w: 3.180947514017335e-42\n",
      "Iteration 80, Loss: 0.0018823170103132725, Min w: 2.1471137232214977e-25\n",
      "Iteration 90, Loss: 0.002415415598079562, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0020751527044922113, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002115588868036866, Min w: 0.0\n",
      "Iteration 120, Loss: 0.00212798616848886, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0021908595226705074, Min w: 2.589427644533136e-19\n",
      "Iteration 140, Loss: 0.0022103777155280113, Min w: 0.000552636687643826\n",
      "Iteration 150, Loss: 0.0022140454966574907, Min w: 5.6542911899912923e-14\n",
      "Iteration 160, Loss: 0.002217178698629141, Min w: 2.9048385224994533e-11\n",
      "Iteration 170, Loss: 0.0023228826466947794, Min w: 2.7121837761767686e-13\n",
      "Iteration 180, Loss: 0.001976922620087862, Min w: 0.00014684628695249557\n",
      "Iteration 190, Loss: 0.002202931558713317, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002123888349160552, Min w: 4.287005424855697e-24\n",
      "Iteration 210, Loss: 0.0021627757232636213, Min w: 5.692724514005931e-08\n",
      "Iteration 220, Loss: 0.0022164126858115196, Min w: 0.00025361779262311757\n",
      "Iteration 230, Loss: 0.0020287251099944115, Min w: 4.4421286342547194e-17\n",
      "Iteration 240, Loss: 0.0024489094503223896, Min w: 4.882604320854966e-10\n",
      "Iteration 250, Loss: 0.0021874569356441498, Min w: 0.010577153414487839\n",
      "Iteration 260, Loss: 0.002176644280552864, Min w: 1.3872854796815689e-43\n",
      "Iteration 270, Loss: 0.0021263931412249804, Min w: 5.6529423800200405e-18\n",
      "Iteration 280, Loss: 0.002360111568123102, Min w: 0.003122524358332157\n",
      "Iteration 290, Loss: 0.002068860223516822, Min w: 1.1571254623761137e-15\n",
      "Iteration 300, Loss: 0.0020411305595189333, Min w: 0.004152488894760609\n",
      "Iteration 310, Loss: 0.002113787457346916, Min w: 0.00516148516908288\n",
      "Iteration 320, Loss: 0.0022809167858213186, Min w: 6.582742299388392e-14\n",
      "Iteration 330, Loss: 0.002254253486171365, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0025629871524870396, Min w: 7.909621850717141e-13\n",
      "Iteration 350, Loss: 0.0024111319798976183, Min w: 6.066684932193311e-08\n",
      "Iteration 360, Loss: 0.0022053164429962635, Min w: 1.3823704680948623e-10\n",
      "Iteration 370, Loss: 0.0022845547646284103, Min w: 2.703010477806228e-29\n",
      "Iteration 380, Loss: 0.0022742084693163633, Min w: 1.853942943250195e-20\n",
      "Iteration 390, Loss: 0.002124092075973749, Min w: 3.2474231637102946e-12\n",
      "Iteration 400, Loss: 0.0022474525030702353, Min w: 3.165728230669629e-07\n",
      "Iteration 410, Loss: 0.002102689119055867, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002122587990015745, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002186223166063428, Min w: 4.825854205137148e-08\n",
      "Iteration 440, Loss: 0.0023116786032915115, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0026042009703814983, Min w: 2.7111131584061885e-39\n",
      "Iteration 460, Loss: 0.002853135112673044, Min w: 6.324726195720896e-16\n",
      "Iteration 470, Loss: 0.0018966859206557274, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0023876370396465063, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0023874237667769194, Min w: 2.473291789533302e-42\n",
      "Iteration 500, Loss: 0.0017734973225742579, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002191899809986353, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002264486625790596, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0020613870583474636, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0021771984174847603, Min w: 7.111029633514142e-15\n",
      "Iteration 550, Loss: 0.0022946815006434917, Min w: 3.481070611417308e-25\n",
      "Iteration 560, Loss: 0.002219288144260645, Min w: 8.96831017167883e-44\n",
      "Iteration 570, Loss: 0.0023714853450655937, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002479829825460911, Min w: 0.0\n",
      "Iteration 590, Loss: 0.00261068157851696, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0016914168372750282, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0028436698485165834, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0028312948998063803, Min w: 0.0\n",
      "Iteration 630, Loss: 0.003405289724469185, Min w: 1.1307059641065911e-35\n",
      "Iteration 640, Loss: 0.0023454963229596615, Min w: 0.0\n",
      "Iteration 650, Loss: 0.003140945453196764, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0032988686580210924, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0026390128768980503, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0028624325059354305, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0033180215395987034, Min w: 0.0\n",
      "Iteration 700, Loss: 0.002164600184187293, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0022454620338976383, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0021408176980912685, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0034027884248644114, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0036076009273529053, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002626686356961727, Min w: 0.0\n",
      "Iteration 760, Loss: 0.00329373637214303, Min w: 3.095468307693521e-42\n",
      "Iteration 770, Loss: 0.0029546557925641537, Min w: 4.427598684095355e-31\n",
      "Iteration 780, Loss: 0.00266412110067904, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0029444932006299496, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0027135086711496115, Min w: 0.0\n",
      "Iteration 810, Loss: 0.003837492549791932, Min w: 0.0\n",
      "Iteration 820, Loss: 0.004664923530071974, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002461214317008853, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002123552607372403, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0025104486849159002, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0018588833045214415, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002358083613216877, Min w: 0.0\n",
      "Iteration 880, Loss: 0.002755408873781562, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002188559388741851, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002036042744293809, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0022587021812796593, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002270766068249941, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0022621548268944025, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002245918847620487, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0021061033476144075, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002147477585822344, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0022952246945351362, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002171555068343878, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0022961427457630634, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002141970442607999, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002224465599283576, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0023504632990807295, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.002773905638605356, Min w: 3.229509104585304e-09\n",
      "Iteration 1040, Loss: 0.0023237981367856264, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0023237052373588085, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002775432774797082, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.002319532446563244, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002451833803206682, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0025054707657545805, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002234863815829158, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.002097681164741516, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0019608139991760254, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0020325903315097094, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002108619548380375, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0016065374948084354, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0023639944847673178, Min w: 1.6952129787286044e-24\n",
      "Iteration 1170, Loss: 0.0023192763328552246, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0017105159349739552, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.002398753771558404, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002541982801631093, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.002156580565497279, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0024167215451598167, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0025892439298331738, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002139903837814927, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0022285389713943005, Min w: 0.0\n",
      "Iteration 10, Loss: 0.002646881388500333, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0024766921997070312, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002586255082860589, Min w: 0.0\n",
      "Iteration 40, Loss: 0.004460656549781561, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0038827366661280394, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002571315970271826, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002126729115843773, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0028305896557867527, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002292394870892167, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0023078203666955233, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0026098403614014387, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0027636082377284765, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0026637513656169176, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002181732328608632, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002160368487238884, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002353522228077054, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0021325640846043825, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002336315345019102, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002221321454271674, Min w: 7.322546926385204e-32\n",
      "Iteration 200, Loss: 0.0033154210541397333, Min w: 0.0\n",
      "Iteration 210, Loss: 0.002502423245459795, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0024627100210636854, Min w: 1.8931508711548237e-34\n",
      "Iteration 230, Loss: 0.002365442691370845, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0024414565414190292, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002364556072279811, Min w: 0.0\n",
      "Iteration 260, Loss: 0.002351396018639207, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0024060572031885386, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0023608184419572353, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002385538537055254, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0025020071770995855, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002485898556187749, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0022801680024713278, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002271263627335429, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002662134123966098, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002752970438450575, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0027354718185961246, Min w: 0.0\n",
      "Iteration 370, Loss: 0.00272155087441206, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002276635030284524, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0023199652787297964, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0022663853596895933, Min w: 0.0\n",
      "Iteration 410, Loss: 0.002453022636473179, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002710294909775257, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002832503756508231, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0028799374122172594, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002327562542632222, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0026202169246971607, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0025413059629499912, Min w: 0.0\n",
      "Iteration 480, Loss: 0.003154977224767208, Min w: 0.0\n",
      "Iteration 490, Loss: 0.002785243559628725, Min w: 0.0\n",
      "Iteration 500, Loss: 0.002916430588811636, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0025318569969385862, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00413929158821702, Min w: 3.108142574373909e-23\n",
      "Iteration 530, Loss: 0.0022742790170013905, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002627155277878046, Min w: 0.0\n",
      "Iteration 550, Loss: 0.003988312091678381, Min w: 1.7057552668180652e-15\n",
      "Iteration 560, Loss: 0.0026647739578038454, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0024154726415872574, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0023964259307831526, Min w: 0.0\n",
      "Iteration 590, Loss: 0.003054576925933361, Min w: 0.0\n",
      "Iteration 600, Loss: 0.00259291916154325, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002344500506296754, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0027097028214484453, Min w: 0.0\n",
      "Iteration 630, Loss: 0.003743631998077035, Min w: 3.188536875118453e-28\n",
      "Iteration 640, Loss: 0.0034993933513760567, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0034769908525049686, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0024685412645339966, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0025865398347377777, Min w: 1.7837638897654874e-34\n",
      "Iteration 680, Loss: 0.002686547115445137, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002818518318235874, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003216981189325452, Min w: 2.054766320886088e-21\n",
      "Iteration 710, Loss: 0.002350195776671171, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0026612598448991776, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002450216095894575, Min w: 0.0\n",
      "Iteration 740, Loss: 0.002541155554354191, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0022415260318666697, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0022407209035009146, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0021358891390264034, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002109694527462125, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002531725913286209, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0023474283516407013, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002735947724431753, Min w: 0.0\n",
      "Iteration 820, Loss: 0.003030484775081277, Min w: 1.8278087860618102e-32\n",
      "Iteration 830, Loss: 0.0022852884139865637, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002092936774715781, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002348170382902026, Min w: 0.0\n",
      "Iteration 860, Loss: 0.001844562590122223, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0024939628783613443, Min w: 0.0\n",
      "Iteration 880, Loss: 0.003001064294949174, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0027487168554216623, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002464007120579481, Min w: 0.0\n",
      "Iteration 910, Loss: 0.00273320940323174, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0034683565609157085, Min w: 0.0\n",
      "Iteration 930, Loss: 0.004031002055853605, Min w: 0.0\n",
      "Iteration 940, Loss: 0.00245314696803689, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0026123335119336843, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0024122679606080055, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0024959754664450884, Min w: 0.0\n",
      "Iteration 980, Loss: 0.00242892699316144, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002484911819919944, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002686034422367811, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.003033821238204837, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.00270919525064528, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.00589368212968111, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0026376538444310427, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0024561849422752857, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0027264466043561697, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0028338225092738867, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0026492485776543617, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.002773115411400795, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0035700493026524782, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0025093895383179188, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.003641559509560466, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0026161866262555122, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0025736032985150814, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.003034026827663183, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.003171466290950775, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0026689174119383097, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0063156019896268845, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.00250020669773221, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.003907524049282074, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0038027120754122734, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.003235634183511138, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0024801455438137054, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002500828355550766, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0027205932419747114, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0025944127701222897, Min w: 0.0\n",
      "Iteration 20, Loss: 0.003621174255385995, Min w: 0.0\n",
      "Iteration 30, Loss: 0.003653518157079816, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0037010889500379562, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00439779506996274, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0026927548460662365, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0029444885440170765, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0025332439690828323, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0030073055531829596, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0028778293635696173, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002879059175029397, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0025842050090432167, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002638560952618718, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0023933628108352423, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002678575459867716, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0025065650697797537, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0026875806506723166, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0032797951716929674, Min w: 1.3230228415115034e-29\n",
      "Iteration 190, Loss: 0.002534468425437808, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0030978797003626823, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00291345058940351, Min w: 0.0\n",
      "Iteration 220, Loss: 0.005583945196121931, Min w: 0.0\n",
      "Iteration 230, Loss: 0.003917848225682974, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0026633194647729397, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0053449575789272785, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0025638204533606768, Min w: 0.0\n",
      "Iteration 270, Loss: 0.003213792107999325, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0034752259962260723, Min w: 0.0\n",
      "Iteration 290, Loss: 0.003120324807241559, Min w: 0.0\n",
      "Iteration 300, Loss: 0.00267969211563468, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0027083298191428185, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0027206644881516695, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002793259685859084, Min w: 0.0\n",
      "Iteration 340, Loss: 0.004418067168444395, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0027494283858686686, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0031648222357034683, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002492551924660802, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0028335051611065865, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0029913634061813354, Min w: 0.0\n",
      "Iteration 400, Loss: 0.003893696004524827, Min w: 0.0\n",
      "Iteration 410, Loss: 0.002706236904487014, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0024631398264318705, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002650714246556163, Min w: 0.0\n",
      "Iteration 440, Loss: 0.003409074852243066, Min w: 2.9208777668780266e-30\n",
      "Iteration 450, Loss: 0.003233175491914153, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0029854148160666227, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0028137145563960075, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0028640315867960453, Min w: 1.401298464324817e-44\n",
      "Iteration 490, Loss: 0.0023802733048796654, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003065620781853795, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002859240397810936, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00308182998560369, Min w: 1.1712244483871913e-24\n",
      "Iteration 530, Loss: 0.0030888805631548166, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0028145844116806984, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0027205790393054485, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0027925039175897837, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0024628236424177885, Min w: 0.0\n",
      "Iteration 580, Loss: 0.004176913294941187, Min w: 1.8010883332565262e-36\n",
      "Iteration 590, Loss: 0.002726561389863491, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0024167520459741354, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0030291499570012093, Min w: 4.0081806058162365e-35\n",
      "Iteration 620, Loss: 0.0026232381351292133, Min w: 0.0\n",
      "Iteration 630, Loss: 0.002634585602208972, Min w: 0.0\n",
      "Iteration 640, Loss: 0.003736694110557437, Min w: 1.0562233589195033e-36\n",
      "Iteration 650, Loss: 0.002938313642516732, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0023542819544672966, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002786707365885377, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0034186283592134714, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0024498237762600183, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0022452473640441895, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0021059818100184202, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0023533222265541553, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0028230887837707996, Min w: 0.0\n",
      "Iteration 740, Loss: 0.002635611454024911, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0021913573145866394, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0029619471170008183, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0034874295815825462, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002708746585994959, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002777005545794964, Min w: 0.0\n",
      "Iteration 800, Loss: 0.00279625435359776, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0025451118126511574, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0032416963949799538, Min w: 0.0\n",
      "Iteration 830, Loss: 0.005849218461662531, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0033145390916615725, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0024284033570438623, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0025638826191425323, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0038573723286390305, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0035928995348513126, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002552787307649851, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002758515067398548, Min w: 0.0\n",
      "Iteration 910, Loss: 0.005267204251140356, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0026956861838698387, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0030787629075348377, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002688219305127859, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0025464219506829977, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0028069752734154463, Min w: 0.0\n",
      "Iteration 970, Loss: 0.002596489852294326, Min w: 0.0\n",
      "Iteration 980, Loss: 0.003309044288471341, Min w: 0.0\n",
      "Iteration 990, Loss: 0.003426192793995142, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002674716990441084, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.006979878526180983, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0028007004875689745, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0024592422414571047, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0031564575619995594, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0033456061501055956, Min w: 3.452846031045115e-26\n",
      "Iteration 1060, Loss: 0.002759041963145137, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.002711101435124874, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.004198655020445585, Min w: 6.238836889433188e-18\n",
      "Iteration 1090, Loss: 0.0030793962068855762, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002715226961299777, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0036575959529727697, Min w: 8.412089358422747e-10\n",
      "Iteration 1120, Loss: 0.0028241612017154694, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0025986223481595516, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0030940817669034004, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0032997047528624535, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.003592688823118806, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002695877803489566, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.004056369420140982, Min w: 3.339265201097703e-35\n",
      "Iteration 1190, Loss: 0.002461409429088235, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0033631334081292152, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0033013317734003067, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.003139015519991517, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002530335448682308, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002802538685500622, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002662269165739417, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031961838249117136, Min w: 7.900339133582342e-38\n",
      "Iteration 20, Loss: 0.0026602172292768955, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0024818265810608864, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002522406168282032, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0025141427759081125, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0036847623996436596, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0031324527226388454, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0024012308567762375, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0027925679460167885, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002865096554160118, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002691093599423766, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0029265619814395905, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0026833766605705023, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0026091281324625015, Min w: 0.0\n",
      "Iteration 150, Loss: 0.003156991209834814, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0023210798390209675, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0029983643908053637, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0031511110719293356, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0025278355460613966, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002844493603333831, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0053543574176728725, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0024689147248864174, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0025140997022390366, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0030138958245515823, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0023991549387574196, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0028133008163422346, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0023406746331602335, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002289918949827552, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00271543487906456, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0026009543798863888, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003749150549992919, Min w: 1.401298464324817e-45\n",
      "Iteration 320, Loss: 0.003294664202257991, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0026486916467547417, Min w: 0.0\n",
      "Iteration 340, Loss: 0.005278752651065588, Min w: 0.0\n",
      "Iteration 350, Loss: 0.004385728854686022, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0025806149933487177, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002602550433948636, Min w: 0.0\n",
      "Iteration 380, Loss: 0.003717288840562105, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0030931346118450165, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0031485208310186863, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0024523388128727674, Min w: 0.0\n",
      "Iteration 420, Loss: 0.00270045455545187, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003964943345636129, Min w: 2.2420775429197073e-44\n",
      "Iteration 440, Loss: 0.002469925908371806, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00270350044593215, Min w: 0.0\n",
      "Iteration 460, Loss: 0.006822206079959869, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0023989167530089617, Min w: 0.0\n",
      "Iteration 480, Loss: 0.005408022087067366, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0024268683046102524, Min w: 0.0\n",
      "Iteration 500, Loss: 0.00268246210180223, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00248549017123878, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0024753587786108255, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0030812572222203016, Min w: 0.0\n",
      "Iteration 540, Loss: 0.005353327840566635, Min w: 0.0\n",
      "Iteration 550, Loss: 0.002534477273002267, Min w: 0.0\n",
      "Iteration 560, Loss: 0.004660383798182011, Min w: 0.0\n",
      "Iteration 570, Loss: 0.003061780007556081, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0031124297529459, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0031799222342669964, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002712445566430688, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0024168018717318773, Min w: 0.0\n",
      "Iteration 620, Loss: 0.002367454580962658, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0030046128667891026, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0026090056635439396, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0035431378055363894, Min w: 4.55233251760173e-16\n",
      "Iteration 660, Loss: 0.0028455364517867565, Min w: 1.7354173797990384e-35\n",
      "Iteration 670, Loss: 0.004143649712204933, Min w: 0.0\n",
      "Iteration 680, Loss: 0.003668742021545768, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0026126571465283632, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0025670218747109175, Min w: 0.0\n",
      "Iteration 710, Loss: 0.00449671084061265, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004013294819742441, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0031225401908159256, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0042924885638058186, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0027922887820750475, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0027424467261880636, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002710351487621665, Min w: 0.0\n",
      "Iteration 780, Loss: 0.004841826390475035, Min w: 6.724094909483268e-29\n",
      "Iteration 790, Loss: 0.002541391411796212, Min w: 0.0\n",
      "Iteration 800, Loss: 0.002795396838337183, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0030458576511591673, Min w: 2.382207389352189e-44\n",
      "Iteration 820, Loss: 0.00376639305613935, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002659243531525135, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002459269715473056, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0030475324019789696, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0035621875431388617, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0029285422060638666, Min w: 0.0\n",
      "Iteration 880, Loss: 0.005967679433524609, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0030984969343990088, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0025787698104977608, Min w: 0.0\n",
      "Iteration 910, Loss: 0.004258274100720882, Min w: 1.8529699487675735e-32\n",
      "Iteration 920, Loss: 0.002985876752063632, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0025225146673619747, Min w: 0.0\n",
      "Iteration 940, Loss: 0.003490652423352003, Min w: 1.5458813736364416e-27\n",
      "Iteration 950, Loss: 0.0046428595669567585, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002414816990494728, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0025560287758708, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0034013802651315928, Min w: 1.0112878170760889e-19\n",
      "Iteration 990, Loss: 0.004464692901819944, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0026672903914004564, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0025625426787883043, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0025865903589874506, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.003053550375625491, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.004037732258439064, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0028101999778300524, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.006208231206983328, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0033237210009247065, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0027436409145593643, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0027980059385299683, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.00321148126386106, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.003072135616093874, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.002913255011662841, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0032111213076859713, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.004019576124846935, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0029192371293902397, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002612213371321559, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0025028972886502743, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002767356112599373, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.007063697557896376, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0024513090029358864, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.00487341545522213, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0043099247850477695, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002749111969023943, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0028805925976485014, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0029040963854640722, Min w: 0.0\n",
      "Iteration 10, Loss: 0.004135969094932079, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0029922849498689175, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002953936345875263, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002874750643968582, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0034073744900524616, Min w: 4.705392087387017e-40\n",
      "Iteration 60, Loss: 0.002754892222583294, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0025480580516159534, Min w: 0.0\n",
      "Iteration 80, Loss: 0.003997644875198603, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0024100004229694605, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0029073513578623533, Min w: 0.0\n",
      "Iteration 110, Loss: 0.005735041107982397, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0023994443472474813, Min w: 0.0\n",
      "Iteration 130, Loss: 0.003229472553357482, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0034126657992601395, Min w: 1.485097411432659e-24\n",
      "Iteration 150, Loss: 0.003303722944110632, Min w: 1.804984946935863e-32\n",
      "Iteration 160, Loss: 0.0027079880237579346, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002513134153559804, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002406568732112646, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0026486297138035297, Min w: 0.0\n",
      "Iteration 200, Loss: 0.004774963948875666, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0029153882060199976, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0040235258638858795, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00427277572453022, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0045579844154417515, Min w: 0.0\n",
      "Iteration 250, Loss: 0.004225858487188816, Min w: 0.0\n",
      "Iteration 260, Loss: 0.002762562595307827, Min w: 0.0\n",
      "Iteration 270, Loss: 0.006274370010942221, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0024644555523991585, Min w: 0.0\n",
      "Iteration 290, Loss: 0.004422441590577364, Min w: 0.0\n",
      "Iteration 300, Loss: 0.004172688815742731, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0035807702224701643, Min w: 0.0\n",
      "Iteration 320, Loss: 0.004266794770956039, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0027380806859582663, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002707958919927478, Min w: 1.8927338357635304e-41\n",
      "Iteration 350, Loss: 0.0027059579733759165, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0026030500885099173, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0024873672518879175, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002625285182148218, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0044706822372972965, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002567785093560815, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003283448750153184, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0031707368325442076, Min w: 0.0\n",
      "Iteration 430, Loss: 0.006569732446223497, Min w: 0.0\n",
      "Iteration 440, Loss: 0.003124808194115758, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002547456882894039, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003903044620528817, Min w: 0.0\n",
      "Iteration 470, Loss: 0.004026917740702629, Min w: 0.0\n",
      "Iteration 480, Loss: 0.002512856852263212, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0025234902277588844, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003263269318267703, Min w: 4.314578039423116e-27\n",
      "Iteration 510, Loss: 0.0027443289291113615, Min w: 0.0\n",
      "Iteration 520, Loss: 0.003279064316302538, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0044863177463412285, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0026713134720921516, Min w: 0.0\n",
      "Iteration 550, Loss: 0.007707876618951559, Min w: 0.0\n",
      "Iteration 560, Loss: 0.002567513845860958, Min w: 0.0\n",
      "Iteration 570, Loss: 0.003062708303332329, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002827021759003401, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0032351838890463114, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0024020043201744556, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002949500922113657, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0027990599628537893, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0024857106618583202, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0027601798065006733, Min w: 0.0\n",
      "Iteration 650, Loss: 0.004838456399738789, Min w: 1.588931465630787e-31\n",
      "Iteration 660, Loss: 0.002842054469510913, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002768109319731593, Min w: 0.0\n",
      "Iteration 680, Loss: 0.003047872567549348, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0052927653305232525, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0029643368907272816, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003438358660787344, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004041639622300863, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0027855043299496174, Min w: 0.0\n",
      "Iteration 740, Loss: 0.00262951641343534, Min w: 0.0\n",
      "Iteration 750, Loss: 0.004074143245816231, Min w: 0.00035303947515785694\n",
      "Iteration 760, Loss: 0.002802769187837839, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0030741840600967407, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0036574830301105976, Min w: 2.344178250492969e-14\n",
      "Iteration 790, Loss: 0.004743566270917654, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0046846806071698666, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0027352645993232727, Min w: 0.0\n",
      "Iteration 820, Loss: 0.004092744551599026, Min w: 3.857510422200505e-10\n",
      "Iteration 830, Loss: 0.003279390512034297, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0032963668927550316, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002845235401764512, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0027688350528478622, Min w: 0.0\n",
      "Iteration 870, Loss: 0.006084756925702095, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0028607326094061136, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0031216340139508247, Min w: 0.0\n",
      "Iteration 900, Loss: 0.003558977274224162, Min w: 2.6695154333594706e-12\n",
      "Iteration 910, Loss: 0.0027489967178553343, Min w: 0.0\n",
      "Iteration 920, Loss: 0.003003278048709035, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0027888549957424402, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0027175727300345898, Min w: 6.025583396596713e-44\n",
      "Iteration 950, Loss: 0.0031250780448317528, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0033179428428411484, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0027892161160707474, Min w: 0.0\n",
      "Iteration 980, Loss: 0.004737159702926874, Min w: 1.5341415587428097e-41\n",
      "Iteration 990, Loss: 0.002774948952719569, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002614289987832308, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0038007921539247036, Min w: 1.1495840723796391e-08\n",
      "Iteration 1020, Loss: 0.0027081891894340515, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.004044713452458382, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0028591228183358908, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002755972556769848, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.004041993524879217, Min w: 1.0051309437557948e-18\n",
      "Iteration 1070, Loss: 0.0027485399041324854, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002759990282356739, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.00391447264701128, Min w: 7.260161396516196e-07\n",
      "Iteration 1100, Loss: 0.004213415551930666, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0025130249559879303, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0028050588443875313, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.004523911513388157, Min w: 5.605193857299268e-45\n",
      "Iteration 1140, Loss: 0.0025285438168793917, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0032217034604400396, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0029156790114939213, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002991302637383342, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0025258620735257864, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.003759597195312381, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0025008718948811293, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0027731936424970627, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0031829415820538998, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   4%|▍         | 1/24 [00:51<19:45, 51.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1230, Loss: 0.0025188836734741926, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.003868460888043046, Min w: 0.0\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.8173357090039362, 'L2_avg': 0.8476029703323846, 'End_point_L1_avg': 0.8684289026498969, 'End_point_L2_avg': 0.8890042104890816}\n",
      "Iteration 0, Loss: 0.006104376167058945, Min w: 2.2540238183373357e-31\n",
      "Iteration 10, Loss: 0.0031032017432153225, Min w: 0.0\n",
      "Iteration 20, Loss: 0.004482163581997156, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002852022647857666, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0023992962669581175, Min w: 9.429070559214087e-37\n",
      "Iteration 50, Loss: 0.0027498346753418446, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002462095580995083, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002459908602759242, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0028923735953867435, Min w: 0.003279550466686487\n",
      "Iteration 90, Loss: 0.0022430396638810635, Min w: 1.0452864027851374e-33\n",
      "Iteration 100, Loss: 0.0022114519961178303, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0028426488861441612, Min w: 1.3091823905587282e-20\n",
      "Iteration 120, Loss: 0.0031561516225337982, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002530111698433757, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0028305836021900177, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002379579935222864, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003032248467206955, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0034619031939655542, Min w: 0.0\n",
      "Iteration 180, Loss: 0.003024789271876216, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0027061623986810446, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0034071928821504116, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0026905445847660303, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0024867902975529432, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0024149371311068535, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002704733982682228, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002347027650102973, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0024199727922677994, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002182913478463888, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0021400065161287785, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002259005093947053, Min w: 1.275596711908527e-26\n",
      "Iteration 300, Loss: 0.0025193977635353804, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0023599136620759964, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0028222922701388597, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0022619834635406733, Min w: 0.0\n",
      "Iteration 340, Loss: 0.003440198954194784, Min w: 6.942413386715033e-36\n",
      "Iteration 350, Loss: 0.0023942533880472183, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002528610872104764, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0030026454478502274, Min w: 2.5538779550462327e-18\n",
      "Iteration 380, Loss: 0.002753441222012043, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0030883890576660633, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0027666413225233555, Min w: 5.043754760853556e-26\n",
      "Iteration 410, Loss: 0.002573286648839712, Min w: 5.907561588306046e-31\n",
      "Iteration 420, Loss: 0.0023561676498502493, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002279877196997404, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0021800524555146694, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0022969930432736874, Min w: 9.473857396874807e-28\n",
      "Iteration 460, Loss: 0.002377784810960293, Min w: 8.808041102037478e-11\n",
      "Iteration 470, Loss: 0.0022727984469383955, Min w: 1.164493251841247e-31\n",
      "Iteration 480, Loss: 0.0023924480192363262, Min w: 9.426700531278698e-10\n",
      "Iteration 490, Loss: 0.0023284247145056725, Min w: 8.648068125417411e-25\n",
      "Iteration 500, Loss: 0.0021998193114995956, Min w: 3.2441419392868125e-27\n",
      "Iteration 510, Loss: 0.0022372209932655096, Min w: 7.58759082413426e-26\n",
      "Iteration 520, Loss: 0.0023293502163141966, Min w: 3.016123666021341e-32\n",
      "Iteration 530, Loss: 0.0027792626060545444, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0025383203756064177, Min w: 0.0\n",
      "Iteration 550, Loss: 0.002946461085230112, Min w: 0.0\n",
      "Iteration 560, Loss: 0.002952352399006486, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002323311986401677, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0023628941271454096, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0027542205061763525, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002635105513036251, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002665682230144739, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0017808839911594987, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0026757477317005396, Min w: 0.0\n",
      "Iteration 640, Loss: 0.002726528560742736, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0028119205962866545, Min w: 3.6433760072445244e-44\n",
      "Iteration 660, Loss: 0.003644308540970087, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0025309680495411158, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0028753746300935745, Min w: 0.0\n",
      "Iteration 690, Loss: 0.005892014596611261, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0024204060900956392, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0026963797863572836, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0032761050388216972, Min w: 3.502331345534868e-31\n",
      "Iteration 730, Loss: 0.005489792209118605, Min w: 0.0\n",
      "Iteration 740, Loss: 0.003378954716026783, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002502037677913904, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002630955073982477, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002471089130267501, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002354687312617898, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0030381481628865004, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0031959128100425005, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0025706577580422163, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002400068799033761, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0039961496368050575, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0025803542230278254, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0023625208996236324, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0025911794509738684, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0028421611059457064, Min w: 1.0451944000619776e-26\n",
      "Iteration 880, Loss: 0.0030300156213343143, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002580821281298995, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0029448755085468292, Min w: 2.7733732092537935e-32\n",
      "Iteration 910, Loss: 0.0025981750804930925, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0036168673541396856, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0035362974740564823, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0026686566416174173, Min w: 0.0\n",
      "Iteration 950, Loss: 0.002164966193959117, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002606439869850874, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0027182491030544043, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002481939271092415, Min w: 1.5274153261140506e-43\n",
      "Iteration 990, Loss: 0.0035408951807767153, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.004454568028450012, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0026500376407057047, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0031635104678571224, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0023880868684500456, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0030325697734951973, Min w: 1.9716269393050176e-42\n",
      "Iteration 1050, Loss: 0.002389517379924655, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0025621268432587385, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0028234359342604876, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002467059763148427, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0023847375996410847, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002450006315484643, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0021268685813993216, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0026092820335179567, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0029580527916550636, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002792580286040902, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002865853253751993, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002454508328810334, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003363395109772682, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002494691638275981, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0030005378648638725, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0031684550922363997, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.002649623667821288, Min w: 3.5262134426423264e-40\n",
      "Iteration 1220, Loss: 0.002321492414921522, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002578561892732978, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0024640578776597977, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0029485905542969704, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031261732801795006, Min w: 0.0\n",
      "Iteration 20, Loss: 0.004691941663622856, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002578390995040536, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0033293168526142836, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0025523360818624496, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002457276452332735, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002727365354076028, Min w: 0.0\n",
      "Iteration 80, Loss: 0.002439801348373294, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002711143810302019, Min w: 0.0\n",
      "Iteration 100, Loss: 0.003345204284414649, Min w: 1.0674951571380024e-39\n",
      "Iteration 110, Loss: 0.002787370700389147, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0026931604370474815, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0024628154933452606, Min w: 0.0\n",
      "Iteration 140, Loss: 0.004986708052456379, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0039017447270452976, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003216838464140892, Min w: 0.0\n",
      "Iteration 170, Loss: 0.003051823703572154, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0031818232964724302, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002917721401900053, Min w: 2.6058365630153896e-27\n",
      "Iteration 200, Loss: 0.0025313147343695164, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0027940571308135986, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0027090527582913637, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0035397775936871767, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0033825684804469347, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0024241572245955467, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00297188526019454, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0034542474895715714, Min w: 8.142387961519292e-16\n",
      "Iteration 280, Loss: 0.0057203881442546844, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002487370977178216, Min w: 0.0\n",
      "Iteration 300, Loss: 0.003470837837085128, Min w: 0.0\n",
      "Iteration 310, Loss: 0.004066118039190769, Min w: 0.0\n",
      "Iteration 320, Loss: 0.004402033053338528, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0031554843299090862, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0038973847404122353, Min w: 0.0\n",
      "Iteration 350, Loss: 0.005069386679679155, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002721155062317848, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002617074176669121, Min w: 0.0\n",
      "Iteration 380, Loss: 0.003296835580840707, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002607035217806697, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0026525454595685005, Min w: 0.0\n",
      "Iteration 410, Loss: 0.002569524571299553, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0024264263920485973, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003818209283053875, Min w: 2.070236312239555e-40\n",
      "Iteration 440, Loss: 0.002725802129134536, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002777742687612772, Min w: 0.0\n",
      "Iteration 460, Loss: 0.004587922245264053, Min w: 0.0\n",
      "Iteration 470, Loss: 0.003852616297081113, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0025377070996910334, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0027090732473880053, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0028248834423720837, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0024703573435544968, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002448601881042123, Min w: 0.0\n",
      "Iteration 530, Loss: 0.002468457445502281, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002573156962171197, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0034290619660168886, Min w: 5.233427806196422e-17\n",
      "Iteration 560, Loss: 0.004736551083624363, Min w: 0.0\n",
      "Iteration 570, Loss: 0.003955270629376173, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0024726197589188814, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0027084816247224808, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002468706341460347, Min w: 0.0\n",
      "Iteration 610, Loss: 0.00255866558291018, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0027905728202313185, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0031429657246917486, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0025345070753246546, Min w: 0.0\n",
      "Iteration 650, Loss: 0.004363872576504946, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0031725114677101374, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0037618421483784914, Min w: 0.0\n",
      "Iteration 680, Loss: 0.004838063381612301, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0035682530142366886, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003808114677667618, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002677009906619787, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0034061232581734657, Min w: 0.0\n",
      "Iteration 730, Loss: 0.00369523954577744, Min w: 0.0\n",
      "Iteration 740, Loss: 0.003028139239177108, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002819802612066269, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0025572050362825394, Min w: 0.0\n",
      "Iteration 770, Loss: 0.005851420108228922, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0025496601592749357, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0024234065786004066, Min w: 0.0\n",
      "Iteration 800, Loss: 0.00323058245703578, Min w: 4.149699530653728e-20\n",
      "Iteration 810, Loss: 0.003202426712960005, Min w: 0.0\n",
      "Iteration 820, Loss: 0.003071308834478259, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0035100639797747135, Min w: 2.8746371431875024e-24\n",
      "Iteration 840, Loss: 0.0026840956415981054, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0029597959946841, Min w: 0.0\n",
      "Iteration 860, Loss: 0.002520902780815959, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0028514324221760035, Min w: 0.0\n",
      "Iteration 880, Loss: 0.003192352829501033, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0025572709273546934, Min w: 0.0\n",
      "Iteration 900, Loss: 0.003337359055876732, Min w: 0.0\n",
      "Iteration 910, Loss: 0.003732425859197974, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0033202660270035267, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0029506932478398085, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0024878259282559156, Min w: 0.0\n",
      "Iteration 950, Loss: 0.005075294990092516, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002413524081930518, Min w: 0.0\n",
      "Iteration 970, Loss: 0.002539649372920394, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002947274362668395, Min w: 4.41714245154925e-22\n",
      "Iteration 990, Loss: 0.0028475536964833736, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0023937977384775877, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0026751463301479816, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.002538540866225958, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0030437647365033627, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.007672196254134178, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.004018617793917656, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0036529970820993185, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.003984193783253431, Min w: 2.980425886233585e-33\n",
      "Iteration 1080, Loss: 0.0027065316680818796, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0024079103022813797, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002463481156155467, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.004014563746750355, Min w: 1.8717446778259032e-19\n",
      "Iteration 1120, Loss: 0.0025761921424418688, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0026137542445212603, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.003765278263017535, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002456456422805786, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0032485753763467073, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.005183888133615255, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0026133842766284943, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.003623278345912695, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0038728450890630484, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.002943489933386445, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002429425483569503, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0025477593299001455, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0025672349147498608, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002925299108028412, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0034860759042203426, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0028874133713543415, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0029930074233561754, Min w: 0.0\n",
      "Iteration 40, Loss: 0.004023226909339428, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0039295051246881485, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0026231566444039345, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0027438171673566103, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0026416077744215727, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0023974748328328133, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0028847993817180395, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002771263010799885, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0031431573443114758, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0030076054390519857, Min w: 7.873019646129513e-31\n",
      "Iteration 140, Loss: 0.004932246636599302, Min w: 0.0\n",
      "Iteration 150, Loss: 0.004009683150798082, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002568305004388094, Min w: 0.0\n",
      "Iteration 170, Loss: 0.005001728888601065, Min w: 5.711866660021605e-23\n",
      "Iteration 180, Loss: 0.0028224412817507982, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0037194627802819014, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0028752051293849945, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0034015148412436247, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002695212373510003, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0026854518800973892, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0027569832745939493, Min w: 0.0\n",
      "Iteration 250, Loss: 0.004265505354851484, Min w: 4.690668005430256e-36\n",
      "Iteration 260, Loss: 0.0027883427683264017, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0027607919182628393, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002692514332011342, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0027023646980524063, Min w: 0.0\n",
      "Iteration 300, Loss: 0.00260716350749135, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002625697758048773, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0025596742052584887, Min w: 0.0\n",
      "Iteration 330, Loss: 0.005897325463593006, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0024429401382803917, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0031305619049817324, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0032778538297861814, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0027106967754662037, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0024312008172273636, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0036904483567923307, Min w: 0.0\n",
      "Iteration 400, Loss: 0.004432033747434616, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0025330735370516777, Min w: 0.0\n",
      "Iteration 420, Loss: 0.005448330193758011, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0029895275365561247, Min w: 0.0\n",
      "Iteration 440, Loss: 0.004709925036877394, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0039799632504582405, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002583222696557641, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0025733914226293564, Min w: 0.0\n",
      "Iteration 480, Loss: 0.002769903279840946, Min w: 0.0\n",
      "Iteration 490, Loss: 0.003804760752245784, Min w: 6.569320709231403e-33\n",
      "Iteration 500, Loss: 0.003629975486546755, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00255286181345582, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0033674228470772505, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0025751099456101656, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0025601268280297518, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0032645827159285545, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0038702073507010937, Min w: 1.2765029640837143e-32\n",
      "Iteration 570, Loss: 0.004145366605371237, Min w: 0.0\n",
      "Iteration 580, Loss: 0.00306568737141788, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002646861830726266, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0030482474248856306, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0024089256767183542, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0030432597268372774, Min w: 0.0\n",
      "Iteration 630, Loss: 0.003528016386553645, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0026938614901155233, Min w: 0.0\n",
      "Iteration 650, Loss: 0.003320072777569294, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0024949212092906237, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0026572756469249725, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002632155315950513, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002774398773908615, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003009374951943755, Min w: 0.0\n",
      "Iteration 710, Loss: 0.00277145323343575, Min w: 0.0\n",
      "Iteration 720, Loss: 0.002830659970641136, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0034121598582714796, Min w: 9.704733993116065e-37\n",
      "Iteration 740, Loss: 0.0030005602166056633, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0024694744497537613, Min w: 0.0\n",
      "Iteration 760, Loss: 0.00292380154132843, Min w: 0.0\n",
      "Iteration 770, Loss: 0.003664642106741667, Min w: 4.135557073302489e-27\n",
      "Iteration 780, Loss: 0.0032774482388049364, Min w: 5.464019202731786e-38\n",
      "Iteration 790, Loss: 0.0026332575362175703, Min w: 0.0\n",
      "Iteration 800, Loss: 0.002976704388856888, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002758303191512823, Min w: 0.0\n",
      "Iteration 820, Loss: 0.005541394930332899, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0025337636470794678, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0023954431526362896, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0033198220189660788, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003093246603384614, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0029941776301711798, Min w: 0.0\n",
      "Iteration 880, Loss: 0.003272017929702997, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0031389370560646057, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002616054378449917, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0027251176070421934, Min w: 0.0\n",
      "Iteration 920, Loss: 0.003047370817512274, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0031168959103524685, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0030474946834146976, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0026927683502435684, Min w: 0.0\n",
      "Iteration 960, Loss: 0.005285247694700956, Min w: 0.0\n",
      "Iteration 970, Loss: 0.00239767599850893, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002488794969394803, Min w: 0.0\n",
      "Iteration 990, Loss: 0.004548410419374704, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0024586208164691925, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002560420660302043, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0025422009639441967, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0027790474705398083, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.004028456751257181, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0036382796242833138, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0027109035290777683, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.002942390041425824, Min w: 9.323670490916574e-28\n",
      "Iteration 1080, Loss: 0.00317007047124207, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0035834219306707382, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0027651081327348948, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0062812501564621925, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0032086758874356747, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.003577965311706066, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002888163086026907, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.006240951828658581, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0025314949452877045, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.004358044825494289, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0034505005460232496, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0025307093746960163, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002739605028182268, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0024568960070610046, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002363170962780714, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002360759535804391, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0025669632013887167, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0025841074530035257, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0030329881701618433, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0029448934365063906, Min w: 1.1704970402388123e-38\n",
      "Iteration 30, Loss: 0.00477344635874033, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002422655699774623, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0025222525000572205, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0030961770098656416, Min w: 1.0551082014879086e-28\n",
      "Iteration 70, Loss: 0.002705848775804043, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0026415884494781494, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002911574672907591, Min w: 0.0\n",
      "Iteration 100, Loss: 0.003503908636048436, Min w: 0.0\n",
      "Iteration 110, Loss: 0.003589338157325983, Min w: 0.0\n",
      "Iteration 120, Loss: 0.003516159951686859, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0027820642571896315, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0028172163292765617, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0028225770220160484, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0024977324064821005, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0027618338353931904, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0027161752805113792, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002735684858635068, Min w: 0.0\n",
      "Iteration 200, Loss: 0.004001567605882883, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0025082938373088837, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0026111772749572992, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0033061825670301914, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0031703049317002296, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0024289735592901707, Min w: 0.0\n",
      "Iteration 260, Loss: 0.003689925419166684, Min w: 0.0\n",
      "Iteration 270, Loss: 0.004911711905151606, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0032593191135674715, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0025452771224081516, Min w: 0.0\n",
      "Iteration 300, Loss: 0.002787425182759762, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0032408242113888264, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0026393597945570946, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002376271178945899, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002649473026394844, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0032413157168775797, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0027278021443635225, Min w: 0.0\n",
      "Iteration 370, Loss: 0.005306235048919916, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0025910281110554934, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0025515826418995857, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0025749760679900646, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003005733247846365, Min w: 0.0\n",
      "Iteration 420, Loss: 0.00291544571518898, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003696055617183447, Min w: 1.463603991316173e-29\n",
      "Iteration 440, Loss: 0.0030223389621824026, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002575164195150137, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002397585893049836, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0026477717328816652, Min w: 0.0\n",
      "Iteration 480, Loss: 0.006274396553635597, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0027525657787919044, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003391276579350233, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00358371390029788, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002445216989144683, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0030820975080132484, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002725041238591075, Min w: 0.0\n",
      "Iteration 550, Loss: 0.003030435647815466, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0027810633182525635, Min w: 0.0\n",
      "Iteration 570, Loss: 0.005108372308313847, Min w: 0.0\n",
      "Iteration 580, Loss: 0.00409971596673131, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0026200381107628345, Min w: 0.0\n",
      "Iteration 600, Loss: 0.00286129885353148, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0053227804601192474, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0034060960169881582, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0024570750538259745, Min w: 0.0\n",
      "Iteration 640, Loss: 0.004844810348004103, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0024994967970997095, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0024469392374157906, Min w: 0.0\n",
      "Iteration 670, Loss: 0.004870712757110596, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0024201017804443836, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0025287040043622255, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0033071183133870363, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002693320158869028, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0029153567738831043, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002854594262316823, Min w: 3.189378823299878e-34\n",
      "Iteration 740, Loss: 0.0025411751121282578, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0027751426678150892, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0025909573305398226, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002817549742758274, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002991011831909418, Min w: 0.0\n",
      "Iteration 790, Loss: 0.00286530377343297, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0027396371588110924, Min w: 0.0\n",
      "Iteration 810, Loss: 0.00309976888820529, Min w: 4.579248041183336e-21\n",
      "Iteration 820, Loss: 0.0030886130407452583, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0026149677578359842, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0024228424299508333, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0025710188783705235, Min w: 0.0\n",
      "Iteration 860, Loss: 0.002597456332296133, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0047966972924768925, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0024628168903291225, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0027889953926205635, Min w: 0.0\n",
      "Iteration 900, Loss: 0.003753481199964881, Min w: 1.5828327147235366e-13\n",
      "Iteration 910, Loss: 0.0030255108140408993, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0024052222725003958, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0037208853755146265, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0030597758013755083, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0029980046674609184, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002995840273797512, Min w: 0.0\n",
      "Iteration 970, Loss: 0.003268232336267829, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0027609465178102255, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0026418084744364023, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.003371701342985034, Min w: 1.1210387714598537e-43\n",
      "Iteration 1010, Loss: 0.003470419440418482, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0032562820706516504, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.003353016683831811, Min w: 4.764414778704378e-44\n",
      "Iteration 1040, Loss: 0.004322772845625877, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0026386796962469816, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0025250022299587727, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0053599076345562935, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002486119046807289, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0027215436566621065, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0034427973441779613, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0028502217028290033, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0027158595621585846, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.005116219632327557, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.004058770835399628, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002456676447764039, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0024585018400102854, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002606266178190708, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0027398092206567526, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.003407246433198452, Min w: 5.499478042514915e-18\n",
      "Iteration 1200, Loss: 0.0030728960409760475, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.002508682431653142, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002754902234300971, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.004600003361701965, Min w: 2.5223372357846707e-44\n",
      "Iteration 1240, Loss: 0.0024864256847649813, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0026387230027467012, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031096800230443478, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0029205442406237125, Min w: 4.985819936067699e-42\n",
      "Iteration 30, Loss: 0.002659039106220007, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002607865957543254, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002399730496108532, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0027262631338089705, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0037048866506665945, Min w: 1.9543915097397502e-10\n",
      "Iteration 80, Loss: 0.0030366950668394566, Min w: 0.0\n",
      "Iteration 90, Loss: 0.00248944410122931, Min w: 0.0\n",
      "Iteration 100, Loss: 0.004608011804521084, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0027130241505801678, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0028013477567583323, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0032934132032096386, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0028484754730015993, Min w: 0.0\n",
      "Iteration 150, Loss: 0.004880292806774378, Min w: 1.362114178788008e-19\n",
      "Iteration 160, Loss: 0.004005465656518936, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0036646071821451187, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0026942193508148193, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0033512876834720373, Min w: 1.0475457396616163e-33\n",
      "Iteration 200, Loss: 0.004095445852726698, Min w: 0.0\n",
      "Iteration 210, Loss: 0.005223054438829422, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002416980220004916, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002509874291718006, Min w: 0.0\n",
      "Iteration 240, Loss: 0.004665963817387819, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0031979556661099195, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0025193507317453623, Min w: 0.0\n",
      "Iteration 270, Loss: 0.003467916278168559, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00308404304087162, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0026223850436508656, Min w: 0.0\n",
      "Iteration 300, Loss: 0.002377481432631612, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0030947779305279255, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0027826246805489063, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0025662339758127928, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0028480077162384987, Min w: 0.0\n",
      "Iteration 350, Loss: 0.003974106162786484, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0025694340001791716, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0024267854169011116, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002430284395813942, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002450362779200077, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0026093926280736923, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0028399131260812283, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0025937738828361034, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0025311934296041727, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0026664703618735075, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0025141285732388496, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0024460130371153355, Min w: 0.0\n",
      "Iteration 470, Loss: 0.003652336774393916, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0024901533033698797, Min w: 0.0\n",
      "Iteration 490, Loss: 0.003082227660343051, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0030841657426208258, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0028252515476197004, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0024793362244963646, Min w: 0.0\n",
      "Iteration 530, Loss: 0.003558758646249771, Min w: 2.403418382798595e-30\n",
      "Iteration 540, Loss: 0.003851785557344556, Min w: 0.0\n",
      "Iteration 550, Loss: 0.003112073754891753, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0030405314173549414, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002745640929788351, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002394170267507434, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0029832676518708467, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002417944837361574, Min w: 0.0\n",
      "Iteration 610, Loss: 0.00294003845192492, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0054346248507499695, Min w: 0.0\n",
      "Iteration 630, Loss: 0.002576257102191448, Min w: 0.0\n",
      "Iteration 640, Loss: 0.005237345118075609, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0034246279392391443, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002766546094790101, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002425720915198326, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002915577497333288, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00275603961199522, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0025593319442123175, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0037915874272584915, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0027625563088804483, Min w: 0.0\n",
      "Iteration 730, Loss: 0.00472431443631649, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0030086354818195105, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002430475316941738, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0034568787086755037, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002646736102178693, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0027172015979886055, Min w: 0.0\n",
      "Iteration 790, Loss: 0.003272657748311758, Min w: 6.218711151999424e-33\n",
      "Iteration 800, Loss: 0.0027851311024278402, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002552950521931052, Min w: 0.0\n",
      "Iteration 820, Loss: 0.00458407262340188, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002595993923023343, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0027425785083323717, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0028384895995259285, Min w: 1.0788670988799631e-32\n",
      "Iteration 860, Loss: 0.0038111868780106306, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002509321551769972, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0027604505885392427, Min w: 5.885453550164232e-44\n",
      "Iteration 890, Loss: 0.0027544263284653425, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0034611013252288103, Min w: 2.487910159023461e-20\n",
      "Iteration 910, Loss: 0.0034860915038734674, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002407887950539589, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0033188359811902046, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002981777535751462, Min w: 0.0\n",
      "Iteration 950, Loss: 0.002733853878453374, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002586186630651355, Min w: 0.0\n",
      "Iteration 970, Loss: 0.002746108453720808, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0032427399419248104, Min w: 1.7816941920498146e-29\n",
      "Iteration 990, Loss: 0.003056065645068884, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0026588544715195894, Min w: 4.203895392974451e-45\n",
      "Iteration 1010, Loss: 0.004001410212367773, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0024059293791651726, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0025561582297086716, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0028892760165035725, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0029053580947220325, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.00242957123555243, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0025418715085834265, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0034340808633714914, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0023344510700553656, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002875739010050893, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0025845947675406933, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.004090035799890757, Min w: 4.707194448682219e-36\n",
      "Iteration 1130, Loss: 0.0025312367361038923, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0029965101275593042, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0026769000105559826, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002606706228107214, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003042452270165086, Min w: 1.4798769271771327e-25\n",
      "Iteration 1180, Loss: 0.0030670177657157183, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0028326367028057575, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.00398433580994606, Min w: 5.1850392559405735e-25\n",
      "Iteration 1210, Loss: 0.0028073631692677736, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0027761035598814487, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.004745027981698513, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002509143203496933, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   8%|▊         | 2/24 [01:43<19:02, 51.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.6196383936405636, 'L2_avg': 0.6443688229572396, 'End_point_L1_avg': 0.599700184488314, 'End_point_L2_avg': 0.6633520545701292}\n",
      "Iteration 0, Loss: 0.0012790338369086385, Min w: 0.002865463262423873\n",
      "Iteration 10, Loss: 0.0005427217110991478, Min w: 0.0\n",
      "Iteration 20, Loss: 0.000572486431337893, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000675520277582109, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006958623416721821, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006713927141390741, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005170268123038113, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005133355152793229, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0008602339657954872, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005882854457013309, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005947654717601836, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005255803698673844, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005442540859803557, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005738086765632033, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006125457002781332, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005938906106166542, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006325030117295682, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006127562955953181, Min w: 0.0\n",
      "Iteration 180, Loss: 0.00064186000963673, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005422778776846826, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005437235231511295, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006001575384289026, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005670944810844958, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006362025160342455, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0008041420369409025, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006160503253340721, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006523989723064005, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005602287710644305, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0005752358702011406, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005453287740238011, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006219113129191101, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006054544937796891, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006257093045860529, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005735359736718237, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006457541603595018, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0005620290758088231, Min w: 0.0\n",
      "Iteration 360, Loss: 0.000544364913366735, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0005881911492906511, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005714535363949835, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005923268035985529, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005144320311956108, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005502784042619169, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006053061224520206, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006191575666889548, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0005392886232584715, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006957693258300424, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005606007762253284, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00058486417401582, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006504137418232858, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006612140568904579, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008440754027105868, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0005771155701950192, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0006070735398679972, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0005812253803014755, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005420895759016275, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005936495726928115, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0005281578050926328, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006557729793712497, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006035897531546652, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005751397693529725, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0005678404704667628, Min w: 1.732048342157868e-38\n",
      "Iteration 610, Loss: 0.000573884230107069, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006129885441623628, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0009898003190755844, Min w: 0.0\n",
      "Iteration 640, Loss: 0.000665649538859725, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008103020372800529, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0006882785237394273, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0009686562698334455, Min w: 2.1434239203411282e-13\n",
      "Iteration 680, Loss: 0.000672118563670665, Min w: 0.0\n",
      "Iteration 690, Loss: 0.000993773341178894, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007296734838746488, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0035698777064681053, Min w: 0.0\n",
      "Iteration 720, Loss: 0.001283728750422597, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0014079540269449353, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0006035426631569862, Min w: 0.0\n",
      "Iteration 750, Loss: 0.001994614489376545, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0005946378223598003, Min w: 0.0\n",
      "Iteration 770, Loss: 0.001619033282622695, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006915067788213491, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0008327755494974554, Min w: 0.0\n",
      "Iteration 800, Loss: 0.000604087021201849, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0010721181752160192, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006615660968236625, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0010002393973991275, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0007075488683767617, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0005879921372979879, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007729025091975927, Min w: 0.0\n",
      "Iteration 870, Loss: 0.000748087652027607, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006411854992620647, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008363024098798633, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0010412532137706876, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006518937298096716, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0007684649899601936, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0008634262485429645, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007970925653353333, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0006787724560126662, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0008724446524865925, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006258044741116464, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006025820039212704, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008366020629182458, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0005749877309426665, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006604247028008103, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0008451833273284137, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006109463865868747, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0005825537955388427, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0005973739316686988, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006997330929152668, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007619787938892841, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0006703450926579535, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006485172198154032, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0008464461425319314, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006522656185552478, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0007094891043379903, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007443282520398498, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0008198475698009133, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006989731919020414, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0012210062704980373, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0019250105833634734, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0017462644027546048, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0014399014180526137, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007607805891893804, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0008699375903233886, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0007932380540296435, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006152738351374865, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006875768885947764, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0013700347626581788, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006120101315900683, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009203326189890504, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007947685662657022, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008300433401018381, Min w: 0.0\n",
      "Iteration 50, Loss: 0.000630094320513308, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006639137864112854, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008697861339896917, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006559158209711313, Min w: 0.0\n",
      "Iteration 90, Loss: 0.001354969572275877, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0007991207530722022, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0009108165395446122, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0008706367807462811, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0010466319508850574, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0018985295901075006, Min w: 0.0\n",
      "Iteration 150, Loss: 0.000668102758936584, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0007149375160224736, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0009452379890717566, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006298210937529802, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006995226722210646, Min w: 0.0\n",
      "Iteration 200, Loss: 0.001125495182350278, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0012431003851816058, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0006223325035534799, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0011620383011177182, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006285072886385024, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0009659967618063092, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0010584938572719693, Min w: 0.0\n",
      "Iteration 270, Loss: 0.000681497564073652, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008146821055561304, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006170510314404964, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0008205209160223603, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006779494578950107, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0009059972944669425, Min w: 0.0\n",
      "Iteration 330, Loss: 0.000725969672203064, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000751591578591615, Min w: 0.0\n",
      "Iteration 350, Loss: 0.000688270665705204, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002079170197248459, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0007299547432921827, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0008119914564304054, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007114451145753264, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006946095381863415, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0012120326282456517, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006141429767012596, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0009895112598314881, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008979514241218567, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001481427694670856, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002197557594627142, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0007259495905600488, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0009483467438258231, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006389396730810404, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008988032350316644, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006655413890257478, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007093946915119886, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0009493952384218574, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0007336772396229208, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006555344443768263, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007507331902161241, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0008693827548995614, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0005995314568281174, Min w: 0.0\n",
      "Iteration 590, Loss: 0.001045029959641397, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0008140288409776986, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002041311701759696, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0010103329550474882, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0014033704064786434, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0007730792858637869, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008545283926650882, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0006892067613080144, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0006841643480584025, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007438048487529159, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005978975677862763, Min w: 0.0\n",
      "Iteration 700, Loss: 0.001103904563933611, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0007467590039595962, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006382762803696096, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0008949545444920659, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0008840085938572884, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0008611634257249534, Min w: 0.0\n",
      "Iteration 760, Loss: 0.001551192020997405, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0015124710043892264, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006543855415657163, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007221914129331708, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009228283888660371, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006281948881223798, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0008408605353906751, Min w: 0.0\n",
      "Iteration 830, Loss: 0.000693495268933475, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0013527929550036788, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0010067353723570704, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008512973436154425, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006044565816409886, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006020692526362836, Min w: 0.0\n",
      "Iteration 890, Loss: 0.001513568451628089, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0010056565515697002, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0015250787837430835, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0008044034475460649, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0018267694395035505, Min w: 0.0\n",
      "Iteration 940, Loss: 0.000617189914919436, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0013294594828039408, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006314057973213494, Min w: 0.0\n",
      "Iteration 970, Loss: 0.000643751525785774, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0007976868073455989, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008933658245950937, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0017761022318154573, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0010730057256296277, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0009977775625884533, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006242563831619918, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0011757975444197655, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0006471661617979407, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006318907835520804, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0021858960390090942, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0009118693415075541, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0012791813351213932, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0009015994728542864, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0009689600556157529, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0010500383796170354, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0008887826115824282, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0010989452712237835, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006779336254112422, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0007372507825493813, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.000685197243001312, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.001398336491547525, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0009108216618187726, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006853113882243633, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0016779769212007523, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.000707338098436594, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0011796376202255487, Min w: 4.484155085839415e-43\n",
      "Iteration 1240, Loss: 0.0008415434858761728, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0022810010705143213, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010912539437413216, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006513750995509326, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0012733476469293237, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009613389265723526, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0012001877184957266, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0011183981550857425, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007501686923205853, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006330885807983577, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006649263086728752, Min w: 0.0\n",
      "Iteration 100, Loss: 0.000940644065849483, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007865962688811123, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0013083657249808311, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006702738464809954, Min w: 0.0\n",
      "Iteration 140, Loss: 0.000784672680310905, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0009461450972594321, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0007681202259846032, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008287397213280201, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0008531143539585173, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007500401115976274, Min w: 0.0\n",
      "Iteration 200, Loss: 0.000849248084705323, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0017888109432533383, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0012275251792743802, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007555104093626142, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006901586311869323, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007638844544999301, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006999428733251989, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0006394936353899539, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0009028320200741291, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0011984084267169237, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0008658668957650661, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0030610717367380857, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0024316939525306225, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007967940182425082, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0011480175890028477, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007841418264433742, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008219213341362774, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0007214469951577485, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0009479897562414408, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0008298225002363324, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007652616477571428, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0007300107390619814, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006509199156425893, Min w: 0.0\n",
      "Iteration 430, Loss: 0.000655895215459168, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006036878912709653, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0009343395358882844, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0009322382393293083, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006615496822632849, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0008359347702935338, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0008157495758496225, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0007529434515163302, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0007173175108619034, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007831988041289151, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006227023550309241, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008848844445310533, Min w: 0.0\n",
      "Iteration 550, Loss: 0.000646107888314873, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007971818558871746, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0007709959172643721, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008648448856547475, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0010235738009214401, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006369132897816598, Min w: 0.0\n",
      "Iteration 610, Loss: 0.000862989341840148, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0009161972557194531, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0010096182813867927, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00233478844165802, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008195265545509756, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0011404900578781962, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0012619656044989824, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0006263974937610328, Min w: 0.0\n",
      "Iteration 690, Loss: 0.001432679477147758, Min w: 0.0\n",
      "Iteration 700, Loss: 0.000890995841473341, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006441743462346494, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006272788741625845, Min w: 0.0\n",
      "Iteration 730, Loss: 0.000838523730635643, Min w: 0.0\n",
      "Iteration 740, Loss: 0.000837328436318785, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007550582522526383, Min w: 0.0\n",
      "Iteration 760, Loss: 0.001161622116342187, Min w: 0.0\n",
      "Iteration 770, Loss: 0.000651082955300808, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0011075730435550213, Min w: 0.0\n",
      "Iteration 790, Loss: 0.001102351932786405, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0011753308353945613, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0007357100257650018, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006041634478606284, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006440194556489587, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012036643456667662, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0008516268571838737, Min w: 0.0\n",
      "Iteration 860, Loss: 0.001120018190704286, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007342511671595275, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0009836509125307202, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0011141406139358878, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0010745883919298649, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0008868699660524726, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0008320824708789587, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0012833669316023588, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006539315218105912, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0011780329514294863, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0016328968340530992, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0007799617596901953, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006329494644887745, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0007480106432922184, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0014776457101106644, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0008753306465223432, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0010498971678316593, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006906840135343373, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0010728565976023674, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0009235751931555569, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006569128599949181, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007201604312285781, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0009935427224263549, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006316491635516286, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007950300932861865, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0010306857293471694, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006646367837674916, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006014262908138335, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007587603176943958, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0012835427187383175, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0011426936835050583, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0007600010721944273, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0011218168074265122, Min w: 5.6404514907626435e-06\n",
      "Iteration 1190, Loss: 0.0009484249167144299, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0010672304779291153, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007180002285167575, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.000813653867226094, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0014645865885540843, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008620465523563325, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0006085900822654366, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0013415093999356031, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006427203770726919, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008031163015402853, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0014311758568510413, Min w: 0.0\n",
      "Iteration 50, Loss: 0.000606080109719187, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007307477644644678, Min w: 0.0\n",
      "Iteration 70, Loss: 0.000900779792573303, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0009855016833171248, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006340761901810765, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0009864153107628226, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007991087040863931, Min w: 0.0\n",
      "Iteration 120, Loss: 0.003667823038995266, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0012288111029192805, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0013133054599165916, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008988658082671463, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0008651186362840235, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006964753265492618, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006655066972598433, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006580358603969216, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007417506421916187, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0010228148894384503, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0012856819666922092, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007124020485207438, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0018781700637191534, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0008009633747860789, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0011348607949912548, Min w: 0.0\n",
      "Iteration 270, Loss: 0.000662395847029984, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008654092089273036, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0008033087360672653, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007238425314426422, Min w: 0.0\n",
      "Iteration 310, Loss: 0.001016734866425395, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006713925977237523, Min w: 0.0\n",
      "Iteration 330, Loss: 0.001051482162438333, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0008957862155511975, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0010610335739329457, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0010120157385244966, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0010048634139820933, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0007078593480400741, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0012185556115582585, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007224055007100105, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0009337503579445183, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0008163158199749887, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0010750619694590569, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006244305986911058, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001089036581106484, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0009616334573365748, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0011132739018648863, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006512803956866264, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006550814141519368, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008937876555137336, Min w: 0.0\n",
      "Iteration 510, Loss: 0.001072143786586821, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0010977762285619974, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0008319098269566894, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006734929047524929, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0011272466508671641, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0011529374169185758, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0008893080521374941, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007569165900349617, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006373940850608051, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0009310857276432216, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0013890417758375406, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006314254133030772, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0007696565007790923, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006114573334343731, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008779813651926816, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007804392953403294, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007266555912792683, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0006132856360636652, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0007075963076204062, Min w: 0.0\n",
      "Iteration 700, Loss: 0.001329055754467845, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008018856751732528, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0008799801580607891, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0010266582248732448, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0016761902952566743, Min w: 0.0\n",
      "Iteration 750, Loss: 0.001879990566521883, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0015171434497460723, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0017518524546176195, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007025343948043883, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0008121263817884028, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0007448948454111814, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0009002611041069031, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006380322738550603, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0024370448663830757, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008335315505973995, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006695250631310046, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0009554657153785229, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0008343053632415831, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0009594136499799788, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0007125865668058395, Min w: 0.0\n",
      "Iteration 900, Loss: 0.001081820810213685, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0008862436516210437, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0011206644121557474, Min w: 0.0\n",
      "Iteration 930, Loss: 0.000930911919567734, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0008527913596481085, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0008363713277503848, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0007231039344333112, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006396589451469481, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0014200547011569142, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0007722717127762735, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006009236094541848, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006918471772223711, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0014888051664456725, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006453584646806121, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0013195378705859184, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.000614662654697895, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007757706334814429, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006040671141818166, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0007449392578564584, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0007415235741063952, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006102759507484734, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006969834212213755, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.000964587030466646, Min w: 8.25196056265946e-30\n",
      "Iteration 1130, Loss: 0.0007217083475552499, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006595251616090536, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0007496876060031354, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006772485794499516, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0008689644746482372, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006910721422173083, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008399062789976597, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.000654348696116358, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007595194038003683, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0009493451216258109, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006161174387671053, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006231367588043213, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0007990896119736135, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0008321146015077829, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0026357711758464575, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0012817524839192629, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007606913568452001, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0009405397577211261, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0012716288911178708, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008963373256847262, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007206070586107671, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006971976836211979, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0008058380917645991, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0011759072076529264, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006976749864406884, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006977533921599388, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009238858474418521, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006707800785079598, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006752537447027862, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0017197906272485852, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006164690130390227, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0008330620476044714, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005897991941310465, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006341967382468283, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0006190143758431077, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007485868409276009, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0007941322401165962, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0011463523842394352, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006321353139355779, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0012779434910044074, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006897458806633949, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0013040772173553705, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0010568525176495314, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006689277361147106, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0010081789223477244, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006356916856020689, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0009671945008449256, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0008019045926630497, Min w: 0.0\n",
      "Iteration 360, Loss: 0.000693359412252903, Min w: 0.0\n",
      "Iteration 370, Loss: 0.00063050736207515, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0010760831646621227, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0006744866841472685, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006012996891513467, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006604266818612814, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006700517260469496, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0009157751337625086, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006614871672354639, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0010042063659057021, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0007234927034005523, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006121136248111725, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007436402374878526, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0010872124694287777, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0009968579979613423, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0008102727588266134, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007364946068264544, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0008085425943136215, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0012764112325385213, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006041289307177067, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0006480938754975796, Min w: 0.0\n",
      "Iteration 570, Loss: 0.001012180931866169, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008384488755837083, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006102542974986136, Min w: 0.0\n",
      "Iteration 600, Loss: 0.001813072245568037, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0007146481075324118, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0013502443907782435, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006819508853368461, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0009096958674490452, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0012377467937767506, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002858339808881283, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0009384952136315405, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0011697643203660846, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0010039623593911529, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007458191248588264, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0013766949996352196, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0007113356259651482, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0008855649502947927, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0010678708786144853, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006039490108378232, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0012779285898432136, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007383974734693766, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0008652305696159601, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0006262707756832242, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0014225379563868046, Min w: 0.0\n",
      "Iteration 810, Loss: 0.000726130383554846, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0009530916577205062, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0009589642286300659, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008640700252726674, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0011240686289966106, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008879872621037066, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0012497559655457735, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006588692776858807, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008189842919819057, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0008535785600543022, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0013169687008485198, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0024576412979513407, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0008244302007369697, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0013721896102651954, Min w: 3.019400359251405e-27\n",
      "Iteration 950, Loss: 0.0010080941719934344, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0012267741840332747, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0007067442056722939, Min w: 0.0\n",
      "Iteration 980, Loss: 0.000870636198669672, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0007715114043094218, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0009250019793398678, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0009851804934442043, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0006686148699373007, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0010926398681476712, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008553547086194158, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0010761212324723601, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007133863982744515, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007980181835591793, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008301186608150601, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0010720251593738794, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006319472449831665, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0010917852632701397, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0009384681470692158, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007843039929866791, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0008661944884806871, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0007017245516180992, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0008604118484072387, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009351076441816986, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0026219477877020836, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008353997254744172, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0011500715045258403, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0006923033506609499, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0015736471395939589, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006927232607267797, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  12%|█▎        | 3/24 [02:46<19:54, 56.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.0008929239120334387, Min w: 0.0\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.8090487641119801, 'L2_avg': 0.85345005335918, 'End_point_L1_avg': 0.7302122083214885, 'End_point_L2_avg': 0.7302173973582698}\n",
      "Iteration 0, Loss: 0.0011204044567421079, Min w: 5.642770531645344e-34\n",
      "Iteration 10, Loss: 0.000751432788092643, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0008374532917514443, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007470041164197028, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0005627191858366132, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006055993726477027, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007339547737501562, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0006891405209898949, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005837273201905191, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005671072285622358, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005915926885791123, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005383111420087516, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005620372830890119, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0005611418164335191, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006870839861221611, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006232571322470903, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006990269175730646, Min w: 1.7095841264762768e-43\n",
      "Iteration 170, Loss: 0.0006150423432700336, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0007624622085131705, Min w: 1.196043688794868e-24\n",
      "Iteration 190, Loss: 0.0006070398958399892, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005315457819961011, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005303698708303273, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005926026497036219, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005717846215702593, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005765238893218338, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006690640584565699, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0005623694742098451, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0005745771341025829, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006304548005573452, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0005710558034479618, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0005699187167920172, Min w: 6.669959172924889e-37\n",
      "Iteration 310, Loss: 0.0006400952697731555, Min w: 1.0013917906865023e-33\n",
      "Iteration 320, Loss: 0.0006277440115809441, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006427066400647163, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0007889368571341038, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0008189703803509474, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0006245640106499195, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006361349951475859, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006480640731751919, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005555367679335177, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005462275585159659, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005738635081797838, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0007829330279491842, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006379528786055744, Min w: 0.0\n",
      "Iteration 440, Loss: 0.000553562305867672, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0005549227353185415, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0005233405972830951, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0005851954920217395, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006295229541137815, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000740397023037076, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006820526323281229, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006618496845476329, Min w: 0.0\n",
      "Iteration 520, Loss: 0.000768145255278796, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0005449220188893378, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0005458696978166699, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0005897743976674974, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0006127794040367007, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0005821399972774088, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006113328854553401, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0005620063748210669, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0005352034349925816, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0005343520897440612, Min w: 0.0\n",
      "Iteration 620, Loss: 0.00058373884530738, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006544193020090461, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006911107338964939, Min w: 0.0\n",
      "Iteration 650, Loss: 0.000644613231997937, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0006761126569472253, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0005809480207972229, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0005510536720976233, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0005906695732846856, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0006893316167406738, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006065688794478774, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000546587398275733, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007385137723758817, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0006028900388628244, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0005588587373495102, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000650550879072398, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007268714834935963, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007609637686982751, Min w: 0.0\n",
      "Iteration 790, Loss: 0.000594064244069159, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006931397947482765, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0005293861613608897, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0005660930764861405, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006786485319025815, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0006795452791266143, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006837701657786965, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0005248630186542869, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006524792406708002, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008609816431999207, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0007287158514373004, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0007133869221433997, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0008005587733350694, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002564382739365101, Min w: 0.0\n",
      "Iteration 930, Loss: 0.000775880878791213, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0012250433210283518, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0014776672469452024, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006709618028253317, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0008391974261030555, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006942382315173745, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008698045858182013, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0007705554598942399, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0029404102824628353, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007059369818307459, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.001185489003546536, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0009609748958609998, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0005843458930030465, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0005401642411015928, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006684773834422231, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0009340659598819911, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.000871273223310709, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0015223188092932105, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006536479922942817, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0008222427568398416, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007511089788749814, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0008977779070846736, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006410935311578214, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006118656019680202, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.000690312182996422, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.001179289654828608, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0010187866864725947, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006490913801826537, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0027268636040389538, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.001684150192886591, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.001063966192305088, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006492045940831304, Min w: 0.0\n",
      "Iteration 0, Loss: 0.000770968443248421, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0013321884907782078, Min w: 0.0\n",
      "Iteration 20, Loss: 0.000634153897408396, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0010049684206023812, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009263849351555109, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006457220879383385, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007317531853914261, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0014108979376032948, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0012064989423379302, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0008761626668274403, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006549438112415373, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0013877559686079621, Min w: 0.0\n",
      "Iteration 120, Loss: 0.000864906411152333, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0010834282729774714, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0008739144541323185, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008403423707932234, Min w: 0.0\n",
      "Iteration 160, Loss: 0.001635069027543068, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0007012346177361906, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0013826473150402308, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0015683162491768599, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0012583787320181727, Min w: 0.0\n",
      "Iteration 210, Loss: 0.001546012586914003, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0006177813047543168, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0018371028127148747, Min w: 0.0\n",
      "Iteration 240, Loss: 0.000617323094047606, Min w: 0.0\n",
      "Iteration 250, Loss: 0.001062389463186264, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0013129583094269037, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007410530233755708, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008313664002344012, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0008323391084559262, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0035719298757612705, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0012159293983131647, Min w: 0.0\n",
      "Iteration 320, Loss: 0.002139111515134573, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0009225160465575755, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0017055964563041925, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007526140543632209, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0006159012555144727, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006497969734482467, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0007841154001653194, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0009481667075306177, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007521063089370728, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0007297807605937123, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0011100796982645988, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0011152238585054874, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0013650550972670317, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006584615912288427, Min w: 0.0\n",
      "Iteration 460, Loss: 0.000917735742405057, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0012695119949057698, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006136762676760554, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0008234194247052073, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008471733890473843, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0007979701040312648, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007050402346067131, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0009299693629145622, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006392104551196098, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0008517171954736114, Min w: 0.0\n",
      "Iteration 560, Loss: 0.000693106499966234, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0008658328442834318, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0011139449197798967, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0009739071247167885, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007512628217227757, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0010545405093580484, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0008581289439462125, Min w: 0.0\n",
      "Iteration 630, Loss: 0.000649794121272862, Min w: 0.0\n",
      "Iteration 640, Loss: 0.00109830591827631, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006552369450218976, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007426112424582243, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0006949985399842262, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0008929428295232356, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0008354486781172454, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007024433580227196, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0011892936890944839, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000712733541149646, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0006469357176683843, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0011493355268612504, Min w: 0.0\n",
      "Iteration 750, Loss: 0.000741880910936743, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0010065160458907485, Min w: 0.0\n",
      "Iteration 770, Loss: 0.000614352582488209, Min w: 0.0\n",
      "Iteration 780, Loss: 0.001019851304590702, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0008995456737466156, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0033161798492074013, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0009258651407435536, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0017837133491411805, Min w: 0.0\n",
      "Iteration 830, Loss: 0.001238879282027483, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0007956273620948195, Min w: 0.0\n",
      "Iteration 850, Loss: 0.000981444725766778, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007477457402274013, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006236554472707212, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0007647920865565538, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008462356054224074, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006960975588299334, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0005760028143413365, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0006049394141882658, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0005372033338062465, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007037596078589559, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00075638567795977, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006396010285243392, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0009594075381755829, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0012274808250367641, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0010764821199700236, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0009346548467874527, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006153961876407266, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0011786476243287325, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.001974277663975954, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0011034299386665225, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0010437009623274207, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002242558402940631, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007262839353643358, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.001250264118425548, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.000794108200352639, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007298734853975475, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0005882532568648458, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0007284784223884344, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0009875902906060219, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007062426302582026, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0005722367786802351, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006275970954447985, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009016794501803815, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006818529218435287, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0006998657481744885, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007589235901832581, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0006503827171400189, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0005985875613987446, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.000972458568867296, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008973026415333152, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0011679816525429487, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00071376544656232, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009594529401510954, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0006406463216990232, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006332186749204993, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006961955223232508, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006678859936073422, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0010968822753056884, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001351265236735344, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006079307058826089, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0010866641532629728, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0008354941965080798, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006295412313193083, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006895125843584538, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0007939222850836813, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006594847654923797, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0007352745160460472, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008602365851402283, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0015191540587693453, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0010701650753617287, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0008852793835103512, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006771222688257694, Min w: 0.0\n",
      "Iteration 220, Loss: 0.001406936557032168, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007329753134399652, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006202553049661219, Min w: 0.0\n",
      "Iteration 250, Loss: 0.000783480703830719, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0008720396435819566, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0014473446644842625, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0007764604524709284, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007945496472530067, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0009886834304779768, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007480695494450629, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0011713310377672315, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0013989879516884685, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0010322539601475, Min w: 0.0\n",
      "Iteration 350, Loss: 0.00103860127273947, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008969712071120739, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006797279929742217, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006113828858360648, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007884043734520674, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006988564855419099, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0008270479156635702, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0014350167475640774, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007430855184793472, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0007307759369723499, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001017115660943091, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0008477095398120582, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0007203797576949, Min w: 0.0\n",
      "Iteration 480, Loss: 0.001587794511578977, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0015810681506991386, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0010128205176442862, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0011930494802072644, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007884644437581301, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0013478753389790654, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006093392730690539, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006493480759672821, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007815244025550783, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0008642836473882198, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006980123580433428, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006065853522159159, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007935379981063306, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0009160575573332608, Min w: 0.0\n",
      "Iteration 620, Loss: 0.003471910487860441, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0010931659489870071, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0013738080160692334, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0010059273336082697, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007387159857898951, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0015375625807791948, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007427593227475882, Min w: 0.0\n",
      "Iteration 690, Loss: 0.001117824693210423, Min w: 0.0\n",
      "Iteration 700, Loss: 0.001209414447657764, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006746173603460193, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000657807569950819, Min w: 0.0\n",
      "Iteration 730, Loss: 0.000611260358709842, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0007823803462088108, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007383972988463938, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0010073528392240405, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0014414666220545769, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007430026889778674, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007005618535913527, Min w: 0.0\n",
      "Iteration 800, Loss: 0.001599553506821394, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008335087914019823, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007251863135024905, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006029184442013502, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0006865372997708619, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006221810472197831, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0006991573027335107, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006692119059152901, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008328980766236782, Min w: 0.0\n",
      "Iteration 890, Loss: 0.00342430523596704, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0009380865376442671, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0013005787041038275, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0010883045615628362, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0007500426727347076, Min w: 0.0\n",
      "Iteration 940, Loss: 0.000751756364479661, Min w: 0.0\n",
      "Iteration 950, Loss: 0.000784339033998549, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0008889702148735523, Min w: 0.0\n",
      "Iteration 970, Loss: 0.001104406313970685, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006670852308161557, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006191851571202278, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.000808409065939486, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0007648838218301535, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0006292778998613358, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0008418759680353105, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0009243149543181062, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0013487088726833463, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006811203202232718, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0008588763303123415, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008561596623621881, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006428994238376617, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0010905428789556026, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.000901940802577883, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006540032336488366, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006103147752583027, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006736299837939441, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0010109260911121964, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0009294733754359186, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.000620005012024194, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0007039999472908676, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.000636447046417743, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006427805637940764, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007890109554864466, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.001082435715943575, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0010847302619367838, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006925026536919177, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0010174765484407544, Min w: 2.7214697339141395e-28\n",
      "Iteration 10, Loss: 0.0014860840747132897, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007956748595461249, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0009563749772496521, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008672581752762198, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006805963348597288, Min w: 0.0\n",
      "Iteration 60, Loss: 0.000704533071257174, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0010458406759425998, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007719981367699802, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0019491317216306925, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0012791111366823316, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000646523607429117, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006792035419493914, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007740763830952346, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0010270109632983804, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0007424834184348583, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002209007041528821, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0012131764087826014, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0009361644042655826, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006086159264668822, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006780400290153921, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006118839373812079, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0009513487457297742, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007695803069509566, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0009675322216935456, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0010255197994410992, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006303399568423629, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0015015460085123777, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006677883211523294, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007741487352177501, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007152978796511889, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0010082367807626724, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006814031512476504, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006535333232022822, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0007449845434166491, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001334384549409151, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0006918611470609903, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0008293712744489312, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006755450740456581, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0008361011277884245, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0009348099702037871, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0009630363201722503, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0036962011363357306, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0015837575774639845, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008926242589950562, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0010089293355122209, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0017846099799498916, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0012050902005285025, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000998486066237092, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0010233091888949275, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0007526731351390481, Min w: 0.0\n",
      "Iteration 510, Loss: 0.001341077033430338, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0006990491528995335, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0012621399946510792, Min w: 0.0\n",
      "Iteration 540, Loss: 0.000812408747151494, Min w: 0.0\n",
      "Iteration 550, Loss: 0.001191533519886434, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007301323348656297, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0007975620683282614, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007909226696938276, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0011561647988855839, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006290777819231153, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006116482545621693, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0007753261015750468, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0007106034317985177, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006317681982181966, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008086877642199397, Min w: 0.0\n",
      "Iteration 660, Loss: 0.001739851082675159, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007514972239732742, Min w: 0.0\n",
      "Iteration 680, Loss: 0.001594156725332141, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006117185694165528, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0014467104338109493, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006348719471134245, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006503679906018078, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007844559731893241, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0007335224072448909, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007994543411768973, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000737419119104743, Min w: 0.0\n",
      "Iteration 770, Loss: 0.001132381847128272, Min w: 4.688000178385164e-22\n",
      "Iteration 780, Loss: 0.001196518656797707, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0006597390165552497, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0010193763300776482, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006797211244702339, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007161382818594575, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006177847972139716, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008475192589685321, Min w: 0.0\n",
      "Iteration 850, Loss: 0.00069105823058635, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007152415346354246, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0014078236417844892, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0010552052408456802, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0007836275617592037, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006707328138872981, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006653660675510764, Min w: 0.0\n",
      "Iteration 920, Loss: 0.000764774507842958, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0008684383356012404, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0008148358319886029, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0016124225221574306, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0008680460741743445, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0010213595815002918, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0010084842797368765, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008356717880815268, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0014517864910885692, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0007076230249367654, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007167040603235364, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0005898004164919257, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0009746147552505136, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0006074619013816118, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0008607355994172394, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0008029929595068097, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.000804391223937273, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006961339386180043, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006845099269412458, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0011177508858963847, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006411667563952506, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0016453830758109689, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007630386389791965, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0010537205962464213, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0008129357011057436, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009465920156799257, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0008283049683086574, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0006793116917833686, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0010079200146719813, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0009461729205213487, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0007506138645112514, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0013572884490713477, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008320632041431963, Min w: 0.0\n",
      "Iteration 0, Loss: 0.000683832389768213, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006445090402849019, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006198865012265742, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007995253545232117, Min w: 0.0\n",
      "Iteration 40, Loss: 0.001271623419597745, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006492867833003402, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006158417090773582, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007642704877071083, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0009137175511568785, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0012124394997954369, Min w: 0.0\n",
      "Iteration 100, Loss: 0.001405780203640461, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007404388743452728, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0009026727639138699, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0009594160947017372, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0007924307719804347, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006192435976117849, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006650217692367733, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008634834666736424, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0015002600848674774, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0008806386613287032, Min w: 0.0\n",
      "Iteration 200, Loss: 0.00103672593832016, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0014076009392738342, Min w: 0.0\n",
      "Iteration 220, Loss: 0.001136086881160736, Min w: 0.0\n",
      "Iteration 230, Loss: 0.000833317986689508, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0007939302595332265, Min w: 0.0\n",
      "Iteration 250, Loss: 0.001089532277546823, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0007412030245177448, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007346473284997046, Min w: 0.0\n",
      "Iteration 280, Loss: 0.000808483047876507, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0009246335248462856, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0027109431102871895, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0009472921956330538, Min w: 0.0\n",
      "Iteration 320, Loss: 0.00129797519184649, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006523832562379539, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0007112662424333394, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001394106075167656, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0007144536357372999, Min w: 0.0\n",
      "Iteration 370, Loss: 0.000786586431786418, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006234809407033026, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000822288915514946, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0009772027842700481, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006109462701715529, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0011672464897856116, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007394121494144201, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0012987949885427952, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006574701401405036, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0008788964478299022, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0018244889797642827, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0016915397718548775, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006782758864574134, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0010912114521488547, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0009005383471958339, Min w: 1.881914550450325e-38\n",
      "Iteration 520, Loss: 0.001406176364980638, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0007992275641299784, Min w: 0.0\n",
      "Iteration 540, Loss: 0.000611080729868263, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006271685124374926, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0017731930129230022, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0007796795107424259, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0009759251843206584, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006395545206032693, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002327426103875041, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0010703916195780039, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0011197584681212902, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0010038845939561725, Min w: 0.0\n",
      "Iteration 640, Loss: 0.000822498754132539, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0012900284491479397, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0006876258412376046, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0009139384492300451, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0011197995627298951, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0012124379863962531, Min w: 0.0\n",
      "Iteration 700, Loss: 0.000740688992664218, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008914975333027542, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0012517845025286078, Min w: 0.0\n",
      "Iteration 730, Loss: 0.000815464009065181, Min w: 0.0\n",
      "Iteration 740, Loss: 0.001129434327594936, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007455634186044335, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0011210134252905846, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007591804605908692, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007484554662369192, Min w: 0.0\n",
      "Iteration 790, Loss: 0.001887899823486805, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009552650735713542, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006333278142847121, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007055987371131778, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0012966060312464833, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012136097066104412, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006574381841346622, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007982050883583724, Min w: 0.0\n",
      "Iteration 870, Loss: 0.001381190144456923, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0022215526551008224, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006603606743738055, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0010806635254994035, Min w: 0.0\n",
      "Iteration 910, Loss: 0.001211301889270544, Min w: 0.0\n",
      "Iteration 920, Loss: 0.000812450482044369, Min w: 0.0\n",
      "Iteration 930, Loss: 0.00082640431355685, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006669075810350478, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0006675606709904969, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006032265373505652, Min w: 0.0\n",
      "Iteration 970, Loss: 0.001309343846514821, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0007135644555091858, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006930162198841572, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0009643459925428033, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0009451709920540452, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0008575253887102008, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006248116260394454, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006225426332093775, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.000701210810802877, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006211582804098725, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.000693719950504601, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0021697860211133957, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0011236458085477352, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0011102701537311077, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0007114300387911499, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006223338423296809, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006400339771062136, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007254857337102294, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0007436207961291075, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006957912701182067, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006227533449418843, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0008328096009790897, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008701143087819219, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007267950568348169, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007824172498658299, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.001770199742168188, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0012965184869244695, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  17%|█▋        | 4/24 [03:47<19:33, 58.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.0008428773726336658, Min w: 0.0\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 1.2635708856234014, 'L2_avg': 1.3168526343104312, 'End_point_L1_avg': 1.2501622405556803, 'End_point_L2_avg': 1.280853635295467}\n",
      "Iteration 0, Loss: 0.005271924193948507, Min w: 0.0\n",
      "Iteration 10, Loss: 0.004112645052373409, Min w: 8.440185399541389e-13\n",
      "Iteration 20, Loss: 0.0035421287175267935, Min w: 7.544400803749176e-37\n",
      "Iteration 30, Loss: 0.0027909923810511827, Min w: 1.7199264721327645e-16\n",
      "Iteration 40, Loss: 0.0027530756779015064, Min w: 2.2363075473946933e-35\n",
      "Iteration 50, Loss: 0.0028625500854104757, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0026183174923062325, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002893633209168911, Min w: 0.0\n",
      "Iteration 80, Loss: 0.002529388526454568, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0025437024887651205, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002506495453417301, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0021544620394706726, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0018130734097212553, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0018327529542148113, Min w: 0.0\n",
      "Iteration 140, Loss: 0.001760873245075345, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0016011149855330586, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0015827808529138565, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0016847539227455854, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0018024775199592113, Min w: 1.4526747902716061e-28\n",
      "Iteration 190, Loss: 0.0014261440373957157, Min w: 1.3160703743599648e-23\n",
      "Iteration 200, Loss: 0.001410926110111177, Min w: 5.111159344722815e-18\n",
      "Iteration 210, Loss: 0.0013474058359861374, Min w: 2.9244113193271914e-06\n",
      "Iteration 220, Loss: 0.001380828325636685, Min w: 0.00024904514430090785\n",
      "Iteration 230, Loss: 0.0013998079812154174, Min w: 6.199155905051157e-06\n",
      "Iteration 240, Loss: 0.0012867040932178497, Min w: 0.09997007995843887\n",
      "Iteration 250, Loss: 0.0011807027040049434, Min w: 0.2502824664115906\n",
      "Iteration 260, Loss: 0.0010853608837351203, Min w: 0.2576591372489929\n",
      "Iteration 270, Loss: 0.0009886181214824319, Min w: 0.3141316771507263\n",
      "Iteration 280, Loss: 0.001012176275253296, Min w: 0.3567866086959839\n",
      "Iteration 290, Loss: 0.0008639838779345155, Min w: 0.382060706615448\n",
      "Iteration 300, Loss: 0.000860133848618716, Min w: 0.4356670677661896\n",
      "Iteration 310, Loss: 0.0007837877492420375, Min w: 0.452199250459671\n",
      "Iteration 320, Loss: 0.0006858341512270272, Min w: 0.508283257484436\n",
      "Iteration 330, Loss: 0.000703480385709554, Min w: 0.5490779876708984\n",
      "Iteration 340, Loss: 0.0006653291056863964, Min w: 0.5387399792671204\n",
      "Iteration 350, Loss: 0.0005855473573319614, Min w: 0.5857430100440979\n",
      "Iteration 360, Loss: 0.0006463835597969592, Min w: 0.6066526174545288\n",
      "Iteration 370, Loss: 0.0005727271200157702, Min w: 0.5955737829208374\n",
      "Iteration 380, Loss: 0.0005518924444913864, Min w: 0.5977771282196045\n",
      "Iteration 390, Loss: 0.0005498026730492711, Min w: 0.627237856388092\n",
      "Iteration 400, Loss: 0.00046113302232697606, Min w: 0.686286449432373\n",
      "Iteration 410, Loss: 0.000447862345026806, Min w: 0.6904734969139099\n",
      "Iteration 420, Loss: 0.0004686241445597261, Min w: 0.7347562909126282\n",
      "Iteration 430, Loss: 0.00034716317895799875, Min w: 0.7641004323959351\n",
      "Iteration 440, Loss: 0.0003873124660458416, Min w: 0.772216796875\n",
      "Iteration 450, Loss: 0.0003657563647720963, Min w: 0.7738346457481384\n",
      "Iteration 460, Loss: 0.0003309770836494863, Min w: 0.8034204244613647\n",
      "Iteration 470, Loss: 0.00033110767253674567, Min w: 0.8184112310409546\n",
      "Iteration 480, Loss: 0.0002917128149420023, Min w: 0.8369559049606323\n",
      "Iteration 490, Loss: 0.000433729263022542, Min w: 0.7098850607872009\n",
      "Iteration 500, Loss: 0.0003731783071998507, Min w: 0.8064337968826294\n",
      "Iteration 510, Loss: 0.00025355478283017874, Min w: 0.8610684275627136\n",
      "Iteration 520, Loss: 0.00021270717843435705, Min w: 0.8671916723251343\n",
      "Iteration 530, Loss: 0.0001892862346721813, Min w: 0.8837118148803711\n",
      "Iteration 540, Loss: 0.00023046109708957374, Min w: 0.875445544719696\n",
      "Iteration 550, Loss: 0.00026564925792627037, Min w: 0.8379642963409424\n",
      "Iteration 560, Loss: 0.00018728563736658543, Min w: 0.8876375555992126\n",
      "Iteration 570, Loss: 0.0001785055355867371, Min w: 0.90574049949646\n",
      "Iteration 580, Loss: 0.00015804149734321982, Min w: 0.9154848456382751\n",
      "Iteration 590, Loss: 0.000166513113072142, Min w: 0.9108552932739258\n",
      "Iteration 600, Loss: 0.00013320169819053262, Min w: 0.9303598403930664\n",
      "Iteration 610, Loss: 0.00013397657312452793, Min w: 0.9312618374824524\n",
      "Iteration 620, Loss: 0.00011805071699200198, Min w: 0.9347173571586609\n",
      "Iteration 630, Loss: 0.00017342115461360663, Min w: 0.8997244834899902\n",
      "Iteration 640, Loss: 0.00018783050472848117, Min w: 0.8825283050537109\n",
      "Iteration 650, Loss: 0.00015151596744544804, Min w: 0.9174941778182983\n",
      "Iteration 660, Loss: 0.00013807699724566191, Min w: 0.9280946850776672\n",
      "Iteration 670, Loss: 0.00013200929970480502, Min w: 0.9210340976715088\n",
      "Iteration 680, Loss: 9.179415792459622e-05, Min w: 0.9521287679672241\n",
      "Iteration 690, Loss: 0.00015966070350259542, Min w: 0.9023998379707336\n",
      "Iteration 700, Loss: 9.039836004376411e-05, Min w: 0.952835738658905\n",
      "Iteration 710, Loss: 0.00013693385699298233, Min w: 0.916945219039917\n",
      "Iteration 720, Loss: 6.789529288653284e-05, Min w: 0.965205192565918\n",
      "Iteration 730, Loss: 7.056150934658945e-05, Min w: 0.9631937742233276\n",
      "Iteration 740, Loss: 9.126697841566056e-05, Min w: 0.9506862163543701\n",
      "Iteration 750, Loss: 0.00011621932935668156, Min w: 0.9287297129631042\n",
      "Iteration 760, Loss: 6.955651042517275e-05, Min w: 0.9627686738967896\n",
      "Iteration 770, Loss: 0.00021201300842221826, Min w: 0.8676826357841492\n",
      "Iteration 780, Loss: 9.586210217094049e-05, Min w: 0.9478989243507385\n",
      "Iteration 790, Loss: 8.39285203255713e-05, Min w: 0.9458697438240051\n",
      "Iteration 800, Loss: 0.0001165211433544755, Min w: 0.9367105960845947\n",
      "Iteration 810, Loss: 4.93003535666503e-05, Min w: 0.9713355302810669\n",
      "Iteration 820, Loss: 0.00011990864004474133, Min w: 0.9218176007270813\n",
      "Iteration 830, Loss: 8.546230674255639e-05, Min w: 0.9383827447891235\n",
      "Iteration 840, Loss: 4.6482233301503584e-05, Min w: 0.9748942852020264\n",
      "Iteration 850, Loss: 6.356173980748281e-05, Min w: 0.9571751952171326\n",
      "Iteration 860, Loss: 5.04726376675535e-05, Min w: 0.9698612689971924\n",
      "Iteration 870, Loss: 0.0001204480358865112, Min w: 0.9179311990737915\n",
      "Iteration 880, Loss: 0.00011733714927686378, Min w: 0.9195943474769592\n",
      "Iteration 890, Loss: 0.00010169803135795519, Min w: 0.9263410568237305\n",
      "Iteration 900, Loss: 4.4284024625085294e-05, Min w: 0.9730350375175476\n",
      "Iteration 910, Loss: 6.201108044479042e-05, Min w: 0.9617753624916077\n",
      "Iteration 920, Loss: 3.7415189581224695e-05, Min w: 0.9804912209510803\n",
      "Iteration 930, Loss: 4.217557216179557e-05, Min w: 0.977545976638794\n",
      "Iteration 940, Loss: 0.00011505883594509214, Min w: 0.9314852356910706\n",
      "Iteration 950, Loss: 3.570473927538842e-05, Min w: 0.9798848032951355\n",
      "Iteration 960, Loss: 3.695805571624078e-05, Min w: 0.9799988865852356\n",
      "Iteration 970, Loss: 3.273660331615247e-05, Min w: 0.9810006022453308\n",
      "Iteration 980, Loss: 6.744354323018342e-05, Min w: 0.9533089399337769\n",
      "Iteration 990, Loss: 3.944187119486742e-05, Min w: 0.9760851860046387\n",
      "Iteration 1000, Loss: 4.2091181967407465e-05, Min w: 0.9778372645378113\n",
      "Iteration 1010, Loss: 3.707686482812278e-05, Min w: 0.9766351580619812\n",
      "Iteration 1020, Loss: 0.00010211128392256796, Min w: 0.9255996942520142\n",
      "Iteration 1030, Loss: 9.033385140355676e-05, Min w: 0.9362469911575317\n",
      "Iteration 1040, Loss: 5.877635339857079e-05, Min w: 0.9672472476959229\n",
      "Iteration 1050, Loss: 2.817933273036033e-05, Min w: 0.9848944544792175\n",
      "Iteration 1060, Loss: 9.324667189503089e-05, Min w: 0.9486106634140015\n",
      "Iteration 1070, Loss: 3.6581652238965034e-05, Min w: 0.9757861495018005\n",
      "Iteration 1080, Loss: 3.594070949475281e-05, Min w: 0.9785142540931702\n",
      "Iteration 1090, Loss: 3.842947262455709e-05, Min w: 0.972587525844574\n",
      "Iteration 1100, Loss: 3.756207297556102e-05, Min w: 0.9783840775489807\n",
      "Iteration 1110, Loss: 9.280964877689257e-05, Min w: 0.9454764723777771\n",
      "Iteration 1120, Loss: 2.9235987312858924e-05, Min w: 0.9824442267417908\n",
      "Iteration 1130, Loss: 9.421673166798428e-05, Min w: 0.9307313561439514\n",
      "Iteration 1140, Loss: 2.5625520720495842e-05, Min w: 0.9852970242500305\n",
      "Iteration 1150, Loss: 7.013705180725083e-05, Min w: 0.9569700956344604\n",
      "Iteration 1160, Loss: 3.3935470128199086e-05, Min w: 0.9801104068756104\n",
      "Iteration 1170, Loss: 3.337486123200506e-05, Min w: 0.9820427894592285\n",
      "Iteration 1180, Loss: 3.0841889383737e-05, Min w: 0.9806410670280457\n",
      "Iteration 1190, Loss: 2.8501995984697714e-05, Min w: 0.984762966632843\n",
      "Iteration 1200, Loss: 6.241413939278573e-05, Min w: 0.9546884894371033\n",
      "Iteration 1210, Loss: 2.181850140914321e-05, Min w: 0.9882869124412537\n",
      "Iteration 1220, Loss: 6.932295946171507e-05, Min w: 0.9510017037391663\n",
      "Iteration 1230, Loss: 6.767718150513247e-05, Min w: 0.9511383771896362\n",
      "Iteration 1240, Loss: 0.00010388554073870182, Min w: 0.9337995052337646\n",
      "Iteration 0, Loss: 2.8729074983857572e-05, Min w: 0.9843965768814087\n",
      "Iteration 10, Loss: 5.092744322610088e-05, Min w: 0.9691790342330933\n",
      "Early break at iteration 16 --------------------------------\n",
      "Iteration 0, Loss: 2.2129197532194667e-05, Min w: 0.9880082011222839\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 2.4625664082122967e-05, Min w: 0.9842657446861267\n",
      "Early break at iteration 6 --------------------------------\n",
      "Iteration 0, Loss: 2.157122435164638e-05, Min w: 0.988449215888977\n",
      "Iteration 10, Loss: 5.4004034609533846e-05, Min w: 0.9674614667892456\n",
      "Iteration 20, Loss: 4.443578654900193e-05, Min w: 0.9741086959838867\n",
      "Iteration 30, Loss: 2.2506983441417105e-05, Min w: 0.9881219863891602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  21%|██        | 5/24 [03:59<13:10, 41.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, Loss: 4.6006389311514795e-05, Min w: 0.9660285115242004\n",
      "Iteration 50, Loss: 2.2855843781144358e-05, Min w: 0.9882131814956665\n",
      "Early break at iteration 51 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 1334, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.008502542100307469, 'L2_avg': 0.010166251866942495, 'End_point_L1_avg': 0.007945281038415818, 'End_point_L2_avg': 0.008057870904915556}\n",
      "Iteration 0, Loss: 0.005413839127868414, Min w: 1.1836285651001114e-34\n",
      "Iteration 10, Loss: 0.004776893183588982, Min w: 0.00045809996663592756\n",
      "Iteration 20, Loss: 0.0033808592706918716, Min w: 4.489910310212508e-08\n",
      "Iteration 30, Loss: 0.002916567027568817, Min w: 3.1122406653594226e-05\n",
      "Iteration 40, Loss: 0.0026223263703286648, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0022462657652795315, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002019984647631645, Min w: 0.0\n",
      "Iteration 70, Loss: 0.001966404030099511, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0018037945264950395, Min w: 0.0\n",
      "Iteration 90, Loss: 0.001799111720174551, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0018723363755270839, Min w: 2.8754644487945246e-42\n",
      "Iteration 110, Loss: 0.0016551259905099869, Min w: 9.790404672862044e-37\n",
      "Iteration 120, Loss: 0.0014761537313461304, Min w: 1.8190028640062127e-32\n",
      "Iteration 130, Loss: 0.001485456246882677, Min w: 2.786256470721581e-25\n",
      "Iteration 140, Loss: 0.0015562484040856361, Min w: 2.0585958068405907e-13\n",
      "Iteration 150, Loss: 0.0015857173129916191, Min w: 0.007651075255125761\n",
      "Iteration 160, Loss: 0.001476756762713194, Min w: 0.03925035148859024\n",
      "Iteration 170, Loss: 0.0012686135014519095, Min w: 0.18287859857082367\n",
      "Iteration 180, Loss: 0.0012155056465417147, Min w: 0.23501287400722504\n",
      "Iteration 190, Loss: 0.0010814405977725983, Min w: 0.31006962060928345\n",
      "Iteration 200, Loss: 0.0010016750311478972, Min w: 0.3612486720085144\n",
      "Iteration 210, Loss: 0.0009292453178204596, Min w: 0.3938143253326416\n",
      "Iteration 220, Loss: 0.0008223408949561417, Min w: 0.4627922475337982\n",
      "Iteration 230, Loss: 0.0007815809221938252, Min w: 0.49973681569099426\n",
      "Iteration 240, Loss: 0.0007582908147014678, Min w: 0.5073524713516235\n",
      "Iteration 250, Loss: 0.0006862161098979414, Min w: 0.5271249413490295\n",
      "Iteration 260, Loss: 0.0007680018898099661, Min w: 0.48733916878700256\n",
      "Iteration 270, Loss: 0.0006210795254446566, Min w: 0.5821726322174072\n",
      "Iteration 280, Loss: 0.0005731453420594335, Min w: 0.6171831488609314\n",
      "Iteration 290, Loss: 0.0005212953547015786, Min w: 0.6501383781433105\n",
      "Iteration 300, Loss: 0.0004966879496350884, Min w: 0.6467989087104797\n",
      "Iteration 310, Loss: 0.0005345913814380765, Min w: 0.6658493876457214\n",
      "Iteration 320, Loss: 0.00046137525350786746, Min w: 0.6740223169326782\n",
      "Iteration 330, Loss: 0.0004316028789617121, Min w: 0.7079391479492188\n",
      "Iteration 340, Loss: 0.00044818021706305444, Min w: 0.7174076437950134\n",
      "Iteration 350, Loss: 0.00044786391663365066, Min w: 0.6962488889694214\n",
      "Iteration 360, Loss: 0.000348861503880471, Min w: 0.7666962146759033\n",
      "Iteration 370, Loss: 0.00032476341584697366, Min w: 0.7739470601081848\n",
      "Iteration 380, Loss: 0.0004535077896434814, Min w: 0.7641777992248535\n",
      "Iteration 390, Loss: 0.0003638344642240554, Min w: 0.8109045624732971\n",
      "Iteration 400, Loss: 0.0003851985093206167, Min w: 0.803968608379364\n",
      "Iteration 410, Loss: 0.0002604993642307818, Min w: 0.823183000087738\n",
      "Iteration 420, Loss: 0.00023721785692032427, Min w: 0.8364836573600769\n",
      "Iteration 430, Loss: 0.00034751699422486126, Min w: 0.818505048751831\n",
      "Iteration 440, Loss: 0.00022341903240885586, Min w: 0.8684813976287842\n",
      "Iteration 450, Loss: 0.00024521516752429307, Min w: 0.8657742142677307\n",
      "Iteration 460, Loss: 0.00025698242825455964, Min w: 0.8622399568557739\n",
      "Iteration 470, Loss: 0.00019023440836463124, Min w: 0.8837687969207764\n",
      "Iteration 480, Loss: 0.00029886531410738826, Min w: 0.8088536262512207\n",
      "Iteration 490, Loss: 0.0001636828383198008, Min w: 0.9025381207466125\n",
      "Iteration 500, Loss: 0.00020077600493095815, Min w: 0.8689941167831421\n",
      "Iteration 510, Loss: 0.00014359987108036876, Min w: 0.9163443446159363\n",
      "Iteration 520, Loss: 0.00017946792650036514, Min w: 0.9031906723976135\n",
      "Iteration 530, Loss: 0.0001688826159806922, Min w: 0.9094957709312439\n",
      "Iteration 540, Loss: 0.0002466224250383675, Min w: 0.8662088513374329\n",
      "Iteration 550, Loss: 0.00019623409025371075, Min w: 0.8846557140350342\n",
      "Iteration 560, Loss: 0.00013937230687588453, Min w: 0.928268313407898\n",
      "Iteration 570, Loss: 0.0001358914450975135, Min w: 0.9220919609069824\n",
      "Iteration 580, Loss: 0.00011367192200850695, Min w: 0.9342958927154541\n",
      "Iteration 590, Loss: 9.265301196137443e-05, Min w: 0.9468851089477539\n",
      "Iteration 600, Loss: 0.00012350172619335353, Min w: 0.9351462721824646\n",
      "Iteration 610, Loss: 8.59107167343609e-05, Min w: 0.9519866108894348\n",
      "Iteration 620, Loss: 0.00010225803998764604, Min w: 0.9417859315872192\n",
      "Iteration 630, Loss: 0.00013493768346961588, Min w: 0.9253476858139038\n",
      "Iteration 640, Loss: 0.0001066914846887812, Min w: 0.9337680339813232\n",
      "Iteration 650, Loss: 0.00018018011178355664, Min w: 0.8822795748710632\n",
      "Iteration 660, Loss: 8.242904004873708e-05, Min w: 0.9576075673103333\n",
      "Iteration 670, Loss: 7.004154031164944e-05, Min w: 0.957168459892273\n",
      "Iteration 680, Loss: 0.00010993135219905525, Min w: 0.9270092248916626\n",
      "Iteration 690, Loss: 8.895242353901267e-05, Min w: 0.9543626308441162\n",
      "Iteration 700, Loss: 0.00013556495832744986, Min w: 0.9191052317619324\n",
      "Iteration 710, Loss: 9.319985838374123e-05, Min w: 0.9512365460395813\n",
      "Iteration 720, Loss: 0.0001003060897346586, Min w: 0.9359868764877319\n",
      "Iteration 730, Loss: 9.663435776019469e-05, Min w: 0.9380415678024292\n",
      "Iteration 740, Loss: 8.775740570854396e-05, Min w: 0.9480717778205872\n",
      "Iteration 750, Loss: 5.5172138672787696e-05, Min w: 0.9685061573982239\n",
      "Iteration 760, Loss: 0.0001136598875746131, Min w: 0.9378336071968079\n",
      "Iteration 770, Loss: 0.00010541428491706029, Min w: 0.9411785006523132\n",
      "Iteration 780, Loss: 0.00015558555605821311, Min w: 0.8825306296348572\n",
      "Iteration 790, Loss: 0.00011940827243961394, Min w: 0.9299934506416321\n",
      "Iteration 800, Loss: 0.00011591960355872288, Min w: 0.9397246241569519\n",
      "Iteration 810, Loss: 6.617381586693227e-05, Min w: 0.9569499492645264\n",
      "Iteration 820, Loss: 0.00011597284901654348, Min w: 0.9333686828613281\n",
      "Iteration 830, Loss: 4.608078597811982e-05, Min w: 0.9760173559188843\n",
      "Iteration 840, Loss: 9.047780622495338e-05, Min w: 0.9498040080070496\n",
      "Iteration 850, Loss: 5.4819462093291804e-05, Min w: 0.9712986350059509\n",
      "Iteration 860, Loss: 4.354069096734747e-05, Min w: 0.9771336317062378\n",
      "Iteration 870, Loss: 5.4025025747250766e-05, Min w: 0.9694164395332336\n",
      "Iteration 880, Loss: 3.818715049419552e-05, Min w: 0.9770902395248413\n",
      "Iteration 890, Loss: 3.9342328818747774e-05, Min w: 0.9788251519203186\n",
      "Iteration 900, Loss: 0.00028501570341177285, Min w: 0.8310532569885254\n",
      "Iteration 910, Loss: 5.3328250942286104e-05, Min w: 0.97062087059021\n",
      "Iteration 920, Loss: 0.000103619800938759, Min w: 0.924860417842865\n",
      "Iteration 930, Loss: 5.8639787312131375e-05, Min w: 0.9609882831573486\n",
      "Iteration 940, Loss: 4.250907659297809e-05, Min w: 0.9772304892539978\n",
      "Iteration 950, Loss: 3.9386697608279064e-05, Min w: 0.9797700047492981\n",
      "Iteration 960, Loss: 4.207935853628442e-05, Min w: 0.9756177663803101\n",
      "Iteration 970, Loss: 0.00011603773600654677, Min w: 0.9122921824455261\n",
      "Iteration 980, Loss: 3.816590833594091e-05, Min w: 0.9780051112174988\n",
      "Iteration 990, Loss: 3.401054345886223e-05, Min w: 0.9804820418357849\n",
      "Iteration 1000, Loss: 3.456029298831709e-05, Min w: 0.9790270924568176\n",
      "Iteration 1010, Loss: 2.81378688669065e-05, Min w: 0.9845039248466492\n",
      "Iteration 1020, Loss: 3.3107600756920874e-05, Min w: 0.9818111062049866\n",
      "Iteration 1030, Loss: 3.101102993241511e-05, Min w: 0.9830170273780823\n",
      "Iteration 1040, Loss: 3.7820194847881794e-05, Min w: 0.9783147573471069\n",
      "Iteration 1050, Loss: 7.654827641090378e-05, Min w: 0.9591969847679138\n",
      "Iteration 1060, Loss: 4.0226550481747836e-05, Min w: 0.9788593649864197\n",
      "Iteration 1070, Loss: 3.5761822800850496e-05, Min w: 0.9816223978996277\n",
      "Iteration 1080, Loss: 2.718704672588501e-05, Min w: 0.9843100309371948\n",
      "Iteration 1090, Loss: 2.9944074412924238e-05, Min w: 0.9836527109146118\n",
      "Iteration 1100, Loss: 4.866697781835683e-05, Min w: 0.9688919186592102\n",
      "Iteration 1110, Loss: 3.414502498344518e-05, Min w: 0.9787689447402954\n",
      "Iteration 1120, Loss: 3.560601908247918e-05, Min w: 0.9803608655929565\n",
      "Iteration 1130, Loss: 9.401138231623918e-05, Min w: 0.9377029538154602\n",
      "Iteration 1140, Loss: 3.3784974220907316e-05, Min w: 0.979722261428833\n",
      "Iteration 1150, Loss: 5.99788581894245e-05, Min w: 0.9605821371078491\n",
      "Iteration 1160, Loss: 2.8174636099720374e-05, Min w: 0.9842894077301025\n",
      "Iteration 1170, Loss: 8.93129690666683e-05, Min w: 0.9500365257263184\n",
      "Iteration 1180, Loss: 3.029479739780072e-05, Min w: 0.9821377992630005\n",
      "Iteration 1190, Loss: 2.1663316147169098e-05, Min w: 0.9881737232208252\n",
      "Iteration 1200, Loss: 0.00012380281987134367, Min w: 0.9203914999961853\n",
      "Iteration 1210, Loss: 2.7687925467034802e-05, Min w: 0.9812753796577454\n",
      "Iteration 1220, Loss: 2.3117871023714542e-05, Min w: 0.9852719306945801\n",
      "Iteration 1230, Loss: 0.00016000622417777777, Min w: 0.8996288180351257\n",
      "Iteration 1240, Loss: 2.397422940703109e-05, Min w: 0.9867277145385742\n",
      "Iteration 0, Loss: 7.787884533172473e-05, Min w: 0.9362543821334839\n",
      "Iteration 10, Loss: 3.325862417113967e-05, Min w: 0.9788312911987305\n",
      "Iteration 20, Loss: 7.441985508194193e-05, Min w: 0.9570266008377075\n",
      "Iteration 30, Loss: 2.6212115699308924e-05, Min w: 0.9847006797790527\n",
      "Iteration 40, Loss: 0.00010508422565180808, Min w: 0.934493899345398\n",
      "Iteration 50, Loss: 2.3762202545185573e-05, Min w: 0.9866555333137512\n",
      "Iteration 60, Loss: 8.461742254439741e-05, Min w: 0.9439293146133423\n",
      "Early break at iteration 67 --------------------------------\n",
      "Iteration 0, Loss: 1.782542312867008e-05, Min w: 0.9896265268325806\n",
      "Iteration 10, Loss: 0.00010477320029167458, Min w: 0.9280127882957458\n",
      "Early break at iteration 16 --------------------------------\n",
      "Iteration 0, Loss: 1.9051372873946093e-05, Min w: 0.9892624020576477\n",
      "Iteration 10, Loss: 9.289599256590009e-05, Min w: 0.946271538734436\n",
      "Iteration 20, Loss: 2.051008414127864e-05, Min w: 0.9890278577804565\n",
      "Iteration 30, Loss: 2.1031253709224984e-05, Min w: 0.9877623319625854\n",
      "Iteration 40, Loss: 4.769951192429289e-05, Min w: 0.9733135104179382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  25%|██▌       | 6/24 [04:11<09:29, 31.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 49 --------------------------------\n",
      "Iteration 0, Loss: 1.6964877431746572e-05, Min w: 0.991098940372467\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 1386, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.007153491611293559, 'L2_avg': 0.008450095874339578, 'End_point_L1_avg': 0.005500434017163899, 'End_point_L2_avg': 0.005922156159486342}\n",
      "Iteration 0, Loss: 0.0011639805743470788, Min w: 0.0\n",
      "Iteration 10, Loss: 0.001107364078052342, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009235889883711934, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0009067904902622104, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009044917533174157, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0008668822119943798, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007944046519696712, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008111377246677876, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007303408929146826, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007541269296780229, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0007023251964710653, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006744315032847226, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0007269565248861909, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006609049160033464, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006614160374738276, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006943239131942391, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006406475440599024, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006884884787723422, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006656176410615444, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006344494759105146, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005985592142678797, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005548170302063227, Min w: 0.0\n",
      "Iteration 220, Loss: 0.00043838596320711076, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0004622821870725602, Min w: 0.0\n",
      "Iteration 240, Loss: 0.00043041023309342563, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0004529770230874419, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00040977814933285117, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0003953695413656533, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0003895815461874008, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0003768930910155177, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0003539627941790968, Min w: 0.0\n",
      "Iteration 310, Loss: 0.000349764566635713, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0003596165624912828, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00037313703796826303, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0003972277627326548, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0004194434150122106, Min w: 0.0\n",
      "Iteration 360, Loss: 0.00039318823837675154, Min w: 4.402548279269705e-26\n",
      "Iteration 370, Loss: 0.0003979174653068185, Min w: 7.697972982797716e-14\n",
      "Iteration 380, Loss: 0.00042596625280566514, Min w: 7.166362792077052e-08\n",
      "Iteration 390, Loss: 0.00036416423972696066, Min w: 3.925650027269967e-09\n",
      "Iteration 400, Loss: 0.00044559664092957973, Min w: 2.1250799332079315e-18\n",
      "Iteration 410, Loss: 0.00037090497789904475, Min w: 8.600946597764803e-27\n",
      "Iteration 420, Loss: 0.00035024117096327245, Min w: 4.0913489561447246e-22\n",
      "Iteration 430, Loss: 0.00035273024695925415, Min w: 3.781670496091601e-15\n",
      "Iteration 440, Loss: 0.000385325460229069, Min w: 5.075076209976048e-12\n",
      "Iteration 450, Loss: 0.0003963237686548382, Min w: 1.6405742542247026e-08\n",
      "Iteration 460, Loss: 0.00037147579132579267, Min w: 1.2951792882631707e-07\n",
      "Iteration 470, Loss: 0.000380572717403993, Min w: 3.0304572646855377e-05\n",
      "Iteration 480, Loss: 0.0003438551793806255, Min w: 0.0010383935878053308\n",
      "Iteration 490, Loss: 0.0003626012767199427, Min w: 0.01608177274465561\n",
      "Iteration 500, Loss: 0.0003772733034566045, Min w: 0.07186554372310638\n",
      "Iteration 510, Loss: 0.0003471099480520934, Min w: 0.09740514308214188\n",
      "Iteration 520, Loss: 0.0003199933853466064, Min w: 0.12117520719766617\n",
      "Iteration 530, Loss: 0.00035801908234134316, Min w: 0.13832701742649078\n",
      "Iteration 540, Loss: 0.0003680497466120869, Min w: 0.1513814628124237\n",
      "Iteration 550, Loss: 0.00028669601306319237, Min w: 0.17967383563518524\n",
      "Iteration 560, Loss: 0.0002760040224529803, Min w: 0.20965316891670227\n",
      "Iteration 570, Loss: 0.00028140979702584445, Min w: 0.2108655422925949\n",
      "Iteration 580, Loss: 0.0002695287112146616, Min w: 0.218144029378891\n",
      "Iteration 590, Loss: 0.0003193116281181574, Min w: 0.20270933210849762\n",
      "Iteration 600, Loss: 0.0003193664597347379, Min w: 0.2127227634191513\n",
      "Iteration 610, Loss: 0.0002802349627017975, Min w: 0.2565149962902069\n",
      "Iteration 620, Loss: 0.000246256502578035, Min w: 0.27720510959625244\n",
      "Iteration 630, Loss: 0.00023951639013830572, Min w: 0.2811901867389679\n",
      "Iteration 640, Loss: 0.000241415313212201, Min w: 0.3067454397678375\n",
      "Iteration 650, Loss: 0.00023068873269949108, Min w: 0.31357234716415405\n",
      "Iteration 660, Loss: 0.0002830313169397414, Min w: 0.30086442828178406\n",
      "Iteration 670, Loss: 0.0002462944248691201, Min w: 0.3333927094936371\n",
      "Iteration 680, Loss: 0.00023088573652785271, Min w: 0.3545316457748413\n",
      "Iteration 690, Loss: 0.00022116157924756408, Min w: 0.3586181104183197\n",
      "Iteration 700, Loss: 0.00023387787223327905, Min w: 0.3496188223361969\n",
      "Iteration 710, Loss: 0.0002074663498206064, Min w: 0.3804020285606384\n",
      "Iteration 720, Loss: 0.00020673905964940786, Min w: 0.399611234664917\n",
      "Iteration 730, Loss: 0.00024002918507903814, Min w: 0.3813909590244293\n",
      "Iteration 740, Loss: 0.00021458472474478185, Min w: 0.41086775064468384\n",
      "Iteration 750, Loss: 0.0001980770903173834, Min w: 0.41783374547958374\n",
      "Iteration 760, Loss: 0.00019708940817508847, Min w: 0.4358934760093689\n",
      "Iteration 770, Loss: 0.0002448858867865056, Min w: 0.41314128041267395\n",
      "Iteration 780, Loss: 0.00023902332759462297, Min w: 0.4087454676628113\n",
      "Iteration 790, Loss: 0.00023140439589042217, Min w: 0.4272903501987457\n",
      "Iteration 800, Loss: 0.0002089922345476225, Min w: 0.4770526885986328\n",
      "Iteration 810, Loss: 0.0002241887414129451, Min w: 0.4496507942676544\n",
      "Iteration 820, Loss: 0.00016574708570260555, Min w: 0.4945681691169739\n",
      "Iteration 830, Loss: 0.00018783059203997254, Min w: 0.5014458298683167\n",
      "Iteration 840, Loss: 0.00017328195099253207, Min w: 0.5157191157341003\n",
      "Iteration 850, Loss: 0.00018238180200569332, Min w: 0.5302957892417908\n",
      "Iteration 860, Loss: 0.0001783918123692274, Min w: 0.5334713459014893\n",
      "Iteration 870, Loss: 0.00019142506062053144, Min w: 0.5167275667190552\n",
      "Iteration 880, Loss: 0.00017941153782885522, Min w: 0.5347062349319458\n",
      "Iteration 890, Loss: 0.00014756974996998906, Min w: 0.5722301602363586\n",
      "Iteration 900, Loss: 0.00015048476052470505, Min w: 0.5849804282188416\n",
      "Iteration 910, Loss: 0.0001342315663350746, Min w: 0.6086305975914001\n",
      "Iteration 920, Loss: 0.00012901333684567362, Min w: 0.6166749000549316\n",
      "Iteration 930, Loss: 0.00013497917097993195, Min w: 0.6089895367622375\n",
      "Iteration 940, Loss: 0.00014022363757248968, Min w: 0.628743588924408\n",
      "Iteration 950, Loss: 0.00016487381071783602, Min w: 0.6075801253318787\n",
      "Iteration 960, Loss: 0.00015466325567103922, Min w: 0.6190748810768127\n",
      "Iteration 970, Loss: 0.0001572544133523479, Min w: 0.6185317635536194\n",
      "Iteration 980, Loss: 0.0001249775814358145, Min w: 0.6654794812202454\n",
      "Iteration 990, Loss: 0.00011817310587503016, Min w: 0.6662799715995789\n",
      "Iteration 1000, Loss: 0.00012902678281534463, Min w: 0.6851423978805542\n",
      "Iteration 1010, Loss: 0.00014296300651039928, Min w: 0.6505007743835449\n",
      "Iteration 1020, Loss: 0.000143101264256984, Min w: 0.6816451549530029\n",
      "Iteration 1030, Loss: 0.00014509022003039718, Min w: 0.668596088886261\n",
      "Iteration 1040, Loss: 0.00011095897934865206, Min w: 0.7235396504402161\n",
      "Iteration 1050, Loss: 0.0001635088410694152, Min w: 0.6440966725349426\n",
      "Iteration 1060, Loss: 0.00014734129945281893, Min w: 0.6824953556060791\n",
      "Iteration 1070, Loss: 0.00011869120498886332, Min w: 0.7438501715660095\n",
      "Iteration 1080, Loss: 0.00012578304449561983, Min w: 0.7348058223724365\n",
      "Iteration 1090, Loss: 0.00013643616694025695, Min w: 0.7173162698745728\n",
      "Iteration 1100, Loss: 0.00013910037523601204, Min w: 0.7124548554420471\n",
      "Iteration 1110, Loss: 0.00013368597137741745, Min w: 0.7249143719673157\n",
      "Iteration 1120, Loss: 0.00010773733083624393, Min w: 0.757994532585144\n",
      "Iteration 1130, Loss: 8.445668208878487e-05, Min w: 0.7888584733009338\n",
      "Iteration 1140, Loss: 0.00010986765846610069, Min w: 0.7690668702125549\n",
      "Iteration 1150, Loss: 9.921245509758592e-05, Min w: 0.779964804649353\n",
      "Iteration 1160, Loss: 6.767005834262818e-05, Min w: 0.8261425495147705\n",
      "Iteration 1170, Loss: 9.80695549515076e-05, Min w: 0.7959194183349609\n",
      "Iteration 1180, Loss: 9.169867553282529e-05, Min w: 0.808127760887146\n",
      "Iteration 1190, Loss: 8.440272358711809e-05, Min w: 0.8274258375167847\n",
      "Iteration 1200, Loss: 9.245009277947247e-05, Min w: 0.8056855797767639\n",
      "Iteration 1210, Loss: 0.00010069772542919964, Min w: 0.7792783379554749\n",
      "Iteration 1220, Loss: 9.231881267623976e-05, Min w: 0.8109031915664673\n",
      "Iteration 1230, Loss: 9.147831588052213e-05, Min w: 0.7964553833007812\n",
      "Iteration 1240, Loss: 8.7711974629201e-05, Min w: 0.8117654919624329\n",
      "Iteration 0, Loss: 9.441532893106341e-05, Min w: 0.7986781597137451\n",
      "Iteration 10, Loss: 8.626552880741656e-05, Min w: 0.8029167056083679\n",
      "Iteration 20, Loss: 0.00010278356057824567, Min w: 0.7846019864082336\n",
      "Iteration 30, Loss: 0.00010182052210438997, Min w: 0.7426818609237671\n",
      "Iteration 40, Loss: 8.512871863786131e-05, Min w: 0.7854186296463013\n",
      "Iteration 50, Loss: 7.004811050137505e-05, Min w: 0.8526647686958313\n",
      "Iteration 60, Loss: 4.8298839828930795e-05, Min w: 0.9011386632919312\n",
      "Iteration 70, Loss: 4.959403304383159e-05, Min w: 0.8945916891098022\n",
      "Iteration 80, Loss: 0.00011228115909034386, Min w: 0.7059004902839661\n",
      "Iteration 90, Loss: 9.207000402966514e-05, Min w: 0.7661296725273132\n",
      "Iteration 100, Loss: 0.00010224090510746464, Min w: 0.7297043800354004\n",
      "Iteration 110, Loss: 8.724014332983643e-05, Min w: 0.7886635661125183\n",
      "Iteration 120, Loss: 6.961596227483824e-05, Min w: 0.8242551684379578\n",
      "Iteration 130, Loss: 6.668434798484668e-05, Min w: 0.8482682108879089\n",
      "Iteration 140, Loss: 4.492804146138951e-05, Min w: 0.9059280157089233\n",
      "Iteration 150, Loss: 6.621961802011356e-05, Min w: 0.8191521167755127\n",
      "Iteration 160, Loss: 4.996025381842628e-05, Min w: 0.885478138923645\n",
      "Iteration 170, Loss: 5.769327617599629e-05, Min w: 0.8553209900856018\n",
      "Iteration 180, Loss: 5.892925037187524e-05, Min w: 0.8564987182617188\n",
      "Iteration 190, Loss: 7.122958777472377e-05, Min w: 0.8286120891571045\n",
      "Iteration 200, Loss: 6.66953856125474e-05, Min w: 0.82743239402771\n",
      "Iteration 210, Loss: 7.227201422210783e-05, Min w: 0.8193579316139221\n",
      "Iteration 220, Loss: 6.63923128740862e-05, Min w: 0.8311471939086914\n",
      "Iteration 230, Loss: 4.436773815541528e-05, Min w: 0.8907063603401184\n",
      "Iteration 240, Loss: 4.4938795326743275e-05, Min w: 0.8927244544029236\n",
      "Iteration 250, Loss: 5.586869519902393e-05, Min w: 0.8638795018196106\n",
      "Iteration 260, Loss: 5.833669638377614e-05, Min w: 0.83864825963974\n",
      "Iteration 270, Loss: 6.455543916672468e-05, Min w: 0.8268934488296509\n",
      "Iteration 280, Loss: 5.249886817182414e-05, Min w: 0.8580670952796936\n",
      "Iteration 290, Loss: 6.166961247799918e-05, Min w: 0.835440993309021\n",
      "Iteration 300, Loss: 5.462444096338004e-05, Min w: 0.8707587122917175\n",
      "Iteration 310, Loss: 5.1239945605630055e-05, Min w: 0.8689637184143066\n",
      "Iteration 320, Loss: 5.9862944908672944e-05, Min w: 0.829624593257904\n",
      "Iteration 330, Loss: 6.0295053117442876e-05, Min w: 0.8413050770759583\n",
      "Iteration 340, Loss: 3.892329550581053e-05, Min w: 0.904083788394928\n",
      "Iteration 350, Loss: 3.61330239684321e-05, Min w: 0.9107391834259033\n",
      "Iteration 360, Loss: 4.634509969037026e-05, Min w: 0.8779876828193665\n",
      "Iteration 370, Loss: 4.971482485416345e-05, Min w: 0.8649951815605164\n",
      "Iteration 380, Loss: 4.491662184591405e-05, Min w: 0.890904426574707\n",
      "Iteration 390, Loss: 4.1800609324127436e-05, Min w: 0.885730504989624\n",
      "Iteration 400, Loss: 5.781546497019008e-05, Min w: 0.839966356754303\n",
      "Iteration 410, Loss: 4.1955096094170585e-05, Min w: 0.89275723695755\n",
      "Iteration 420, Loss: 4.0531453123549e-05, Min w: 0.8860781192779541\n",
      "Iteration 430, Loss: 4.0249229641631246e-05, Min w: 0.898115336894989\n",
      "Iteration 440, Loss: 4.776452260557562e-05, Min w: 0.8812438249588013\n",
      "Iteration 450, Loss: 4.2090294300578535e-05, Min w: 0.8840257525444031\n",
      "Iteration 460, Loss: 4.576490755425766e-05, Min w: 0.8742753863334656\n",
      "Iteration 470, Loss: 5.001439058105461e-05, Min w: 0.8669050931930542\n",
      "Iteration 480, Loss: 3.761134939850308e-05, Min w: 0.9087494611740112\n",
      "Iteration 490, Loss: 4.864743459620513e-05, Min w: 0.8643297553062439\n",
      "Iteration 500, Loss: 4.254280065651983e-05, Min w: 0.8784662485122681\n",
      "Iteration 510, Loss: 3.65800951840356e-05, Min w: 0.9032232761383057\n",
      "Iteration 520, Loss: 4.3688058212865144e-05, Min w: 0.8759220242500305\n",
      "Iteration 530, Loss: 5.0866514357039705e-05, Min w: 0.860271692276001\n",
      "Iteration 540, Loss: 3.81838581233751e-05, Min w: 0.8944981098175049\n",
      "Iteration 550, Loss: 4.584691851050593e-05, Min w: 0.875010073184967\n",
      "Iteration 560, Loss: 3.528054367052391e-05, Min w: 0.9125317931175232\n",
      "Iteration 570, Loss: 4.3320753320585936e-05, Min w: 0.8891676664352417\n",
      "Iteration 580, Loss: 4.9850481445901096e-05, Min w: 0.8598612546920776\n",
      "Iteration 590, Loss: 3.2251307857222855e-05, Min w: 0.9153660535812378\n",
      "Iteration 600, Loss: 3.4375410905340686e-05, Min w: 0.911731481552124\n",
      "Iteration 610, Loss: 2.751670399447903e-05, Min w: 0.9300416707992554\n",
      "Iteration 620, Loss: 3.0059121854719706e-05, Min w: 0.9238742589950562\n",
      "Iteration 630, Loss: 3.560918048606254e-05, Min w: 0.9064622521400452\n",
      "Iteration 640, Loss: 5.4199776059249416e-05, Min w: 0.850430965423584\n",
      "Iteration 650, Loss: 2.5044790163519792e-05, Min w: 0.9387162923812866\n",
      "Iteration 660, Loss: 3.258918150095269e-05, Min w: 0.9132221937179565\n",
      "Iteration 670, Loss: 2.302118627994787e-05, Min w: 0.9348753094673157\n",
      "Iteration 680, Loss: 3.7696365325246006e-05, Min w: 0.8963961005210876\n",
      "Iteration 690, Loss: 4.5006181608187035e-05, Min w: 0.888656497001648\n",
      "Iteration 700, Loss: 3.521344478940591e-05, Min w: 0.9064327478408813\n",
      "Iteration 710, Loss: 2.7729838620871305e-05, Min w: 0.9235408902168274\n",
      "Iteration 720, Loss: 2.5803919925238006e-05, Min w: 0.9271236658096313\n",
      "Iteration 730, Loss: 5.1248091040179133e-05, Min w: 0.8504289984703064\n",
      "Iteration 740, Loss: 3.226037006243132e-05, Min w: 0.9161404371261597\n",
      "Iteration 750, Loss: 2.8655191272264346e-05, Min w: 0.9207119345664978\n",
      "Iteration 760, Loss: 3.705487324623391e-05, Min w: 0.9021206498146057\n",
      "Iteration 770, Loss: 3.221082442905754e-05, Min w: 0.92072993516922\n",
      "Iteration 780, Loss: 2.7158675948157907e-05, Min w: 0.9307940602302551\n",
      "Iteration 790, Loss: 1.933411112986505e-05, Min w: 0.9510396718978882\n",
      "Iteration 800, Loss: 3.065510463784449e-05, Min w: 0.9099986553192139\n",
      "Iteration 810, Loss: 5.104034789837897e-05, Min w: 0.8516191840171814\n",
      "Iteration 820, Loss: 3.6722263757837936e-05, Min w: 0.8973153829574585\n",
      "Iteration 830, Loss: 3.440231012064032e-05, Min w: 0.9042319059371948\n",
      "Iteration 840, Loss: 3.051423300348688e-05, Min w: 0.915922999382019\n",
      "Iteration 850, Loss: 2.7232592401560396e-05, Min w: 0.9239279627799988\n",
      "Iteration 860, Loss: 2.9556445952039212e-05, Min w: 0.9199842214584351\n",
      "Iteration 870, Loss: 2.7584164854488336e-05, Min w: 0.9261441826820374\n",
      "Iteration 880, Loss: 1.983582114917226e-05, Min w: 0.9486055374145508\n",
      "Iteration 890, Loss: 2.215646418335382e-05, Min w: 0.943215012550354\n",
      "Iteration 900, Loss: 5.562309888773598e-05, Min w: 0.8437151312828064\n",
      "Iteration 910, Loss: 2.4744836991885677e-05, Min w: 0.9334577322006226\n",
      "Iteration 920, Loss: 2.323667285963893e-05, Min w: 0.9329959750175476\n",
      "Iteration 930, Loss: 4.45613513875287e-05, Min w: 0.862740695476532\n",
      "Iteration 940, Loss: 2.2389976948034018e-05, Min w: 0.9383351802825928\n",
      "Iteration 950, Loss: 1.666021125856787e-05, Min w: 0.9623363614082336\n",
      "Iteration 960, Loss: 4.923400774714537e-05, Min w: 0.8645647764205933\n",
      "Iteration 970, Loss: 3.476003621472046e-05, Min w: 0.8951356410980225\n",
      "Iteration 980, Loss: 4.2882500565610826e-05, Min w: 0.8707233667373657\n",
      "Iteration 990, Loss: 4.352236646809615e-05, Min w: 0.8676570653915405\n",
      "Iteration 1000, Loss: 2.9694925615331158e-05, Min w: 0.9056954979896545\n",
      "Iteration 1010, Loss: 4.1047504055313766e-05, Min w: 0.8862780928611755\n",
      "Iteration 1020, Loss: 2.8821641535614617e-05, Min w: 0.9267570972442627\n",
      "Iteration 1030, Loss: 3.6541074223350734e-05, Min w: 0.9036679267883301\n",
      "Iteration 1040, Loss: 1.783544576028362e-05, Min w: 0.9531177282333374\n",
      "Iteration 1050, Loss: 2.7265998141956516e-05, Min w: 0.922151505947113\n",
      "Iteration 1060, Loss: 3.0739054636796936e-05, Min w: 0.9043687582015991\n",
      "Iteration 1070, Loss: 1.8369964891462587e-05, Min w: 0.9513762593269348\n",
      "Iteration 1080, Loss: 3.841747820843011e-05, Min w: 0.8915488719940186\n",
      "Iteration 1090, Loss: 3.348447353346273e-05, Min w: 0.90626060962677\n",
      "Iteration 1100, Loss: 2.0920884708175436e-05, Min w: 0.9453353881835938\n",
      "Iteration 1110, Loss: 3.56705641024746e-05, Min w: 0.9029654860496521\n",
      "Iteration 1120, Loss: 3.82232537958771e-05, Min w: 0.8875697255134583\n",
      "Iteration 1130, Loss: 3.5249842767370865e-05, Min w: 0.9056454300880432\n",
      "Iteration 1140, Loss: 2.5685019863885827e-05, Min w: 0.9290313720703125\n",
      "Iteration 1150, Loss: 1.9293447621748783e-05, Min w: 0.9423726797103882\n",
      "Iteration 1160, Loss: 3.508861846057698e-05, Min w: 0.8981468677520752\n",
      "Iteration 1170, Loss: 2.3085636712494306e-05, Min w: 0.9365277290344238\n",
      "Iteration 1180, Loss: 4.111023008590564e-05, Min w: 0.871066689491272\n",
      "Iteration 1190, Loss: 2.5964911401388235e-05, Min w: 0.9234127402305603\n",
      "Iteration 1200, Loss: 2.4899078198359348e-05, Min w: 0.9307570457458496\n",
      "Iteration 1210, Loss: 2.497349851182662e-05, Min w: 0.929754376411438\n",
      "Iteration 1220, Loss: 2.2004185666446574e-05, Min w: 0.939426600933075\n",
      "Iteration 1230, Loss: 3.3470962080173194e-05, Min w: 0.9056187272071838\n",
      "Iteration 1240, Loss: 3.282888064859435e-05, Min w: 0.9055044054985046\n",
      "Iteration 0, Loss: 2.3158107069320977e-05, Min w: 0.9295023679733276\n",
      "Iteration 10, Loss: 2.408318869129289e-05, Min w: 0.9331833720207214\n",
      "Iteration 20, Loss: 3.375909727765247e-05, Min w: 0.9019031524658203\n",
      "Iteration 30, Loss: 2.3321488697547466e-05, Min w: 0.931164026260376\n",
      "Iteration 40, Loss: 2.0733541532536037e-05, Min w: 0.9441213011741638\n",
      "Iteration 50, Loss: 2.557655534474179e-05, Min w: 0.926493227481842\n",
      "Iteration 60, Loss: 2.0180414139758795e-05, Min w: 0.9422988295555115\n",
      "Iteration 70, Loss: 3.929618469555862e-05, Min w: 0.8868491649627686\n",
      "Iteration 80, Loss: 3.096404907410033e-05, Min w: 0.9106690287590027\n",
      "Iteration 90, Loss: 1.5710060324636288e-05, Min w: 0.9582308530807495\n",
      "Iteration 100, Loss: 1.6675969163770787e-05, Min w: 0.9555780291557312\n",
      "Iteration 110, Loss: 1.5002049622125924e-05, Min w: 0.9610585570335388\n",
      "Iteration 120, Loss: 3.9609032683074474e-05, Min w: 0.8816463947296143\n",
      "Iteration 130, Loss: 3.0442653951467946e-05, Min w: 0.9157544374465942\n",
      "Iteration 140, Loss: 2.3264239644049667e-05, Min w: 0.9329709410667419\n",
      "Iteration 150, Loss: 2.276322447869461e-05, Min w: 0.9314101934432983\n",
      "Iteration 160, Loss: 1.714410973363556e-05, Min w: 0.952191948890686\n",
      "Iteration 170, Loss: 3.434195605223067e-05, Min w: 0.8944580554962158\n",
      "Iteration 180, Loss: 1.7884927729028277e-05, Min w: 0.9515200853347778\n",
      "Iteration 190, Loss: 3.227510751457885e-05, Min w: 0.9061453938484192\n",
      "Iteration 200, Loss: 1.3572350326285232e-05, Min w: 0.9639961123466492\n",
      "Iteration 210, Loss: 3.443901732680388e-05, Min w: 0.9096593260765076\n",
      "Iteration 220, Loss: 1.7450372979510576e-05, Min w: 0.9569746851921082\n",
      "Iteration 230, Loss: 1.9572766177589074e-05, Min w: 0.9396147131919861\n",
      "Iteration 240, Loss: 3.204674430890009e-05, Min w: 0.9183841943740845\n",
      "Iteration 250, Loss: 2.1386602384154685e-05, Min w: 0.9354049563407898\n",
      "Iteration 260, Loss: 2.5756484319572337e-05, Min w: 0.9255729913711548\n",
      "Iteration 270, Loss: 2.8199548978591338e-05, Min w: 0.9250679016113281\n",
      "Iteration 280, Loss: 1.7241873138118535e-05, Min w: 0.9509783387184143\n",
      "Iteration 290, Loss: 2.510949161660392e-05, Min w: 0.9355102181434631\n",
      "Iteration 300, Loss: 2.7971394956693985e-05, Min w: 0.9159634113311768\n",
      "Iteration 310, Loss: 1.1994262422376778e-05, Min w: 0.9692170023918152\n",
      "Iteration 320, Loss: 2.98587456200039e-05, Min w: 0.9182615280151367\n",
      "Iteration 330, Loss: 3.7269572203513235e-05, Min w: 0.8809872269630432\n",
      "Iteration 340, Loss: 3.467749047558755e-05, Min w: 0.8999235033988953\n",
      "Iteration 350, Loss: 1.3108756320434622e-05, Min w: 0.9655789732933044\n",
      "Iteration 360, Loss: 2.5887233277899213e-05, Min w: 0.9298335909843445\n",
      "Iteration 370, Loss: 3.1675554055254906e-05, Min w: 0.8965919017791748\n",
      "Iteration 380, Loss: 1.0862613635254093e-05, Min w: 0.9728531837463379\n",
      "Iteration 390, Loss: 2.958289041998796e-05, Min w: 0.9148768782615662\n",
      "Iteration 400, Loss: 1.3588222827820573e-05, Min w: 0.9628516435623169\n",
      "Iteration 410, Loss: 4.3066185753559694e-05, Min w: 0.8776194453239441\n",
      "Iteration 420, Loss: 1.9500568669172935e-05, Min w: 0.9528207778930664\n",
      "Iteration 430, Loss: 3.4405347832944244e-05, Min w: 0.8964778184890747\n",
      "Iteration 440, Loss: 2.4602362827863544e-05, Min w: 0.9282556176185608\n",
      "Iteration 450, Loss: 1.1374029782018624e-05, Min w: 0.9701008796691895\n",
      "Iteration 460, Loss: 4.475356399780139e-05, Min w: 0.8668686151504517\n",
      "Iteration 470, Loss: 2.613597098388709e-05, Min w: 0.9266982078552246\n",
      "Iteration 480, Loss: 2.947523898910731e-05, Min w: 0.9056666493415833\n",
      "Iteration 490, Loss: 2.202744326496031e-05, Min w: 0.9434705972671509\n",
      "Iteration 500, Loss: 2.35955449170433e-05, Min w: 0.935982346534729\n",
      "Iteration 510, Loss: 2.6957619411405176e-05, Min w: 0.926380455493927\n",
      "Iteration 520, Loss: 2.7901511202799156e-05, Min w: 0.9238437414169312\n",
      "Iteration 530, Loss: 1.8266473489347845e-05, Min w: 0.944976270198822\n",
      "Iteration 540, Loss: 2.9576351153082214e-05, Min w: 0.9151508212089539\n",
      "Iteration 550, Loss: 1.2007420991722029e-05, Min w: 0.9677513837814331\n",
      "Iteration 560, Loss: 3.0042065191082656e-05, Min w: 0.9202077388763428\n",
      "Iteration 570, Loss: 1.3212505109549966e-05, Min w: 0.9639655351638794\n",
      "Iteration 580, Loss: 2.655834032339044e-05, Min w: 0.921280562877655\n",
      "Iteration 590, Loss: 4.061694198753685e-05, Min w: 0.8900796175003052\n",
      "Iteration 600, Loss: 2.425676393613685e-05, Min w: 0.9204953908920288\n",
      "Iteration 610, Loss: 8.55217695061583e-06, Min w: 0.980659544467926\n",
      "Iteration 620, Loss: 2.082472747133579e-05, Min w: 0.9396600127220154\n",
      "Iteration 630, Loss: 1.0720890713855624e-05, Min w: 0.9756797552108765\n",
      "Iteration 640, Loss: 2.850293822120875e-05, Min w: 0.9205288887023926\n",
      "Iteration 650, Loss: 1.102655915019568e-05, Min w: 0.9725749492645264\n",
      "Iteration 660, Loss: 3.430471406318247e-05, Min w: 0.9045664072036743\n",
      "Iteration 670, Loss: 2.455670983181335e-05, Min w: 0.9375556111335754\n",
      "Iteration 680, Loss: 1.981827153940685e-05, Min w: 0.9444486498832703\n",
      "Iteration 690, Loss: 2.2613070541410707e-05, Min w: 0.9330007433891296\n",
      "Iteration 700, Loss: 1.9947290638810955e-05, Min w: 0.9505952596664429\n",
      "Iteration 710, Loss: 2.463662895024754e-05, Min w: 0.9285430908203125\n",
      "Iteration 720, Loss: 1.627001074666623e-05, Min w: 0.9487640857696533\n",
      "Iteration 730, Loss: 2.808279350574594e-05, Min w: 0.9331883788108826\n",
      "Iteration 740, Loss: 1.166341553471284e-05, Min w: 0.9718632698059082\n",
      "Iteration 750, Loss: 3.078911322518252e-05, Min w: 0.9155049324035645\n",
      "Iteration 760, Loss: 1.185833662020741e-05, Min w: 0.9668072462081909\n",
      "Iteration 770, Loss: 2.085092455672566e-05, Min w: 0.9372937083244324\n",
      "Iteration 780, Loss: 3.506705616018735e-05, Min w: 0.9018760919570923\n",
      "Iteration 790, Loss: 2.1030853531556204e-05, Min w: 0.9423761367797852\n",
      "Iteration 800, Loss: 2.242045957245864e-05, Min w: 0.9365282654762268\n",
      "Iteration 810, Loss: 1.76803587237373e-05, Min w: 0.9580910801887512\n",
      "Iteration 820, Loss: 4.282948066247627e-05, Min w: 0.8756230473518372\n",
      "Iteration 830, Loss: 1.546602652524598e-05, Min w: 0.9573090672492981\n",
      "Iteration 840, Loss: 1.6258880350505933e-05, Min w: 0.9519591331481934\n",
      "Iteration 850, Loss: 2.7353586119716056e-05, Min w: 0.9320129752159119\n",
      "Iteration 860, Loss: 1.996784340008162e-05, Min w: 0.9478777647018433\n",
      "Iteration 870, Loss: 1.9018014427274466e-05, Min w: 0.9418469071388245\n",
      "Iteration 880, Loss: 1.2032627637381665e-05, Min w: 0.9671807885169983\n",
      "Iteration 890, Loss: 2.8012742404825985e-05, Min w: 0.9198639392852783\n",
      "Iteration 900, Loss: 2.4883229343686253e-05, Min w: 0.9226236939430237\n",
      "Iteration 910, Loss: 1.997889921767637e-05, Min w: 0.9426800012588501\n",
      "Iteration 920, Loss: 1.685514689597767e-05, Min w: 0.9549282193183899\n",
      "Iteration 930, Loss: 2.121242505381815e-05, Min w: 0.9439427852630615\n",
      "Iteration 940, Loss: 1.540981793368701e-05, Min w: 0.95509934425354\n",
      "Iteration 950, Loss: 2.7054757083533332e-05, Min w: 0.9241858720779419\n",
      "Iteration 960, Loss: 1.9669736502692103e-05, Min w: 0.9380414485931396\n",
      "Iteration 970, Loss: 1.1445993550296407e-05, Min w: 0.9685477614402771\n",
      "Iteration 980, Loss: 3.138252577628009e-05, Min w: 0.9122602343559265\n",
      "Iteration 990, Loss: 1.5100989003258292e-05, Min w: 0.9585646986961365\n",
      "Iteration 1000, Loss: 3.185391324223019e-05, Min w: 0.8976723551750183\n",
      "Iteration 1010, Loss: 1.6827665604068898e-05, Min w: 0.9540679454803467\n",
      "Iteration 1020, Loss: 2.241930087620858e-05, Min w: 0.9291419982910156\n",
      "Iteration 1030, Loss: 2.0807601686101407e-05, Min w: 0.9411281943321228\n",
      "Iteration 1040, Loss: 1.4435137927648611e-05, Min w: 0.959491491317749\n",
      "Iteration 1050, Loss: 1.929859718075022e-05, Min w: 0.9477551579475403\n",
      "Iteration 1060, Loss: 2.2372943931259215e-05, Min w: 0.9350162148475647\n",
      "Iteration 1070, Loss: 8.10194524092367e-06, Min w: 0.9800816774368286\n",
      "Iteration 1080, Loss: 2.0590056010405533e-05, Min w: 0.9359005093574524\n",
      "Iteration 1090, Loss: 1.4853489119559526e-05, Min w: 0.9565861225128174\n",
      "Iteration 1100, Loss: 3.203527376172133e-05, Min w: 0.904603123664856\n",
      "Iteration 1110, Loss: 1.5845984307816252e-05, Min w: 0.9652394652366638\n",
      "Iteration 1120, Loss: 2.524343472032342e-05, Min w: 0.936164140701294\n",
      "Iteration 1130, Loss: 2.6671359592000954e-05, Min w: 0.9205754995346069\n",
      "Iteration 1140, Loss: 7.482739874831168e-06, Min w: 0.9838254451751709\n",
      "Iteration 1150, Loss: 3.694522820296697e-05, Min w: 0.9002962112426758\n",
      "Iteration 1160, Loss: 1.1116915629827417e-05, Min w: 0.9720073342323303\n",
      "Iteration 1170, Loss: 1.7239954104297794e-05, Min w: 0.9488257169723511\n",
      "Iteration 1180, Loss: 3.640820432337932e-05, Min w: 0.885450541973114\n",
      "Iteration 1190, Loss: 5.975809472147375e-06, Min w: 0.9877572655677795\n",
      "Iteration 1200, Loss: 1.675711064308416e-05, Min w: 0.9533607959747314\n",
      "Iteration 1210, Loss: 9.970316568796989e-06, Min w: 0.9731000065803528\n",
      "Iteration 1220, Loss: 6.273862254602136e-06, Min w: 0.9861266613006592\n",
      "Iteration 1230, Loss: 3.773978096432984e-05, Min w: 0.9106557369232178\n",
      "Iteration 1240, Loss: 1.9375074771232903e-05, Min w: 0.9543061256408691\n",
      "Iteration 0, Loss: 1.8446527974447235e-05, Min w: 0.9572518467903137\n",
      "Iteration 10, Loss: 2.799931462504901e-05, Min w: 0.923952043056488\n",
      "Iteration 20, Loss: 7.989899131644052e-06, Min w: 0.9801611304283142\n",
      "Iteration 30, Loss: 3.110870238742791e-05, Min w: 0.917456328868866\n",
      "Iteration 40, Loss: 3.0311552109196782e-05, Min w: 0.9065634608268738\n",
      "Iteration 50, Loss: 2.171906817238778e-05, Min w: 0.9341114163398743\n",
      "Iteration 60, Loss: 1.4756598829990253e-05, Min w: 0.9579689502716064\n",
      "Iteration 70, Loss: 1.8780638129101135e-05, Min w: 0.9479653239250183\n",
      "Iteration 80, Loss: 3.2362499041482806e-05, Min w: 0.9022929668426514\n",
      "Iteration 90, Loss: 1.5067418644321151e-05, Min w: 0.9555087685585022\n",
      "Iteration 100, Loss: 2.9961656764498912e-05, Min w: 0.9121529459953308\n",
      "Iteration 110, Loss: 1.1131493010907434e-05, Min w: 0.9683327078819275\n",
      "Iteration 120, Loss: 2.753343324002344e-05, Min w: 0.9113644361495972\n",
      "Iteration 130, Loss: 2.0013916582684033e-05, Min w: 0.9348509907722473\n",
      "Iteration 140, Loss: 2.4924074750742875e-05, Min w: 0.9203694462776184\n",
      "Iteration 150, Loss: 6.83318785377196e-06, Min w: 0.9822621941566467\n",
      "Iteration 160, Loss: 2.1756390196969733e-05, Min w: 0.9455798864364624\n",
      "Iteration 170, Loss: 3.91133944503963e-05, Min w: 0.8866093754768372\n",
      "Iteration 180, Loss: 1.6782725651864894e-05, Min w: 0.9496104121208191\n",
      "Iteration 190, Loss: 1.6972466255538166e-05, Min w: 0.9525020718574524\n",
      "Iteration 200, Loss: 3.0392775443033315e-05, Min w: 0.9151178598403931\n",
      "Iteration 210, Loss: 2.4074230168480426e-05, Min w: 0.9273742437362671\n",
      "Iteration 220, Loss: 5.762346063420409e-06, Min w: 0.9878255724906921\n",
      "Iteration 230, Loss: 2.3294453058042563e-05, Min w: 0.9378193616867065\n",
      "Iteration 240, Loss: 6.739796845067758e-06, Min w: 0.9858053922653198\n",
      "Iteration 250, Loss: 2.674132520041894e-05, Min w: 0.9226846694946289\n",
      "Iteration 260, Loss: 1.6334659449057654e-05, Min w: 0.9508654475212097\n",
      "Iteration 270, Loss: 2.935869270004332e-05, Min w: 0.9034128189086914\n",
      "Iteration 280, Loss: 2.1523821487789974e-05, Min w: 0.9302341341972351\n",
      "Iteration 290, Loss: 1.9006558432010934e-05, Min w: 0.9498364329338074\n",
      "Iteration 300, Loss: 2.608571776363533e-05, Min w: 0.9309322834014893\n",
      "Iteration 310, Loss: 1.2081855857104529e-05, Min w: 0.9668502807617188\n",
      "Iteration 320, Loss: 2.4865630621206947e-05, Min w: 0.930450975894928\n",
      "Iteration 330, Loss: 1.8107768482877873e-05, Min w: 0.9421341419219971\n",
      "Iteration 340, Loss: 2.2012149202055298e-05, Min w: 0.9415686726570129\n",
      "Iteration 350, Loss: 1.4909115634509362e-05, Min w: 0.9630095362663269\n",
      "Iteration 360, Loss: 2.3683634935878217e-05, Min w: 0.923966646194458\n",
      "Iteration 370, Loss: 1.6078125554486178e-05, Min w: 0.9575492143630981\n",
      "Iteration 380, Loss: 1.895173772936687e-05, Min w: 0.948425829410553\n",
      "Iteration 390, Loss: 1.96966157091083e-05, Min w: 0.9443389773368835\n",
      "Iteration 400, Loss: 1.2696594239969272e-05, Min w: 0.9702931046485901\n",
      "Iteration 410, Loss: 1.9794537365669385e-05, Min w: 0.9592493772506714\n",
      "Iteration 420, Loss: 5.608421815850306e-06, Min w: 0.9882220029830933\n",
      "Iteration 430, Loss: 3.887379352818243e-05, Min w: 0.8906255960464478\n",
      "Iteration 440, Loss: 8.344593879883178e-06, Min w: 0.9811750054359436\n",
      "Iteration 450, Loss: 1.7930053218151443e-05, Min w: 0.9588411450386047\n",
      "Iteration 460, Loss: 2.4529816073481925e-05, Min w: 0.9324582815170288\n",
      "Iteration 470, Loss: 2.6017954951385036e-05, Min w: 0.9119940996170044\n",
      "Iteration 480, Loss: 2.2569713109987788e-05, Min w: 0.9272841811180115\n",
      "Iteration 490, Loss: 9.715266060084105e-06, Min w: 0.9740055203437805\n",
      "Iteration 500, Loss: 2.181243871746119e-05, Min w: 0.935193657875061\n",
      "Iteration 510, Loss: 9.17709076020401e-06, Min w: 0.976607620716095\n",
      "Iteration 520, Loss: 2.5794146495172754e-05, Min w: 0.9257782101631165\n",
      "Iteration 530, Loss: 1.4134835510049015e-05, Min w: 0.9661944508552551\n",
      "Iteration 540, Loss: 2.171531377825886e-05, Min w: 0.9373193979263306\n",
      "Iteration 550, Loss: 2.694339127629064e-05, Min w: 0.9121254086494446\n",
      "Iteration 560, Loss: 1.598842027306091e-05, Min w: 0.9521284103393555\n",
      "Iteration 570, Loss: 1.3533729543269146e-05, Min w: 0.9630573987960815\n",
      "Iteration 580, Loss: 3.0871200578985736e-05, Min w: 0.9093689322471619\n",
      "Iteration 590, Loss: 1.429911753803026e-05, Min w: 0.9532723426818848\n",
      "Iteration 600, Loss: 2.955949639726896e-05, Min w: 0.9206048846244812\n",
      "Iteration 610, Loss: 1.8504280888009816e-05, Min w: 0.9537719488143921\n",
      "Iteration 620, Loss: 1.807084117899649e-05, Min w: 0.9432172179222107\n",
      "Iteration 630, Loss: 2.099876473948825e-05, Min w: 0.9557404518127441\n",
      "Iteration 640, Loss: 9.568234418111388e-06, Min w: 0.9798301458358765\n",
      "Iteration 650, Loss: 2.4067005142569542e-05, Min w: 0.9431173801422119\n",
      "Iteration 660, Loss: 1.3297501027409453e-05, Min w: 0.9640722274780273\n",
      "Iteration 670, Loss: 1.8551581888459623e-05, Min w: 0.9616313576698303\n",
      "Iteration 680, Loss: 1.7064259736798704e-05, Min w: 0.9564294815063477\n",
      "Iteration 690, Loss: 1.9953014998463914e-05, Min w: 0.9380766749382019\n",
      "Iteration 700, Loss: 2.0023659089929424e-05, Min w: 0.9510610103607178\n",
      "Iteration 710, Loss: 1.9487337340251543e-05, Min w: 0.9393154382705688\n",
      "Iteration 720, Loss: 1.1653004548861645e-05, Min w: 0.9702937006950378\n",
      "Iteration 730, Loss: 2.438120100123342e-05, Min w: 0.9283396601676941\n",
      "Iteration 740, Loss: 1.9671593690873124e-05, Min w: 0.9373154640197754\n",
      "Iteration 750, Loss: 2.1498022761079483e-05, Min w: 0.9516565799713135\n",
      "Iteration 760, Loss: 1.3069576198176946e-05, Min w: 0.9699522852897644\n",
      "Iteration 770, Loss: 1.8523962353356183e-05, Min w: 0.9429507851600647\n",
      "Iteration 780, Loss: 2.3538674213341437e-05, Min w: 0.9388686418533325\n",
      "Iteration 790, Loss: 1.4453788026003167e-05, Min w: 0.9597570300102234\n",
      "Iteration 800, Loss: 1.567560320836492e-05, Min w: 0.9554934501647949\n",
      "Iteration 810, Loss: 8.88918020791607e-06, Min w: 0.9757274985313416\n",
      "Iteration 820, Loss: 2.5360730433021672e-05, Min w: 0.9300198554992676\n",
      "Iteration 830, Loss: 1.7278638551943004e-05, Min w: 0.9465277194976807\n",
      "Iteration 840, Loss: 1.9076300304732285e-05, Min w: 0.9512773156166077\n",
      "Iteration 850, Loss: 1.447706381441094e-05, Min w: 0.9580181241035461\n",
      "Iteration 860, Loss: 3.426847979426384e-05, Min w: 0.9059082269668579\n",
      "Iteration 870, Loss: 1.787162727850955e-05, Min w: 0.9560927152633667\n",
      "Iteration 880, Loss: 7.626273600180866e-06, Min w: 0.9789527654647827\n",
      "Iteration 890, Loss: 3.5021366784349084e-05, Min w: 0.9083248972892761\n",
      "Iteration 900, Loss: 6.77544039717759e-06, Min w: 0.9828462600708008\n",
      "Iteration 910, Loss: 3.8422604120569304e-05, Min w: 0.8938183784484863\n",
      "Iteration 920, Loss: 1.0717266377469059e-05, Min w: 0.9679152369499207\n",
      "Iteration 930, Loss: 1.4894806554366369e-05, Min w: 0.9622754454612732\n",
      "Iteration 940, Loss: 4.7695834837213624e-06, Min w: 0.98908931016922\n",
      "Iteration 950, Loss: 3.981048575951718e-05, Min w: 0.8821880221366882\n",
      "Iteration 960, Loss: 9.330547982244752e-06, Min w: 0.9717475175857544\n",
      "Iteration 970, Loss: 3.10663235723041e-05, Min w: 0.9120046496391296\n",
      "Iteration 980, Loss: 6.131942427600734e-06, Min w: 0.9862377643585205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  29%|██▉       | 7/24 [04:58<10:24, 36.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 985 --------------------------------\n",
      "Iteration 0, Loss: 4.447288574738195e-06, Min w: 0.9903450012207031\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 4737, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.005050896245312979, 'L2_avg': 0.006617545981958406, 'End_point_L1_avg': 0.00568404612539449, 'End_point_L2_avg': 0.0056924200319034175}\n",
      "Iteration 0, Loss: 0.0010006249649450183, Min w: 0.0\n",
      "Iteration 10, Loss: 0.001090470002964139, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009579108445905149, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000843711313791573, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007730806246399879, Min w: 0.0\n",
      "Iteration 50, Loss: 0.000715899164788425, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005708331591449678, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005220439052209258, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005145180621184409, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0004859778855461627, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0004651355557143688, Min w: 0.0\n",
      "Iteration 110, Loss: 0.00047592021292075515, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0004503673408180475, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0004438417381606996, Min w: 0.0\n",
      "Iteration 140, Loss: 0.00043853092938661575, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00039669565740041435, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0004021377535536885, Min w: 0.0\n",
      "Iteration 170, Loss: 0.00039839150849729776, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0003972788399551064, Min w: 0.0\n",
      "Iteration 190, Loss: 0.00038647197652608156, Min w: 0.0\n",
      "Iteration 200, Loss: 0.00038726607454009354, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00039602251490578055, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0003505314525682479, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0003289253800176084, Min w: 0.0\n",
      "Iteration 240, Loss: 0.00034630176378414035, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0003496749559417367, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0003369073383510113, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0003839624405372888, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00042573895188979805, Min w: 1.273865122668081e-19\n",
      "Iteration 290, Loss: 0.000432272587204352, Min w: 1.431493257264549e-09\n",
      "Iteration 300, Loss: 0.0004512621962931007, Min w: 2.3579296131980687e-38\n",
      "Iteration 310, Loss: 0.0004166435683146119, Min w: 1.2110122670600009e-36\n",
      "Iteration 320, Loss: 0.00039077564724721014, Min w: 1.4479067669825937e-19\n",
      "Iteration 330, Loss: 0.00036735832691192627, Min w: 5.25539375279889e-17\n",
      "Iteration 340, Loss: 0.00034344071173109114, Min w: 1.733252846802813e-10\n",
      "Iteration 350, Loss: 0.00037002298631705344, Min w: 0.0001948379067471251\n",
      "Iteration 360, Loss: 0.0003295165370218456, Min w: 0.058581653982400894\n",
      "Iteration 370, Loss: 0.0003644072567112744, Min w: 0.07315582036972046\n",
      "Iteration 380, Loss: 0.00034675851929932833, Min w: 0.10988642275333405\n",
      "Iteration 390, Loss: 0.00031816193950362504, Min w: 0.12973731756210327\n",
      "Iteration 400, Loss: 0.0003122488269582391, Min w: 0.1512182056903839\n",
      "Iteration 410, Loss: 0.0002968121552839875, Min w: 0.18592721223831177\n",
      "Iteration 420, Loss: 0.00029142064158804715, Min w: 0.22263018786907196\n",
      "Iteration 430, Loss: 0.0002727509709075093, Min w: 0.24567806720733643\n",
      "Iteration 440, Loss: 0.00025848401128314435, Min w: 0.27958017587661743\n",
      "Iteration 450, Loss: 0.0002536420652177185, Min w: 0.3033982515335083\n",
      "Iteration 460, Loss: 0.0002579192805569619, Min w: 0.32214123010635376\n",
      "Iteration 470, Loss: 0.0003068558871746063, Min w: 0.30194777250289917\n",
      "Iteration 480, Loss: 0.0002878936065826565, Min w: 0.31079578399658203\n",
      "Iteration 490, Loss: 0.0002615777775645256, Min w: 0.3361968994140625\n",
      "Iteration 500, Loss: 0.0002281392371514812, Min w: 0.3786318302154541\n",
      "Iteration 510, Loss: 0.0002734141889959574, Min w: 0.3542569875717163\n",
      "Iteration 520, Loss: 0.0002373856696067378, Min w: 0.4034402668476105\n",
      "Iteration 530, Loss: 0.00024122244212776423, Min w: 0.3774167597293854\n",
      "Iteration 540, Loss: 0.00021599899628199637, Min w: 0.43378159403800964\n",
      "Iteration 550, Loss: 0.00020141273853369057, Min w: 0.48872140049934387\n",
      "Iteration 560, Loss: 0.00025431238464079797, Min w: 0.38389378786087036\n",
      "Iteration 570, Loss: 0.0002555031969677657, Min w: 0.41663286089897156\n",
      "Iteration 580, Loss: 0.00020237386343069375, Min w: 0.4965181052684784\n",
      "Iteration 590, Loss: 0.00022614604677073658, Min w: 0.47870343923568726\n",
      "Iteration 600, Loss: 0.0001748387876432389, Min w: 0.5313128232955933\n",
      "Iteration 610, Loss: 0.0001881030766526237, Min w: 0.5474880933761597\n",
      "Iteration 620, Loss: 0.00016970696742646396, Min w: 0.5582403540611267\n",
      "Iteration 630, Loss: 0.00016238917305599898, Min w: 0.5664582848548889\n",
      "Iteration 640, Loss: 0.00016328679339494556, Min w: 0.5747389793395996\n",
      "Iteration 650, Loss: 0.0001900248316815123, Min w: 0.5619938969612122\n",
      "Iteration 660, Loss: 0.000179028938873671, Min w: 0.5656306147575378\n",
      "Iteration 670, Loss: 0.00014703514170832932, Min w: 0.6029682159423828\n",
      "Iteration 680, Loss: 0.00016089870769064873, Min w: 0.5796780586242676\n",
      "Iteration 690, Loss: 0.0001393721904605627, Min w: 0.6289280652999878\n",
      "Iteration 700, Loss: 0.00015095520939212292, Min w: 0.6380548477172852\n",
      "Iteration 710, Loss: 0.00017135350208263844, Min w: 0.5981490612030029\n",
      "Iteration 720, Loss: 0.00017053923511411995, Min w: 0.609021782875061\n",
      "Iteration 730, Loss: 0.00015450321370735765, Min w: 0.6374766826629639\n",
      "Iteration 740, Loss: 0.00015766496653668582, Min w: 0.6233539581298828\n",
      "Iteration 750, Loss: 0.00013861601473763585, Min w: 0.6520918011665344\n",
      "Iteration 760, Loss: 0.0001566347200423479, Min w: 0.6261467933654785\n",
      "Iteration 770, Loss: 0.00016465678345412016, Min w: 0.6596112251281738\n",
      "Iteration 780, Loss: 0.00011156405525980517, Min w: 0.7089983224868774\n",
      "Iteration 790, Loss: 0.0001318727299803868, Min w: 0.6998979449272156\n",
      "Iteration 800, Loss: 0.00014016144268680364, Min w: 0.692421019077301\n",
      "Iteration 810, Loss: 0.00012882761075161397, Min w: 0.7013381719589233\n",
      "Iteration 820, Loss: 0.0001440052001271397, Min w: 0.6704394221305847\n",
      "Iteration 830, Loss: 0.0001449874835088849, Min w: 0.6512889266014099\n",
      "Iteration 840, Loss: 0.00013773387763649225, Min w: 0.6601720452308655\n",
      "Iteration 850, Loss: 9.859105193754658e-05, Min w: 0.7470274567604065\n",
      "Iteration 860, Loss: 0.00010266523895552382, Min w: 0.7494826316833496\n",
      "Iteration 870, Loss: 0.00010785514314193279, Min w: 0.7522264122962952\n",
      "Iteration 880, Loss: 9.954746201401576e-05, Min w: 0.7731699347496033\n",
      "Iteration 890, Loss: 0.00015311808965634555, Min w: 0.6780943274497986\n",
      "Iteration 900, Loss: 8.860038360580802e-05, Min w: 0.7831209301948547\n",
      "Iteration 910, Loss: 9.146046795649454e-05, Min w: 0.7716225385665894\n",
      "Iteration 920, Loss: 8.593605161877349e-05, Min w: 0.7848078608512878\n",
      "Iteration 930, Loss: 0.0001303681347053498, Min w: 0.7254444360733032\n",
      "Iteration 940, Loss: 0.00013906987442169338, Min w: 0.6901382207870483\n",
      "Iteration 950, Loss: 9.768388554221019e-05, Min w: 0.7906148433685303\n",
      "Iteration 960, Loss: 0.0001157539154519327, Min w: 0.7642378807067871\n",
      "Iteration 970, Loss: 8.979887934401631e-05, Min w: 0.7779296040534973\n",
      "Iteration 980, Loss: 8.135230018524453e-05, Min w: 0.8143961429595947\n",
      "Iteration 990, Loss: 9.198532643495128e-05, Min w: 0.7958471775054932\n",
      "Iteration 1000, Loss: 6.932549877092242e-05, Min w: 0.8293371200561523\n",
      "Iteration 1010, Loss: 0.00013905801461078227, Min w: 0.6963436007499695\n",
      "Iteration 1020, Loss: 0.00012734880147036165, Min w: 0.7043308615684509\n",
      "Iteration 1030, Loss: 8.978484402177855e-05, Min w: 0.8078099489212036\n",
      "Iteration 1040, Loss: 6.773712811991572e-05, Min w: 0.8368054032325745\n",
      "Iteration 1050, Loss: 0.00010246719466522336, Min w: 0.7677735686302185\n",
      "Iteration 1060, Loss: 8.332227298524231e-05, Min w: 0.8251966238021851\n",
      "Iteration 1070, Loss: 7.744351023575291e-05, Min w: 0.8201336860656738\n",
      "Iteration 1080, Loss: 7.457144238287583e-05, Min w: 0.8200567364692688\n",
      "Iteration 1090, Loss: 6.451872468460351e-05, Min w: 0.8591792583465576\n",
      "Iteration 1100, Loss: 0.0001472941949032247, Min w: 0.6682601571083069\n",
      "Iteration 1110, Loss: 0.0001062313313013874, Min w: 0.7628147006034851\n",
      "Iteration 1120, Loss: 5.756065002060495e-05, Min w: 0.8645000457763672\n",
      "Iteration 1130, Loss: 5.9906888054683805e-05, Min w: 0.8775537014007568\n",
      "Iteration 1140, Loss: 0.0001107060961658135, Min w: 0.7712050676345825\n",
      "Iteration 1150, Loss: 9.337122901342809e-05, Min w: 0.7842649221420288\n",
      "Iteration 1160, Loss: 8.656261343276128e-05, Min w: 0.8105415105819702\n",
      "Iteration 1170, Loss: 7.632112101418898e-05, Min w: 0.8419841527938843\n",
      "Iteration 1180, Loss: 7.30247120372951e-05, Min w: 0.8334619402885437\n",
      "Iteration 1190, Loss: 7.057179027469829e-05, Min w: 0.8238877058029175\n",
      "Iteration 1200, Loss: 6.2998675275594e-05, Min w: 0.8579961657524109\n",
      "Iteration 1210, Loss: 7.127434219000861e-05, Min w: 0.8491170406341553\n",
      "Iteration 1220, Loss: 6.234469765331596e-05, Min w: 0.8576372265815735\n",
      "Iteration 1230, Loss: 5.820344449602999e-05, Min w: 0.8713512420654297\n",
      "Iteration 1240, Loss: 7.388845551759005e-05, Min w: 0.8337363004684448\n",
      "Iteration 0, Loss: 5.3281051805242896e-05, Min w: 0.8802070021629333\n",
      "Iteration 10, Loss: 6.87079518684186e-05, Min w: 0.8439856767654419\n",
      "Iteration 20, Loss: 7.338733121287078e-05, Min w: 0.8307114243507385\n",
      "Iteration 30, Loss: 5.633287946693599e-05, Min w: 0.8804513812065125\n",
      "Iteration 40, Loss: 4.411400368553586e-05, Min w: 0.9018694758415222\n",
      "Iteration 50, Loss: 5.003121623303741e-05, Min w: 0.8890014290809631\n",
      "Iteration 60, Loss: 6.158745236461982e-05, Min w: 0.8636941313743591\n",
      "Iteration 70, Loss: 4.034317680634558e-05, Min w: 0.905720055103302\n",
      "Iteration 80, Loss: 5.001183308195323e-05, Min w: 0.8956687450408936\n",
      "Iteration 90, Loss: 5.751493517891504e-05, Min w: 0.8672972321510315\n",
      "Iteration 100, Loss: 8.112316572805867e-05, Min w: 0.8201746344566345\n",
      "Iteration 110, Loss: 4.465293022803962e-05, Min w: 0.9066619873046875\n",
      "Iteration 120, Loss: 6.811569619458169e-05, Min w: 0.8288161158561707\n",
      "Iteration 130, Loss: 6.244088581297547e-05, Min w: 0.858831524848938\n",
      "Iteration 140, Loss: 7.332927634706721e-05, Min w: 0.8322031497955322\n",
      "Iteration 150, Loss: 5.83327237109188e-05, Min w: 0.8801597356796265\n",
      "Iteration 160, Loss: 6.975417636567727e-05, Min w: 0.8470116257667542\n",
      "Iteration 170, Loss: 5.4687301599187776e-05, Min w: 0.8642953038215637\n",
      "Iteration 180, Loss: 5.439115557237528e-05, Min w: 0.8876205086708069\n",
      "Iteration 190, Loss: 5.7846453273668885e-05, Min w: 0.8524633646011353\n",
      "Iteration 200, Loss: 4.363523839856498e-05, Min w: 0.9008235931396484\n",
      "Iteration 210, Loss: 2.99867879220983e-05, Min w: 0.9340296983718872\n",
      "Iteration 220, Loss: 5.5529711971757933e-05, Min w: 0.8616652488708496\n",
      "Iteration 230, Loss: 5.855011841049418e-05, Min w: 0.8509262204170227\n",
      "Iteration 240, Loss: 9.514913108432665e-05, Min w: 0.7639868855476379\n",
      "Iteration 250, Loss: 8.696524309925735e-05, Min w: 0.7976883053779602\n",
      "Iteration 260, Loss: 5.3697116527473554e-05, Min w: 0.8732573390007019\n",
      "Iteration 270, Loss: 5.404664989328012e-05, Min w: 0.862058162689209\n",
      "Iteration 280, Loss: 2.8266185836400837e-05, Min w: 0.9365261793136597\n",
      "Iteration 290, Loss: 9.848392801359296e-05, Min w: 0.7717332243919373\n",
      "Iteration 300, Loss: 2.942242645076476e-05, Min w: 0.9383823275566101\n",
      "Iteration 310, Loss: 4.459549381863326e-05, Min w: 0.8930321335792542\n",
      "Iteration 320, Loss: 6.369312177412212e-05, Min w: 0.8428829312324524\n",
      "Iteration 330, Loss: 3.659102731035091e-05, Min w: 0.911344051361084\n",
      "Iteration 340, Loss: 4.9962673074333e-05, Min w: 0.8833008408546448\n",
      "Iteration 350, Loss: 6.687943823635578e-05, Min w: 0.8356638550758362\n",
      "Iteration 360, Loss: 7.317007111851126e-05, Min w: 0.827050507068634\n",
      "Iteration 370, Loss: 3.48428038705606e-05, Min w: 0.9261724948883057\n",
      "Iteration 380, Loss: 2.5355157049489208e-05, Min w: 0.9469285607337952\n",
      "Iteration 390, Loss: 2.5498336981399916e-05, Min w: 0.9470868706703186\n",
      "Iteration 400, Loss: 3.257663411204703e-05, Min w: 0.9238842725753784\n",
      "Iteration 410, Loss: 2.7801568649010733e-05, Min w: 0.940983235836029\n",
      "Iteration 420, Loss: 3.509327507345006e-05, Min w: 0.9114426374435425\n",
      "Iteration 430, Loss: 4.279519635019824e-05, Min w: 0.8996953964233398\n",
      "Iteration 440, Loss: 6.98474541422911e-05, Min w: 0.8415984511375427\n",
      "Iteration 450, Loss: 6.844092422397807e-05, Min w: 0.800568163394928\n",
      "Iteration 460, Loss: 3.801864659180865e-05, Min w: 0.9215371012687683\n",
      "Iteration 470, Loss: 2.767897785815876e-05, Min w: 0.9339509010314941\n",
      "Iteration 480, Loss: 7.50459439586848e-05, Min w: 0.8083054423332214\n",
      "Iteration 490, Loss: 5.274648719932884e-05, Min w: 0.8828219771385193\n",
      "Iteration 500, Loss: 2.8736345484503545e-05, Min w: 0.9298003911972046\n",
      "Iteration 510, Loss: 2.2411515601561405e-05, Min w: 0.9522406458854675\n",
      "Iteration 520, Loss: 8.273585990536958e-05, Min w: 0.7748251557350159\n",
      "Iteration 530, Loss: 5.837495700689033e-05, Min w: 0.844704270362854\n",
      "Iteration 540, Loss: 6.424728780984879e-05, Min w: 0.8219872713088989\n",
      "Iteration 550, Loss: 4.027441536891274e-05, Min w: 0.887691080570221\n",
      "Iteration 560, Loss: 2.2092088329372928e-05, Min w: 0.9496686458587646\n",
      "Iteration 570, Loss: 4.907792390440591e-05, Min w: 0.8699094653129578\n",
      "Iteration 580, Loss: 6.664401007583365e-05, Min w: 0.8292710185050964\n",
      "Iteration 590, Loss: 5.850115849170834e-05, Min w: 0.8320027589797974\n",
      "Iteration 600, Loss: 4.287814590497874e-05, Min w: 0.8952621221542358\n",
      "Iteration 610, Loss: 2.6152860300499015e-05, Min w: 0.9342061877250671\n",
      "Iteration 620, Loss: 4.798352892976254e-05, Min w: 0.8692283630371094\n",
      "Iteration 630, Loss: 4.469120176509023e-05, Min w: 0.8756594657897949\n",
      "Iteration 640, Loss: 4.141597673879005e-05, Min w: 0.8967219591140747\n",
      "Iteration 650, Loss: 2.652275543368887e-05, Min w: 0.9456439018249512\n",
      "Iteration 660, Loss: 3.407427357160486e-05, Min w: 0.9182774424552917\n",
      "Iteration 670, Loss: 4.401406113174744e-05, Min w: 0.9054690003395081\n",
      "Iteration 680, Loss: 6.584754009963945e-05, Min w: 0.830845832824707\n",
      "Iteration 690, Loss: 2.265215152874589e-05, Min w: 0.9473289251327515\n",
      "Iteration 700, Loss: 1.8623284631757997e-05, Min w: 0.9588189721107483\n",
      "Iteration 710, Loss: 1.7709873645799235e-05, Min w: 0.9599611163139343\n",
      "Iteration 720, Loss: 3.988796743215062e-05, Min w: 0.907580554485321\n",
      "Iteration 730, Loss: 3.519648817018606e-05, Min w: 0.9090688824653625\n",
      "Iteration 740, Loss: 2.8418688089004718e-05, Min w: 0.9231733679771423\n",
      "Iteration 750, Loss: 2.364037572988309e-05, Min w: 0.9387799501419067\n",
      "Iteration 760, Loss: 2.0113935534027405e-05, Min w: 0.956105649471283\n",
      "Iteration 770, Loss: 5.0350390665698797e-05, Min w: 0.8790639042854309\n",
      "Iteration 780, Loss: 1.973757753148675e-05, Min w: 0.9573448896408081\n",
      "Iteration 790, Loss: 5.359645001590252e-05, Min w: 0.8860257863998413\n",
      "Iteration 800, Loss: 6.787434540456161e-05, Min w: 0.830953061580658\n",
      "Iteration 810, Loss: 3.261254823883064e-05, Min w: 0.9155512452125549\n",
      "Iteration 820, Loss: 3.507460860419087e-05, Min w: 0.8971736431121826\n",
      "Iteration 830, Loss: 4.456233000382781e-05, Min w: 0.8750466704368591\n",
      "Iteration 840, Loss: 4.7979847295209765e-05, Min w: 0.8708903789520264\n",
      "Iteration 850, Loss: 1.6707481336197816e-05, Min w: 0.9650000929832458\n",
      "Iteration 860, Loss: 4.657535828300752e-05, Min w: 0.8879472017288208\n",
      "Iteration 870, Loss: 2.7780033633462153e-05, Min w: 0.9221312403678894\n",
      "Iteration 880, Loss: 2.1219166228547692e-05, Min w: 0.9435741305351257\n",
      "Iteration 890, Loss: 4.618083039531484e-05, Min w: 0.8732311129570007\n",
      "Iteration 900, Loss: 3.8335314457071945e-05, Min w: 0.9082425236701965\n",
      "Iteration 910, Loss: 3.1304287404054776e-05, Min w: 0.9090979099273682\n",
      "Iteration 920, Loss: 2.776539076876361e-05, Min w: 0.9282581806182861\n",
      "Iteration 930, Loss: 3.587968603824265e-05, Min w: 0.8870840668678284\n",
      "Iteration 940, Loss: 3.685810588649474e-05, Min w: 0.8903953433036804\n",
      "Iteration 950, Loss: 3.1697822123533115e-05, Min w: 0.9059327244758606\n",
      "Iteration 960, Loss: 2.9120619728928432e-05, Min w: 0.9158759117126465\n",
      "Iteration 970, Loss: 3.005950929946266e-05, Min w: 0.9155416488647461\n",
      "Iteration 980, Loss: 2.4908546038204804e-05, Min w: 0.9345546364784241\n",
      "Iteration 990, Loss: 2.1060714061604813e-05, Min w: 0.9396410584449768\n",
      "Iteration 1000, Loss: 3.821290374617092e-05, Min w: 0.8980081677436829\n",
      "Iteration 1010, Loss: 4.851632911595516e-05, Min w: 0.8669250011444092\n",
      "Iteration 1020, Loss: 2.613863216538448e-05, Min w: 0.9305129647254944\n",
      "Iteration 1030, Loss: 3.929268132196739e-05, Min w: 0.8847513198852539\n",
      "Iteration 1040, Loss: 2.579908505140338e-05, Min w: 0.9274957776069641\n",
      "Iteration 1050, Loss: 5.164324466022663e-05, Min w: 0.8599778413772583\n",
      "Iteration 1060, Loss: 3.2519263186259195e-05, Min w: 0.9110456705093384\n",
      "Iteration 1070, Loss: 1.8827515305019915e-05, Min w: 0.9483983516693115\n",
      "Iteration 1080, Loss: 4.026821261504665e-05, Min w: 0.9015226364135742\n",
      "Iteration 1090, Loss: 4.5514298108173534e-05, Min w: 0.900606632232666\n",
      "Iteration 1100, Loss: 2.3242817405844107e-05, Min w: 0.9509047865867615\n",
      "Iteration 1110, Loss: 2.8301210477366112e-05, Min w: 0.9347633719444275\n",
      "Iteration 1120, Loss: 2.7601658075582236e-05, Min w: 0.930703341960907\n",
      "Iteration 1130, Loss: 4.0263003029394895e-05, Min w: 0.8963993191719055\n",
      "Iteration 1140, Loss: 2.661691360117402e-05, Min w: 0.9230089783668518\n",
      "Iteration 1150, Loss: 3.5765689972322434e-05, Min w: 0.9086905717849731\n",
      "Iteration 1160, Loss: 4.592750337906182e-05, Min w: 0.871043860912323\n",
      "Iteration 1170, Loss: 4.3822918087244034e-05, Min w: 0.8999452590942383\n",
      "Iteration 1180, Loss: 2.5980742066167295e-05, Min w: 0.9282349348068237\n",
      "Iteration 1190, Loss: 1.8849388652597554e-05, Min w: 0.9489966034889221\n",
      "Iteration 1200, Loss: 4.355740384198725e-05, Min w: 0.8806370496749878\n",
      "Iteration 1210, Loss: 2.3723150661680847e-05, Min w: 0.9446412920951843\n",
      "Iteration 1220, Loss: 1.3714638953388203e-05, Min w: 0.9675885438919067\n",
      "Iteration 1230, Loss: 4.726980114355683e-05, Min w: 0.8730783462524414\n",
      "Iteration 1240, Loss: 1.708511081233155e-05, Min w: 0.956635057926178\n",
      "Iteration 0, Loss: 2.2420543245971203e-05, Min w: 0.940610945224762\n",
      "Iteration 10, Loss: 4.216108573018573e-05, Min w: 0.8646038174629211\n",
      "Iteration 20, Loss: 3.8928868889342993e-05, Min w: 0.8728578090667725\n",
      "Iteration 30, Loss: 2.4774901248747483e-05, Min w: 0.929111897945404\n",
      "Iteration 40, Loss: 4.3466134229674935e-05, Min w: 0.8672859072685242\n",
      "Iteration 50, Loss: 9.28958979784511e-06, Min w: 0.9808531999588013\n",
      "Iteration 60, Loss: 9.826657333178446e-06, Min w: 0.9789949059486389\n",
      "Iteration 70, Loss: 1.0769201253424399e-05, Min w: 0.9770141243934631\n",
      "Iteration 80, Loss: 3.4492910344852135e-05, Min w: 0.9160544276237488\n",
      "Iteration 90, Loss: 2.0483350454014726e-05, Min w: 0.9396692514419556\n",
      "Iteration 100, Loss: 2.2797099518356845e-05, Min w: 0.9316020011901855\n",
      "Iteration 110, Loss: 1.9186736608389765e-05, Min w: 0.9484668970108032\n",
      "Iteration 120, Loss: 4.045237074024044e-05, Min w: 0.91379714012146\n",
      "Iteration 130, Loss: 2.500645314285066e-05, Min w: 0.9333714842796326\n",
      "Iteration 140, Loss: 1.9068958863499574e-05, Min w: 0.9414895176887512\n",
      "Iteration 150, Loss: 3.453221870586276e-05, Min w: 0.9042935371398926\n",
      "Iteration 160, Loss: 2.8958584152860567e-05, Min w: 0.9155911803245544\n",
      "Iteration 170, Loss: 1.994604099309072e-05, Min w: 0.9416045546531677\n",
      "Iteration 180, Loss: 1.8678589185583405e-05, Min w: 0.9571861028671265\n",
      "Iteration 190, Loss: 3.6403875128598884e-05, Min w: 0.9186587929725647\n",
      "Iteration 200, Loss: 1.4676100363431033e-05, Min w: 0.9587217569351196\n",
      "Iteration 210, Loss: 3.36464581778273e-05, Min w: 0.9068123698234558\n",
      "Iteration 220, Loss: 3.465624831733294e-05, Min w: 0.8914448618888855\n",
      "Iteration 230, Loss: 3.3567117498023435e-05, Min w: 0.8999013900756836\n",
      "Iteration 240, Loss: 2.1543028196902014e-05, Min w: 0.9459971189498901\n",
      "Iteration 250, Loss: 1.63317599799484e-05, Min w: 0.9514016509056091\n",
      "Iteration 260, Loss: 2.461443727952428e-05, Min w: 0.936957061290741\n",
      "Iteration 270, Loss: 3.5722332540899515e-05, Min w: 0.9126242399215698\n",
      "Iteration 280, Loss: 1.6082567526609637e-05, Min w: 0.9543481469154358\n",
      "Iteration 290, Loss: 2.211632272519637e-05, Min w: 0.932479739189148\n",
      "Iteration 300, Loss: 4.336711936048232e-05, Min w: 0.8662534952163696\n",
      "Iteration 310, Loss: 2.4774582925601862e-05, Min w: 0.9220321178436279\n",
      "Iteration 320, Loss: 1.68562401086092e-05, Min w: 0.9557373523712158\n",
      "Iteration 330, Loss: 4.2747316911118105e-05, Min w: 0.9012072086334229\n",
      "Iteration 340, Loss: 1.2580230759340338e-05, Min w: 0.9666646718978882\n",
      "Iteration 350, Loss: 3.14053577312734e-05, Min w: 0.9187414646148682\n",
      "Iteration 360, Loss: 9.813452379603405e-06, Min w: 0.9770747423171997\n",
      "Iteration 370, Loss: 4.278227424947545e-05, Min w: 0.8748143315315247\n",
      "Iteration 380, Loss: 1.1345344319124706e-05, Min w: 0.9693053960800171\n",
      "Iteration 390, Loss: 3.0053715818212368e-05, Min w: 0.9298728704452515\n",
      "Iteration 400, Loss: 2.3097440134733915e-05, Min w: 0.9195645451545715\n",
      "Iteration 410, Loss: 6.103634223109111e-05, Min w: 0.8219279050827026\n",
      "Iteration 420, Loss: 3.935181302949786e-05, Min w: 0.899459958076477\n",
      "Iteration 430, Loss: 2.6779391191666946e-05, Min w: 0.9281617999076843\n",
      "Iteration 440, Loss: 1.8522543541621417e-05, Min w: 0.9407532215118408\n",
      "Iteration 450, Loss: 2.6304491257178597e-05, Min w: 0.9270626902580261\n",
      "Iteration 460, Loss: 2.7203337594983168e-05, Min w: 0.9196426272392273\n",
      "Iteration 470, Loss: 1.7274118363275193e-05, Min w: 0.9470471739768982\n",
      "Iteration 480, Loss: 1.5080113371368498e-05, Min w: 0.9603709578514099\n",
      "Iteration 490, Loss: 3.091911639785394e-05, Min w: 0.8989006280899048\n",
      "Iteration 500, Loss: 2.2094563973951153e-05, Min w: 0.9322040677070618\n",
      "Iteration 510, Loss: 1.4226106941350736e-05, Min w: 0.9679386019706726\n",
      "Iteration 520, Loss: 3.323209966765717e-05, Min w: 0.921109139919281\n",
      "Iteration 530, Loss: 2.390767986071296e-05, Min w: 0.9259086847305298\n",
      "Iteration 540, Loss: 1.14863623821293e-05, Min w: 0.9748405814170837\n",
      "Iteration 550, Loss: 1.2015913853247184e-05, Min w: 0.9652422070503235\n",
      "Iteration 560, Loss: 3.108797682216391e-05, Min w: 0.9202880263328552\n",
      "Iteration 570, Loss: 3.69574518117588e-05, Min w: 0.901902973651886\n",
      "Iteration 580, Loss: 2.6134193831239827e-05, Min w: 0.9086693525314331\n",
      "Iteration 590, Loss: 2.4347018552361988e-05, Min w: 0.922909140586853\n",
      "Iteration 600, Loss: 3.754362842300907e-05, Min w: 0.918555736541748\n",
      "Iteration 610, Loss: 2.8441356334951706e-05, Min w: 0.9005065560340881\n",
      "Iteration 620, Loss: 2.525292984500993e-05, Min w: 0.9437657594680786\n",
      "Iteration 630, Loss: 3.571168053895235e-05, Min w: 0.881325364112854\n",
      "Iteration 640, Loss: 7.79483889346011e-06, Min w: 0.9811737537384033\n",
      "Iteration 650, Loss: 3.097753142355941e-05, Min w: 0.8989216089248657\n",
      "Iteration 660, Loss: 3.6177749279886484e-05, Min w: 0.9210083484649658\n",
      "Iteration 670, Loss: 2.0415947801666334e-05, Min w: 0.9393792152404785\n",
      "Iteration 680, Loss: 2.1323023247532547e-05, Min w: 0.9311389923095703\n",
      "Iteration 690, Loss: 2.5562352675478905e-05, Min w: 0.9354435801506042\n",
      "Iteration 700, Loss: 2.1527515855268575e-05, Min w: 0.9458764791488647\n",
      "Iteration 710, Loss: 2.076436794595793e-05, Min w: 0.9462858438491821\n",
      "Iteration 720, Loss: 2.203078656748403e-05, Min w: 0.9235221743583679\n",
      "Iteration 730, Loss: 2.646692519192584e-05, Min w: 0.9431833624839783\n",
      "Iteration 740, Loss: 2.6121968403458595e-05, Min w: 0.9190732836723328\n",
      "Iteration 750, Loss: 2.0888559447485022e-05, Min w: 0.9561702013015747\n",
      "Iteration 760, Loss: 2.10193084058119e-05, Min w: 0.9439583420753479\n",
      "Iteration 770, Loss: 3.6205055948812515e-05, Min w: 0.889569103717804\n",
      "Iteration 780, Loss: 2.7310283257975243e-05, Min w: 0.9142705798149109\n",
      "Iteration 790, Loss: 2.549280361563433e-05, Min w: 0.9459309577941895\n",
      "Iteration 800, Loss: 1.3904578736401163e-05, Min w: 0.9628560543060303\n",
      "Iteration 810, Loss: 1.2941603017679881e-05, Min w: 0.9635709524154663\n",
      "Iteration 820, Loss: 1.9773760868702084e-05, Min w: 0.9371638894081116\n",
      "Iteration 830, Loss: 1.132033776229946e-05, Min w: 0.9760757684707642\n",
      "Iteration 840, Loss: 1.0486234714335296e-05, Min w: 0.9679176211357117\n",
      "Iteration 850, Loss: 1.8997216102434322e-05, Min w: 0.9522438645362854\n",
      "Iteration 860, Loss: 4.553865801426582e-05, Min w: 0.8508000373840332\n",
      "Iteration 870, Loss: 2.3411061192746274e-05, Min w: 0.9284145832061768\n",
      "Iteration 880, Loss: 2.588975621620193e-05, Min w: 0.9341809153556824\n",
      "Iteration 890, Loss: 1.566263017593883e-05, Min w: 0.9488023519515991\n",
      "Iteration 900, Loss: 2.2957521650823765e-05, Min w: 0.9323883652687073\n",
      "Iteration 910, Loss: 2.4038903575274162e-05, Min w: 0.9361903071403503\n",
      "Iteration 920, Loss: 1.854596303019207e-05, Min w: 0.9558994174003601\n",
      "Iteration 930, Loss: 1.543666257930454e-05, Min w: 0.9522616863250732\n",
      "Iteration 940, Loss: 2.4084505639621057e-05, Min w: 0.9384565949440002\n",
      "Iteration 950, Loss: 1.4015037777426187e-05, Min w: 0.95032799243927\n",
      "Iteration 960, Loss: 2.2763209926779382e-05, Min w: 0.9479835033416748\n",
      "Iteration 970, Loss: 1.5334944691858254e-05, Min w: 0.9483178853988647\n",
      "Iteration 980, Loss: 3.1032792321639135e-05, Min w: 0.9116777777671814\n",
      "Iteration 990, Loss: 1.3460649824992288e-05, Min w: 0.968994140625\n",
      "Iteration 1000, Loss: 8.276255357486662e-06, Min w: 0.976742148399353\n",
      "Iteration 1010, Loss: 1.9822409740299918e-05, Min w: 0.9566978812217712\n",
      "Iteration 1020, Loss: 4.327984424890019e-05, Min w: 0.8613869547843933\n",
      "Iteration 1030, Loss: 6.428142569347983e-06, Min w: 0.9835589528083801\n",
      "Iteration 1040, Loss: 3.641788134700619e-05, Min w: 0.9177969098091125\n",
      "Iteration 1050, Loss: 2.2201194951776415e-05, Min w: 0.9401013851165771\n",
      "Iteration 1060, Loss: 1.1642223398666829e-05, Min w: 0.9722427725791931\n",
      "Iteration 1070, Loss: 7.441015441145282e-06, Min w: 0.9788427352905273\n",
      "Iteration 1080, Loss: 3.125943476334214e-05, Min w: 0.8949839472770691\n",
      "Iteration 1090, Loss: 2.0762605345225893e-05, Min w: 0.9331545233726501\n",
      "Iteration 1100, Loss: 2.2558395357918926e-05, Min w: 0.9322813153266907\n",
      "Iteration 1110, Loss: 2.540629247960169e-05, Min w: 0.9353260397911072\n",
      "Iteration 1120, Loss: 3.6679448385257274e-05, Min w: 0.9023052453994751\n",
      "Iteration 1130, Loss: 1.895492459880188e-05, Min w: 0.9543631672859192\n",
      "Iteration 1140, Loss: 4.130151864956133e-05, Min w: 0.8894043564796448\n",
      "Iteration 1150, Loss: 6.0408510762499645e-06, Min w: 0.9844560027122498\n",
      "Iteration 1160, Loss: 1.6075327948783524e-05, Min w: 0.9501014351844788\n",
      "Iteration 1170, Loss: 1.2761605830746703e-05, Min w: 0.9619877934455872\n",
      "Iteration 1180, Loss: 1.7176947949337773e-05, Min w: 0.9617478251457214\n",
      "Iteration 1190, Loss: 1.737164711812511e-05, Min w: 0.9584775567054749\n",
      "Iteration 1200, Loss: 1.1755474588426296e-05, Min w: 0.9709808826446533\n",
      "Iteration 1210, Loss: 5.6980316003318876e-05, Min w: 0.8762889504432678\n",
      "Iteration 1220, Loss: 3.457616185187362e-05, Min w: 0.9006956219673157\n",
      "Iteration 1230, Loss: 2.0643414245569147e-05, Min w: 0.934840977191925\n",
      "Iteration 1240, Loss: 1.2840121598856058e-05, Min w: 0.9632845520973206\n",
      "Iteration 0, Loss: 3.0814437195658684e-05, Min w: 0.9150899052619934\n",
      "Iteration 10, Loss: 2.230244172096718e-05, Min w: 0.9299985766410828\n",
      "Iteration 20, Loss: 8.692374649399426e-06, Min w: 0.9765706062316895\n",
      "Iteration 30, Loss: 8.909767529985402e-06, Min w: 0.976852536201477\n",
      "Iteration 40, Loss: 1.410097502230201e-05, Min w: 0.9689286351203918\n",
      "Iteration 50, Loss: 4.1744333429960534e-05, Min w: 0.8762925863265991\n",
      "Iteration 60, Loss: 3.953199120587669e-05, Min w: 0.874835729598999\n",
      "Iteration 70, Loss: 1.6724132365197875e-05, Min w: 0.9525966644287109\n",
      "Iteration 80, Loss: 3.0242750653997064e-05, Min w: 0.9301719665527344\n",
      "Iteration 90, Loss: 1.9844923372147605e-05, Min w: 0.9547123908996582\n",
      "Iteration 100, Loss: 3.320175892440602e-05, Min w: 0.9040274620056152\n",
      "Iteration 110, Loss: 8.601102308603004e-06, Min w: 0.9750956892967224\n",
      "Iteration 120, Loss: 3.477927384665236e-05, Min w: 0.9118413329124451\n",
      "Iteration 130, Loss: 1.2353634701867122e-05, Min w: 0.9705057144165039\n",
      "Iteration 140, Loss: 3.336659574415535e-05, Min w: 0.9123315811157227\n",
      "Iteration 150, Loss: 1.4566900972567964e-05, Min w: 0.9521755576133728\n",
      "Iteration 160, Loss: 2.4505845431121998e-05, Min w: 0.944042980670929\n",
      "Iteration 170, Loss: 1.8437185644870624e-05, Min w: 0.9610288143157959\n",
      "Iteration 180, Loss: 2.587567905720789e-05, Min w: 0.9133452773094177\n",
      "Iteration 190, Loss: 1.955063817149494e-05, Min w: 0.9368022680282593\n",
      "Iteration 200, Loss: 3.033557914022822e-05, Min w: 0.8994501829147339\n",
      "Iteration 210, Loss: 6.082377240090864e-06, Min w: 0.9860016703605652\n",
      "Iteration 220, Loss: 6.715221843478503e-06, Min w: 0.9854358434677124\n",
      "Iteration 230, Loss: 3.848065898637287e-05, Min w: 0.8971174359321594\n",
      "Iteration 240, Loss: 1.059365149558289e-05, Min w: 0.9747093915939331\n",
      "Iteration 250, Loss: 3.529320383677259e-05, Min w: 0.887541651725769\n",
      "Iteration 260, Loss: 9.906430932460353e-06, Min w: 0.9686546921730042\n",
      "Iteration 270, Loss: 3.9301547076320276e-05, Min w: 0.914084255695343\n",
      "Iteration 280, Loss: 2.0754099750774913e-05, Min w: 0.9301895499229431\n",
      "Iteration 290, Loss: 1.9330384020577185e-05, Min w: 0.9375400543212891\n",
      "Iteration 300, Loss: 2.1805719370604493e-05, Min w: 0.9476621747016907\n",
      "Iteration 310, Loss: 3.124328577541746e-05, Min w: 0.9255340099334717\n",
      "Iteration 320, Loss: 1.777068609953858e-05, Min w: 0.9403814077377319\n",
      "Iteration 330, Loss: 2.643803964019753e-05, Min w: 0.9145070314407349\n",
      "Iteration 340, Loss: 1.8579965399112552e-05, Min w: 0.9546864628791809\n",
      "Iteration 350, Loss: 1.8340755559620447e-05, Min w: 0.9545466899871826\n",
      "Iteration 360, Loss: 6.277578904700931e-06, Min w: 0.9850649237632751\n",
      "Iteration 370, Loss: 9.97954066406237e-06, Min w: 0.9687680602073669\n",
      "Iteration 380, Loss: 2.6276225980836898e-05, Min w: 0.9348381757736206\n",
      "Iteration 390, Loss: 2.0856872652075253e-05, Min w: 0.945813000202179\n",
      "Iteration 400, Loss: 2.5785308025660925e-05, Min w: 0.9456961154937744\n",
      "Iteration 410, Loss: 2.8974141969229095e-05, Min w: 0.939130961894989\n",
      "Iteration 420, Loss: 2.2868225642014295e-05, Min w: 0.9355568289756775\n",
      "Iteration 430, Loss: 1.5834146324777976e-05, Min w: 0.9516019821166992\n",
      "Iteration 440, Loss: 1.807716762414202e-05, Min w: 0.952232301235199\n",
      "Iteration 450, Loss: 9.306216270488221e-06, Min w: 0.973042368888855\n",
      "Iteration 460, Loss: 1.367890217807144e-05, Min w: 0.9671357870101929\n",
      "Iteration 470, Loss: 2.0742867491208017e-05, Min w: 0.935321569442749\n",
      "Iteration 480, Loss: 1.987461291719228e-05, Min w: 0.9303094148635864\n",
      "Iteration 490, Loss: 2.180345654778648e-05, Min w: 0.9399048089981079\n",
      "Iteration 500, Loss: 2.3111129848985e-05, Min w: 0.9385579824447632\n",
      "Iteration 510, Loss: 1.9226410586270504e-05, Min w: 0.934755802154541\n",
      "Iteration 520, Loss: 2.3120710466173477e-05, Min w: 0.9278907179832458\n",
      "Iteration 530, Loss: 1.3508459232980385e-05, Min w: 0.9707218408584595\n",
      "Iteration 540, Loss: 6.374283202603692e-06, Min w: 0.9844488501548767\n",
      "Iteration 550, Loss: 3.0580617021769285e-05, Min w: 0.9168519377708435\n",
      "Iteration 560, Loss: 1.3112020496919286e-05, Min w: 0.9641159772872925\n",
      "Iteration 570, Loss: 1.1243563676544e-05, Min w: 0.9762086272239685\n",
      "Iteration 580, Loss: 3.9776376070221886e-05, Min w: 0.8723251223564148\n",
      "Iteration 590, Loss: 2.0853616661042906e-05, Min w: 0.925063967704773\n",
      "Iteration 600, Loss: 1.2537424481706694e-05, Min w: 0.9680781364440918\n",
      "Iteration 610, Loss: 1.5531919416389428e-05, Min w: 0.9455917477607727\n",
      "Iteration 620, Loss: 1.2186718777229544e-05, Min w: 0.9630028605461121\n",
      "Iteration 630, Loss: 2.1061347069917247e-05, Min w: 0.9563018679618835\n",
      "Iteration 640, Loss: 1.7951086192624643e-05, Min w: 0.9545969367027283\n",
      "Iteration 650, Loss: 2.489547296136152e-05, Min w: 0.9212826490402222\n",
      "Iteration 660, Loss: 2.0294130081310868e-05, Min w: 0.940750002861023\n",
      "Iteration 670, Loss: 1.3400043826550245e-05, Min w: 0.9719915390014648\n",
      "Iteration 680, Loss: 2.120207682310138e-05, Min w: 0.9298295378684998\n",
      "Iteration 690, Loss: 9.434062121727038e-06, Min w: 0.9695824980735779\n",
      "Iteration 700, Loss: 7.202929737104569e-06, Min w: 0.9779228568077087\n",
      "Iteration 710, Loss: 3.336746885906905e-05, Min w: 0.9299908876419067\n",
      "Iteration 720, Loss: 2.0467587091843598e-05, Min w: 0.9267327785491943\n",
      "Iteration 730, Loss: 1.4418390492210165e-05, Min w: 0.9523687362670898\n",
      "Iteration 740, Loss: 2.6398085537948646e-05, Min w: 0.9426736235618591\n",
      "Iteration 750, Loss: 1.9105187675449997e-05, Min w: 0.9492790102958679\n",
      "Iteration 760, Loss: 7.734918654023204e-06, Min w: 0.9794624447822571\n",
      "Iteration 770, Loss: 1.1447727047197986e-05, Min w: 0.9672447443008423\n",
      "Iteration 780, Loss: 2.279291038576048e-05, Min w: 0.9483941793441772\n",
      "Iteration 790, Loss: 3.584897785913199e-05, Min w: 0.8852962255477905\n",
      "Iteration 800, Loss: 1.2627687283384148e-05, Min w: 0.9627118706703186\n",
      "Iteration 810, Loss: 5.209882147028111e-06, Min w: 0.9849277138710022\n",
      "Iteration 820, Loss: 6.530360678880243e-06, Min w: 0.9803214073181152\n",
      "Iteration 830, Loss: 2.4286684492835775e-05, Min w: 0.9491294622421265\n",
      "Iteration 840, Loss: 3.0015389711479656e-05, Min w: 0.8950883150100708\n",
      "Iteration 850, Loss: 6.011521691107191e-06, Min w: 0.9872338771820068\n",
      "Iteration 860, Loss: 2.9203309168224223e-05, Min w: 0.9242950677871704\n",
      "Iteration 870, Loss: 1.835164221120067e-05, Min w: 0.9458893537521362\n",
      "Iteration 880, Loss: 1.1037481272069272e-05, Min w: 0.9723862409591675\n",
      "Early break at iteration 885 --------------------------------\n",
      "Iteration 0, Loss: 3.949563051719451e-06, Min w: 0.9890808463096619\n",
      "Iteration 10, Loss: 4.492210427997634e-05, Min w: 0.8578965663909912\n",
      "Iteration 20, Loss: 4.488369813770987e-05, Min w: 0.8740044832229614\n",
      "Iteration 30, Loss: 4.241878559696488e-05, Min w: 0.8976003527641296\n",
      "Iteration 40, Loss: 9.907923413265962e-06, Min w: 0.9672082662582397\n",
      "Iteration 50, Loss: 1.7747785022947937e-05, Min w: 0.9398576021194458\n",
      "Iteration 60, Loss: 1.5590045222779736e-05, Min w: 0.9655409455299377\n",
      "Iteration 70, Loss: 9.392872925673146e-06, Min w: 0.9710127115249634\n",
      "Iteration 80, Loss: 2.1455141904880293e-05, Min w: 0.9338331818580627\n",
      "Iteration 90, Loss: 8.135855750879273e-06, Min w: 0.9792237877845764\n",
      "Iteration 100, Loss: 2.9764578357571736e-05, Min w: 0.9125181436538696\n",
      "Iteration 110, Loss: 7.862890015530866e-06, Min w: 0.9831701517105103\n",
      "Iteration 120, Loss: 3.306383587187156e-05, Min w: 0.8927998542785645\n",
      "Iteration 130, Loss: 7.190929409262026e-06, Min w: 0.984228253364563\n",
      "Iteration 140, Loss: 1.0433196621306706e-05, Min w: 0.9709283709526062\n",
      "Iteration 150, Loss: 7.391393410216551e-06, Min w: 0.984872043132782\n",
      "Iteration 160, Loss: 4.459432966541499e-05, Min w: 0.8645187616348267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  33%|███▎      | 8/24 [05:46<10:41, 40.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 170, Loss: 3.720692802744452e-06, Min w: 0.9900546669960022\n",
      "Early break at iteration 170 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 4807, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.00517210992636879, 'L2_avg': 0.007047958772801613, 'End_point_L1_avg': 0.002188222999108222, 'End_point_L2_avg': 0.0028474624615756968}\n",
      "Iteration 0, Loss: 0.004988871514797211, Min w: 2.432922308059915e-08\n",
      "Iteration 10, Loss: 0.002474435605108738, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0021249742712825537, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0023466376587748528, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0023387547116726637, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002517370507121086, Min w: 0.0\n",
      "Iteration 60, Loss: 0.004225520417094231, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0034877939615398645, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0054391007870435715, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002968305256217718, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0029975525103509426, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0024612967390567064, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0027265073731541634, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0029592476785182953, Min w: 3.685414961174269e-43\n",
      "Iteration 140, Loss: 0.0028907412197440863, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0027231862768530846, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0031207408756017685, Min w: 0.0\n",
      "Iteration 170, Loss: 0.003321773838251829, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002430698834359646, Min w: 0.0\n",
      "Iteration 190, Loss: 0.003420485183596611, Min w: 1.3446632223124013e-28\n",
      "Iteration 200, Loss: 0.003430550452321768, Min w: 0.0\n",
      "Iteration 210, Loss: 0.003608518745750189, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002396984724327922, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0028879104647785425, Min w: 4.5339147378108436e-29\n",
      "Iteration 240, Loss: 0.002517419634386897, Min w: 8.894136478141943e-34\n",
      "Iteration 250, Loss: 0.0024611225817352533, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0025652351323515177, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002536230953410268, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002454781671985984, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0022361783776432276, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0024261735379695892, Min w: 0.0\n",
      "Iteration 310, Loss: 0.004637573380023241, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0024030485656112432, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0028942283242940903, Min w: 1.401298464324817e-45\n",
      "Iteration 340, Loss: 0.0025880024768412113, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0024659924674779177, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0024280038196593523, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002713373163715005, Min w: 0.0\n",
      "Iteration 380, Loss: 0.005213502794504166, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002737472765147686, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002867191331461072, Min w: 0.0\n",
      "Iteration 410, Loss: 0.005123231094330549, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0026442555245012045, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0027336336206644773, Min w: 0.0\n",
      "Iteration 440, Loss: 0.004660958424210548, Min w: 1.401298464324817e-45\n",
      "Iteration 450, Loss: 0.002543303184211254, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003205149434506893, Min w: 0.0\n",
      "Iteration 470, Loss: 0.003995510283857584, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0029605927411466837, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0030730548314750195, Min w: 0.0\n",
      "Iteration 500, Loss: 0.004135976545512676, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0037561017088592052, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002579884137958288, Min w: 0.0\n",
      "Iteration 530, Loss: 0.003263189923018217, Min w: 0.0\n",
      "Iteration 540, Loss: 0.004914959892630577, Min w: 3.655565867372035e-12\n",
      "Iteration 550, Loss: 0.002668406581506133, Min w: 0.0\n",
      "Iteration 560, Loss: 0.00302675343118608, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0036717928014695644, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002557678148150444, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0030949958600103855, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002447520848363638, Min w: 0.0\n",
      "Iteration 610, Loss: 0.003254928160458803, Min w: 0.0\n",
      "Iteration 620, Loss: 0.005319880787283182, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0027191892731934786, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0032104181591421366, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002891062293201685, Min w: 1.0675587607993888e-26\n",
      "Iteration 660, Loss: 0.0026931462343782187, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002814627718180418, Min w: 0.0\n",
      "Iteration 680, Loss: 0.006614695768803358, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0024388909805566072, Min w: 0.0\n",
      "Iteration 700, Loss: 0.004552151542156935, Min w: 0.0\n",
      "Iteration 710, Loss: 0.005818517412990332, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0026612402871251106, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0025144428946077824, Min w: 0.0\n",
      "Iteration 740, Loss: 0.005364519543945789, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0029326071962714195, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0026118727400898933, Min w: 0.0\n",
      "Iteration 770, Loss: 0.003039246192201972, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0036247780080884695, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0030451358761638403, Min w: 0.0\n",
      "Iteration 800, Loss: 0.002786706667393446, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0025537770707160234, Min w: 0.0\n",
      "Iteration 820, Loss: 0.003399956040084362, Min w: 3.0280930079442103e-30\n",
      "Iteration 830, Loss: 0.003205773886293173, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0029168822802603245, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0044537559151649475, Min w: 1.1420582484247259e-42\n",
      "Iteration 860, Loss: 0.0031642441172152758, Min w: 0.0\n",
      "Iteration 870, Loss: 0.003292842535302043, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0072984094731509686, Min w: 0.0\n",
      "Iteration 890, Loss: 0.003129992401227355, Min w: 0.0\n",
      "Iteration 900, Loss: 0.004085151478648186, Min w: 0.0\n",
      "Iteration 910, Loss: 0.003015725174918771, Min w: 0.0\n",
      "Iteration 920, Loss: 0.003510068403556943, Min w: 0.0\n",
      "Iteration 930, Loss: 0.005402504000812769, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0031718106474727392, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0023979363031685352, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0025966863613575697, Min w: 0.0\n",
      "Iteration 970, Loss: 0.003868438769131899, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0029178967233747244, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0028074102010577917, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.00242594163864851, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0029410910792648792, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0032129220198839903, Min w: 2.841544023433173e-19\n",
      "Iteration 1030, Loss: 0.0030185116920620203, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0026497230865061283, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.005480247084051371, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0029475137125700712, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0024701603688299656, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002527782926335931, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.00456329807639122, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.003062137169763446, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.002651560353115201, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0030606628861278296, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0031141506042331457, Min w: 3.526886267692181e-35\n",
      "Iteration 1140, Loss: 0.0026583364233374596, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.004700010176748037, Min w: 4.436510938052371e-42\n",
      "Iteration 1160, Loss: 0.0026726212818175554, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003257578006014228, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0030219387263059616, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0035886918194592, Min w: 7.575082562898041e-15\n",
      "Iteration 1200, Loss: 0.003811741014942527, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0026989157777279615, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0034233606420457363, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0038077349308878183, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0042609721422195435, Min w: 0.0\n",
      "Iteration 0, Loss: 0.003048849757760763, Min w: 0.0\n",
      "Iteration 10, Loss: 0.006638034246861935, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0026062156539410353, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002422619378194213, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0028469213284552097, Min w: 0.0\n",
      "Iteration 50, Loss: 0.003766442881897092, Min w: 2.744185010738524e-21\n",
      "Iteration 60, Loss: 0.0029234979301691055, Min w: 0.0\n",
      "Iteration 70, Loss: 0.003479018807411194, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0035242363810539246, Min w: 1.299652127883962e-22\n",
      "Iteration 90, Loss: 0.003521066391840577, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0025288655888289213, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0038465692196041346, Min w: 0.0\n",
      "Iteration 120, Loss: 0.005835963413119316, Min w: 0.0\n",
      "Iteration 130, Loss: 0.004110431764274836, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0061857979744672775, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0025900080800056458, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003980730194598436, Min w: 0.0\n",
      "Iteration 170, Loss: 0.004804841708391905, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0027637367602437735, Min w: 0.0\n",
      "Iteration 190, Loss: 0.00361761637032032, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0025226548314094543, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0024488940834999084, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0026003241073340178, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00497854920104146, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002431779634207487, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0028323447331786156, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0030661565251648426, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0030881084967404604, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0024658693000674248, Min w: 0.0\n",
      "Iteration 290, Loss: 0.004334693308919668, Min w: 0.0\n",
      "Iteration 300, Loss: 0.005789655726402998, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003238803008571267, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0024121419992297888, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0029118882957845926, Min w: 0.0\n",
      "Iteration 340, Loss: 0.006164578255265951, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002549398224800825, Min w: 0.0\n",
      "Iteration 360, Loss: 0.003900641342625022, Min w: 0.0\n",
      "Iteration 370, Loss: 0.004542963579297066, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002924536820501089, Min w: 0.0\n",
      "Iteration 390, Loss: 0.003622142830863595, Min w: 0.0\n",
      "Iteration 400, Loss: 0.006997942924499512, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0024367377627640963, Min w: 0.0\n",
      "Iteration 420, Loss: 0.005962568335235119, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003954729996621609, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0027576421853154898, Min w: 0.0\n",
      "Iteration 450, Loss: 0.004542142618447542, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003314029425382614, Min w: 2.252646549045833e-25\n",
      "Iteration 470, Loss: 0.0026432194281369448, Min w: 0.0\n",
      "Iteration 480, Loss: 0.002671791473403573, Min w: 0.0\n",
      "Iteration 490, Loss: 0.002531845588237047, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0030114168766885996, Min w: 6.56970759029404e-41\n",
      "Iteration 510, Loss: 0.003539623226970434, Min w: 0.0\n",
      "Iteration 520, Loss: 0.005743683781474829, Min w: 0.0\n",
      "Iteration 530, Loss: 0.00278471945784986, Min w: 3.22393652050413e-33\n",
      "Iteration 540, Loss: 0.0027010412886738777, Min w: 0.0\n",
      "Iteration 550, Loss: 0.002625480992719531, Min w: 0.0\n",
      "Iteration 560, Loss: 0.002620260464027524, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0031013123225420713, Min w: 0.0\n",
      "Iteration 580, Loss: 0.00589638389647007, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002679622732102871, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0042073167860507965, Min w: 0.0\n",
      "Iteration 610, Loss: 0.006362412590533495, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0029936416540294886, Min w: 0.0\n",
      "Iteration 630, Loss: 0.004756267182528973, Min w: 0.0\n",
      "Iteration 640, Loss: 0.004979505203664303, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002869519405066967, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0031816924456506968, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00318376487120986, Min w: 5.309697644633443e-26\n",
      "Iteration 680, Loss: 0.004161986988037825, Min w: 0.0\n",
      "Iteration 690, Loss: 0.005498897284269333, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0030225059017539024, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0026088799349963665, Min w: 0.0\n",
      "Iteration 720, Loss: 0.002695747185498476, Min w: 0.0\n",
      "Iteration 730, Loss: 0.003305284772068262, Min w: 1.2671604580219111e-37\n",
      "Iteration 740, Loss: 0.0028383214958012104, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002395968185737729, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0036934155505150557, Min w: 0.0\n",
      "Iteration 770, Loss: 0.004741466138511896, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0026191738434135914, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0025011792313307524, Min w: 0.0\n",
      "Iteration 800, Loss: 0.002637590980157256, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0025525314267724752, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0034458909649401903, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002820775378495455, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0028928101528435946, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0065925330854952335, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003188534639775753, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002681165002286434, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0045666866935789585, Min w: 7.278274594883609e-15\n",
      "Iteration 890, Loss: 0.00364207336679101, Min w: 0.0\n",
      "Iteration 900, Loss: 0.003389008343219757, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0026981807313859463, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0035454020835459232, Min w: 9.888021499455957e-31\n",
      "Iteration 930, Loss: 0.0024325347039848566, Min w: 0.0\n",
      "Iteration 940, Loss: 0.004282589070498943, Min w: 0.0\n",
      "Iteration 950, Loss: 0.002561346162110567, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0038781343027949333, Min w: 0.0\n",
      "Iteration 970, Loss: 0.003298360388725996, Min w: 2.9638274258565944e-18\n",
      "Iteration 980, Loss: 0.0026531571056693792, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002422705292701721, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002839971100911498, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0033653262071311474, Min w: 2.144771377556992e-40\n",
      "Iteration 1020, Loss: 0.00527698639780283, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.005704327020794153, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002462524687871337, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0038060431834310293, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0024027028121054173, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0027113803662359715, Min w: 2.8736399581939737e-39\n",
      "Iteration 1080, Loss: 0.0025263901334255934, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.002998644718900323, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.003144637681543827, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.007453599013388157, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0026212099473923445, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.002802629489451647, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.004381746985018253, Min w: 1.8979879749750825e-27\n",
      "Iteration 1150, Loss: 0.0026976685039699078, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.004374494310468435, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0031625719275325537, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0028169574216008186, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0027134071569889784, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.003345381934195757, Min w: 4.561678019921183e-34\n",
      "Iteration 1210, Loss: 0.0029326004441827536, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002761377952992916, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002830851124599576, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0025479095056653023, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002416734816506505, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0027802763506770134, Min w: 0.0\n",
      "Iteration 20, Loss: 0.004485005978494883, Min w: 3.540933080801397e-35\n",
      "Iteration 30, Loss: 0.004160590004175901, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0031013686675578356, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002722041681408882, Min w: 0.0\n",
      "Iteration 60, Loss: 0.003329424886032939, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002564182272180915, Min w: 0.0\n",
      "Iteration 80, Loss: 0.005992666818201542, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0039995224215090275, Min w: 0.0\n",
      "Iteration 100, Loss: 0.003301031421869993, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0024354273919016123, Min w: 0.0\n",
      "Iteration 120, Loss: 0.003307746723294258, Min w: 0.0\n",
      "Iteration 130, Loss: 0.003135574981570244, Min w: 1.6059976902637234e-34\n",
      "Iteration 140, Loss: 0.0027279092464596033, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0028481916524469852, Min w: 9.958327536724313e-41\n",
      "Iteration 160, Loss: 0.002656041644513607, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002644855761900544, Min w: 0.0\n",
      "Iteration 180, Loss: 0.003154064528644085, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0046272799372673035, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0028175825718790293, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0026813086587935686, Min w: 0.0\n",
      "Iteration 220, Loss: 0.004102661274373531, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0032293207477778196, Min w: 1.0069966082683776e-17\n",
      "Iteration 240, Loss: 0.0058489772491157055, Min w: 0.0\n",
      "Iteration 250, Loss: 0.004615041892975569, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0027544277254492044, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0027627607341855764, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002647670917212963, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0041181487031280994, Min w: 0.0\n",
      "Iteration 300, Loss: 0.004860023036599159, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0026687837671488523, Min w: 0.0\n",
      "Iteration 320, Loss: 0.003803274594247341, Min w: 1.547898250464641e-06\n",
      "Iteration 330, Loss: 0.00394053990021348, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002834030892699957, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002814378822222352, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0026246164925396442, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002773116808384657, Min w: 0.0\n",
      "Iteration 380, Loss: 0.003059366485103965, Min w: 0.0\n",
      "Iteration 390, Loss: 0.003816641168668866, Min w: 0.0\n",
      "Iteration 400, Loss: 0.003035719972103834, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003079137299209833, Min w: 0.0\n",
      "Iteration 420, Loss: 0.00254727341234684, Min w: 0.0\n",
      "Iteration 430, Loss: 0.004690255969762802, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0031971747521311045, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0026966084260493517, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0028808889910578728, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0024882329162210226, Min w: 0.0\n",
      "Iteration 480, Loss: 0.005542439874261618, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0025232622865587473, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0025258243549615145, Min w: 0.0\n",
      "Iteration 510, Loss: 0.003394505474716425, Min w: 2.284922533704632e-30\n",
      "Iteration 520, Loss: 0.005753248929977417, Min w: 0.0\n",
      "Iteration 530, Loss: 0.00522582745179534, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002458103932440281, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0026552709750831127, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0033976458944380283, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0030059318523854017, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0031532873399555683, Min w: 9.620460294848626e-32\n",
      "Iteration 590, Loss: 0.002555771032348275, Min w: 0.0\n",
      "Iteration 600, Loss: 0.00479635177180171, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0024526785127818584, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0025099432095885277, Min w: 0.0\n",
      "Iteration 630, Loss: 0.004041193053126335, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0026826218236237764, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002402244135737419, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002558542648330331, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0032666297629475594, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002949407557025552, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0030093109235167503, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0026846800465136766, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003881283337250352, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0038388606626540422, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0027845215518027544, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0038323230110108852, Min w: 4.40231806564384e-09\n",
      "Iteration 750, Loss: 0.0035063601098954678, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0024244303349405527, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0025795134715735912, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0026118988171219826, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0030235538724809885, Min w: 0.0\n",
      "Iteration 800, Loss: 0.00298900855705142, Min w: 0.0\n",
      "Iteration 810, Loss: 0.003019653493538499, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0026066128630191088, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0032570455223321915, Min w: 0.0\n",
      "Iteration 840, Loss: 0.005407150834798813, Min w: 0.0\n",
      "Iteration 850, Loss: 0.005717938300222158, Min w: 0.0\n",
      "Iteration 860, Loss: 0.002943377010524273, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002669181674718857, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0027611921541392803, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0025002015754580498, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0026453984901309013, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0024856021627783775, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0030539915896952152, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0037962975911796093, Min w: 0.0\n",
      "Iteration 940, Loss: 0.003195504192262888, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0027129328809678555, Min w: 0.0\n",
      "Iteration 960, Loss: 0.00346894608810544, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0028895954601466656, Min w: 0.0\n",
      "Iteration 980, Loss: 0.003243378596380353, Min w: 6.5955101385308465e-18\n",
      "Iteration 990, Loss: 0.003091292455792427, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.004771113861352205, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0026917345821857452, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.002498126355931163, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.004118565935641527, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002771865576505661, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.003543082857504487, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002599959960207343, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0025474235881119967, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.003124797949567437, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.003207666100934148, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0030161747708916664, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0028832629323005676, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0034768725745379925, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.002399445977061987, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002761251525953412, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.005269769113510847, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0024054779205471277, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.004241046030074358, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0026699977461248636, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.006205069832503796, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002719129901379347, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0032704086042940617, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.003573269583284855, Min w: 1.566486127739463e-27\n",
      "Iteration 1230, Loss: 0.0026530080940574408, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0024103778414428234, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0027087267953902483, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0026027527637779713, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002998625859618187, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0037517910823225975, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0028834776021540165, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002394241513684392, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0028232112526893616, Min w: 1.0762738114052553e-31\n",
      "Iteration 70, Loss: 0.0034683411940932274, Min w: 0.0\n",
      "Iteration 80, Loss: 0.002436579205095768, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0026185649912804365, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002790197031572461, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0035569509491324425, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0027112674433737993, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0025908255483955145, Min w: 0.0\n",
      "Iteration 140, Loss: 0.003218607045710087, Min w: 1.7095841264762768e-43\n",
      "Iteration 150, Loss: 0.0026687539648264647, Min w: 0.0\n",
      "Iteration 160, Loss: 0.00245128502137959, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0030450366903096437, Min w: 1.4741095374889302e-22\n",
      "Iteration 180, Loss: 0.0026375793386250734, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002894484670832753, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002728818915784359, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00267046969383955, Min w: 8.407790785948902e-45\n",
      "Iteration 220, Loss: 0.002769118407741189, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002721788128837943, Min w: 0.0\n",
      "Iteration 240, Loss: 0.003006050130352378, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0026904214173555374, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0026861780788749456, Min w: 0.0\n",
      "Iteration 270, Loss: 0.003038868773728609, Min w: 0.0\n",
      "Iteration 280, Loss: 0.006137569900602102, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0024876983370631933, Min w: 0.0\n",
      "Iteration 300, Loss: 0.003268953412771225, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002907671732828021, Min w: 0.0\n",
      "Iteration 320, Loss: 0.005140020977705717, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0025713222566992044, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002952679991722107, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0024761089589446783, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0025277072563767433, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002576880855485797, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002340154256671667, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0026773277204483747, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002497706562280655, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0031009402591735125, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0027264750096946955, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002711182925850153, Min w: 0.0\n",
      "Iteration 440, Loss: 0.00258793612010777, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0031288787722587585, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002729346975684166, Min w: 0.0\n",
      "Iteration 470, Loss: 0.002345530316233635, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0026485472917556763, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0034584798850119114, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0024199087638407946, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002622434636577964, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002843850292265415, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0031794870737940073, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0028044646605849266, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0028544410597532988, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026057958602905273, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002814436098560691, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0027085489127784967, Min w: 0.0\n",
      "Iteration 590, Loss: 0.00297738378867507, Min w: 0.0\n",
      "Iteration 600, Loss: 0.003665320575237274, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0025282977148890495, Min w: 0.0\n",
      "Iteration 620, Loss: 0.003731783712282777, Min w: 0.0\n",
      "Iteration 630, Loss: 0.003879786003381014, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0026939348317682743, Min w: 0.0\n",
      "Iteration 650, Loss: 0.004933546297252178, Min w: 5.829086977230462e-28\n",
      "Iteration 660, Loss: 0.0026958645321428776, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002955257659777999, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002796491142362356, Min w: 0.0\n",
      "Iteration 690, Loss: 0.003411484882235527, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003176366677507758, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003262919606640935, Min w: 0.0\n",
      "Iteration 720, Loss: 0.00273442012257874, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0036308516282588243, Min w: 2.606030068569603e-31\n",
      "Iteration 740, Loss: 0.0024531453382223845, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0024649992119520903, Min w: 0.0\n",
      "Iteration 760, Loss: 0.003228103742003441, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0025215018540620804, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0029814555309712887, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0023663926403969526, Min w: 0.0\n",
      "Iteration 800, Loss: 0.002680594567209482, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002419379772618413, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002703477395698428, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0032497206702828407, Min w: 2.364288009630908e-31\n",
      "Iteration 840, Loss: 0.005390941631048918, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002422442426905036, Min w: 0.0\n",
      "Iteration 860, Loss: 0.00304623250849545, Min w: 0.0\n",
      "Iteration 870, Loss: 0.003409253666177392, Min w: 2.5346988353269483e-26\n",
      "Iteration 880, Loss: 0.002919559832662344, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002435289788991213, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002828126074746251, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0054311323910951614, Min w: 0.0\n",
      "Iteration 920, Loss: 0.005107130855321884, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0026904940605163574, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002604616340249777, Min w: 0.0\n",
      "Iteration 950, Loss: 0.003245178610086441, Min w: 0.0\n",
      "Iteration 960, Loss: 0.00289159151725471, Min w: 0.0\n",
      "Iteration 970, Loss: 0.003449302865192294, Min w: 2.4155167436900263e-28\n",
      "Iteration 980, Loss: 0.0031477808952331543, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0038799848407506943, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0026801256462931633, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.003277798881754279, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.003056214191019535, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0026545668952167034, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0026085367426276207, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0026243221946060658, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002609784482046962, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0029735644347965717, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.003054823726415634, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.003051742212846875, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002824778901413083, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.00362831586971879, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.002607408445328474, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0029997911769896746, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002491173567250371, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002601379994302988, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0032397806644439697, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003007153980433941, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002728999126702547, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0027812712360173464, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002849500859156251, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.005097854416817427, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0025071422569453716, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0037101004272699356, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0028687005396932364, Min w: 1.328033535935444e-37\n",
      "Iteration 0, Loss: 0.003909653518348932, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031583597883582115, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0027792162727564573, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0038567606825381517, Min w: 1.8257405587810896e-38\n",
      "Iteration 40, Loss: 0.002783148782327771, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00289718434214592, Min w: 0.0\n",
      "Iteration 60, Loss: 0.004682715982198715, Min w: 4.405695761959842e-16\n",
      "Iteration 70, Loss: 0.0032477369531989098, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0026986347511410713, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0024037540424615145, Min w: 0.0\n",
      "Iteration 100, Loss: 0.00260548060759902, Min w: 0.0\n",
      "Iteration 110, Loss: 0.003913331776857376, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002500055357813835, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0027001467533409595, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0033821112010627985, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0025526888202875853, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002810695441439748, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002680968027561903, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002476651221513748, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0032718568108975887, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0024958625435829163, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0027876582462340593, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002892319578677416, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0027020378038287163, Min w: 0.0\n",
      "Iteration 240, Loss: 0.003369811922311783, Min w: 3.83244122743355e-15\n",
      "Iteration 250, Loss: 0.005483606364578009, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0025165549013763666, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0033386400900781155, Min w: 0.0\n",
      "Iteration 280, Loss: 0.004571165889501572, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002626255387440324, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0024741056840866804, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0030673062428832054, Min w: 0.0\n",
      "Iteration 320, Loss: 0.006426159758120775, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0027960471343249083, Min w: 0.0\n",
      "Iteration 340, Loss: 0.004503859672695398, Min w: 0.0\n",
      "Iteration 350, Loss: 0.004932337906211615, Min w: 0.0\n",
      "Iteration 360, Loss: 0.003011374268680811, Min w: 0.0\n",
      "Iteration 370, Loss: 0.005138409323990345, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0026672868989408016, Min w: 0.0\n",
      "Iteration 390, Loss: 0.004408677574247122, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0033862022683024406, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0024635230656713247, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002564354334026575, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0029000244103372097, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0049462090246379375, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0031596776098012924, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0024891747161746025, Min w: 0.0\n",
      "Iteration 470, Loss: 0.004092961084097624, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0024120749440044165, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0026551010087132454, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003266287734732032, Min w: 4.068921823156635e-29\n",
      "Iteration 510, Loss: 0.0025485956575721502, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0031351458746939898, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0027285395190119743, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0028968174010515213, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0029633089434355497, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0031370206270366907, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0032581265550106764, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002418709686025977, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0037353045772761106, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0025193640030920506, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0025379681028425694, Min w: 0.0\n",
      "Iteration 620, Loss: 0.005041554570198059, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0035579921677708626, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0024509369395673275, Min w: 0.0\n",
      "Iteration 650, Loss: 0.00259911990724504, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0027165545616298914, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002639142330735922, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0024916452821344137, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0028023237828165293, Min w: 0.0\n",
      "Iteration 700, Loss: 0.005008528474718332, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002400386845692992, Min w: 0.0\n",
      "Iteration 720, Loss: 0.002703762846067548, Min w: 0.0\n",
      "Iteration 730, Loss: 0.003875071182847023, Min w: 0.0\n",
      "Iteration 740, Loss: 0.002487159799784422, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002676591742783785, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002777303569018841, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0029479938093572855, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0026710648089647293, Min w: 0.0\n",
      "Iteration 790, Loss: 0.003628631355240941, Min w: 0.0\n",
      "Iteration 800, Loss: 0.004337141755968332, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002520147245377302, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0025070118717849255, Min w: 0.0\n",
      "Iteration 830, Loss: 0.003181253792718053, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0027779899537563324, Min w: 0.0\n",
      "Iteration 850, Loss: 0.00245285895653069, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0031268226448446512, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0024906776379793882, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0037771398201584816, Min w: 0.0\n",
      "Iteration 890, Loss: 0.003695540828630328, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0024951340164989233, Min w: 0.0\n",
      "Iteration 910, Loss: 0.003179929219186306, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0037067525554448366, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0026953835040330887, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0024633845314383507, Min w: 0.0\n",
      "Iteration 950, Loss: 0.003181223524734378, Min w: 0.0\n",
      "Iteration 960, Loss: 0.00440747756510973, Min w: 0.0\n",
      "Iteration 970, Loss: 0.006614355836063623, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0035077843349426985, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0025385452900081873, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.00281078414991498, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0038150050677359104, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0025881389155983925, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.003570446977391839, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0024007910396903753, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002799887442961335, Min w: 8.357236062778742e-36\n",
      "Iteration 1060, Loss: 0.003521809820085764, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0031128269620239735, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002428472740575671, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.004981997422873974, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0030542132444679737, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.002905069850385189, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0040375664830207825, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.002540025394409895, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0028621982783079147, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.003949964884668589, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.003356673289090395, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0026341662742197514, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0025261230766773224, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0027628152165561914, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0034829501528292894, Min w: 1.2065076007167552e-28\n",
      "Iteration 1210, Loss: 0.004633492324501276, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0026471500750631094, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0030942498706281185, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002812920603901148, Min w: 1.065172504933384e-38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  38%|███▊      | 9/24 [06:46<11:35, 46.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.70911146482622, 'L2_avg': 0.7329268747508225, 'End_point_L1_avg': 0.7156457770109351, 'End_point_L2_avg': 0.79070087433116}\n",
      "Iteration 0, Loss: 0.0042107985354959965, Min w: 1.0760879376903176e-05\n",
      "Iteration 10, Loss: 0.0025170876178890467, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0026382063515484333, Min w: 1.91410070016218e-08\n",
      "Iteration 30, Loss: 0.0023797403555363417, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0023852449376136065, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0023636333644390106, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0035835716407746077, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0023812695872038603, Min w: 0.0\n",
      "Iteration 80, Loss: 0.002475908026099205, Min w: 0.0\n",
      "Iteration 90, Loss: 0.00262033985927701, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0030109635554254055, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0027325989212840796, Min w: 1.229040116842639e-31\n",
      "Iteration 120, Loss: 0.0031376320403069258, Min w: 1.401298464324817e-44\n",
      "Iteration 130, Loss: 0.002417519921436906, Min w: 8.407790785948902e-45\n",
      "Iteration 140, Loss: 0.0024781376123428345, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002400129335001111, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002438706113025546, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0038119631353765726, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0026102059055119753, Min w: 0.0\n",
      "Iteration 190, Loss: 0.003058685688301921, Min w: 2.7887669387313685e-13\n",
      "Iteration 200, Loss: 0.0024282715748995543, Min w: 0.0\n",
      "Iteration 210, Loss: 0.002687915926799178, Min w: 0.0\n",
      "Iteration 220, Loss: 0.003016890725120902, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0027428483590483665, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002592418808490038, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002784420968964696, Min w: 0.0\n",
      "Iteration 260, Loss: 0.003285285085439682, Min w: 3.957910344243369e-32\n",
      "Iteration 270, Loss: 0.0030044245067983866, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002846262650564313, Min w: 0.0\n",
      "Iteration 290, Loss: 0.006454482674598694, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0026653853710740805, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0026458578649908304, Min w: 0.0\n",
      "Iteration 320, Loss: 0.002548241289332509, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0027517490088939667, Min w: 0.0\n",
      "Iteration 340, Loss: 0.004521805327385664, Min w: 1.7732507209044106e-39\n",
      "Iteration 350, Loss: 0.0027248987462371588, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0025604860857129097, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0025899691972881556, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0038074064068496227, Min w: 0.0\n",
      "Iteration 390, Loss: 0.004584568087011576, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0033709558192640543, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0028092493303120136, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0030229727271944284, Min w: 0.0\n",
      "Iteration 430, Loss: 0.00409981282427907, Min w: 0.0\n",
      "Iteration 440, Loss: 0.005324997007846832, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0033098466228693724, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002682531252503395, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0024561577010899782, Min w: 0.0\n",
      "Iteration 480, Loss: 0.004916020203381777, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0038528735749423504, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0026853084564208984, Min w: 2.8015879937553203e-40\n",
      "Iteration 510, Loss: 0.004513798747211695, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002703206380829215, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0029746834188699722, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0030923360027372837, Min w: 0.0\n",
      "Iteration 550, Loss: 0.004739114083349705, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026181726716458797, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002955155912786722, Min w: 0.0\n",
      "Iteration 580, Loss: 0.00334495329298079, Min w: 0.0\n",
      "Iteration 590, Loss: 0.003367579309269786, Min w: 0.0\n",
      "Iteration 600, Loss: 0.004874513018876314, Min w: 0.0\n",
      "Iteration 610, Loss: 0.004253066144883633, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0031738453544676304, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0031042066402733326, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0025457784067839384, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002675597323104739, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0037715951912105083, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0037424066103994846, Min w: 0.0\n",
      "Iteration 680, Loss: 0.004200384486466646, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0026499521918594837, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0033647404052317142, Min w: 0.0\n",
      "Iteration 710, Loss: 0.006874520797282457, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0025780964642763138, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0031591961160302162, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0027226596139371395, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0024732688907533884, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0033790450543165207, Min w: 6.006139040701927e-22\n",
      "Iteration 770, Loss: 0.0028290944173932076, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002692518522962928, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002856162842363119, Min w: 0.0\n",
      "Iteration 800, Loss: 0.005636407062411308, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0027061086148023605, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002639628015458584, Min w: 4.189882408331203e-43\n",
      "Iteration 830, Loss: 0.0027996257413178682, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0026952913030982018, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0027369034942239523, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0047996086068451405, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0035202668514102697, Min w: 0.0\n",
      "Iteration 880, Loss: 0.002642163308337331, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0032016863115131855, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0029551826883107424, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0026317648589611053, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0024562589824199677, Min w: 0.0\n",
      "Iteration 930, Loss: 0.002410554327070713, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002927955240011215, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0036555964034050703, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0030506851617246866, Min w: 4.1025433000341254e-35\n",
      "Iteration 970, Loss: 0.002462756587192416, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002615247154608369, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002517153974622488, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002504700794816017, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002742056269198656, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0031090639531612396, Min w: 1.6051513861924727e-28\n",
      "Iteration 1030, Loss: 0.0038208269979804754, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0029405143577605486, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002835286082699895, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.00332292215898633, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0029490452725440264, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.002850533463060856, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0025895526632666588, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.004614236764609814, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0031985798850655556, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0027675675228238106, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.005140069872140884, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002664936939254403, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002992786467075348, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.004438404925167561, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002987791085615754, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.003301189746707678, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0027520707808434963, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.003922427073121071, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0028944076038897038, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002741585485637188, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0066229491494596004, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002996023278683424, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002427170053124428, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031809755600988865, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0026035583578050137, Min w: 0.0\n",
      "Iteration 30, Loss: 0.006592745892703533, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0023980478290468454, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0036409185267984867, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0030483249574899673, Min w: 1.7100232373630577e-37\n",
      "Iteration 70, Loss: 0.0027818302623927593, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0028651668690145016, Min w: 3.14171115701624e-42\n",
      "Iteration 90, Loss: 0.004016835242509842, Min w: 0.0\n",
      "Iteration 100, Loss: 0.002643184270709753, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0027063454035669565, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0038453012239187956, Min w: 8.665069183998939e-41\n",
      "Iteration 130, Loss: 0.004180519375950098, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002610334660857916, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00260753626935184, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002690870314836502, Min w: 0.0\n",
      "Iteration 170, Loss: 0.003163002897053957, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0024428172037005424, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0026890530716627836, Min w: 0.0\n",
      "Iteration 200, Loss: 0.004191211424767971, Min w: 0.0\n",
      "Iteration 210, Loss: 0.002535475417971611, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002479374874383211, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0028398223221302032, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0027900191489607096, Min w: 4.0013100364861095e-33\n",
      "Iteration 250, Loss: 0.0025814310647547245, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0027415005024522543, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0030338424257934093, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0030753305181860924, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0028645959682762623, Min w: 2.0134548087212137e-30\n",
      "Iteration 300, Loss: 0.0027582708280533552, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002416444243863225, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0026067798025906086, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0031507660169154406, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0031182577367872, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0029273636173456907, Min w: 0.0\n",
      "Iteration 360, Loss: 0.005615775007754564, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0058084167540073395, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0034411451779305935, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002411650260910392, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0033030719496309757, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003102815942838788, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002987705171108246, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0046949503012001514, Min w: 0.0\n",
      "Iteration 440, Loss: 0.005441386718302965, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0032748726662248373, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003946720622479916, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0038925763219594955, Min w: 0.0\n",
      "Iteration 480, Loss: 0.003407412674278021, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0025355869438499212, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003649862250313163, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002500418107956648, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0025926646776497364, Min w: 0.0\n",
      "Iteration 530, Loss: 0.005495013203471899, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002467954298481345, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0027143193874508142, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0030456206295639277, Min w: 6.644396798442553e-41\n",
      "Iteration 570, Loss: 0.00394830759614706, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0029820234049111605, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0033701283391565084, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0036859416868537664, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0028727527242153883, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0031024126801639795, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0028562070801854134, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0024899558629840612, Min w: 0.0\n",
      "Iteration 650, Loss: 0.004390890710055828, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002780250972136855, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0025057406164705753, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0037105553783476353, Min w: 0.0\n",
      "Iteration 690, Loss: 0.005281864665448666, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003692097496241331, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003300438402220607, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0026098687667399645, Min w: 0.0\n",
      "Iteration 730, Loss: 0.00462233554571867, Min w: 8.547920632381384e-44\n",
      "Iteration 740, Loss: 0.0027001462876796722, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0025404966436326504, Min w: 0.0\n",
      "Iteration 760, Loss: 0.003076367313042283, Min w: 0.0\n",
      "Iteration 770, Loss: 0.004441188182681799, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0032632341608405113, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0026242274325340986, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0026277443394064903, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002890849020332098, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0031731189228594303, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002731871558353305, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0031738595571368933, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0031949803233146667, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003124997252598405, Min w: 0.0\n",
      "Iteration 870, Loss: 0.005119560286402702, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0029721411410719156, Min w: 4.386941611190915e-33\n",
      "Iteration 890, Loss: 0.002609171438962221, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0033640102483332157, Min w: 0.0\n",
      "Iteration 910, Loss: 0.002948520239442587, Min w: 0.0\n",
      "Iteration 920, Loss: 0.005834085401147604, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0036274329759180546, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0028926697559654713, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0040694335475564, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002363775856792927, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0026592181529849768, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002607450122013688, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0025075674057006836, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002534223021939397, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002439371543005109, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0025552131701260805, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0024575451388955116, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0044381339102983475, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0025271675549447536, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0031782041769474745, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0032049750443547964, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0029312786646187305, Min w: 1.6288991097209373e-36\n",
      "Iteration 1090, Loss: 0.0035507006105035543, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002833097241818905, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0034520153421908617, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0057115936651825905, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0024815041106194258, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0031334671657532454, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002705143066123128, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0050754244439303875, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0031157631892710924, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002800938906148076, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.005569232627749443, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0028453355189412832, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0026923443656414747, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0027081393636763096, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0025745094753801823, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0037157253827899694, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002460025018081069, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0024345621932297945, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002936224453151226, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0034553103614598513, Min w: 3.7673479161435724e-28\n",
      "Iteration 40, Loss: 0.002651265589520335, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0026312845293432474, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0035889220889657736, Min w: 2.5160574996815066e-19\n",
      "Iteration 70, Loss: 0.0029317326843738556, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0034288254100829363, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0032160761766135693, Min w: 0.0\n",
      "Iteration 100, Loss: 0.004324914421886206, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0025355012621730566, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0027720159851014614, Min w: 0.0\n",
      "Iteration 130, Loss: 0.004038013983517885, Min w: 8.323712878089413e-43\n",
      "Iteration 140, Loss: 0.003002805169671774, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00267228577286005, Min w: 0.0\n",
      "Iteration 160, Loss: 0.004316544625908136, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0026860791258513927, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0029195339884608984, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0027769762091338634, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0032283319160342216, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0024304238613694906, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0032194124069064856, Min w: 0.0\n",
      "Iteration 230, Loss: 0.003880716860294342, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0034729859326034784, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002567606745287776, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0028289975598454475, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00307632377371192, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002698588417842984, Min w: 0.0\n",
      "Iteration 290, Loss: 0.005031737498939037, Min w: 1.0411719888663122e-17\n",
      "Iteration 300, Loss: 0.0032882788218557835, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003607500344514847, Min w: 0.0\n",
      "Iteration 320, Loss: 0.004861755762249231, Min w: 0.0\n",
      "Iteration 330, Loss: 0.003405814990401268, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0029832927975803614, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0026839543133974075, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0026750050019472837, Min w: 1.301490981203282e-39\n",
      "Iteration 370, Loss: 0.0025316241662949324, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0030064345337450504, Min w: 0.0\n",
      "Iteration 390, Loss: 0.003335790242999792, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002571609802544117, Min w: 0.0\n",
      "Iteration 410, Loss: 0.004135624039918184, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0032476638443768024, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0025447625666856766, Min w: 0.0\n",
      "Iteration 440, Loss: 0.004917833022773266, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0036108503118157387, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003764249850064516, Min w: 0.0\n",
      "Iteration 470, Loss: 0.006316218990832567, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0038105612620711327, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0030959192663431168, Min w: 0.0\n",
      "Iteration 500, Loss: 0.002582316752523184, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0066592395305633545, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0025590977165848017, Min w: 0.0\n",
      "Iteration 530, Loss: 0.002648027380928397, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0038409798871725798, Min w: 0.0\n",
      "Iteration 550, Loss: 0.002463879995048046, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0030231198761612177, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0032837693579494953, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0028570068534463644, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0026252444367855787, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002765520941466093, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0024891558568924665, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0057876622304320335, Min w: 0.0\n",
      "Iteration 630, Loss: 0.005674709100276232, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0031518733594566584, Min w: 0.0\n",
      "Iteration 650, Loss: 0.00513419508934021, Min w: 1.2667164404062902e-21\n",
      "Iteration 660, Loss: 0.002682432532310486, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002749609062448144, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0032326076179742813, Min w: 6.804529850867872e-35\n",
      "Iteration 690, Loss: 0.004103018436580896, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0034293681383132935, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0026650610379874706, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004911364521831274, Min w: 3.1169677686187814e-36\n",
      "Iteration 730, Loss: 0.0025992593728005886, Min w: 0.0\n",
      "Iteration 740, Loss: 0.002481323666870594, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0025839984882622957, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0031419850420206785, Min w: 7.430707960501178e-26\n",
      "Iteration 770, Loss: 0.00370477931573987, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0024622527416795492, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002918897196650505, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0031181632075458765, Min w: 0.0\n",
      "Iteration 810, Loss: 0.003035855945199728, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0024157834704965353, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002608725568279624, Min w: 0.0\n",
      "Iteration 840, Loss: 0.007063174154609442, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0024392702616751194, Min w: 0.0\n",
      "Iteration 860, Loss: 0.004871681798249483, Min w: 0.0\n",
      "Iteration 870, Loss: 0.004228473640978336, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0029695965349674225, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0026570253539830446, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002511628670617938, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0025344244204461575, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002567680785432458, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0030673134606331587, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0038105505518615246, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0028998060151934624, Min w: 3.569607532094717e-33\n",
      "Iteration 960, Loss: 0.00367628107778728, Min w: 0.0\n",
      "Iteration 970, Loss: 0.004345808643847704, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0024353829212486744, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002591727301478386, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.004535488784313202, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.003510665614157915, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.004473402164876461, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0028312522917985916, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.007919281721115112, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002629751805216074, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002637076424434781, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0027129459194839, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0024747485294938087, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.00264666392467916, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.003260048571974039, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0074669974856078625, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.003405806375667453, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0024825367145240307, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0034317271783947945, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.005132452119141817, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0025752619840204716, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.005158922169357538, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0026908048894256353, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0024550913367420435, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0026645795442163944, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.004581619054079056, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.003618009388446808, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.00366342649795115, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0026084682904183865, Min w: 0.0\n",
      "Iteration 0, Loss: 0.004901473876088858, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0033698873594403267, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0035010899882763624, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0048517766408622265, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0025520205963402987, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0029086261056363583, Min w: 0.0\n",
      "Iteration 60, Loss: 0.004118647426366806, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0025905477814376354, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0024842540733516216, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0025745125021785498, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0036281461361795664, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002504354575648904, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0029867789708077908, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0041825855150818825, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002472121501341462, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002511773956939578, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0028426756616681814, Min w: 0.0\n",
      "Iteration 170, Loss: 0.003362551098689437, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0035630196798592806, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002768450416624546, Min w: 0.0\n",
      "Iteration 200, Loss: 0.004866988398134708, Min w: 0.0\n",
      "Iteration 210, Loss: 0.006112170405685902, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002563407411798835, Min w: 0.0\n",
      "Iteration 230, Loss: 0.008060772903263569, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0025014199782162905, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0034983179066330194, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0032770077232271433, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0032322483602911234, Min w: 4.612708805658109e-39\n",
      "Iteration 280, Loss: 0.0024385934229940176, Min w: 0.0\n",
      "Iteration 290, Loss: 0.004127495922148228, Min w: 0.0\n",
      "Iteration 300, Loss: 0.002731460379436612, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0023987512104213238, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0026941397227346897, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0033506015315651894, Min w: 2.5695914915525963e-18\n",
      "Iteration 340, Loss: 0.004447559826076031, Min w: 0.0\n",
      "Iteration 350, Loss: 0.005697304382920265, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002474955515936017, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0035958481021225452, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0033168301451951265, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002809520112350583, Min w: 4.390268088729652e-42\n",
      "Iteration 400, Loss: 0.0025589964352548122, Min w: 0.0\n",
      "Iteration 410, Loss: 0.004075601696968079, Min w: 0.0\n",
      "Iteration 420, Loss: 0.003266909858211875, Min w: 4.478578557536845e-30\n",
      "Iteration 430, Loss: 0.0027519476134330034, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0026871557347476482, Min w: 0.0\n",
      "Iteration 450, Loss: 0.003951659891754389, Min w: 1.1278933342850905e-08\n",
      "Iteration 460, Loss: 0.004097545053809881, Min w: 8.127531093083939e-44\n",
      "Iteration 470, Loss: 0.0024192112032324076, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0023651544470340014, Min w: 0.0\n",
      "Iteration 490, Loss: 0.002679921220988035, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0025812676176428795, Min w: 0.0\n",
      "Iteration 510, Loss: 0.003087261924520135, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0029674379620701075, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0029607219621539116, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002622670726850629, Min w: 0.0\n",
      "Iteration 550, Loss: 0.003407585434615612, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0029594385996460915, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002462005475535989, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0025503512006253004, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002680625068023801, Min w: 0.0\n",
      "Iteration 600, Loss: 0.004417387302964926, Min w: 0.0\n",
      "Iteration 610, Loss: 0.004366354085505009, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0030384878627955914, Min w: 0.0\n",
      "Iteration 630, Loss: 0.006950513459742069, Min w: 0.0\n",
      "Iteration 640, Loss: 0.002518921857699752, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0029439928475767374, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002946029417216778, Min w: 0.0\n",
      "Iteration 670, Loss: 0.007837411016225815, Min w: 0.0\n",
      "Iteration 680, Loss: 0.00271278596483171, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002595513826236129, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0028867328073829412, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003057160647585988, Min w: 0.0\n",
      "Iteration 720, Loss: 0.00631675822660327, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0026770306285470724, Min w: 0.0\n",
      "Iteration 740, Loss: 0.00384895084425807, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0034033700358122587, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002719904761761427, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0024185683578252792, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0037369905039668083, Min w: 0.0\n",
      "Iteration 790, Loss: 0.003327585058286786, Min w: 7.919478075577405e-21\n",
      "Iteration 800, Loss: 0.0037052002735435963, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0027057479601353407, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002437531016767025, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0030669402331113815, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0025838050059974194, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0030777729116380215, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0034489035606384277, Min w: 8.859350737480845e-21\n",
      "Iteration 870, Loss: 0.0035393740981817245, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0030881897546350956, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002820430789142847, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002431639702990651, Min w: 0.0\n",
      "Iteration 910, Loss: 0.00284403283149004, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0030723840463906527, Min w: 0.0\n",
      "Iteration 930, Loss: 0.003186664544045925, Min w: 0.0\n",
      "Iteration 940, Loss: 0.00269088102504611, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00275024282746017, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002450961619615555, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0037926044315099716, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0025589470751583576, Min w: 0.0\n",
      "Iteration 990, Loss: 0.004045955371111631, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0031131068244576454, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0030314396135509014, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.00344461714848876, Min w: 8.83522205050169e-13\n",
      "Iteration 1030, Loss: 0.002808990189805627, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002651526825502515, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0025548269040882587, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002506207674741745, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0027292086742818356, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.003205277258530259, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0031853914260864258, Min w: 8.98678986618943e-21\n",
      "Iteration 1100, Loss: 0.002855895785614848, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0027715137694031, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.002980222227051854, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0026978962123394012, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0032610404305160046, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002797056920826435, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0026702762115746737, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.005004745442420244, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0029141027480363846, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0029266963247209787, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0030735451728105545, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0032512040343135595, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0028007477521896362, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0049454462714493275, Min w: 3.6334368765894505e-25\n",
      "Iteration 1240, Loss: 0.0034811152145266533, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0028463054914027452, Min w: 0.0\n",
      "Iteration 10, Loss: 0.003431301796808839, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0035317717120051384, Min w: 2.194593367840578e-20\n",
      "Iteration 30, Loss: 0.004380404017865658, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0059465267695486546, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0026186120230704546, Min w: 0.0\n",
      "Iteration 60, Loss: 0.003965502139180899, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002735166810452938, Min w: 0.0\n",
      "Iteration 80, Loss: 0.003389425575733185, Min w: 0.0\n",
      "Iteration 90, Loss: 0.003226368920877576, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0026330112013965845, Min w: 0.0\n",
      "Iteration 110, Loss: 0.005453174002468586, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0026182597503066063, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002872452139854431, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0027069540228694677, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0026362575590610504, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003132506273686886, Min w: 0.0\n",
      "Iteration 170, Loss: 0.006968626286834478, Min w: 0.0\n",
      "Iteration 180, Loss: 0.003955901600420475, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0030899832490831614, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0036220767069607973, Min w: 1.9089695373498278e-13\n",
      "Iteration 210, Loss: 0.002815650077536702, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0028172293677926064, Min w: 0.0\n",
      "Iteration 230, Loss: 0.006091520190238953, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0026361676864326, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0026562216226011515, Min w: 0.0\n",
      "Iteration 260, Loss: 0.003105510724708438, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002823535120114684, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002438932191580534, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002641532337293029, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0026057008653879166, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0024089650250971317, Min w: 0.0\n",
      "Iteration 320, Loss: 0.003693382488563657, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0026346403174102306, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0024886673782020807, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002588758710771799, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0036551563534885645, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002964177168905735, Min w: 0.0\n",
      "Iteration 380, Loss: 0.00241162721067667, Min w: 0.0\n",
      "Iteration 390, Loss: 0.004307571332901716, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002884565619751811, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0024817606899887323, Min w: 0.0\n",
      "Iteration 420, Loss: 0.004683904815465212, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0026894058100879192, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0034394164104014635, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00552143482491374, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0029833964072167873, Min w: 0.0\n",
      "Iteration 470, Loss: 0.00497090769931674, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0028615756891667843, Min w: 2.7064332728529973e-31\n",
      "Iteration 490, Loss: 0.005868974607437849, Min w: 0.0\n",
      "Iteration 500, Loss: 0.00274216802790761, Min w: 0.0\n",
      "Iteration 510, Loss: 0.004514285363256931, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0029910511802881956, Min w: 0.0\n",
      "Iteration 530, Loss: 0.004422633443027735, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0027248230762779713, Min w: 0.0\n",
      "Iteration 550, Loss: 0.00415012426674366, Min w: 0.0\n",
      "Iteration 560, Loss: 0.002399088116362691, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0026821582578122616, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002924512140452862, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0030731260776519775, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0031262990087270737, Min w: 0.0\n",
      "Iteration 610, Loss: 0.004660630598664284, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0024283165112137794, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0025042330380529165, Min w: 0.0\n",
      "Iteration 640, Loss: 0.002955885836854577, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0029988931491971016, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0024861041456460953, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002541813999414444, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0031285330187529325, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00295321736484766, Min w: 0.0\n",
      "Iteration 700, Loss: 0.005923647899180651, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002468205988407135, Min w: 0.0\n",
      "Iteration 720, Loss: 0.003545778803527355, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0032973664347082376, Min w: 0.0\n",
      "Iteration 740, Loss: 0.003042206633836031, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0024192980490624905, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0029654987156391144, Min w: 0.0\n",
      "Iteration 770, Loss: 0.00744556775316596, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0025122095830738544, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0030118683353066444, Min w: 0.0\n",
      "Iteration 800, Loss: 0.00239762756973505, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0037827345076948404, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0035195443779230118, Min w: 0.0\n",
      "Iteration 830, Loss: 0.004285470116883516, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002648810623213649, Min w: 0.0\n",
      "Iteration 850, Loss: 0.004915820900350809, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0035912597086280584, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0027343761175870895, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0030129030346870422, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0062266988679766655, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002732903230935335, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0027772090397775173, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0027757547795772552, Min w: 0.0\n",
      "Iteration 930, Loss: 0.007095405366271734, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0023970173206180334, Min w: 0.0\n",
      "Iteration 950, Loss: 0.004880793392658234, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002610480645671487, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0027477641124278307, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002977771917358041, Min w: 1.022832411963656e-37\n",
      "Iteration 990, Loss: 0.00416457187384367, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0026678135618567467, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0025322556030005217, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0028403294272720814, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.003041874850168824, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002676750300452113, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002651542890816927, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002618029247969389, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0034697367809712887, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0024634243454784155, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0024991051759570837, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0024434146471321583, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0030137847643345594, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0024905202444642782, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0029074714984744787, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.003080476773902774, Min w: 2.970964017468172e-22\n",
      "Iteration 1150, Loss: 0.002643163548782468, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002400715136900544, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0024828165769577026, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0033132508397102356, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0068204631097614765, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002404207829385996, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0027469806373119354, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0033230369444936514, Min w: 1.0870643558381765e-30\n",
      "Iteration 1230, Loss: 0.0028148686978965998, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0028323526494205, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  42%|████▏     | 10/24 [07:46<11:49, 50.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.9743968056060377, 'L2_avg': 1.0193181142564427, 'End_point_L1_avg': 1.0609989631414587, 'End_point_L2_avg': 1.065517885679236}\n",
      "Iteration 0, Loss: 0.0013512750156223774, Min w: 5.6393630813288825e-14\n",
      "Iteration 10, Loss: 0.0006276267813518643, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005236159777268767, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0006053929682821035, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007849349058233202, Min w: 0.0\n",
      "Iteration 50, Loss: 0.000966337975114584, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006205504760146141, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007431694539263844, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001064892509020865, Min w: 1.0224148784543363e-11\n",
      "Iteration 90, Loss: 0.0006242928211577237, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0013824052875861526, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0009927782230079174, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0013633290072903037, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007660040282644331, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006025832262821496, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008819526410661638, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0016341939335688949, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0010892909485846758, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0007707307231612504, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007349039078690112, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007717669941484928, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0007604521815665066, Min w: 0.0\n",
      "Iteration 220, Loss: 0.000800298701506108, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0008431215537711978, Min w: 0.0\n",
      "Iteration 240, Loss: 0.000957019510678947, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0010956698097288609, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0019188569858670235, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0006870085489936173, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0009418319677934051, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0008259298629127443, Min w: 0.0\n",
      "Iteration 300, Loss: 0.00061674730386585, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0009649624698795378, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0011109467595815659, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0008352009463123977, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0011002118699252605, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0008365918765775859, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008408078574575484, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0007122114766389132, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0010117358760908246, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000872136908583343, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0019467518432065845, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0018536729039624333, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0007137935608625412, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0010757714044302702, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008697076118551195, Min w: 0.0\n",
      "Iteration 450, Loss: 0.000770601152908057, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0011953804641962051, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0007564688567072153, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006960575701668859, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0011391433654353023, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006053955294191837, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0007247854955494404, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007285078754648566, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006690580048598349, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008277029264718294, Min w: 0.0\n",
      "Iteration 550, Loss: 0.000737544905859977, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0008191274246200919, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006814987864345312, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0005880413227714598, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0009956791764125228, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006527354707941413, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006268421420827508, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0007157279178500175, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0007270066416822374, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0008284784271381795, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0007400949252769351, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007157504442147911, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0006863335147500038, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0008170779328793287, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006113161216489971, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0010874480940401554, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008799108909443021, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006580182234756649, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0006914114346727729, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0009253698517568409, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0010341895977035165, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000605467357672751, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0008599596912972629, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0008034460479393601, Min w: 0.0\n",
      "Iteration 790, Loss: 0.001424268470145762, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0011468299198895693, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006497874273918569, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006313215126283467, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0007312161033041775, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008032310870476067, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006628492847084999, Min w: 0.0\n",
      "Iteration 860, Loss: 0.000606382149271667, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0011824965476989746, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006840224959887564, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0009212025906890631, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0007348950603045523, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0009816787205636501, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0007799011655151844, Min w: 0.0\n",
      "Iteration 930, Loss: 0.002028408460319042, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0008659998420625925, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0017017618520185351, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0007724106544628739, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0009021930163726211, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006833101506344974, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006223244126886129, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0007638552342541516, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006681933882646263, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000802178867161274, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006288271397352219, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006167821120470762, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008581457077525556, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0008125220192596316, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0026074631605297327, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008481941767968237, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0011789454147219658, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.000695752096362412, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.001216772710904479, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0013516800245270133, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007523930980823934, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006414559320546687, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0012349382741376758, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0011043611448258162, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006162957870401442, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006960583268664777, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008514305227436125, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.00068804738111794, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.000616380712017417, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0008615276892669499, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0007491366704925895, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006136319134384394, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0006447621854022145, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0008512029307894409, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002110013272613287, Min w: 0.0\n",
      "Iteration 30, Loss: 0.001339120790362358, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0013080760836601257, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006179410847835243, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0009832152863964438, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007501413929276168, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007719206623733044, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0010403234045952559, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0014612696832045913, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006089948583394289, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0013544752728193998, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006028125062584877, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006530914106406271, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0010527957929298282, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0010685096494853497, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006250145961530507, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0013637662632390857, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007449081167578697, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0011892049806192517, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006037594866938889, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0006478656432591379, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0009253251482732594, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0015409862389788032, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0008776981849223375, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0010817284928634763, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0009448801865801215, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006159621407277882, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0008607913623563945, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0011256703874096274, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006307047442533076, Min w: 0.0\n",
      "Iteration 320, Loss: 0.001429906697012484, Min w: 0.0\n",
      "Iteration 330, Loss: 0.001362913055345416, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0010210395557805896, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007553727482445538, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0010258815018460155, Min w: 7.846986015257743e-18\n",
      "Iteration 370, Loss: 0.0007679839618504047, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0011436642380431294, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0006798726390115917, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007999265217222273, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0010943777160719037, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006477450369857252, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007016685558483005, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0010655589867383242, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006491494132205844, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006224132957868278, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006276027415879071, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0009163161739706993, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006129086250439286, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008934639045037329, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0009039949509315193, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0010481810895726085, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000650059781037271, Min w: 0.0\n",
      "Iteration 540, Loss: 0.001040771254338324, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006447361665777862, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007389503880403936, Min w: 0.0\n",
      "Iteration 570, Loss: 0.001729268697090447, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008495710790157318, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002236803760752082, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0008856211788952351, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006825642776675522, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0007805985515005887, Min w: 0.0\n",
      "Iteration 630, Loss: 0.000842551002278924, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0009877142729237676, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0007082268712110817, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007429353427141905, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0006050807423889637, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007177207735367119, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0011090051848441362, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007875479641370475, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008141782600432634, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006604598020203412, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0011288996320217848, Min w: 0.0\n",
      "Iteration 740, Loss: 0.000724994286429137, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006355912191793323, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0009192089200951159, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007932917797006667, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0009388976031914353, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0009212418808601797, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0011479287641122937, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008157423580996692, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006621081265620887, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0008554400410503149, Min w: 0.0\n",
      "Iteration 840, Loss: 0.00084340461762622, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006331677432172, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0011429631849750876, Min w: 0.0\n",
      "Iteration 870, Loss: 0.000670220295432955, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008073723292909563, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0010388009250164032, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006786276353523135, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0010321284644305706, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0009150082478299737, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006115963915362954, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006105938809923828, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0008096866658888757, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0009216936305165291, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0013835693243891, Min w: 0.0\n",
      "Iteration 980, Loss: 0.001373114064335823, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0009994192514568567, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0011399684008210897, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0008352433214895427, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0008490305626764894, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006212710868567228, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008732565911486745, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008788398117758334, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0010649869218468666, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006605461821891367, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0009717323118820786, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0011006486602127552, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.001003751065582037, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0010512068402022123, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006547112134285271, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.001832073787227273, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006529735401272774, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.001325123361311853, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0008535581873729825, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006875357939861715, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.000628259324003011, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0009025163017213345, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0008695734431967139, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0006400863640010357, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006990989786572754, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006874612299725413, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006143842474557459, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0007887741085141897, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0018773381598293781, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0008056360529735684, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008166649495251477, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006749873864464462, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006138710887171328, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0011313692666590214, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008975511882454157, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0008526770980097353, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0011323228245601058, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006254902109503746, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0008494118228554726, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0012314923806115985, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0012258026981726289, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0010889223776757717, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0010601446265354753, Min w: 0.0\n",
      "Iteration 160, Loss: 0.000655110168736428, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008906557923182845, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006103094201534986, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0008918615058064461, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0008215155103243887, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0032960502430796623, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0014290526742115617, Min w: 0.0\n",
      "Iteration 230, Loss: 0.001442593988031149, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0007245467859320343, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002453614491969347, Min w: 0.0\n",
      "Iteration 260, Loss: 0.001032761880196631, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0009034090326167643, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0009101888281293213, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002367547247558832, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007752343663014472, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0011575684184208512, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0009391462081111968, Min w: 0.0\n",
      "Iteration 330, Loss: 0.001026471029035747, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00075857515912503, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0010748228523880243, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008748192340135574, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0007383198826573789, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006501851603388786, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0008251479011960328, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007506789988838136, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0016433588461950421, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0007840784965083003, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0008581727743148804, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006657443009316921, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001103439019061625, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0009184291120618582, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0016751100774854422, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0008850849699229002, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0015884144231677055, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008612329256720841, Min w: 0.0\n",
      "Iteration 510, Loss: 0.00239687692373991, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0013896190794184804, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0007314528920687735, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006171272834762931, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0014868266880512238, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0006046451744623482, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0010482327779754996, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008634321857243776, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0009914204711094499, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0012436071410775185, Min w: 0.0\n",
      "Iteration 610, Loss: 0.000617543701082468, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0009674316388554871, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0022697162348777056, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0008379174396395683, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0029177034739404917, Min w: 0.0\n",
      "Iteration 660, Loss: 0.001068280776962638, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0012707201531156898, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0010661750566214323, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0008354524034075439, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0026540416292846203, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0010379976592957973, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0009230416617356241, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0009211510187014937, Min w: 0.0\n",
      "Iteration 740, Loss: 0.00108804099727422, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006211731815710664, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0006229486898519099, Min w: 0.0\n",
      "Iteration 770, Loss: 0.000875170633662492, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006928160437382758, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007452865829691291, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0007141969399526715, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008392413146793842, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0025595577899366617, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006732090259902179, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012308420846238732, Min w: 0.0\n",
      "Iteration 850, Loss: 0.000913019641302526, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008002353715710342, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006081133615225554, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006487020291388035, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0007427921518683434, Min w: 0.0\n",
      "Iteration 900, Loss: 0.00069878448266536, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006108111701905727, Min w: 0.0\n",
      "Iteration 920, Loss: 0.001304362784139812, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0019929229747503996, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007721487199887633, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00066826690454036, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0013456312008202076, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0015722204698249698, Min w: 0.0\n",
      "Iteration 980, Loss: 0.001664814306423068, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0012892683735117316, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0009500209125690162, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006069358787499368, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0008340999484062195, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0008798647904768586, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0009296929929405451, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008272081613540649, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0012422717409208417, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0016743114683777094, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008748481632210314, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0007169458549469709, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0008443234255537391, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006038323044776917, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0007699455018155277, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007094052853062749, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007009076653048396, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.000759089074563235, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002535390667617321, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0008036661893129349, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0016313366359099746, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0006898838910274208, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007807042566128075, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0006976875010877848, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006976022850722075, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0007138010114431381, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008303988724946976, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0006631284486502409, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0011089285835623741, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006927662179805338, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000985112157650292, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006293042679317296, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007285515894182026, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006079777958802879, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007457109750248492, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006997768068686128, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007019064505584538, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006930420058779418, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0009141865302808583, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006332631455734372, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0010030773701146245, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0015791762853041291, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006518582231365144, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006214394816197455, Min w: 0.0\n",
      "Iteration 170, Loss: 0.000825548660941422, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0007011272828094661, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0012389107141643763, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0008203044417314231, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006109873065724969, Min w: 0.0\n",
      "Iteration 220, Loss: 0.000717033923137933, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007941634976305068, Min w: 0.0\n",
      "Iteration 240, Loss: 0.001460098079405725, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006220444920472801, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0009905797196552157, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0008781637297943234, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008019608212634921, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007438942557200789, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0011416515335440636, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007028452237136662, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006141162011772394, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007601921097375453, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0014937006635591388, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007320152362808585, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0015001146821305156, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006855067331343889, Min w: 0.0\n",
      "Iteration 380, Loss: 0.000694788817781955, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0006110782851465046, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006328269955702126, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0013666024897247553, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002274578670039773, Min w: 0.0\n",
      "Iteration 430, Loss: 0.000718757975846529, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0015116840368136764, Min w: 0.0\n",
      "Iteration 450, Loss: 0.000891503703314811, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0007142338436096907, Min w: 0.0\n",
      "Iteration 470, Loss: 0.001122063142247498, Min w: 0.0\n",
      "Iteration 480, Loss: 0.001029271399602294, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006847258191555738, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0009079964947886765, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0008159506833180785, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0009653238230384886, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0010235641384497285, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006396184326149523, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0008007240830920637, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007786740316078067, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0009713546023704112, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008300088811665773, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006616874597966671, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0021750673186033964, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0010576347121968865, Min w: 0.0\n",
      "Iteration 620, Loss: 0.001551349530927837, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0009043858153745532, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006234855391085148, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008541105198673904, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0008243339834734797, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0009256353368982673, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007330775260925293, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006790709448978305, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007003936916589737, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0007813732954673469, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0008526910096406937, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0008070163312368095, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0018659159541130066, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0009803150314837694, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0007287915796041489, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0008827838464640081, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0009135222062468529, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0006934343837201595, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009770147735252976, Min w: 0.0\n",
      "Iteration 810, Loss: 0.000719019619282335, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0009011962683871388, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0013927753316238523, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008850600570440292, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0010845171054825187, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0006424332968890667, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0009710881859064102, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0007051784778013825, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0009243348613381386, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0008314737933687866, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0009223665110766888, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0009075624984689057, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0010087625123560429, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007286560139618814, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00125220010522753, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006769619649276137, Min w: 0.0\n",
      "Iteration 970, Loss: 0.001578365103341639, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006974560674279928, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0017098052194342017, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006018441636115313, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0007211169577203691, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000738766451831907, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.001485740882344544, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006381772109307349, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.001213761861436069, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0008169937063939869, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006360972765833139, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0006305165006779134, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0008849621517583728, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0012378293322399259, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006557026063092053, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006330844480544329, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0009439748246222734, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0008719298057258129, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0007790765375830233, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0017681806348264217, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009265695116482675, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0007482209475710988, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.001073056715540588, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.000943728256970644, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007979490328580141, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0009065014310181141, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0008351479191333055, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0009779748506844044, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0007692447979934514, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010163342813029885, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007270178757607937, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007020153570920229, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009904655162245035, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0014041806571185589, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006445646286010742, Min w: 0.0\n",
      "Iteration 70, Loss: 0.001705313683487475, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0008989146444946527, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0014829994179308414, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0009743314585648477, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000841662404127419, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006850515492260456, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0009830312337726355, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0008540214039385319, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0009083651239052415, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006921570748090744, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0007296478725038469, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006406242027878761, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0011284248903393745, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007263463921844959, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006425181636586785, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0008027792791835964, Min w: 0.0\n",
      "Iteration 230, Loss: 0.000853964826092124, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0009123028721660376, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007238644175231457, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0010215664515271783, Min w: 6.833487253656802e-26\n",
      "Iteration 270, Loss: 0.0012255347101017833, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0019862425979226828, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00062766601331532, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0015210468554869294, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006192377186380327, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0007845173240639269, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0008360248757526278, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0009460260043852031, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007436078158207238, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0009239116916432977, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0010604469571262598, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006169186090119183, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000629723712336272, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0010987381683662534, Min w: 0.0\n",
      "Iteration 410, Loss: 0.00112329819239676, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0008167251362465322, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0008493252680636942, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008992390939965844, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0010152251925319433, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006783119752071798, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006286929128691554, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006257056957110763, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0007559866062365472, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006764641148038208, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0012049104552716017, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007139472872950137, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0011393167078495026, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008076192461885512, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0008682344341650605, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0006811957573518157, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006854697712697089, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006203466327860951, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0009410742204636335, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006880757864564657, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006880512228235602, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0007259742124006152, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006653185118921101, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006087489891797304, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0007196585065685213, Min w: 0.0\n",
      "Iteration 660, Loss: 0.001612178049981594, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0011526612797752023, Min w: 0.0\n",
      "Iteration 680, Loss: 0.000997156952507794, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0007352391839958727, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0006719363736920059, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006867977208457887, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0009735279600135982, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007427241653203964, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0006396278622560203, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006124756764620543, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0007904928061179817, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0012854133965447545, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0012744568521156907, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0010263625299558043, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006314702332019806, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006127602537162602, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007079234928824008, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0007448730757459998, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0007304816390387714, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007731609512120485, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0006884370814077556, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006684777908958495, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008698647143319249, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0009685169789008796, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0015754657797515392, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006502265459857881, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0009513314580544829, Min w: 0.0\n",
      "Iteration 930, Loss: 0.00076590187381953, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006464830948971212, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0008814503089524806, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0012617167085409164, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0010025344090536237, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006219787755981088, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0012716909404844046, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006139835459180176, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.001417298917658627, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007303896709345281, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0007333926623687148, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0007632551132701337, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0006457592826336622, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0011142868315801024, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007049629930406809, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0006856162217445672, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006135852891020477, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0008270763792097569, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0008269689860753715, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0015757981454953551, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007022942299954593, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.001254299539141357, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006023262976668775, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0008768614497967064, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006392639479599893, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0009364551515318453, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.001127526513300836, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006553318235091865, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007432135171256959, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006961036124266684, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0011929712491109967, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  46%|████▌     | 11/24 [08:44<11:27, 52.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.0006469814106822014, Min w: 0.0\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.8263707863320389, 'L2_avg': 0.858616781963469, 'End_point_L1_avg': 0.8812910485506232, 'End_point_L2_avg': 0.8926340053944962}\n",
      "Iteration 0, Loss: 0.0010327121708542109, Min w: 1.9498829140330777e-17\n",
      "Iteration 10, Loss: 0.0006968328380025923, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007245464366860688, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0006413559895008802, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006385815213434398, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0008018738008104265, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0008061481639742851, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0006570756668224931, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0008295316365547478, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007421697373501956, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0007025266531854868, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006314956117421389, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005982530419714749, Min w: 0.0\n",
      "Iteration 130, Loss: 0.000653581868391484, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0010288968915119767, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0005922415293753147, Min w: 0.0\n",
      "Iteration 160, Loss: 0.000578058825340122, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0007863639038987458, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006710938178002834, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006612587021663785, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006062870961613953, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0008141990401782095, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0009085990604944527, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0008748968248255551, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0011474649654701352, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0009625699603930116, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0007327008061110973, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0006083426997065544, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0012315419735386968, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006307583535090089, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007519734208472073, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007121755043044686, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0005399261717684567, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006742951227352023, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006058346480131149, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007144546252675354, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0007169221062213182, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006488334620371461, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0008445926941931248, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007736452971585095, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006316166836768389, Min w: 0.0\n",
      "Iteration 410, Loss: 0.001145919319242239, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006186372484080493, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006902702152729034, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008377530612051487, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006742143887095153, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0019342034356668591, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006205836543813348, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006580197368748486, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0009242805535905063, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0007621552795171738, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006777719245292246, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007185281137935817, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000871644529979676, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0007372893742285669, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006015673861838877, Min w: 0.0\n",
      "Iteration 560, Loss: 0.000917891098652035, Min w: 0.0\n",
      "Iteration 570, Loss: 0.001588278915733099, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0012012115912511945, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006369616603478789, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006792254280298948, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0010808863444253802, Min w: 0.0\n",
      "Iteration 620, Loss: 0.000794881081674248, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0007940313662402332, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006691584712825716, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006424765451811254, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0012444698950275779, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0009848978370428085, Min w: 0.0\n",
      "Iteration 680, Loss: 0.001059471513144672, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0008338774787262082, Min w: 0.0\n",
      "Iteration 700, Loss: 0.00107955327257514, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0011492447229102254, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0009091832907870412, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007444970542564988, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0008194259135052562, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006921637686900795, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0007418438326567411, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0008158390992321074, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006863512680865824, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0009450662764720619, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0007846422377042472, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0028935063164681196, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0011801382061094046, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0013530813157558441, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0007314239628612995, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007345733465626836, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0009605857776477933, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0009414800442755222, Min w: 0.0\n",
      "Iteration 880, Loss: 0.00064442417351529, Min w: 0.0\n",
      "Iteration 890, Loss: 0.000936643686145544, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0010132350726053119, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0008128131739795208, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0011322578648105264, Min w: 0.0\n",
      "Iteration 930, Loss: 0.001062678056769073, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0009023455204442143, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0010110727744176984, Min w: 0.0\n",
      "Iteration 960, Loss: 0.000683420046698302, Min w: 0.0\n",
      "Iteration 970, Loss: 0.001044873963110149, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0009751729085110128, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006504194461740553, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006549494573846459, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006917356513440609, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000618013902567327, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.000658055767416954, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008993552764877677, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0007226916495710611, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.001021496020257473, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006691075977869332, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.000788870791438967, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0007699951529502869, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007906275568529963, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0009673674940131605, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006205574027262628, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006979516474530101, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006312240147963166, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0014370353892445564, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0012394506484270096, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009657394839450717, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0010579965310171247, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008278807508759201, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0029293315019458532, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.00104386021848768, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0014688201481476426, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006836421089246869, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.001098816515877843, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0011598033597692847, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0012125702342018485, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006387885077856481, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007157512009143829, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0012905753683298826, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007908417610451579, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0014411068987101316, Min w: 0.0\n",
      "Iteration 70, Loss: 0.000619700294919312, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007233800133690238, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0016120829386636615, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0011497264495119452, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0011211587116122246, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0009122461779043078, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0010005998192355037, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0007324775215238333, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006861703586764634, Min w: 0.0\n",
      "Iteration 160, Loss: 0.001485948683694005, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008596857660450041, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0011140849674120545, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006160064949654043, Min w: 0.0\n",
      "Iteration 200, Loss: 0.001195968477986753, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0017026113346219063, Min w: 0.0\n",
      "Iteration 220, Loss: 0.000770591024775058, Min w: 0.0\n",
      "Iteration 230, Loss: 0.000792741309851408, Min w: 0.0\n",
      "Iteration 240, Loss: 0.000977121526375413, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007564089028164744, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0007883874350227416, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002956463024020195, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0011936593800783157, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0011540795676410198, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006063581677153707, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007122880779206753, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006413108203560114, Min w: 0.0\n",
      "Iteration 330, Loss: 0.000641262682620436, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0007378290756605566, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0008601590525358915, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0011553580407053232, Min w: 0.0\n",
      "Iteration 370, Loss: 0.001498124678619206, Min w: 0.0\n",
      "Iteration 380, Loss: 0.001510206377133727, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0010297494009137154, Min w: 4.8198789941802275e-25\n",
      "Iteration 400, Loss: 0.001946722506545484, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006622517248615623, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0009768796153366566, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0009451767546124756, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0009417393594048917, Min w: 4.301628086477056e-27\n",
      "Iteration 450, Loss: 0.0010549342259764671, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006393610965460539, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006791083724237978, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007610240718349814, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0012238535564392805, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0010652992641553283, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0015231398865580559, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0010764104081317782, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006192772998474538, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008403487736359239, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0007987619028426707, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0015355250798165798, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006357062375172973, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0009409388876520097, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0009781240951269865, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007604544516652822, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0007343142060562968, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006390895578078926, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0008598275599069893, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0011869913432747126, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008914615027606487, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0013691564090549946, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007731497171334922, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0012062041787430644, Min w: 0.0\n",
      "Iteration 690, Loss: 0.000631249975413084, Min w: 0.0\n",
      "Iteration 700, Loss: 0.000982079771347344, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008111135102808475, Min w: 0.0\n",
      "Iteration 720, Loss: 0.001870671403594315, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007237535901367664, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0017548734322190285, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006241797818802297, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0008460504468530416, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0006661106017418206, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007405888754874468, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0019737256225198507, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006158850737847388, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0012486391933634877, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006592986173927784, Min w: 0.0\n",
      "Iteration 830, Loss: 0.002799741458147764, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0010104692773893476, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006599208572879434, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007860134937800467, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0009440511930733919, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008095261291600764, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006453166133724153, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0007393038249574602, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0024630373809486628, Min w: 0.0\n",
      "Iteration 920, Loss: 0.001761427614837885, Min w: 0.0\n",
      "Iteration 930, Loss: 0.000706618360709399, Min w: 0.0\n",
      "Iteration 940, Loss: 0.001181702595204115, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0013641183031722903, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0013127243146300316, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0007208809838630259, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0007502908702008426, Min w: 0.0\n",
      "Iteration 990, Loss: 0.000976445444393903, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0007046091486699879, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006293494370765984, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007600372773595154, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.001591196865774691, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0007007498061284423, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002666566288098693, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0012982800835743546, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0008539553382433951, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008186196791939437, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006762239499948919, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006277948850765824, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.001074344152584672, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0008684801287017763, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007100146031007171, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.000761292059905827, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.000782734714448452, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0010209301253780723, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0008600043365731835, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0009708417346701026, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0006720615201629698, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0010751120280474424, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0008305622031912208, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0033123285975307226, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0009366950253024697, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0016569369472563267, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0007729956996627152, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006200523930601776, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0010028077522292733, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007606662111356854, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0030045181047171354, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0018088798969984055, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007542881066910923, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0013156912755221128, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0009229651768691838, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0007165063288994133, Min w: 0.0\n",
      "Iteration 100, Loss: 0.000917151861358434, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006205107201822102, Min w: 0.0\n",
      "Iteration 120, Loss: 0.000782358052674681, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0009273043251596391, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009076565620489419, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008113315561786294, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0007123109535314143, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0011644473997876048, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006082238396629691, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006478906725533307, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006204514647834003, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0008890352328307927, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0008799765491858125, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006222641095519066, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006320865359157324, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006588200340047479, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0010009963298216462, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007183749112300575, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008010199526324868, Min w: 0.0\n",
      "Iteration 290, Loss: 0.000906340079382062, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006357948877848685, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0009154524304904044, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0008350497810170054, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007356274290941656, Min w: 0.0\n",
      "Iteration 340, Loss: 0.001675445819273591, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001003137556836009, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008552573272027075, Min w: 0.0\n",
      "Iteration 370, Loss: 0.000776670640334487, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006906797643750906, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0006462368764914572, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006196690374054015, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0009541096515022218, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0007653384818695486, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006130787660367787, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006614568410441279, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006646404508501291, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0009111895342357457, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0007880335906520486, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0011988910846412182, Min w: 0.0\n",
      "Iteration 490, Loss: 0.001072979997843504, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0007613365305587649, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006699089426547289, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0006156924646347761, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006032326491549611, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006164785590954125, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0007188476156443357, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0025361913722008467, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002015407895669341, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006747221341356635, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0008802568772807717, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0008933265344239771, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0009594035218469799, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006173060974106193, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0013213224010542035, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0010823567863553762, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0007344148471020162, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007054642192088068, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007525341934524477, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0006135058356449008, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006336074438877404, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0008190629305317998, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0011685218196362257, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006003197631798685, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0006376640521921217, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0007618060917593539, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007288692868314683, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0009893833193928003, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0015404934529215097, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006027134950272739, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0010006397496908903, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006027910276316106, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0007145038689486682, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007436901214532554, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0010628578020259738, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0007580627570860088, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007219684193842113, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0013184440322220325, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007444496732205153, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008286623051390052, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0011749983532354236, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0007023471407592297, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0009063117322511971, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0006407890468835831, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0009748215670697391, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0017671268433332443, Min w: 0.0\n",
      "Iteration 950, Loss: 0.001408624928444624, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006236676126718521, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0012210641289129853, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006833112565800548, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0007565867272205651, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0008575491374358535, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0011017054785043001, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0006377225508913398, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0010033374419435859, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008815860492177308, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.000649389112368226, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0015625214437022805, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006692432216368616, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0018568389350548387, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0007711504003964365, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0014747049426659942, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0010166961001232266, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0007291596848517656, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007820827886462212, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007790487143211067, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006011488731019199, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0007436519954353571, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0024703762028366327, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006433214875869453, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0017957993550226092, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006569488323293626, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007303630700334907, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0011694376589730382, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0007243642467074096, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.003248702734708786, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0009983114432543516, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006399477715604007, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007030924898572266, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000857875682413578, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002067750319838524, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007032885914668441, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006907376227900386, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0006623455556109548, Min w: 0.0\n",
      "Iteration 80, Loss: 0.000663797662127763, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006607028772123158, Min w: 0.0\n",
      "Iteration 100, Loss: 0.000850366719532758, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000687024206854403, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0010935422033071518, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007025259546935558, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009127191151492298, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006811963394284248, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0009131788974627852, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006947917281650007, Min w: 0.0\n",
      "Iteration 180, Loss: 0.000807474076282233, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0016875423025339842, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006023741443641484, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0007807334186509252, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0009200423955917358, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007216667872853577, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006922153988853097, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006112106493674219, Min w: 0.0\n",
      "Iteration 260, Loss: 0.001176718040369451, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007603839039802551, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0011383537203073502, Min w: 0.0\n",
      "Iteration 290, Loss: 0.000985360355116427, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006626135436818004, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006393387448042631, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006786147714592516, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007917695329524577, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006020157015882432, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001242036116309464, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0007280963473021984, Min w: 0.0\n",
      "Iteration 370, Loss: 0.001026791986078024, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0009723005350679159, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000740596151445061, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006136946612969041, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0015139520401135087, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0014318248722702265, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0012386942980811, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006688219727948308, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0007092307205311954, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0013273317599669099, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0016103197121992707, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0013497942127287388, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0008073918288573623, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0013101835502311587, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0010884562507271767, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0012064359616488218, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0010010568657889962, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0014646127820014954, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006927133654244244, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0009086007485166192, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0009338805684819818, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0025668716989457607, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006176657043397427, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0013766357442364097, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0007639837567694485, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006650854484178126, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006508876685984433, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0008092457428574562, Min w: 0.0\n",
      "Iteration 650, Loss: 0.00099374249111861, Min w: 0.0\n",
      "Iteration 660, Loss: 0.000706518825609237, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0025051466654986143, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0011820498621091247, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0008397246128879488, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0011575657408684492, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0009387517347931862, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0008679571328684688, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007425682852044702, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0011152570368722081, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0008197109564207494, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0019719600677490234, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007193447672761977, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006088716327212751, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007180264219641685, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0015241908840835094, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006066896021366119, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006888105417601764, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0007278402918018401, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008122267317958176, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0010474497685208917, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0010837442241609097, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007048103725537658, Min w: 0.0\n",
      "Iteration 880, Loss: 0.00211959145963192, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0012613493017852306, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0008193290559574962, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0007274913368746638, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0014099811669439077, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0007164634298533201, Min w: 0.0\n",
      "Iteration 940, Loss: 0.001081565278582275, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0007705612806603312, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006206776015460491, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006135159055702388, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006266707205213606, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008864247938618064, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0008027793373912573, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006578392931260169, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000721863005310297, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0010685534216463566, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006755921640433371, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0013658161042258143, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007247459725476801, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0010509233688935637, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0006812399951741099, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006781527190469205, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006772266933694482, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.000832767691463232, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0012964631896466017, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0008815655601210892, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0012891939841210842, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0008991194190457463, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006888143252581358, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0014343142975121737, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0009778421372175217, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0013622133992612362, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0019703367725014687, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007706695469096303, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0011698148446157575, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0012727384455502033, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0007317689596675336, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0010216949740424752, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0013916378375142813, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0012478958815336227, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000793833052739501, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008667126530781388, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0012860287679359317, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006655705510638654, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0009572416311129928, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0010677310638129711, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0008134795934893191, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0015122236218303442, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0012822026619687676, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0010469298576936126, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0008265509968623519, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002868088660761714, Min w: 0.0\n",
      "Iteration 150, Loss: 0.002668075729161501, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0007685463060624897, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0015578112797811627, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0008412755560129881, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0011853009928017855, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007327089551836252, Min w: 0.0\n",
      "Iteration 210, Loss: 0.001124640111811459, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0008552010403946042, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006482194876298308, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006256272317841649, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007366440258920193, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0009469805518165231, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007348263170570135, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0009271319722756743, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0008505457080900669, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0009556605946272612, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0014687126968055964, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0012600008631125093, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0010880307527258992, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006615153979510069, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0006588706746697426, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0007243495783768594, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0011210424127057195, Min w: 0.0\n",
      "Iteration 380, Loss: 0.001232774113304913, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007333956891670823, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006845116731710732, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0007157647050917149, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006956590223126113, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006859571440145373, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0016053908038884401, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002796343294903636, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0007621057447977364, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0012242932571098208, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007101679802872241, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000826740637421608, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0013210717588663101, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006586454692296684, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0023309611715376377, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0011744117364287376, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0010541613446548581, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006231091683730483, Min w: 0.0\n",
      "Iteration 560, Loss: 0.000627741334028542, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006204706733115017, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007904850644990802, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0011680321767926216, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0008434524061158299, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0008504716097377241, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0009253923199139535, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0007745091570541263, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0007108402205631137, Min w: 0.0\n",
      "Iteration 650, Loss: 0.000709682353772223, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0008796592010185122, Min w: 0.0\n",
      "Iteration 670, Loss: 0.00318093947134912, Min w: 0.0\n",
      "Iteration 680, Loss: 0.00059961446095258, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0022478648461401463, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007693555089645088, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006128494860604405, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000662845850456506, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0009145963122136891, Min w: 9.274038071769326e-37\n",
      "Iteration 740, Loss: 0.0006871182704344392, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0010436981683596969, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0006519705639220774, Min w: 0.0\n",
      "Iteration 770, Loss: 0.00074947060784325, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0008651543175801635, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0006056053680367768, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0015140878967940807, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008306730305776, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0019077014876529574, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006147195235826075, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0006943842745386064, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007512157899327576, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007176338694989681, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0015102068427950144, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006470364169217646, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008428941364400089, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0008936998783610761, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006309411837719381, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0006604042137041688, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0009417804540134966, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0010869877878576517, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0007641043048352003, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006436971016228199, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006283912225626409, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006963306805118918, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0011915680952370167, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006063656765036285, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0008496128139086068, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007287242915481329, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006458651041612029, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0007051403517834842, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0007636391092091799, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0008997355471365154, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0018536498537287116, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.001239418750628829, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0008333391160704195, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006530029932036996, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0007564043626189232, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0008264174102805555, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.000873298617079854, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007550689042545855, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0007919569034129381, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002912802854552865, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0010765917832031846, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.000976532930508256, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0011396142654120922, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0008649657829664648, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0008036753279156983, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0011446552816778421, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0011521545238792896, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.001007452723570168, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  50%|█████     | 12/24 [09:40<10:44, 53.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.4341544077404395, 'L2_avg': 0.5388706736594062, 'End_point_L1_avg': 0.31908846827747184, 'End_point_L2_avg': 0.45096771607127817}\n",
      "Iteration 0, Loss: 0.004464808385819197, Min w: 2.4342000859262355e-22\n",
      "Iteration 10, Loss: 0.003768738592043519, Min w: 7.358933476692489e-14\n",
      "Iteration 20, Loss: 0.003636027919128537, Min w: 9.234136490361247e-41\n",
      "Iteration 30, Loss: 0.0027559539303183556, Min w: 3.732091248927585e-34\n",
      "Iteration 40, Loss: 0.0022968496195971966, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0020364245865494013, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0017884765984490514, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0016691199271008372, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0015858374536037445, Min w: 0.0\n",
      "Iteration 90, Loss: 0.001649624900892377, Min w: 7.567011707354012e-44\n",
      "Iteration 100, Loss: 0.0014472800539806485, Min w: 1.9473003979643388e-40\n",
      "Iteration 110, Loss: 0.0014696221332997084, Min w: 2.6841098303329066e-25\n",
      "Iteration 120, Loss: 0.0014443841064348817, Min w: 1.721532072451737e-08\n",
      "Iteration 130, Loss: 0.0014442892279475927, Min w: 0.0008299989276565611\n",
      "Iteration 140, Loss: 0.001267479034140706, Min w: 0.1642102301120758\n",
      "Iteration 150, Loss: 0.0010765050537884235, Min w: 0.28229475021362305\n",
      "Iteration 160, Loss: 0.0010069286217913032, Min w: 0.3123635947704315\n",
      "Iteration 170, Loss: 0.00108308473136276, Min w: 0.3641122877597809\n",
      "Iteration 180, Loss: 0.00077245564898476, Min w: 0.46952810883522034\n",
      "Iteration 190, Loss: 0.0007423681672662497, Min w: 0.5098580121994019\n",
      "Iteration 200, Loss: 0.0007053597364574671, Min w: 0.4927603304386139\n",
      "Iteration 210, Loss: 0.0006966665387153625, Min w: 0.5438449382781982\n",
      "Iteration 220, Loss: 0.0006355400546453893, Min w: 0.5539877414703369\n",
      "Iteration 230, Loss: 0.0005702071357518435, Min w: 0.6209430694580078\n",
      "Iteration 240, Loss: 0.0006357175880111754, Min w: 0.6419007778167725\n",
      "Iteration 250, Loss: 0.00048264479846693575, Min w: 0.6872807145118713\n",
      "Iteration 260, Loss: 0.0006764684803783894, Min w: 0.6161903738975525\n",
      "Iteration 270, Loss: 0.0007269057095982134, Min w: 0.5889403223991394\n",
      "Iteration 280, Loss: 0.0006114752613939345, Min w: 0.6794240474700928\n",
      "Iteration 290, Loss: 0.0005981328431516886, Min w: 0.6823953986167908\n",
      "Iteration 300, Loss: 0.00036255066515877843, Min w: 0.8004842400550842\n",
      "Iteration 310, Loss: 0.00045439740642905235, Min w: 0.7511827349662781\n",
      "Iteration 320, Loss: 0.00038009564741514623, Min w: 0.7890011072158813\n",
      "Iteration 330, Loss: 0.00035883401869796216, Min w: 0.7518297433853149\n",
      "Iteration 340, Loss: 0.00041185750160366297, Min w: 0.7000871896743774\n",
      "Iteration 350, Loss: 0.00028707212186418474, Min w: 0.8199344873428345\n",
      "Iteration 360, Loss: 0.00023353056167252362, Min w: 0.8729453086853027\n",
      "Iteration 370, Loss: 0.00033483808510936797, Min w: 0.8047695159912109\n",
      "Iteration 380, Loss: 0.00035898524220101535, Min w: 0.7856461405754089\n",
      "Iteration 390, Loss: 0.0003161730710417032, Min w: 0.7961938381195068\n",
      "Iteration 400, Loss: 0.0004035142483189702, Min w: 0.7538015246391296\n",
      "Iteration 410, Loss: 0.0003152336576022208, Min w: 0.8006119728088379\n",
      "Iteration 420, Loss: 0.000184544813237153, Min w: 0.9046569466590881\n",
      "Iteration 430, Loss: 0.0002112295915139839, Min w: 0.8631008267402649\n",
      "Iteration 440, Loss: 0.00030001881532371044, Min w: 0.8410413265228271\n",
      "Iteration 450, Loss: 0.0001972008030861616, Min w: 0.8835556507110596\n",
      "Iteration 460, Loss: 0.00018485366308595985, Min w: 0.8912907838821411\n",
      "Iteration 470, Loss: 0.0001717110862955451, Min w: 0.9077930450439453\n",
      "Iteration 480, Loss: 0.00023053144104778767, Min w: 0.8474682569503784\n",
      "Iteration 490, Loss: 0.0002129750355379656, Min w: 0.8445009589195251\n",
      "Iteration 500, Loss: 0.00017542509885970503, Min w: 0.8975024819374084\n",
      "Iteration 510, Loss: 0.0005088954931125045, Min w: 0.6882689595222473\n",
      "Iteration 520, Loss: 0.00020831628353334963, Min w: 0.8748266100883484\n",
      "Iteration 530, Loss: 0.00015175642329268157, Min w: 0.9147776365280151\n",
      "Iteration 540, Loss: 0.0001338126021437347, Min w: 0.9248941540718079\n",
      "Iteration 550, Loss: 0.00020420776854734868, Min w: 0.8821483850479126\n",
      "Iteration 560, Loss: 0.00032671703957021236, Min w: 0.8002870678901672\n",
      "Iteration 570, Loss: 0.00015181064372882247, Min w: 0.9026722311973572\n",
      "Iteration 580, Loss: 0.00011655301932478324, Min w: 0.9373397827148438\n",
      "Iteration 590, Loss: 0.0002219142479589209, Min w: 0.8855132460594177\n",
      "Iteration 600, Loss: 0.00018580823962111026, Min w: 0.8996673822402954\n",
      "Iteration 610, Loss: 0.00013799684529658407, Min w: 0.9291408658027649\n",
      "Iteration 620, Loss: 0.00012585068179760128, Min w: 0.9300333261489868\n",
      "Iteration 630, Loss: 0.00012081944441888481, Min w: 0.9356555938720703\n",
      "Iteration 640, Loss: 0.00023780246556270868, Min w: 0.8301527500152588\n",
      "Iteration 650, Loss: 0.00010856435255846009, Min w: 0.9367271065711975\n",
      "Iteration 660, Loss: 0.0002079525584122166, Min w: 0.8816143274307251\n",
      "Iteration 670, Loss: 0.00012203198275528848, Min w: 0.922100305557251\n",
      "Iteration 680, Loss: 0.00011346251994837075, Min w: 0.9398626089096069\n",
      "Iteration 690, Loss: 0.00015790249744895846, Min w: 0.915555477142334\n",
      "Iteration 700, Loss: 0.00011089898907812312, Min w: 0.9394846558570862\n",
      "Iteration 710, Loss: 8.743500075070187e-05, Min w: 0.9541926383972168\n",
      "Iteration 720, Loss: 0.00016533922462258488, Min w: 0.9097461700439453\n",
      "Iteration 730, Loss: 8.717652963241562e-05, Min w: 0.9522234201431274\n",
      "Iteration 740, Loss: 0.00016338985005859286, Min w: 0.9096220135688782\n",
      "Iteration 750, Loss: 0.00012839374539908022, Min w: 0.9068945646286011\n",
      "Iteration 760, Loss: 0.00017083456623367965, Min w: 0.9060243368148804\n",
      "Iteration 770, Loss: 0.0001001331620500423, Min w: 0.9343666434288025\n",
      "Iteration 780, Loss: 9.929117368301377e-05, Min w: 0.9428012371063232\n",
      "Iteration 790, Loss: 0.0001869948027888313, Min w: 0.871199369430542\n",
      "Iteration 800, Loss: 9.344578575110063e-05, Min w: 0.9506989121437073\n",
      "Iteration 810, Loss: 0.00019124180835206062, Min w: 0.8903955221176147\n",
      "Iteration 820, Loss: 9.991366823669523e-05, Min w: 0.9411951303482056\n",
      "Iteration 830, Loss: 0.00012439563579391688, Min w: 0.9317916631698608\n",
      "Iteration 840, Loss: 7.631920016137883e-05, Min w: 0.956030011177063\n",
      "Iteration 850, Loss: 9.764373680809513e-05, Min w: 0.949304461479187\n",
      "Iteration 860, Loss: 9.880668949335814e-05, Min w: 0.9428538084030151\n",
      "Iteration 870, Loss: 7.363174518104643e-05, Min w: 0.9591999650001526\n",
      "Iteration 880, Loss: 0.00017427082639187574, Min w: 0.8840826153755188\n",
      "Iteration 890, Loss: 9.167355892714113e-05, Min w: 0.9427028894424438\n",
      "Iteration 900, Loss: 9.626217797631398e-05, Min w: 0.9443178772926331\n",
      "Iteration 910, Loss: 8.114640513667837e-05, Min w: 0.945452868938446\n",
      "Iteration 920, Loss: 0.00015794784121681005, Min w: 0.9140018820762634\n",
      "Iteration 930, Loss: 6.236549961613491e-05, Min w: 0.967113733291626\n",
      "Iteration 940, Loss: 0.00013733041123487055, Min w: 0.9286343455314636\n",
      "Iteration 950, Loss: 6.645388930337504e-05, Min w: 0.9659465551376343\n",
      "Iteration 960, Loss: 9.712376049719751e-05, Min w: 0.936082661151886\n",
      "Iteration 970, Loss: 0.0001230380148626864, Min w: 0.9335645437240601\n",
      "Iteration 980, Loss: 7.769195508444682e-05, Min w: 0.9595044851303101\n",
      "Iteration 990, Loss: 6.026588016538881e-05, Min w: 0.9671130180358887\n",
      "Iteration 1000, Loss: 0.00024174917780328542, Min w: 0.8633359670639038\n",
      "Iteration 1010, Loss: 0.0001693904778221622, Min w: 0.8847540616989136\n",
      "Iteration 1020, Loss: 7.877280586399138e-05, Min w: 0.9523643851280212\n",
      "Iteration 1030, Loss: 0.00014372266014106572, Min w: 0.9167657494544983\n",
      "Iteration 1040, Loss: 0.00014311620907392353, Min w: 0.9146357774734497\n",
      "Iteration 1050, Loss: 5.6348682846874e-05, Min w: 0.9698396921157837\n",
      "Iteration 1060, Loss: 6.1897182604298e-05, Min w: 0.9664129018783569\n",
      "Iteration 1070, Loss: 0.0001450202107662335, Min w: 0.9080348610877991\n",
      "Iteration 1080, Loss: 7.66682205721736e-05, Min w: 0.9582962989807129\n",
      "Iteration 1090, Loss: 0.00010333437967346981, Min w: 0.9379288554191589\n",
      "Iteration 1100, Loss: 0.0001303883909713477, Min w: 0.8982375264167786\n",
      "Iteration 1110, Loss: 7.605014252476394e-05, Min w: 0.9505624175071716\n",
      "Iteration 1120, Loss: 0.0001059946880559437, Min w: 0.9270915389060974\n",
      "Iteration 1130, Loss: 7.960372022353113e-05, Min w: 0.9562575817108154\n",
      "Iteration 1140, Loss: 7.786252535879612e-05, Min w: 0.9490907192230225\n",
      "Iteration 1150, Loss: 5.768166374764405e-05, Min w: 0.9678777456283569\n",
      "Iteration 1160, Loss: 0.0001669283810770139, Min w: 0.8949857354164124\n",
      "Iteration 1170, Loss: 0.00014423490210901946, Min w: 0.9082494974136353\n",
      "Iteration 1180, Loss: 5.597662675427273e-05, Min w: 0.9661574959754944\n",
      "Iteration 1190, Loss: 9.648319974076003e-05, Min w: 0.9437171816825867\n",
      "Iteration 1200, Loss: 6.114905409049243e-05, Min w: 0.9675682187080383\n",
      "Iteration 1210, Loss: 9.164029324892908e-05, Min w: 0.9463422894477844\n",
      "Iteration 1220, Loss: 7.203255518106744e-05, Min w: 0.9589070081710815\n",
      "Iteration 1230, Loss: 0.00011945189180551097, Min w: 0.9188747406005859\n",
      "Iteration 1240, Loss: 4.8033522034529597e-05, Min w: 0.9751878976821899\n",
      "Iteration 0, Loss: 5.560521094594151e-05, Min w: 0.9695014357566833\n",
      "Iteration 10, Loss: 5.969642006675713e-05, Min w: 0.9690043330192566\n",
      "Iteration 20, Loss: 9.245755063602701e-05, Min w: 0.9363901615142822\n",
      "Iteration 30, Loss: 0.00011347796680638567, Min w: 0.9325881004333496\n",
      "Iteration 40, Loss: 7.485010428354144e-05, Min w: 0.9506562352180481\n",
      "Iteration 50, Loss: 5.547074761125259e-05, Min w: 0.9605663418769836\n",
      "Iteration 60, Loss: 5.5964610510272905e-05, Min w: 0.9670409560203552\n",
      "Iteration 70, Loss: 6.947426300030202e-05, Min w: 0.9546195864677429\n",
      "Iteration 80, Loss: 0.00015132642874959856, Min w: 0.9007006883621216\n",
      "Iteration 90, Loss: 8.904615242499858e-05, Min w: 0.9319047331809998\n",
      "Iteration 100, Loss: 4.560145316645503e-05, Min w: 0.976291835308075\n",
      "Iteration 110, Loss: 6.0644244513241574e-05, Min w: 0.9604452848434448\n",
      "Iteration 120, Loss: 7.041284698061645e-05, Min w: 0.9633769989013672\n",
      "Iteration 130, Loss: 4.2920528358081356e-05, Min w: 0.9772946834564209\n",
      "Iteration 140, Loss: 5.1060942496405914e-05, Min w: 0.9707621932029724\n",
      "Iteration 150, Loss: 5.528513793251477e-05, Min w: 0.9669410586357117\n",
      "Iteration 160, Loss: 0.00011232906399527565, Min w: 0.9222217202186584\n",
      "Iteration 170, Loss: 4.971286398358643e-05, Min w: 0.9707098603248596\n",
      "Iteration 180, Loss: 0.00012121539475629106, Min w: 0.914553701877594\n",
      "Iteration 190, Loss: 0.00024967684294097126, Min w: 0.8167186379432678\n",
      "Iteration 200, Loss: 0.00010427583038108423, Min w: 0.9286717772483826\n",
      "Iteration 210, Loss: 0.00010506300895940512, Min w: 0.9362996220588684\n",
      "Iteration 220, Loss: 3.884954276145436e-05, Min w: 0.9799357652664185\n",
      "Iteration 230, Loss: 6.7040731664747e-05, Min w: 0.9506003856658936\n",
      "Iteration 240, Loss: 6.557080632774159e-05, Min w: 0.9566904902458191\n",
      "Iteration 250, Loss: 8.225092460634187e-05, Min w: 0.9554262757301331\n",
      "Iteration 260, Loss: 9.511116513749585e-05, Min w: 0.9463004469871521\n",
      "Iteration 270, Loss: 0.00015121007163543254, Min w: 0.9155851006507874\n",
      "Iteration 280, Loss: 0.00010152532922802493, Min w: 0.9411391615867615\n",
      "Iteration 290, Loss: 0.00012109556701034307, Min w: 0.9358571767807007\n",
      "Iteration 300, Loss: 3.5025943361688405e-05, Min w: 0.9816884994506836\n",
      "Iteration 310, Loss: 9.550567483529449e-05, Min w: 0.9400004744529724\n",
      "Iteration 320, Loss: 0.00011547281610546634, Min w: 0.914906919002533\n",
      "Iteration 330, Loss: 3.822386133833788e-05, Min w: 0.977920413017273\n",
      "Iteration 340, Loss: 4.859121690969914e-05, Min w: 0.967533528804779\n",
      "Iteration 350, Loss: 0.0001854829170042649, Min w: 0.8643272519111633\n",
      "Iteration 360, Loss: 0.00011754980369005352, Min w: 0.9275026917457581\n",
      "Iteration 370, Loss: 6.674163887510076e-05, Min w: 0.9511372447013855\n",
      "Iteration 380, Loss: 0.00013898745237383991, Min w: 0.9237159490585327\n",
      "Iteration 390, Loss: 7.491042197216302e-05, Min w: 0.9529850482940674\n",
      "Iteration 400, Loss: 3.8677058910252526e-05, Min w: 0.9778132438659668\n",
      "Iteration 410, Loss: 4.2496572859818116e-05, Min w: 0.9776854515075684\n",
      "Iteration 420, Loss: 6.871571531519294e-05, Min w: 0.9519068002700806\n",
      "Iteration 430, Loss: 4.336715574027039e-05, Min w: 0.9742159247398376\n",
      "Iteration 440, Loss: 0.00011039365926990286, Min w: 0.9312337636947632\n",
      "Iteration 450, Loss: 8.121940481942147e-05, Min w: 0.9502190351486206\n",
      "Iteration 460, Loss: 4.518939749686979e-05, Min w: 0.9741470813751221\n",
      "Iteration 470, Loss: 3.4633812902029604e-05, Min w: 0.978839635848999\n",
      "Iteration 480, Loss: 9.925952326739207e-05, Min w: 0.9417312145233154\n",
      "Iteration 490, Loss: 3.978044696850702e-05, Min w: 0.9749864935874939\n",
      "Iteration 500, Loss: 4.478047412703745e-05, Min w: 0.9663268327713013\n",
      "Iteration 510, Loss: 7.017356983851641e-05, Min w: 0.955000102519989\n",
      "Iteration 520, Loss: 3.076284338021651e-05, Min w: 0.9837409853935242\n",
      "Iteration 530, Loss: 7.318452844629064e-05, Min w: 0.9531479477882385\n",
      "Iteration 540, Loss: 0.00013379928714130074, Min w: 0.9276520013809204\n",
      "Iteration 550, Loss: 7.20007810741663e-05, Min w: 0.9624379873275757\n",
      "Iteration 560, Loss: 3.087159711867571e-05, Min w: 0.9838523864746094\n",
      "Iteration 570, Loss: 4.979295044904575e-05, Min w: 0.967972457408905\n",
      "Iteration 580, Loss: 5.7640390878077596e-05, Min w: 0.9569637775421143\n",
      "Iteration 590, Loss: 6.229006248759106e-05, Min w: 0.9655662178993225\n",
      "Iteration 600, Loss: 0.00019302226428408176, Min w: 0.8777600526809692\n",
      "Iteration 610, Loss: 6.586654490092769e-05, Min w: 0.9521863460540771\n",
      "Iteration 620, Loss: 5.5256576160900295e-05, Min w: 0.9656991362571716\n",
      "Iteration 630, Loss: 4.293349775252864e-05, Min w: 0.9765172004699707\n",
      "Iteration 640, Loss: 6.880090950289741e-05, Min w: 0.9570299983024597\n",
      "Iteration 650, Loss: 3.9154630940174684e-05, Min w: 0.9760600328445435\n",
      "Iteration 660, Loss: 2.8294005460338667e-05, Min w: 0.9853295087814331\n",
      "Iteration 670, Loss: 8.622236055089161e-05, Min w: 0.9403715133666992\n",
      "Iteration 680, Loss: 6.190424755914137e-05, Min w: 0.9586242437362671\n",
      "Iteration 690, Loss: 3.627936166594736e-05, Min w: 0.9803016185760498\n",
      "Iteration 700, Loss: 7.927983097033575e-05, Min w: 0.9558092951774597\n",
      "Iteration 710, Loss: 0.00014246112550608814, Min w: 0.9048172831535339\n",
      "Iteration 720, Loss: 4.7719950089231133e-05, Min w: 0.9679533243179321\n",
      "Iteration 730, Loss: 3.741451655514538e-05, Min w: 0.9749394655227661\n",
      "Iteration 740, Loss: 5.934456567047164e-05, Min w: 0.9664100408554077\n",
      "Iteration 750, Loss: 4.462949073058553e-05, Min w: 0.9697408080101013\n",
      "Iteration 760, Loss: 3.208245107089169e-05, Min w: 0.9820466637611389\n",
      "Iteration 770, Loss: 9.151478298008442e-05, Min w: 0.9354808330535889\n",
      "Iteration 780, Loss: 3.0158098525134847e-05, Min w: 0.9835571646690369\n",
      "Iteration 790, Loss: 3.2831012504175305e-05, Min w: 0.9808998703956604\n",
      "Iteration 800, Loss: 3.0307661290862598e-05, Min w: 0.9830338358879089\n",
      "Iteration 810, Loss: 0.000183594660484232, Min w: 0.9043427109718323\n",
      "Iteration 820, Loss: 3.460984953562729e-05, Min w: 0.9814281463623047\n",
      "Iteration 830, Loss: 3.978343011112884e-05, Min w: 0.9722608327865601\n",
      "Iteration 840, Loss: 4.00134886149317e-05, Min w: 0.9752013087272644\n",
      "Iteration 850, Loss: 2.348456473555416e-05, Min w: 0.986753523349762\n",
      "Iteration 860, Loss: 7.409953832393512e-05, Min w: 0.9492961168289185\n",
      "Iteration 870, Loss: 7.565109262941405e-05, Min w: 0.9427412152290344\n",
      "Iteration 880, Loss: 6.416049291146919e-05, Min w: 0.9457928538322449\n",
      "Iteration 890, Loss: 6.340398249449208e-05, Min w: 0.949225127696991\n",
      "Iteration 900, Loss: 5.170411168364808e-05, Min w: 0.963923990726471\n",
      "Iteration 910, Loss: 2.8464553906815127e-05, Min w: 0.9852957725524902\n",
      "Iteration 920, Loss: 0.00010082637891173363, Min w: 0.9335901737213135\n",
      "Iteration 930, Loss: 8.616018749307841e-05, Min w: 0.948544979095459\n",
      "Iteration 940, Loss: 8.584570605307817e-05, Min w: 0.9467369318008423\n",
      "Iteration 950, Loss: 0.00013353141548577696, Min w: 0.9031614065170288\n",
      "Iteration 960, Loss: 6.888588541187346e-05, Min w: 0.9615157842636108\n",
      "Iteration 970, Loss: 5.018790398025885e-05, Min w: 0.9688645005226135\n",
      "Iteration 980, Loss: 3.9919792470755056e-05, Min w: 0.9772289395332336\n",
      "Iteration 990, Loss: 3.643133823061362e-05, Min w: 0.9772989153862\n",
      "Iteration 1000, Loss: 8.540113776689395e-05, Min w: 0.9284425377845764\n",
      "Iteration 1010, Loss: 4.388323941384442e-05, Min w: 0.9763208031654358\n",
      "Iteration 1020, Loss: 5.4257736337604e-05, Min w: 0.9646632671356201\n",
      "Iteration 1030, Loss: 5.296337985782884e-05, Min w: 0.9631702899932861\n",
      "Iteration 1040, Loss: 4.475649620871991e-05, Min w: 0.9727741479873657\n",
      "Iteration 1050, Loss: 4.9400008720112965e-05, Min w: 0.9631085395812988\n",
      "Iteration 1060, Loss: 5.41352346772328e-05, Min w: 0.9685229659080505\n",
      "Iteration 1070, Loss: 4.626277950592339e-05, Min w: 0.9640856981277466\n",
      "Iteration 1080, Loss: 8.846477430779487e-05, Min w: 0.9471171498298645\n",
      "Iteration 1090, Loss: 4.751979577122256e-05, Min w: 0.971619725227356\n",
      "Iteration 1100, Loss: 3.774789365706965e-05, Min w: 0.9747290015220642\n",
      "Iteration 1110, Loss: 0.00014760918566025794, Min w: 0.9006349444389343\n",
      "Iteration 1120, Loss: 7.061938958941028e-05, Min w: 0.9549964666366577\n",
      "Iteration 1130, Loss: 3.416612889850512e-05, Min w: 0.9816293120384216\n",
      "Iteration 1140, Loss: 8.308370888698846e-05, Min w: 0.9565174579620361\n",
      "Iteration 1150, Loss: 4.587153671309352e-05, Min w: 0.9699307084083557\n",
      "Iteration 1160, Loss: 4.012143472209573e-05, Min w: 0.9724978804588318\n",
      "Iteration 1170, Loss: 4.4882330257678404e-05, Min w: 0.975204586982727\n",
      "Iteration 1180, Loss: 3.0046101528569125e-05, Min w: 0.9843659400939941\n",
      "Iteration 1190, Loss: 5.825982225360349e-05, Min w: 0.9657750129699707\n",
      "Iteration 1200, Loss: 0.0001691976358415559, Min w: 0.8767179846763611\n",
      "Iteration 1210, Loss: 8.204944606404752e-05, Min w: 0.9453296661376953\n",
      "Iteration 1220, Loss: 2.262824637000449e-05, Min w: 0.9880176186561584\n",
      "Iteration 1230, Loss: 3.297152943559922e-05, Min w: 0.9825308918952942\n",
      "Iteration 1240, Loss: 6.988399400142953e-05, Min w: 0.9632508754730225\n",
      "Iteration 0, Loss: 2.226750075351447e-05, Min w: 0.9864665865898132\n",
      "Iteration 10, Loss: 2.6814726879820228e-05, Min w: 0.9846436381340027\n",
      "Iteration 20, Loss: 4.050387360621244e-05, Min w: 0.9732075333595276\n",
      "Iteration 30, Loss: 5.918823444517329e-05, Min w: 0.9627227187156677\n",
      "Iteration 40, Loss: 3.339910108479671e-05, Min w: 0.9817095398902893\n",
      "Iteration 50, Loss: 3.181577267241664e-05, Min w: 0.9803085327148438\n",
      "Iteration 60, Loss: 7.221986015792936e-05, Min w: 0.9474554061889648\n",
      "Early break at iteration 63 --------------------------------\n",
      "Iteration 0, Loss: 3.8202229916350916e-05, Min w: 0.9723942279815674\n",
      "Iteration 10, Loss: 2.8096443202230148e-05, Min w: 0.9844407439231873\n",
      "Iteration 20, Loss: 4.459458068595268e-05, Min w: 0.9677054286003113\n",
      "Early break at iteration 23 --------------------------------\n",
      "Iteration 0, Loss: 2.3146598323364742e-05, Min w: 0.9842649698257446\n",
      "Iteration 10, Loss: 2.5731045752763748e-05, Min w: 0.9849055409431458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  54%|█████▍    | 13/24 [10:03<08:10, 44.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 14 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 2603, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.00805478435588871, 'L2_avg': 0.00928689046795976, 'End_point_L1_avg': 0.007538573867065099, 'End_point_L2_avg': 0.007560634868550259}\n",
      "Iteration 0, Loss: 0.00521037308499217, Min w: 1.401298464324817e-45\n",
      "Iteration 10, Loss: 0.004822843242436647, Min w: 0.0012939959997311234\n",
      "Iteration 20, Loss: 0.003678611945360899, Min w: 0.012151083908975124\n",
      "Iteration 30, Loss: 0.0030522316228598356, Min w: 1.4983033906901255e-05\n",
      "Iteration 40, Loss: 0.002709026914089918, Min w: 3.638247342285794e-11\n",
      "Iteration 50, Loss: 0.002408338012173772, Min w: 5.684332258985771e-21\n",
      "Iteration 60, Loss: 0.002213757485151291, Min w: 2.307132824125987e-39\n",
      "Iteration 70, Loss: 0.0021049214992672205, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001974215032532811, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0018360188696533442, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0017323425272479653, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0016375568229705095, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0015211651334539056, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002016606740653515, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0017544010188430548, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0013973399763926864, Min w: 1.8092178485882356e-39\n",
      "Iteration 160, Loss: 0.00134642468765378, Min w: 6.896136836464321e-23\n",
      "Iteration 170, Loss: 0.0014545726589858532, Min w: 6.342232154565863e-06\n",
      "Iteration 180, Loss: 0.0013107272097840905, Min w: 5.680145704900497e-07\n",
      "Iteration 190, Loss: 0.0013622554251924157, Min w: 0.07362014055252075\n",
      "Iteration 200, Loss: 0.0010419496102258563, Min w: 0.2985372841358185\n",
      "Iteration 210, Loss: 0.0009340717224404216, Min w: 0.4277917742729187\n",
      "Iteration 220, Loss: 0.0009141004993580282, Min w: 0.4484831392765045\n",
      "Iteration 230, Loss: 0.0007472889265045524, Min w: 0.49070408940315247\n",
      "Iteration 240, Loss: 0.0007015606970526278, Min w: 0.5249007344245911\n",
      "Iteration 250, Loss: 0.0007188317249529064, Min w: 0.5470709204673767\n",
      "Iteration 260, Loss: 0.000700591248460114, Min w: 0.5413624048233032\n",
      "Iteration 270, Loss: 0.000853416626341641, Min w: 0.5287018418312073\n",
      "Iteration 280, Loss: 0.000662207487039268, Min w: 0.6246908903121948\n",
      "Iteration 290, Loss: 0.0006474640686064959, Min w: 0.6035269498825073\n",
      "Iteration 300, Loss: 0.0005349096027202904, Min w: 0.6828011274337769\n",
      "Iteration 310, Loss: 0.0004610035684891045, Min w: 0.6718178391456604\n",
      "Iteration 320, Loss: 0.00042471260530874133, Min w: 0.7195327877998352\n",
      "Iteration 330, Loss: 0.0004323872271925211, Min w: 0.7620915770530701\n",
      "Iteration 340, Loss: 0.0006324070272967219, Min w: 0.6227277517318726\n",
      "Iteration 350, Loss: 0.0003714124613907188, Min w: 0.7463837265968323\n",
      "Iteration 360, Loss: 0.0006528486264869571, Min w: 0.6182774901390076\n",
      "Iteration 370, Loss: 0.00032040083897300065, Min w: 0.7765553593635559\n",
      "Iteration 380, Loss: 0.0006832286017015576, Min w: 0.6053837537765503\n",
      "Iteration 390, Loss: 0.00034997708280570805, Min w: 0.7614663243293762\n",
      "Iteration 400, Loss: 0.0003181759675499052, Min w: 0.837551474571228\n",
      "Iteration 410, Loss: 0.00041143977432511747, Min w: 0.744718611240387\n",
      "Iteration 420, Loss: 0.00024952940293587744, Min w: 0.8499860167503357\n",
      "Iteration 430, Loss: 0.0002773834567051381, Min w: 0.8462080359458923\n",
      "Iteration 440, Loss: 0.00033051808713935316, Min w: 0.804039716720581\n",
      "Iteration 450, Loss: 0.00043520203325897455, Min w: 0.7418872117996216\n",
      "Iteration 460, Loss: 0.00022970860300119966, Min w: 0.8603155612945557\n",
      "Iteration 470, Loss: 0.00021737262431997806, Min w: 0.8887934684753418\n",
      "Iteration 480, Loss: 0.00025838211877271533, Min w: 0.855675458908081\n",
      "Iteration 490, Loss: 0.0002791685110423714, Min w: 0.8308468461036682\n",
      "Iteration 500, Loss: 0.00022213617921806872, Min w: 0.8832069635391235\n",
      "Iteration 510, Loss: 0.0002652932016644627, Min w: 0.8559415340423584\n",
      "Iteration 520, Loss: 0.00015633023576810956, Min w: 0.9162017703056335\n",
      "Iteration 530, Loss: 0.00015321627142839134, Min w: 0.9122565388679504\n",
      "Iteration 540, Loss: 0.00015761608665343374, Min w: 0.9096043109893799\n",
      "Iteration 550, Loss: 0.0002486669400241226, Min w: 0.8597986698150635\n",
      "Iteration 560, Loss: 0.0002032112388405949, Min w: 0.863153338432312\n",
      "Iteration 570, Loss: 0.00014718154852744192, Min w: 0.9045111536979675\n",
      "Iteration 580, Loss: 0.00015016253746580333, Min w: 0.9052090644836426\n",
      "Iteration 590, Loss: 0.0003338791138958186, Min w: 0.8149286508560181\n",
      "Iteration 600, Loss: 0.0002173834218410775, Min w: 0.874694287776947\n",
      "Iteration 610, Loss: 0.00025171192828565836, Min w: 0.832676887512207\n",
      "Iteration 620, Loss: 0.00017575651872903109, Min w: 0.8851340413093567\n",
      "Iteration 630, Loss: 0.00013065757229924202, Min w: 0.9262354373931885\n",
      "Iteration 640, Loss: 0.00022311764769256115, Min w: 0.8656944632530212\n",
      "Iteration 650, Loss: 0.00017614361422602087, Min w: 0.8958771228790283\n",
      "Iteration 660, Loss: 0.00015181180788204074, Min w: 0.9008698463439941\n",
      "Iteration 670, Loss: 0.00010864439536817372, Min w: 0.9300243854522705\n",
      "Iteration 680, Loss: 0.00015409359184559435, Min w: 0.913296639919281\n",
      "Iteration 690, Loss: 9.890250657917932e-05, Min w: 0.9385327696800232\n",
      "Iteration 700, Loss: 0.00014492035552393645, Min w: 0.922278106212616\n",
      "Iteration 710, Loss: 9.590834815753624e-05, Min w: 0.9482976794242859\n",
      "Iteration 720, Loss: 0.00022989948047325015, Min w: 0.8638755083084106\n",
      "Iteration 730, Loss: 0.00010261477291351184, Min w: 0.942996621131897\n",
      "Iteration 740, Loss: 0.00027211738051846623, Min w: 0.8496668338775635\n",
      "Iteration 750, Loss: 8.790074207354337e-05, Min w: 0.9449627995491028\n",
      "Iteration 760, Loss: 0.00019646462169475853, Min w: 0.8908235430717468\n",
      "Iteration 770, Loss: 7.702974835410714e-05, Min w: 0.9594864845275879\n",
      "Iteration 780, Loss: 0.00011512915807543322, Min w: 0.9402404427528381\n",
      "Iteration 790, Loss: 0.0002468400925863534, Min w: 0.8698034882545471\n",
      "Iteration 800, Loss: 0.00013162146206013858, Min w: 0.9075793623924255\n",
      "Iteration 810, Loss: 7.467757677659392e-05, Min w: 0.9562162756919861\n",
      "Iteration 820, Loss: 6.524447962874547e-05, Min w: 0.9620578289031982\n",
      "Iteration 830, Loss: 0.0001904909295262769, Min w: 0.8948772549629211\n",
      "Iteration 840, Loss: 0.00017143777222372591, Min w: 0.9029532074928284\n",
      "Iteration 850, Loss: 0.0003033043467439711, Min w: 0.7819111943244934\n",
      "Iteration 860, Loss: 7.788310904288664e-05, Min w: 0.9593982100486755\n",
      "Iteration 870, Loss: 6.944737106096e-05, Min w: 0.9616774916648865\n",
      "Iteration 880, Loss: 7.907392136985436e-05, Min w: 0.9503088593482971\n",
      "Iteration 890, Loss: 9.037488780450076e-05, Min w: 0.952233076095581\n",
      "Iteration 900, Loss: 6.335966463666409e-05, Min w: 0.9642225503921509\n",
      "Iteration 910, Loss: 6.701170786982402e-05, Min w: 0.959282398223877\n",
      "Iteration 920, Loss: 8.278518362203613e-05, Min w: 0.9506220817565918\n",
      "Iteration 930, Loss: 5.8695051848189905e-05, Min w: 0.9698479175567627\n",
      "Iteration 940, Loss: 0.00011032533802790567, Min w: 0.9287344217300415\n",
      "Iteration 950, Loss: 6.561165355378762e-05, Min w: 0.9568971395492554\n",
      "Iteration 960, Loss: 0.00013257900718599558, Min w: 0.9170691967010498\n",
      "Iteration 970, Loss: 0.00018617790192365646, Min w: 0.8990601897239685\n",
      "Iteration 980, Loss: 8.202610479202121e-05, Min w: 0.9558321237564087\n",
      "Iteration 990, Loss: 0.00015174811414908618, Min w: 0.9095344543457031\n",
      "Iteration 1000, Loss: 5.461848559207283e-05, Min w: 0.9683392643928528\n",
      "Iteration 1010, Loss: 0.00016119010979309678, Min w: 0.8841723203659058\n",
      "Iteration 1020, Loss: 7.304483006009832e-05, Min w: 0.9619527459144592\n",
      "Iteration 1030, Loss: 0.0001809108507586643, Min w: 0.8801679015159607\n",
      "Iteration 1040, Loss: 5.037552546127699e-05, Min w: 0.9737743139266968\n",
      "Iteration 1050, Loss: 0.0001399322209181264, Min w: 0.9173434972763062\n",
      "Iteration 1060, Loss: 7.396669388981536e-05, Min w: 0.954817533493042\n",
      "Iteration 1070, Loss: 4.284172609914094e-05, Min w: 0.976198673248291\n",
      "Iteration 1080, Loss: 0.00026536910445429385, Min w: 0.8439950346946716\n",
      "Iteration 1090, Loss: 5.766739195678383e-05, Min w: 0.9700281620025635\n",
      "Iteration 1100, Loss: 0.00019658867677208036, Min w: 0.886225700378418\n",
      "Iteration 1110, Loss: 6.781720003345981e-05, Min w: 0.9591498970985413\n",
      "Iteration 1120, Loss: 0.00013388476509135216, Min w: 0.9225228428840637\n",
      "Iteration 1130, Loss: 0.00010553746687946841, Min w: 0.9225223064422607\n",
      "Iteration 1140, Loss: 0.0001139413652708754, Min w: 0.9317421913146973\n",
      "Iteration 1150, Loss: 6.687633140245453e-05, Min w: 0.9575189352035522\n",
      "Iteration 1160, Loss: 7.920822827145457e-05, Min w: 0.9477812051773071\n",
      "Iteration 1170, Loss: 5.193385004531592e-05, Min w: 0.9717856049537659\n",
      "Iteration 1180, Loss: 0.000235633400734514, Min w: 0.859861433506012\n",
      "Iteration 1190, Loss: 0.00015483921742998064, Min w: 0.8946543335914612\n",
      "Iteration 1200, Loss: 4.114569674129598e-05, Min w: 0.9757360816001892\n",
      "Iteration 1210, Loss: 8.395030454266816e-05, Min w: 0.9500388503074646\n",
      "Iteration 1220, Loss: 8.255983993876725e-05, Min w: 0.9499260783195496\n",
      "Iteration 1230, Loss: 4.5676049921894446e-05, Min w: 0.9721457958221436\n",
      "Iteration 1240, Loss: 0.00013175034837331623, Min w: 0.9248304963111877\n",
      "Iteration 0, Loss: 5.759303894592449e-05, Min w: 0.9607305526733398\n",
      "Iteration 10, Loss: 3.952248516725376e-05, Min w: 0.9794496893882751\n",
      "Iteration 20, Loss: 5.49764845345635e-05, Min w: 0.9622334837913513\n",
      "Iteration 30, Loss: 4.1996350773843005e-05, Min w: 0.9740375280380249\n",
      "Iteration 40, Loss: 3.8541362300748006e-05, Min w: 0.9779919981956482\n",
      "Iteration 50, Loss: 0.00011418093345128, Min w: 0.9371490478515625\n",
      "Iteration 60, Loss: 6.16322795394808e-05, Min w: 0.9637489914894104\n",
      "Iteration 70, Loss: 6.351108459057286e-05, Min w: 0.959263265132904\n",
      "Iteration 80, Loss: 4.9525173380970955e-05, Min w: 0.9646437764167786\n",
      "Iteration 90, Loss: 3.7478672311408445e-05, Min w: 0.9755408763885498\n",
      "Iteration 100, Loss: 9.400604176335037e-05, Min w: 0.9402688145637512\n",
      "Iteration 110, Loss: 4.73317013529595e-05, Min w: 0.9739137291908264\n",
      "Iteration 120, Loss: 4.61261224700138e-05, Min w: 0.9740598201751709\n",
      "Iteration 130, Loss: 0.00011619743600022048, Min w: 0.9227123260498047\n",
      "Iteration 140, Loss: 3.27961788570974e-05, Min w: 0.9829216599464417\n",
      "Iteration 150, Loss: 0.00018931612430606037, Min w: 0.8991304039955139\n",
      "Iteration 160, Loss: 0.00012148053792770952, Min w: 0.9200624227523804\n",
      "Iteration 170, Loss: 8.578378037782386e-05, Min w: 0.9380074143409729\n",
      "Iteration 180, Loss: 3.030645711987745e-05, Min w: 0.9819313883781433\n",
      "Iteration 190, Loss: 0.00013180205132812262, Min w: 0.9301902651786804\n",
      "Iteration 200, Loss: 2.86184367723763e-05, Min w: 0.9838383793830872\n",
      "Iteration 210, Loss: 3.424446185817942e-05, Min w: 0.9767354726791382\n",
      "Iteration 220, Loss: 0.00014664763875771314, Min w: 0.9086127877235413\n",
      "Iteration 230, Loss: 9.91296983556822e-05, Min w: 0.928505539894104\n",
      "Iteration 240, Loss: 5.605069236480631e-05, Min w: 0.9605692625045776\n",
      "Iteration 250, Loss: 2.892375414376147e-05, Min w: 0.982596755027771\n",
      "Iteration 260, Loss: 6.274330371525139e-05, Min w: 0.9598963856697083\n",
      "Iteration 270, Loss: 8.282151975436136e-05, Min w: 0.955782949924469\n",
      "Iteration 280, Loss: 2.5609508156776428e-05, Min w: 0.9861020445823669\n",
      "Iteration 290, Loss: 3.145371374557726e-05, Min w: 0.9781818389892578\n",
      "Iteration 300, Loss: 2.961121208500117e-05, Min w: 0.9843947887420654\n",
      "Iteration 310, Loss: 0.00014537516108248383, Min w: 0.9248844385147095\n",
      "Iteration 320, Loss: 0.00015532891848124564, Min w: 0.8790647387504578\n",
      "Iteration 330, Loss: 3.573143112589605e-05, Min w: 0.9754565954208374\n",
      "Iteration 340, Loss: 2.8491054763435386e-05, Min w: 0.9822900295257568\n",
      "Iteration 350, Loss: 5.5811287893448025e-05, Min w: 0.9643111228942871\n",
      "Iteration 360, Loss: 0.00013682353892363608, Min w: 0.9269891977310181\n",
      "Iteration 370, Loss: 0.00017615745309740305, Min w: 0.9010521173477173\n",
      "Iteration 380, Loss: 4.3443607864901423e-05, Min w: 0.9726700782775879\n",
      "Iteration 390, Loss: 2.9342616471694782e-05, Min w: 0.9794856309890747\n",
      "Iteration 400, Loss: 2.3223892640089616e-05, Min w: 0.9857009649276733\n",
      "Iteration 410, Loss: 2.2230071408557706e-05, Min w: 0.9880921840667725\n",
      "Iteration 420, Loss: 9.392313950229436e-05, Min w: 0.939693033695221\n",
      "Iteration 430, Loss: 3.605714664445259e-05, Min w: 0.978409469127655\n",
      "Iteration 440, Loss: 5.159050851943903e-05, Min w: 0.9686352014541626\n",
      "Iteration 450, Loss: 4.701638317783363e-05, Min w: 0.9706178903579712\n",
      "Iteration 460, Loss: 0.00010990112059516832, Min w: 0.9358034729957581\n",
      "Iteration 470, Loss: 7.530718721682206e-05, Min w: 0.937038004398346\n",
      "Iteration 480, Loss: 4.976594937033951e-05, Min w: 0.9657984972000122\n",
      "Iteration 490, Loss: 3.0232207791414112e-05, Min w: 0.9821553230285645\n",
      "Iteration 500, Loss: 0.00016350408259313554, Min w: 0.8754954934120178\n",
      "Iteration 510, Loss: 9.631423745304346e-05, Min w: 0.9351949095726013\n",
      "Iteration 520, Loss: 7.169203308876604e-05, Min w: 0.9540982842445374\n",
      "Iteration 530, Loss: 3.0017872632015496e-05, Min w: 0.9832006096839905\n",
      "Early break at iteration 534 --------------------------------\n",
      "Iteration 0, Loss: 1.9568607967812568e-05, Min w: 0.9896317720413208\n",
      "Iteration 10, Loss: 4.176907896180637e-05, Min w: 0.9669570326805115\n",
      "Iteration 20, Loss: 4.242061550030485e-05, Min w: 0.9738238453865051\n",
      "Iteration 30, Loss: 0.00010301609290763736, Min w: 0.9210347533226013\n",
      "Iteration 40, Loss: 0.00020446089911274612, Min w: 0.8867825865745544\n",
      "Iteration 50, Loss: 5.405084084486589e-05, Min w: 0.9583547711372375\n",
      "Iteration 60, Loss: 2.6697873181547038e-05, Min w: 0.9824557304382324\n",
      "Iteration 70, Loss: 2.8397746064001694e-05, Min w: 0.9809943437576294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  58%|█████▊    | 14/24 [10:21<06:05, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80, Loss: 2.914509786933195e-05, Min w: 0.980238139629364\n",
      "Iteration 90, Loss: 1.8523696780903265e-05, Min w: 0.9897494912147522\n",
      "Early break at iteration 91 --------------------------------\n",
      "Iteration 0, Loss: 1.7313675925834104e-05, Min w: 0.9907891154289246\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.745073495840188e-05, Min w: 0.9905067682266235\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 1879, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.007973788323163736, 'L2_avg': 0.009400342031967652, 'End_point_L1_avg': 0.008866475014371065, 'End_point_L2_avg': 0.009600185948880895}\n",
      "Iteration 0, Loss: 0.0011357958428561687, Min w: 0.0\n",
      "Iteration 10, Loss: 0.001082167262211442, Min w: 5.045047780565336e-32\n",
      "Iteration 20, Loss: 0.0009365868172608316, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008154454990290105, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006441433797590435, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006024204194545746, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005506044835783541, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005214494303800166, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0004922535154037178, Min w: 0.0\n",
      "Iteration 90, Loss: 0.00047510318108834326, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0004548937431536615, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000481176539324224, Min w: 0.0\n",
      "Iteration 120, Loss: 0.00042118263081647456, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0004008261894341558, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0003991916310042143, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00045672510168515146, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0003954533312935382, Min w: 0.0\n",
      "Iteration 170, Loss: 0.00042452389607205987, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005562906735576689, Min w: 0.0\n",
      "Iteration 190, Loss: 0.000502708600834012, Min w: 0.0\n",
      "Iteration 200, Loss: 0.000416316936025396, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00043684334377758205, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0004429260443430394, Min w: 1.4979880583632294e-42\n",
      "Iteration 230, Loss: 0.0003596378373913467, Min w: 6.167307769451645e-17\n",
      "Iteration 240, Loss: 0.0003730746393557638, Min w: 1.5434890698884374e-08\n",
      "Iteration 250, Loss: 0.00040241950773634017, Min w: 1.7847163312258916e-27\n",
      "Iteration 260, Loss: 0.0003817040997091681, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00040769134648144245, Min w: 4.488773317162321e-37\n",
      "Iteration 280, Loss: 0.00034437834983691573, Min w: 8.587838466161156e-33\n",
      "Iteration 290, Loss: 0.00036707683466374874, Min w: 2.7033997921312653e-31\n",
      "Iteration 300, Loss: 0.0003602625511121005, Min w: 1.366645477616696e-22\n",
      "Iteration 310, Loss: 0.0003524096682667732, Min w: 9.551348654031404e-17\n",
      "Iteration 320, Loss: 0.00037930585676804185, Min w: 3.6250724644304455e-11\n",
      "Iteration 330, Loss: 0.000370582944015041, Min w: 0.00010960019426420331\n",
      "Iteration 340, Loss: 0.00034781621070578694, Min w: 0.06653066724538803\n",
      "Iteration 350, Loss: 0.00034928525565192103, Min w: 0.10053624957799911\n",
      "Iteration 360, Loss: 0.0002826160052791238, Min w: 0.1533847600221634\n",
      "Iteration 370, Loss: 0.0003776222874876112, Min w: 0.17002291977405548\n",
      "Iteration 380, Loss: 0.0002981661818921566, Min w: 0.2606642544269562\n",
      "Iteration 390, Loss: 0.00025832329993136227, Min w: 0.25949397683143616\n",
      "Iteration 400, Loss: 0.0002516192616894841, Min w: 0.3135751485824585\n",
      "Iteration 410, Loss: 0.0003572646528482437, Min w: 0.31176337599754333\n",
      "Iteration 420, Loss: 0.0003003115998581052, Min w: 0.29477810859680176\n",
      "Iteration 430, Loss: 0.0003230363945476711, Min w: 0.33144399523735046\n",
      "Iteration 440, Loss: 0.00023261459136847407, Min w: 0.3517216742038727\n",
      "Iteration 450, Loss: 0.00025586658739484847, Min w: 0.3564160466194153\n",
      "Iteration 460, Loss: 0.0002413005131529644, Min w: 0.4183586835861206\n",
      "Iteration 470, Loss: 0.00021292049495968968, Min w: 0.4352465271949768\n",
      "Iteration 480, Loss: 0.00023203351884149015, Min w: 0.4154853820800781\n",
      "Iteration 490, Loss: 0.00027499356656335294, Min w: 0.42506635189056396\n",
      "Iteration 500, Loss: 0.00020639346621464938, Min w: 0.44184231758117676\n",
      "Iteration 510, Loss: 0.00018969735538121313, Min w: 0.5310940146446228\n",
      "Iteration 520, Loss: 0.00018797737720888108, Min w: 0.5305216312408447\n",
      "Iteration 530, Loss: 0.00017717383161652833, Min w: 0.5510891675949097\n",
      "Iteration 540, Loss: 0.00022273528156802058, Min w: 0.5303219556808472\n",
      "Iteration 550, Loss: 0.00021577576990239322, Min w: 0.5066512823104858\n",
      "Iteration 560, Loss: 0.00020432201563380659, Min w: 0.44563427567481995\n",
      "Iteration 570, Loss: 0.00018736078345682472, Min w: 0.5360202193260193\n",
      "Iteration 580, Loss: 0.00020914815831929445, Min w: 0.5232920050621033\n",
      "Iteration 590, Loss: 0.00020068068988621235, Min w: 0.5118921399116516\n",
      "Iteration 600, Loss: 0.00019457282905932516, Min w: 0.5541642904281616\n",
      "Iteration 610, Loss: 0.00017862067034002393, Min w: 0.6074244379997253\n",
      "Iteration 620, Loss: 0.00014774831652175635, Min w: 0.6455894112586975\n",
      "Iteration 630, Loss: 0.00016430921095889062, Min w: 0.6465460658073425\n",
      "Iteration 640, Loss: 0.0001951558660948649, Min w: 0.5369951128959656\n",
      "Iteration 650, Loss: 0.00017813775048125535, Min w: 0.5836230516433716\n",
      "Iteration 660, Loss: 0.00015243128291331232, Min w: 0.6208128929138184\n",
      "Iteration 670, Loss: 0.0001663785515120253, Min w: 0.6403864622116089\n",
      "Iteration 680, Loss: 0.00016061471251305193, Min w: 0.6479874849319458\n",
      "Iteration 690, Loss: 0.00015103715122677386, Min w: 0.6342024207115173\n",
      "Iteration 700, Loss: 0.0001651161874178797, Min w: 0.6123720407485962\n",
      "Iteration 710, Loss: 0.00014145023305900395, Min w: 0.6916930079460144\n",
      "Iteration 720, Loss: 0.0001679117267485708, Min w: 0.5384688973426819\n",
      "Iteration 730, Loss: 0.00014149911294225603, Min w: 0.7097840309143066\n",
      "Iteration 740, Loss: 0.000166577854542993, Min w: 0.6121002435684204\n",
      "Iteration 750, Loss: 0.0001861266791820526, Min w: 0.5746143460273743\n",
      "Iteration 760, Loss: 0.0001635470543988049, Min w: 0.6360740065574646\n",
      "Iteration 770, Loss: 0.0001577112270751968, Min w: 0.6534826755523682\n",
      "Iteration 780, Loss: 0.00017112380010075867, Min w: 0.6028264760971069\n",
      "Iteration 790, Loss: 0.00013749119534622878, Min w: 0.6669737100601196\n",
      "Iteration 800, Loss: 0.00010854026186279953, Min w: 0.774339497089386\n",
      "Iteration 810, Loss: 0.00014353948063217103, Min w: 0.6807006001472473\n",
      "Iteration 820, Loss: 0.0001280526485061273, Min w: 0.7281051278114319\n",
      "Iteration 830, Loss: 0.00017731758998706937, Min w: 0.579837441444397\n",
      "Iteration 840, Loss: 0.0001169384631793946, Min w: 0.7393203377723694\n",
      "Iteration 850, Loss: 0.0001007198661682196, Min w: 0.7925131916999817\n",
      "Iteration 860, Loss: 0.00010518482304178178, Min w: 0.7767137885093689\n",
      "Iteration 870, Loss: 0.00010180265962844715, Min w: 0.7817493677139282\n",
      "Iteration 880, Loss: 0.00013798702275380492, Min w: 0.657496988773346\n",
      "Iteration 890, Loss: 0.00014645737246610224, Min w: 0.676324725151062\n",
      "Iteration 900, Loss: 0.00013052865688223392, Min w: 0.7135531306266785\n",
      "Iteration 910, Loss: 0.00011925314174732193, Min w: 0.7296066284179688\n",
      "Iteration 920, Loss: 0.0001465540553908795, Min w: 0.6945117115974426\n",
      "Iteration 930, Loss: 0.00015149479440879077, Min w: 0.6522961854934692\n",
      "Iteration 940, Loss: 0.00014016915520187467, Min w: 0.6781013607978821\n",
      "Iteration 950, Loss: 0.00013929751003161073, Min w: 0.6376524567604065\n",
      "Iteration 960, Loss: 0.00013376050628721714, Min w: 0.6681174039840698\n",
      "Iteration 970, Loss: 0.00010692529031075537, Min w: 0.7193088531494141\n",
      "Iteration 980, Loss: 0.00016589474398642778, Min w: 0.613257884979248\n",
      "Iteration 990, Loss: 0.00010070654388982803, Min w: 0.752029299736023\n",
      "Iteration 1000, Loss: 0.0001314376713708043, Min w: 0.7308017015457153\n",
      "Iteration 1010, Loss: 0.00011230155359953642, Min w: 0.6927308440208435\n",
      "Iteration 1020, Loss: 0.00014926024596206844, Min w: 0.6753020286560059\n",
      "Iteration 1030, Loss: 0.00011437418288551271, Min w: 0.7599442005157471\n",
      "Iteration 1040, Loss: 9.452839731238782e-05, Min w: 0.7888423204421997\n",
      "Iteration 1050, Loss: 9.735313506098464e-05, Min w: 0.7659021615982056\n",
      "Iteration 1060, Loss: 0.00010479494812898338, Min w: 0.7744579315185547\n",
      "Iteration 1070, Loss: 0.00010917095642071217, Min w: 0.7693602442741394\n",
      "Iteration 1080, Loss: 0.00012537553266156465, Min w: 0.6949058175086975\n",
      "Iteration 1090, Loss: 0.0001091844096663408, Min w: 0.7165651321411133\n",
      "Iteration 1100, Loss: 0.00010839282185770571, Min w: 0.7175048589706421\n",
      "Iteration 1110, Loss: 9.071723616216332e-05, Min w: 0.8123819231987\n",
      "Iteration 1120, Loss: 7.61110641178675e-05, Min w: 0.8337516188621521\n",
      "Iteration 1130, Loss: 5.588095882558264e-05, Min w: 0.8731157183647156\n",
      "Iteration 1140, Loss: 0.00011713362619047984, Min w: 0.7257032990455627\n",
      "Iteration 1150, Loss: 0.0001232201320817694, Min w: 0.710318386554718\n",
      "Iteration 1160, Loss: 9.754039638210088e-05, Min w: 0.7628040313720703\n",
      "Iteration 1170, Loss: 0.00010229158942820504, Min w: 0.7321085333824158\n",
      "Iteration 1180, Loss: 0.0001282612793147564, Min w: 0.6712988615036011\n",
      "Iteration 1190, Loss: 0.00012740302190650254, Min w: 0.7334656119346619\n",
      "Iteration 1200, Loss: 8.675573917571455e-05, Min w: 0.7720423936843872\n",
      "Iteration 1210, Loss: 7.45617289794609e-05, Min w: 0.8047509789466858\n",
      "Iteration 1220, Loss: 0.0001470055285608396, Min w: 0.6864009499549866\n",
      "Iteration 1230, Loss: 5.09465389768593e-05, Min w: 0.8816778659820557\n",
      "Iteration 1240, Loss: 7.784522313158959e-05, Min w: 0.8119946718215942\n",
      "Iteration 0, Loss: 0.00011478157830424607, Min w: 0.6541363596916199\n",
      "Iteration 10, Loss: 0.0001619430840946734, Min w: 0.6388123035430908\n",
      "Iteration 20, Loss: 0.00010214020585408434, Min w: 0.7095725536346436\n",
      "Iteration 30, Loss: 9.578159369993955e-05, Min w: 0.7921952605247498\n",
      "Iteration 40, Loss: 0.00016070080164354295, Min w: 0.5404530763626099\n",
      "Iteration 50, Loss: 0.0002264108625240624, Min w: 0.42765694856643677\n",
      "Iteration 60, Loss: 0.0003238852077629417, Min w: 0.2344392091035843\n",
      "Iteration 70, Loss: 0.0003461680607870221, Min w: 0.24674947559833527\n",
      "Iteration 80, Loss: 0.0003007069753948599, Min w: 0.3494880199432373\n",
      "Iteration 90, Loss: 0.0003548561071511358, Min w: 0.17904488742351532\n",
      "Iteration 100, Loss: 0.00022913662542123348, Min w: 0.4298090934753418\n",
      "Iteration 110, Loss: 0.00047442791401408613, Min w: 0.026530152186751366\n",
      "Iteration 120, Loss: 0.000361964397598058, Min w: 0.17155839502811432\n",
      "Iteration 130, Loss: 0.0003458558931015432, Min w: 0.2674655616283417\n",
      "Iteration 140, Loss: 0.00026538988458923995, Min w: 0.40240252017974854\n",
      "Iteration 150, Loss: 0.0002656427095644176, Min w: 0.3897753059864044\n",
      "Iteration 160, Loss: 0.0002727982646320015, Min w: 0.3782137930393219\n",
      "Iteration 170, Loss: 0.0001448962721042335, Min w: 0.6041326522827148\n",
      "Iteration 180, Loss: 6.642015796387568e-05, Min w: 0.8442733287811279\n",
      "Iteration 190, Loss: 7.050036947475746e-05, Min w: 0.8314302563667297\n",
      "Iteration 200, Loss: 6.743068661307916e-05, Min w: 0.8561065196990967\n",
      "Iteration 210, Loss: 5.636727291857824e-05, Min w: 0.8568372130393982\n",
      "Iteration 220, Loss: 5.447433431982063e-05, Min w: 0.867372989654541\n",
      "Iteration 230, Loss: 5.2935291023459285e-05, Min w: 0.8680225610733032\n",
      "Iteration 240, Loss: 5.1048496970906854e-05, Min w: 0.8709401488304138\n",
      "Iteration 250, Loss: 5.119586057844572e-05, Min w: 0.866930365562439\n",
      "Iteration 260, Loss: 4.9882743041962385e-05, Min w: 0.8800143003463745\n",
      "Iteration 270, Loss: 4.661358252633363e-05, Min w: 0.8803545236587524\n",
      "Iteration 280, Loss: 4.515781984082423e-05, Min w: 0.8865141272544861\n",
      "Iteration 290, Loss: 4.442585850483738e-05, Min w: 0.8911480903625488\n",
      "Iteration 300, Loss: 4.3736741645261645e-05, Min w: 0.8897354006767273\n",
      "Iteration 310, Loss: 4.447385799721815e-05, Min w: 0.8916016221046448\n",
      "Iteration 320, Loss: 4.2715768358903006e-05, Min w: 0.8898638486862183\n",
      "Iteration 330, Loss: 4.467002145247534e-05, Min w: 0.8995358943939209\n",
      "Iteration 340, Loss: 6.697911157971248e-05, Min w: 0.8454102277755737\n",
      "Iteration 350, Loss: 5.211555981077254e-05, Min w: 0.8913596272468567\n",
      "Iteration 360, Loss: 5.7714783906703815e-05, Min w: 0.8673237562179565\n",
      "Iteration 370, Loss: 5.4065058066044e-05, Min w: 0.8734862804412842\n",
      "Iteration 380, Loss: 3.81659010599833e-05, Min w: 0.9107508659362793\n",
      "Iteration 390, Loss: 3.508649024297483e-05, Min w: 0.9179648756980896\n",
      "Iteration 400, Loss: 9.961812611436471e-05, Min w: 0.7261559367179871\n",
      "Iteration 410, Loss: 7.367739453911781e-05, Min w: 0.8282043933868408\n",
      "Iteration 420, Loss: 5.2732146286871284e-05, Min w: 0.8736234903335571\n",
      "Iteration 430, Loss: 6.126309017417952e-05, Min w: 0.846720278263092\n",
      "Iteration 440, Loss: 4.406587686389685e-05, Min w: 0.8990535140037537\n",
      "Iteration 450, Loss: 5.758099359809421e-05, Min w: 0.8418510556221008\n",
      "Iteration 460, Loss: 7.080264913383871e-05, Min w: 0.8515883684158325\n",
      "Iteration 470, Loss: 6.197555194376037e-05, Min w: 0.861663818359375\n",
      "Iteration 480, Loss: 5.617145143332891e-05, Min w: 0.8487710356712341\n",
      "Iteration 490, Loss: 5.6554392358521e-05, Min w: 0.8730006814002991\n",
      "Iteration 500, Loss: 3.53614377672784e-05, Min w: 0.9240764379501343\n",
      "Iteration 510, Loss: 9.233188757207245e-05, Min w: 0.7794417142868042\n",
      "Iteration 520, Loss: 8.817776688374579e-05, Min w: 0.8079433441162109\n",
      "Iteration 530, Loss: 6.370082701323554e-05, Min w: 0.8468554615974426\n",
      "Iteration 540, Loss: 6.483906327048317e-05, Min w: 0.8349820375442505\n",
      "Iteration 550, Loss: 5.143904127180576e-05, Min w: 0.8736514449119568\n",
      "Iteration 560, Loss: 5.871511893928982e-05, Min w: 0.857444167137146\n",
      "Iteration 570, Loss: 5.40219152753707e-05, Min w: 0.8889338374137878\n",
      "Iteration 580, Loss: 5.828896973980591e-05, Min w: 0.8433141708374023\n",
      "Iteration 590, Loss: 4.695487587014213e-05, Min w: 0.8731282353401184\n",
      "Iteration 600, Loss: 7.483286026399583e-05, Min w: 0.8376379013061523\n",
      "Iteration 610, Loss: 6.457344716181979e-05, Min w: 0.8016912937164307\n",
      "Iteration 620, Loss: 8.362761582247913e-05, Min w: 0.7959953546524048\n",
      "Iteration 630, Loss: 3.944649870391004e-05, Min w: 0.9042555093765259\n",
      "Iteration 640, Loss: 5.172680175746791e-05, Min w: 0.8618764281272888\n",
      "Iteration 650, Loss: 5.166927439859137e-05, Min w: 0.882236123085022\n",
      "Iteration 660, Loss: 6.479515286628157e-05, Min w: 0.8521800637245178\n",
      "Iteration 670, Loss: 5.848235377925448e-05, Min w: 0.877140462398529\n",
      "Iteration 680, Loss: 7.035081944195554e-05, Min w: 0.846966028213501\n",
      "Iteration 690, Loss: 4.6424214815488085e-05, Min w: 0.8756842017173767\n",
      "Iteration 700, Loss: 6.724958802806213e-05, Min w: 0.7999244928359985\n",
      "Iteration 710, Loss: 3.6052570067113265e-05, Min w: 0.9100304245948792\n",
      "Iteration 720, Loss: 5.458643499878235e-05, Min w: 0.8630113005638123\n",
      "Iteration 730, Loss: 4.7104178520385176e-05, Min w: 0.8809744119644165\n",
      "Iteration 740, Loss: 2.523479088267777e-05, Min w: 0.946684718132019\n",
      "Iteration 750, Loss: 8.198866271413863e-05, Min w: 0.8057050108909607\n",
      "Iteration 760, Loss: 4.337087375461124e-05, Min w: 0.8820444345474243\n",
      "Iteration 770, Loss: 8.448256267001852e-05, Min w: 0.759436845779419\n",
      "Iteration 780, Loss: 0.00011956765229115263, Min w: 0.6287146806716919\n",
      "Iteration 790, Loss: 2.9685363188036717e-05, Min w: 0.9307436347007751\n",
      "Iteration 800, Loss: 8.677042933413759e-05, Min w: 0.8036091327667236\n",
      "Iteration 810, Loss: 4.5413613406708464e-05, Min w: 0.8843416571617126\n",
      "Iteration 820, Loss: 7.822301267879084e-05, Min w: 0.7871605157852173\n",
      "Iteration 830, Loss: 4.904780143988319e-05, Min w: 0.8667947053909302\n",
      "Iteration 840, Loss: 9.452441008761525e-05, Min w: 0.7490704655647278\n",
      "Iteration 850, Loss: 2.4934379325713962e-05, Min w: 0.9437166452407837\n",
      "Iteration 860, Loss: 2.3874117687228136e-05, Min w: 0.9395118355751038\n",
      "Iteration 870, Loss: 6.425981700886041e-05, Min w: 0.8058199286460876\n",
      "Iteration 880, Loss: 7.852626004023477e-05, Min w: 0.7437885999679565\n",
      "Iteration 890, Loss: 7.815894787199795e-05, Min w: 0.7924268841743469\n",
      "Iteration 900, Loss: 4.475440800888464e-05, Min w: 0.8851885199546814\n",
      "Iteration 910, Loss: 7.26698272046633e-05, Min w: 0.7577468752861023\n",
      "Iteration 920, Loss: 7.203542918432504e-05, Min w: 0.7987404465675354\n",
      "Iteration 930, Loss: 9.530022362014279e-05, Min w: 0.781302273273468\n",
      "Iteration 940, Loss: 3.7470843381015584e-05, Min w: 0.9184445738792419\n",
      "Iteration 950, Loss: 4.280679058865644e-05, Min w: 0.8695581555366516\n",
      "Iteration 960, Loss: 7.571240712422878e-05, Min w: 0.8206009268760681\n",
      "Iteration 970, Loss: 6.873862730572e-05, Min w: 0.8127856254577637\n",
      "Iteration 980, Loss: 3.9300535718211904e-05, Min w: 0.8899177312850952\n",
      "Iteration 990, Loss: 8.238424925366417e-05, Min w: 0.8244621157646179\n",
      "Iteration 1000, Loss: 2.8278187528485432e-05, Min w: 0.9210829734802246\n",
      "Iteration 1010, Loss: 2.3956616132636555e-05, Min w: 0.9389774203300476\n",
      "Iteration 1020, Loss: 3.274738628533669e-05, Min w: 0.9112244844436646\n",
      "Iteration 1030, Loss: 3.728953379322775e-05, Min w: 0.8962368369102478\n",
      "Iteration 1040, Loss: 6.152000423753634e-05, Min w: 0.8228771090507507\n",
      "Iteration 1050, Loss: 7.306870975298807e-05, Min w: 0.7533106207847595\n",
      "Iteration 1060, Loss: 4.4186530431034043e-05, Min w: 0.8876617550849915\n",
      "Iteration 1070, Loss: 9.218092600349337e-05, Min w: 0.7658370733261108\n",
      "Iteration 1080, Loss: 2.425643651804421e-05, Min w: 0.9367352724075317\n",
      "Iteration 1090, Loss: 4.395129872136749e-05, Min w: 0.869516909122467\n",
      "Iteration 1100, Loss: 3.1769537599757314e-05, Min w: 0.9206129312515259\n",
      "Iteration 1110, Loss: 3.5270044463686645e-05, Min w: 0.8999090790748596\n",
      "Iteration 1120, Loss: 3.914531407644972e-05, Min w: 0.8784236907958984\n",
      "Iteration 1130, Loss: 5.213751137489453e-05, Min w: 0.8433555364608765\n",
      "Iteration 1140, Loss: 6.036964259692468e-05, Min w: 0.8673673272132874\n",
      "Iteration 1150, Loss: 4.5629356463905424e-05, Min w: 0.8477725982666016\n",
      "Iteration 1160, Loss: 2.325765490240883e-05, Min w: 0.9507254958152771\n",
      "Iteration 1170, Loss: 3.90847708331421e-05, Min w: 0.8784640431404114\n",
      "Iteration 1180, Loss: 3.254472539993003e-05, Min w: 0.9128863215446472\n",
      "Iteration 1190, Loss: 5.1274793804623187e-05, Min w: 0.870357096195221\n",
      "Iteration 1200, Loss: 3.694864790304564e-05, Min w: 0.904443085193634\n",
      "Iteration 1210, Loss: 1.8859731426346116e-05, Min w: 0.9529687762260437\n",
      "Iteration 1220, Loss: 4.3855314288521186e-05, Min w: 0.8805926442146301\n",
      "Iteration 1230, Loss: 4.8541540309088305e-05, Min w: 0.8700767159461975\n",
      "Iteration 1240, Loss: 3.855783506878652e-05, Min w: 0.8934730291366577\n",
      "Iteration 0, Loss: 5.27906340721529e-05, Min w: 0.8454450368881226\n",
      "Iteration 10, Loss: 4.6657747589051723e-05, Min w: 0.8672064542770386\n",
      "Iteration 20, Loss: 6.14749442320317e-05, Min w: 0.8673199415206909\n",
      "Iteration 30, Loss: 4.466062819119543e-05, Min w: 0.8871430158615112\n",
      "Iteration 40, Loss: 3.544128412613645e-05, Min w: 0.8958531618118286\n",
      "Iteration 50, Loss: 4.0174665628001094e-05, Min w: 0.9115451574325562\n",
      "Iteration 60, Loss: 4.940256985719316e-05, Min w: 0.8298308253288269\n",
      "Iteration 70, Loss: 5.8040619478560984e-05, Min w: 0.840414822101593\n",
      "Iteration 80, Loss: 8.220750169130042e-05, Min w: 0.8165978789329529\n",
      "Iteration 90, Loss: 0.00010865277727134526, Min w: 0.767927885055542\n",
      "Iteration 100, Loss: 5.888763553230092e-05, Min w: 0.8079710006713867\n",
      "Iteration 110, Loss: 8.074621291598305e-05, Min w: 0.772688090801239\n",
      "Iteration 120, Loss: 9.20183229027316e-05, Min w: 0.7556772828102112\n",
      "Iteration 130, Loss: 9.51027832343243e-05, Min w: 0.7234784364700317\n",
      "Iteration 140, Loss: 5.917944872635417e-05, Min w: 0.8290567398071289\n",
      "Iteration 150, Loss: 2.853815931302961e-05, Min w: 0.9339888095855713\n",
      "Iteration 160, Loss: 4.262754009687342e-05, Min w: 0.8890097737312317\n",
      "Iteration 170, Loss: 6.623725494137034e-05, Min w: 0.8355270624160767\n",
      "Iteration 180, Loss: 1.5084686310729012e-05, Min w: 0.9619500637054443\n",
      "Iteration 190, Loss: 1.8847720639314502e-05, Min w: 0.9591661691665649\n",
      "Iteration 200, Loss: 1.4499836652248632e-05, Min w: 0.9668400883674622\n",
      "Iteration 210, Loss: 3.019632822542917e-05, Min w: 0.9059816598892212\n",
      "Iteration 220, Loss: 1.926713412103709e-05, Min w: 0.9530550837516785\n",
      "Iteration 230, Loss: 4.20317446696572e-05, Min w: 0.8915828466415405\n",
      "Iteration 240, Loss: 3.666784687084146e-05, Min w: 0.9208669662475586\n",
      "Iteration 250, Loss: 4.069662463734858e-05, Min w: 0.8790538311004639\n",
      "Iteration 260, Loss: 4.324062683735974e-05, Min w: 0.9083343148231506\n",
      "Iteration 270, Loss: 3.806247332249768e-05, Min w: 0.8664005398750305\n",
      "Iteration 280, Loss: 3.556573938112706e-05, Min w: 0.9078441262245178\n",
      "Iteration 290, Loss: 2.2169353542267345e-05, Min w: 0.9381760358810425\n",
      "Iteration 300, Loss: 3.950371319660917e-05, Min w: 0.9169079065322876\n",
      "Iteration 310, Loss: 4.639692633645609e-05, Min w: 0.9048610329627991\n",
      "Iteration 320, Loss: 5.7701912737684324e-05, Min w: 0.8406950831413269\n",
      "Iteration 330, Loss: 2.308694638486486e-05, Min w: 0.9457768201828003\n",
      "Iteration 340, Loss: 6.172608118504286e-05, Min w: 0.8587213754653931\n",
      "Iteration 350, Loss: 6.728887092322111e-05, Min w: 0.8026686310768127\n",
      "Iteration 360, Loss: 5.6699653214309365e-05, Min w: 0.8668468594551086\n",
      "Iteration 370, Loss: 7.150577584980056e-05, Min w: 0.8029698133468628\n",
      "Iteration 380, Loss: 5.55823789909482e-05, Min w: 0.8382813334465027\n",
      "Iteration 390, Loss: 2.1892970835324377e-05, Min w: 0.9372691512107849\n",
      "Iteration 400, Loss: 1.740860716381576e-05, Min w: 0.9469925761222839\n",
      "Iteration 410, Loss: 4.738052302855067e-05, Min w: 0.8791215419769287\n",
      "Iteration 420, Loss: 6.741633842466399e-05, Min w: 0.7810950875282288\n",
      "Iteration 430, Loss: 5.893975685467012e-05, Min w: 0.8703261017799377\n",
      "Iteration 440, Loss: 2.8879167075501755e-05, Min w: 0.9340402483940125\n",
      "Iteration 450, Loss: 6.699271034449339e-05, Min w: 0.8274050354957581\n",
      "Iteration 460, Loss: 2.850367673090659e-05, Min w: 0.9034854173660278\n",
      "Iteration 470, Loss: 5.294229049468413e-05, Min w: 0.8794434070587158\n",
      "Iteration 480, Loss: 5.028895247960463e-05, Min w: 0.8311808705329895\n",
      "Iteration 490, Loss: 4.361661558505148e-05, Min w: 0.9026720523834229\n",
      "Iteration 500, Loss: 1.427191909897374e-05, Min w: 0.9707663655281067\n",
      "Iteration 510, Loss: 3.065206328756176e-05, Min w: 0.9016510844230652\n",
      "Iteration 520, Loss: 2.48025608016178e-05, Min w: 0.9241635799407959\n",
      "Iteration 530, Loss: 2.9411810828605667e-05, Min w: 0.9306467771530151\n",
      "Iteration 540, Loss: 4.005048322142102e-05, Min w: 0.8768807649612427\n",
      "Iteration 550, Loss: 2.5606801500543952e-05, Min w: 0.9407280683517456\n",
      "Iteration 560, Loss: 3.4713517379714176e-05, Min w: 0.8811397552490234\n",
      "Iteration 570, Loss: 2.4805076463962905e-05, Min w: 0.9432514309883118\n",
      "Iteration 580, Loss: 7.546374399680644e-05, Min w: 0.8013994097709656\n",
      "Iteration 590, Loss: 5.6982244132086635e-05, Min w: 0.8495393395423889\n",
      "Iteration 600, Loss: 8.790344145381823e-05, Min w: 0.774429202079773\n",
      "Iteration 610, Loss: 6.423462036764249e-05, Min w: 0.7643725275993347\n",
      "Iteration 620, Loss: 4.192219421383925e-05, Min w: 0.9112532138824463\n",
      "Iteration 630, Loss: 1.5094694390427321e-05, Min w: 0.9614086151123047\n",
      "Iteration 640, Loss: 1.6018078895285726e-05, Min w: 0.9582241773605347\n",
      "Iteration 650, Loss: 1.2679286555794533e-05, Min w: 0.96803879737854\n",
      "Iteration 660, Loss: 1.1165931937284768e-05, Min w: 0.9717233180999756\n",
      "Iteration 670, Loss: 1.775760574673768e-05, Min w: 0.947515606880188\n",
      "Iteration 680, Loss: 2.812110324157402e-05, Min w: 0.938929557800293\n",
      "Iteration 690, Loss: 2.080566991935484e-05, Min w: 0.949344277381897\n",
      "Iteration 700, Loss: 4.640578481485136e-05, Min w: 0.8597633838653564\n",
      "Iteration 710, Loss: 1.2960254025529139e-05, Min w: 0.9670888781547546\n",
      "Iteration 720, Loss: 2.9280639864737168e-05, Min w: 0.9360350966453552\n",
      "Iteration 730, Loss: 4.111204179935157e-05, Min w: 0.8651384711265564\n",
      "Iteration 740, Loss: 4.810882091987878e-05, Min w: 0.875700831413269\n",
      "Iteration 750, Loss: 2.417983159830328e-05, Min w: 0.9390819668769836\n",
      "Iteration 760, Loss: 8.638860163046047e-05, Min w: 0.816154956817627\n",
      "Iteration 770, Loss: 3.2087515137391165e-05, Min w: 0.9204599261283875\n",
      "Iteration 780, Loss: 7.770901720505208e-05, Min w: 0.7617427706718445\n",
      "Iteration 790, Loss: 2.6033303583972156e-05, Min w: 0.9183036088943481\n",
      "Iteration 800, Loss: 6.04778942943085e-05, Min w: 0.8386014103889465\n",
      "Iteration 810, Loss: 5.894356218050234e-05, Min w: 0.7885205745697021\n",
      "Iteration 820, Loss: 4.330258889240213e-05, Min w: 0.9007421135902405\n",
      "Iteration 830, Loss: 3.05021367239533e-05, Min w: 0.891146183013916\n",
      "Iteration 840, Loss: 4.2297844629501924e-05, Min w: 0.9001693725585938\n",
      "Iteration 850, Loss: 1.2324620001891162e-05, Min w: 0.9728232622146606\n",
      "Iteration 860, Loss: 1.3004382708459161e-05, Min w: 0.9692708849906921\n",
      "Iteration 870, Loss: 2.6524823624640703e-05, Min w: 0.9225568175315857\n",
      "Iteration 880, Loss: 1.1779049600590952e-05, Min w: 0.9750377535820007\n",
      "Iteration 890, Loss: 4.6468408982036635e-05, Min w: 0.8407564759254456\n",
      "Iteration 900, Loss: 1.4483022823696956e-05, Min w: 0.9670969247817993\n",
      "Iteration 910, Loss: 2.2359381546266377e-05, Min w: 0.9343807697296143\n",
      "Iteration 920, Loss: 2.366026456002146e-05, Min w: 0.9459587335586548\n",
      "Iteration 930, Loss: 4.052556323586032e-05, Min w: 0.8884483575820923\n",
      "Iteration 940, Loss: 5.480746767716482e-05, Min w: 0.8732818365097046\n",
      "Iteration 950, Loss: 4.936584809911437e-05, Min w: 0.8623881936073303\n",
      "Iteration 960, Loss: 4.6033208491280675e-05, Min w: 0.835500180721283\n",
      "Iteration 970, Loss: 6.236320041352883e-05, Min w: 0.8403281569480896\n",
      "Iteration 980, Loss: 3.2855667086550966e-05, Min w: 0.9323015809059143\n",
      "Iteration 990, Loss: 3.2826384995132685e-05, Min w: 0.8876295685768127\n",
      "Iteration 1000, Loss: 1.617950874788221e-05, Min w: 0.9524641633033752\n",
      "Iteration 1010, Loss: 1.3484888768289238e-05, Min w: 0.9588591456413269\n",
      "Iteration 1020, Loss: 3.334685243316926e-05, Min w: 0.8855621218681335\n",
      "Iteration 1030, Loss: 1.1219734005862847e-05, Min w: 0.9703738689422607\n",
      "Iteration 1040, Loss: 2.2842381440568715e-05, Min w: 0.940866231918335\n",
      "Iteration 1050, Loss: 3.6409375752555206e-05, Min w: 0.9063507914543152\n",
      "Iteration 1060, Loss: 3.856363764498383e-05, Min w: 0.8657839298248291\n",
      "Iteration 1070, Loss: 2.773812047962565e-05, Min w: 0.9276856780052185\n",
      "Iteration 1080, Loss: 4.410480323713273e-05, Min w: 0.8997705578804016\n",
      "Iteration 1090, Loss: 4.2651787225622684e-05, Min w: 0.8564438223838806\n",
      "Iteration 1100, Loss: 1.0727736480475869e-05, Min w: 0.9728123545646667\n",
      "Iteration 1110, Loss: 3.513904812280089e-05, Min w: 0.880544126033783\n",
      "Iteration 1120, Loss: 9.982769370253664e-06, Min w: 0.9777305126190186\n",
      "Iteration 1130, Loss: 2.908563874370884e-05, Min w: 0.9397726058959961\n",
      "Iteration 1140, Loss: 5.3354393457993865e-05, Min w: 0.8797383904457092\n",
      "Iteration 1150, Loss: 3.47942223015707e-05, Min w: 0.8989347815513611\n",
      "Iteration 1160, Loss: 3.33199423039332e-05, Min w: 0.9144690036773682\n",
      "Iteration 1170, Loss: 5.640773815684952e-05, Min w: 0.8331087231636047\n",
      "Iteration 1180, Loss: 3.621724681579508e-05, Min w: 0.8939633965492249\n",
      "Iteration 1190, Loss: 4.098681893083267e-05, Min w: 0.8616651296615601\n",
      "Iteration 1200, Loss: 2.527411561459303e-05, Min w: 0.9294944405555725\n",
      "Iteration 1210, Loss: 1.942697235790547e-05, Min w: 0.9593673348426819\n",
      "Iteration 1220, Loss: 3.9515725802630186e-05, Min w: 0.8839760422706604\n",
      "Iteration 1230, Loss: 2.3782358766766265e-05, Min w: 0.9227548241615295\n",
      "Iteration 1240, Loss: 2.621422208903823e-05, Min w: 0.9402931332588196\n",
      "Iteration 0, Loss: 8.666714165883604e-06, Min w: 0.9767094850540161\n",
      "Iteration 10, Loss: 4.881376662524417e-05, Min w: 0.8596009016036987\n",
      "Iteration 20, Loss: 3.378925975994207e-05, Min w: 0.8831978440284729\n",
      "Iteration 30, Loss: 4.670946509577334e-05, Min w: 0.8309174180030823\n",
      "Iteration 40, Loss: 2.0570290871546604e-05, Min w: 0.9475922584533691\n",
      "Iteration 50, Loss: 1.6816513380035758e-05, Min w: 0.9460334181785583\n",
      "Iteration 60, Loss: 3.2274798286380246e-05, Min w: 0.8905234932899475\n",
      "Iteration 70, Loss: 2.5191200620611198e-05, Min w: 0.9452000856399536\n",
      "Iteration 80, Loss: 4.049743802170269e-05, Min w: 0.9078517556190491\n",
      "Iteration 90, Loss: 2.2871370674693026e-05, Min w: 0.9237203598022461\n",
      "Iteration 100, Loss: 2.360106009291485e-05, Min w: 0.9306895136833191\n",
      "Iteration 110, Loss: 2.206132558058016e-05, Min w: 0.9293612241744995\n",
      "Iteration 120, Loss: 1.1614210052357521e-05, Min w: 0.9718717932701111\n",
      "Iteration 130, Loss: 1.661540227360092e-05, Min w: 0.9645217657089233\n",
      "Iteration 140, Loss: 4.2391573515487835e-05, Min w: 0.8740479350090027\n",
      "Iteration 150, Loss: 2.665303873072844e-05, Min w: 0.9252052307128906\n",
      "Iteration 160, Loss: 2.6734247512649745e-05, Min w: 0.9074992537498474\n",
      "Iteration 170, Loss: 2.198466427216772e-05, Min w: 0.9505093693733215\n",
      "Iteration 180, Loss: 3.738656232599169e-05, Min w: 0.874325156211853\n",
      "Iteration 190, Loss: 1.8358976376475766e-05, Min w: 0.9445906281471252\n",
      "Iteration 200, Loss: 1.9882039850926958e-05, Min w: 0.9561766386032104\n",
      "Iteration 210, Loss: 4.6241497329901904e-05, Min w: 0.9037795662879944\n",
      "Iteration 220, Loss: 3.999353793915361e-05, Min w: 0.8550461530685425\n",
      "Iteration 230, Loss: 3.5941542591899633e-05, Min w: 0.909927248954773\n",
      "Iteration 240, Loss: 3.0634757422376424e-05, Min w: 0.9244374632835388\n",
      "Iteration 250, Loss: 2.7881364076165482e-05, Min w: 0.9049472808837891\n",
      "Iteration 260, Loss: 2.873723497032188e-05, Min w: 0.9219786524772644\n",
      "Iteration 270, Loss: 1.3845967259840108e-05, Min w: 0.9640294313430786\n",
      "Iteration 280, Loss: 4.034002995467745e-05, Min w: 0.9064652323722839\n",
      "Iteration 290, Loss: 2.8720001864712685e-05, Min w: 0.9083446860313416\n",
      "Iteration 300, Loss: 2.655748357938137e-05, Min w: 0.9318585395812988\n",
      "Iteration 310, Loss: 3.7483663618331775e-05, Min w: 0.874908447265625\n",
      "Iteration 320, Loss: 4.877414903603494e-05, Min w: 0.8675787448883057\n",
      "Iteration 330, Loss: 2.5463967176619917e-05, Min w: 0.9463021159172058\n",
      "Iteration 340, Loss: 3.2295716664521024e-05, Min w: 0.8903118371963501\n",
      "Iteration 350, Loss: 2.348482667002827e-05, Min w: 0.9183323383331299\n",
      "Iteration 360, Loss: 3.46222695952747e-05, Min w: 0.9151125550270081\n",
      "Iteration 370, Loss: 1.776149292709306e-05, Min w: 0.9375344514846802\n",
      "Iteration 380, Loss: 2.6844920284929685e-05, Min w: 0.931597113609314\n",
      "Iteration 390, Loss: 4.600738247972913e-05, Min w: 0.8901072144508362\n",
      "Iteration 400, Loss: 1.943639108503703e-05, Min w: 0.9532552361488342\n",
      "Iteration 410, Loss: 4.644042928703129e-05, Min w: 0.8870511651039124\n",
      "Iteration 420, Loss: 5.9798421716550365e-05, Min w: 0.8626980781555176\n",
      "Iteration 430, Loss: 5.6926077377283946e-05, Min w: 0.8762850761413574\n",
      "Iteration 440, Loss: 4.925741086481139e-05, Min w: 0.8841186761856079\n",
      "Iteration 450, Loss: 3.0213555874070153e-05, Min w: 0.9370059370994568\n",
      "Iteration 460, Loss: 3.667559212772176e-05, Min w: 0.8993045687675476\n",
      "Iteration 470, Loss: 3.043740798602812e-05, Min w: 0.9122068285942078\n",
      "Iteration 480, Loss: 2.2758449631510302e-05, Min w: 0.9172140955924988\n",
      "Iteration 490, Loss: 2.773273990896996e-05, Min w: 0.9410173892974854\n",
      "Iteration 500, Loss: 2.0289853637223132e-05, Min w: 0.9456455111503601\n",
      "Iteration 510, Loss: 3.131424819002859e-05, Min w: 0.9347110390663147\n",
      "Iteration 520, Loss: 3.540500983945094e-05, Min w: 0.8802210688591003\n",
      "Iteration 530, Loss: 4.700219869846478e-05, Min w: 0.8696103096008301\n",
      "Iteration 540, Loss: 6.329955795081332e-05, Min w: 0.8624411821365356\n",
      "Iteration 550, Loss: 4.0792034269543365e-05, Min w: 0.9031942486763\n",
      "Iteration 560, Loss: 6.723406113451347e-05, Min w: 0.8411200642585754\n",
      "Iteration 570, Loss: 1.59991359396372e-05, Min w: 0.9496625065803528\n",
      "Iteration 580, Loss: 2.717962888709735e-05, Min w: 0.9060041904449463\n",
      "Iteration 590, Loss: 1.886034442577511e-05, Min w: 0.9555003643035889\n",
      "Iteration 600, Loss: 8.924472240323666e-06, Min w: 0.9731976389884949\n",
      "Iteration 610, Loss: 3.3714961318764836e-05, Min w: 0.9014840126037598\n",
      "Iteration 620, Loss: 1.7440903320675716e-05, Min w: 0.938668429851532\n",
      "Iteration 630, Loss: 2.1633133655996062e-05, Min w: 0.944961428642273\n",
      "Iteration 640, Loss: 4.404430364957079e-05, Min w: 0.8972874283790588\n",
      "Iteration 650, Loss: 1.2815044101444073e-05, Min w: 0.9612435698509216\n",
      "Iteration 660, Loss: 2.448037594149355e-05, Min w: 0.9337230324745178\n",
      "Iteration 670, Loss: 1.455159144825302e-05, Min w: 0.9553545713424683\n",
      "Iteration 680, Loss: 4.049803828820586e-05, Min w: 0.8836053013801575\n",
      "Iteration 690, Loss: 1.3013452189625241e-05, Min w: 0.967135488986969\n",
      "Iteration 700, Loss: 4.352369796833955e-05, Min w: 0.884944498538971\n",
      "Iteration 710, Loss: 4.4698634155793115e-05, Min w: 0.8890827894210815\n",
      "Iteration 720, Loss: 9.823836990108248e-06, Min w: 0.9790003895759583\n",
      "Iteration 730, Loss: 4.075230026501231e-05, Min w: 0.8632478713989258\n",
      "Iteration 740, Loss: 2.2425072529586032e-05, Min w: 0.9417189359664917\n",
      "Iteration 750, Loss: 3.3607208024477586e-05, Min w: 0.9033942222595215\n",
      "Iteration 760, Loss: 8.40843676996883e-06, Min w: 0.9810188412666321\n",
      "Iteration 770, Loss: 1.4037842447578441e-05, Min w: 0.9680482149124146\n",
      "Iteration 780, Loss: 8.248077392636333e-06, Min w: 0.9803341031074524\n",
      "Iteration 790, Loss: 3.794331132667139e-05, Min w: 0.9174490571022034\n",
      "Iteration 800, Loss: 5.0719383580144495e-05, Min w: 0.8309816122055054\n",
      "Iteration 810, Loss: 5.7826164265861735e-05, Min w: 0.83101487159729\n",
      "Iteration 820, Loss: 3.3022886782418936e-05, Min w: 0.9320616126060486\n",
      "Iteration 830, Loss: 8.226306817959994e-06, Min w: 0.9770498871803284\n",
      "Iteration 840, Loss: 7.948442544147838e-06, Min w: 0.981707751750946\n",
      "Iteration 850, Loss: 1.4632830243499484e-05, Min w: 0.9521556496620178\n",
      "Iteration 860, Loss: 9.517308171780314e-06, Min w: 0.9697906374931335\n",
      "Iteration 870, Loss: 3.968156306655146e-05, Min w: 0.8626481890678406\n",
      "Iteration 880, Loss: 1.2518615221779328e-05, Min w: 0.9713326096534729\n",
      "Iteration 890, Loss: 2.9603908842545934e-05, Min w: 0.8961781859397888\n",
      "Iteration 900, Loss: 2.0718525775009766e-05, Min w: 0.9300398230552673\n",
      "Iteration 910, Loss: 2.383479477430228e-05, Min w: 0.942572832107544\n",
      "Iteration 920, Loss: 3.0378303563338704e-05, Min w: 0.9227439761161804\n",
      "Iteration 930, Loss: 4.601442924467847e-05, Min w: 0.9030433893203735\n",
      "Iteration 940, Loss: 4.607514347299002e-05, Min w: 0.8968433737754822\n",
      "Iteration 950, Loss: 3.56223426933866e-05, Min w: 0.8946146965026855\n",
      "Iteration 960, Loss: 2.1294879843480885e-05, Min w: 0.9296014308929443\n",
      "Iteration 970, Loss: 5.3719781135441735e-05, Min w: 0.8855180144309998\n",
      "Iteration 980, Loss: 7.032234861981124e-06, Min w: 0.9825723171234131\n",
      "Iteration 990, Loss: 1.0924421076197177e-05, Min w: 0.9749318957328796\n",
      "Iteration 1000, Loss: 8.009780685824808e-06, Min w: 0.9755866527557373\n",
      "Iteration 1010, Loss: 8.75078603712609e-06, Min w: 0.9730322360992432\n",
      "Iteration 1020, Loss: 1.6209864043048583e-05, Min w: 0.96319180727005\n",
      "Iteration 1030, Loss: 1.3247863535070792e-05, Min w: 0.9669930934906006\n",
      "Iteration 1040, Loss: 1.546994644741062e-05, Min w: 0.962076723575592\n",
      "Iteration 1050, Loss: 3.420810026000254e-05, Min w: 0.9077962636947632\n",
      "Iteration 1060, Loss: 1.5000309758761432e-05, Min w: 0.9656932353973389\n",
      "Iteration 1070, Loss: 2.705637780309189e-05, Min w: 0.932401716709137\n",
      "Iteration 1080, Loss: 1.7710608517518267e-05, Min w: 0.9544011354446411\n",
      "Iteration 1090, Loss: 3.37466444761958e-05, Min w: 0.8747351765632629\n",
      "Iteration 1100, Loss: 1.2739654266624711e-05, Min w: 0.968195378780365\n",
      "Iteration 1110, Loss: 2.8920518161612563e-05, Min w: 0.9289825558662415\n",
      "Iteration 1120, Loss: 1.2954441444890108e-05, Min w: 0.9702630639076233\n",
      "Iteration 1130, Loss: 3.774839569814503e-05, Min w: 0.9001355767250061\n",
      "Iteration 1140, Loss: 4.082655505044386e-05, Min w: 0.8636655807495117\n",
      "Iteration 1150, Loss: 8.765051461523399e-06, Min w: 0.9809764623641968\n",
      "Iteration 1160, Loss: 4.6828881750116125e-05, Min w: 0.8551127314567566\n",
      "Iteration 1170, Loss: 3.3099157008109614e-05, Min w: 0.8860442042350769\n",
      "Iteration 1180, Loss: 1.4452226423600223e-05, Min w: 0.9665190577507019\n",
      "Iteration 1190, Loss: 3.303339326521382e-05, Min w: 0.891309916973114\n",
      "Iteration 1200, Loss: 4.648758113035001e-05, Min w: 0.8899854421615601\n",
      "Iteration 1210, Loss: 3.816998651018366e-05, Min w: 0.8732965588569641\n",
      "Iteration 1220, Loss: 1.6457383026136085e-05, Min w: 0.9596095085144043\n",
      "Iteration 1230, Loss: 1.1117911526525859e-05, Min w: 0.9751152992248535\n",
      "Iteration 1240, Loss: 2.2205646018846892e-05, Min w: 0.9367372989654541\n",
      "Iteration 0, Loss: 4.653127689380199e-05, Min w: 0.8907874822616577\n",
      "Iteration 10, Loss: 1.8151918993680738e-05, Min w: 0.9474925398826599\n",
      "Iteration 20, Loss: 3.379839472472668e-05, Min w: 0.9301653504371643\n",
      "Iteration 30, Loss: 5.698678069165908e-05, Min w: 0.840774416923523\n",
      "Iteration 40, Loss: 4.112118040211499e-05, Min w: 0.8815789818763733\n",
      "Iteration 50, Loss: 5.278989192447625e-05, Min w: 0.8256263136863708\n",
      "Iteration 60, Loss: 4.8728761612437665e-05, Min w: 0.8402746319770813\n",
      "Iteration 70, Loss: 3.613897933973931e-05, Min w: 0.9047302603721619\n",
      "Iteration 80, Loss: 3.037192982446868e-05, Min w: 0.905689537525177\n",
      "Iteration 90, Loss: 5.4923070820223074e-06, Min w: 0.9856017231941223\n",
      "Iteration 100, Loss: 5.208909442444565e-06, Min w: 0.9853019118309021\n",
      "Iteration 110, Loss: 2.710741500777658e-05, Min w: 0.9059471487998962\n",
      "Iteration 120, Loss: 2.7555812266655266e-05, Min w: 0.9401787519454956\n",
      "Iteration 130, Loss: 3.67442007700447e-05, Min w: 0.9100037217140198\n",
      "Iteration 140, Loss: 2.3061766114551574e-05, Min w: 0.9354636669158936\n",
      "Iteration 150, Loss: 3.49324727721978e-05, Min w: 0.8879106640815735\n",
      "Iteration 160, Loss: 3.216136610717513e-05, Min w: 0.9235422611236572\n",
      "Iteration 170, Loss: 8.026335308386479e-06, Min w: 0.9795692563056946\n",
      "Iteration 180, Loss: 6.19250386080239e-06, Min w: 0.9814751148223877\n",
      "Iteration 190, Loss: 1.4050150639377534e-05, Min w: 0.9686033129692078\n",
      "Iteration 200, Loss: 2.0539660908980295e-05, Min w: 0.931358277797699\n",
      "Iteration 210, Loss: 7.326484592340421e-06, Min w: 0.9794442057609558\n",
      "Iteration 220, Loss: 3.4402244637021795e-05, Min w: 0.8786286115646362\n",
      "Iteration 230, Loss: 2.142611629096791e-05, Min w: 0.9355920553207397\n",
      "Iteration 240, Loss: 1.9614084521890618e-05, Min w: 0.9343913197517395\n",
      "Iteration 250, Loss: 1.900716779346112e-05, Min w: 0.951156735420227\n",
      "Iteration 260, Loss: 2.2304171579889953e-05, Min w: 0.9182409644126892\n",
      "Iteration 270, Loss: 4.4171618355903774e-05, Min w: 0.8548355102539062\n",
      "Iteration 280, Loss: 2.3002632588031702e-05, Min w: 0.9205746650695801\n",
      "Iteration 290, Loss: 4.914621058560442e-06, Min w: 0.9863817095756531\n",
      "Iteration 300, Loss: 1.0448404282215051e-05, Min w: 0.9703693985939026\n",
      "Iteration 310, Loss: 2.3735439754091203e-05, Min w: 0.9251369833946228\n",
      "Iteration 320, Loss: 2.3177348339231685e-05, Min w: 0.9306243658065796\n",
      "Iteration 330, Loss: 1.6207439330173656e-05, Min w: 0.9503657221794128\n",
      "Iteration 340, Loss: 1.05385106508038e-05, Min w: 0.9782930016517639\n",
      "Iteration 350, Loss: 2.6865607651416212e-05, Min w: 0.9338463544845581\n",
      "Iteration 360, Loss: 4.38896422565449e-05, Min w: 0.8787335157394409\n",
      "Iteration 370, Loss: 2.827881144185085e-05, Min w: 0.913475751876831\n",
      "Iteration 380, Loss: 1.0815919267770369e-05, Min w: 0.9627408981323242\n",
      "Iteration 390, Loss: 1.58765324158594e-05, Min w: 0.9580671191215515\n",
      "Iteration 400, Loss: 2.4426033633062616e-05, Min w: 0.947448194026947\n",
      "Iteration 410, Loss: 1.676218926149886e-05, Min w: 0.9522062540054321\n",
      "Iteration 420, Loss: 7.264834039233392e-06, Min w: 0.9828271865844727\n",
      "Iteration 430, Loss: 5.295271876093466e-06, Min w: 0.9872196316719055\n",
      "Iteration 440, Loss: 2.895959551096894e-05, Min w: 0.9112887978553772\n",
      "Iteration 450, Loss: 3.161058702971786e-05, Min w: 0.9040470719337463\n",
      "Iteration 460, Loss: 1.580456955707632e-05, Min w: 0.9463861584663391\n",
      "Iteration 470, Loss: 2.4492623197147623e-05, Min w: 0.9291776418685913\n",
      "Iteration 480, Loss: 1.3365196537051816e-05, Min w: 0.961526095867157\n",
      "Iteration 490, Loss: 2.0768984541064128e-05, Min w: 0.9492781758308411\n",
      "Iteration 500, Loss: 1.899523522297386e-05, Min w: 0.9552795886993408\n",
      "Iteration 510, Loss: 1.9964043531217612e-05, Min w: 0.956860363483429\n",
      "Iteration 520, Loss: 9.283312465413474e-06, Min w: 0.9728589653968811\n",
      "Iteration 530, Loss: 3.493453186820261e-05, Min w: 0.8806628584861755\n",
      "Iteration 540, Loss: 1.751891613821499e-05, Min w: 0.9499562978744507\n",
      "Iteration 550, Loss: 1.1518633073137607e-05, Min w: 0.9698310494422913\n",
      "Iteration 560, Loss: 2.5893781639751978e-05, Min w: 0.9425244927406311\n",
      "Iteration 570, Loss: 5.477313152368879e-06, Min w: 0.9838716983795166\n",
      "Iteration 580, Loss: 1.0677813406800851e-05, Min w: 0.9652847647666931\n",
      "Iteration 590, Loss: 3.2372157875215635e-05, Min w: 0.926129937171936\n",
      "Iteration 600, Loss: 2.1365465727285482e-05, Min w: 0.9421638250350952\n",
      "Iteration 610, Loss: 1.557707400934305e-05, Min w: 0.9447179436683655\n",
      "Iteration 620, Loss: 4.7687448386568576e-05, Min w: 0.8574655652046204\n",
      "Iteration 630, Loss: 4.4387823436409235e-05, Min w: 0.8963425755500793\n",
      "Iteration 640, Loss: 1.2129884453315753e-05, Min w: 0.9636273384094238\n",
      "Iteration 650, Loss: 1.003271245281212e-05, Min w: 0.9714444875717163\n",
      "Iteration 660, Loss: 1.1737135537259746e-05, Min w: 0.9750730991363525\n",
      "Iteration 670, Loss: 2.0961671907571144e-05, Min w: 0.9299998879432678\n",
      "Iteration 680, Loss: 1.2650792086787988e-05, Min w: 0.957697868347168\n",
      "Iteration 690, Loss: 1.2946043170813937e-05, Min w: 0.9576724171638489\n",
      "Iteration 700, Loss: 1.922726551129017e-05, Min w: 0.9453012347221375\n",
      "Iteration 710, Loss: 1.7784272131393664e-05, Min w: 0.9424431920051575\n",
      "Iteration 720, Loss: 3.4369219065411016e-05, Min w: 0.9151148200035095\n",
      "Iteration 730, Loss: 3.687964635901153e-05, Min w: 0.908208429813385\n",
      "Iteration 740, Loss: 1.2300868547754362e-05, Min w: 0.9618393778800964\n",
      "Iteration 750, Loss: 1.4370009921549354e-05, Min w: 0.9615811109542847\n",
      "Iteration 760, Loss: 1.9988237909274176e-05, Min w: 0.9557451605796814\n",
      "Iteration 770, Loss: 3.0017754397704266e-05, Min w: 0.9042322635650635\n",
      "Iteration 780, Loss: 4.650662958738394e-06, Min w: 0.9872424006462097\n",
      "Iteration 790, Loss: 2.3166196115198545e-05, Min w: 0.932967483997345\n",
      "Iteration 800, Loss: 9.916009730659425e-06, Min w: 0.9794823527336121\n",
      "Iteration 810, Loss: 2.889403549488634e-05, Min w: 0.9114130139350891\n",
      "Iteration 820, Loss: 3.370503327460028e-05, Min w: 0.8978686928749084\n",
      "Iteration 830, Loss: 7.843807907192968e-06, Min w: 0.9756380915641785\n",
      "Iteration 840, Loss: 2.6690424419939518e-05, Min w: 0.9416052103042603\n",
      "Iteration 850, Loss: 2.3905862690298818e-05, Min w: 0.9414466619491577\n",
      "Iteration 860, Loss: 1.2127812624385115e-05, Min w: 0.9593018293380737\n",
      "Iteration 870, Loss: 8.693843483342789e-06, Min w: 0.9714054465293884\n",
      "Iteration 880, Loss: 1.6656618754495867e-05, Min w: 0.9497931003570557\n",
      "Iteration 890, Loss: 1.586546204634942e-05, Min w: 0.9533007740974426\n",
      "Iteration 900, Loss: 4.0555576561018825e-05, Min w: 0.9021868705749512\n",
      "Iteration 910, Loss: 1.988069197977893e-05, Min w: 0.9449254274368286\n",
      "Iteration 920, Loss: 2.6550975235295482e-05, Min w: 0.9151289463043213\n",
      "Iteration 930, Loss: 8.613722457084805e-06, Min w: 0.9822038412094116\n",
      "Iteration 940, Loss: 2.1891421056352556e-05, Min w: 0.9502430558204651\n",
      "Iteration 950, Loss: 1.7223272152477875e-05, Min w: 0.9446337819099426\n",
      "Iteration 960, Loss: 1.3987777492729947e-05, Min w: 0.9531952142715454\n",
      "Iteration 970, Loss: 3.332862615934573e-05, Min w: 0.9128726720809937\n",
      "Iteration 980, Loss: 7.21623746358091e-06, Min w: 0.9834033846855164\n",
      "Iteration 990, Loss: 2.4551833121222444e-05, Min w: 0.9284392595291138\n",
      "Iteration 1000, Loss: 1.5215170606097672e-05, Min w: 0.9478737711906433\n",
      "Iteration 1010, Loss: 2.9063783586025238e-05, Min w: 0.9261905550956726\n",
      "Iteration 1020, Loss: 1.6266729289782234e-05, Min w: 0.9622408151626587\n",
      "Iteration 1030, Loss: 4.1997278458438814e-05, Min w: 0.8786239624023438\n",
      "Iteration 1040, Loss: 4.027743671031203e-06, Min w: 0.9899720549583435\n",
      "Iteration 1050, Loss: 2.5035018552443944e-05, Min w: 0.932466447353363\n",
      "Iteration 1060, Loss: 8.905164577299729e-06, Min w: 0.97165447473526\n",
      "Iteration 1070, Loss: 2.213165680586826e-05, Min w: 0.9466381669044495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  62%|██████▎   | 15/24 [11:17<06:20, 42.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1080, Loss: 1.845859515015036e-05, Min w: 0.9533313512802124\n",
      "Early break at iteration 1089 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6090, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.00678460740748529, 'L2_avg': 0.010218123850666597, 'End_point_L1_avg': 0.0023334073409263163, 'End_point_L2_avg': 0.0031689582825859043}\n",
      "Iteration 0, Loss: 0.0010344828478991985, Min w: 1.2916866868600415e-34\n",
      "Iteration 10, Loss: 0.0008929035975597799, Min w: 1.6975985062117616e-08\n",
      "Iteration 20, Loss: 0.0008723450009711087, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000694104062858969, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006197424372658134, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0005813317256979644, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0005523463478311896, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0005327778635546565, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0005145971081219614, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0004938772763125598, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005330891581252217, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0004445006779860705, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0004891279968433082, Min w: 0.0\n",
      "Iteration 130, Loss: 0.00041348973172716796, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0003881386364810169, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00042058550752699375, Min w: 0.0\n",
      "Iteration 160, Loss: 0.00042494796798564494, Min w: 0.0\n",
      "Iteration 170, Loss: 0.00058301369426772, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0005437533836811781, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005256462609395385, Min w: 0.0\n",
      "Iteration 200, Loss: 0.000538992288056761, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0004966570413671434, Min w: 0.0\n",
      "Iteration 220, Loss: 0.00039258276228792965, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00037371035432443023, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0004023093788418919, Min w: 0.0\n",
      "Iteration 250, Loss: 0.000402763340389356, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0003669859142974019, Min w: 1.5118884635805344e-17\n",
      "Iteration 270, Loss: 0.0003493243712000549, Min w: 6.532546725779298e-11\n",
      "Iteration 280, Loss: 0.000413725123507902, Min w: 1.5105997445421528e-42\n",
      "Iteration 290, Loss: 0.00038188276812434196, Min w: 0.0\n",
      "Iteration 300, Loss: 0.00033957939012907445, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0003279701340943575, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0003278651274740696, Min w: 4.571289035073005e-36\n",
      "Iteration 330, Loss: 0.00041419322951696813, Min w: 1.4366947057047693e-33\n",
      "Iteration 340, Loss: 0.00034424749901518226, Min w: 1.5379160658694141e-21\n",
      "Iteration 350, Loss: 0.0003299227973911911, Min w: 2.3427321958454164e-16\n",
      "Iteration 360, Loss: 0.0003551161498762667, Min w: 2.370126230694103e-12\n",
      "Iteration 370, Loss: 0.0003481098101474345, Min w: 1.6759346976868983e-07\n",
      "Iteration 380, Loss: 0.000383539532776922, Min w: 0.0005889332387596369\n",
      "Iteration 390, Loss: 0.00032182573340833187, Min w: 0.09041506797075272\n",
      "Iteration 400, Loss: 0.00029310330864973366, Min w: 0.12937098741531372\n",
      "Iteration 410, Loss: 0.0004022916837129742, Min w: 0.16815003752708435\n",
      "Iteration 420, Loss: 0.00029528498998843133, Min w: 0.1989019513130188\n",
      "Iteration 430, Loss: 0.0002838738146238029, Min w: 0.2288217693567276\n",
      "Iteration 440, Loss: 0.0003502853505779058, Min w: 0.12653695046901703\n",
      "Iteration 450, Loss: 0.00026684984914027154, Min w: 0.2850184738636017\n",
      "Iteration 460, Loss: 0.0003130791592411697, Min w: 0.23015789687633514\n",
      "Iteration 470, Loss: 0.00025816031848080456, Min w: 0.37140655517578125\n",
      "Iteration 480, Loss: 0.00023056127247400582, Min w: 0.36074087023735046\n",
      "Iteration 490, Loss: 0.0002721103955991566, Min w: 0.32180941104888916\n",
      "Iteration 500, Loss: 0.00022811771486885846, Min w: 0.48399096727371216\n",
      "Iteration 510, Loss: 0.00019689591135829687, Min w: 0.5154640078544617\n",
      "Iteration 520, Loss: 0.00019873064593411982, Min w: 0.5163491368293762\n",
      "Iteration 530, Loss: 0.00023360014893114567, Min w: 0.46747976541519165\n",
      "Iteration 540, Loss: 0.000214042462175712, Min w: 0.4606654644012451\n",
      "Iteration 550, Loss: 0.00018478368292562664, Min w: 0.5338146686553955\n",
      "Iteration 560, Loss: 0.00019579363288357854, Min w: 0.5023775100708008\n",
      "Iteration 570, Loss: 0.00021249883866403252, Min w: 0.4953896701335907\n",
      "Iteration 580, Loss: 0.00020622601732611656, Min w: 0.5468037724494934\n",
      "Iteration 590, Loss: 0.00021669337002094835, Min w: 0.4941103160381317\n",
      "Iteration 600, Loss: 0.00016391879762522876, Min w: 0.652168333530426\n",
      "Iteration 610, Loss: 0.00014242444012779742, Min w: 0.6623032093048096\n",
      "Iteration 620, Loss: 0.00016665246221236885, Min w: 0.6189159154891968\n",
      "Iteration 630, Loss: 0.00012491604138631374, Min w: 0.7125325798988342\n",
      "Iteration 640, Loss: 0.00016490275447722524, Min w: 0.6435828804969788\n",
      "Iteration 650, Loss: 0.0001823751226766035, Min w: 0.5124596357345581\n",
      "Iteration 660, Loss: 0.00012383355351630598, Min w: 0.7213990092277527\n",
      "Iteration 670, Loss: 0.000215858148294501, Min w: 0.5501960515975952\n",
      "Iteration 680, Loss: 0.00015923175669740885, Min w: 0.6529849767684937\n",
      "Iteration 690, Loss: 0.00012646455434150994, Min w: 0.7066307067871094\n",
      "Iteration 700, Loss: 0.00010251550702378154, Min w: 0.7678735256195068\n",
      "Iteration 710, Loss: 0.00010486788960406557, Min w: 0.7735673189163208\n",
      "Iteration 720, Loss: 0.00014384703536052257, Min w: 0.703269362449646\n",
      "Iteration 730, Loss: 0.00012399831030052155, Min w: 0.706081211566925\n",
      "Iteration 740, Loss: 0.00020010181469842792, Min w: 0.5603992342948914\n",
      "Iteration 750, Loss: 0.00022518588230013847, Min w: 0.509829044342041\n",
      "Iteration 760, Loss: 0.00010044263035524637, Min w: 0.7799917459487915\n",
      "Iteration 770, Loss: 0.00012178450560895726, Min w: 0.7456502914428711\n",
      "Iteration 780, Loss: 0.00011643575271591544, Min w: 0.7434737682342529\n",
      "Iteration 790, Loss: 0.0001535473420517519, Min w: 0.6425604820251465\n",
      "Iteration 800, Loss: 0.00011635950795607641, Min w: 0.7447913885116577\n",
      "Iteration 810, Loss: 0.00012198369950056076, Min w: 0.6803945899009705\n",
      "Iteration 820, Loss: 9.628922998672351e-05, Min w: 0.7870055437088013\n",
      "Iteration 830, Loss: 0.0001814868883229792, Min w: 0.6003748774528503\n",
      "Iteration 840, Loss: 0.0001575149508425966, Min w: 0.6624516248703003\n",
      "Iteration 850, Loss: 8.829389116726816e-05, Min w: 0.8112812638282776\n",
      "Iteration 860, Loss: 9.234328172169626e-05, Min w: 0.8079394698143005\n",
      "Iteration 870, Loss: 0.00012824038276448846, Min w: 0.7382110357284546\n",
      "Iteration 880, Loss: 6.808514444855973e-05, Min w: 0.859032928943634\n",
      "Iteration 890, Loss: 0.00013262235734146088, Min w: 0.6958470940589905\n",
      "Iteration 900, Loss: 0.00016153226897586137, Min w: 0.6677109003067017\n",
      "Iteration 910, Loss: 0.00010637257219059393, Min w: 0.7746211886405945\n",
      "Iteration 920, Loss: 7.577620272058994e-05, Min w: 0.8133527636528015\n",
      "Iteration 930, Loss: 9.805829176912084e-05, Min w: 0.7695914506912231\n",
      "Iteration 940, Loss: 0.00012395162775646895, Min w: 0.6952992081642151\n",
      "Iteration 950, Loss: 8.977925608633086e-05, Min w: 0.7890016436576843\n",
      "Iteration 960, Loss: 7.349975930992514e-05, Min w: 0.8464524149894714\n",
      "Iteration 970, Loss: 7.118054782040417e-05, Min w: 0.813977062702179\n",
      "Iteration 980, Loss: 7.138330693123862e-05, Min w: 0.805942714214325\n",
      "Iteration 990, Loss: 8.281829650513828e-05, Min w: 0.8174496293067932\n",
      "Iteration 1000, Loss: 8.074876677710563e-05, Min w: 0.7871957421302795\n",
      "Iteration 1010, Loss: 7.117905624909326e-05, Min w: 0.8264986276626587\n",
      "Iteration 1020, Loss: 9.093656990444288e-05, Min w: 0.7965572476387024\n",
      "Iteration 1030, Loss: 7.626251317560673e-05, Min w: 0.832065999507904\n",
      "Iteration 1040, Loss: 7.504898530896753e-05, Min w: 0.7802132368087769\n",
      "Iteration 1050, Loss: 6.913962715771049e-05, Min w: 0.8190423250198364\n",
      "Iteration 1060, Loss: 6.49249050184153e-05, Min w: 0.8388572335243225\n",
      "Iteration 1070, Loss: 7.005091902101412e-05, Min w: 0.8247107267379761\n",
      "Iteration 1080, Loss: 7.166049181250855e-05, Min w: 0.8177675008773804\n",
      "Iteration 1090, Loss: 5.5646709370194e-05, Min w: 0.8554998636245728\n",
      "Iteration 1100, Loss: 9.618810872780159e-05, Min w: 0.7291821837425232\n",
      "Iteration 1110, Loss: 7.27756050764583e-05, Min w: 0.7918025255203247\n",
      "Iteration 1120, Loss: 7.119953806977719e-05, Min w: 0.7914770245552063\n",
      "Iteration 1130, Loss: 4.1378967580385506e-05, Min w: 0.9132806658744812\n",
      "Iteration 1140, Loss: 6.533812120324001e-05, Min w: 0.839897871017456\n",
      "Iteration 1150, Loss: 0.00015337711374741048, Min w: 0.6122093796730042\n",
      "Iteration 1160, Loss: 3.8898371713003144e-05, Min w: 0.9194080829620361\n",
      "Iteration 1170, Loss: 6.645998655585572e-05, Min w: 0.8386399745941162\n",
      "Iteration 1180, Loss: 0.00010898741311393678, Min w: 0.7360535264015198\n",
      "Iteration 1190, Loss: 9.93952271528542e-05, Min w: 0.7426186203956604\n",
      "Iteration 1200, Loss: 6.987203232711181e-05, Min w: 0.8108506798744202\n",
      "Iteration 1210, Loss: 6.0011410823790357e-05, Min w: 0.8612323999404907\n",
      "Iteration 1220, Loss: 7.591467146994546e-05, Min w: 0.8410687446594238\n",
      "Iteration 1230, Loss: 5.104922820464708e-05, Min w: 0.8674067258834839\n",
      "Iteration 1240, Loss: 5.0684157031355426e-05, Min w: 0.8691351413726807\n",
      "Iteration 0, Loss: 6.247959390748292e-05, Min w: 0.8587709665298462\n",
      "Iteration 10, Loss: 9.138537279795855e-05, Min w: 0.7577635645866394\n",
      "Iteration 20, Loss: 4.9647722335066646e-05, Min w: 0.8815921545028687\n",
      "Iteration 30, Loss: 5.214936027186923e-05, Min w: 0.856891393661499\n",
      "Iteration 40, Loss: 4.526791599346325e-05, Min w: 0.8796899914741516\n",
      "Iteration 50, Loss: 0.00015475023246835917, Min w: 0.6125052571296692\n",
      "Iteration 60, Loss: 5.498552491189912e-05, Min w: 0.8704748153686523\n",
      "Iteration 70, Loss: 4.4062326196581125e-05, Min w: 0.8910686373710632\n",
      "Iteration 80, Loss: 6.23021405772306e-05, Min w: 0.8292666077613831\n",
      "Iteration 90, Loss: 6.894102989463136e-05, Min w: 0.7987460494041443\n",
      "Iteration 100, Loss: 6.130956171546131e-05, Min w: 0.8163924217224121\n",
      "Iteration 110, Loss: 5.028805026086047e-05, Min w: 0.8641010522842407\n",
      "Iteration 120, Loss: 4.6336263039847836e-05, Min w: 0.8770419955253601\n",
      "Iteration 130, Loss: 5.6074113672366366e-05, Min w: 0.865412712097168\n",
      "Iteration 140, Loss: 7.978921348694712e-05, Min w: 0.8021533489227295\n",
      "Iteration 150, Loss: 6.707959983032197e-05, Min w: 0.8442436456680298\n",
      "Iteration 160, Loss: 6.205577665241435e-05, Min w: 0.8292384147644043\n",
      "Iteration 170, Loss: 4.022282155347057e-05, Min w: 0.9075797200202942\n",
      "Iteration 180, Loss: 3.745513458852656e-05, Min w: 0.9207261204719543\n",
      "Iteration 190, Loss: 9.126697113970295e-05, Min w: 0.7958422899246216\n",
      "Iteration 200, Loss: 8.196560520445928e-05, Min w: 0.8116735219955444\n",
      "Iteration 210, Loss: 6.866333569632843e-05, Min w: 0.8584638833999634\n",
      "Iteration 220, Loss: 5.317311661201529e-05, Min w: 0.8399598598480225\n",
      "Iteration 230, Loss: 7.282292062882334e-05, Min w: 0.774705708026886\n",
      "Iteration 240, Loss: 5.837310527567752e-05, Min w: 0.8220407366752625\n",
      "Iteration 250, Loss: 6.0681733884848654e-05, Min w: 0.836527943611145\n",
      "Iteration 260, Loss: 5.798105485155247e-05, Min w: 0.8170604109764099\n",
      "Iteration 270, Loss: 4.6605531679233536e-05, Min w: 0.8577784895896912\n",
      "Iteration 280, Loss: 7.593281043227762e-05, Min w: 0.8135747909545898\n",
      "Iteration 290, Loss: 5.8002191508421674e-05, Min w: 0.8352565765380859\n",
      "Iteration 300, Loss: 2.9254671972012147e-05, Min w: 0.9298835396766663\n",
      "Iteration 310, Loss: 4.4845615775557235e-05, Min w: 0.9011553525924683\n",
      "Iteration 320, Loss: 3.421111250645481e-05, Min w: 0.9205628037452698\n",
      "Iteration 330, Loss: 5.2121893531875685e-05, Min w: 0.8372119665145874\n",
      "Iteration 340, Loss: 5.399283327278681e-05, Min w: 0.8300454020500183\n",
      "Iteration 350, Loss: 3.936697976314463e-05, Min w: 0.9051811695098877\n",
      "Iteration 360, Loss: 6.324145942926407e-05, Min w: 0.8680275082588196\n",
      "Iteration 370, Loss: 4.553196413326077e-05, Min w: 0.8953501582145691\n",
      "Iteration 380, Loss: 5.308527033776045e-05, Min w: 0.884470522403717\n",
      "Iteration 390, Loss: 2.8085103622288443e-05, Min w: 0.9390314221382141\n",
      "Iteration 400, Loss: 3.6200090107740834e-05, Min w: 0.890400767326355\n",
      "Iteration 410, Loss: 4.234275547787547e-05, Min w: 0.8989167213439941\n",
      "Iteration 420, Loss: 6.54820614727214e-05, Min w: 0.8274555802345276\n",
      "Iteration 430, Loss: 4.467978942557238e-05, Min w: 0.8767854571342468\n",
      "Iteration 440, Loss: 4.2740761273307726e-05, Min w: 0.8642393946647644\n",
      "Iteration 450, Loss: 3.18412967317272e-05, Min w: 0.9029176235198975\n",
      "Iteration 460, Loss: 3.372345236130059e-05, Min w: 0.9254654049873352\n",
      "Iteration 470, Loss: 1.744543442327995e-05, Min w: 0.9608269333839417\n",
      "Iteration 480, Loss: 6.48512359475717e-05, Min w: 0.807349681854248\n",
      "Iteration 490, Loss: 4.647036621463485e-05, Min w: 0.8720288276672363\n",
      "Iteration 500, Loss: 0.00010624925198499113, Min w: 0.7567996978759766\n",
      "Iteration 510, Loss: 3.369803380337544e-05, Min w: 0.9242612719535828\n",
      "Iteration 520, Loss: 3.7684694689232856e-05, Min w: 0.8850386738777161\n",
      "Iteration 530, Loss: 4.368338704807684e-05, Min w: 0.8562307953834534\n",
      "Iteration 540, Loss: 3.794384247157723e-05, Min w: 0.8773662447929382\n",
      "Iteration 550, Loss: 4.863719368586317e-05, Min w: 0.8503624200820923\n",
      "Iteration 560, Loss: 4.5195229176897556e-05, Min w: 0.8715745210647583\n",
      "Iteration 570, Loss: 4.8146015615202487e-05, Min w: 0.8603157997131348\n",
      "Iteration 580, Loss: 4.343265027273446e-05, Min w: 0.8634698390960693\n",
      "Iteration 590, Loss: 4.648097456083633e-05, Min w: 0.8517282009124756\n",
      "Iteration 600, Loss: 2.778290036076214e-05, Min w: 0.917676568031311\n",
      "Iteration 610, Loss: 4.39300638390705e-05, Min w: 0.9042826294898987\n",
      "Iteration 620, Loss: 3.363932410138659e-05, Min w: 0.9017676115036011\n",
      "Iteration 630, Loss: 3.766541703953408e-05, Min w: 0.8907386660575867\n",
      "Iteration 640, Loss: 3.229013964300975e-05, Min w: 0.9134662747383118\n",
      "Iteration 650, Loss: 2.125306309608277e-05, Min w: 0.9422913193702698\n",
      "Iteration 660, Loss: 3.2795374863781035e-05, Min w: 0.8996182084083557\n",
      "Iteration 670, Loss: 3.259701406932436e-05, Min w: 0.9299939870834351\n",
      "Iteration 680, Loss: 3.6768800782738253e-05, Min w: 0.885280191898346\n",
      "Iteration 690, Loss: 3.0259947379818186e-05, Min w: 0.9121169447898865\n",
      "Iteration 700, Loss: 4.126589192310348e-05, Min w: 0.9110934734344482\n",
      "Iteration 710, Loss: 2.9600840207422152e-05, Min w: 0.9092742800712585\n",
      "Iteration 720, Loss: 4.3029405787819996e-05, Min w: 0.8864847421646118\n",
      "Iteration 730, Loss: 3.352632847963832e-05, Min w: 0.9226539731025696\n",
      "Iteration 740, Loss: 5.0800277676898986e-05, Min w: 0.8316037058830261\n",
      "Iteration 750, Loss: 3.657097840914503e-05, Min w: 0.9131485819816589\n",
      "Iteration 760, Loss: 4.663940126192756e-05, Min w: 0.8544484376907349\n",
      "Iteration 770, Loss: 1.922164301504381e-05, Min w: 0.9531917572021484\n",
      "Iteration 780, Loss: 3.5030272556468844e-05, Min w: 0.9053865671157837\n",
      "Iteration 790, Loss: 1.5836614693398587e-05, Min w: 0.9651434421539307\n",
      "Iteration 800, Loss: 6.632058648392558e-05, Min w: 0.8583815097808838\n",
      "Iteration 810, Loss: 2.939759724540636e-05, Min w: 0.9198914766311646\n",
      "Iteration 820, Loss: 3.294030102551915e-05, Min w: 0.9308127760887146\n",
      "Iteration 830, Loss: 4.389968671603128e-05, Min w: 0.8889355659484863\n",
      "Iteration 840, Loss: 4.496072870097123e-05, Min w: 0.8710427284240723\n",
      "Iteration 850, Loss: 4.478714618016966e-05, Min w: 0.851202666759491\n",
      "Iteration 860, Loss: 3.8480520743178204e-05, Min w: 0.8814688920974731\n",
      "Iteration 870, Loss: 3.157487662974745e-05, Min w: 0.8926703333854675\n",
      "Iteration 880, Loss: 4.195802102913149e-05, Min w: 0.9083418846130371\n",
      "Iteration 890, Loss: 3.009094507433474e-05, Min w: 0.903450071811676\n",
      "Iteration 900, Loss: 2.3049768060445786e-05, Min w: 0.9498183131217957\n",
      "Iteration 910, Loss: 3.776512676267885e-05, Min w: 0.8797891736030579\n",
      "Iteration 920, Loss: 1.3955893336969893e-05, Min w: 0.9673605561256409\n",
      "Iteration 930, Loss: 1.7312229829258285e-05, Min w: 0.9505817890167236\n",
      "Iteration 940, Loss: 1.506803891970776e-05, Min w: 0.9682810306549072\n",
      "Iteration 950, Loss: 3.128140087937936e-05, Min w: 0.9059773683547974\n",
      "Iteration 960, Loss: 3.795816519414075e-05, Min w: 0.9191285967826843\n",
      "Iteration 970, Loss: 3.495542478049174e-05, Min w: 0.879173994064331\n",
      "Iteration 980, Loss: 2.358137135161087e-05, Min w: 0.9421107769012451\n",
      "Iteration 990, Loss: 2.9014139727223665e-05, Min w: 0.9196172952651978\n",
      "Iteration 1000, Loss: 2.9339011234696954e-05, Min w: 0.9061011672019958\n",
      "Iteration 1010, Loss: 2.9242481105029583e-05, Min w: 0.9076170921325684\n",
      "Iteration 1020, Loss: 2.8870519599877298e-05, Min w: 0.9202515482902527\n",
      "Iteration 1030, Loss: 3.3751275623217225e-05, Min w: 0.8987802863121033\n",
      "Iteration 1040, Loss: 2.8751073841704056e-05, Min w: 0.9334891438484192\n",
      "Iteration 1050, Loss: 3.8818750908831134e-05, Min w: 0.867659866809845\n",
      "Iteration 1060, Loss: 1.3878964637115132e-05, Min w: 0.9687220454216003\n",
      "Iteration 1070, Loss: 4.304261165088974e-05, Min w: 0.8588677644729614\n",
      "Iteration 1080, Loss: 1.658307883189991e-05, Min w: 0.9557035565376282\n",
      "Iteration 1090, Loss: 1.656155291129835e-05, Min w: 0.9550732970237732\n",
      "Iteration 1100, Loss: 4.623844870366156e-05, Min w: 0.8970879316329956\n",
      "Iteration 1110, Loss: 5.509984475793317e-05, Min w: 0.8701589703559875\n",
      "Iteration 1120, Loss: 1.2446202163118869e-05, Min w: 0.9692004323005676\n",
      "Iteration 1130, Loss: 5.091699858894572e-05, Min w: 0.8819704055786133\n",
      "Iteration 1140, Loss: 2.908942951762583e-05, Min w: 0.9172970056533813\n",
      "Iteration 1150, Loss: 1.984821392397862e-05, Min w: 0.9427825808525085\n",
      "Iteration 1160, Loss: 4.0400325815426186e-05, Min w: 0.9159988164901733\n",
      "Iteration 1170, Loss: 3.711050158017315e-05, Min w: 0.8797274231910706\n",
      "Iteration 1180, Loss: 2.5063407520065084e-05, Min w: 0.9283819198608398\n",
      "Iteration 1190, Loss: 1.8108405129169114e-05, Min w: 0.9507659077644348\n",
      "Iteration 1200, Loss: 2.0246865460649133e-05, Min w: 0.9466971158981323\n",
      "Iteration 1210, Loss: 5.2280545787652954e-05, Min w: 0.8346699476242065\n",
      "Iteration 1220, Loss: 4.575981438392773e-05, Min w: 0.8376392126083374\n",
      "Iteration 1230, Loss: 1.9682813217514195e-05, Min w: 0.953624427318573\n",
      "Iteration 1240, Loss: 2.442105505906511e-05, Min w: 0.9232913851737976\n",
      "Iteration 0, Loss: 2.4956296329037286e-05, Min w: 0.9456823468208313\n",
      "Iteration 10, Loss: 3.005757025675848e-05, Min w: 0.9175015091896057\n",
      "Iteration 20, Loss: 3.1064515496836975e-05, Min w: 0.931248128414154\n",
      "Iteration 30, Loss: 2.1726993509219028e-05, Min w: 0.9304138422012329\n",
      "Iteration 40, Loss: 1.1968103535764385e-05, Min w: 0.9656423330307007\n",
      "Iteration 50, Loss: 5.353828601073474e-05, Min w: 0.8598652482032776\n",
      "Iteration 60, Loss: 3.041466152353678e-05, Min w: 0.9179548621177673\n",
      "Iteration 70, Loss: 2.415465860394761e-05, Min w: 0.938900887966156\n",
      "Iteration 80, Loss: 1.9681809135363437e-05, Min w: 0.951935350894928\n",
      "Iteration 90, Loss: 3.982190173701383e-05, Min w: 0.908726692199707\n",
      "Iteration 100, Loss: 4.4669202907243744e-05, Min w: 0.8507004380226135\n",
      "Iteration 110, Loss: 2.9358807296375744e-05, Min w: 0.904083251953125\n",
      "Iteration 120, Loss: 7.190957603597781e-06, Min w: 0.9842661619186401\n",
      "Iteration 130, Loss: 4.657564568333328e-05, Min w: 0.8937067985534668\n",
      "Iteration 140, Loss: 2.9175545932957903e-05, Min w: 0.9085638523101807\n",
      "Iteration 150, Loss: 4.024943336844444e-05, Min w: 0.8812034130096436\n",
      "Iteration 160, Loss: 4.774437547894195e-05, Min w: 0.8948070406913757\n",
      "Iteration 170, Loss: 1.9620596503955312e-05, Min w: 0.9374871850013733\n",
      "Iteration 180, Loss: 2.779737042146735e-05, Min w: 0.9325074553489685\n",
      "Iteration 190, Loss: 2.9568022000603378e-05, Min w: 0.9049166440963745\n",
      "Iteration 200, Loss: 2.6305673600290902e-05, Min w: 0.9134213328361511\n",
      "Iteration 210, Loss: 1.6533602320123464e-05, Min w: 0.9483712315559387\n",
      "Iteration 220, Loss: 3.1114916055230424e-05, Min w: 0.92601478099823\n",
      "Iteration 230, Loss: 2.365296495554503e-05, Min w: 0.9372498989105225\n",
      "Iteration 240, Loss: 2.0492092517088167e-05, Min w: 0.95774906873703\n",
      "Iteration 250, Loss: 3.8056201447034255e-05, Min w: 0.9101635813713074\n",
      "Iteration 260, Loss: 1.573341251059901e-05, Min w: 0.9582677483558655\n",
      "Iteration 270, Loss: 2.1680489226127975e-05, Min w: 0.9358354210853577\n",
      "Iteration 280, Loss: 1.5166801858867984e-05, Min w: 0.9516253471374512\n",
      "Iteration 290, Loss: 3.9589995139976963e-05, Min w: 0.8669697642326355\n",
      "Iteration 300, Loss: 1.4706755791848991e-05, Min w: 0.9533560872077942\n",
      "Iteration 310, Loss: 1.7417243725503795e-05, Min w: 0.9584707617759705\n",
      "Iteration 320, Loss: 2.9263022952363826e-05, Min w: 0.9013510942459106\n",
      "Iteration 330, Loss: 3.846586696454324e-05, Min w: 0.8904899954795837\n",
      "Iteration 340, Loss: 3.306481085019186e-05, Min w: 0.9230055809020996\n",
      "Iteration 350, Loss: 1.459429768146947e-05, Min w: 0.9552587270736694\n",
      "Iteration 360, Loss: 2.7039375709136948e-05, Min w: 0.9347048997879028\n",
      "Iteration 370, Loss: 3.2882126106414944e-05, Min w: 0.8940113186836243\n",
      "Iteration 380, Loss: 7.867860404076055e-06, Min w: 0.9823485612869263\n",
      "Iteration 390, Loss: 3.379985355422832e-05, Min w: 0.904786229133606\n",
      "Iteration 400, Loss: 1.2065425835317e-05, Min w: 0.965250551700592\n",
      "Iteration 410, Loss: 3.0226801754906774e-05, Min w: 0.933202862739563\n",
      "Iteration 420, Loss: 3.6637880839407444e-05, Min w: 0.905148446559906\n",
      "Iteration 430, Loss: 2.7455826057121158e-05, Min w: 0.9292694330215454\n",
      "Iteration 440, Loss: 1.2568787497002631e-05, Min w: 0.9692331552505493\n",
      "Iteration 450, Loss: 1.0486755854799412e-05, Min w: 0.9689542651176453\n",
      "Iteration 460, Loss: 2.30889672820922e-05, Min w: 0.9463894367218018\n",
      "Iteration 470, Loss: 2.64302270807093e-05, Min w: 0.9143260717391968\n",
      "Iteration 480, Loss: 1.3870246220903937e-05, Min w: 0.9548483490943909\n",
      "Iteration 490, Loss: 3.2665808248566464e-05, Min w: 0.8985470533370972\n",
      "Iteration 500, Loss: 2.4747918359935284e-05, Min w: 0.9151842594146729\n",
      "Iteration 510, Loss: 3.7573427107417956e-05, Min w: 0.9170570373535156\n",
      "Iteration 520, Loss: 1.7675194612820633e-05, Min w: 0.9398851990699768\n",
      "Iteration 530, Loss: 1.7106660379795358e-05, Min w: 0.9506723284721375\n",
      "Iteration 540, Loss: 3.3224758226424456e-05, Min w: 0.9141475558280945\n",
      "Iteration 550, Loss: 2.5814981199800968e-05, Min w: 0.9291651248931885\n",
      "Iteration 560, Loss: 1.4461585124081466e-05, Min w: 0.9520336389541626\n",
      "Iteration 570, Loss: 1.712779703666456e-05, Min w: 0.9440292119979858\n",
      "Iteration 580, Loss: 2.6135119696846232e-05, Min w: 0.9191915988922119\n",
      "Iteration 590, Loss: 2.243671042378992e-05, Min w: 0.9396398663520813\n",
      "Iteration 600, Loss: 2.442825098114554e-05, Min w: 0.9433552622795105\n",
      "Iteration 610, Loss: 3.2135987567016855e-05, Min w: 0.8952683806419373\n",
      "Iteration 620, Loss: 2.503135874576401e-05, Min w: 0.9167376160621643\n",
      "Iteration 630, Loss: 1.6328549463651143e-05, Min w: 0.9656964540481567\n",
      "Iteration 640, Loss: 3.561614721547812e-05, Min w: 0.8870955109596252\n",
      "Iteration 650, Loss: 2.6018728021881543e-05, Min w: 0.9261114597320557\n",
      "Iteration 660, Loss: 1.754722325131297e-05, Min w: 0.9534271955490112\n",
      "Iteration 670, Loss: 2.097051947202999e-05, Min w: 0.9481741189956665\n",
      "Iteration 680, Loss: 3.207958798157051e-05, Min w: 0.9008582830429077\n",
      "Iteration 690, Loss: 2.2566724510397762e-05, Min w: 0.949072003364563\n",
      "Iteration 700, Loss: 2.7069589123129845e-05, Min w: 0.9042823314666748\n",
      "Iteration 710, Loss: 3.5744262277148664e-05, Min w: 0.8934204578399658\n",
      "Iteration 720, Loss: 7.88018496677978e-06, Min w: 0.9818155765533447\n",
      "Iteration 730, Loss: 2.5135474061244167e-05, Min w: 0.9160709381103516\n",
      "Iteration 740, Loss: 1.5812764104339294e-05, Min w: 0.9559072256088257\n",
      "Iteration 750, Loss: 3.905951598426327e-05, Min w: 0.9081474542617798\n",
      "Iteration 760, Loss: 9.790723197511397e-06, Min w: 0.974952757358551\n",
      "Iteration 770, Loss: 2.345169377804268e-05, Min w: 0.9442556500434875\n",
      "Iteration 780, Loss: 2.687439337023534e-05, Min w: 0.9067612886428833\n",
      "Iteration 790, Loss: 2.6373008950031362e-05, Min w: 0.9305160641670227\n",
      "Iteration 800, Loss: 1.8871160136768594e-05, Min w: 0.951592743396759\n",
      "Iteration 810, Loss: 3.2591404306003824e-05, Min w: 0.9311059713363647\n",
      "Iteration 820, Loss: 2.806390511977952e-05, Min w: 0.9120840430259705\n",
      "Iteration 830, Loss: 2.7721123842638917e-05, Min w: 0.9224869012832642\n",
      "Iteration 840, Loss: 2.577101440692786e-05, Min w: 0.9147591590881348\n",
      "Iteration 850, Loss: 1.264758702745894e-05, Min w: 0.9672253727912903\n",
      "Iteration 860, Loss: 1.8014019588008523e-05, Min w: 0.9617829918861389\n",
      "Iteration 870, Loss: 2.860688437067438e-05, Min w: 0.9167424440383911\n",
      "Iteration 880, Loss: 5.689611043635523e-06, Min w: 0.9869621396064758\n",
      "Iteration 890, Loss: 3.4635537303984165e-05, Min w: 0.8877260684967041\n",
      "Iteration 900, Loss: 2.4784245397313498e-05, Min w: 0.9250474572181702\n",
      "Iteration 910, Loss: 1.7604512322577648e-05, Min w: 0.9500385522842407\n",
      "Iteration 920, Loss: 1.4167282643029466e-05, Min w: 0.9587187767028809\n",
      "Iteration 930, Loss: 2.308505463588517e-05, Min w: 0.9170408248901367\n",
      "Iteration 940, Loss: 2.3209931896417402e-05, Min w: 0.9323965311050415\n",
      "Iteration 950, Loss: 2.0362920622574165e-05, Min w: 0.9550281167030334\n",
      "Iteration 960, Loss: 3.7264882848830894e-05, Min w: 0.9156265258789062\n",
      "Iteration 970, Loss: 3.363007999723777e-05, Min w: 0.8969329595565796\n",
      "Iteration 980, Loss: 1.6712117940187454e-05, Min w: 0.9444778561592102\n",
      "Iteration 990, Loss: 3.235511394450441e-05, Min w: 0.9272137880325317\n",
      "Iteration 1000, Loss: 2.832912650774233e-05, Min w: 0.904923677444458\n",
      "Iteration 1010, Loss: 1.063481886376394e-05, Min w: 0.9770157933235168\n",
      "Iteration 1020, Loss: 1.718324529065285e-05, Min w: 0.9637866616249084\n",
      "Iteration 1030, Loss: 1.7778271285351366e-05, Min w: 0.9461212158203125\n",
      "Iteration 1040, Loss: 1.9163775505148806e-05, Min w: 0.9594815373420715\n",
      "Iteration 1050, Loss: 1.580351818120107e-05, Min w: 0.9441606998443604\n",
      "Iteration 1060, Loss: 1.2307179531489965e-05, Min w: 0.9639257788658142\n",
      "Iteration 1070, Loss: 1.4162554180074949e-05, Min w: 0.9579585194587708\n",
      "Iteration 1080, Loss: 2.2407910364563577e-05, Min w: 0.925801694393158\n",
      "Iteration 1090, Loss: 3.1082003260962665e-05, Min w: 0.9351815581321716\n",
      "Iteration 1100, Loss: 3.8938509533181787e-05, Min w: 0.8510299921035767\n",
      "Iteration 1110, Loss: 4.211405757814646e-05, Min w: 0.8842248916625977\n",
      "Iteration 1120, Loss: 3.0692724976688623e-05, Min w: 0.9285687208175659\n",
      "Iteration 1130, Loss: 1.522471120551927e-05, Min w: 0.9517694115638733\n",
      "Iteration 1140, Loss: 5.412510290625505e-06, Min w: 0.9880213141441345\n",
      "Iteration 1150, Loss: 2.4413911887677386e-05, Min w: 0.9273771047592163\n",
      "Iteration 1160, Loss: 4.398544660944026e-06, Min w: 0.9888021945953369\n",
      "Early break at iteration 1162 --------------------------------\n",
      "Iteration 0, Loss: 4.984024599252734e-06, Min w: 0.9864972233772278\n",
      "Iteration 10, Loss: 3.4641416277736425e-05, Min w: 0.885910153388977\n",
      "Iteration 20, Loss: 3.638391717686318e-05, Min w: 0.8928342461585999\n",
      "Iteration 30, Loss: 2.8908756576129235e-05, Min w: 0.9241165518760681\n",
      "Iteration 40, Loss: 2.1886558897676878e-05, Min w: 0.92811518907547\n",
      "Iteration 50, Loss: 1.4307134733826388e-05, Min w: 0.9656334519386292\n",
      "Iteration 60, Loss: 2.708985994104296e-05, Min w: 0.899743914604187\n",
      "Iteration 70, Loss: 2.8639180527534336e-05, Min w: 0.9005604982376099\n",
      "Iteration 80, Loss: 1.4714845747221261e-05, Min w: 0.963577151298523\n",
      "Iteration 90, Loss: 1.568540756125003e-05, Min w: 0.9613354206085205\n",
      "Iteration 100, Loss: 1.2389205039653461e-05, Min w: 0.9600358009338379\n",
      "Iteration 110, Loss: 2.8505332011263818e-05, Min w: 0.9334871768951416\n",
      "Iteration 120, Loss: 1.090107616619207e-05, Min w: 0.9717930555343628\n",
      "Iteration 130, Loss: 2.767627483990509e-05, Min w: 0.904396653175354\n",
      "Iteration 140, Loss: 1.8051778170047328e-05, Min w: 0.9556133151054382\n",
      "Iteration 150, Loss: 2.533891711209435e-05, Min w: 0.919934868812561\n",
      "Iteration 160, Loss: 1.2198981494293548e-05, Min w: 0.9619635939598083\n",
      "Iteration 170, Loss: 3.542373451637104e-05, Min w: 0.8897291421890259\n",
      "Iteration 180, Loss: 9.78321986622177e-06, Min w: 0.9744794964790344\n",
      "Iteration 190, Loss: 6.413477422029246e-06, Min w: 0.9840346574783325\n",
      "Iteration 200, Loss: 2.2659685782855377e-05, Min w: 0.9388249516487122\n",
      "Iteration 210, Loss: 1.1445247764640953e-05, Min w: 0.9623212814331055\n",
      "Iteration 220, Loss: 1.3036363270657603e-05, Min w: 0.9725382924079895\n",
      "Iteration 230, Loss: 1.1146045835630503e-05, Min w: 0.9761006236076355\n",
      "Iteration 240, Loss: 2.1393219867604785e-05, Min w: 0.9355144500732422\n",
      "Iteration 250, Loss: 3.619983544922434e-05, Min w: 0.8751979470252991\n",
      "Iteration 260, Loss: 1.3449937796394806e-05, Min w: 0.9646105766296387\n",
      "Iteration 270, Loss: 2.5971970899263397e-05, Min w: 0.9380608201026917\n",
      "Iteration 280, Loss: 2.3746340957586654e-05, Min w: 0.9118816256523132\n",
      "Iteration 290, Loss: 1.2688148672168609e-05, Min w: 0.9693739414215088\n",
      "Iteration 300, Loss: 2.710363332880661e-05, Min w: 0.9111984372138977\n",
      "Iteration 310, Loss: 2.327457332285121e-05, Min w: 0.9512394070625305\n",
      "Iteration 320, Loss: 1.5466010154341348e-05, Min w: 0.9479883313179016\n",
      "Iteration 330, Loss: 2.3033866455079988e-05, Min w: 0.9285880923271179\n",
      "Iteration 340, Loss: 1.7262342225876637e-05, Min w: 0.9473178386688232\n",
      "Iteration 350, Loss: 1.6518439224455506e-05, Min w: 0.9499179720878601\n",
      "Iteration 360, Loss: 1.5151926163525786e-05, Min w: 0.953706681728363\n",
      "Iteration 370, Loss: 1.4835487490927335e-05, Min w: 0.949929416179657\n",
      "Iteration 380, Loss: 2.3797960238880478e-05, Min w: 0.9409286379814148\n",
      "Iteration 390, Loss: 1.392252670484595e-05, Min w: 0.9584521651268005\n",
      "Iteration 400, Loss: 2.665521424205508e-05, Min w: 0.9176709055900574\n",
      "Iteration 410, Loss: 1.3424795724858996e-05, Min w: 0.9595602750778198\n",
      "Iteration 420, Loss: 1.337446337856818e-05, Min w: 0.9607821106910706\n",
      "Iteration 430, Loss: 3.004077916557435e-05, Min w: 0.9381384253501892\n",
      "Early break at iteration 438 --------------------------------\n",
      "Iteration 0, Loss: 5.467869868880371e-06, Min w: 0.9876596331596375\n",
      "Iteration 10, Loss: 4.11379623983521e-05, Min w: 0.8637459874153137\n",
      "Iteration 20, Loss: 1.0701551218517125e-05, Min w: 0.9774417877197266\n",
      "Iteration 30, Loss: 4.12149602198042e-05, Min w: 0.8991273045539856\n",
      "Iteration 40, Loss: 4.262536549504148e-06, Min w: 0.988063633441925\n",
      "Iteration 50, Loss: 3.2758798624854535e-05, Min w: 0.884944498538971\n",
      "Iteration 60, Loss: 2.0367320757941343e-05, Min w: 0.9514255523681641\n",
      "Iteration 70, Loss: 1.9917024474125355e-05, Min w: 0.934392511844635\n",
      "Iteration 80, Loss: 1.3790740922559053e-05, Min w: 0.957435667514801\n",
      "Iteration 90, Loss: 9.949832019628957e-06, Min w: 0.9680548310279846\n",
      "Iteration 100, Loss: 2.716169365157839e-05, Min w: 0.9344139099121094\n",
      "Iteration 110, Loss: 1.0228056453343015e-05, Min w: 0.9740065336227417\n",
      "Iteration 120, Loss: 3.124656359432265e-05, Min w: 0.9062926769256592\n",
      "Iteration 130, Loss: 1.3982989912619814e-05, Min w: 0.9504360556602478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  67%|██████▋   | 16/24 [11:59<05:37, 42.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 140, Loss: 9.48089927987894e-06, Min w: 0.9760243892669678\n",
      "Iteration 150, Loss: 2.2686346710543148e-05, Min w: 0.9489811658859253\n",
      "Early break at iteration 155 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 4258, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.007088416500958757, 'L2_avg': 0.011133640020607563, 'End_point_L1_avg': 0.0024451162241224318, 'End_point_L2_avg': 0.0030143990918246313}\n",
      "Iteration 0, Loss: 0.0044160569086670876, Min w: 0.00024545498308725655\n",
      "Iteration 10, Loss: 0.002909864066168666, Min w: 0.0\n",
      "Iteration 20, Loss: 0.003306057071313262, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0024728195276111364, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002485618693754077, Min w: 0.0\n",
      "Iteration 50, Loss: 0.004644878674298525, Min w: 6.09424702134863e-42\n",
      "Iteration 60, Loss: 0.0026245645713061094, Min w: 0.0\n",
      "Iteration 70, Loss: 0.004736021161079407, Min w: 0.0\n",
      "Iteration 80, Loss: 0.003514386946335435, Min w: 0.0\n",
      "Iteration 90, Loss: 0.005976272746920586, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0042755682952702045, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0032069033477455378, Min w: 0.0\n",
      "Iteration 120, Loss: 0.004318798426538706, Min w: 0.0\n",
      "Iteration 130, Loss: 0.003058505477383733, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0026096191722899675, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00482991524040699, Min w: 8.722663298035491e-14\n",
      "Iteration 160, Loss: 0.0026055104099214077, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002857241313904524, Min w: 0.0\n",
      "Iteration 180, Loss: 0.00275683356449008, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002668780041858554, Min w: 7.146622168056567e-44\n",
      "Iteration 200, Loss: 0.0038379719480872154, Min w: 0.0\n",
      "Iteration 210, Loss: 0.002712724031880498, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0025171940214931965, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0028270387556403875, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0026053846813738346, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0036504187155514956, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0033858628012239933, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0025632691103965044, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0027462835423648357, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002586130052804947, Min w: 0.0\n",
      "Iteration 300, Loss: 0.003170034848153591, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003111653495579958, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0026070326566696167, Min w: 0.0\n",
      "Iteration 330, Loss: 0.003648756304755807, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002780802780762315, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0029919827356934547, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002679822500795126, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0024315533228218555, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002767251105979085, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0029727004002779722, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0036960477009415627, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003236876567825675, Min w: 2.2072985841684054e-18\n",
      "Iteration 420, Loss: 0.0024531742092221975, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003766327630728483, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0034217655193060637, Min w: 2.9319569323367505e-19\n",
      "Iteration 450, Loss: 0.005700208712369204, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0024570489767938852, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0026454890612512827, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0045620352029800415, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0026036188937723637, Min w: 0.0\n",
      "Iteration 500, Loss: 0.00263522332534194, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0038285553455352783, Min w: 0.0\n",
      "Iteration 520, Loss: 0.005286611616611481, Min w: 3.040610081425643e-12\n",
      "Iteration 530, Loss: 0.0024138204753398895, Min w: 0.0\n",
      "Iteration 540, Loss: 0.003918301314115524, Min w: 0.0\n",
      "Iteration 550, Loss: 0.004112830385565758, Min w: 0.0\n",
      "Iteration 560, Loss: 0.003087911056354642, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0031559255439788103, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002928671892732382, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0026716222055256367, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002997002564370632, Min w: 0.0\n",
      "Iteration 610, Loss: 0.003104613395407796, Min w: 2.0010267809941532e-23\n",
      "Iteration 620, Loss: 0.0029362058266997337, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0027171382680535316, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0029164941515773535, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0024900096468627453, Min w: 0.0\n",
      "Iteration 660, Loss: 0.004983406513929367, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002428862964734435, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002741800155490637, Min w: 0.0\n",
      "Iteration 690, Loss: 0.005063510034233332, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0024911430664360523, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0030368699226528406, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004188223276287317, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002976188436150551, Min w: 5.717510953049281e-31\n",
      "Iteration 740, Loss: 0.0026930442545562983, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0024289574939757586, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002890658564865589, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0034601250663399696, Min w: 8.558612600385842e-23\n",
      "Iteration 780, Loss: 0.0044462354853749275, Min w: 0.0\n",
      "Iteration 790, Loss: 0.004885854199528694, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0026482781395316124, Min w: 0.0\n",
      "Iteration 810, Loss: 0.002424828242510557, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002971403067931533, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0058898236602544785, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002693863119930029, Min w: 0.0\n",
      "Iteration 850, Loss: 0.005808712914586067, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003041235264390707, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002469028811901808, Min w: 0.0\n",
      "Iteration 880, Loss: 0.002633176278322935, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0028291824273765087, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0031292946077883244, Min w: 8.208019911254875e-27\n",
      "Iteration 910, Loss: 0.002906155539676547, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0026481356471776962, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0024082083255052567, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0028862066101282835, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0031661787070333958, Min w: 0.0\n",
      "Iteration 960, Loss: 0.003890017978847027, Min w: 0.0\n",
      "Iteration 970, Loss: 0.003336697816848755, Min w: 0.0\n",
      "Iteration 980, Loss: 0.00262911943718791, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002589800162240863, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.003357846522703767, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002712004352360964, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0023998182732611895, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0033362475223839283, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0026043192483484745, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002584142843261361, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0024661244824528694, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0025196427013725042, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.005206755828112364, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0028245795983821154, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.00269722705706954, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.003800142789259553, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.005359290633350611, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.002491883933544159, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0027773487381637096, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0029334186110645533, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0031283567659556866, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003843761747702956, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0045877681113779545, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0025630260352045298, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.004831697326153517, Min w: 3.328744615019308e-14\n",
      "Iteration 1210, Loss: 0.0028456300497055054, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0027699661441147327, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.005010392516851425, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0024258694611489773, Min w: 0.0\n",
      "Iteration 0, Loss: 0.00332681555300951, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0031861718744039536, Min w: 0.0\n",
      "Iteration 20, Loss: 0.003455415368080139, Min w: 0.0\n",
      "Iteration 30, Loss: 0.004942240659147501, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002801769645884633, Min w: 0.0\n",
      "Iteration 50, Loss: 0.003762345528230071, Min w: 0.0\n",
      "Iteration 60, Loss: 0.005921635311096907, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0032618846744298935, Min w: 0.0\n",
      "Iteration 80, Loss: 0.002484892262145877, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002745535923168063, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0031853271648287773, Min w: 0.0\n",
      "Iteration 110, Loss: 0.003291735192760825, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0027145345229655504, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0032282269094139338, Min w: 0.0\n",
      "Iteration 140, Loss: 0.004848754499107599, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0027740143705159426, Min w: 0.0\n",
      "Iteration 160, Loss: 0.008087594993412495, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002433332148939371, Min w: 0.0\n",
      "Iteration 180, Loss: 0.00290594226680696, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002949030138552189, Min w: 0.0\n",
      "Iteration 200, Loss: 0.003122357651591301, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0027023134753108025, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002894387813284993, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002479968825355172, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0036030584014952183, Min w: 0.0\n",
      "Iteration 250, Loss: 0.00354578229598701, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0026652102824300528, Min w: 0.0\n",
      "Iteration 270, Loss: 0.00379726174287498, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0038665158208459616, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0026890025474131107, Min w: 0.0\n",
      "Iteration 300, Loss: 0.005342194344848394, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003558805678039789, Min w: 0.0\n",
      "Iteration 320, Loss: 0.003342192620038986, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00652703270316124, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002547646639868617, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0038852982688695192, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0033909545745700598, Min w: 1.0144532076663794e-39\n",
      "Iteration 370, Loss: 0.003080444410443306, Min w: 0.0\n",
      "Iteration 380, Loss: 0.004291371908038855, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002407073276117444, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002816944383084774, Min w: 0.0\n",
      "Iteration 410, Loss: 0.00311651430092752, Min w: 5.3520208950151654e-24\n",
      "Iteration 420, Loss: 0.0031992364674806595, Min w: 0.0\n",
      "Iteration 430, Loss: 0.002868275623768568, Min w: 0.0\n",
      "Iteration 440, Loss: 0.004215634427964687, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0028905810322612524, Min w: 2.324428700661333e-32\n",
      "Iteration 460, Loss: 0.0027698276098817587, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0027212072163820267, Min w: 0.0\n",
      "Iteration 480, Loss: 0.006984607316553593, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0026684084441512823, Min w: 0.0\n",
      "Iteration 500, Loss: 0.004358811769634485, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0031333519145846367, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0025139660574495792, Min w: 0.0\n",
      "Iteration 530, Loss: 0.00441161822527647, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0044480967335402966, Min w: 0.0\n",
      "Iteration 550, Loss: 0.002829823875799775, Min w: 0.0\n",
      "Iteration 560, Loss: 0.003063004929572344, Min w: 0.0\n",
      "Iteration 570, Loss: 0.003522053826600313, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0027220265474170446, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0025625634007155895, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0029441651422530413, Min w: 9.390381269133464e-41\n",
      "Iteration 610, Loss: 0.0029233915265649557, Min w: 0.0\n",
      "Iteration 620, Loss: 0.004927416332066059, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0032924909610301256, Min w: 0.0\n",
      "Iteration 640, Loss: 0.004935369826853275, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002944262232631445, Min w: 0.0\n",
      "Iteration 660, Loss: 0.003043526317924261, Min w: 1.490462188778788e-37\n",
      "Iteration 670, Loss: 0.0034367619082331657, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0029968086164444685, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0032401748467236757, Min w: 0.0\n",
      "Iteration 700, Loss: 0.00437202351167798, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002545352093875408, Min w: 0.0\n",
      "Iteration 720, Loss: 0.006637223530560732, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002487052232027054, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0028679908718913794, Min w: 0.0\n",
      "Iteration 750, Loss: 0.003958916757255793, Min w: 2.661896877056437e-36\n",
      "Iteration 760, Loss: 0.002640804275870323, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002512131817638874, Min w: 0.0\n",
      "Iteration 780, Loss: 0.00262602255679667, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002768425503745675, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0024756670463830233, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0039786240085959435, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0024280434008687735, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0029647161718457937, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0038399617187678814, Min w: 0.0\n",
      "Iteration 850, Loss: 0.004038795363157988, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0024294457398355007, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0036629512906074524, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0026947178412228823, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0028662276454269886, Min w: 0.0\n",
      "Iteration 900, Loss: 0.004331785254180431, Min w: 0.0\n",
      "Iteration 910, Loss: 0.002351099159568548, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0024553637485951185, Min w: 0.0\n",
      "Iteration 930, Loss: 0.003114078426733613, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0031912068370729685, Min w: 2.802596928649634e-45\n",
      "Iteration 950, Loss: 0.005560625344514847, Min w: 0.0\n",
      "Iteration 960, Loss: 0.004125491715967655, Min w: 0.0\n",
      "Iteration 970, Loss: 0.002782177645713091, Min w: 0.0\n",
      "Iteration 980, Loss: 0.004694328177720308, Min w: 1.945527947100345e-05\n",
      "Iteration 990, Loss: 0.002494894666597247, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0025856972206383944, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0027190442197024822, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.002547440119087696, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.00344636756926775, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.003016961505636573, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0034196642227470875, Min w: 1.0646454990017269e-36\n",
      "Iteration 1060, Loss: 0.0028942811768501997, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0027521539013832808, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0031495082657784224, Min w: 4.75040179406113e-43\n",
      "Iteration 1090, Loss: 0.0033206352964043617, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0035835939925163984, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0031149883288890123, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0068527283146977425, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0026872707530856133, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0045928009785711765, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002940143458545208, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.005791060160845518, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0024612341076135635, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0030282491352409124, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0035474065225571394, Min w: 1.2605251791876335e-24\n",
      "Iteration 1200, Loss: 0.0025024760980159044, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.003175206482410431, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002887560287490487, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0026981146074831486, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002549403114244342, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002607976086437702, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0027412991039454937, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0026836725883185863, Min w: 0.0\n",
      "Iteration 30, Loss: 0.002662279177457094, Min w: 0.0\n",
      "Iteration 40, Loss: 0.00404675817117095, Min w: 7.013562571955845e-05\n",
      "Iteration 50, Loss: 0.0031638951040804386, Min w: 1.6880252331476379e-23\n",
      "Iteration 60, Loss: 0.00482143322005868, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002519341418519616, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0037334500811994076, Min w: 0.0\n",
      "Iteration 90, Loss: 0.004565836396068335, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0026723153423517942, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0032227940391749144, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002689438872039318, Min w: 1.401298464324817e-45\n",
      "Iteration 130, Loss: 0.003214155789464712, Min w: 0.0\n",
      "Iteration 140, Loss: 0.004285994451493025, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00253947451710701, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003189505310729146, Min w: 1.4672520486963793e-32\n",
      "Iteration 170, Loss: 0.004466402344405651, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002582958899438381, Min w: 0.0\n",
      "Iteration 190, Loss: 0.005537896417081356, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0043393331579864025, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0025324791204184294, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0026996585074812174, Min w: 5.324935565732769e-39\n",
      "Iteration 230, Loss: 0.0030709828715771437, Min w: 4.876102911278715e-31\n",
      "Iteration 240, Loss: 0.0025063923094421625, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0024380420800298452, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0032352956477552652, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0027378222439438105, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002776017878204584, Min w: 2.1787756224039295e-37\n",
      "Iteration 290, Loss: 0.0025399967562407255, Min w: 0.0\n",
      "Iteration 300, Loss: 0.003160028485581279, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0034151801373809576, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0028630306478589773, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0029528499580919743, Min w: 0.0\n",
      "Iteration 340, Loss: 0.004007712006568909, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002823200076818466, Min w: 0.0\n",
      "Iteration 360, Loss: 0.002714548259973526, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002678442979231477, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002631391864269972, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0033097376581281424, Min w: 8.407790785948902e-45\n",
      "Iteration 400, Loss: 0.0030776856001466513, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0034030135720968246, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0030073868110775948, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0031735070515424013, Min w: 0.0\n",
      "Iteration 440, Loss: 0.002494468353688717, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0034208588767796755, Min w: 0.0\n",
      "Iteration 460, Loss: 0.004038638900965452, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0026970484759658575, Min w: 0.0\n",
      "Iteration 480, Loss: 0.005121840164065361, Min w: 2.5214341269503827e-37\n",
      "Iteration 490, Loss: 0.0038188763428479433, Min w: 0.0\n",
      "Iteration 500, Loss: 0.002908840775489807, Min w: 0.0\n",
      "Iteration 510, Loss: 0.003710115561261773, Min w: 3.174657979613191e-17\n",
      "Iteration 520, Loss: 0.002752992557361722, Min w: 0.0\n",
      "Iteration 530, Loss: 0.003570984583348036, Min w: 0.0\n",
      "Iteration 540, Loss: 0.002819814020767808, Min w: 0.0\n",
      "Iteration 550, Loss: 0.006978225894272327, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026156778912991285, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002466328674927354, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002726118778809905, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0034523592330515385, Min w: 8.092099261413486e-39\n",
      "Iteration 600, Loss: 0.0032590327318757772, Min w: 1.8423956883157059e-34\n",
      "Iteration 610, Loss: 0.0027204747311770916, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0035457334015518427, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0026119286194443703, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0024287181440740824, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0026672997046262026, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0033480313140898943, Min w: 9.925071005000654e-28\n",
      "Iteration 670, Loss: 0.0032994456123560667, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0026328996755182743, Min w: 0.0\n",
      "Iteration 690, Loss: 0.003002205630764365, Min w: 0.0\n",
      "Iteration 700, Loss: 0.002455422654747963, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0026758352760225534, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004504594020545483, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0039020886179059744, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0034399034921079874, Min w: 0.0\n",
      "Iteration 750, Loss: 0.003132002893835306, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002634035423398018, Min w: 0.0\n",
      "Iteration 770, Loss: 0.002802712144330144, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0029345182701945305, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0036936167161911726, Min w: 3.8936402049056205e-15\n",
      "Iteration 800, Loss: 0.0026590449269860983, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0024615430738776922, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0037167081609368324, Min w: 0.0\n",
      "Iteration 830, Loss: 0.004290162585675716, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0025659489911049604, Min w: 0.0\n",
      "Iteration 850, Loss: 0.00296425842680037, Min w: 2.222232286805613e-36\n",
      "Iteration 860, Loss: 0.0028225728310644627, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002553537953644991, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0029994728974997997, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0026175230741500854, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0024706691037863493, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0029244855977594852, Min w: 8.09764563651402e-27\n",
      "Iteration 920, Loss: 0.0029828990809619427, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0024653382133692503, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0027653034776449203, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0044724359177052975, Min w: 0.0\n",
      "Iteration 960, Loss: 0.003638644004240632, Min w: 0.0\n",
      "Iteration 970, Loss: 0.00315307080745697, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0035261057782918215, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002698583295568824, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0024155855644494295, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0028204068075865507, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0038447827100753784, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.002534789266064763, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0028693603817373514, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0025833030231297016, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002705630147829652, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.002893951954320073, Min w: 3.457858103552562e-40\n",
      "Iteration 1080, Loss: 0.0048419637605547905, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0024159641470760107, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.002500067465007305, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.002931225346401334, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.003135247156023979, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.003320290008559823, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.002402468817308545, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002750533167272806, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.004749147687107325, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0026901126839220524, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002860684646293521, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0029663285240530968, Min w: 1.8216880036222622e-44\n",
      "Iteration 1200, Loss: 0.0026867527049034834, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0031093808356672525, Min w: 1.4589441612984188e-36\n",
      "Iteration 1220, Loss: 0.0041216593235731125, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.006173936650156975, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002422572346404195, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0025583053939044476, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0027279993519186974, Min w: 0.0\n",
      "Iteration 20, Loss: 0.00297325337305665, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0028928671963512897, Min w: 3.923635700109488e-44\n",
      "Iteration 40, Loss: 0.002611739095300436, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0034380792640149593, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0030172374099493027, Min w: 0.0\n",
      "Iteration 70, Loss: 0.004139808006584644, Min w: 3.051381774128916e-27\n",
      "Iteration 80, Loss: 0.0025218597147613764, Min w: 0.0\n",
      "Iteration 90, Loss: 0.004005632363259792, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0028928087558597326, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0063446336425840855, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0030308428686112165, Min w: 0.0\n",
      "Iteration 130, Loss: 0.002803067909553647, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0035911693703383207, Min w: 3.800129514120609e-19\n",
      "Iteration 150, Loss: 0.004645050037652254, Min w: 0.0\n",
      "Iteration 160, Loss: 0.004192551132291555, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0025264376308768988, Min w: 0.0\n",
      "Iteration 180, Loss: 0.006297342479228973, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002910202369093895, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0026146734599024057, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0029354116413742304, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0036140657030045986, Min w: 2.459494879297711e-22\n",
      "Iteration 230, Loss: 0.006203516386449337, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002640604740008712, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0031771757639944553, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0033220257610082626, Min w: 1.3470234268897564e-30\n",
      "Iteration 270, Loss: 0.004516120534390211, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0023969304747879505, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002450058236718178, Min w: 0.0\n",
      "Iteration 300, Loss: 0.003302063560113311, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002490120707079768, Min w: 0.0\n",
      "Iteration 320, Loss: 0.003351558232679963, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0029236627742648125, Min w: 0.0\n",
      "Iteration 340, Loss: 0.00326378270983696, Min w: 0.0\n",
      "Iteration 350, Loss: 0.005061077885329723, Min w: 0.0\n",
      "Iteration 360, Loss: 0.003003992373123765, Min w: 0.0\n",
      "Iteration 370, Loss: 0.004940438084304333, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0026326703373342752, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0027288736309856176, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0025917391758412123, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0037430303636938334, Min w: 8.282243705963477e-13\n",
      "Iteration 420, Loss: 0.00495284516364336, Min w: 0.0\n",
      "Iteration 430, Loss: 0.003034549066796899, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0025803069584071636, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0025060740299522877, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003044229932129383, Min w: 0.0\n",
      "Iteration 470, Loss: 0.003296756884083152, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0026284323539584875, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0024064849130809307, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003860152792185545, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002712666755542159, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002758945571258664, Min w: 0.0\n",
      "Iteration 530, Loss: 0.005930567160248756, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0024001465644687414, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0031441878527402878, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0028306932654231787, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002415864961221814, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0028175630141049623, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0025625363923609257, Min w: 0.0\n",
      "Iteration 600, Loss: 0.003262291196733713, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002929993439465761, Min w: 0.0\n",
      "Iteration 620, Loss: 0.002490116050466895, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0028299179393798113, Min w: 0.0\n",
      "Iteration 640, Loss: 0.002749840961769223, Min w: 2.722302526643822e-41\n",
      "Iteration 650, Loss: 0.003323235781863332, Min w: 0.0\n",
      "Iteration 660, Loss: 0.002804254414513707, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0032610672060400248, Min w: 0.0\n",
      "Iteration 680, Loss: 0.003810762194916606, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002557992935180664, Min w: 0.0\n",
      "Iteration 700, Loss: 0.002581582870334387, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0029578404501080513, Min w: 0.0\n",
      "Iteration 720, Loss: 0.002814828883856535, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002861791057512164, Min w: 0.0\n",
      "Iteration 740, Loss: 0.003361476818099618, Min w: 0.0\n",
      "Iteration 750, Loss: 0.003584877587854862, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002463974989950657, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0027388171292841434, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0026011685840785503, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0028115964960306883, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0031435564160346985, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0035534733906388283, Min w: 4.3178973194969565e-30\n",
      "Iteration 820, Loss: 0.003000123891979456, Min w: 0.0\n",
      "Iteration 830, Loss: 0.003493157448247075, Min w: 6.953635916784148e-18\n",
      "Iteration 840, Loss: 0.002716876333579421, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002424416830763221, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003466853639110923, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0026640528813004494, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0027371905744075775, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0035416169557720423, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0025870585814118385, Min w: 0.0\n",
      "Iteration 910, Loss: 0.002542067551985383, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0038317316211760044, Min w: 0.0\n",
      "Iteration 930, Loss: 0.002650859532877803, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002911480376496911, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0026902426034212112, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0026549834292382, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0036206610966473818, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0028703580610454082, Min w: 0.0\n",
      "Iteration 990, Loss: 0.004326116759330034, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0036485770251601934, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0032041410449892282, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0030734813772141933, Min w: 1.1712000369261622e-35\n",
      "Iteration 1030, Loss: 0.002648439258337021, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002491382649168372, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002765956800431013, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.004047036170959473, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0024173783604055643, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.003587420331314206, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0030420999974012375, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0025722866412252188, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0025528897531330585, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.004050949588418007, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.004580235108733177, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0029268350917845964, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0026261359453201294, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0028655773494392633, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003345385892316699, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002605044050142169, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0032352618873119354, Min w: 1.2713081109392841e-17\n",
      "Iteration 1200, Loss: 0.002768056932836771, Min w: 6.769672881153191e-42\n",
      "Iteration 1210, Loss: 0.004157974384725094, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0033255943562835455, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002710337284952402, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.004013495985418558, Min w: 0.0\n",
      "Iteration 0, Loss: 0.002629399299621582, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0029699141159653664, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0030853941570967436, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0028360348660498857, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0026829850394278765, Min w: 0.0\n",
      "Iteration 50, Loss: 0.003133494174107909, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0033353057224303484, Min w: 3.3889821940892345e-26\n",
      "Iteration 70, Loss: 0.0023381425999104977, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0026323264464735985, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0024452395737171173, Min w: 0.0\n",
      "Iteration 100, Loss: 0.003402081085368991, Min w: 0.0\n",
      "Iteration 110, Loss: 0.003922728821635246, Min w: 0.0\n",
      "Iteration 120, Loss: 0.002513321815058589, Min w: 0.0\n",
      "Iteration 130, Loss: 0.004537856671959162, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0028072032146155834, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0026130646001547575, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003609235165640712, Min w: 0.0\n",
      "Iteration 170, Loss: 0.004075477831065655, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0027414432261139154, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002607006812468171, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002608860842883587, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0024559686426073313, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0031809338834136724, Min w: 0.0\n",
      "Iteration 230, Loss: 0.00256180576980114, Min w: 0.0\n",
      "Iteration 240, Loss: 0.004343811422586441, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0029675420373678207, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0030493095982819796, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0024405806325376034, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002412952482700348, Min w: 0.0\n",
      "Iteration 290, Loss: 0.003120649605989456, Min w: 0.0\n",
      "Iteration 300, Loss: 0.002724488964304328, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0035501685924828053, Min w: 0.0\n",
      "Iteration 320, Loss: 0.003884300822392106, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0026508946903049946, Min w: 0.0\n",
      "Iteration 340, Loss: 0.004022718407213688, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002595203462988138, Min w: 0.0\n",
      "Iteration 360, Loss: 0.00297240586951375, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0032875696197152138, Min w: 1.2606352252839118e-25\n",
      "Iteration 380, Loss: 0.0037839708384126425, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0025500613264739513, Min w: 0.0\n",
      "Iteration 400, Loss: 0.002525186166167259, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0031155580654740334, Min w: 2.71767824171155e-41\n",
      "Iteration 420, Loss: 0.0028876415453851223, Min w: 0.0\n",
      "Iteration 430, Loss: 0.00251781870611012, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0025037105660885572, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002523823408409953, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0026430850848555565, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0033409702591598034, Min w: 0.0\n",
      "Iteration 480, Loss: 0.003169350093230605, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0024433848448097706, Min w: 0.0\n",
      "Iteration 500, Loss: 0.003129042452201247, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0030547971837222576, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0025663545820862055, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0026995374355465174, Min w: 0.0\n",
      "Iteration 540, Loss: 0.005497514735907316, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0024213141296058893, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026102466508746147, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0033231826964765787, Min w: 1.1053856863616193e-20\n",
      "Iteration 580, Loss: 0.0031895709689706564, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002566730137914419, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002556389896199107, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002887590089812875, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0025420181918889284, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0033759018406271935, Min w: 2.808573481628715e-30\n",
      "Iteration 640, Loss: 0.005542515777051449, Min w: 0.0\n",
      "Iteration 650, Loss: 0.005361542105674744, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0025584418326616287, Min w: 0.0\n",
      "Iteration 670, Loss: 0.003997668623924255, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002994764130562544, Min w: 3.5733110840282835e-43\n",
      "Iteration 690, Loss: 0.003256432479247451, Min w: 0.0\n",
      "Iteration 700, Loss: 0.004627708345651627, Min w: 0.0\n",
      "Iteration 710, Loss: 0.00241907499730587, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004800640977919102, Min w: 0.0\n",
      "Iteration 730, Loss: 0.003150521544739604, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0024423866998404264, Min w: 0.0\n",
      "Iteration 750, Loss: 0.002433421788737178, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0026728908997029066, Min w: 0.0\n",
      "Iteration 770, Loss: 0.00282693887129426, Min w: 0.0\n",
      "Iteration 780, Loss: 0.00295360223390162, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002462292555719614, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0033059369307011366, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0029770720284432173, Min w: 0.0\n",
      "Iteration 820, Loss: 0.003274443792179227, Min w: 4.6423658863570794e-39\n",
      "Iteration 830, Loss: 0.0034025758504867554, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0027202125638723373, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002470105653628707, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0026370156556367874, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0033281799405813217, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0024238331243395805, Min w: 0.0\n",
      "Iteration 890, Loss: 0.002844679169356823, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0031443999614566565, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0026103705167770386, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002666375832632184, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0029493356123566628, Min w: 1.3312335411085762e-43\n",
      "Iteration 940, Loss: 0.0038511590100824833, Min w: 0.0\n",
      "Iteration 950, Loss: 0.004772481974214315, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0024096451234072447, Min w: 0.0\n",
      "Iteration 970, Loss: 0.004102897830307484, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002541291294619441, Min w: 0.0\n",
      "Iteration 990, Loss: 0.00290220370516181, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0034668699372559786, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002698927652090788, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0026757766027003527, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.002480847528204322, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0024568745866417885, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002577675972133875, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0027507925406098366, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.002735123271122575, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.00329791777767241, Min w: 6.541961880700408e-41\n",
      "Iteration 1090, Loss: 0.002762063406407833, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0027591276448220015, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.003612395841628313, Min w: 3.448802875227752e-12\n",
      "Iteration 1120, Loss: 0.00280217407271266, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.002458845730870962, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0031899434980005026, Min w: 3.850811566587143e-26\n",
      "Iteration 1150, Loss: 0.00405476288869977, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.004139150492846966, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0027660061605274677, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.004115295130759478, Min w: 3.3204327048263377e-32\n",
      "Iteration 1190, Loss: 0.0023641642183065414, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0030548523645848036, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.003820048412308097, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.002699622418731451, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0029430610593408346, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.00260556535795331, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  71%|███████   | 17/24 [13:08<05:51, 50.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.5364814492049468, 'L2_avg': 0.579562472006085, 'End_point_L1_avg': 0.48090379866363364, 'End_point_L2_avg': 0.5635198832658217}\n",
      "Iteration 0, Loss: 0.004577320534735918, Min w: 8.885343572018201e-10\n",
      "Iteration 10, Loss: 0.0030410888139158487, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0025822303723543882, Min w: 0.0\n",
      "Iteration 30, Loss: 0.003998843487352133, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0033059804700315, Min w: 0.0\n",
      "Iteration 50, Loss: 0.002404568949714303, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0029779854230582714, Min w: 0.0\n",
      "Iteration 70, Loss: 0.002566768554970622, Min w: 0.0\n",
      "Iteration 80, Loss: 0.003124440321698785, Min w: 0.0\n",
      "Iteration 90, Loss: 0.004549501929432154, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0027092089876532555, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0033932526130229235, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0034512656275182962, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0029898108914494514, Min w: 0.0\n",
      "Iteration 140, Loss: 0.003152480348944664, Min w: 1.555441295400547e-43\n",
      "Iteration 150, Loss: 0.002707519568502903, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0026251222006976604, Min w: 2.802596928649634e-45\n",
      "Iteration 170, Loss: 0.002707694424316287, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0024918036069720984, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0025268010795116425, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002695186994969845, Min w: 0.0\n",
      "Iteration 210, Loss: 0.002453223569318652, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002541131339967251, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002772867912426591, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0031156493350863457, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0033675781451165676, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0029399218037724495, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0025445620995014906, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0028626825660467148, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0030620747711509466, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0025962626095861197, Min w: 0.0\n",
      "Iteration 310, Loss: 0.003009853418916464, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0031299509573727846, Min w: 2.805529846335466e-39\n",
      "Iteration 330, Loss: 0.0031849551014602184, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002367848064750433, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002856244333088398, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0028298639226704836, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0025180985685437918, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002802482107654214, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0033286679536104202, Min w: 2.785769602533226e-16\n",
      "Iteration 400, Loss: 0.0023859101347625256, Min w: 0.0\n",
      "Iteration 410, Loss: 0.002555161714553833, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002717850264161825, Min w: 0.0\n",
      "Iteration 430, Loss: 0.006053227931261063, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0024325596168637276, Min w: 0.0\n",
      "Iteration 450, Loss: 0.004154167603701353, Min w: 0.0\n",
      "Iteration 460, Loss: 0.003970684949308634, Min w: 5.829176252802881e-09\n",
      "Iteration 470, Loss: 0.0027921476867049932, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0025950849521905184, Min w: 0.0\n",
      "Iteration 490, Loss: 0.003946581389755011, Min w: 2.5949525479518343e-06\n",
      "Iteration 500, Loss: 0.0028816470876336098, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002423566998913884, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0034655604977160692, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0025827724020928144, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0029945503920316696, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0037109493277966976, Min w: 6.55695442386417e-10\n",
      "Iteration 560, Loss: 0.003723016008734703, Min w: 0.0\n",
      "Iteration 570, Loss: 0.002750548766925931, Min w: 0.0\n",
      "Iteration 580, Loss: 0.002421116456389427, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0028820286970585585, Min w: 0.0\n",
      "Iteration 600, Loss: 0.002501040231436491, Min w: 0.0\n",
      "Iteration 610, Loss: 0.002762460382655263, Min w: 0.0\n",
      "Iteration 620, Loss: 0.003406459465622902, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0027772667817771435, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0026737090665847063, Min w: 0.0\n",
      "Iteration 650, Loss: 0.002685712417587638, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0028350993525236845, Min w: 0.0\n",
      "Iteration 670, Loss: 0.002624691464006901, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002512074774131179, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002545490162447095, Min w: 0.0\n",
      "Iteration 700, Loss: 0.003302839584648609, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0028058704920113087, Min w: 0.0\n",
      "Iteration 720, Loss: 0.005843520164489746, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0027724450919777155, Min w: 0.0\n",
      "Iteration 740, Loss: 0.00323087046854198, Min w: 0.0\n",
      "Iteration 750, Loss: 0.004271826706826687, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0029161113779991865, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0025363871827721596, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0035426386166363955, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0026381067000329494, Min w: 0.0\n",
      "Iteration 800, Loss: 0.004541583359241486, Min w: 0.0\n",
      "Iteration 810, Loss: 0.003398917382583022, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0029139933176338673, Min w: 0.0\n",
      "Iteration 830, Loss: 0.003112804377451539, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0031272575724869967, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002588297938928008, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0027627553790807724, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0030868127942085266, Min w: 1.9407983730898716e-42\n",
      "Iteration 880, Loss: 0.0031115130987018347, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0026116555090993643, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002544791204854846, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0034237727522850037, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0031827467028051615, Min w: 5.486846690048299e-24\n",
      "Iteration 930, Loss: 0.0025892402045428753, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002415233990177512, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0037998470943421125, Min w: 0.0\n",
      "Iteration 960, Loss: 0.00488242506980896, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0037878123112022877, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0028552052099257708, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0026442522648721933, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002558804349973798, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002505221404135227, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0025282769929617643, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0024509539362043142, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0027378087397664785, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.005054950714111328, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.004781615454703569, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.003047289326786995, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.004082521889358759, Min w: 1.723941238651605e-07\n",
      "Iteration 1090, Loss: 0.0034417402930557728, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.005356630776077509, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0032833381555974483, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.003213845891878009, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0025508520193398, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.003162572393193841, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0024366886354982853, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0031363421585410833, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003514552488923073, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.002745086094364524, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0029166319873183966, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0024689717683941126, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0025074658915400505, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0025397727731615305, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002513468498364091, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0029805584345012903, Min w: 0.0\n",
      "Iteration 0, Loss: 0.003862114390358329, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0024604718200862408, Min w: 0.0\n",
      "Iteration 20, Loss: 0.002804527059197426, Min w: 0.0\n",
      "Iteration 30, Loss: 0.00556184072047472, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0042695170268416405, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0024333233013749123, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002505791839212179, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0025671578478068113, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0025336239486932755, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0025189972948282957, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0023947644513100386, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0026300260797142982, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0038287632633000612, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0031262466218322515, Min w: 0.0\n",
      "Iteration 140, Loss: 0.002737615955993533, Min w: 0.0\n",
      "Iteration 150, Loss: 0.00497779855504632, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0029618004336953163, Min w: 0.0\n",
      "Iteration 170, Loss: 0.003251412883400917, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0026543987914919853, Min w: 2.5783891743576634e-43\n",
      "Iteration 190, Loss: 0.00477207824587822, Min w: 0.0\n",
      "Iteration 200, Loss: 0.003656512126326561, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0025107741821557283, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002469709375873208, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002818180015310645, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0025511032436043024, Min w: 0.0\n",
      "Iteration 250, Loss: 0.004540346562862396, Min w: 0.0\n",
      "Iteration 260, Loss: 0.00236123101785779, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002867290051653981, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0026705313939601183, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0026201275177299976, Min w: 2.1019476964872256e-44\n",
      "Iteration 300, Loss: 0.0034228593576699495, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0035073442850261927, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0037899406161159277, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0056622643023729324, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002788729267194867, Min w: 0.0\n",
      "Iteration 350, Loss: 0.002489669481292367, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0035757035948336124, Min w: 0.0\n",
      "Iteration 370, Loss: 0.004183589480817318, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0026467873249202967, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002466528443619609, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0044957855716347694, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0026932426262646914, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002628810005262494, Min w: 0.0\n",
      "Iteration 430, Loss: 0.00646620150655508, Min w: 0.0\n",
      "Iteration 440, Loss: 0.002412546658888459, Min w: 0.0\n",
      "Iteration 450, Loss: 0.004193686880171299, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0032598767429590225, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0024660236667841673, Min w: 0.0\n",
      "Iteration 480, Loss: 0.00386338890530169, Min w: 0.0\n",
      "Iteration 490, Loss: 0.002425026847049594, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0037922407500445843, Min w: 0.0\n",
      "Iteration 510, Loss: 0.004738317336887121, Min w: 0.0\n",
      "Iteration 520, Loss: 0.00287936651147902, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0037858199793845415, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0032606760505586863, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0025512289721518755, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026776238810271025, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0034618875943124294, Min w: 3.1939891270010845e-14\n",
      "Iteration 580, Loss: 0.0028545965906232595, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0029070954769849777, Min w: 0.0\n",
      "Iteration 600, Loss: 0.005655000917613506, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0030631341505795717, Min w: 0.0\n",
      "Iteration 620, Loss: 0.005444831680506468, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0035491830203682184, Min w: 0.0\n",
      "Iteration 640, Loss: 0.002413764363154769, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0030412995256483555, Min w: 0.0\n",
      "Iteration 660, Loss: 0.003019925905391574, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0030375488568097353, Min w: 0.0\n",
      "Iteration 680, Loss: 0.003560628043487668, Min w: 3.13338119059143e-30\n",
      "Iteration 690, Loss: 0.003262447891756892, Min w: 5.099079828394814e-35\n",
      "Iteration 700, Loss: 0.002450538333505392, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0024695617612451315, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0030482106376439333, Min w: 0.0\n",
      "Iteration 730, Loss: 0.002540263347327709, Min w: 0.0\n",
      "Iteration 740, Loss: 0.002833343343809247, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0035500752273947, Min w: 6.935256448754231e-24\n",
      "Iteration 760, Loss: 0.0032276527490466833, Min w: 6.602873073932171e-37\n",
      "Iteration 770, Loss: 0.002436454873532057, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0031328746117651463, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0025318777188658714, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0027455459348857403, Min w: 5.7215518523751895e-37\n",
      "Iteration 810, Loss: 0.003372427774593234, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0027609001845121384, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0034882747568190098, Min w: 0.0\n",
      "Iteration 840, Loss: 0.002709705149754882, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0024369098246097565, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0027562989853322506, Min w: 0.0\n",
      "Iteration 870, Loss: 0.003192304400727153, Min w: 1.9183484056053588e-26\n",
      "Iteration 880, Loss: 0.00492072943598032, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0024472461082041264, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0038220311980694532, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0025200890377163887, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002536152722314, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0034973688889294863, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002503378549590707, Min w: 0.0\n",
      "Iteration 950, Loss: 0.00276581896468997, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0034185482654720545, Min w: 0.0\n",
      "Iteration 970, Loss: 0.002523658098652959, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002803558250889182, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002661518519744277, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002563260495662689, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.002585344947874546, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.002442582743242383, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0025239780079573393, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0036911771167069674, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0028747173491865396, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0028238571248948574, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0028754493687301874, Min w: 1.932306952811572e-37\n",
      "Iteration 1080, Loss: 0.0025596078485250473, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0037753290962427855, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0023759272880852222, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0032827435061335564, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0026304603088647127, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.003215864533558488, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0036857726518064737, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0024528950452804565, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0024998679291456938, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.003236420452594757, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.006233855150640011, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.002639566548168659, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.003141620894894004, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0024495364632457495, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0046155136078596115, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002573803998529911, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002431295346468687, Min w: 0.0\n",
      "Iteration 0, Loss: 0.003956349566578865, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0027202286291867495, Min w: 0.0\n",
      "Iteration 20, Loss: 0.003054144559428096, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0024573474656790495, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0026041409000754356, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00246761878952384, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002981419675052166, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0027500910218805075, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00258345203474164, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002406124724075198, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0028816701378673315, Min w: 0.0\n",
      "Iteration 110, Loss: 0.003434519749134779, Min w: 3.0332786818467855e-40\n",
      "Iteration 120, Loss: 0.003102023620158434, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0024212473072111607, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0024929053615778685, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0026547841262072325, Min w: 0.0\n",
      "Iteration 160, Loss: 0.003692596685141325, Min w: 0.0\n",
      "Iteration 170, Loss: 0.002929398790001869, Min w: 0.0\n",
      "Iteration 180, Loss: 0.00299265724606812, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0027279455680400133, Min w: 0.0\n",
      "Iteration 200, Loss: 0.002459027338773012, Min w: 0.0\n",
      "Iteration 210, Loss: 0.00240536336787045, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0027175063733011484, Min w: 0.0\n",
      "Iteration 230, Loss: 0.003928634338080883, Min w: 0.0\n",
      "Iteration 240, Loss: 0.002510510850697756, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0027121135499328375, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0029527496080845594, Min w: 2.3401684354224445e-43\n",
      "Iteration 270, Loss: 0.0026030330918729305, Min w: 0.0\n",
      "Iteration 280, Loss: 0.002419379074126482, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002696782583370805, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0026952410116791725, Min w: 0.0\n",
      "Iteration 310, Loss: 0.002592950826510787, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0026442757807672024, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002463000826537609, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0027895686216652393, Min w: 0.0\n",
      "Iteration 350, Loss: 0.003040514187887311, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0027225795201957226, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002613397315144539, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002662247745320201, Min w: 0.0\n",
      "Iteration 390, Loss: 0.002994054462760687, Min w: 6.332294723471936e-27\n",
      "Iteration 400, Loss: 0.004906269256025553, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0027131771203130484, Min w: 0.0\n",
      "Iteration 420, Loss: 0.002803039038553834, Min w: 0.0\n",
      "Iteration 430, Loss: 0.004475378431379795, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0024157902225852013, Min w: 0.0\n",
      "Iteration 450, Loss: 0.002809857716783881, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0032801683992147446, Min w: 0.0\n",
      "Iteration 470, Loss: 0.004050314426422119, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0024458165280520916, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0024330427404493093, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0025806829798966646, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002945932559669018, Min w: 3.001113276896674e-39\n",
      "Iteration 520, Loss: 0.002784648910164833, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0026614037342369556, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0026046091224998236, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0029524301644414663, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0026075285859405994, Min w: 0.0\n",
      "Iteration 570, Loss: 0.004453430417925119, Min w: 1.3047272003031615e-17\n",
      "Iteration 580, Loss: 0.004261940252035856, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0031516789458692074, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0024749566800892353, Min w: 0.0\n",
      "Iteration 610, Loss: 0.00357480114325881, Min w: 1.9049349161341482e-14\n",
      "Iteration 620, Loss: 0.0025777423288673162, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0027203841600567102, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0032824608497321606, Min w: 5.612168525553601e-23\n",
      "Iteration 650, Loss: 0.004208911210298538, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0024879896081984043, Min w: 0.0\n",
      "Iteration 670, Loss: 0.004224357660859823, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002656953176483512, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0024793511256575584, Min w: 0.0\n",
      "Iteration 700, Loss: 0.002495602471753955, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002625168301165104, Min w: 0.0\n",
      "Iteration 720, Loss: 0.004444686230272055, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0027209154795855284, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0031596235930919647, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0027241159696131945, Min w: 0.0\n",
      "Iteration 760, Loss: 0.002805356401950121, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0029003038071095943, Min w: 4.066813892832503e-28\n",
      "Iteration 780, Loss: 0.0024326727725565434, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002455428009852767, Min w: 0.0\n",
      "Iteration 800, Loss: 0.003854652401059866, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0032678009010851383, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002464677905663848, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0029933061450719833, Min w: 0.0\n",
      "Iteration 840, Loss: 0.004144425503909588, Min w: 1.3766577717154918e-18\n",
      "Iteration 850, Loss: 0.0024940166622400284, Min w: 0.0\n",
      "Iteration 860, Loss: 0.003281541634351015, Min w: 0.0\n",
      "Iteration 870, Loss: 0.00375146372243762, Min w: 0.0\n",
      "Iteration 880, Loss: 0.004149413667619228, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0025333173107355833, Min w: 0.0\n",
      "Iteration 900, Loss: 0.00285568879917264, Min w: 0.0\n",
      "Iteration 910, Loss: 0.005898287054151297, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0027181082405149937, Min w: 0.0\n",
      "Iteration 930, Loss: 0.002734587760642171, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0027175189461559057, Min w: 0.0\n",
      "Iteration 950, Loss: 0.002809755736961961, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0025033741258084774, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0026128950994461775, Min w: 0.0\n",
      "Iteration 980, Loss: 0.002345246495679021, Min w: 0.0\n",
      "Iteration 990, Loss: 0.002537579508498311, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0024745254777371883, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.003429048229008913, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.003580925054848194, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0030827790033072233, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002626496832817793, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0025817682035267353, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0031769340857863426, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.003299701726064086, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0024980497546494007, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.002450049389153719, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.005230003036558628, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0024248857516795397, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.004552491940557957, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0026867231354117393, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0024390623439103365, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0025244562420994043, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0032282688189297915, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002742909360677004, Min w: 1.3316004346776996e-36\n",
      "Iteration 1180, Loss: 0.002471080282703042, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.003829214023426175, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.002904354128986597, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.002590601099655032, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0038577381055802107, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.002950264373794198, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0026424836833029985, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0024513788521289825, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0026904160622507334, Min w: 0.0\n",
      "Iteration 20, Loss: 0.004499251488596201, Min w: 2.2741675916436016e-36\n",
      "Iteration 30, Loss: 0.0029821067582815886, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002750713611021638, Min w: 0.0\n",
      "Iteration 50, Loss: 0.003026441438123584, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0036423467099666595, Min w: 5.88641982379734e-11\n",
      "Iteration 70, Loss: 0.0026607131585478783, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0027982788160443306, Min w: 0.0\n",
      "Iteration 90, Loss: 0.005374478176236153, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0026190727949142456, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002443527802824974, Min w: 0.0\n",
      "Iteration 120, Loss: 0.003386165713891387, Min w: 0.0\n",
      "Iteration 130, Loss: 0.003926383331418037, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0031461480539292097, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0025580243673175573, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0026700813323259354, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0029349576216191053, Min w: 0.0\n",
      "Iteration 180, Loss: 0.002398323966190219, Min w: 0.0\n",
      "Iteration 190, Loss: 0.002671018475666642, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0024054963141679764, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0027206570375710726, Min w: 0.0\n",
      "Iteration 220, Loss: 0.003907613921910524, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002469284925609827, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0027964976616203785, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0029817346949130297, Min w: 8.652282645618434e-27\n",
      "Iteration 260, Loss: 0.0030360519886016846, Min w: 0.0\n",
      "Iteration 270, Loss: 0.002729767467826605, Min w: 0.0\n",
      "Iteration 280, Loss: 0.004851996898651123, Min w: 0.0\n",
      "Iteration 290, Loss: 0.003200724022462964, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0027163063641637564, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0050718821585178375, Min w: 0.0\n",
      "Iteration 320, Loss: 0.004198879934847355, Min w: 0.0\n",
      "Iteration 330, Loss: 0.004315496888011694, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0026011094450950623, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0038464278914034367, Min w: 9.662620703565494e-11\n",
      "Iteration 360, Loss: 0.002842174842953682, Min w: 0.0\n",
      "Iteration 370, Loss: 0.002665073610842228, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0025249063037335873, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0024980795569717884, Min w: 0.0\n",
      "Iteration 400, Loss: 0.004208238795399666, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0026610216591507196, Min w: 0.0\n",
      "Iteration 420, Loss: 0.003301271004602313, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0029044286347925663, Min w: 0.0\n",
      "Iteration 440, Loss: 0.003849572967737913, Min w: 3.3231708584935404e-07\n",
      "Iteration 450, Loss: 0.0030941993463784456, Min w: 0.0\n",
      "Iteration 460, Loss: 0.002401235280558467, Min w: 0.0\n",
      "Iteration 470, Loss: 0.003512475872412324, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0025530036073178053, Min w: 0.0\n",
      "Iteration 490, Loss: 0.003163503250107169, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0036385185085237026, Min w: 0.0\n",
      "Iteration 510, Loss: 0.002603704109787941, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002907068934291601, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0027537080459296703, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0024084188044071198, Min w: 0.0\n",
      "Iteration 550, Loss: 0.004132398869842291, Min w: 0.0\n",
      "Iteration 560, Loss: 0.002395802177488804, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0025092712603509426, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0027754914481192827, Min w: 0.0\n",
      "Iteration 590, Loss: 0.002540112007409334, Min w: 0.0\n",
      "Iteration 600, Loss: 0.003049311460927129, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0030967681668698788, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0037150313146412373, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0040166014805436134, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0029781695920974016, Min w: 0.0\n",
      "Iteration 650, Loss: 0.004772895481437445, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0033914055675268173, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0024218070320785046, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0027940378058701754, Min w: 0.0\n",
      "Iteration 690, Loss: 0.002583287423476577, Min w: 0.0\n",
      "Iteration 700, Loss: 0.002847835188731551, Min w: 0.0\n",
      "Iteration 710, Loss: 0.003074497915804386, Min w: 0.0\n",
      "Iteration 720, Loss: 0.003213923191651702, Min w: 0.0\n",
      "Iteration 730, Loss: 0.004251483362168074, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0026472886092960835, Min w: 0.0\n",
      "Iteration 750, Loss: 0.003263960825279355, Min w: 6.452812762144003e-32\n",
      "Iteration 760, Loss: 0.004344840068370104, Min w: 0.0\n",
      "Iteration 770, Loss: 0.003185524372383952, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002616453217342496, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0034675549250096083, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0024154726415872574, Min w: 0.0\n",
      "Iteration 810, Loss: 0.003430528100579977, Min w: 0.0\n",
      "Iteration 820, Loss: 0.003614946035668254, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0027039595879614353, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0024244722444564104, Min w: 0.0\n",
      "Iteration 850, Loss: 0.002657491248100996, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0041973483748734, Min w: 0.0\n",
      "Iteration 870, Loss: 0.004011406097561121, Min w: 0.0\n",
      "Iteration 880, Loss: 0.002645027358084917, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0025872669648379087, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0032529435120522976, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0024213562719523907, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0031446649227291346, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0030897664837539196, Min w: 0.0\n",
      "Iteration 940, Loss: 0.005186404101550579, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0027578093577176332, Min w: 0.0\n",
      "Iteration 960, Loss: 0.002935479860752821, Min w: 0.0\n",
      "Iteration 970, Loss: 0.006006075069308281, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0034971737768501043, Min w: 0.0\n",
      "Iteration 990, Loss: 0.00667937658727169, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002951299771666527, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.004592464305460453, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0026011152658611536, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0026683069299906492, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.004405362065881491, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.002914920449256897, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0035509534645825624, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.003658575937151909, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.003512511495500803, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.002617990132421255, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0026042351964861155, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.003126239636912942, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.002722922945395112, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0025807979982346296, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0024040404241532087, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0030266663525253534, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.002992835594341159, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.00262837833724916, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0038179277908056974, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0030601597391068935, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0027559809386730194, Min w: 1.401298464324817e-45\n",
      "Iteration 1210, Loss: 0.0032938718795776367, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0028781157452613115, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0060275886207818985, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.00500797014683485, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0032466640695929527, Min w: 0.0\n",
      "Iteration 10, Loss: 0.002494081621989608, Min w: 0.0\n",
      "Iteration 20, Loss: 0.003322330769151449, Min w: 1.0442785449490019e-32\n",
      "Iteration 30, Loss: 0.0029911512974649668, Min w: 0.0\n",
      "Iteration 40, Loss: 0.002603713423013687, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0052128806710243225, Min w: 0.0\n",
      "Iteration 60, Loss: 0.002495069755241275, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0030163214541971684, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0033241980709135532, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0030735477339476347, Min w: 0.0\n",
      "Iteration 100, Loss: 0.004508188460022211, Min w: 0.0\n",
      "Iteration 110, Loss: 0.002466804813593626, Min w: 0.0\n",
      "Iteration 120, Loss: 0.005303817801177502, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0027738872449845076, Min w: 0.0\n",
      "Iteration 140, Loss: 0.004358482547104359, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0025061429478228092, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002569445176050067, Min w: 0.0\n",
      "Iteration 170, Loss: 0.005428088363260031, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0024162475019693375, Min w: 0.0\n",
      "Iteration 190, Loss: 0.004048167262226343, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0030726378317922354, Min w: 0.0\n",
      "Iteration 210, Loss: 0.003037448041141033, Min w: 0.0\n",
      "Iteration 220, Loss: 0.002454419620335102, Min w: 0.0\n",
      "Iteration 230, Loss: 0.002853632904589176, Min w: 0.0\n",
      "Iteration 240, Loss: 0.005558775272220373, Min w: 0.0\n",
      "Iteration 250, Loss: 0.002531679579988122, Min w: 0.0\n",
      "Iteration 260, Loss: 0.003096159780398011, Min w: 0.0\n",
      "Iteration 270, Loss: 0.003401384688913822, Min w: 3.1928430806290496e-37\n",
      "Iteration 280, Loss: 0.0033192287664860487, Min w: 0.0\n",
      "Iteration 290, Loss: 0.002400233643129468, Min w: 0.0\n",
      "Iteration 300, Loss: 0.002619756618514657, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0035373938735574484, Min w: 0.0\n",
      "Iteration 320, Loss: 0.002683772938326001, Min w: 0.0\n",
      "Iteration 330, Loss: 0.00250402488745749, Min w: 0.0\n",
      "Iteration 340, Loss: 0.002595410915091634, Min w: 0.0\n",
      "Iteration 350, Loss: 0.003217184217646718, Min w: 5.493604749973059e-19\n",
      "Iteration 360, Loss: 0.0035555690992623568, Min w: 0.0\n",
      "Iteration 370, Loss: 0.004171065986156464, Min w: 0.0\n",
      "Iteration 380, Loss: 0.002679477445781231, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0055641187354922295, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0027504072058945894, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003558326279744506, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0024550962261855602, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0024403766728937626, Min w: 0.0\n",
      "Iteration 440, Loss: 0.004061442334204912, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0027580440510064363, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0029997159726917744, Min w: 0.0\n",
      "Iteration 470, Loss: 0.002838695188984275, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0029078428633511066, Min w: 0.0\n",
      "Iteration 490, Loss: 0.003225767519325018, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0037411213852465153, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0024569849483668804, Min w: 0.0\n",
      "Iteration 520, Loss: 0.002618512837216258, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0034361791331321, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0026637816336005926, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0025746761821210384, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0030708976555615664, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0030230304691940546, Min w: 0.0\n",
      "Iteration 580, Loss: 0.006381714716553688, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0049349358305335045, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0032298762816935778, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0026676449924707413, Min w: 0.0\n",
      "Iteration 620, Loss: 0.003268131986260414, Min w: 0.0\n",
      "Iteration 630, Loss: 0.006261701695621014, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0028485998045653105, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0033401455730199814, Min w: 0.0\n",
      "Iteration 660, Loss: 0.003253076458349824, Min w: 1.9409987461000744e-18\n",
      "Iteration 670, Loss: 0.0026748632080852985, Min w: 0.0\n",
      "Iteration 680, Loss: 0.002573073375970125, Min w: 0.0\n",
      "Iteration 690, Loss: 0.00366872432641685, Min w: 3.0057457404382568e-21\n",
      "Iteration 700, Loss: 0.004713751841336489, Min w: 0.0\n",
      "Iteration 710, Loss: 0.002381341066211462, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0026719127781689167, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0024910413194447756, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0028380025178194046, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0025268057361245155, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0024972313549369574, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0028476447332650423, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0025319643318653107, Min w: 0.0\n",
      "Iteration 790, Loss: 0.002997645176947117, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0034594822209328413, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0025792920496314764, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002731562126427889, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0025382470339536667, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0025983271189033985, Min w: 0.0\n",
      "Iteration 850, Loss: 0.004134402144700289, Min w: 0.0\n",
      "Iteration 860, Loss: 0.002642708830535412, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002701141871511936, Min w: 0.0\n",
      "Iteration 880, Loss: 0.004424051847308874, Min w: 3.445460109784254e-36\n",
      "Iteration 890, Loss: 0.0026974661741405725, Min w: 0.0\n",
      "Iteration 900, Loss: 0.002475014654919505, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0027145342901349068, Min w: 0.0\n",
      "Iteration 920, Loss: 0.002584543079137802, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0028877886943519115, Min w: 0.0\n",
      "Iteration 940, Loss: 0.002516103209927678, Min w: 0.0\n",
      "Iteration 950, Loss: 0.002627058420330286, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0025728587061166763, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0029140166006982327, Min w: 0.0\n",
      "Iteration 980, Loss: 0.005966081749647856, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0029507288709282875, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.002973412862047553, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0035770840477198362, Min w: 4.0622622103753284e-32\n",
      "Iteration 1020, Loss: 0.0034236747305840254, Min w: 5.885427910099622e-16\n",
      "Iteration 1030, Loss: 0.0027895609382539988, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.002839303808286786, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0067313052713871, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0024053072556853294, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0031407007481902838, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0030390711035579443, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0037336284294724464, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0032398828770965338, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0028387177735567093, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0024949724320322275, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0029032465536147356, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.003595318179577589, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.002905401634052396, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.004906466696411371, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.002781827002763748, Min w: 1.5414283107572988e-44\n",
      "Iteration 1180, Loss: 0.002508938079699874, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.003602629527449608, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.00311487028375268, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0032372286077588797, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0025547510012984276, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0027288675773888826, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  75%|███████▌  | 18/24 [14:17<05:34, 55.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 0.004653641488403082, Min w: 6.069407492666131e-37\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.6288010825851672, 'L2_avg': 0.6485734946147161, 'End_point_L1_avg': 0.6228301990270789, 'End_point_L2_avg': 0.6455489687027749}\n",
      "Iteration 0, Loss: 0.0015202263602986932, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0007016643066890538, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0005767822731286287, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000683443620800972, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006415793322958052, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006670777802355587, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0010524045210331678, Min w: 0.0\n",
      "Iteration 70, Loss: 0.001434624777175486, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006754638743586838, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006076092249713838, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006359771941788495, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007940255454741418, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006010509096086025, Min w: 0.0\n",
      "Iteration 130, Loss: 0.00108764145988971, Min w: 0.0007293671369552612\n",
      "Iteration 140, Loss: 0.0006435568793676794, Min w: 0.0\n",
      "Iteration 150, Loss: 0.001040938077494502, Min w: 0.0\n",
      "Iteration 160, Loss: 0.000970525958109647, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008814602042548358, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006564343930222094, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007553322939202189, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0011128238402307034, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0007860456244088709, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0007673167856410146, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0018213436705991626, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0007556107011623681, Min w: 0.0\n",
      "Iteration 250, Loss: 0.001104922965168953, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0008665478671900928, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0009763974812813103, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008846247219480574, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006457804120145738, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0011535343946889043, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007733303937129676, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0012817693641409278, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007617106894031167, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0012291180901229382, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001052165636792779, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0015991516411304474, Min w: 0.0\n",
      "Iteration 370, Loss: 0.00178438238799572, Min w: 0.0\n",
      "Iteration 380, Loss: 0.001420316519215703, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0009522606851533055, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006261063972488046, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0008511149790138006, Min w: 0.0\n",
      "Iteration 420, Loss: 0.001341118710115552, Min w: 0.0\n",
      "Iteration 430, Loss: 0.000761364761274308, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0009501669555902481, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0009030968067236245, Min w: 3.682991015197631e-32\n",
      "Iteration 460, Loss: 0.0028688444290310144, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0008539530099369586, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000646643980871886, Min w: 0.0\n",
      "Iteration 490, Loss: 0.001289994572289288, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0010698653059080243, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0007271330687217414, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0033815738279372454, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006437976844608784, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008635241538286209, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0010118628852069378, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0006122483173385262, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0008788632694631815, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008060089312493801, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0011502994457259774, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007200492545962334, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006568746757693589, Min w: 0.0\n",
      "Iteration 620, Loss: 0.001315114670433104, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0010668961331248283, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0008491441840305924, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0008278519962914288, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0018046243349090219, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007485446403734386, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0013211802579462528, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0009111898834817111, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0011616746196523309, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008158109267242253, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0012217212934046984, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0007970842416398227, Min w: 0.0\n",
      "Iteration 740, Loss: 0.000923847546800971, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0011537481332197785, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000850023003295064, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0009589677210897207, Min w: 0.0\n",
      "Iteration 780, Loss: 0.002458311151713133, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0019577043130993843, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0007575278868898749, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0011003412073478103, Min w: 0.0\n",
      "Iteration 820, Loss: 0.002332146279513836, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0014699907042086124, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0015951436944305897, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007595208007842302, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007053242297843099, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007024664082564414, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006903390749357641, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008585323812440038, Min w: 0.0\n",
      "Iteration 900, Loss: 0.000668124936055392, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0008459672681055963, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0007406597142107785, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0008730289409868419, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0010418373858556151, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0006211661966517568, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006541638867929578, Min w: 0.0\n",
      "Iteration 970, Loss: 0.000661222031340003, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0009487111819908023, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008773437002673745, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0007133333710953593, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0008601376903243363, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0010448602261021733, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.000727261183783412, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0011485880240797997, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0007394415442831814, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007305813487619162, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0015573831042274833, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0009418262634426355, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.000872475968208164, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0012723417021334171, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0010585235431790352, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0008836874621920288, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006355657242238522, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0010531413136050105, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0010036660823971033, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0007567569264210761, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0009214845485985279, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0007280497229658067, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0007134923944249749, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.001184260006994009, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007952721789479256, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006125766667537391, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.001280682859942317, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0009612705325707793, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0014473741175606847, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0020895435009151697, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007628059829585254, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0011641108430922031, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008195090922527015, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006605337257497013, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0013471804559230804, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007577887736260891, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006582160131074488, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0013972441665828228, Min w: 0.0\n",
      "Iteration 100, Loss: 0.000642001919914037, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006478587747551501, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0010627922601997852, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007862739148549736, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009540323517285287, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0011070807231590152, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0013894143048673868, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0007866130326874554, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0008523239521309733, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007002830388955772, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007982036331668496, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0007782565662637353, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0009704051190055907, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006914953701198101, Min w: 0.0\n",
      "Iteration 240, Loss: 0.003442285815253854, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0020148877520114183, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0008664467604830861, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0006927457870915532, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008121844148263335, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006910117226652801, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0012446329928934574, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006714900955557823, Min w: 0.0\n",
      "Iteration 320, Loss: 0.001083536189980805, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0008359330240637064, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0011910954490303993, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007470395066775382, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0008384836837649345, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006240044604055583, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0008665655623190105, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0008768158731982112, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006050947704352438, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006623641238547862, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0015583919594064355, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0012081739259883761, Min w: 0.0\n",
      "Iteration 440, Loss: 0.000695361231919378, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0010124649852514267, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006195954629220068, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0011354488087818027, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007101799710653722, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0015608022222295403, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006765048601664603, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0013373090187087655, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0008110772469080985, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0006108153029344976, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0017117655370384455, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0007657852256670594, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0012943495530635118, Min w: 1.8459789430380624e-07\n",
      "Iteration 570, Loss: 0.0006055898847989738, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006917043356224895, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0008631412056274712, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006453684763982892, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006496827118098736, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0013617698568850756, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006688654539175332, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0011385752586647868, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0020186693873256445, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0022067902609705925, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007422681082971394, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0009721173555590212, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0012687360867857933, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0014292503474280238, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0017052507027983665, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006792989443056285, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0008218465954996645, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0007070009014569223, Min w: 0.0\n",
      "Iteration 750, Loss: 0.00074192596366629, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0007756738923490047, Min w: 0.0\n",
      "Iteration 770, Loss: 0.000649821653496474, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007475746679119766, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007770436932332814, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006243784446269274, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006795644294470549, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006047668866813183, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006367831956595182, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0014781056670472026, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006466194754466414, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0011828166898339987, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007515180623158813, Min w: 0.0\n",
      "Iteration 880, Loss: 0.001030141138471663, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0009035833063535392, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006081511382944882, Min w: 0.0\n",
      "Iteration 910, Loss: 0.000865069916471839, Min w: 0.0\n",
      "Iteration 920, Loss: 0.001438024453818798, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0007389645907096565, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0012052805395796895, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0014557508984580636, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0013058377662673593, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0008800518116913736, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006773832137696445, Min w: 0.0\n",
      "Iteration 990, Loss: 0.000881396175827831, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0009584229555912316, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0010353527031838894, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000710740452632308, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0010032716672867537, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008719156612642109, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008430094458162785, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0008460478857159615, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006207719561643898, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0006186148966662586, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0010594762861728668, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007193068158812821, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.001058397931046784, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.000806017720606178, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0025308923795819283, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0014062910340726376, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0011598686687648296, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0009558486635796726, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0027816505171358585, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0017734639113768935, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.000811886100564152, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.001051419647410512, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0007858911994844675, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0014874414773657918, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.000635359319858253, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0012924401089549065, Min w: 0.0\n",
      "Iteration 0, Loss: 0.001330250990577042, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0009857051772996783, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0008559957495890558, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0011277709854766726, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008441045065410435, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006415293319150805, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006551172700710595, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007721120491623878, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0011765682138502598, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0008082456770353019, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0007250133785419166, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0010745917679741979, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006859083659946918, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006295870989561081, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0008412615279667079, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0006887997733429074, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0010181386023759842, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006571760750375688, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006013495149090886, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006494789849966764, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007549139554612339, Min w: 0.0\n",
      "Iteration 210, Loss: 0.000711266475263983, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0020437028724700212, Min w: 0.0\n",
      "Iteration 230, Loss: 0.001090239966288209, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006961569306440651, Min w: 0.0\n",
      "Iteration 250, Loss: 0.000705025449860841, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0023455582559108734, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0017076838994398713, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0007333094836212695, Min w: 0.0\n",
      "Iteration 290, Loss: 0.000648820714559406, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006572018028236926, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0009458564454689622, Min w: 0.0\n",
      "Iteration 320, Loss: 0.001027765916660428, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007842945633456111, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006116555887274444, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0008307882235385478, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0014034686610102654, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0012149193789809942, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0008112824289128184, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007820316241122782, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006410255446098745, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0007088437560014427, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0014433993492275476, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006646032561548054, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0011136522516608238, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006952145486138761, Min w: 0.0\n",
      "Iteration 460, Loss: 0.000796496111433953, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0009658289491198957, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0006941192550584674, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000646650034468621, Min w: 0.0\n",
      "Iteration 500, Loss: 0.001514222240075469, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006608934490941465, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007257154211401939, Min w: 0.0\n",
      "Iteration 530, Loss: 0.001135019469074905, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008657848811708391, Min w: 0.0\n",
      "Iteration 550, Loss: 0.000939719146117568, Min w: 0.0\n",
      "Iteration 560, Loss: 0.000661453406792134, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006229064310900867, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0008264087373390794, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006122307968325913, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007832447299733758, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0008809485589154065, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0014212941750884056, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0012575624277815223, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0014441416133195162, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006073002587072551, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0006769238971173763, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0008026130963116884, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0006017865962348878, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0007521267398260534, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0013034509029239416, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008377383346669376, Min w: 0.0\n",
      "Iteration 720, Loss: 0.000966426741797477, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0023071777541190386, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0018565731588751078, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007221901905722916, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0010802479228004813, Min w: 0.0\n",
      "Iteration 770, Loss: 0.000712177308741957, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0010726870968937874, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0006636946345679462, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009245542460121214, Min w: 0.0\n",
      "Iteration 810, Loss: 0.00073666573734954, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0006014601094648242, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006608818657696247, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012897920096293092, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0010096931364387274, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0010049754055216908, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006215386092662811, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008080803090706468, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0008205922786146402, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0009798670653253794, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0014263768680393696, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0008374809985980392, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006040283478796482, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0008675359422340989, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0018464516615495086, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006250215810723603, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0008109222981147468, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0009613634319975972, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006732272449880838, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006771648768335581, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006975515279918909, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.000619351863861084, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0014045553980395198, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0008096856181509793, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0007593734771944582, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0010261640418320894, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0010375311831012368, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0007928393315523863, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.001273072324693203, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007746834889985621, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0014663416659459472, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.000711957341991365, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006149141700007021, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0008031695033423603, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0008069805335253477, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.000781460665166378, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0005999095155857503, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006834588130004704, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.002361531835049391, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0011271452531218529, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.000915928278118372, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0007557265926152468, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0016437806189060211, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002282052766531706, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0014183070743456483, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010122323874384165, Min w: 0.0\n",
      "Iteration 20, Loss: 0.000902499130461365, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0007820511236786842, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0013324777828529477, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0008237699512392282, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006445618928410113, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008778779301792383, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0009574024588800967, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0009171109413728118, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0008475931826978922, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0008864917908795178, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0030102015007287264, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006504383054561913, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0014411919983103871, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0010596197098493576, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006983013008721173, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0007668653270229697, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0007552096503786743, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0009525763452984393, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007661725394427776, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0007995730265974998, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0008294270955957472, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0007087723934091628, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0011069553438574076, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007856262964196503, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006629585404880345, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007419337052851915, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0008551031933166087, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0009015494724735618, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0017757515888661146, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006079935119487345, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0011091206688433886, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0007658225949853659, Min w: 0.0\n",
      "Iteration 340, Loss: 0.000809659599326551, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0007907768012955785, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0009233452146872878, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0010556565830484033, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006814353400841355, Min w: 0.0\n",
      "Iteration 390, Loss: 0.001037751673720777, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007753508980385959, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006439232965931296, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0012681109365075827, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006033946410752833, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0010038790060207248, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006768082967028022, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0007246574969030917, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0008577091502957046, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000925677886698395, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000625175831373781, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0013107709819450974, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0008717268938198686, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0011214084224775434, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0008971148054115474, Min w: 0.0\n",
      "Iteration 540, Loss: 0.000655790267046541, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0008189099607989192, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0019853361882269382, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0018554693087935448, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007353283581323922, Min w: 0.0\n",
      "Iteration 590, Loss: 0.000989232794381678, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0009050339576788247, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0016788310604169965, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006083867629058659, Min w: 0.0\n",
      "Iteration 630, Loss: 0.001221991260536015, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006112800911068916, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0011071779299527407, Min w: 0.0\n",
      "Iteration 660, Loss: 0.001157265272922814, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0011761542409658432, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0009421393042430282, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0009317905642092228, Min w: 0.0\n",
      "Iteration 700, Loss: 0.001442291890271008, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006512146210297942, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0012112141121178865, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0006844604504294693, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0006735307397320867, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006040012231096625, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0006417835247702897, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0006982524646446109, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0019290113123133779, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0007689208723604679, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0012182020582258701, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0006760143442079425, Min w: 0.0\n",
      "Iteration 820, Loss: 0.001556432107463479, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0008113742806017399, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012259978102520108, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006302124820649624, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008467091829515994, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0009132481645792723, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006376864621415734, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006038218270987272, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006500334711745381, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0010704492451623082, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0008368727285414934, Min w: 0.0\n",
      "Iteration 930, Loss: 0.000628266017884016, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007348600775003433, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0014245007187128067, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0008024885319173336, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0008825959521345794, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0008402055245824158, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0017407680861651897, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006924828048795462, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0010318633867427707, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007382347248494625, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.002572248224169016, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0010286695323884487, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0017655006377026439, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.001088036340661347, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.000969377055298537, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.000820414163172245, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006786442827433348, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0010157100623473525, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.000893611169885844, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0011688703671097755, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006891022785566747, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0007317009149119258, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0009345716098323464, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006666713743470609, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0011079305550083518, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0008271431433968246, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0006721304962411523, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006600936758331954, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0010853244457393885, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0009176231687888503, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0015233351150527596, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006643577944487333, Min w: 0.0\n",
      "Iteration 0, Loss: 0.000850569223985076, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006064465851522982, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006164450314827263, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0006322106928564608, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0008791153086349368, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007206001318991184, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006762727280147374, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0010463560465723276, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0009462883463129401, Min w: 0.0\n",
      "Iteration 90, Loss: 0.001081636524759233, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0008570422069169581, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000983381294645369, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006474819383583963, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0009198958287015557, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009412119397893548, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008158863638527691, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0008453397895209491, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0008424618281424046, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006352491327561438, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0010552493622526526, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006294838385656476, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0010349798249080777, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0007359026931226254, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0010325403418391943, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0006193095468915999, Min w: 0.0\n",
      "Iteration 250, Loss: 0.000688551866915077, Min w: 0.0\n",
      "Iteration 260, Loss: 0.000732584681827575, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007527819252572954, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0024110323283821344, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0013062622165307403, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006760702235624194, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0008638490689918399, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0015480166766792536, Min w: 0.0\n",
      "Iteration 330, Loss: 0.002306311624124646, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0008091601193882525, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001461124513298273, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0010445518419146538, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0006908749346621335, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0007382773328572512, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0007431824342347682, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0010961220832541585, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0008571197977289557, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0015945754712447524, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0010394161799922585, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006680251099169254, Min w: 0.0\n",
      "Iteration 450, Loss: 0.001064542680978775, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0009667883277870715, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006766509613953531, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000766636454500258, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0007449659751728177, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006304132402874529, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0023111184127628803, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0009851371869444847, Min w: 0.0\n",
      "Iteration 530, Loss: 0.00063032511388883, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0006912761018611491, Min w: 0.0\n",
      "Iteration 550, Loss: 0.001525566796772182, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007861745543777943, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006326602888293564, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0006638073245994747, Min w: 0.0\n",
      "Iteration 590, Loss: 0.001527894870378077, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0006311592878773808, Min w: 0.0\n",
      "Iteration 610, Loss: 0.001173070864751935, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0008533518994227052, Min w: 0.0\n",
      "Iteration 630, Loss: 0.00133175787050277, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0007661209092475474, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0009460627334192395, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0008172804955393076, Min w: 0.0\n",
      "Iteration 670, Loss: 0.001085612690076232, Min w: 0.0\n",
      "Iteration 680, Loss: 0.000645172200165689, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0009132474078796804, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0008615782135166228, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0014818600611761212, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0006789771723560989, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0008994486997835338, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0008325505186803639, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0013839395251125097, Min w: 0.0\n",
      "Iteration 760, Loss: 0.000999228679575026, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007978272042237222, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006264436524361372, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0010066068498417735, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009045422775670886, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008567977347411215, Min w: 0.0\n",
      "Iteration 820, Loss: 0.001627814956009388, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0012605638476088643, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0012696150224655867, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0009058945579454303, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007341138552874327, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0008261253824457526, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0010768090141937137, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0013669992331415415, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0008624800248071551, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0009380322881042957, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0008449923479929566, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0012259857030585408, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0007071830332279205, Min w: 0.0\n",
      "Iteration 950, Loss: 0.001079270150512457, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0009148428216576576, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0021260131616145372, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0008566232863813639, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008981625433079898, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006186143727973104, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0008018327062018216, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0006587059469893575, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006067725480534136, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.000658840814139694, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0006762734265066683, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.002247678814455867, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0007008060929365456, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0013287876499816775, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006812880164943635, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006855917745269835, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0008569348137825727, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0008126299362629652, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0015608526300638914, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0009688069112598896, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.001196407014504075, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0010773418471217155, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0007579576340503991, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0006932442192919552, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0010079413186758757, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0010555819608271122, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0008144324528984725, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0010205594589933753, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0010763484751805663, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0007695159292779863, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  79%|███████▉  | 19/24 [15:21<04:51, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.6074738950222606, 'L2_avg': 0.78034573163662, 'End_point_L1_avg': 0.5672239545079106, 'End_point_L2_avg': 0.7689432853332439}\n",
      "Iteration 0, Loss: 0.0011333624133840203, Min w: 6.928152170883328e-14\n",
      "Iteration 10, Loss: 0.0006908810464665294, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0006924736080691218, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0009475314291194081, Min w: 5.723860052597729e-09\n",
      "Iteration 40, Loss: 0.0006551618571393192, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0007303889142349362, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0009053945541381836, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008959570550359786, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006856093532405794, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006483573815785348, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006442078738473356, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0006471499218605459, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0006704339757561684, Min w: 0.0\n",
      "Iteration 130, Loss: 0.001217037788592279, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0007825143402442336, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008260149625129998, Min w: 0.0\n",
      "Iteration 160, Loss: 0.002175872214138508, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006419374840334058, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0009534516138955951, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0011342070065438747, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007969351718202233, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0008100134436972439, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0006093517295084894, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0011000098893418908, Min w: 2.4075973419773744e-12\n",
      "Iteration 240, Loss: 0.0007786016212776303, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007379123126156628, Min w: 0.0\n",
      "Iteration 260, Loss: 0.001064445124939084, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0006651336443610489, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006507890066131949, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007360746967606246, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0006647820118814707, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0006087043439038098, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0007595797651447356, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0020434209145605564, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0007074672030285001, Min w: 0.0\n",
      "Iteration 350, Loss: 0.001012548222206533, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0013137132627889514, Min w: 1.505291918326202e-34\n",
      "Iteration 370, Loss: 0.0017920158570632339, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0011089546605944633, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0008253307896666229, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0009194130543619394, Min w: 0.0\n",
      "Iteration 410, Loss: 0.003122702008113265, Min w: 0.0\n",
      "Iteration 420, Loss: 0.000676546769682318, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0015370226465165615, Min w: 0.0\n",
      "Iteration 440, Loss: 0.000818936969153583, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0013079129857942462, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0008434408809989691, Min w: 0.0\n",
      "Iteration 470, Loss: 0.001489804475568235, Min w: 0.0\n",
      "Iteration 480, Loss: 0.000852459401357919, Min w: 0.0\n",
      "Iteration 490, Loss: 0.001718961400911212, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0009186208480969071, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006957585574127734, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0008045877912081778, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0007232485804706812, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008106465684249997, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006538484012708068, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007469160482287407, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006950496463105083, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0016584501136094332, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006621715729124844, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0007662714924663305, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0010156080825254321, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0009332802146673203, Min w: 0.0\n",
      "Iteration 630, Loss: 0.001017106114886701, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006103325868025422, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0007422874914482236, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0022669024765491486, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0017196907429024577, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0006675691111013293, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0008784693782217801, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0006222227239049971, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0008138948469422758, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0007179842214100063, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0006557541200891137, Min w: 0.0\n",
      "Iteration 740, Loss: 0.000627599423751235, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0014114495133981109, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0006371234776452184, Min w: 0.0\n",
      "Iteration 770, Loss: 0.001921383198350668, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0007961391238495708, Min w: 0.0\n",
      "Iteration 790, Loss: 0.001286958926357329, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0009649547864682972, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0008259628666564822, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0014484517741948366, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0006399904377758503, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0006639105267822742, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0009984240168705583, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008205138146877289, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0006469529471360147, Min w: 0.0\n",
      "Iteration 880, Loss: 0.000840882072225213, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0007837616140022874, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0007825990323908627, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0010886387899518013, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0007403098279610276, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006287585711106658, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006712865433655679, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0009682846139185131, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0007100159418769181, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0009848319459706545, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006793273496441543, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006571837584488094, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006437819101847708, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006940236780792475, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0009000211721286178, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0020814004819840193, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006675201002508402, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008952683419920504, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007394740823656321, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0027174940332770348, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0014888755977153778, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006710246670991182, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0010328367352485657, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0008454699418507516, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.000733182649128139, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006715963245369494, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006667225388810039, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006880538421683013, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.001179593033157289, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.000625302258413285, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.000963131315074861, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.000773065083194524, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007792402757331729, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.000987401930615306, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006231084698811173, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006853177910670638, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008236204739660025, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0008620157022960484, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0006242432282306254, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007418710738420486, Min w: 0.0\n",
      "Iteration 30, Loss: 0.001073051244020462, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006357983220368624, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0010063770459964871, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0007707882323302329, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0013776442501693964, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001139067462645471, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006388806505128741, Min w: 0.0\n",
      "Iteration 100, Loss: 0.000835628539789468, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0008186579798348248, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0009082162869162858, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006294816848821938, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0011036123614758253, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008591772639192641, Min w: 0.0\n",
      "Iteration 160, Loss: 0.000774318992625922, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0013471138663589954, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006252124439924955, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0006968626985326409, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007566222338937223, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006850017234683037, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0016930586425587535, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006649299175478518, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0013964429963380098, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006832203944213688, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0026957495138049126, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0010788814397528768, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0009258819045498967, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006428470951505005, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0009065847261808813, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0014198597054928541, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006736797513440251, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0009434226667508483, Min w: 1.588716890157304e-34\n",
      "Iteration 340, Loss: 0.0009376745438203216, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0013163011753931642, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0010362028842791915, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0011188570642843843, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0009882586309686303, Min w: 0.0\n",
      "Iteration 390, Loss: 0.000616841483861208, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007941515650600195, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0007701454451307654, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0016446619993075728, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0006621576030738652, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008343311492353678, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0009479055879637599, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006225379765965044, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006059785955585539, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007311663939617574, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0007265432504937053, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0008369527058675885, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0006200780626386404, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007376467110589147, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0008187025669030845, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0016826462233439088, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006996776210144162, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007398869493044913, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006364387809298933, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007944006938487291, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0011839783983305097, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0022285536397248507, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0008083345601335168, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0010669835610315204, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0008350950083695352, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0007965494296513498, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006844097515568137, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0009640514035709202, Min w: 7.072030005992422e-35\n",
      "Iteration 670, Loss: 0.000760694732889533, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0011235337005928159, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006910509546287358, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0020251325331628323, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0009403464500792325, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0007028412655927241, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0010246209567412734, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0008348613046109676, Min w: 0.0\n",
      "Iteration 750, Loss: 0.00225718691945076, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0015627923421561718, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0007096482440829277, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0011392290471121669, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0008113026851788163, Min w: 0.0\n",
      "Iteration 800, Loss: 0.000899856211617589, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0017231840174645185, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0013793734833598137, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0010014454601332545, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008171539520844817, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0006116367294453084, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0008021675748750567, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0008527874015271664, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0015837083337828517, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006530280807055533, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0011154315434396267, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0009735909407027066, Min w: 0.0\n",
      "Iteration 920, Loss: 0.001046866411343217, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006868329364806414, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0008567061158828437, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0006368734175339341, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0014310484984889627, Min w: 0.0\n",
      "Iteration 970, Loss: 0.000775860040448606, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0012393825454637408, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0006274672923609614, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0011866679415106773, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0007140404777601361, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0014894099440425634, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0006923681357875466, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0010325458133593202, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0007190654287114739, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0022525545209646225, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006766539299860597, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0011907134903594851, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006413600058294833, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0015095252310857177, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006064683548174798, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0010072258301079273, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0009160935296677053, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0011100656120106578, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006578809698112309, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.001103089889511466, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006700006779283285, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.000655921408906579, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0012169742258265615, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006614502053707838, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0017976847011595964, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0008825409458950162, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0016238897806033492, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0006840714486315846, Min w: 0.0\n",
      "Iteration 0, Loss: 0.001036366680637002, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0009705094853416085, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007869426044635475, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0009531654068268836, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0007022288627922535, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006690789596177638, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0008561572758480906, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007137596257962286, Min w: 0.0\n",
      "Iteration 80, Loss: 0.001670914818532765, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0014540121192112565, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0011902461992576718, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0009963777847588062, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0007710147183388472, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0006522751064039767, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0009736930369399488, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0008579110144637525, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0009699996444396675, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006019040010869503, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0011103891301900148, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005998404230922461, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0007223376305773854, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0008706076187081635, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0010094664758071303, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006711320602335036, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0009749716846272349, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006087867077440023, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0006877389387227595, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007628380553796887, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0015551185933873057, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0006498198490589857, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0011103240540251136, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0009852518560364842, Min w: 0.0\n",
      "Iteration 320, Loss: 0.000746331294067204, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0010501877404749393, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006575623410753906, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0006125804502516985, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0006855560350231826, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0022830951493233442, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0012476361589506269, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0009176203748211265, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0007032924913801253, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006893218960613012, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0009709727019071579, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007869144319556653, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0006460016593337059, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0008168298518285155, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0008554640226066113, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0007818807498551905, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0008286612574011087, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0006669341237284243, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0023740516044199467, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0012156572192907333, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0007101715309545398, Min w: 0.0\n",
      "Iteration 530, Loss: 0.0010631069308146834, Min w: 0.0\n",
      "Iteration 540, Loss: 0.000928852881770581, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0009811391355469823, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0015126185026019812, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0007050540880300105, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0010005102958530188, Min w: 0.0\n",
      "Iteration 590, Loss: 0.001397599931806326, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0013940510107204318, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0007830142858438194, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0010060202330350876, Min w: 0.0\n",
      "Iteration 630, Loss: 0.0006833162624388933, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0006076823337934911, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006284470437094569, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0008504327270202339, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0008608342614024878, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007249637856148183, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0020140474662184715, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0007487849215976894, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0006737129297107458, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0008804142125882208, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0009254793985746801, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0007533513125963509, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0010235215304419398, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0007057449547573924, Min w: 0.0\n",
      "Iteration 770, Loss: 0.00107668898999691, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0009545484208501875, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0009339000680483878, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0008756192401051521, Min w: 0.0\n",
      "Iteration 810, Loss: 0.001320821000263095, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0007130078738555312, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0012696603080257773, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0008779980125837028, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0007947420235723257, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0007871661800891161, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0007729376666247845, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0009533639531582594, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006985829677432775, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006537408335134387, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0007228756439872086, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0007238692487590015, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0007887238753028214, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006091411923989654, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0007821464678272605, Min w: 0.0\n",
      "Iteration 960, Loss: 0.00100229075178504, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006189616397023201, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0006425970350392163, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0014107198221608996, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006090127862989902, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0007504219538532197, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0007465960807166994, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0009339384851045907, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0006526084616780281, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.000642455939669162, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007893750444054604, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.000713962537702173, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0007778037106618285, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0009759675594978034, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006412894581444561, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0011083877179771662, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0006728005828335881, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0007536955527029932, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006792555213905871, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0015788041055202484, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0006923655746504664, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0008093372453004122, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0007422289345413446, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0008326738025061786, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007829814567230642, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0009554331772960722, Min w: 2.0422523819069884e-41\n",
      "Iteration 1220, Loss: 0.0006580511690117419, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0007210361654870212, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.000675914459861815, Min w: 0.0\n",
      "Iteration 0, Loss: 0.0009081781608983874, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0007063494413159788, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009576416341587901, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0008175735711120069, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0006543530034832656, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006067671929486096, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0008701679180376232, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0007182838744483888, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0007590384921059012, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0006392190116457641, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006206142134033144, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0008161564473994076, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0007387953228317201, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0023434613831341267, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0006467451457865536, Min w: 0.0\n",
      "Iteration 150, Loss: 0.001209764275699854, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0006472021341323853, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006060122395865619, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006778800743632019, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0008302934584207833, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006674128235317767, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0006678334320895374, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0009533161646686494, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0008144935709424317, Min w: 0.0\n",
      "Iteration 240, Loss: 0.000990247237496078, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0006119257304817438, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0008563526789657772, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0008147741318680346, Min w: 0.0\n",
      "Iteration 280, Loss: 0.001458186306990683, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007075067842379212, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007013093563728034, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0008146948530338705, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0006222225492820144, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0006821080460213125, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0008153729722835124, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0009116819710470736, Min w: 0.0\n",
      "Iteration 360, Loss: 0.000702786142937839, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0010239447001367807, Min w: 8.14298135317534e-23\n",
      "Iteration 380, Loss: 0.0013575564371421933, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0009043791214935482, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006875832914374769, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0006365716690197587, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0007966880802996457, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007653404609300196, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008079410181380808, Min w: 0.0\n",
      "Iteration 450, Loss: 0.0006233641179278493, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0006401060381904244, Min w: 0.0\n",
      "Iteration 470, Loss: 0.0006880444125272334, Min w: 0.0\n",
      "Iteration 480, Loss: 0.00135319703258574, Min w: 0.0\n",
      "Iteration 490, Loss: 0.000641352089587599, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0006205979734659195, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0007130518788471818, Min w: 0.0\n",
      "Iteration 520, Loss: 0.001039523514918983, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000763476942665875, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0007689140038564801, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006489945226348937, Min w: 0.0\n",
      "Iteration 560, Loss: 0.001327450736425817, Min w: 0.0\n",
      "Iteration 570, Loss: 0.0006476276321336627, Min w: 0.0\n",
      "Iteration 580, Loss: 0.0007661033305339515, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0007351280655711889, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0012937103165313601, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006078724982216954, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006243236712180078, Min w: 0.0\n",
      "Iteration 630, Loss: 0.001003773184493184, Min w: 0.0\n",
      "Iteration 640, Loss: 0.0016190385213121772, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0016680278349667788, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0007299226126633584, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007528547430410981, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0007160574314184487, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0006902869208715856, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0006416803225874901, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0012706986162811518, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0008307769312523305, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0010056101018562913, Min w: 0.0\n",
      "Iteration 740, Loss: 0.001582461060024798, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0006576664745807648, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0009700936498120427, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0009109684033319354, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0009910953231155872, Min w: 6.271203439839076e-37\n",
      "Iteration 790, Loss: 0.0012203565565869212, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0006672509480267763, Min w: 0.0\n",
      "Iteration 810, Loss: 0.001000639284029603, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0008354674209840596, Min w: 0.0\n",
      "Iteration 830, Loss: 0.001923992414958775, Min w: 0.0\n",
      "Iteration 840, Loss: 0.0006441888399422169, Min w: 0.0\n",
      "Iteration 850, Loss: 0.0012159135658293962, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0006922466563992202, Min w: 0.0\n",
      "Iteration 870, Loss: 0.002666932065039873, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0006328925956040621, Min w: 0.0\n",
      "Iteration 890, Loss: 0.001181102590635419, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006746197468601167, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0007237237296067178, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0009158797329291701, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006281525711528957, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0011020320234820247, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0005997343687340617, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0006904975161887705, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0007591979228891432, Min w: 0.0\n",
      "Iteration 980, Loss: 0.001134584890678525, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0011553000658750534, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0006158927571959794, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0006197666516527534, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0006916149286553264, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.0007293425151146948, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0020316035952419043, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.0008839603397063911, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0006068178336136043, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0008042138651944697, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0008361046202480793, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0006336652440950274, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0006396612734533846, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006036942941136658, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0007087826379574835, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.000755089451558888, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0006030660588294268, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0006862729205749929, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0007272306247614324, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0008187323692254722, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.000964461883995682, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0007563380640931427, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0006128340028226376, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.000737435300834477, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.000914775999262929, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006704296683892608, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.002048148773610592, Min w: 0.0\n",
      "Iteration 0, Loss: 0.000611187017057091, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0007098016794770956, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0007062135264277458, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0010157021461054683, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0010968490969389677, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0006394676165655255, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0006987121887505054, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0008373886812478304, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0010425018845126033, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0011759793851524591, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0006971544935368001, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0007428918033838272, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0011295309523120522, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007084388053044677, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0007679871050640941, Min w: 0.0\n",
      "Iteration 150, Loss: 0.000732935150153935, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0008883277187123895, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0014546604361385107, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0007104593678377569, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0007177917286753654, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0006892536766827106, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0011004458647221327, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0007918632472865283, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0006403213483281434, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0009152750135399401, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0007000949117355049, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0018801110563799739, Min w: 0.0\n",
      "Iteration 270, Loss: 0.0007159537635743618, Min w: 0.0\n",
      "Iteration 280, Loss: 0.0006492360262200236, Min w: 0.0\n",
      "Iteration 290, Loss: 0.0007116307388059795, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0007229035254567862, Min w: 0.0\n",
      "Iteration 310, Loss: 0.0007172598270699382, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0008497170638293028, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0009348291787318885, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0006407360197044909, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0006221924559213221, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0006816402310505509, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0008584505994804204, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0006570197292603552, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0010427730157971382, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0006621800130233169, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0012306104181334376, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0006493532564491034, Min w: 0.0\n",
      "Iteration 430, Loss: 0.0007411799160763621, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0008558564586564898, Min w: 0.0\n",
      "Iteration 450, Loss: 0.00136968691367656, Min w: 0.0\n",
      "Iteration 460, Loss: 0.0007935212342999876, Min w: 0.0\n",
      "Iteration 470, Loss: 0.001084799412637949, Min w: 0.0\n",
      "Iteration 480, Loss: 0.0007938587805256248, Min w: 0.0\n",
      "Iteration 490, Loss: 0.0007967801066115499, Min w: 0.0\n",
      "Iteration 500, Loss: 0.0007277586264535785, Min w: 0.0\n",
      "Iteration 510, Loss: 0.0009510761010460556, Min w: 0.0\n",
      "Iteration 520, Loss: 0.0006557425367645919, Min w: 0.0\n",
      "Iteration 530, Loss: 0.000936876458581537, Min w: 0.0\n",
      "Iteration 540, Loss: 0.0008940499974414706, Min w: 0.0\n",
      "Iteration 550, Loss: 0.0006723267724737525, Min w: 0.0\n",
      "Iteration 560, Loss: 0.0007410505204461515, Min w: 0.0\n",
      "Iteration 570, Loss: 0.000702620018273592, Min w: 0.0\n",
      "Iteration 580, Loss: 0.000749255355913192, Min w: 0.0\n",
      "Iteration 590, Loss: 0.0006833234219811857, Min w: 0.0\n",
      "Iteration 600, Loss: 0.0008343752124346793, Min w: 0.0\n",
      "Iteration 610, Loss: 0.0006781643605791032, Min w: 0.0\n",
      "Iteration 620, Loss: 0.0006105135544203222, Min w: 0.0\n",
      "Iteration 630, Loss: 0.000740467628929764, Min w: 0.0\n",
      "Iteration 640, Loss: 0.000902291911188513, Min w: 0.0\n",
      "Iteration 650, Loss: 0.0006475459085777402, Min w: 0.0\n",
      "Iteration 660, Loss: 0.0010134675540030003, Min w: 0.0\n",
      "Iteration 670, Loss: 0.0007595900679007173, Min w: 0.0\n",
      "Iteration 680, Loss: 0.0015640477649867535, Min w: 0.0\n",
      "Iteration 690, Loss: 0.0007028167019598186, Min w: 0.0\n",
      "Iteration 700, Loss: 0.0015329597517848015, Min w: 0.0\n",
      "Iteration 710, Loss: 0.0011514065554365516, Min w: 0.0\n",
      "Iteration 720, Loss: 0.0009753155172802508, Min w: 0.0\n",
      "Iteration 730, Loss: 0.0014479480450972915, Min w: 0.0\n",
      "Iteration 740, Loss: 0.0010669023031368852, Min w: 0.0\n",
      "Iteration 750, Loss: 0.0007097212364897132, Min w: 0.0\n",
      "Iteration 760, Loss: 0.0008763507939875126, Min w: 0.0\n",
      "Iteration 770, Loss: 0.0006150624831207097, Min w: 0.0\n",
      "Iteration 780, Loss: 0.0006263511604629457, Min w: 0.0\n",
      "Iteration 790, Loss: 0.0009325718856416643, Min w: 0.0\n",
      "Iteration 800, Loss: 0.0013380114687606692, Min w: 0.0\n",
      "Iteration 810, Loss: 0.0007752934470772743, Min w: 0.0\n",
      "Iteration 820, Loss: 0.0010667851893231273, Min w: 0.0\n",
      "Iteration 830, Loss: 0.0007892951252870262, Min w: 0.0\n",
      "Iteration 840, Loss: 0.001977398060262203, Min w: 0.0\n",
      "Iteration 850, Loss: 0.000834085454698652, Min w: 0.0\n",
      "Iteration 860, Loss: 0.0015577604062855244, Min w: 0.0\n",
      "Iteration 870, Loss: 0.0010587897850200534, Min w: 0.0\n",
      "Iteration 880, Loss: 0.0008465633145533502, Min w: 0.0\n",
      "Iteration 890, Loss: 0.0006649828283116221, Min w: 0.0\n",
      "Iteration 900, Loss: 0.0006903813336975873, Min w: 0.0\n",
      "Iteration 910, Loss: 0.0006281016394495964, Min w: 0.0\n",
      "Iteration 920, Loss: 0.0006483767065219581, Min w: 0.0\n",
      "Iteration 930, Loss: 0.0006084552733227611, Min w: 0.0\n",
      "Iteration 940, Loss: 0.0006047498318366706, Min w: 0.0\n",
      "Iteration 950, Loss: 0.0007763386820442975, Min w: 0.0\n",
      "Iteration 960, Loss: 0.0009785050060600042, Min w: 0.0\n",
      "Iteration 970, Loss: 0.0006210593273863196, Min w: 0.0\n",
      "Iteration 980, Loss: 0.0009162623318843544, Min w: 0.0\n",
      "Iteration 990, Loss: 0.0008050397736951709, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.0025692132767289877, Min w: 0.0\n",
      "Iteration 1010, Loss: 0.0009922903263941407, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.0010102004744112492, Min w: 0.0\n",
      "Iteration 1030, Loss: 0.000666053791064769, Min w: 0.0\n",
      "Iteration 1040, Loss: 0.0007612186600454152, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.000895331206265837, Min w: 0.0\n",
      "Iteration 1060, Loss: 0.0007069476414471865, Min w: 0.0\n",
      "Iteration 1070, Loss: 0.0006503835320472717, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.0021461695432662964, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.0008181891753338277, Min w: 0.0\n",
      "Iteration 1100, Loss: 0.0007852796697989106, Min w: 0.0\n",
      "Iteration 1110, Loss: 0.0006730790482833982, Min w: 0.0\n",
      "Iteration 1120, Loss: 0.0016278999391943216, Min w: 0.0\n",
      "Iteration 1130, Loss: 0.0006048640934750438, Min w: 0.0\n",
      "Iteration 1140, Loss: 0.0015163777861744165, Min w: 0.0\n",
      "Iteration 1150, Loss: 0.0008028430747799575, Min w: 0.0\n",
      "Iteration 1160, Loss: 0.0007738645654171705, Min w: 0.0\n",
      "Iteration 1170, Loss: 0.0006093510892242193, Min w: 0.0\n",
      "Iteration 1180, Loss: 0.0007775126723572612, Min w: 0.0\n",
      "Iteration 1190, Loss: 0.0007599596283398569, Min w: 0.0\n",
      "Iteration 1200, Loss: 0.0007683915318921208, Min w: 0.0\n",
      "Iteration 1210, Loss: 0.0006553685525432229, Min w: 0.0\n",
      "Iteration 1220, Loss: 0.0006319290841929615, Min w: 0.0\n",
      "Iteration 1230, Loss: 0.0006748957093805075, Min w: 0.0\n",
      "Iteration 1240, Loss: 0.0008473389898426831, Min w: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  83%|████████▎ | 20/24 [16:24<03:59, 59.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.5977695268571924, 'L2_avg': 0.6459984081823595, 'End_point_L1_avg': 0.5547877419233497, 'End_point_L2_avg': 0.6762721920558021}\n",
      "Iteration 0, Loss: 0.005873672664165497, Min w: 1.9478048654114957e-43\n",
      "Iteration 10, Loss: 0.004582544788718224, Min w: 0.014270895160734653\n",
      "Iteration 20, Loss: 0.0035770535469055176, Min w: 0.007317258510738611\n",
      "Iteration 30, Loss: 0.002954991301521659, Min w: 5.69192870614188e-09\n",
      "Iteration 40, Loss: 0.0025422254111617804, Min w: 5.198936455529189e-20\n",
      "Iteration 50, Loss: 0.0022778718266636133, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0020689843222498894, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0018160843756049871, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0019618230871856213, Min w: 0.0\n",
      "Iteration 90, Loss: 0.002254334045574069, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0020792416762560606, Min w: 1.3282618223500674e-29\n",
      "Iteration 110, Loss: 0.001526172854937613, Min w: 3.619028904680577e-14\n",
      "Iteration 120, Loss: 0.0014718411257490516, Min w: 0.004334397614002228\n",
      "Iteration 130, Loss: 0.001469399780035019, Min w: 0.026297036558389664\n",
      "Iteration 140, Loss: 0.0013071424327790737, Min w: 0.20860552787780762\n",
      "Iteration 150, Loss: 0.0011206927010789514, Min w: 0.2809267044067383\n",
      "Iteration 160, Loss: 0.0010840180329978466, Min w: 0.34134483337402344\n",
      "Iteration 170, Loss: 0.0009272376773878932, Min w: 0.35452914237976074\n",
      "Iteration 180, Loss: 0.0009190082200802863, Min w: 0.4575478136539459\n",
      "Iteration 190, Loss: 0.0008161445730365813, Min w: 0.5331668257713318\n",
      "Iteration 200, Loss: 0.000847662566229701, Min w: 0.5157048106193542\n",
      "Iteration 210, Loss: 0.0006993231945671141, Min w: 0.5558363199234009\n",
      "Iteration 220, Loss: 0.0007969376747496426, Min w: 0.5881841778755188\n",
      "Iteration 230, Loss: 0.0006499358569271863, Min w: 0.6487525701522827\n",
      "Iteration 240, Loss: 0.0005345053505152464, Min w: 0.6566002368927002\n",
      "Iteration 250, Loss: 0.0007499940111301839, Min w: 0.6226611733436584\n",
      "Iteration 260, Loss: 0.0006337498198263347, Min w: 0.5904534459114075\n",
      "Iteration 270, Loss: 0.000705496990121901, Min w: 0.5907278656959534\n",
      "Iteration 280, Loss: 0.0005701552727259696, Min w: 0.6799416542053223\n",
      "Iteration 290, Loss: 0.0004885591915808618, Min w: 0.6950878500938416\n",
      "Iteration 300, Loss: 0.0004010957491118461, Min w: 0.7698858380317688\n",
      "Iteration 310, Loss: 0.0006741838878951967, Min w: 0.618092954158783\n",
      "Iteration 320, Loss: 0.0006936577265150845, Min w: 0.6334682703018188\n",
      "Iteration 330, Loss: 0.0003801351704169065, Min w: 0.8017151951789856\n",
      "Iteration 340, Loss: 0.0004585459246300161, Min w: 0.703904926776886\n",
      "Iteration 350, Loss: 0.0003793863579630852, Min w: 0.7749919295310974\n",
      "Iteration 360, Loss: 0.00031672767363488674, Min w: 0.7924612760543823\n",
      "Iteration 370, Loss: 0.0003130051482003182, Min w: 0.8222037553787231\n",
      "Iteration 380, Loss: 0.0005480360123328865, Min w: 0.6491413116455078\n",
      "Iteration 390, Loss: 0.00037632460589520633, Min w: 0.7996747493743896\n",
      "Iteration 400, Loss: 0.00032391672721132636, Min w: 0.7857328653335571\n",
      "Iteration 410, Loss: 0.0002806725387927145, Min w: 0.8282982110977173\n",
      "Iteration 420, Loss: 0.0003877724229823798, Min w: 0.7822638750076294\n",
      "Iteration 430, Loss: 0.00037241249810904264, Min w: 0.7528765201568604\n",
      "Iteration 440, Loss: 0.0004543437098618597, Min w: 0.7239366173744202\n",
      "Iteration 450, Loss: 0.0002639841113705188, Min w: 0.8515478372573853\n",
      "Iteration 460, Loss: 0.00024254371237475425, Min w: 0.8559856414794922\n",
      "Iteration 470, Loss: 0.00024066441983450204, Min w: 0.8739968538284302\n",
      "Iteration 480, Loss: 0.00034657565993256867, Min w: 0.7700562477111816\n",
      "Iteration 490, Loss: 0.00023420491197612137, Min w: 0.8631064891815186\n",
      "Iteration 500, Loss: 0.00028016077703796327, Min w: 0.8499321341514587\n",
      "Iteration 510, Loss: 0.0002139661810360849, Min w: 0.8683804273605347\n",
      "Iteration 520, Loss: 0.0002606897905934602, Min w: 0.8555077910423279\n",
      "Iteration 530, Loss: 0.00030373167828656733, Min w: 0.8118169903755188\n",
      "Iteration 540, Loss: 0.00015999528113752604, Min w: 0.9156652688980103\n",
      "Iteration 550, Loss: 0.00015708310820627958, Min w: 0.9172496199607849\n",
      "Iteration 560, Loss: 0.00018022912263404578, Min w: 0.8780452609062195\n",
      "Iteration 570, Loss: 0.00030624528881162405, Min w: 0.8330628275871277\n",
      "Iteration 580, Loss: 0.00012708432041108608, Min w: 0.9318899512290955\n",
      "Iteration 590, Loss: 0.00023174819943960756, Min w: 0.8408128619194031\n",
      "Iteration 600, Loss: 0.00037639233050867915, Min w: 0.7478917241096497\n",
      "Iteration 610, Loss: 0.00020526529988273978, Min w: 0.8539411425590515\n",
      "Iteration 620, Loss: 0.00012825663725379854, Min w: 0.932411253452301\n",
      "Iteration 630, Loss: 0.00014875068154651672, Min w: 0.9112501740455627\n",
      "Iteration 640, Loss: 0.00011699739843606949, Min w: 0.9399758577346802\n",
      "Iteration 650, Loss: 0.00029570405604317784, Min w: 0.8294752240180969\n",
      "Iteration 660, Loss: 0.0003429558710195124, Min w: 0.765850305557251\n",
      "Iteration 670, Loss: 0.00015381985576823354, Min w: 0.9031627774238586\n",
      "Iteration 680, Loss: 0.00019120663637295365, Min w: 0.8719075918197632\n",
      "Iteration 690, Loss: 0.00014817093324381858, Min w: 0.9165570139884949\n",
      "Iteration 700, Loss: 0.00022700375120621175, Min w: 0.8552905321121216\n",
      "Iteration 710, Loss: 0.00014348933473229408, Min w: 0.9165163040161133\n",
      "Iteration 720, Loss: 9.360906551592052e-05, Min w: 0.9491866827011108\n",
      "Iteration 730, Loss: 0.0002789884165395051, Min w: 0.8463312387466431\n",
      "Iteration 740, Loss: 0.00011998054105788469, Min w: 0.9313821792602539\n",
      "Iteration 750, Loss: 0.00023400603095069528, Min w: 0.8633504509925842\n",
      "Iteration 760, Loss: 0.00020514360221568495, Min w: 0.8710964918136597\n",
      "Iteration 770, Loss: 0.0001324703189311549, Min w: 0.9070154428482056\n",
      "Iteration 780, Loss: 0.00014301486953627318, Min w: 0.9228174090385437\n",
      "Iteration 790, Loss: 0.00020288983068894595, Min w: 0.8527593016624451\n",
      "Iteration 800, Loss: 0.00012762135884258896, Min w: 0.9224048852920532\n",
      "Iteration 810, Loss: 0.00019933680596295744, Min w: 0.8889895677566528\n",
      "Iteration 820, Loss: 0.00016027723904699087, Min w: 0.8934624791145325\n",
      "Iteration 830, Loss: 0.00010400883911643177, Min w: 0.9270572066307068\n",
      "Iteration 840, Loss: 0.00013789572403766215, Min w: 0.8951876759529114\n",
      "Iteration 850, Loss: 0.00011864075349876657, Min w: 0.9182108640670776\n",
      "Iteration 860, Loss: 9.447267802897841e-05, Min w: 0.9483140110969543\n",
      "Iteration 870, Loss: 0.00011302681377856061, Min w: 0.9315440654754639\n",
      "Iteration 880, Loss: 0.0002214624109910801, Min w: 0.8706580996513367\n",
      "Iteration 890, Loss: 7.813505362719297e-05, Min w: 0.9591929316520691\n",
      "Iteration 900, Loss: 0.0001658758701523766, Min w: 0.8853150606155396\n",
      "Iteration 910, Loss: 0.00019332958618178964, Min w: 0.8969424366950989\n",
      "Iteration 920, Loss: 0.00013451071572490036, Min w: 0.9033646583557129\n",
      "Iteration 930, Loss: 0.000132466564537026, Min w: 0.9140031337738037\n",
      "Iteration 940, Loss: 0.00013963425590191036, Min w: 0.9100361466407776\n",
      "Iteration 950, Loss: 9.118287562159821e-05, Min w: 0.9502854347229004\n",
      "Iteration 960, Loss: 0.00010939432104350999, Min w: 0.9307356476783752\n",
      "Iteration 970, Loss: 0.00012669885472860187, Min w: 0.9088255167007446\n",
      "Iteration 980, Loss: 8.61656226334162e-05, Min w: 0.9427900314331055\n",
      "Iteration 990, Loss: 0.0001169423630926758, Min w: 0.9335525631904602\n",
      "Iteration 1000, Loss: 7.009557157289237e-05, Min w: 0.9596549868583679\n",
      "Iteration 1010, Loss: 0.00011044925486203283, Min w: 0.9425732493400574\n",
      "Iteration 1020, Loss: 7.83670402597636e-05, Min w: 0.958103358745575\n",
      "Iteration 1030, Loss: 9.297936776420102e-05, Min w: 0.9438360929489136\n",
      "Iteration 1040, Loss: 6.908286013640463e-05, Min w: 0.9628319144248962\n",
      "Iteration 1050, Loss: 8.476512448396534e-05, Min w: 0.954782247543335\n",
      "Iteration 1060, Loss: 9.129438694799319e-05, Min w: 0.9508269429206848\n",
      "Iteration 1070, Loss: 0.00011484140122774988, Min w: 0.9169703722000122\n",
      "Iteration 1080, Loss: 0.00024051734362728894, Min w: 0.8338037729263306\n",
      "Iteration 1090, Loss: 0.00013918933109380305, Min w: 0.92743319272995\n",
      "Iteration 1100, Loss: 8.327716932399198e-05, Min w: 0.9512554407119751\n",
      "Iteration 1110, Loss: 0.00011506355804158375, Min w: 0.9241470694541931\n",
      "Iteration 1120, Loss: 9.055321424966678e-05, Min w: 0.9519894123077393\n",
      "Iteration 1130, Loss: 9.849259367911145e-05, Min w: 0.9483692049980164\n",
      "Iteration 1140, Loss: 0.00020994893566239625, Min w: 0.8367910981178284\n",
      "Iteration 1150, Loss: 0.00019581780361477286, Min w: 0.8658469319343567\n",
      "Iteration 1160, Loss: 7.571577589260414e-05, Min w: 0.9587152600288391\n",
      "Iteration 1170, Loss: 5.462542685563676e-05, Min w: 0.9696270227432251\n",
      "Iteration 1180, Loss: 0.00014147633919492364, Min w: 0.91701340675354\n",
      "Iteration 1190, Loss: 0.0001881591451819986, Min w: 0.8623587489128113\n",
      "Iteration 1200, Loss: 0.00019123290257994086, Min w: 0.8827256560325623\n",
      "Iteration 1210, Loss: 0.0001280352589674294, Min w: 0.93119877576828\n",
      "Iteration 1220, Loss: 7.120371446944773e-05, Min w: 0.9545148015022278\n",
      "Iteration 1230, Loss: 0.00014704141358379275, Min w: 0.9031267762184143\n",
      "Iteration 1240, Loss: 0.00011406962585169822, Min w: 0.9328038096427917\n",
      "Iteration 0, Loss: 5.8768167946254835e-05, Min w: 0.9673948884010315\n",
      "Iteration 10, Loss: 6.112601113272831e-05, Min w: 0.9652370810508728\n",
      "Iteration 20, Loss: 7.870669651310891e-05, Min w: 0.9479533433914185\n",
      "Iteration 30, Loss: 0.00010255263623548672, Min w: 0.9434266686439514\n",
      "Iteration 40, Loss: 0.00016456500452477485, Min w: 0.9146288633346558\n",
      "Iteration 50, Loss: 0.00016798054275568575, Min w: 0.8959413766860962\n",
      "Iteration 60, Loss: 8.777044422458857e-05, Min w: 0.9374958872795105\n",
      "Iteration 70, Loss: 0.0002111715148203075, Min w: 0.8676748275756836\n",
      "Iteration 80, Loss: 7.857963646529242e-05, Min w: 0.9498136043548584\n",
      "Iteration 90, Loss: 0.0001976561325136572, Min w: 0.8814365863800049\n",
      "Iteration 100, Loss: 0.00012138224701629952, Min w: 0.9264108538627625\n",
      "Iteration 110, Loss: 5.219606828177348e-05, Min w: 0.9718189835548401\n",
      "Iteration 120, Loss: 0.00017207965720444918, Min w: 0.8947623372077942\n",
      "Iteration 130, Loss: 0.00010799495066748932, Min w: 0.9298867583274841\n",
      "Iteration 140, Loss: 8.240475290222093e-05, Min w: 0.9512309432029724\n",
      "Iteration 150, Loss: 9.596160816727206e-05, Min w: 0.9488208293914795\n",
      "Iteration 160, Loss: 0.00010277532419422641, Min w: 0.9405385255813599\n",
      "Iteration 170, Loss: 0.00021402459242381155, Min w: 0.8788859248161316\n",
      "Iteration 180, Loss: 7.17861985322088e-05, Min w: 0.9502601623535156\n",
      "Iteration 190, Loss: 0.00012194573355372995, Min w: 0.9199501276016235\n",
      "Iteration 200, Loss: 5.7959678088082e-05, Min w: 0.9653825759887695\n",
      "Iteration 210, Loss: 7.790431845933199e-05, Min w: 0.9498001337051392\n",
      "Iteration 220, Loss: 0.00012416082608979195, Min w: 0.9320463538169861\n",
      "Iteration 230, Loss: 0.00011041726975236088, Min w: 0.9330321550369263\n",
      "Iteration 240, Loss: 0.00010540995572227985, Min w: 0.9346787333488464\n",
      "Iteration 250, Loss: 0.00010130388545803726, Min w: 0.9468114972114563\n",
      "Iteration 260, Loss: 9.22140825423412e-05, Min w: 0.9388009905815125\n",
      "Iteration 270, Loss: 0.00020609608327504247, Min w: 0.8541949987411499\n",
      "Iteration 280, Loss: 9.593868890078738e-05, Min w: 0.9329358339309692\n",
      "Iteration 290, Loss: 8.091478957794607e-05, Min w: 0.9456443786621094\n",
      "Iteration 300, Loss: 5.017781586502679e-05, Min w: 0.970939576625824\n",
      "Iteration 310, Loss: 0.00011831708252429962, Min w: 0.9144747257232666\n",
      "Iteration 320, Loss: 0.00014515755174215883, Min w: 0.9235286116600037\n",
      "Iteration 330, Loss: 7.862207712605596e-05, Min w: 0.9564129114151001\n",
      "Iteration 340, Loss: 0.00012211233843117952, Min w: 0.9270655512809753\n",
      "Iteration 350, Loss: 0.00012776232324540615, Min w: 0.9082176089286804\n",
      "Iteration 360, Loss: 7.328528590733185e-05, Min w: 0.962165355682373\n",
      "Iteration 370, Loss: 6.159852637210861e-05, Min w: 0.966744065284729\n",
      "Iteration 380, Loss: 7.015118171693757e-05, Min w: 0.9583885073661804\n",
      "Iteration 390, Loss: 0.0001032949221553281, Min w: 0.9384391903877258\n",
      "Iteration 400, Loss: 4.667435132432729e-05, Min w: 0.9721853137016296\n",
      "Iteration 410, Loss: 0.00015489733777940273, Min w: 0.912828266620636\n",
      "Iteration 420, Loss: 7.016187009867281e-05, Min w: 0.9612338542938232\n",
      "Iteration 430, Loss: 8.546641765860841e-05, Min w: 0.9499987959861755\n",
      "Iteration 440, Loss: 7.546137203462422e-05, Min w: 0.9495270252227783\n",
      "Iteration 450, Loss: 7.448906399076805e-05, Min w: 0.9614090323448181\n",
      "Iteration 460, Loss: 0.00021223192743491381, Min w: 0.885466456413269\n",
      "Iteration 470, Loss: 0.0001329363149125129, Min w: 0.9112238883972168\n",
      "Iteration 480, Loss: 5.060858893557452e-05, Min w: 0.9717474579811096\n",
      "Iteration 490, Loss: 4.618703678715974e-05, Min w: 0.9728480577468872\n",
      "Iteration 500, Loss: 7.071713480399922e-05, Min w: 0.9618307948112488\n",
      "Iteration 510, Loss: 5.000472810934298e-05, Min w: 0.9743339419364929\n",
      "Iteration 520, Loss: 0.00023532916384283453, Min w: 0.85667484998703\n",
      "Iteration 530, Loss: 6.214484892552719e-05, Min w: 0.9613704085350037\n",
      "Iteration 540, Loss: 4.9703652621246874e-05, Min w: 0.9724575281143188\n",
      "Iteration 550, Loss: 6.789425970055163e-05, Min w: 0.9571823477745056\n",
      "Iteration 560, Loss: 6.29623609711416e-05, Min w: 0.9648311734199524\n",
      "Iteration 570, Loss: 0.00011828415881609544, Min w: 0.9362936615943909\n",
      "Iteration 580, Loss: 0.00013651604240294546, Min w: 0.9248188734054565\n",
      "Iteration 590, Loss: 8.736312884138897e-05, Min w: 0.9355860352516174\n",
      "Iteration 600, Loss: 4.7999124944908544e-05, Min w: 0.9740750193595886\n",
      "Iteration 610, Loss: 0.00011040901154046878, Min w: 0.9416018724441528\n",
      "Iteration 620, Loss: 9.468560892855749e-05, Min w: 0.9507943391799927\n",
      "Iteration 630, Loss: 0.00023434571630787104, Min w: 0.870194673538208\n",
      "Iteration 640, Loss: 5.627883365377784e-05, Min w: 0.9644020795822144\n",
      "Iteration 650, Loss: 0.00011984735465375707, Min w: 0.9325788617134094\n",
      "Iteration 660, Loss: 4.7803547204239294e-05, Min w: 0.9714725017547607\n",
      "Iteration 670, Loss: 9.442502778256312e-05, Min w: 0.9382390379905701\n",
      "Iteration 680, Loss: 3.576420567696914e-05, Min w: 0.981389582157135\n",
      "Iteration 690, Loss: 6.938199658179656e-05, Min w: 0.9582540392875671\n",
      "Iteration 700, Loss: 3.924523844034411e-05, Min w: 0.973784863948822\n",
      "Iteration 710, Loss: 5.0229766202392057e-05, Min w: 0.973819375038147\n",
      "Iteration 720, Loss: 8.628616342321038e-05, Min w: 0.9288631081581116\n",
      "Iteration 730, Loss: 7.495677709812298e-05, Min w: 0.9544067978858948\n",
      "Iteration 740, Loss: 0.00011125303717562929, Min w: 0.9292656779289246\n",
      "Iteration 750, Loss: 5.14588100486435e-05, Min w: 0.9711171388626099\n",
      "Iteration 760, Loss: 3.751376789296046e-05, Min w: 0.9807403087615967\n",
      "Iteration 770, Loss: 4.0734077629167587e-05, Min w: 0.9774899482727051\n",
      "Iteration 780, Loss: 0.00012350485485512763, Min w: 0.927140474319458\n",
      "Iteration 790, Loss: 9.667953418102115e-05, Min w: 0.9408616423606873\n",
      "Iteration 800, Loss: 5.694223000318743e-05, Min w: 0.9647205471992493\n",
      "Iteration 810, Loss: 8.452333713648841e-05, Min w: 0.9537002444267273\n",
      "Iteration 820, Loss: 0.00012587920355144888, Min w: 0.9133666157722473\n",
      "Iteration 830, Loss: 0.00010538539936533198, Min w: 0.9166213870048523\n",
      "Iteration 840, Loss: 7.434270810335875e-05, Min w: 0.96016526222229\n",
      "Iteration 850, Loss: 7.588406151626259e-05, Min w: 0.9590857028961182\n",
      "Iteration 860, Loss: 0.00013421443873085082, Min w: 0.895142674446106\n",
      "Iteration 870, Loss: 4.3902549805352464e-05, Min w: 0.9735220074653625\n",
      "Iteration 880, Loss: 6.96383067406714e-05, Min w: 0.9566084742546082\n",
      "Iteration 890, Loss: 8.821557275950909e-05, Min w: 0.9434468150138855\n",
      "Iteration 900, Loss: 8.409526344621554e-05, Min w: 0.9488521814346313\n",
      "Iteration 910, Loss: 3.763188942684792e-05, Min w: 0.97823566198349\n",
      "Iteration 920, Loss: 6.07432120887097e-05, Min w: 0.9668429493904114\n",
      "Iteration 930, Loss: 6.252218008739874e-05, Min w: 0.9639408588409424\n",
      "Iteration 940, Loss: 8.066222653724253e-05, Min w: 0.9417670965194702\n",
      "Iteration 950, Loss: 0.00010266363096889108, Min w: 0.9218129515647888\n",
      "Iteration 960, Loss: 5.065040386398323e-05, Min w: 0.9694329500198364\n",
      "Iteration 970, Loss: 3.1966592359822243e-05, Min w: 0.979390561580658\n",
      "Iteration 980, Loss: 0.00018056547560263425, Min w: 0.8877936005592346\n",
      "Iteration 990, Loss: 4.4960121158510447e-05, Min w: 0.9730668067932129\n",
      "Iteration 1000, Loss: 4.059547063661739e-05, Min w: 0.9744609594345093\n",
      "Iteration 1010, Loss: 5.8818404795601964e-05, Min w: 0.9685525894165039\n",
      "Iteration 1020, Loss: 0.00016895505541469902, Min w: 0.8567199110984802\n",
      "Iteration 1030, Loss: 5.4499967518495396e-05, Min w: 0.9651246070861816\n",
      "Iteration 1040, Loss: 3.703463153215125e-05, Min w: 0.9776955842971802\n",
      "Iteration 1050, Loss: 0.00010990587179549038, Min w: 0.939563512802124\n",
      "Iteration 1060, Loss: 4.880762207903899e-05, Min w: 0.9708907604217529\n",
      "Iteration 1070, Loss: 3.534854840836488e-05, Min w: 0.9808632135391235\n",
      "Iteration 1080, Loss: 8.943775173975155e-05, Min w: 0.9420685768127441\n",
      "Iteration 1090, Loss: 0.000123523102956824, Min w: 0.9204578995704651\n",
      "Iteration 1100, Loss: 0.0001294981484534219, Min w: 0.9010280966758728\n",
      "Iteration 1110, Loss: 3.8969585148151964e-05, Min w: 0.9753364324569702\n",
      "Iteration 1120, Loss: 3.410851422813721e-05, Min w: 0.9809872508049011\n",
      "Iteration 1130, Loss: 0.00014021316019352525, Min w: 0.9064509868621826\n",
      "Iteration 1140, Loss: 0.0001743789471220225, Min w: 0.8683622479438782\n",
      "Iteration 1150, Loss: 7.200151594588533e-05, Min w: 0.9505679607391357\n",
      "Iteration 1160, Loss: 0.0001132702236645855, Min w: 0.9207767844200134\n",
      "Iteration 1170, Loss: 3.861910954583436e-05, Min w: 0.9786506295204163\n",
      "Iteration 1180, Loss: 4.232461651554331e-05, Min w: 0.9697158932685852\n",
      "Iteration 1190, Loss: 0.0001187403904623352, Min w: 0.9306313991546631\n",
      "Iteration 1200, Loss: 0.00012657992192544043, Min w: 0.9276970028877258\n",
      "Iteration 1210, Loss: 0.00010424989159218967, Min w: 0.9284944534301758\n",
      "Iteration 1220, Loss: 3.3782835089368746e-05, Min w: 0.9826250672340393\n",
      "Iteration 1230, Loss: 4.277669722796418e-05, Min w: 0.9733967781066895\n",
      "Iteration 1240, Loss: 5.39586108061485e-05, Min w: 0.9698984026908875\n",
      "Iteration 0, Loss: 8.536529639968649e-05, Min w: 0.9500329494476318\n",
      "Iteration 10, Loss: 0.00015422400610987097, Min w: 0.9020898938179016\n",
      "Iteration 20, Loss: 7.099818321876228e-05, Min w: 0.9538851976394653\n",
      "Iteration 30, Loss: 8.357027400052175e-05, Min w: 0.9559678435325623\n",
      "Iteration 40, Loss: 4.5681594201596454e-05, Min w: 0.9735901355743408\n",
      "Iteration 50, Loss: 0.00010321507579647005, Min w: 0.9120979905128479\n",
      "Iteration 60, Loss: 8.383408567169681e-05, Min w: 0.9415479898452759\n",
      "Iteration 70, Loss: 5.588748899754137e-05, Min w: 0.9687284231185913\n",
      "Iteration 80, Loss: 0.00012291449820622802, Min w: 0.9044601917266846\n",
      "Iteration 90, Loss: 6.002134250593372e-05, Min w: 0.9573467969894409\n",
      "Iteration 100, Loss: 8.672230615047738e-05, Min w: 0.9392105937004089\n",
      "Iteration 110, Loss: 3.6283861845731735e-05, Min w: 0.9806729555130005\n",
      "Iteration 120, Loss: 5.813715688418597e-05, Min w: 0.9582132697105408\n",
      "Iteration 130, Loss: 3.879353971569799e-05, Min w: 0.9775533676147461\n",
      "Iteration 140, Loss: 0.00010900909546762705, Min w: 0.9206451773643494\n",
      "Iteration 150, Loss: 5.8427132898941636e-05, Min w: 0.9682835936546326\n",
      "Iteration 160, Loss: 9.750264143804088e-05, Min w: 0.9287518262863159\n",
      "Iteration 170, Loss: 0.00021024719171691686, Min w: 0.8654744625091553\n",
      "Iteration 180, Loss: 0.00013226743612904102, Min w: 0.9256620407104492\n",
      "Iteration 190, Loss: 3.980557812610641e-05, Min w: 0.9774129390716553\n",
      "Iteration 200, Loss: 3.0084212994552217e-05, Min w: 0.9820666313171387\n",
      "Iteration 210, Loss: 3.253731847507879e-05, Min w: 0.9777251482009888\n",
      "Iteration 220, Loss: 2.843359652615618e-05, Min w: 0.9835634231567383\n",
      "Iteration 230, Loss: 8.915262151276693e-05, Min w: 0.9465306401252747\n",
      "Iteration 240, Loss: 0.00011360282951500267, Min w: 0.9398941397666931\n",
      "Iteration 250, Loss: 0.00012027139018755406, Min w: 0.9188393354415894\n",
      "Iteration 260, Loss: 2.5839975933195092e-05, Min w: 0.9840753674507141\n",
      "Iteration 270, Loss: 3.73860530089587e-05, Min w: 0.9773157835006714\n",
      "Iteration 280, Loss: 0.00013424509961623698, Min w: 0.9182845950126648\n",
      "Iteration 290, Loss: 9.952951950253919e-05, Min w: 0.9485898017883301\n",
      "Iteration 300, Loss: 2.9349204851314425e-05, Min w: 0.981080949306488\n",
      "Iteration 310, Loss: 3.532519986038096e-05, Min w: 0.979223370552063\n",
      "Iteration 320, Loss: 3.1761941500008106e-05, Min w: 0.9815186262130737\n",
      "Iteration 330, Loss: 7.059532072162256e-05, Min w: 0.9493977427482605\n",
      "Iteration 340, Loss: 7.91113416198641e-05, Min w: 0.9377347230911255\n",
      "Iteration 350, Loss: 3.656802437035367e-05, Min w: 0.978995144367218\n",
      "Iteration 360, Loss: 0.00014326411474030465, Min w: 0.9097315073013306\n",
      "Iteration 370, Loss: 2.8849823138443753e-05, Min w: 0.9829947352409363\n",
      "Iteration 380, Loss: 3.667051350930706e-05, Min w: 0.9794087409973145\n",
      "Iteration 390, Loss: 4.8811398301040754e-05, Min w: 0.9698281288146973\n",
      "Iteration 400, Loss: 2.9919419830548577e-05, Min w: 0.9842237830162048\n",
      "Iteration 410, Loss: 3.489550726953894e-05, Min w: 0.9807451367378235\n",
      "Iteration 420, Loss: 4.0423343307338655e-05, Min w: 0.976608157157898\n",
      "Iteration 430, Loss: 3.890426523867063e-05, Min w: 0.9687681198120117\n",
      "Iteration 440, Loss: 4.8992151278071105e-05, Min w: 0.9674022793769836\n",
      "Iteration 450, Loss: 2.7346895876689814e-05, Min w: 0.9840388894081116\n",
      "Iteration 460, Loss: 3.095073043368757e-05, Min w: 0.9838321208953857\n",
      "Iteration 470, Loss: 7.262378494488075e-05, Min w: 0.9450395107269287\n",
      "Iteration 480, Loss: 5.6688368204049766e-05, Min w: 0.9680330753326416\n",
      "Iteration 490, Loss: 4.535356492851861e-05, Min w: 0.9687309861183167\n",
      "Iteration 500, Loss: 2.4683624360477552e-05, Min w: 0.9850475192070007\n",
      "Iteration 510, Loss: 2.5025194190675393e-05, Min w: 0.9855025410652161\n",
      "Iteration 520, Loss: 7.501355867134407e-05, Min w: 0.956246554851532\n",
      "Iteration 530, Loss: 0.00011242942855460569, Min w: 0.9392654299736023\n",
      "Iteration 540, Loss: 5.501850682776421e-05, Min w: 0.9646981358528137\n",
      "Iteration 550, Loss: 5.688047895091586e-05, Min w: 0.9636096358299255\n",
      "Iteration 560, Loss: 5.0436592573532835e-05, Min w: 0.9652335047721863\n",
      "Iteration 570, Loss: 0.00010742312588263303, Min w: 0.9162489175796509\n",
      "Iteration 580, Loss: 7.018573523964733e-05, Min w: 0.9583048820495605\n",
      "Iteration 590, Loss: 3.722853216459043e-05, Min w: 0.9736228585243225\n",
      "Iteration 600, Loss: 6.0314305301290005e-05, Min w: 0.9614365100860596\n",
      "Iteration 610, Loss: 3.3093765523517504e-05, Min w: 0.9773529767990112\n",
      "Iteration 620, Loss: 7.616474613314494e-05, Min w: 0.9437798261642456\n",
      "Iteration 630, Loss: 8.137807890307158e-05, Min w: 0.9386187195777893\n",
      "Iteration 640, Loss: 9.474735998082906e-05, Min w: 0.9481164216995239\n",
      "Iteration 650, Loss: 4.449019252206199e-05, Min w: 0.9707092642784119\n",
      "Iteration 660, Loss: 3.7373360100900754e-05, Min w: 0.9770296216011047\n",
      "Iteration 670, Loss: 6.000372741254978e-05, Min w: 0.9601351618766785\n",
      "Iteration 680, Loss: 0.00011669421655824408, Min w: 0.9108184576034546\n",
      "Iteration 690, Loss: 2.9714125048485585e-05, Min w: 0.9837177395820618\n",
      "Iteration 700, Loss: 8.954788791015744e-05, Min w: 0.9385759830474854\n",
      "Iteration 710, Loss: 0.0002592864912003279, Min w: 0.8433621525764465\n",
      "Iteration 720, Loss: 7.318890129681677e-05, Min w: 0.9623683094978333\n",
      "Iteration 730, Loss: 4.748958599520847e-05, Min w: 0.9691466689109802\n",
      "Iteration 740, Loss: 3.698353248182684e-05, Min w: 0.9804172515869141\n",
      "Iteration 750, Loss: 6.254584877751768e-05, Min w: 0.9499655961990356\n",
      "Iteration 760, Loss: 3.4956105082528666e-05, Min w: 0.9800822138786316\n",
      "Iteration 770, Loss: 6.795129593228921e-05, Min w: 0.9616942405700684\n",
      "Iteration 780, Loss: 4.715002796729095e-05, Min w: 0.9748595952987671\n",
      "Iteration 790, Loss: 3.2889078283915296e-05, Min w: 0.9819579720497131\n",
      "Iteration 800, Loss: 3.587880200939253e-05, Min w: 0.9784987568855286\n",
      "Iteration 810, Loss: 4.457323666429147e-05, Min w: 0.9744625687599182\n",
      "Iteration 820, Loss: 5.654615961248055e-05, Min w: 0.9648450613021851\n",
      "Iteration 830, Loss: 7.461104542016983e-05, Min w: 0.9528048038482666\n",
      "Iteration 840, Loss: 3.1373776437249035e-05, Min w: 0.9819883108139038\n",
      "Iteration 850, Loss: 2.698739626794122e-05, Min w: 0.9821680188179016\n",
      "Iteration 860, Loss: 2.2661819457425736e-05, Min w: 0.9842808842658997\n",
      "Iteration 870, Loss: 6.877827399875969e-05, Min w: 0.9527233839035034\n",
      "Iteration 880, Loss: 4.6775567170698196e-05, Min w: 0.9688523411750793\n",
      "Iteration 890, Loss: 5.980133937555365e-05, Min w: 0.9669713973999023\n",
      "Iteration 900, Loss: 4.89232552354224e-05, Min w: 0.9709610342979431\n",
      "Iteration 910, Loss: 5.485984365805052e-05, Min w: 0.9689167141914368\n",
      "Iteration 920, Loss: 3.7997484469087794e-05, Min w: 0.9796515703201294\n",
      "Iteration 930, Loss: 4.626049485523254e-05, Min w: 0.9758694171905518\n",
      "Iteration 940, Loss: 3.935694257961586e-05, Min w: 0.97616046667099\n",
      "Iteration 950, Loss: 7.652348722331226e-05, Min w: 0.9429817199707031\n",
      "Iteration 960, Loss: 0.00010592012404231355, Min w: 0.9425374269485474\n",
      "Iteration 970, Loss: 2.320036946912296e-05, Min w: 0.9866284728050232\n",
      "Iteration 980, Loss: 7.688503683311865e-05, Min w: 0.9455843567848206\n",
      "Iteration 990, Loss: 5.670847895089537e-05, Min w: 0.9686427116394043\n",
      "Iteration 1000, Loss: 2.7431236958364025e-05, Min w: 0.9855334758758545\n",
      "Iteration 1010, Loss: 2.5452733098063618e-05, Min w: 0.9858619570732117\n",
      "Iteration 1020, Loss: 2.7456024326966144e-05, Min w: 0.9829312562942505\n",
      "Iteration 1030, Loss: 9.827748726820573e-05, Min w: 0.9395676255226135\n",
      "Iteration 1040, Loss: 2.9681750675081275e-05, Min w: 0.984355092048645\n",
      "Iteration 1050, Loss: 7.995035412022844e-05, Min w: 0.9387187361717224\n",
      "Iteration 1060, Loss: 3.114826904493384e-05, Min w: 0.9802722334861755\n",
      "Iteration 1070, Loss: 3.4187527489848435e-05, Min w: 0.9791339039802551\n",
      "Iteration 1080, Loss: 2.3127784515963867e-05, Min w: 0.985329270362854\n",
      "Iteration 1090, Loss: 3.555187504389323e-05, Min w: 0.9774402976036072\n",
      "Iteration 1100, Loss: 6.782353739254177e-05, Min w: 0.9441825747489929\n",
      "Iteration 1110, Loss: 2.3980948753887787e-05, Min w: 0.9875572323799133\n",
      "Iteration 1120, Loss: 7.551043381681666e-05, Min w: 0.9464673399925232\n",
      "Iteration 1130, Loss: 8.676372090121731e-05, Min w: 0.9448493123054504\n",
      "Iteration 1140, Loss: 2.133173074980732e-05, Min w: 0.9848366379737854\n",
      "Iteration 1150, Loss: 3.0245661037042737e-05, Min w: 0.9809810519218445\n",
      "Iteration 1160, Loss: 2.7090145522379316e-05, Min w: 0.9835256934165955\n",
      "Iteration 1170, Loss: 2.5983994419220835e-05, Min w: 0.984563410282135\n",
      "Iteration 1180, Loss: 9.369807958137244e-05, Min w: 0.9430761933326721\n",
      "Iteration 1190, Loss: 4.798900772584602e-05, Min w: 0.968462347984314\n",
      "Iteration 1200, Loss: 2.625096203701105e-05, Min w: 0.9855731129646301\n",
      "Iteration 1210, Loss: 2.6476645871298388e-05, Min w: 0.9850789308547974\n",
      "Iteration 1220, Loss: 2.1762583855888806e-05, Min w: 0.9879921674728394\n",
      "Iteration 1230, Loss: 5.1867624279111624e-05, Min w: 0.9731032848358154\n",
      "Iteration 1240, Loss: 0.00012599884939845651, Min w: 0.9065870046615601\n",
      "Iteration 0, Loss: 3.654309330158867e-05, Min w: 0.9781420826911926\n",
      "Iteration 10, Loss: 0.00011780118802562356, Min w: 0.9308066368103027\n",
      "Iteration 20, Loss: 4.754502515424974e-05, Min w: 0.9696989059448242\n",
      "Iteration 30, Loss: 3.536717122187838e-05, Min w: 0.9758555889129639\n",
      "Iteration 40, Loss: 2.675666291906964e-05, Min w: 0.9815552234649658\n",
      "Iteration 50, Loss: 1.898964910651557e-05, Min w: 0.9888846278190613\n",
      "Iteration 60, Loss: 1.8855851521948352e-05, Min w: 0.9894930720329285\n",
      "Iteration 70, Loss: 9.390831110067666e-05, Min w: 0.9151254892349243\n",
      "Iteration 80, Loss: 3.071729952353053e-05, Min w: 0.9813096523284912\n",
      "Iteration 90, Loss: 1.9060498743783683e-05, Min w: 0.9896678328514099\n",
      "Iteration 100, Loss: 3.8462119846371934e-05, Min w: 0.9755951166152954\n",
      "Iteration 110, Loss: 2.0292918634368107e-05, Min w: 0.986532986164093\n",
      "Iteration 120, Loss: 2.5330286007374525e-05, Min w: 0.9846163392066956\n",
      "Iteration 130, Loss: 5.970104393782094e-05, Min w: 0.9523210525512695\n",
      "Iteration 140, Loss: 7.43459168006666e-05, Min w: 0.9512871503829956\n",
      "Iteration 150, Loss: 2.5980651116697118e-05, Min w: 0.9816222190856934\n",
      "Iteration 160, Loss: 3.870856380672194e-05, Min w: 0.9777843356132507\n",
      "Iteration 170, Loss: 6.15339376963675e-05, Min w: 0.9613419771194458\n",
      "Iteration 180, Loss: 3.4893524571089074e-05, Min w: 0.9762416481971741\n",
      "Iteration 190, Loss: 3.131300036329776e-05, Min w: 0.9834690690040588\n",
      "Iteration 200, Loss: 5.141636938787997e-05, Min w: 0.9680044054985046\n",
      "Iteration 210, Loss: 4.870273915003054e-05, Min w: 0.9646822810173035\n",
      "Iteration 220, Loss: 2.5737219402799383e-05, Min w: 0.9828090667724609\n",
      "Early break at iteration 221 --------------------------------\n",
      "Iteration 0, Loss: 2.6576892196317203e-05, Min w: 0.9802948236465454\n",
      "Iteration 10, Loss: 2.3245274860528298e-05, Min w: 0.9864023923873901\n",
      "Iteration 20, Loss: 2.9989869290147908e-05, Min w: 0.9836035370826721\n",
      "Iteration 30, Loss: 5.0214293878525496e-05, Min w: 0.9633904099464417\n",
      "Iteration 40, Loss: 7.235604425659403e-05, Min w: 0.9443157911300659\n",
      "Iteration 50, Loss: 5.2600367780542e-05, Min w: 0.9590818881988525\n",
      "Iteration 60, Loss: 2.8860407837782986e-05, Min w: 0.9827000498771667\n",
      "Iteration 70, Loss: 5.2476734708761796e-05, Min w: 0.972537100315094\n",
      "Iteration 80, Loss: 1.8962908143294044e-05, Min w: 0.9886455535888672\n",
      "Early break at iteration 89 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  88%|████████▊ | 21/24 [17:07<02:44, 54.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 4062, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.007685613680583821, 'L2_avg': 0.008761031361143196, 'End_point_L1_avg': 0.007164359143358854, 'End_point_L2_avg': 0.0074620322517567695}\n",
      "Iteration 0, Loss: 0.0050908783450722694, Min w: 0.008704579435288906\n",
      "Iteration 10, Loss: 0.0037066657096147537, Min w: 0.012435425072908401\n",
      "Iteration 20, Loss: 0.003526844084262848, Min w: 0.0001244733575731516\n",
      "Iteration 30, Loss: 0.002880645217373967, Min w: 2.6166345534761604e-08\n",
      "Iteration 40, Loss: 0.0025321405846625566, Min w: 3.853411319302447e-19\n",
      "Iteration 50, Loss: 0.0022496478632092476, Min w: 6.464189815930381e-42\n",
      "Iteration 60, Loss: 0.0021087212953716516, Min w: 0.0\n",
      "Iteration 70, Loss: 0.001975266495719552, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0018059139838442206, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0017280661268159747, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0019168829312548041, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0018544435733929276, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0014638908905908465, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0013106518890708685, Min w: 0.0\n",
      "Iteration 140, Loss: 0.001411002711392939, Min w: 6.489713380815547e-26\n",
      "Iteration 150, Loss: 0.0015220860950648785, Min w: 8.622156997262209e-07\n",
      "Iteration 160, Loss: 0.0012972140684723854, Min w: 2.2807090938048447e-10\n",
      "Iteration 170, Loss: 0.0013207924785092473, Min w: 0.00029818742768839\n",
      "Iteration 180, Loss: 0.0011701096082106233, Min w: 0.2378847748041153\n",
      "Iteration 190, Loss: 0.0012130440445616841, Min w: 0.21029286086559296\n",
      "Iteration 200, Loss: 0.0008702923078089952, Min w: 0.4047797918319702\n",
      "Iteration 210, Loss: 0.0009445524192415178, Min w: 0.4427318274974823\n",
      "Iteration 220, Loss: 0.0007323430036194623, Min w: 0.5132791996002197\n",
      "Iteration 230, Loss: 0.0006188290426507592, Min w: 0.6010433435440063\n",
      "Iteration 240, Loss: 0.0006121450569480658, Min w: 0.6245035529136658\n",
      "Iteration 250, Loss: 0.0005307865794748068, Min w: 0.6140419244766235\n",
      "Iteration 260, Loss: 0.0004736025584861636, Min w: 0.7194966673851013\n",
      "Iteration 270, Loss: 0.000507691060192883, Min w: 0.7337043285369873\n",
      "Iteration 280, Loss: 0.00042948132613673806, Min w: 0.7585014700889587\n",
      "Iteration 290, Loss: 0.0003685595584101975, Min w: 0.7582501173019409\n",
      "Iteration 300, Loss: 0.0006901560118421912, Min w: 0.5200815200805664\n",
      "Iteration 310, Loss: 0.00030254662851803005, Min w: 0.823043942451477\n",
      "Iteration 320, Loss: 0.0002529744815547019, Min w: 0.8661950826644897\n",
      "Iteration 330, Loss: 0.0007297630072571337, Min w: 0.6126570105552673\n",
      "Iteration 340, Loss: 0.0003307322331238538, Min w: 0.800906777381897\n",
      "Iteration 350, Loss: 0.0003881667216774076, Min w: 0.787238597869873\n",
      "Iteration 360, Loss: 0.0004587679577525705, Min w: 0.7424581050872803\n",
      "Iteration 370, Loss: 0.00028388435021042824, Min w: 0.8335602283477783\n",
      "Iteration 380, Loss: 0.00032884321990422904, Min w: 0.7910476326942444\n",
      "Iteration 390, Loss: 0.00032814996666274965, Min w: 0.8247077465057373\n",
      "Iteration 400, Loss: 0.00018896780966315418, Min w: 0.8897521495819092\n",
      "Iteration 410, Loss: 0.00036351787275634706, Min w: 0.7649436593055725\n",
      "Iteration 420, Loss: 0.000336655939463526, Min w: 0.8207491636276245\n",
      "Iteration 430, Loss: 0.00019165508274454623, Min w: 0.879658043384552\n",
      "Iteration 440, Loss: 0.00024124434276018292, Min w: 0.8372215032577515\n",
      "Iteration 450, Loss: 0.00023216662521008402, Min w: 0.8724986910820007\n",
      "Iteration 460, Loss: 0.00033495351090095937, Min w: 0.7947549819946289\n",
      "Iteration 470, Loss: 0.00014094931248109788, Min w: 0.9173855781555176\n",
      "Iteration 480, Loss: 0.00020692635735031217, Min w: 0.8924643397331238\n",
      "Iteration 490, Loss: 0.0002261898625874892, Min w: 0.824508547782898\n",
      "Iteration 500, Loss: 0.0001703343295957893, Min w: 0.8888212442398071\n",
      "Iteration 510, Loss: 0.00020211243827361614, Min w: 0.8715121746063232\n",
      "Iteration 520, Loss: 0.0003064089978579432, Min w: 0.8220635652542114\n",
      "Iteration 530, Loss: 0.00010282568837283179, Min w: 0.9443671107292175\n",
      "Iteration 540, Loss: 0.0001223557337652892, Min w: 0.9296575784683228\n",
      "Iteration 550, Loss: 0.00023323013738263398, Min w: 0.8664319515228271\n",
      "Iteration 560, Loss: 8.35624014143832e-05, Min w: 0.9538424611091614\n",
      "Iteration 570, Loss: 0.00014373967132996768, Min w: 0.9125186204910278\n",
      "Iteration 580, Loss: 0.00015419568808283657, Min w: 0.9153707027435303\n",
      "Iteration 590, Loss: 9.429323836229742e-05, Min w: 0.9445100426673889\n",
      "Iteration 600, Loss: 0.00012509521911852062, Min w: 0.9329943060874939\n",
      "Iteration 610, Loss: 0.0002573766396380961, Min w: 0.8572432398796082\n",
      "Iteration 620, Loss: 0.00010832204861799255, Min w: 0.9351264834403992\n",
      "Iteration 630, Loss: 0.00018971679673995823, Min w: 0.8487847447395325\n",
      "Iteration 640, Loss: 0.00021946767810732126, Min w: 0.8445014953613281\n",
      "Iteration 650, Loss: 6.142582424217835e-05, Min w: 0.9639716744422913\n",
      "Iteration 660, Loss: 0.00010933745943475515, Min w: 0.9283052682876587\n",
      "Iteration 670, Loss: 8.78400678629987e-05, Min w: 0.9541842937469482\n",
      "Iteration 680, Loss: 8.01539426902309e-05, Min w: 0.949445903301239\n",
      "Iteration 690, Loss: 0.00017625439795665443, Min w: 0.9032607674598694\n",
      "Iteration 700, Loss: 0.00015309535956475884, Min w: 0.8911957144737244\n",
      "Iteration 710, Loss: 0.0001529370347270742, Min w: 0.8809716701507568\n",
      "Iteration 720, Loss: 6.290389865171164e-05, Min w: 0.9623913764953613\n",
      "Iteration 730, Loss: 8.056221122387797e-05, Min w: 0.9488326907157898\n",
      "Iteration 740, Loss: 0.00010291754006175324, Min w: 0.9304666519165039\n",
      "Iteration 750, Loss: 0.00010210153413936496, Min w: 0.9399259090423584\n",
      "Iteration 760, Loss: 9.879357094177976e-05, Min w: 0.9300026297569275\n",
      "Iteration 770, Loss: 0.0001236322714248672, Min w: 0.91065913438797\n",
      "Iteration 780, Loss: 0.00020823077647946775, Min w: 0.8906822800636292\n",
      "Iteration 790, Loss: 5.688252713298425e-05, Min w: 0.9655081033706665\n",
      "Iteration 800, Loss: 8.647453068988398e-05, Min w: 0.9401142001152039\n",
      "Iteration 810, Loss: 0.0001536138152005151, Min w: 0.8700435757637024\n",
      "Iteration 820, Loss: 6.854750972706825e-05, Min w: 0.9593298435211182\n",
      "Iteration 830, Loss: 0.00017358700279146433, Min w: 0.8600960373878479\n",
      "Iteration 840, Loss: 4.1302439058199525e-05, Min w: 0.9766721129417419\n",
      "Iteration 850, Loss: 7.45653233025223e-05, Min w: 0.9522459506988525\n",
      "Iteration 860, Loss: 0.0001683801383478567, Min w: 0.8832400441169739\n",
      "Iteration 870, Loss: 0.00020344748918432742, Min w: 0.8915273547172546\n",
      "Iteration 880, Loss: 0.00010633432248141617, Min w: 0.9267391562461853\n",
      "Iteration 890, Loss: 0.0001682933361735195, Min w: 0.8637874722480774\n",
      "Iteration 900, Loss: 0.00011842756066471338, Min w: 0.9137836694717407\n",
      "Iteration 910, Loss: 7.645701407454908e-05, Min w: 0.9477283358573914\n",
      "Iteration 920, Loss: 8.620857988717034e-05, Min w: 0.9496520757675171\n",
      "Iteration 930, Loss: 6.559088069479913e-05, Min w: 0.959731936454773\n",
      "Iteration 940, Loss: 0.00027050927747040987, Min w: 0.8576884865760803\n",
      "Iteration 950, Loss: 0.00011955048830714077, Min w: 0.9199367165565491\n",
      "Iteration 960, Loss: 8.144368621287867e-05, Min w: 0.9574897885322571\n",
      "Iteration 970, Loss: 5.835506453877315e-05, Min w: 0.9700771570205688\n",
      "Iteration 980, Loss: 4.1804989450611174e-05, Min w: 0.9743158221244812\n",
      "Iteration 990, Loss: 0.00020737059821840376, Min w: 0.8366878628730774\n",
      "Iteration 1000, Loss: 7.862811617087573e-05, Min w: 0.9413177967071533\n",
      "Iteration 1010, Loss: 7.260761049110442e-05, Min w: 0.9504895806312561\n",
      "Iteration 1020, Loss: 0.00010427657252876088, Min w: 0.9142229557037354\n",
      "Iteration 1030, Loss: 5.429947850643657e-05, Min w: 0.9658142924308777\n",
      "Iteration 1040, Loss: 0.00011286151857348159, Min w: 0.9196937680244446\n",
      "Iteration 1050, Loss: 0.0001263131998712197, Min w: 0.9109651446342468\n",
      "Iteration 1060, Loss: 8.328074909513816e-05, Min w: 0.9487007856369019\n",
      "Iteration 1070, Loss: 5.6683864386286587e-05, Min w: 0.9630926251411438\n",
      "Iteration 1080, Loss: 0.00016818133008200675, Min w: 0.8851497769355774\n",
      "Iteration 1090, Loss: 0.00011230514064664021, Min w: 0.9031016230583191\n",
      "Iteration 1100, Loss: 8.930781768867746e-05, Min w: 0.9325618743896484\n",
      "Iteration 1110, Loss: 0.00014792743604630232, Min w: 0.9072579741477966\n",
      "Iteration 1120, Loss: 8.336012251675129e-05, Min w: 0.9463487267494202\n",
      "Iteration 1130, Loss: 9.151367703452706e-05, Min w: 0.9346475601196289\n",
      "Iteration 1140, Loss: 0.00015073265240062028, Min w: 0.919221818447113\n",
      "Iteration 1150, Loss: 0.00011109404294984415, Min w: 0.90909743309021\n",
      "Iteration 1160, Loss: 5.634616536553949e-05, Min w: 0.9572296738624573\n",
      "Iteration 1170, Loss: 4.136686402489431e-05, Min w: 0.9787717461585999\n",
      "Iteration 1180, Loss: 0.00013245448644738644, Min w: 0.925709068775177\n",
      "Iteration 1190, Loss: 5.699901157640852e-05, Min w: 0.9540702700614929\n",
      "Iteration 1200, Loss: 4.179603638476692e-05, Min w: 0.977025032043457\n",
      "Iteration 1210, Loss: 0.00019248182070441544, Min w: 0.8960383534431458\n",
      "Iteration 1220, Loss: 0.00010130681766895577, Min w: 0.9147116541862488\n",
      "Iteration 1230, Loss: 3.582677527447231e-05, Min w: 0.9798256158828735\n",
      "Iteration 1240, Loss: 0.00017479386588092893, Min w: 0.8820116519927979\n",
      "Iteration 0, Loss: 7.281229773070663e-05, Min w: 0.9393997192382812\n",
      "Iteration 10, Loss: 4.37246126239188e-05, Min w: 0.9754853248596191\n",
      "Iteration 20, Loss: 9.960751776816323e-05, Min w: 0.9249370098114014\n",
      "Iteration 30, Loss: 3.228579953429289e-05, Min w: 0.9815229177474976\n",
      "Iteration 40, Loss: 3.232758535887115e-05, Min w: 0.9814234972000122\n",
      "Iteration 50, Loss: 4.5407447032630444e-05, Min w: 0.9727529287338257\n",
      "Iteration 60, Loss: 0.0002760017232503742, Min w: 0.7815208435058594\n",
      "Iteration 70, Loss: 0.00023341694031842053, Min w: 0.8467286825180054\n",
      "Iteration 80, Loss: 6.990916153881699e-05, Min w: 0.9501834511756897\n",
      "Iteration 90, Loss: 6.441375444410369e-05, Min w: 0.9531689882278442\n",
      "Iteration 100, Loss: 4.890150739811361e-05, Min w: 0.9696183800697327\n",
      "Iteration 110, Loss: 4.0649229049449787e-05, Min w: 0.9772332310676575\n",
      "Iteration 120, Loss: 4.243643343215808e-05, Min w: 0.9729388952255249\n",
      "Iteration 130, Loss: 0.00011628445645328611, Min w: 0.8981848359107971\n",
      "Iteration 140, Loss: 4.61165836895816e-05, Min w: 0.9753568172454834\n",
      "Iteration 150, Loss: 4.589659511111677e-05, Min w: 0.9762036204338074\n",
      "Iteration 160, Loss: 6.543350900756195e-05, Min w: 0.9563089609146118\n",
      "Iteration 170, Loss: 7.030608685454354e-05, Min w: 0.9545473456382751\n",
      "Iteration 180, Loss: 2.691331428650301e-05, Min w: 0.9847260117530823\n",
      "Iteration 190, Loss: 3.436272527324036e-05, Min w: 0.9796625971794128\n",
      "Iteration 200, Loss: 0.000128533472889103, Min w: 0.905931293964386\n",
      "Iteration 210, Loss: 3.8628113543381914e-05, Min w: 0.9745584726333618\n",
      "Iteration 220, Loss: 3.57697244908195e-05, Min w: 0.9771587252616882\n",
      "Iteration 230, Loss: 9.098896407522261e-05, Min w: 0.9236035943031311\n",
      "Iteration 240, Loss: 0.00012829779007006437, Min w: 0.8922092914581299\n",
      "Iteration 250, Loss: 0.0001017810427583754, Min w: 0.9314348697662354\n",
      "Iteration 260, Loss: 3.0986673664301634e-05, Min w: 0.9832165837287903\n",
      "Iteration 270, Loss: 8.067488670349121e-05, Min w: 0.929652988910675\n",
      "Iteration 280, Loss: 0.00010436325828777626, Min w: 0.9143511652946472\n",
      "Iteration 290, Loss: 2.2976026230026037e-05, Min w: 0.9871149063110352\n",
      "Iteration 300, Loss: 0.00013281436986289918, Min w: 0.8884005546569824\n",
      "Iteration 310, Loss: 5.570651774178259e-05, Min w: 0.9607824683189392\n",
      "Iteration 320, Loss: 0.00011904653365490958, Min w: 0.9324884414672852\n",
      "Iteration 330, Loss: 5.2882078307447955e-05, Min w: 0.9617118835449219\n",
      "Iteration 340, Loss: 4.256009924574755e-05, Min w: 0.9708139896392822\n",
      "Iteration 350, Loss: 5.443316695163958e-05, Min w: 0.9688199162483215\n",
      "Iteration 360, Loss: 5.030717147747055e-05, Min w: 0.9641923308372498\n",
      "Iteration 370, Loss: 4.802365219802596e-05, Min w: 0.9742982387542725\n",
      "Iteration 380, Loss: 8.682810585014522e-05, Min w: 0.9310405850410461\n",
      "Iteration 390, Loss: 8.417618664680049e-05, Min w: 0.9509828090667725\n",
      "Iteration 400, Loss: 1.9770315702771768e-05, Min w: 0.9890502095222473\n",
      "Iteration 410, Loss: 9.111752297030762e-05, Min w: 0.9275072813034058\n",
      "Iteration 420, Loss: 8.244308264693245e-05, Min w: 0.9433922171592712\n",
      "Iteration 430, Loss: 2.3466562197427265e-05, Min w: 0.9874677062034607\n",
      "Early break at iteration 431 --------------------------------\n",
      "Iteration 0, Loss: 2.087445682263933e-05, Min w: 0.9878242015838623\n",
      "Iteration 10, Loss: 7.712092337897047e-05, Min w: 0.9522419571876526\n",
      "Iteration 20, Loss: 4.1239520214730874e-05, Min w: 0.9742355346679688\n",
      "Iteration 30, Loss: 5.3803742048330605e-05, Min w: 0.9584859609603882\n",
      "Early break at iteration 36 --------------------------------\n",
      "Iteration 0, Loss: 2.2072614228818566e-05, Min w: 0.9876080751419067\n",
      "Iteration 10, Loss: 0.0001009054176392965, Min w: 0.9084442853927612\n",
      "Iteration 20, Loss: 7.496513717342168e-05, Min w: 0.961185872554779\n",
      "Iteration 30, Loss: 6.959048914723098e-05, Min w: 0.9506911635398865\n",
      "Iteration 40, Loss: 7.42659904062748e-05, Min w: 0.93333500623703\n",
      "Iteration 50, Loss: 0.00010395905701443553, Min w: 0.913876473903656\n",
      "Iteration 60, Loss: 0.0001058286361512728, Min w: 0.9178212285041809\n",
      "Iteration 70, Loss: 8.474888454657048e-05, Min w: 0.9525647759437561\n",
      "Iteration 80, Loss: 2.8248208764125593e-05, Min w: 0.9829664826393127\n",
      "Early break at iteration 81 --------------------------------\n",
      "Iteration 0, Loss: 1.978371074073948e-05, Min w: 0.9863779544830322\n",
      "Iteration 10, Loss: 8.913507190300152e-05, Min w: 0.9507338404655457\n",
      "Iteration 20, Loss: 0.00011635530972853303, Min w: 0.9362528324127197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  92%|█████████▏| 22/24 [17:27<01:28, 44.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.00016688034520484507, Min w: 0.8820842504501343\n",
      "Iteration 40, Loss: 3.701450987136923e-05, Min w: 0.9739022254943848\n",
      "Early break at iteration 42 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 1844, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.009209067614102399, 'L2_avg': 0.011667557293180753, 'End_point_L1_avg': 0.002981553292072407, 'End_point_L2_avg': 0.002994967230537184}\n",
      "Iteration 0, Loss: 0.0013641067780554295, Min w: 1.310584168435629e-16\n",
      "Iteration 10, Loss: 0.0012376329395920038, Min w: 7.758401920909819e-08\n",
      "Iteration 20, Loss: 0.0011114152148365974, Min w: 0.0022816951386630535\n",
      "Iteration 30, Loss: 0.001110415905714035, Min w: 8.330012894741667e-12\n",
      "Iteration 40, Loss: 0.0008509015315212309, Min w: 1.533099691641837e-08\n",
      "Iteration 50, Loss: 0.0008284111972898245, Min w: 1.7413144510976296e-18\n",
      "Iteration 60, Loss: 0.0007459475891664624, Min w: 4.9509319539364445e-36\n",
      "Iteration 70, Loss: 0.0006690964219160378, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0006147108506411314, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0005728385876864195, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0005480244872160256, Min w: 0.0\n",
      "Iteration 110, Loss: 0.0005296717863529921, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0005114770610816777, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0004948123241774738, Min w: 0.0\n",
      "Iteration 140, Loss: 0.0005131851066835225, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0004587949370034039, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0004731388471554965, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0004576403589453548, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0004095402255188674, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0004210284387227148, Min w: 0.0\n",
      "Iteration 200, Loss: 0.00041378289461135864, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0003720224485732615, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0004417606396600604, Min w: 0.0\n",
      "Iteration 230, Loss: 0.000455226021585986, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0003934986307285726, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0003476533747743815, Min w: 6.813083489602777e-25\n",
      "Iteration 260, Loss: 0.00047366388025693595, Min w: 3.5584957913670223e-07\n",
      "Iteration 270, Loss: 0.0003945504722651094, Min w: 8.22709559105176e-38\n",
      "Iteration 280, Loss: 0.0004395511350594461, Min w: 1.0325469177108759e-22\n",
      "Iteration 290, Loss: 0.00045832348405383527, Min w: 3.1077522367730032e-15\n",
      "Iteration 300, Loss: 0.00042609989759512246, Min w: 0.0005501550040207803\n",
      "Iteration 310, Loss: 0.00030915436218492687, Min w: 0.1359056979417801\n",
      "Iteration 320, Loss: 0.0003539752506185323, Min w: 0.15635858476161957\n",
      "Iteration 330, Loss: 0.00032617757096886635, Min w: 0.1770291030406952\n",
      "Iteration 340, Loss: 0.00025757343973964453, Min w: 0.2695356011390686\n",
      "Iteration 350, Loss: 0.00035736168501898646, Min w: 0.15962739288806915\n",
      "Iteration 360, Loss: 0.00023381139908451587, Min w: 0.3526609539985657\n",
      "Iteration 370, Loss: 0.00032752324477769434, Min w: 0.35908985137939453\n",
      "Iteration 380, Loss: 0.0003328643215354532, Min w: 0.2807570993900299\n",
      "Iteration 390, Loss: 0.00021169563115108758, Min w: 0.4133515954017639\n",
      "Iteration 400, Loss: 0.0003148501564282924, Min w: 0.37148746848106384\n",
      "Iteration 410, Loss: 0.0003993834543507546, Min w: 0.13537856936454773\n",
      "Iteration 420, Loss: 0.0004427818930707872, Min w: 0.014439569786190987\n",
      "Iteration 430, Loss: 0.0005054337088949978, Min w: 5.437743896656577e-13\n",
      "Iteration 440, Loss: 0.0005059732357040048, Min w: 3.0261858756281703e-16\n",
      "Iteration 450, Loss: 0.0003768261522054672, Min w: 0.05755649134516716\n",
      "Iteration 460, Loss: 0.00030057213734835386, Min w: 0.24143290519714355\n",
      "Iteration 470, Loss: 0.00025451238616369665, Min w: 0.42171356081962585\n",
      "Iteration 480, Loss: 0.0002005297428695485, Min w: 0.4412217438220978\n",
      "Iteration 490, Loss: 0.00018892125808633864, Min w: 0.5162466168403625\n",
      "Iteration 500, Loss: 0.0002027633017860353, Min w: 0.5332769155502319\n",
      "Iteration 510, Loss: 0.00022689990873914212, Min w: 0.5519364476203918\n",
      "Iteration 520, Loss: 0.00021434399241115898, Min w: 0.5363107919692993\n",
      "Iteration 530, Loss: 0.00025203608674928546, Min w: 0.4108794033527374\n",
      "Iteration 540, Loss: 0.0001903455558931455, Min w: 0.5619924068450928\n",
      "Iteration 550, Loss: 0.00022782424639444798, Min w: 0.43665918707847595\n",
      "Iteration 560, Loss: 0.00018023370648734272, Min w: 0.5932524800300598\n",
      "Iteration 570, Loss: 0.00020666877389885485, Min w: 0.5493877530097961\n",
      "Iteration 580, Loss: 0.00021582641056738794, Min w: 0.4672524929046631\n",
      "Iteration 590, Loss: 0.00017193164967466146, Min w: 0.5725792050361633\n",
      "Iteration 600, Loss: 0.0001992988254642114, Min w: 0.5189231038093567\n",
      "Iteration 610, Loss: 0.00020929156744387, Min w: 0.4701485335826874\n",
      "Iteration 620, Loss: 0.00017797897453419864, Min w: 0.6021244525909424\n",
      "Iteration 630, Loss: 0.00012604350922629237, Min w: 0.6946825385093689\n",
      "Iteration 640, Loss: 0.00030164289637468755, Min w: 0.37390050292015076\n",
      "Iteration 650, Loss: 0.00025707538588903844, Min w: 0.34800490736961365\n",
      "Iteration 660, Loss: 0.00043215404730290174, Min w: 0.00057115318486467\n",
      "Iteration 670, Loss: 0.00041648995829746127, Min w: 0.03331536054611206\n",
      "Iteration 680, Loss: 0.00039515766547992826, Min w: 0.06011627987027168\n",
      "Iteration 690, Loss: 0.00048755272291600704, Min w: 0.01999642699956894\n",
      "Iteration 700, Loss: 0.00036023621214553714, Min w: 0.1416434347629547\n",
      "Iteration 710, Loss: 0.00021163825294934213, Min w: 0.36315006017684937\n",
      "Iteration 720, Loss: 0.00017276311700697988, Min w: 0.497799813747406\n",
      "Iteration 730, Loss: 0.00013668558676727116, Min w: 0.6195346117019653\n",
      "Iteration 740, Loss: 0.00012718778452835977, Min w: 0.6560564041137695\n",
      "Iteration 750, Loss: 0.0001201378254336305, Min w: 0.6714156866073608\n",
      "Iteration 760, Loss: 0.00011407517740735784, Min w: 0.6934210062026978\n",
      "Iteration 770, Loss: 0.0001337456051260233, Min w: 0.670497477054596\n",
      "Iteration 780, Loss: 0.0001232076610904187, Min w: 0.6897479295730591\n",
      "Iteration 790, Loss: 0.0001593227789271623, Min w: 0.6472339034080505\n",
      "Iteration 800, Loss: 0.00014747325622010976, Min w: 0.6539437770843506\n",
      "Iteration 810, Loss: 0.00016786546621005982, Min w: 0.6040306091308594\n",
      "Iteration 820, Loss: 0.00014292907144408673, Min w: 0.7080087661743164\n",
      "Iteration 830, Loss: 0.00016080605564638972, Min w: 0.6275184750556946\n",
      "Iteration 840, Loss: 0.00014606802142225206, Min w: 0.6684446930885315\n",
      "Iteration 850, Loss: 0.0001394151768181473, Min w: 0.6799324154853821\n",
      "Iteration 860, Loss: 0.00015652735601179302, Min w: 0.6352269053459167\n",
      "Iteration 870, Loss: 0.0001311885134782642, Min w: 0.709980845451355\n",
      "Iteration 880, Loss: 0.0001350828242721036, Min w: 0.6866118311882019\n",
      "Iteration 890, Loss: 0.0001453537552151829, Min w: 0.6749248504638672\n",
      "Iteration 900, Loss: 0.00010869187826756388, Min w: 0.7703381180763245\n",
      "Iteration 910, Loss: 0.0001361193717457354, Min w: 0.708572506904602\n",
      "Iteration 920, Loss: 0.0001508761924924329, Min w: 0.6268473863601685\n",
      "Iteration 930, Loss: 9.322729601990432e-05, Min w: 0.7723513841629028\n",
      "Iteration 940, Loss: 0.00011922732664970681, Min w: 0.7577787041664124\n",
      "Iteration 950, Loss: 0.0001555572380311787, Min w: 0.5858588814735413\n",
      "Iteration 960, Loss: 0.0001213231444125995, Min w: 0.6749369502067566\n",
      "Iteration 970, Loss: 0.00011292434646748006, Min w: 0.7340048551559448\n",
      "Iteration 980, Loss: 8.416148193646222e-05, Min w: 0.8240851759910583\n",
      "Iteration 990, Loss: 0.00012208244879730046, Min w: 0.6502628326416016\n",
      "Iteration 1000, Loss: 9.312979091191664e-05, Min w: 0.776276171207428\n",
      "Iteration 1010, Loss: 0.00010061317880172282, Min w: 0.7549572587013245\n",
      "Iteration 1020, Loss: 0.00010421618208056316, Min w: 0.7794821262359619\n",
      "Iteration 1030, Loss: 9.975525608751923e-05, Min w: 0.7516038417816162\n",
      "Iteration 1040, Loss: 0.0001323167234659195, Min w: 0.6498752236366272\n",
      "Iteration 1050, Loss: 0.00014376183389686048, Min w: 0.6471177935600281\n",
      "Iteration 1060, Loss: 0.00016474562289658934, Min w: 0.6356438398361206\n",
      "Iteration 1070, Loss: 5.9990386944264174e-05, Min w: 0.8579892516136169\n",
      "Iteration 1080, Loss: 0.00011175631516380236, Min w: 0.6793960928916931\n",
      "Iteration 1090, Loss: 7.00710661476478e-05, Min w: 0.8350123763084412\n",
      "Iteration 1100, Loss: 6.0647034842986614e-05, Min w: 0.8637624382972717\n",
      "Iteration 1110, Loss: 9.523485641693696e-05, Min w: 0.7556071281433105\n",
      "Iteration 1120, Loss: 9.309482265962288e-05, Min w: 0.800639271736145\n",
      "Iteration 1130, Loss: 0.00012140613398514688, Min w: 0.6650134921073914\n",
      "Iteration 1140, Loss: 0.00012864450400229543, Min w: 0.7074663639068604\n",
      "Iteration 1150, Loss: 5.5678556236671284e-05, Min w: 0.8763723969459534\n",
      "Iteration 1160, Loss: 9.489025978837162e-05, Min w: 0.7500775456428528\n",
      "Iteration 1170, Loss: 0.0001242938742507249, Min w: 0.6600401997566223\n",
      "Iteration 1180, Loss: 7.340715092141181e-05, Min w: 0.8114645481109619\n",
      "Iteration 1190, Loss: 6.971193943172693e-05, Min w: 0.8431225419044495\n",
      "Iteration 1200, Loss: 9.698612120701e-05, Min w: 0.7510604858398438\n",
      "Iteration 1210, Loss: 9.994228457799181e-05, Min w: 0.7175253033638\n",
      "Iteration 1220, Loss: 7.836896111257374e-05, Min w: 0.7958604097366333\n",
      "Iteration 1230, Loss: 9.688972204457968e-05, Min w: 0.7827216386795044\n",
      "Iteration 1240, Loss: 8.09306584415026e-05, Min w: 0.7950109839439392\n",
      "Iteration 0, Loss: 6.743080302840099e-05, Min w: 0.8247196674346924\n",
      "Iteration 10, Loss: 6.348402530420572e-05, Min w: 0.8155431747436523\n",
      "Iteration 20, Loss: 9.60365214268677e-05, Min w: 0.746553897857666\n",
      "Iteration 30, Loss: 0.0001239882258232683, Min w: 0.7183985114097595\n",
      "Iteration 40, Loss: 0.00013044399383943528, Min w: 0.6483979821205139\n",
      "Iteration 50, Loss: 7.482097862521186e-05, Min w: 0.7861159443855286\n",
      "Iteration 60, Loss: 9.793275967240334e-05, Min w: 0.7860954999923706\n",
      "Iteration 70, Loss: 9.41236867220141e-05, Min w: 0.798039436340332\n",
      "Iteration 80, Loss: 9.088970546144992e-05, Min w: 0.7678167819976807\n",
      "Iteration 90, Loss: 0.00010425787331769243, Min w: 0.7305983901023865\n",
      "Iteration 100, Loss: 6.027002746122889e-05, Min w: 0.8564097881317139\n",
      "Iteration 110, Loss: 8.581839938415214e-05, Min w: 0.8194940686225891\n",
      "Iteration 120, Loss: 8.880851964931935e-05, Min w: 0.7700576782226562\n",
      "Iteration 130, Loss: 7.041233766358346e-05, Min w: 0.8529478907585144\n",
      "Iteration 140, Loss: 9.47776497923769e-05, Min w: 0.7793858647346497\n",
      "Iteration 150, Loss: 8.964371227193624e-05, Min w: 0.7333692312240601\n",
      "Iteration 160, Loss: 9.667820268077776e-05, Min w: 0.7232925891876221\n",
      "Iteration 170, Loss: 7.899342745076865e-05, Min w: 0.7655563354492188\n",
      "Iteration 180, Loss: 9.418034460395575e-05, Min w: 0.7488452792167664\n",
      "Iteration 190, Loss: 3.533239578246139e-05, Min w: 0.9126713275909424\n",
      "Iteration 200, Loss: 9.838469850365072e-05, Min w: 0.7882217168807983\n",
      "Iteration 210, Loss: 7.932190055726096e-05, Min w: 0.8138364553451538\n",
      "Iteration 220, Loss: 0.00011390945292077959, Min w: 0.7440317273139954\n",
      "Iteration 230, Loss: 9.052275709109381e-05, Min w: 0.8021814823150635\n",
      "Iteration 240, Loss: 8.427673310507089e-05, Min w: 0.7791616320610046\n",
      "Iteration 250, Loss: 8.05020536063239e-05, Min w: 0.7886874079704285\n",
      "Iteration 260, Loss: 7.732881931588054e-05, Min w: 0.7696854472160339\n",
      "Iteration 270, Loss: 6.012350058881566e-05, Min w: 0.8381140232086182\n",
      "Iteration 280, Loss: 6.842661241535097e-05, Min w: 0.8342289924621582\n",
      "Iteration 290, Loss: 8.711251575732604e-05, Min w: 0.7910012006759644\n",
      "Iteration 300, Loss: 8.127259206958115e-05, Min w: 0.7853105664253235\n",
      "Iteration 310, Loss: 6.435775139834732e-05, Min w: 0.8104475140571594\n",
      "Iteration 320, Loss: 6.030259100953117e-05, Min w: 0.8450075387954712\n",
      "Iteration 330, Loss: 7.332696986850351e-05, Min w: 0.8314966559410095\n",
      "Iteration 340, Loss: 5.744335794588551e-05, Min w: 0.8775359392166138\n",
      "Iteration 350, Loss: 5.998822962283157e-05, Min w: 0.8563463091850281\n",
      "Iteration 360, Loss: 7.131359598133713e-05, Min w: 0.8271531462669373\n",
      "Iteration 370, Loss: 6.927278445800766e-05, Min w: 0.8178021907806396\n",
      "Iteration 380, Loss: 6.972336996113881e-05, Min w: 0.8555096983909607\n",
      "Iteration 390, Loss: 5.8504789194557816e-05, Min w: 0.8405289649963379\n",
      "Iteration 400, Loss: 4.8501235141884536e-05, Min w: 0.8656406998634338\n",
      "Iteration 410, Loss: 2.9183582228142768e-05, Min w: 0.9353747367858887\n",
      "Iteration 420, Loss: 2.7159325327374972e-05, Min w: 0.9364790320396423\n",
      "Iteration 430, Loss: 9.323198901256546e-05, Min w: 0.808823823928833\n",
      "Iteration 440, Loss: 7.206260488601401e-05, Min w: 0.8206828832626343\n",
      "Iteration 450, Loss: 7.251009810715914e-05, Min w: 0.7751603722572327\n",
      "Iteration 460, Loss: 9.328175656264648e-05, Min w: 0.7541723847389221\n",
      "Iteration 470, Loss: 5.6833323469618335e-05, Min w: 0.878868043422699\n",
      "Iteration 480, Loss: 3.799000842263922e-05, Min w: 0.9185537695884705\n",
      "Iteration 490, Loss: 7.762497261865065e-05, Min w: 0.7866749167442322\n",
      "Iteration 500, Loss: 8.538035035599023e-05, Min w: 0.7433929443359375\n",
      "Iteration 510, Loss: 8.460136450594291e-05, Min w: 0.7660738229751587\n",
      "Iteration 520, Loss: 6.23472296865657e-05, Min w: 0.8135199546813965\n",
      "Iteration 530, Loss: 5.938770482316613e-05, Min w: 0.8067602515220642\n",
      "Iteration 540, Loss: 6.544293864862993e-05, Min w: 0.7915827035903931\n",
      "Iteration 550, Loss: 5.866015999345109e-05, Min w: 0.8221112489700317\n",
      "Iteration 560, Loss: 5.326174505171366e-05, Min w: 0.8605896234512329\n",
      "Iteration 570, Loss: 7.157534855650738e-05, Min w: 0.8430677652359009\n",
      "Iteration 580, Loss: 6.0717145970556885e-05, Min w: 0.8191904425621033\n",
      "Iteration 590, Loss: 5.2587391110137105e-05, Min w: 0.838618814945221\n",
      "Iteration 600, Loss: 5.6895845773397014e-05, Min w: 0.8575875759124756\n",
      "Iteration 610, Loss: 4.33447421528399e-05, Min w: 0.8893688917160034\n",
      "Iteration 620, Loss: 7.494171586586162e-05, Min w: 0.7999092936515808\n",
      "Iteration 630, Loss: 5.4130927310325205e-05, Min w: 0.8303370475769043\n",
      "Iteration 640, Loss: 6.164071965031326e-05, Min w: 0.8009437322616577\n",
      "Iteration 650, Loss: 6.612547440454364e-05, Min w: 0.8008043169975281\n",
      "Iteration 660, Loss: 6.128774111857638e-05, Min w: 0.8029400110244751\n",
      "Iteration 670, Loss: 2.0383758965181187e-05, Min w: 0.9533835649490356\n",
      "Iteration 680, Loss: 5.647343277814798e-05, Min w: 0.8449071645736694\n",
      "Iteration 690, Loss: 8.900425746105611e-05, Min w: 0.7552535533905029\n",
      "Iteration 700, Loss: 7.398751768050715e-05, Min w: 0.7568626999855042\n",
      "Iteration 710, Loss: 6.023382593411952e-05, Min w: 0.8117865324020386\n",
      "Iteration 720, Loss: 4.883810106548481e-05, Min w: 0.8669165372848511\n",
      "Iteration 730, Loss: 5.685930955223739e-05, Min w: 0.8455156683921814\n",
      "Iteration 740, Loss: 5.969270205241628e-05, Min w: 0.8154173493385315\n",
      "Iteration 750, Loss: 3.838092743535526e-05, Min w: 0.8900724649429321\n",
      "Iteration 760, Loss: 4.248163168085739e-05, Min w: 0.9118881225585938\n",
      "Iteration 770, Loss: 4.523556344793178e-05, Min w: 0.8730999231338501\n",
      "Iteration 780, Loss: 6.0931299231015146e-05, Min w: 0.855134904384613\n",
      "Iteration 790, Loss: 3.961801849072799e-05, Min w: 0.882182240486145\n",
      "Iteration 800, Loss: 5.578796844929457e-05, Min w: 0.8602874279022217\n",
      "Iteration 810, Loss: 3.123557326034643e-05, Min w: 0.922153115272522\n",
      "Iteration 820, Loss: 4.432342029758729e-05, Min w: 0.8921723961830139\n",
      "Iteration 830, Loss: 7.354650006163865e-05, Min w: 0.8318290710449219\n",
      "Iteration 840, Loss: 3.95941169699654e-05, Min w: 0.9060869216918945\n",
      "Iteration 850, Loss: 3.3455151424277574e-05, Min w: 0.9214330315589905\n",
      "Iteration 860, Loss: 5.203178443480283e-05, Min w: 0.884450376033783\n",
      "Iteration 870, Loss: 5.6868211686378345e-05, Min w: 0.8173258304595947\n",
      "Iteration 880, Loss: 4.440417978912592e-05, Min w: 0.8675470948219299\n",
      "Iteration 890, Loss: 3.020415169885382e-05, Min w: 0.9220200777053833\n",
      "Iteration 900, Loss: 6.155532173579559e-05, Min w: 0.8558142781257629\n",
      "Iteration 910, Loss: 3.7041907489765435e-05, Min w: 0.9164861440658569\n",
      "Iteration 920, Loss: 4.2970303184119985e-05, Min w: 0.8721394538879395\n",
      "Iteration 930, Loss: 5.093778599984944e-05, Min w: 0.843371570110321\n",
      "Iteration 940, Loss: 5.2716295613208786e-05, Min w: 0.8788499236106873\n",
      "Iteration 950, Loss: 5.477501326822676e-05, Min w: 0.8329458236694336\n",
      "Iteration 960, Loss: 2.4121245587593876e-05, Min w: 0.9372109770774841\n",
      "Iteration 970, Loss: 3.5362434573471546e-05, Min w: 0.8929822444915771\n",
      "Iteration 980, Loss: 4.340569648775272e-05, Min w: 0.8951276540756226\n",
      "Iteration 990, Loss: 5.23922972206492e-05, Min w: 0.8446741104125977\n",
      "Iteration 1000, Loss: 5.606985359918326e-05, Min w: 0.8481798768043518\n",
      "Iteration 1010, Loss: 1.961969246622175e-05, Min w: 0.9563735127449036\n",
      "Iteration 1020, Loss: 4.288713898858987e-05, Min w: 0.871068000793457\n",
      "Iteration 1030, Loss: 3.241106605855748e-05, Min w: 0.8992928266525269\n",
      "Iteration 1040, Loss: 4.77238827443216e-05, Min w: 0.8783032298088074\n",
      "Iteration 1050, Loss: 5.988851626170799e-05, Min w: 0.8009064793586731\n",
      "Iteration 1060, Loss: 4.3928928789682686e-05, Min w: 0.8798763155937195\n",
      "Iteration 1070, Loss: 5.580651486525312e-05, Min w: 0.8349215388298035\n",
      "Iteration 1080, Loss: 3.965962241636589e-05, Min w: 0.8965519666671753\n",
      "Iteration 1090, Loss: 6.275341002037749e-05, Min w: 0.8452028632164001\n",
      "Iteration 1100, Loss: 4.835010622628033e-05, Min w: 0.8512215614318848\n",
      "Iteration 1110, Loss: 2.1618592654704116e-05, Min w: 0.946818470954895\n",
      "Iteration 1120, Loss: 5.538627374335192e-05, Min w: 0.8499726057052612\n",
      "Iteration 1130, Loss: 1.4217190255294554e-05, Min w: 0.9681000709533691\n",
      "Iteration 1140, Loss: 5.840547601110302e-05, Min w: 0.834982693195343\n",
      "Iteration 1150, Loss: 6.275263876887038e-05, Min w: 0.8020346164703369\n",
      "Iteration 1160, Loss: 2.5867395379464142e-05, Min w: 0.9304749965667725\n",
      "Iteration 1170, Loss: 5.2064475312363356e-05, Min w: 0.8927251100540161\n",
      "Iteration 1180, Loss: 4.581829853123054e-05, Min w: 0.885494589805603\n",
      "Iteration 1190, Loss: 4.0294398786500096e-05, Min w: 0.8730964064598083\n",
      "Iteration 1200, Loss: 3.2718908187234774e-05, Min w: 0.927304208278656\n",
      "Iteration 1210, Loss: 4.2133873648708686e-05, Min w: 0.9092435836791992\n",
      "Iteration 1220, Loss: 6.728077278239653e-05, Min w: 0.8052423000335693\n",
      "Iteration 1230, Loss: 7.939424540381879e-05, Min w: 0.8052549958229065\n",
      "Iteration 1240, Loss: 2.0356470486149192e-05, Min w: 0.9505429863929749\n",
      "Iteration 0, Loss: 4.52790227427613e-05, Min w: 0.8865294456481934\n",
      "Iteration 10, Loss: 3.368163379491307e-05, Min w: 0.9209972620010376\n",
      "Iteration 20, Loss: 5.047826925874688e-05, Min w: 0.848799467086792\n",
      "Iteration 30, Loss: 4.567071664496325e-05, Min w: 0.8587785363197327\n",
      "Iteration 40, Loss: 5.221473838901147e-05, Min w: 0.831457793712616\n",
      "Iteration 50, Loss: 8.758409239817411e-05, Min w: 0.7863637208938599\n",
      "Iteration 60, Loss: 3.690136145451106e-05, Min w: 0.9149401783943176\n",
      "Iteration 70, Loss: 7.149772136472166e-05, Min w: 0.8156506419181824\n",
      "Iteration 80, Loss: 2.4381317416555248e-05, Min w: 0.9496045112609863\n",
      "Iteration 90, Loss: 1.9248391254222952e-05, Min w: 0.9500440359115601\n",
      "Iteration 100, Loss: 2.8751335776178166e-05, Min w: 0.9249425530433655\n",
      "Iteration 110, Loss: 2.6274296033079736e-05, Min w: 0.9243748784065247\n",
      "Iteration 120, Loss: 6.602777284570038e-05, Min w: 0.7838110327720642\n",
      "Iteration 130, Loss: 3.914436820195988e-05, Min w: 0.9193310737609863\n",
      "Iteration 140, Loss: 2.8841210223617963e-05, Min w: 0.9150869846343994\n",
      "Iteration 150, Loss: 4.3352538341423497e-05, Min w: 0.8942915201187134\n",
      "Iteration 160, Loss: 3.987780655734241e-05, Min w: 0.8865877985954285\n",
      "Iteration 170, Loss: 5.421909372671507e-05, Min w: 0.8887466192245483\n",
      "Iteration 180, Loss: 4.123547114431858e-05, Min w: 0.8654153347015381\n",
      "Iteration 190, Loss: 4.2767333070514724e-05, Min w: 0.9089341163635254\n",
      "Iteration 200, Loss: 2.9307508157216944e-05, Min w: 0.9170773029327393\n",
      "Iteration 210, Loss: 4.91964710818138e-05, Min w: 0.8797205686569214\n",
      "Iteration 220, Loss: 4.690175410360098e-05, Min w: 0.881371796131134\n",
      "Iteration 230, Loss: 3.801953062065877e-05, Min w: 0.8888316750526428\n",
      "Iteration 240, Loss: 2.811076774378307e-05, Min w: 0.9111307859420776\n",
      "Iteration 250, Loss: 3.345216464367695e-05, Min w: 0.8984163403511047\n",
      "Iteration 260, Loss: 1.201772283820901e-05, Min w: 0.9734249711036682\n",
      "Iteration 270, Loss: 7.346339407376945e-05, Min w: 0.7710055708885193\n",
      "Iteration 280, Loss: 9.59783501457423e-05, Min w: 0.7854715585708618\n",
      "Iteration 290, Loss: 0.00011071970220655203, Min w: 0.7206016182899475\n",
      "Iteration 300, Loss: 8.375700417673215e-05, Min w: 0.809731662273407\n",
      "Iteration 310, Loss: 6.443206802941859e-05, Min w: 0.8115042448043823\n",
      "Iteration 320, Loss: 3.378537076059729e-05, Min w: 0.9248343110084534\n",
      "Iteration 330, Loss: 1.8404709408059716e-05, Min w: 0.9500516653060913\n",
      "Iteration 340, Loss: 1.8308317521587014e-05, Min w: 0.9620753526687622\n",
      "Iteration 350, Loss: 2.3766790036461316e-05, Min w: 0.9338614344596863\n",
      "Iteration 360, Loss: 4.1159786633215845e-05, Min w: 0.8729032278060913\n",
      "Iteration 370, Loss: 5.614780093310401e-05, Min w: 0.8239894509315491\n",
      "Iteration 380, Loss: 3.2514184567844495e-05, Min w: 0.9009050726890564\n",
      "Iteration 390, Loss: 3.784446744248271e-05, Min w: 0.8968340158462524\n",
      "Iteration 400, Loss: 3.89485212508589e-05, Min w: 0.8973684906959534\n",
      "Iteration 410, Loss: 2.1415555238490924e-05, Min w: 0.942481279373169\n",
      "Iteration 420, Loss: 1.702099689282477e-05, Min w: 0.9624728560447693\n",
      "Iteration 430, Loss: 4.344197441241704e-05, Min w: 0.8558183908462524\n",
      "Iteration 440, Loss: 4.3735315557569265e-05, Min w: 0.900698721408844\n",
      "Iteration 450, Loss: 5.202536340220831e-05, Min w: 0.8340193629264832\n",
      "Iteration 460, Loss: 6.432104419218376e-05, Min w: 0.8233305811882019\n",
      "Iteration 470, Loss: 6.7470311478246e-05, Min w: 0.8325915336608887\n",
      "Iteration 480, Loss: 5.8403940784046426e-05, Min w: 0.8213285803794861\n",
      "Iteration 490, Loss: 6.261626549530774e-05, Min w: 0.7920501232147217\n",
      "Iteration 500, Loss: 6.343339191516861e-05, Min w: 0.7871555089950562\n",
      "Iteration 510, Loss: 2.521439819247462e-05, Min w: 0.9483271837234497\n",
      "Iteration 520, Loss: 3.686786658363417e-05, Min w: 0.9238402247428894\n",
      "Iteration 530, Loss: 1.8040193026536144e-05, Min w: 0.9629490375518799\n",
      "Iteration 540, Loss: 3.6273468140279874e-05, Min w: 0.8852169513702393\n",
      "Iteration 550, Loss: 3.6127010389463976e-05, Min w: 0.9159877896308899\n",
      "Iteration 560, Loss: 3.64266088581644e-05, Min w: 0.8986899256706238\n",
      "Iteration 570, Loss: 4.184562203590758e-05, Min w: 0.900353729724884\n",
      "Iteration 580, Loss: 1.542445897939615e-05, Min w: 0.964327871799469\n",
      "Iteration 590, Loss: 4.797978181159124e-05, Min w: 0.8462833166122437\n",
      "Iteration 600, Loss: 3.326509249745868e-05, Min w: 0.9186761379241943\n",
      "Iteration 610, Loss: 2.3944716303958558e-05, Min w: 0.9498946666717529\n",
      "Iteration 620, Loss: 2.334210876142606e-05, Min w: 0.9332355260848999\n",
      "Iteration 630, Loss: 2.6421599613968283e-05, Min w: 0.9368323683738708\n",
      "Iteration 640, Loss: 2.5484694560873322e-05, Min w: 0.9343228340148926\n",
      "Iteration 650, Loss: 1.2914101716887672e-05, Min w: 0.9732288122177124\n",
      "Iteration 660, Loss: 2.076290184049867e-05, Min w: 0.9480344653129578\n",
      "Iteration 670, Loss: 5.078119284007698e-05, Min w: 0.8602048754692078\n",
      "Iteration 680, Loss: 5.620331285172142e-05, Min w: 0.858526885509491\n",
      "Iteration 690, Loss: 2.3365544620901346e-05, Min w: 0.9430668950080872\n",
      "Iteration 700, Loss: 1.4443899999605492e-05, Min w: 0.9691199064254761\n",
      "Iteration 710, Loss: 2.067353852908127e-05, Min w: 0.9399312734603882\n",
      "Iteration 720, Loss: 2.4182618290069513e-05, Min w: 0.9250283241271973\n",
      "Iteration 730, Loss: 2.693331043701619e-05, Min w: 0.9284061789512634\n",
      "Iteration 740, Loss: 3.835375537164509e-05, Min w: 0.911709189414978\n",
      "Iteration 750, Loss: 1.1149027159262914e-05, Min w: 0.9754827618598938\n",
      "Iteration 760, Loss: 4.609054303728044e-05, Min w: 0.8642692565917969\n",
      "Iteration 770, Loss: 2.3209067876450717e-05, Min w: 0.9409905672073364\n",
      "Iteration 780, Loss: 4.030147465527989e-05, Min w: 0.8874847888946533\n",
      "Iteration 790, Loss: 1.952617458300665e-05, Min w: 0.9577361941337585\n",
      "Iteration 800, Loss: 1.192950367112644e-05, Min w: 0.9742463827133179\n",
      "Iteration 810, Loss: 2.5556997570674866e-05, Min w: 0.9409699440002441\n",
      "Iteration 820, Loss: 2.5765151804080233e-05, Min w: 0.9356852173805237\n",
      "Iteration 830, Loss: 4.171132604824379e-05, Min w: 0.853768527507782\n",
      "Iteration 840, Loss: 4.5207176299300045e-05, Min w: 0.8469650745391846\n",
      "Iteration 850, Loss: 2.5528324840706773e-05, Min w: 0.9296615719795227\n",
      "Iteration 860, Loss: 2.173050779674668e-05, Min w: 0.9524307250976562\n",
      "Iteration 870, Loss: 3.611469946918078e-05, Min w: 0.9034429788589478\n",
      "Iteration 880, Loss: 3.232260132790543e-05, Min w: 0.8959804773330688\n",
      "Iteration 890, Loss: 4.765630728797987e-05, Min w: 0.8896874785423279\n",
      "Iteration 900, Loss: 5.685861469828524e-05, Min w: 0.8778424263000488\n",
      "Iteration 910, Loss: 4.890010677627288e-05, Min w: 0.8583992719650269\n",
      "Iteration 920, Loss: 4.11133878515102e-05, Min w: 0.8548662066459656\n",
      "Iteration 930, Loss: 5.354846143745817e-05, Min w: 0.8859660625457764\n",
      "Iteration 940, Loss: 2.0768433387274854e-05, Min w: 0.9502782225608826\n",
      "Iteration 950, Loss: 3.5005617974093184e-05, Min w: 0.8832229375839233\n",
      "Iteration 960, Loss: 3.351001214468852e-05, Min w: 0.8968110680580139\n",
      "Iteration 970, Loss: 3.76078205590602e-05, Min w: 0.8781148195266724\n",
      "Iteration 980, Loss: 2.4316823328263126e-05, Min w: 0.9410295486450195\n",
      "Iteration 990, Loss: 2.2837939468445256e-05, Min w: 0.9414071440696716\n",
      "Iteration 1000, Loss: 4.6252342144725844e-05, Min w: 0.8545019626617432\n",
      "Iteration 1010, Loss: 1.9502524082781747e-05, Min w: 0.9412993788719177\n",
      "Iteration 1020, Loss: 2.336260695301462e-05, Min w: 0.9446449875831604\n",
      "Iteration 1030, Loss: 1.1252403965045232e-05, Min w: 0.9760746359825134\n",
      "Iteration 1040, Loss: 4.449003972695209e-05, Min w: 0.8502642512321472\n",
      "Iteration 1050, Loss: 5.366127152228728e-05, Min w: 0.8162479400634766\n",
      "Iteration 1060, Loss: 3.9701812056591734e-05, Min w: 0.8648787140846252\n",
      "Iteration 1070, Loss: 3.5984397982247174e-05, Min w: 0.8902976512908936\n",
      "Iteration 1080, Loss: 2.4163207854144275e-05, Min w: 0.9218039512634277\n",
      "Iteration 1090, Loss: 2.293534816999454e-05, Min w: 0.9430691003799438\n",
      "Iteration 1100, Loss: 4.026402530143969e-05, Min w: 0.8721256256103516\n",
      "Iteration 1110, Loss: 2.9306225769687444e-05, Min w: 0.9208424091339111\n",
      "Iteration 1120, Loss: 2.3427646738127805e-05, Min w: 0.9461109042167664\n",
      "Iteration 1130, Loss: 4.006333983852528e-05, Min w: 0.9112805724143982\n",
      "Iteration 1140, Loss: 5.441757821245119e-05, Min w: 0.8141399621963501\n",
      "Iteration 1150, Loss: 2.1144716811249964e-05, Min w: 0.942724883556366\n",
      "Iteration 1160, Loss: 1.7923282939591445e-05, Min w: 0.9502716660499573\n",
      "Iteration 1170, Loss: 4.5291813876247033e-05, Min w: 0.8873885273933411\n",
      "Iteration 1180, Loss: 5.6051649153232574e-05, Min w: 0.8687964677810669\n",
      "Iteration 1190, Loss: 4.957790588377975e-05, Min w: 0.8793831467628479\n",
      "Iteration 1200, Loss: 2.5657640435383655e-05, Min w: 0.9381533861160278\n",
      "Iteration 1210, Loss: 2.0797388060600497e-05, Min w: 0.9424746632575989\n",
      "Iteration 1220, Loss: 4.0903178160078824e-05, Min w: 0.913173496723175\n",
      "Iteration 1230, Loss: 4.2094798118341714e-05, Min w: 0.9072582721710205\n",
      "Iteration 1240, Loss: 4.758534123538993e-05, Min w: 0.8748018741607666\n",
      "Iteration 0, Loss: 2.6280367819708772e-05, Min w: 0.9228987097740173\n",
      "Iteration 10, Loss: 2.5270210244343616e-05, Min w: 0.9259920120239258\n",
      "Iteration 20, Loss: 1.9939230696763843e-05, Min w: 0.9419530034065247\n",
      "Iteration 30, Loss: 3.115987783530727e-05, Min w: 0.9133098125457764\n",
      "Iteration 40, Loss: 1.7954915165319107e-05, Min w: 0.9474313259124756\n",
      "Iteration 50, Loss: 3.3955784601857886e-05, Min w: 0.9144188165664673\n",
      "Iteration 60, Loss: 2.3924101697048172e-05, Min w: 0.9468781352043152\n",
      "Iteration 70, Loss: 3.073800326092169e-05, Min w: 0.9100470542907715\n",
      "Iteration 80, Loss: 1.797997538233176e-05, Min w: 0.9473510384559631\n",
      "Iteration 90, Loss: 5.676785804098472e-05, Min w: 0.8423348665237427\n",
      "Iteration 100, Loss: 1.4478334378509317e-05, Min w: 0.9637410640716553\n",
      "Iteration 110, Loss: 1.871897984528914e-05, Min w: 0.9422976970672607\n",
      "Iteration 120, Loss: 2.7909201889997348e-05, Min w: 0.9355654716491699\n",
      "Iteration 130, Loss: 1.9865883587044664e-05, Min w: 0.9586580991744995\n",
      "Iteration 140, Loss: 3.126924639218487e-05, Min w: 0.9098277688026428\n",
      "Iteration 150, Loss: 2.1035661120549776e-05, Min w: 0.9474437832832336\n",
      "Iteration 160, Loss: 5.8428558986634016e-05, Min w: 0.8799288868904114\n",
      "Iteration 170, Loss: 4.510954022407532e-05, Min w: 0.8925250172615051\n",
      "Iteration 180, Loss: 2.5317993276985362e-05, Min w: 0.9247240424156189\n",
      "Iteration 190, Loss: 3.979785105912015e-05, Min w: 0.9156549572944641\n",
      "Iteration 200, Loss: 5.3110816224943846e-05, Min w: 0.8532284498214722\n",
      "Iteration 210, Loss: 3.953120540245436e-05, Min w: 0.8862036466598511\n",
      "Iteration 220, Loss: 2.7335943741491064e-05, Min w: 0.9155599474906921\n",
      "Iteration 230, Loss: 1.1697176887537353e-05, Min w: 0.9702672958374023\n",
      "Iteration 240, Loss: 4.409644679981284e-05, Min w: 0.8422278165817261\n",
      "Iteration 250, Loss: 4.182692282483913e-05, Min w: 0.9061858057975769\n",
      "Iteration 260, Loss: 2.3806347599020228e-05, Min w: 0.9439039826393127\n",
      "Iteration 270, Loss: 4.4088494178140536e-05, Min w: 0.8928460478782654\n",
      "Iteration 280, Loss: 2.6861755031859502e-05, Min w: 0.921223521232605\n",
      "Iteration 290, Loss: 3.900517549482174e-05, Min w: 0.9163153171539307\n",
      "Iteration 300, Loss: 2.9754462957498617e-05, Min w: 0.9009928703308105\n",
      "Iteration 310, Loss: 2.7776026399806142e-05, Min w: 0.9155102968215942\n",
      "Iteration 320, Loss: 3.1207444408209994e-05, Min w: 0.9339779019355774\n",
      "Iteration 330, Loss: 2.04298321477836e-05, Min w: 0.9468277096748352\n",
      "Iteration 340, Loss: 3.678186840261333e-05, Min w: 0.9176843762397766\n",
      "Iteration 350, Loss: 3.275027120253071e-05, Min w: 0.8967196941375732\n",
      "Iteration 360, Loss: 3.516176002449356e-05, Min w: 0.9159947037696838\n",
      "Iteration 370, Loss: 1.751062154653482e-05, Min w: 0.9536123871803284\n",
      "Iteration 380, Loss: 2.3289469027076848e-05, Min w: 0.9498220682144165\n",
      "Iteration 390, Loss: 2.6878460630541667e-05, Min w: 0.9150246381759644\n",
      "Iteration 400, Loss: 2.855455022654496e-05, Min w: 0.9296159744262695\n",
      "Iteration 410, Loss: 3.352052590344101e-05, Min w: 0.9206053614616394\n",
      "Iteration 420, Loss: 1.8968989024870098e-05, Min w: 0.946725606918335\n",
      "Iteration 430, Loss: 3.2045845728134736e-05, Min w: 0.9219669103622437\n",
      "Iteration 440, Loss: 2.9611759600811638e-05, Min w: 0.9155387282371521\n",
      "Iteration 450, Loss: 2.95411009574309e-05, Min w: 0.9381306171417236\n",
      "Iteration 460, Loss: 2.2952510335016996e-05, Min w: 0.940722644329071\n",
      "Iteration 470, Loss: 3.3648590033408254e-05, Min w: 0.9031487107276917\n",
      "Iteration 480, Loss: 1.6762518498580903e-05, Min w: 0.9613064527511597\n",
      "Iteration 490, Loss: 3.379870759090409e-05, Min w: 0.9196414351463318\n",
      "Iteration 500, Loss: 2.811766171362251e-05, Min w: 0.9132071733474731\n",
      "Iteration 510, Loss: 1.7780917914933525e-05, Min w: 0.9540506601333618\n",
      "Iteration 520, Loss: 3.066350836888887e-05, Min w: 0.9161553382873535\n",
      "Iteration 530, Loss: 2.5207655198755674e-05, Min w: 0.9293491244316101\n",
      "Iteration 540, Loss: 1.716794940875843e-05, Min w: 0.95091313123703\n",
      "Iteration 550, Loss: 1.8175049262936227e-05, Min w: 0.9580444693565369\n",
      "Iteration 560, Loss: 3.5754357668338344e-05, Min w: 0.908775269985199\n",
      "Iteration 570, Loss: 1.616072404431179e-05, Min w: 0.9654134511947632\n",
      "Iteration 580, Loss: 3.604622179409489e-05, Min w: 0.9027348160743713\n",
      "Iteration 590, Loss: 2.683686398086138e-05, Min w: 0.9354662299156189\n",
      "Iteration 600, Loss: 4.263728260411881e-05, Min w: 0.8812887668609619\n",
      "Iteration 610, Loss: 1.899277776828967e-05, Min w: 0.9385166168212891\n",
      "Iteration 620, Loss: 1.4836624359304551e-05, Min w: 0.963325023651123\n",
      "Iteration 630, Loss: 1.5009514754638076e-05, Min w: 0.9658079147338867\n",
      "Iteration 640, Loss: 1.710197284410242e-05, Min w: 0.9589725136756897\n",
      "Iteration 650, Loss: 1.3402041076915339e-05, Min w: 0.9663800001144409\n",
      "Iteration 660, Loss: 1.89740167115815e-05, Min w: 0.9542863965034485\n",
      "Iteration 670, Loss: 8.741987585381139e-06, Min w: 0.9787818789482117\n",
      "Iteration 680, Loss: 3.454176476225257e-05, Min w: 0.9203511476516724\n",
      "Iteration 690, Loss: 4.0138675103662536e-05, Min w: 0.8793699145317078\n",
      "Iteration 700, Loss: 4.4603253627428785e-05, Min w: 0.898298442363739\n",
      "Iteration 710, Loss: 1.476346096751513e-05, Min w: 0.9579419493675232\n",
      "Iteration 720, Loss: 1.842727760958951e-05, Min w: 0.9516398906707764\n",
      "Iteration 730, Loss: 1.8966926290886477e-05, Min w: 0.9596432447433472\n",
      "Iteration 740, Loss: 1.9497074390528724e-05, Min w: 0.9424468874931335\n",
      "Iteration 750, Loss: 3.694025508593768e-05, Min w: 0.9075628519058228\n",
      "Iteration 760, Loss: 2.489974576747045e-05, Min w: 0.9336957931518555\n",
      "Iteration 770, Loss: 3.298898081993684e-05, Min w: 0.8997015357017517\n",
      "Iteration 780, Loss: 1.669269477133639e-05, Min w: 0.9589368104934692\n",
      "Iteration 790, Loss: 2.173472967115231e-05, Min w: 0.9296924471855164\n",
      "Iteration 800, Loss: 3.287625077064149e-05, Min w: 0.9118712544441223\n",
      "Iteration 810, Loss: 2.025747198786121e-05, Min w: 0.9448199272155762\n",
      "Iteration 820, Loss: 3.302100230939686e-05, Min w: 0.9197958707809448\n",
      "Iteration 830, Loss: 1.978774344024714e-05, Min w: 0.953151285648346\n",
      "Iteration 840, Loss: 2.855582170013804e-05, Min w: 0.9330172538757324\n",
      "Iteration 850, Loss: 3.7994257581885904e-05, Min w: 0.8837893009185791\n",
      "Iteration 860, Loss: 2.7949812647420913e-05, Min w: 0.9197549819946289\n",
      "Iteration 870, Loss: 1.7898639271152206e-05, Min w: 0.9507273435592651\n",
      "Iteration 880, Loss: 2.708983993215952e-05, Min w: 0.9265919923782349\n",
      "Iteration 890, Loss: 1.957427230081521e-05, Min w: 0.936636209487915\n",
      "Iteration 900, Loss: 2.2015721697243862e-05, Min w: 0.930274248123169\n",
      "Iteration 910, Loss: 2.617358768475242e-05, Min w: 0.915503978729248\n",
      "Iteration 920, Loss: 3.431818186072633e-05, Min w: 0.9043650031089783\n",
      "Iteration 930, Loss: 3.020522854058072e-05, Min w: 0.9309301972389221\n",
      "Iteration 940, Loss: 2.34788913076045e-05, Min w: 0.9286072850227356\n",
      "Iteration 950, Loss: 1.935220461746212e-05, Min w: 0.9589403867721558\n",
      "Iteration 960, Loss: 3.2563344575464725e-05, Min w: 0.9256003499031067\n",
      "Iteration 970, Loss: 1.3338210919755511e-05, Min w: 0.9648887515068054\n",
      "Iteration 980, Loss: 3.747058508452028e-05, Min w: 0.919217586517334\n",
      "Iteration 990, Loss: 4.014608566649258e-05, Min w: 0.8952003717422485\n",
      "Iteration 1000, Loss: 1.2448217603377998e-05, Min w: 0.9679641127586365\n",
      "Iteration 1010, Loss: 2.1744972400483675e-05, Min w: 0.9446455836296082\n",
      "Iteration 1020, Loss: 4.172184344497509e-05, Min w: 0.8836314082145691\n",
      "Iteration 1030, Loss: 3.730422758962959e-05, Min w: 0.9001755714416504\n",
      "Iteration 1040, Loss: 2.3934650016599335e-05, Min w: 0.9340299367904663\n",
      "Iteration 1050, Loss: 2.760125971690286e-05, Min w: 0.9277000427246094\n",
      "Iteration 1060, Loss: 2.828414653777145e-05, Min w: 0.9369977712631226\n",
      "Iteration 1070, Loss: 8.797196642262861e-06, Min w: 0.9817540049552917\n",
      "Iteration 1080, Loss: 2.0552955902530812e-05, Min w: 0.9444239139556885\n",
      "Iteration 1090, Loss: 2.6170539058512077e-05, Min w: 0.920985758304596\n",
      "Iteration 1100, Loss: 1.7635335098020732e-05, Min w: 0.9505993127822876\n",
      "Iteration 1110, Loss: 5.883573612663895e-05, Min w: 0.8177645206451416\n",
      "Iteration 1120, Loss: 1.8062846720567904e-05, Min w: 0.9570104479789734\n",
      "Iteration 1130, Loss: 1.624468859517947e-05, Min w: 0.9467623829841614\n",
      "Iteration 1140, Loss: 4.2248233512509614e-05, Min w: 0.8800768256187439\n",
      "Iteration 1150, Loss: 2.4120685338857584e-05, Min w: 0.9476742744445801\n",
      "Iteration 1160, Loss: 1.4489235582004767e-05, Min w: 0.9545703530311584\n",
      "Iteration 1170, Loss: 1.0757979907793924e-05, Min w: 0.9777774810791016\n",
      "Iteration 1180, Loss: 6.565643707290292e-05, Min w: 0.8216246366500854\n",
      "Iteration 1190, Loss: 3.0995754059404135e-05, Min w: 0.9165418148040771\n",
      "Iteration 1200, Loss: 2.974683593492955e-05, Min w: 0.9299828410148621\n",
      "Iteration 1210, Loss: 1.2315864296397194e-05, Min w: 0.9681850671768188\n",
      "Iteration 1220, Loss: 1.8120847016689368e-05, Min w: 0.9596812129020691\n",
      "Iteration 1230, Loss: 3.637105692178011e-05, Min w: 0.8932123780250549\n",
      "Iteration 1240, Loss: 1.1546647328941617e-05, Min w: 0.9722062945365906\n",
      "Iteration 0, Loss: 3.164538065902889e-05, Min w: 0.9022161960601807\n",
      "Iteration 10, Loss: 1.4472376278718002e-05, Min w: 0.9592800140380859\n",
      "Iteration 20, Loss: 1.137428898800863e-05, Min w: 0.9700685143470764\n",
      "Iteration 30, Loss: 1.1818139682873152e-05, Min w: 0.9705238938331604\n",
      "Iteration 40, Loss: 5.40188884770032e-05, Min w: 0.8799755573272705\n",
      "Iteration 50, Loss: 3.0302227969514206e-05, Min w: 0.9161741137504578\n",
      "Iteration 60, Loss: 1.669616176513955e-05, Min w: 0.9557846784591675\n",
      "Iteration 70, Loss: 1.539659388072323e-05, Min w: 0.9584505558013916\n",
      "Iteration 80, Loss: 2.206553290307056e-05, Min w: 0.9526900053024292\n",
      "Iteration 90, Loss: 2.233350278402213e-05, Min w: 0.9412698149681091\n",
      "Iteration 100, Loss: 4.3073225242551416e-05, Min w: 0.8587682247161865\n",
      "Iteration 110, Loss: 1.7385929822921753e-05, Min w: 0.9473822712898254\n",
      "Iteration 120, Loss: 7.443315098498715e-06, Min w: 0.9819226861000061\n",
      "Iteration 130, Loss: 7.9207729868358e-06, Min w: 0.9834950566291809\n",
      "Iteration 140, Loss: 2.3089331079972908e-05, Min w: 0.9233769774436951\n",
      "Iteration 150, Loss: 2.5866258511086926e-05, Min w: 0.9277306795120239\n",
      "Iteration 160, Loss: 2.635718738019932e-05, Min w: 0.9331315159797668\n",
      "Iteration 170, Loss: 1.0262800060445443e-05, Min w: 0.9773228764533997\n",
      "Iteration 180, Loss: 2.7247100661043078e-05, Min w: 0.914462149143219\n",
      "Iteration 190, Loss: 7.931513209769037e-06, Min w: 0.9820170402526855\n",
      "Iteration 200, Loss: 2.6481475288164802e-05, Min w: 0.9391244053840637\n",
      "Iteration 210, Loss: 4.00516546505969e-05, Min w: 0.8827134370803833\n",
      "Iteration 220, Loss: 1.7673646652838215e-05, Min w: 0.9529699087142944\n",
      "Iteration 230, Loss: 9.771869372343644e-06, Min w: 0.9759970307350159\n",
      "Iteration 240, Loss: 2.4637600290589035e-05, Min w: 0.940265953540802\n",
      "Iteration 250, Loss: 3.327256126794964e-05, Min w: 0.8836973905563354\n",
      "Iteration 260, Loss: 1.6492200302309357e-05, Min w: 0.9536380171775818\n",
      "Iteration 270, Loss: 1.5809577234904282e-05, Min w: 0.9667752981185913\n",
      "Iteration 280, Loss: 2.0018047507619485e-05, Min w: 0.958607017993927\n",
      "Iteration 290, Loss: 2.2022839402779937e-05, Min w: 0.9412435293197632\n",
      "Iteration 300, Loss: 2.025020876317285e-05, Min w: 0.9423506855964661\n",
      "Iteration 310, Loss: 1.5991770851542242e-05, Min w: 0.9605097770690918\n",
      "Iteration 320, Loss: 2.762900294328574e-05, Min w: 0.907039999961853\n",
      "Iteration 330, Loss: 5.009643791709095e-05, Min w: 0.8958329558372498\n",
      "Iteration 340, Loss: 3.1890031095827e-05, Min w: 0.9216246008872986\n",
      "Iteration 350, Loss: 2.0895990019198507e-05, Min w: 0.9352292418479919\n",
      "Iteration 360, Loss: 6.271090569498483e-06, Min w: 0.9860106110572815\n",
      "Iteration 370, Loss: 1.2214894013595767e-05, Min w: 0.9708877205848694\n",
      "Iteration 380, Loss: 5.157132909516804e-05, Min w: 0.8652909994125366\n",
      "Iteration 390, Loss: 2.6180268832831644e-05, Min w: 0.9254589080810547\n",
      "Iteration 400, Loss: 8.896429790183902e-06, Min w: 0.9791316390037537\n",
      "Iteration 410, Loss: 3.0758608772885054e-05, Min w: 0.9010360836982727\n",
      "Iteration 420, Loss: 1.3024327927269042e-05, Min w: 0.9703271389007568\n",
      "Iteration 430, Loss: 1.9217372027924284e-05, Min w: 0.9567448496818542\n",
      "Iteration 440, Loss: 1.68164842762053e-05, Min w: 0.952717661857605\n",
      "Iteration 450, Loss: 1.3455786756821908e-05, Min w: 0.9575204849243164\n",
      "Iteration 460, Loss: 3.078188456129283e-05, Min w: 0.9020818471908569\n",
      "Iteration 470, Loss: 2.293221405125223e-05, Min w: 0.9227869510650635\n",
      "Iteration 480, Loss: 2.1201272829785012e-05, Min w: 0.9335651397705078\n",
      "Iteration 490, Loss: 2.3040178348310292e-05, Min w: 0.9292342662811279\n",
      "Iteration 500, Loss: 7.404235475405585e-06, Min w: 0.9821676015853882\n",
      "Iteration 510, Loss: 7.1738477345206775e-06, Min w: 0.9824258685112\n",
      "Iteration 520, Loss: 3.720212043845095e-05, Min w: 0.9006893038749695\n",
      "Iteration 530, Loss: 2.61320255958708e-05, Min w: 0.9111009836196899\n",
      "Iteration 540, Loss: 3.6521356378216296e-05, Min w: 0.9033970236778259\n",
      "Iteration 550, Loss: 1.7046304492396303e-05, Min w: 0.9570986032485962\n",
      "Iteration 560, Loss: 8.06336902314797e-06, Min w: 0.9796985983848572\n",
      "Iteration 570, Loss: 5.6182168918894604e-05, Min w: 0.8693757653236389\n",
      "Iteration 580, Loss: 1.7767055396689102e-05, Min w: 0.9496411681175232\n",
      "Iteration 590, Loss: 6.342067354125902e-05, Min w: 0.8402515053749084\n",
      "Iteration 600, Loss: 5.301841883920133e-05, Min w: 0.8766475915908813\n",
      "Iteration 610, Loss: 4.975030606146902e-05, Min w: 0.8406727313995361\n",
      "Iteration 620, Loss: 1.6787842469057068e-05, Min w: 0.9654092788696289\n",
      "Iteration 630, Loss: 1.3779133041680325e-05, Min w: 0.9574620723724365\n",
      "Iteration 640, Loss: 2.7874240913661197e-05, Min w: 0.9176075458526611\n",
      "Iteration 650, Loss: 8.772446562943514e-06, Min w: 0.9796105623245239\n",
      "Iteration 660, Loss: 2.5811839805101044e-05, Min w: 0.9137704968452454\n",
      "Iteration 670, Loss: 1.759799852152355e-05, Min w: 0.9465824365615845\n",
      "Iteration 680, Loss: 2.3668255380471237e-05, Min w: 0.9404904246330261\n",
      "Iteration 690, Loss: 2.5290273697464727e-05, Min w: 0.9409538507461548\n",
      "Iteration 700, Loss: 2.9792545319651254e-05, Min w: 0.9337832927703857\n",
      "Iteration 710, Loss: 4.1268365748692304e-05, Min w: 0.9013548493385315\n",
      "Iteration 720, Loss: 3.681072121253237e-05, Min w: 0.8920996785163879\n",
      "Iteration 730, Loss: 1.4462840226769913e-05, Min w: 0.9647502303123474\n",
      "Iteration 740, Loss: 2.3151220375439152e-05, Min w: 0.9308741092681885\n",
      "Iteration 750, Loss: 3.610389103414491e-05, Min w: 0.9093418121337891\n",
      "Iteration 760, Loss: 2.1220572307356633e-05, Min w: 0.9533188939094543\n",
      "Iteration 770, Loss: 2.8044563805451617e-05, Min w: 0.9197423458099365\n",
      "Iteration 780, Loss: 2.8872409529867582e-05, Min w: 0.933107852935791\n",
      "Iteration 790, Loss: 2.0046145436936058e-05, Min w: 0.9411582946777344\n",
      "Iteration 800, Loss: 2.1066111003165133e-05, Min w: 0.9304940700531006\n",
      "Iteration 810, Loss: 7.586814263049746e-06, Min w: 0.9834349155426025\n",
      "Iteration 820, Loss: 1.8231174180982634e-05, Min w: 0.9399315714836121\n",
      "Iteration 830, Loss: 2.74501544481609e-05, Min w: 0.9089964628219604\n",
      "Iteration 840, Loss: 1.3760761248704512e-05, Min w: 0.9586290717124939\n",
      "Iteration 850, Loss: 2.0739649698953144e-05, Min w: 0.9385332465171814\n",
      "Iteration 860, Loss: 1.1479342902021017e-05, Min w: 0.9732740521430969\n",
      "Iteration 870, Loss: 1.2763346603605896e-05, Min w: 0.969066858291626\n",
      "Iteration 880, Loss: 3.1850882805883884e-05, Min w: 0.9334821701049805\n",
      "Iteration 890, Loss: 3.840886347461492e-05, Min w: 0.9124781489372253\n",
      "Iteration 900, Loss: 2.08544333872851e-05, Min w: 0.9544839262962341\n",
      "Iteration 910, Loss: 1.2848382539232261e-05, Min w: 0.9652631878852844\n",
      "Iteration 920, Loss: 2.820443296513986e-05, Min w: 0.9141532778739929\n",
      "Iteration 930, Loss: 1.790126771084033e-05, Min w: 0.9594511985778809\n",
      "Iteration 940, Loss: 3.4310880437260494e-05, Min w: 0.8853865265846252\n",
      "Iteration 950, Loss: 2.6049252483062446e-05, Min w: 0.916435182094574\n",
      "Iteration 960, Loss: 3.1870560633251444e-05, Min w: 0.9193126559257507\n",
      "Iteration 970, Loss: 2.1845011360710487e-05, Min w: 0.9391375184059143\n",
      "Iteration 980, Loss: 9.032389243657235e-06, Min w: 0.9801607728004456\n",
      "Iteration 990, Loss: 3.5726512578548864e-05, Min w: 0.8951244354248047\n",
      "Iteration 1000, Loss: 6.182818196975859e-06, Min w: 0.9860379695892334\n",
      "Iteration 1010, Loss: 1.662063368712552e-05, Min w: 0.958225667476654\n",
      "Iteration 1020, Loss: 9.246257832273841e-06, Min w: 0.980998158454895\n",
      "Iteration 1030, Loss: 3.5163491702405736e-05, Min w: 0.8970358967781067\n",
      "Iteration 1040, Loss: 3.7701822293456644e-05, Min w: 0.9053663015365601\n",
      "Iteration 1050, Loss: 1.6575093468418345e-05, Min w: 0.9563276171684265\n",
      "Iteration 1060, Loss: 2.2456448277807795e-05, Min w: 0.9354279637336731\n",
      "Iteration 1070, Loss: 1.6842006516526453e-05, Min w: 0.9478802680969238\n",
      "Iteration 1080, Loss: 1.1472181540739257e-05, Min w: 0.9736303687095642\n",
      "Iteration 1090, Loss: 1.9426888684392907e-05, Min w: 0.9417932033538818\n",
      "Iteration 1100, Loss: 3.6911238566972315e-05, Min w: 0.912287712097168\n",
      "Iteration 1110, Loss: 2.51096353167668e-05, Min w: 0.9262316226959229\n",
      "Iteration 1120, Loss: 1.5312100003939122e-05, Min w: 0.9549639225006104\n",
      "Iteration 1130, Loss: 1.2300808521104045e-05, Min w: 0.9609278440475464\n",
      "Iteration 1140, Loss: 4.494926179177128e-05, Min w: 0.8771420121192932\n",
      "Iteration 1150, Loss: 3.2660114811733365e-05, Min w: 0.9146538376808167\n",
      "Iteration 1160, Loss: 3.1988805858418345e-05, Min w: 0.9073541164398193\n",
      "Iteration 1170, Loss: 2.3908656658022664e-05, Min w: 0.9207393527030945\n",
      "Iteration 1180, Loss: 2.5419642042834312e-05, Min w: 0.9399032592773438\n",
      "Iteration 1190, Loss: 6.662126907031052e-06, Min w: 0.9841980338096619\n",
      "Iteration 1200, Loss: 1.539244294690434e-05, Min w: 0.9640573263168335\n",
      "Iteration 1210, Loss: 2.5011575417011045e-05, Min w: 0.9412543177604675\n",
      "Iteration 1220, Loss: 1.768901347531937e-05, Min w: 0.9538099765777588\n",
      "Iteration 1230, Loss: 4.3447082134662196e-05, Min w: 0.8950454592704773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  96%|█████████▌| 23/24 [18:31<00:50, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240, Loss: 3.9714959712000564e-05, Min w: 0.9128456711769104\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 6250, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.009690188852416416, 'L2_avg': 0.014729482957870044, 'End_point_L1_avg': 0.009090325845760493, 'End_point_L2_avg': 0.009371156627297489}\n",
      "Iteration 0, Loss: 0.0010572653263807297, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010009508114308119, Min w: 2.1514460968319327e-07\n",
      "Iteration 20, Loss: 0.0009451908408664167, Min w: 1.2642994379663447e-26\n",
      "Iteration 30, Loss: 0.000984969432465732, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0009105460485443473, Min w: 2.2545259116633215e-13\n",
      "Iteration 50, Loss: 0.0009649989078752697, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0008789243292994797, Min w: 1.1823705613762564e-17\n",
      "Iteration 70, Loss: 0.0009260678780265152, Min w: 0.0\n",
      "Iteration 80, Loss: 0.0008316473104059696, Min w: 3.1103733802282816e-15\n",
      "Iteration 90, Loss: 0.000847614137455821, Min w: 0.0\n",
      "Iteration 100, Loss: 0.0008297524182125926, Min w: 0.0\n",
      "Iteration 110, Loss: 0.000813847582321614, Min w: 0.0\n",
      "Iteration 120, Loss: 0.0008604148169979453, Min w: 0.0\n",
      "Iteration 130, Loss: 0.0007922977674752474, Min w: 0.0\n",
      "Iteration 140, Loss: 0.000839534099213779, Min w: 0.0\n",
      "Iteration 150, Loss: 0.0007914510206319392, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0008080746047198772, Min w: 0.0\n",
      "Iteration 170, Loss: 0.0006466783815994859, Min w: 0.0\n",
      "Iteration 180, Loss: 0.0006399987614713609, Min w: 0.0\n",
      "Iteration 190, Loss: 0.0005929183680564165, Min w: 0.0\n",
      "Iteration 200, Loss: 0.0005741774803027511, Min w: 0.0\n",
      "Iteration 210, Loss: 0.0005613340763375163, Min w: 0.0\n",
      "Iteration 220, Loss: 0.0005491249030455947, Min w: 0.0\n",
      "Iteration 230, Loss: 0.0005359823117032647, Min w: 0.0\n",
      "Iteration 240, Loss: 0.0005236687720753253, Min w: 0.0\n",
      "Iteration 250, Loss: 0.0005124541348777711, Min w: 0.0\n",
      "Iteration 260, Loss: 0.0005886451690457761, Min w: 0.0\n",
      "Iteration 270, Loss: 0.000504607567563653, Min w: 0.0\n",
      "Iteration 280, Loss: 0.00046865997137501836, Min w: 0.0\n",
      "Iteration 290, Loss: 0.00047398966853506863, Min w: 0.0\n",
      "Iteration 300, Loss: 0.0005055641522631049, Min w: 0.0\n",
      "Iteration 310, Loss: 0.00043240695958957076, Min w: 0.0\n",
      "Iteration 320, Loss: 0.0004133655165787786, Min w: 0.0\n",
      "Iteration 330, Loss: 0.0005539053818210959, Min w: 0.0\n",
      "Iteration 340, Loss: 0.0004797883448190987, Min w: 0.0\n",
      "Iteration 350, Loss: 0.0003998241445515305, Min w: 0.0\n",
      "Iteration 360, Loss: 0.0005986009491607547, Min w: 0.0\n",
      "Iteration 370, Loss: 0.0005538206896744668, Min w: 0.0\n",
      "Iteration 380, Loss: 0.0005713891587220132, Min w: 0.0\n",
      "Iteration 390, Loss: 0.0005624929326586425, Min w: 0.0\n",
      "Iteration 400, Loss: 0.0005666557117365301, Min w: 0.0\n",
      "Iteration 410, Loss: 0.0005558161064982414, Min w: 0.0\n",
      "Iteration 420, Loss: 0.0004690931527875364, Min w: 0.0\n",
      "Iteration 430, Loss: 0.00040553667349740863, Min w: 0.0\n",
      "Iteration 440, Loss: 0.0003839278651867062, Min w: 3.7579644869353764e-26\n",
      "Iteration 450, Loss: 0.0004587982257362455, Min w: 1.1775159691751469e-06\n",
      "Iteration 460, Loss: 0.00043671007733792067, Min w: 6.3054034751854506e-24\n",
      "Iteration 470, Loss: 0.00043842161539942026, Min w: 0.0\n",
      "Iteration 480, Loss: 0.00046492950059473515, Min w: 3.3414942313016874e-28\n",
      "Iteration 490, Loss: 0.00038184321601875126, Min w: 2.3609737279908956e-14\n",
      "Iteration 500, Loss: 0.0005011914181523025, Min w: 8.893825231837127e-09\n",
      "Iteration 510, Loss: 0.0004029703268315643, Min w: 2.0666857381002046e-06\n",
      "Iteration 520, Loss: 0.00041494760080240667, Min w: 0.0003410290228202939\n",
      "Iteration 530, Loss: 0.0003706512798089534, Min w: 0.03006649948656559\n",
      "Iteration 540, Loss: 0.00035059379297308624, Min w: 0.03904370218515396\n",
      "Iteration 550, Loss: 0.0003733116027433425, Min w: 0.10910302400588989\n",
      "Iteration 560, Loss: 0.0005072252242825925, Min w: 0.028977863490581512\n",
      "Iteration 570, Loss: 0.00036090120556764305, Min w: 0.002292211866006255\n",
      "Iteration 580, Loss: 0.00039904186269268394, Min w: 0.018373707309365273\n",
      "Iteration 590, Loss: 0.00046603064402006567, Min w: 0.09050220996141434\n",
      "Iteration 600, Loss: 0.0003448914794716984, Min w: 0.21264399588108063\n",
      "Iteration 610, Loss: 0.0003299240779597312, Min w: 0.16733801364898682\n",
      "Iteration 620, Loss: 0.0003019138821400702, Min w: 0.23668073117733002\n",
      "Iteration 630, Loss: 0.00029935120255686343, Min w: 0.26571565866470337\n",
      "Iteration 640, Loss: 0.00024605559883639216, Min w: 0.3309211730957031\n",
      "Iteration 650, Loss: 0.00025534266023896635, Min w: 0.34290963411331177\n",
      "Iteration 660, Loss: 0.00034455754212103784, Min w: 0.25847503542900085\n",
      "Iteration 670, Loss: 0.00025483345962129533, Min w: 0.39229702949523926\n",
      "Iteration 680, Loss: 0.000278156396234408, Min w: 0.35646852850914\n",
      "Iteration 690, Loss: 0.000244374037720263, Min w: 0.39656174182891846\n",
      "Iteration 700, Loss: 0.0001993726473301649, Min w: 0.46919575333595276\n",
      "Iteration 710, Loss: 0.0002351950533920899, Min w: 0.44037607312202454\n",
      "Iteration 720, Loss: 0.000251604215009138, Min w: 0.26459774374961853\n",
      "Iteration 730, Loss: 0.00027254869928583503, Min w: 0.29828765988349915\n",
      "Iteration 740, Loss: 0.0002198545989813283, Min w: 0.4285156726837158\n",
      "Iteration 750, Loss: 0.00022488304239232093, Min w: 0.47559648752212524\n",
      "Iteration 760, Loss: 0.00021572773403022438, Min w: 0.4029776155948639\n",
      "Iteration 770, Loss: 0.00028495819424279034, Min w: 0.4210392236709595\n",
      "Iteration 780, Loss: 0.0001927571720443666, Min w: 0.5791960954666138\n",
      "Iteration 790, Loss: 0.00025205864221788943, Min w: 0.42087286710739136\n",
      "Iteration 800, Loss: 0.000162326599820517, Min w: 0.6054718494415283\n",
      "Iteration 810, Loss: 0.00021890817151870579, Min w: 0.4880044162273407\n",
      "Iteration 820, Loss: 0.00018255601753480732, Min w: 0.6264491677284241\n",
      "Iteration 830, Loss: 0.0002405598061159253, Min w: 0.4854094088077545\n",
      "Iteration 840, Loss: 0.00014209716755431145, Min w: 0.675203800201416\n",
      "Iteration 850, Loss: 0.00016407176735810935, Min w: 0.568572998046875\n",
      "Iteration 860, Loss: 0.0002020920073846355, Min w: 0.5811114311218262\n",
      "Iteration 870, Loss: 0.0001941901136888191, Min w: 0.47803372144699097\n",
      "Iteration 880, Loss: 0.0001655997766647488, Min w: 0.6541898846626282\n",
      "Iteration 890, Loss: 0.00013007255620323122, Min w: 0.6766529679298401\n",
      "Iteration 900, Loss: 0.0002674987481441349, Min w: 0.44089436531066895\n",
      "Iteration 910, Loss: 0.00030861119739711285, Min w: 0.3525089621543884\n",
      "Iteration 920, Loss: 0.0002566587645560503, Min w: 0.3627933859825134\n",
      "Iteration 930, Loss: 0.00038653836236335337, Min w: 0.044322676956653595\n",
      "Iteration 940, Loss: 0.000429118808824569, Min w: 0.0009634889429435134\n",
      "Iteration 950, Loss: 0.0003580612246878445, Min w: 0.0087363813072443\n",
      "Iteration 960, Loss: 0.00034466481884010136, Min w: 0.21365758776664734\n",
      "Iteration 970, Loss: 0.00034104270162060857, Min w: 0.029613807797431946\n",
      "Iteration 980, Loss: 0.00043656237539835274, Min w: 0.08582936972379684\n",
      "Iteration 990, Loss: 0.0004952789167873561, Min w: 0.003385012038052082\n",
      "Iteration 1000, Loss: 0.0005006144638173282, Min w: 1.522792783255171e-14\n",
      "Iteration 1010, Loss: 0.0004955582553520799, Min w: 2.2236503003508767e-12\n",
      "Iteration 1020, Loss: 0.0003790063492488116, Min w: 0.029469365254044533\n",
      "Iteration 1030, Loss: 0.00029669859213754535, Min w: 0.3669869601726532\n",
      "Iteration 1040, Loss: 0.00024586968356743455, Min w: 0.44528713822364807\n",
      "Iteration 1050, Loss: 0.00018394162179902196, Min w: 0.5622203946113586\n",
      "Iteration 1060, Loss: 0.0001718815474305302, Min w: 0.5527655482292175\n",
      "Iteration 1070, Loss: 0.00014864964759908617, Min w: 0.6250287890434265\n",
      "Iteration 1080, Loss: 0.00013719948765356094, Min w: 0.6430743336677551\n",
      "Iteration 1090, Loss: 0.00012799767137039453, Min w: 0.6647562980651855\n",
      "Iteration 1100, Loss: 0.0001229370100190863, Min w: 0.6810961961746216\n",
      "Iteration 1110, Loss: 0.00012082906323485076, Min w: 0.6893019080162048\n",
      "Iteration 1120, Loss: 0.00011682230979204178, Min w: 0.6948897242546082\n",
      "Iteration 1130, Loss: 0.00016104866517707705, Min w: 0.6310083270072937\n",
      "Iteration 1140, Loss: 0.00017447136633563787, Min w: 0.6058933734893799\n",
      "Iteration 1150, Loss: 0.00015302990505006164, Min w: 0.6483398675918579\n",
      "Iteration 1160, Loss: 0.00014982048014644533, Min w: 0.6753544807434082\n",
      "Iteration 1170, Loss: 0.00015147976228035986, Min w: 0.6774255037307739\n",
      "Iteration 1180, Loss: 0.00015750261081848294, Min w: 0.6204285621643066\n",
      "Iteration 1190, Loss: 0.00013432263222057372, Min w: 0.692211925983429\n",
      "Iteration 1200, Loss: 0.000136146045406349, Min w: 0.7127119898796082\n",
      "Iteration 1210, Loss: 0.00011787689436459914, Min w: 0.7530099749565125\n",
      "Iteration 1220, Loss: 0.0001331934763584286, Min w: 0.7193732857704163\n",
      "Iteration 1230, Loss: 0.00014574136002920568, Min w: 0.6829171776771545\n",
      "Iteration 1240, Loss: 0.00015348118904512376, Min w: 0.6751933693885803\n",
      "Iteration 0, Loss: 0.00015059649012982845, Min w: 0.6942840218544006\n",
      "Iteration 10, Loss: 0.0001266096660401672, Min w: 0.7211377024650574\n",
      "Iteration 20, Loss: 0.0001246052561327815, Min w: 0.728198766708374\n",
      "Iteration 30, Loss: 0.00011661128519335762, Min w: 0.7492132782936096\n",
      "Iteration 40, Loss: 0.00012367061572149396, Min w: 0.7296960353851318\n",
      "Iteration 50, Loss: 0.00011699476453941315, Min w: 0.7311553359031677\n",
      "Iteration 60, Loss: 0.00011857673234771937, Min w: 0.7560834288597107\n",
      "Iteration 70, Loss: 8.690361573826522e-05, Min w: 0.8007097840309143\n",
      "Iteration 80, Loss: 0.00011060797260142863, Min w: 0.7493429183959961\n",
      "Iteration 90, Loss: 0.00012680127110797912, Min w: 0.7316564321517944\n",
      "Iteration 100, Loss: 0.00011723070201696828, Min w: 0.7561888098716736\n",
      "Iteration 110, Loss: 0.00010647394810803235, Min w: 0.7481086254119873\n",
      "Iteration 120, Loss: 0.00011021926184184849, Min w: 0.7445729374885559\n",
      "Iteration 130, Loss: 9.472443343838677e-05, Min w: 0.7913973331451416\n",
      "Iteration 140, Loss: 0.00011415177141316235, Min w: 0.7591345906257629\n",
      "Iteration 150, Loss: 0.00010058229963760823, Min w: 0.7755481600761414\n",
      "Iteration 160, Loss: 0.0001128710646298714, Min w: 0.7070534229278564\n",
      "Iteration 170, Loss: 0.00011476325744297355, Min w: 0.6763710379600525\n",
      "Iteration 180, Loss: 8.566320320824161e-05, Min w: 0.8138595819473267\n",
      "Iteration 190, Loss: 8.612633973825723e-05, Min w: 0.7581567168235779\n",
      "Iteration 200, Loss: 0.00013861636398360133, Min w: 0.7053723335266113\n",
      "Iteration 210, Loss: 8.382272062590346e-05, Min w: 0.8151828646659851\n",
      "Iteration 220, Loss: 8.69423893163912e-05, Min w: 0.7946850657463074\n",
      "Iteration 230, Loss: 0.00011280034959781915, Min w: 0.7379322648048401\n",
      "Iteration 240, Loss: 9.500421583652496e-05, Min w: 0.7308673858642578\n",
      "Iteration 250, Loss: 9.916969429468736e-05, Min w: 0.7247961163520813\n",
      "Iteration 260, Loss: 7.535266922786832e-05, Min w: 0.8419248461723328\n",
      "Iteration 270, Loss: 5.812523522763513e-05, Min w: 0.8785443305969238\n",
      "Iteration 280, Loss: 8.9874432887882e-05, Min w: 0.7574478387832642\n",
      "Iteration 290, Loss: 0.0001345012424280867, Min w: 0.5729324221611023\n",
      "Iteration 300, Loss: 0.00013379107986111194, Min w: 0.670947790145874\n",
      "Iteration 310, Loss: 0.00011525113950483501, Min w: 0.735041081905365\n",
      "Iteration 320, Loss: 5.267919186735526e-05, Min w: 0.8813627362251282\n",
      "Iteration 330, Loss: 5.723914728150703e-05, Min w: 0.8647209405899048\n",
      "Iteration 340, Loss: 4.12119334214367e-05, Min w: 0.9101670384407043\n",
      "Iteration 350, Loss: 4.369435555418022e-05, Min w: 0.8967555165290833\n",
      "Iteration 360, Loss: 0.00010218025272479281, Min w: 0.7440930008888245\n",
      "Iteration 370, Loss: 0.00013494992163032293, Min w: 0.6872133016586304\n",
      "Iteration 380, Loss: 9.572447743266821e-05, Min w: 0.7726014256477356\n",
      "Iteration 390, Loss: 9.16190110729076e-05, Min w: 0.782324492931366\n",
      "Iteration 400, Loss: 0.00010949821444228292, Min w: 0.7646577954292297\n",
      "Iteration 410, Loss: 7.138053479138762e-05, Min w: 0.8267951011657715\n",
      "Iteration 420, Loss: 6.475142436102033e-05, Min w: 0.8577877879142761\n",
      "Iteration 430, Loss: 7.40949617465958e-05, Min w: 0.8275229334831238\n",
      "Iteration 440, Loss: 8.163500024238601e-05, Min w: 0.8051018118858337\n",
      "Iteration 450, Loss: 8.119483391055837e-05, Min w: 0.7906404733657837\n",
      "Iteration 460, Loss: 8.49528078106232e-05, Min w: 0.8122615218162537\n",
      "Iteration 470, Loss: 5.043937198934145e-05, Min w: 0.870266318321228\n",
      "Iteration 480, Loss: 8.143575541907921e-05, Min w: 0.8296863436698914\n",
      "Iteration 490, Loss: 8.500453986926004e-05, Min w: 0.8182695508003235\n",
      "Iteration 500, Loss: 9.112145198741928e-05, Min w: 0.7898417115211487\n",
      "Iteration 510, Loss: 7.151060708565637e-05, Min w: 0.790372371673584\n",
      "Iteration 520, Loss: 6.871349614812061e-05, Min w: 0.8060012459754944\n",
      "Iteration 530, Loss: 4.2898987885564566e-05, Min w: 0.903057336807251\n",
      "Iteration 540, Loss: 9.444949682801962e-05, Min w: 0.7965165376663208\n",
      "Iteration 550, Loss: 3.747973096324131e-05, Min w: 0.909885048866272\n",
      "Iteration 560, Loss: 5.131349462317303e-05, Min w: 0.865496814250946\n",
      "Iteration 570, Loss: 3.474120603641495e-05, Min w: 0.919396698474884\n",
      "Iteration 580, Loss: 9.593059803592041e-05, Min w: 0.7217356562614441\n",
      "Iteration 590, Loss: 9.980947652366012e-05, Min w: 0.7404826283454895\n",
      "Iteration 600, Loss: 7.833966810721904e-05, Min w: 0.7568735480308533\n",
      "Iteration 610, Loss: 7.299854041775689e-05, Min w: 0.7704560160636902\n",
      "Iteration 620, Loss: 8.20014756754972e-05, Min w: 0.7967910766601562\n",
      "Iteration 630, Loss: 6.617017061216757e-05, Min w: 0.8033837676048279\n",
      "Iteration 640, Loss: 9.088191291084513e-05, Min w: 0.8006661534309387\n",
      "Iteration 650, Loss: 4.6797333197901025e-05, Min w: 0.8684519529342651\n",
      "Iteration 660, Loss: 4.2595707782311365e-05, Min w: 0.9111443758010864\n",
      "Iteration 670, Loss: 7.909371925052255e-05, Min w: 0.7510212659835815\n",
      "Iteration 680, Loss: 7.649618783034384e-05, Min w: 0.8261255025863647\n",
      "Iteration 690, Loss: 4.821232141694054e-05, Min w: 0.8573676943778992\n",
      "Iteration 700, Loss: 8.96322526386939e-05, Min w: 0.7697402834892273\n",
      "Iteration 710, Loss: 7.931833533803001e-05, Min w: 0.8356533646583557\n",
      "Iteration 720, Loss: 6.810512422816828e-05, Min w: 0.8385841846466064\n",
      "Iteration 730, Loss: 5.162989691598341e-05, Min w: 0.8493243455886841\n",
      "Iteration 740, Loss: 4.6585479140048847e-05, Min w: 0.871392011642456\n",
      "Iteration 750, Loss: 9.046096965903416e-05, Min w: 0.725997269153595\n",
      "Iteration 760, Loss: 9.570147085469216e-05, Min w: 0.744323194026947\n",
      "Iteration 770, Loss: 8.691896073287353e-05, Min w: 0.8033514022827148\n",
      "Iteration 780, Loss: 3.777637175517157e-05, Min w: 0.8983689546585083\n",
      "Iteration 790, Loss: 6.348021270241588e-05, Min w: 0.8339345455169678\n",
      "Iteration 800, Loss: 5.4939308029133826e-05, Min w: 0.874649703502655\n",
      "Iteration 810, Loss: 5.881269316887483e-05, Min w: 0.8378673791885376\n",
      "Iteration 820, Loss: 7.696509419474751e-05, Min w: 0.82135009765625\n",
      "Iteration 830, Loss: 3.9416481740772724e-05, Min w: 0.8955055475234985\n",
      "Iteration 840, Loss: 6.791585474275053e-05, Min w: 0.8106629848480225\n",
      "Iteration 850, Loss: 8.074672950897366e-05, Min w: 0.8345141410827637\n",
      "Iteration 860, Loss: 2.929472248069942e-05, Min w: 0.9185451865196228\n",
      "Iteration 870, Loss: 7.850024849176407e-05, Min w: 0.8331982493400574\n",
      "Iteration 880, Loss: 4.292762605473399e-05, Min w: 0.8742307424545288\n",
      "Iteration 890, Loss: 3.877237031701952e-05, Min w: 0.8992639780044556\n",
      "Iteration 900, Loss: 5.303059151628986e-05, Min w: 0.8397328853607178\n",
      "Iteration 910, Loss: 6.082757317926735e-05, Min w: 0.8140701651573181\n",
      "Iteration 920, Loss: 7.16781651135534e-05, Min w: 0.7527597546577454\n",
      "Iteration 930, Loss: 4.5335167669691145e-05, Min w: 0.8999972939491272\n",
      "Iteration 940, Loss: 7.116151391528547e-05, Min w: 0.8071483373641968\n",
      "Iteration 950, Loss: 9.94372894638218e-05, Min w: 0.7803703546524048\n",
      "Iteration 960, Loss: 1.5917541531962343e-05, Min w: 0.9673351049423218\n",
      "Iteration 970, Loss: 3.096590080531314e-05, Min w: 0.9353122115135193\n",
      "Iteration 980, Loss: 4.096497650607489e-05, Min w: 0.9127846360206604\n",
      "Iteration 990, Loss: 3.902456955984235e-05, Min w: 0.8826420307159424\n",
      "Iteration 1000, Loss: 3.298980664112605e-05, Min w: 0.9265250563621521\n",
      "Iteration 1010, Loss: 2.9198043193900958e-05, Min w: 0.9282592535018921\n",
      "Iteration 1020, Loss: 6.57293203403242e-05, Min w: 0.7891892790794373\n",
      "Iteration 1030, Loss: 7.975184416864067e-05, Min w: 0.818850576877594\n",
      "Iteration 1040, Loss: 5.712467464036308e-05, Min w: 0.8128424882888794\n",
      "Iteration 1050, Loss: 5.288354441290721e-05, Min w: 0.8657549023628235\n",
      "Iteration 1060, Loss: 4.620875188265927e-05, Min w: 0.8624415993690491\n",
      "Iteration 1070, Loss: 5.6483997468603775e-05, Min w: 0.8247219324111938\n",
      "Iteration 1080, Loss: 5.4728094255551696e-05, Min w: 0.8462432026863098\n",
      "Iteration 1090, Loss: 2.57961200986756e-05, Min w: 0.9386522173881531\n",
      "Iteration 1100, Loss: 3.252951864851639e-05, Min w: 0.8997668623924255\n",
      "Iteration 1110, Loss: 6.579035107279196e-05, Min w: 0.7809925675392151\n",
      "Iteration 1120, Loss: 5.217281068325974e-05, Min w: 0.8929048180580139\n",
      "Iteration 1130, Loss: 4.289333810447715e-05, Min w: 0.9097499251365662\n",
      "Iteration 1140, Loss: 6.739697710145265e-05, Min w: 0.8137819170951843\n",
      "Iteration 1150, Loss: 6.16900360910222e-05, Min w: 0.8242018818855286\n",
      "Iteration 1160, Loss: 1.3653460882778745e-05, Min w: 0.9707028269767761\n",
      "Iteration 1170, Loss: 2.4715665858821012e-05, Min w: 0.926821768283844\n",
      "Iteration 1180, Loss: 5.0405571528244764e-05, Min w: 0.881377637386322\n",
      "Iteration 1190, Loss: 4.040338899358176e-05, Min w: 0.8655203580856323\n",
      "Iteration 1200, Loss: 4.4092921598348767e-05, Min w: 0.8730056881904602\n",
      "Iteration 1210, Loss: 4.1223280277336016e-05, Min w: 0.8775830268859863\n",
      "Iteration 1220, Loss: 3.1760817364556715e-05, Min w: 0.9168120622634888\n",
      "Iteration 1230, Loss: 2.5996654585469514e-05, Min w: 0.9367935061454773\n",
      "Iteration 1240, Loss: 4.0347251342609525e-05, Min w: 0.8941205739974976\n",
      "Iteration 0, Loss: 9.594232687959448e-05, Min w: 0.7019833326339722\n",
      "Iteration 10, Loss: 7.446869130944833e-05, Min w: 0.8001387119293213\n",
      "Iteration 20, Loss: 2.0792425857507624e-05, Min w: 0.9463366866111755\n",
      "Iteration 30, Loss: 2.8157128326711245e-05, Min w: 0.9129278063774109\n",
      "Iteration 40, Loss: 4.0976905438583344e-05, Min w: 0.8946724534034729\n",
      "Iteration 50, Loss: 4.204520155326463e-05, Min w: 0.9002672433853149\n",
      "Iteration 60, Loss: 3.137049134238623e-05, Min w: 0.9274884462356567\n",
      "Iteration 70, Loss: 4.5770957513013855e-05, Min w: 0.8722682595252991\n",
      "Iteration 80, Loss: 3.810480848187581e-05, Min w: 0.8771935105323792\n",
      "Iteration 90, Loss: 4.036315658595413e-05, Min w: 0.8979777097702026\n",
      "Iteration 100, Loss: 6.355906225508079e-05, Min w: 0.8332344889640808\n",
      "Iteration 110, Loss: 5.350771971279755e-05, Min w: 0.822277307510376\n",
      "Iteration 120, Loss: 2.241403672087472e-05, Min w: 0.9527422189712524\n",
      "Iteration 130, Loss: 3.420328357606195e-05, Min w: 0.9037604331970215\n",
      "Iteration 140, Loss: 4.3236246710876e-05, Min w: 0.8958536386489868\n",
      "Iteration 150, Loss: 5.058952228864655e-05, Min w: 0.8819449543952942\n",
      "Iteration 160, Loss: 3.380676207598299e-05, Min w: 0.8941857814788818\n",
      "Iteration 170, Loss: 3.83970036637038e-05, Min w: 0.8911313414573669\n",
      "Iteration 180, Loss: 2.7411711926106364e-05, Min w: 0.909107506275177\n",
      "Iteration 190, Loss: 3.9873833884485066e-05, Min w: 0.8853811025619507\n",
      "Iteration 200, Loss: 5.4121806897455826e-05, Min w: 0.8650041818618774\n",
      "Iteration 210, Loss: 4.9387799663236365e-05, Min w: 0.8720312118530273\n",
      "Iteration 220, Loss: 4.965435073245317e-05, Min w: 0.8400307297706604\n",
      "Iteration 230, Loss: 4.5160653826314956e-05, Min w: 0.8710346817970276\n",
      "Iteration 240, Loss: 3.748559902305715e-05, Min w: 0.8848658204078674\n",
      "Iteration 250, Loss: 2.190972190874163e-05, Min w: 0.9335944056510925\n",
      "Iteration 260, Loss: 1.3925734492659103e-05, Min w: 0.9708000421524048\n",
      "Iteration 270, Loss: 3.6265209928387776e-05, Min w: 0.8856427669525146\n",
      "Iteration 280, Loss: 3.531031325110234e-05, Min w: 0.9046310782432556\n",
      "Iteration 290, Loss: 4.7053054004209116e-05, Min w: 0.8555005192756653\n",
      "Iteration 300, Loss: 1.0206228580500465e-05, Min w: 0.9785625338554382\n",
      "Iteration 310, Loss: 4.675870877690613e-05, Min w: 0.8877751231193542\n",
      "Iteration 320, Loss: 3.510454553179443e-05, Min w: 0.8798936009407043\n",
      "Iteration 330, Loss: 5.893642810406163e-05, Min w: 0.8458422422409058\n",
      "Iteration 340, Loss: 5.905596481170505e-05, Min w: 0.8645754456520081\n",
      "Iteration 350, Loss: 1.467825859435834e-05, Min w: 0.9621596336364746\n",
      "Iteration 360, Loss: 1.8256485418532975e-05, Min w: 0.9488536715507507\n",
      "Iteration 370, Loss: 3.5511930036591366e-05, Min w: 0.9130957722663879\n",
      "Iteration 380, Loss: 3.036372254427988e-05, Min w: 0.9357760548591614\n",
      "Iteration 390, Loss: 2.456818037899211e-05, Min w: 0.9211885333061218\n",
      "Iteration 400, Loss: 2.5833483960013837e-05, Min w: 0.9180393815040588\n",
      "Iteration 410, Loss: 4.8159465222852305e-05, Min w: 0.8935728669166565\n",
      "Iteration 420, Loss: 3.96384930354543e-05, Min w: 0.8660376667976379\n",
      "Iteration 430, Loss: 5.1485949370544404e-05, Min w: 0.8708934187889099\n",
      "Iteration 440, Loss: 4.914668534183875e-05, Min w: 0.848514199256897\n",
      "Iteration 450, Loss: 4.002572313765995e-05, Min w: 0.8761958479881287\n",
      "Iteration 460, Loss: 4.291442746762186e-05, Min w: 0.8590708374977112\n",
      "Iteration 470, Loss: 1.870064079412259e-05, Min w: 0.9499465227127075\n",
      "Iteration 480, Loss: 1.2109439012419898e-05, Min w: 0.9695453643798828\n",
      "Iteration 490, Loss: 1.948166755028069e-05, Min w: 0.9439697265625\n",
      "Iteration 500, Loss: 4.0312952478416264e-05, Min w: 0.8785844445228577\n",
      "Iteration 510, Loss: 4.169899693806656e-05, Min w: 0.8694985508918762\n",
      "Iteration 520, Loss: 1.3946025319455657e-05, Min w: 0.9621732234954834\n",
      "Iteration 530, Loss: 1.900696224765852e-05, Min w: 0.9568372964859009\n",
      "Iteration 540, Loss: 3.4007371141342446e-05, Min w: 0.9271585941314697\n",
      "Iteration 550, Loss: 1.2760366189468186e-05, Min w: 0.9703362584114075\n",
      "Iteration 560, Loss: 1.4112380085862242e-05, Min w: 0.962128758430481\n",
      "Iteration 570, Loss: 2.5941251806216314e-05, Min w: 0.9173787236213684\n",
      "Iteration 580, Loss: 6.357013626256958e-05, Min w: 0.8454036116600037\n",
      "Iteration 590, Loss: 4.4590833567781374e-05, Min w: 0.8393657803535461\n",
      "Iteration 600, Loss: 3.692750397021882e-05, Min w: 0.8718152046203613\n",
      "Iteration 610, Loss: 5.313693327479996e-05, Min w: 0.83647221326828\n",
      "Iteration 620, Loss: 4.090459333383478e-05, Min w: 0.9021016955375671\n",
      "Iteration 630, Loss: 2.5164945327560417e-05, Min w: 0.9439437985420227\n",
      "Iteration 640, Loss: 2.018147824855987e-05, Min w: 0.9316635131835938\n",
      "Iteration 650, Loss: 1.5835719750612043e-05, Min w: 0.9536870718002319\n",
      "Iteration 660, Loss: 2.691647932806518e-05, Min w: 0.934579610824585\n",
      "Iteration 670, Loss: 3.378954352228902e-05, Min w: 0.8871407508850098\n",
      "Iteration 680, Loss: 1.8615090084495023e-05, Min w: 0.948151707649231\n",
      "Iteration 690, Loss: 3.308641680632718e-05, Min w: 0.9132630228996277\n",
      "Iteration 700, Loss: 5.331797001417726e-05, Min w: 0.8223429918289185\n",
      "Iteration 710, Loss: 3.092171755270101e-05, Min w: 0.9010137319564819\n",
      "Iteration 720, Loss: 3.787367677432485e-05, Min w: 0.9059948921203613\n",
      "Iteration 730, Loss: 3.6036708479514346e-05, Min w: 0.9046979546546936\n",
      "Iteration 740, Loss: 8.87191799847642e-06, Min w: 0.9792357683181763\n",
      "Iteration 750, Loss: 3.350439146743156e-05, Min w: 0.8882311582565308\n",
      "Iteration 760, Loss: 3.3042113500414416e-05, Min w: 0.9294084310531616\n",
      "Iteration 770, Loss: 5.0418577302480116e-05, Min w: 0.8910219669342041\n",
      "Iteration 780, Loss: 2.996746843564324e-05, Min w: 0.8958696722984314\n",
      "Iteration 790, Loss: 1.1704185453709215e-05, Min w: 0.9642903208732605\n",
      "Iteration 800, Loss: 2.6596053430694155e-05, Min w: 0.9427626729011536\n",
      "Iteration 810, Loss: 4.9563601351110265e-05, Min w: 0.8405000567436218\n",
      "Iteration 820, Loss: 2.7919517378904857e-05, Min w: 0.9220685362815857\n",
      "Iteration 830, Loss: 2.727913852140773e-05, Min w: 0.9210761785507202\n",
      "Iteration 840, Loss: 2.249254976049997e-05, Min w: 0.947115421295166\n",
      "Iteration 850, Loss: 2.2053762222640216e-05, Min w: 0.945621907711029\n",
      "Iteration 860, Loss: 4.054792952956632e-05, Min w: 0.864357054233551\n",
      "Iteration 870, Loss: 1.7280346582992934e-05, Min w: 0.9577245712280273\n",
      "Iteration 880, Loss: 3.288258085376583e-05, Min w: 0.9147248864173889\n",
      "Iteration 890, Loss: 2.8461834517656825e-05, Min w: 0.9028353691101074\n",
      "Iteration 900, Loss: 1.9698971300385892e-05, Min w: 0.9377188682556152\n",
      "Iteration 910, Loss: 5.247802255325951e-05, Min w: 0.8838234543800354\n",
      "Iteration 920, Loss: 1.722091474221088e-05, Min w: 0.9527360796928406\n",
      "Iteration 930, Loss: 1.9929371774196625e-05, Min w: 0.951557993888855\n",
      "Iteration 940, Loss: 1.177733520307811e-05, Min w: 0.9707090854644775\n",
      "Iteration 950, Loss: 2.9992519557708874e-05, Min w: 0.9013485312461853\n",
      "Iteration 960, Loss: 4.838444874621928e-05, Min w: 0.8783501982688904\n",
      "Iteration 970, Loss: 4.872932186117396e-05, Min w: 0.8535565137863159\n",
      "Iteration 980, Loss: 3.311612090328708e-05, Min w: 0.8848495483398438\n",
      "Iteration 990, Loss: 4.875575905316509e-05, Min w: 0.8501256108283997\n",
      "Iteration 1000, Loss: 3.345162986079231e-05, Min w: 0.9137903451919556\n",
      "Iteration 1010, Loss: 1.6807349311420694e-05, Min w: 0.9459978938102722\n",
      "Iteration 1020, Loss: 1.7403075617039576e-05, Min w: 0.9628810882568359\n",
      "Iteration 1030, Loss: 2.973391929117497e-05, Min w: 0.8980922698974609\n",
      "Iteration 1040, Loss: 2.0963399947504513e-05, Min w: 0.9535707831382751\n",
      "Iteration 1050, Loss: 2.255316030641552e-05, Min w: 0.9419891238212585\n",
      "Iteration 1060, Loss: 1.8678498236113228e-05, Min w: 0.9602975249290466\n",
      "Iteration 1070, Loss: 2.666159525688272e-05, Min w: 0.93775874376297\n",
      "Iteration 1080, Loss: 4.6856763219693676e-05, Min w: 0.855231523513794\n",
      "Iteration 1090, Loss: 2.6436604457558133e-05, Min w: 0.9282268285751343\n",
      "Iteration 1100, Loss: 3.383204966667108e-05, Min w: 0.8860265612602234\n",
      "Iteration 1110, Loss: 4.144538615946658e-05, Min w: 0.8896220326423645\n",
      "Iteration 1120, Loss: 2.056943776551634e-05, Min w: 0.9547948837280273\n",
      "Iteration 1130, Loss: 2.3358905309578404e-05, Min w: 0.9323258399963379\n",
      "Iteration 1140, Loss: 4.9770074838306755e-05, Min w: 0.8454701900482178\n",
      "Iteration 1150, Loss: 1.644520125410054e-05, Min w: 0.9554511904716492\n",
      "Iteration 1160, Loss: 2.6914414775092155e-05, Min w: 0.9185522198677063\n",
      "Iteration 1170, Loss: 2.5004279450513422e-05, Min w: 0.912925124168396\n",
      "Iteration 1180, Loss: 2.562745794421062e-05, Min w: 0.9374371767044067\n",
      "Iteration 1190, Loss: 2.9470835215761326e-05, Min w: 0.9310758113861084\n",
      "Iteration 1200, Loss: 1.6402707842644304e-05, Min w: 0.9638839960098267\n",
      "Iteration 1210, Loss: 5.38481144758407e-05, Min w: 0.8850739002227783\n",
      "Iteration 1220, Loss: 2.971471803903114e-05, Min w: 0.9004256129264832\n",
      "Iteration 1230, Loss: 2.9506960345315747e-05, Min w: 0.9354123473167419\n",
      "Iteration 1240, Loss: 2.477967063896358e-05, Min w: 0.9252539873123169\n",
      "Iteration 0, Loss: 2.5487670427537523e-05, Min w: 0.912813663482666\n",
      "Iteration 10, Loss: 1.1766428542614449e-05, Min w: 0.972331166267395\n",
      "Iteration 20, Loss: 4.11176988563966e-05, Min w: 0.9053458571434021\n",
      "Iteration 30, Loss: 1.9723320292541757e-05, Min w: 0.9297894239425659\n",
      "Iteration 40, Loss: 2.4035944079514593e-05, Min w: 0.9356831312179565\n",
      "Iteration 50, Loss: 2.6492127290111966e-05, Min w: 0.9356637597084045\n",
      "Iteration 60, Loss: 2.205999771831557e-05, Min w: 0.9283187985420227\n",
      "Iteration 70, Loss: 7.98418386693811e-06, Min w: 0.9760569334030151\n",
      "Iteration 80, Loss: 3.1168114219326526e-05, Min w: 0.9335640072822571\n",
      "Iteration 90, Loss: 2.7935015168623067e-05, Min w: 0.9023401141166687\n",
      "Iteration 100, Loss: 7.072304470057134e-06, Min w: 0.9847486019134521\n",
      "Iteration 110, Loss: 1.7578389815753326e-05, Min w: 0.9390988349914551\n",
      "Iteration 120, Loss: 4.353159965830855e-05, Min w: 0.9022413492202759\n",
      "Iteration 130, Loss: 1.3224664144217968e-05, Min w: 0.9562399983406067\n",
      "Iteration 140, Loss: 2.9696868296014145e-05, Min w: 0.9161462187767029\n",
      "Iteration 150, Loss: 4.02930672862567e-05, Min w: 0.8760116696357727\n",
      "Iteration 160, Loss: 2.1368472516769543e-05, Min w: 0.9481767416000366\n",
      "Iteration 170, Loss: 5.241511462372728e-05, Min w: 0.8611934185028076\n",
      "Iteration 180, Loss: 3.895895861205645e-05, Min w: 0.8900715112686157\n",
      "Iteration 190, Loss: 5.251086986390874e-05, Min w: 0.865463137626648\n",
      "Iteration 200, Loss: 4.0983144572237507e-05, Min w: 0.9001980423927307\n",
      "Iteration 210, Loss: 2.8335136448731646e-05, Min w: 0.9136456847190857\n",
      "Iteration 220, Loss: 3.1497576856054366e-05, Min w: 0.8906282186508179\n",
      "Iteration 230, Loss: 7.0222181420831475e-06, Min w: 0.9823884963989258\n",
      "Iteration 240, Loss: 2.0812180082430132e-05, Min w: 0.9536416530609131\n",
      "Iteration 250, Loss: 2.7233587388764136e-05, Min w: 0.909273624420166\n",
      "Iteration 260, Loss: 2.4164599381037988e-05, Min w: 0.948457658290863\n",
      "Iteration 270, Loss: 1.952451202669181e-05, Min w: 0.9482598900794983\n",
      "Iteration 280, Loss: 1.4665294656879269e-05, Min w: 0.9671046137809753\n",
      "Iteration 290, Loss: 4.716829062090255e-05, Min w: 0.8717064261436462\n",
      "Iteration 300, Loss: 4.6070825192146e-05, Min w: 0.88754802942276\n",
      "Iteration 310, Loss: 3.2433239539386705e-05, Min w: 0.9332431554794312\n",
      "Iteration 320, Loss: 3.704940536408685e-05, Min w: 0.8860416412353516\n",
      "Iteration 330, Loss: 7.038349849608494e-06, Min w: 0.9804092049598694\n",
      "Iteration 340, Loss: 2.9522814656957053e-05, Min w: 0.9100834727287292\n",
      "Iteration 350, Loss: 4.280596840544604e-05, Min w: 0.8952218294143677\n",
      "Iteration 360, Loss: 1.4577229194401298e-05, Min w: 0.9621659517288208\n",
      "Iteration 370, Loss: 2.4406928787357174e-05, Min w: 0.9320083856582642\n",
      "Iteration 380, Loss: 2.3776095986249857e-05, Min w: 0.9333422183990479\n",
      "Iteration 390, Loss: 9.58795499172993e-06, Min w: 0.9760886430740356\n",
      "Iteration 400, Loss: 3.082721013925038e-05, Min w: 0.9277390837669373\n",
      "Iteration 410, Loss: 2.607916212582495e-05, Min w: 0.9173756837844849\n",
      "Iteration 420, Loss: 3.275731796748005e-05, Min w: 0.9148266315460205\n",
      "Iteration 430, Loss: 1.2874166714027524e-05, Min w: 0.9592763185501099\n",
      "Iteration 440, Loss: 1.4292135347204749e-05, Min w: 0.9612184166908264\n",
      "Iteration 450, Loss: 3.2905092666624114e-05, Min w: 0.8834599256515503\n",
      "Iteration 460, Loss: 3.806464155786671e-05, Min w: 0.890723466873169\n",
      "Iteration 470, Loss: 4.861428533331491e-05, Min w: 0.8616798520088196\n",
      "Iteration 480, Loss: 4.4002670620102435e-05, Min w: 0.8620743155479431\n",
      "Iteration 490, Loss: 1.427598181180656e-05, Min w: 0.9535648226737976\n",
      "Iteration 500, Loss: 1.0856050721486099e-05, Min w: 0.9713104367256165\n",
      "Iteration 510, Loss: 4.875537706539035e-05, Min w: 0.8717579245567322\n",
      "Iteration 520, Loss: 7.614613878104137e-06, Min w: 0.9802606701850891\n",
      "Iteration 530, Loss: 2.88109113171231e-05, Min w: 0.9193931221961975\n",
      "Iteration 540, Loss: 2.0649871657951735e-05, Min w: 0.9504156708717346\n",
      "Iteration 550, Loss: 1.6249226973741315e-05, Min w: 0.956857442855835\n",
      "Iteration 560, Loss: 3.8356170989573e-05, Min w: 0.9191004633903503\n",
      "Iteration 570, Loss: 3.0106915801297873e-05, Min w: 0.9210888147354126\n",
      "Iteration 580, Loss: 5.527349003386917e-06, Min w: 0.9866845011711121\n",
      "Iteration 590, Loss: 4.607152004609816e-05, Min w: 0.8741676211357117\n",
      "Iteration 600, Loss: 2.2893284040037543e-05, Min w: 0.9526565074920654\n",
      "Iteration 610, Loss: 3.111643309239298e-05, Min w: 0.9190763235092163\n",
      "Iteration 620, Loss: 1.0821378964465111e-05, Min w: 0.9742919206619263\n",
      "Iteration 630, Loss: 2.319799932593014e-05, Min w: 0.9196276068687439\n",
      "Iteration 640, Loss: 1.1999294656561688e-05, Min w: 0.9753533005714417\n",
      "Iteration 650, Loss: 3.3112053642980754e-05, Min w: 0.896047055721283\n",
      "Iteration 660, Loss: 1.503167277405737e-05, Min w: 0.9648026823997498\n",
      "Iteration 670, Loss: 5.4623833420919254e-05, Min w: 0.8733447194099426\n",
      "Iteration 680, Loss: 1.9615872588474303e-05, Min w: 0.9413904547691345\n",
      "Iteration 690, Loss: 1.4862768694001716e-05, Min w: 0.9532086253166199\n",
      "Iteration 700, Loss: 2.3708800654276274e-05, Min w: 0.9244903326034546\n",
      "Iteration 710, Loss: 2.8537868274725042e-05, Min w: 0.9238944053649902\n",
      "Iteration 720, Loss: 2.957371179945767e-05, Min w: 0.9093083739280701\n",
      "Iteration 730, Loss: 1.4467987057287246e-05, Min w: 0.95206218957901\n",
      "Iteration 740, Loss: 2.6576442905934528e-05, Min w: 0.9401158094406128\n",
      "Iteration 750, Loss: 4.348601578385569e-05, Min w: 0.8553104400634766\n",
      "Iteration 760, Loss: 3.548279346432537e-05, Min w: 0.923987090587616\n",
      "Iteration 770, Loss: 1.9509458070388064e-05, Min w: 0.9468376636505127\n",
      "Iteration 780, Loss: 7.737653504591435e-06, Min w: 0.9808030128479004\n",
      "Iteration 790, Loss: 5.3477557230507955e-05, Min w: 0.8473289608955383\n",
      "Iteration 800, Loss: 2.3413183953380212e-05, Min w: 0.9279003143310547\n",
      "Iteration 810, Loss: 3.011839544342365e-05, Min w: 0.9125798940658569\n",
      "Iteration 820, Loss: 2.8069987820344977e-05, Min w: 0.9403009414672852\n",
      "Iteration 830, Loss: 9.879737262963317e-06, Min w: 0.9762226939201355\n",
      "Iteration 840, Loss: 2.619097904243972e-05, Min w: 0.9447572827339172\n",
      "Iteration 850, Loss: 2.387286258453969e-05, Min w: 0.92441725730896\n",
      "Iteration 860, Loss: 3.654305328382179e-05, Min w: 0.9175891280174255\n",
      "Iteration 870, Loss: 3.64565166819375e-05, Min w: 0.8675439953804016\n",
      "Iteration 880, Loss: 2.1590922187897377e-05, Min w: 0.9335917234420776\n",
      "Iteration 890, Loss: 1.4132676369627006e-05, Min w: 0.9667280912399292\n",
      "Iteration 900, Loss: 2.620089435367845e-05, Min w: 0.9202873706817627\n",
      "Iteration 910, Loss: 3.361699418746866e-05, Min w: 0.9089855551719666\n",
      "Iteration 920, Loss: 2.282122841279488e-05, Min w: 0.9450713396072388\n",
      "Iteration 930, Loss: 3.950553582399152e-05, Min w: 0.8949794769287109\n",
      "Iteration 940, Loss: 1.1799831554526463e-05, Min w: 0.9744359850883484\n",
      "Iteration 950, Loss: 1.5896896002232097e-05, Min w: 0.946249783039093\n",
      "Iteration 960, Loss: 9.21998707781313e-06, Min w: 0.981063187122345\n",
      "Iteration 970, Loss: 2.6967782105202787e-05, Min w: 0.9094711542129517\n",
      "Iteration 980, Loss: 2.7055599275627173e-05, Min w: 0.926798939704895\n",
      "Iteration 990, Loss: 3.0331990274135023e-05, Min w: 0.9270147085189819\n",
      "Iteration 1000, Loss: 2.5545017706463113e-05, Min w: 0.941545844078064\n",
      "Iteration 1010, Loss: 2.5951658244594e-05, Min w: 0.9167189002037048\n",
      "Iteration 1020, Loss: 2.1548692529904656e-05, Min w: 0.9504429697990417\n",
      "Iteration 1030, Loss: 2.940047488664277e-05, Min w: 0.8955638408660889\n",
      "Iteration 1040, Loss: 3.0787028663326055e-05, Min w: 0.9070831537246704\n",
      "Iteration 1050, Loss: 2.3477943614125252e-05, Min w: 0.931756854057312\n",
      "Iteration 1060, Loss: 4.733865716843866e-05, Min w: 0.8599366545677185\n",
      "Iteration 1070, Loss: 3.816009848378599e-05, Min w: 0.9144017696380615\n",
      "Iteration 1080, Loss: 2.168065111618489e-05, Min w: 0.9516609907150269\n",
      "Iteration 1090, Loss: 2.2014539354131557e-05, Min w: 0.937730073928833\n",
      "Iteration 1100, Loss: 6.60258319840068e-06, Min w: 0.9818164706230164\n",
      "Iteration 1110, Loss: 1.64315351867117e-05, Min w: 0.9404160976409912\n",
      "Iteration 1120, Loss: 1.8298484064871445e-05, Min w: 0.9539011716842651\n",
      "Iteration 1130, Loss: 3.539286626619287e-05, Min w: 0.914714515209198\n",
      "Iteration 1140, Loss: 1.090421028493438e-05, Min w: 0.9755247235298157\n",
      "Iteration 1150, Loss: 3.144971196888946e-05, Min w: 0.892673909664154\n",
      "Iteration 1160, Loss: 5.7148965424858034e-05, Min w: 0.8726861476898193\n",
      "Iteration 1170, Loss: 4.08693085773848e-05, Min w: 0.8724888563156128\n",
      "Iteration 1180, Loss: 4.412268754094839e-05, Min w: 0.861386775970459\n",
      "Iteration 1190, Loss: 1.2178938959550578e-05, Min w: 0.9694481492042542\n",
      "Iteration 1200, Loss: 2.005634996748995e-05, Min w: 0.9478793144226074\n",
      "Iteration 1210, Loss: 2.914185097324662e-05, Min w: 0.9266038537025452\n",
      "Iteration 1220, Loss: 3.857159390463494e-05, Min w: 0.8681427836418152\n",
      "Iteration 1230, Loss: 1.4790465684200171e-05, Min w: 0.9687839150428772\n",
      "Iteration 1240, Loss: 2.1803900381200947e-05, Min w: 0.9421451091766357\n",
      "Iteration 0, Loss: 1.2948138646606822e-05, Min w: 0.9562781453132629\n",
      "Iteration 10, Loss: 2.9618102416861802e-05, Min w: 0.9148602485656738\n",
      "Iteration 20, Loss: 1.9754941604333e-05, Min w: 0.9539862275123596\n",
      "Iteration 30, Loss: 2.0810181013075635e-05, Min w: 0.9315947890281677\n",
      "Iteration 40, Loss: 3.620178540586494e-05, Min w: 0.9152977466583252\n",
      "Iteration 50, Loss: 9.10732978809392e-06, Min w: 0.9756482839584351\n",
      "Iteration 60, Loss: 1.7282100088777952e-05, Min w: 0.9549222588539124\n",
      "Iteration 70, Loss: 2.1506535631488077e-05, Min w: 0.9516847133636475\n",
      "Iteration 80, Loss: 4.027322574984282e-05, Min w: 0.9030136466026306\n",
      "Iteration 90, Loss: 3.935531640308909e-05, Min w: 0.8864796757698059\n",
      "Iteration 100, Loss: 3.370031845406629e-05, Min w: 0.9226976633071899\n",
      "Iteration 110, Loss: 3.2883312087506056e-05, Min w: 0.9138374328613281\n",
      "Iteration 120, Loss: 3.788345566135831e-05, Min w: 0.9156498908996582\n",
      "Iteration 130, Loss: 9.646217222325504e-06, Min w: 0.9786576628684998\n",
      "Iteration 140, Loss: 2.7080393920186907e-05, Min w: 0.9161334037780762\n",
      "Iteration 150, Loss: 2.537629916332662e-05, Min w: 0.9092590808868408\n",
      "Iteration 160, Loss: 1.797774530132301e-05, Min w: 0.9534677863121033\n",
      "Iteration 170, Loss: 1.791595423128456e-05, Min w: 0.9475277662277222\n",
      "Iteration 180, Loss: 1.3901963939133566e-05, Min w: 0.96382075548172\n",
      "Iteration 190, Loss: 3.8070324080763385e-05, Min w: 0.8830371499061584\n",
      "Iteration 200, Loss: 1.436900220141979e-05, Min w: 0.9597390294075012\n",
      "Iteration 210, Loss: 2.643302832439076e-05, Min w: 0.9291098117828369\n",
      "Iteration 220, Loss: 1.838004209275823e-05, Min w: 0.9523717761039734\n",
      "Iteration 230, Loss: 1.550222259538714e-05, Min w: 0.9619192481040955\n",
      "Iteration 240, Loss: 7.0254268393910024e-06, Min w: 0.9847183227539062\n",
      "Iteration 250, Loss: 2.596693957457319e-05, Min w: 0.9195079207420349\n",
      "Iteration 260, Loss: 2.4816952645778656e-05, Min w: 0.9256265759468079\n",
      "Iteration 270, Loss: 3.317752270959318e-05, Min w: 0.8908087611198425\n",
      "Iteration 280, Loss: 7.34789136913605e-06, Min w: 0.9795263409614563\n",
      "Iteration 290, Loss: 1.3151507118891459e-05, Min w: 0.9695639610290527\n",
      "Iteration 300, Loss: 2.40104000113206e-05, Min w: 0.9257217049598694\n",
      "Iteration 310, Loss: 2.529507219151128e-05, Min w: 0.9176191687583923\n",
      "Iteration 320, Loss: 1.5846508176764473e-05, Min w: 0.9661226272583008\n",
      "Iteration 330, Loss: 1.710868855298031e-05, Min w: 0.9417253732681274\n",
      "Iteration 340, Loss: 2.8716791348415427e-05, Min w: 0.902338445186615\n",
      "Iteration 350, Loss: 2.522329486964736e-05, Min w: 0.9316380023956299\n",
      "Iteration 360, Loss: 4.349861410446465e-05, Min w: 0.877353310585022\n",
      "Iteration 370, Loss: 2.547540316300001e-05, Min w: 0.925698459148407\n",
      "Iteration 380, Loss: 5.053386303188745e-06, Min w: 0.9874988198280334\n",
      "Iteration 390, Loss: 5.546954707824625e-05, Min w: 0.8693312406539917\n",
      "Iteration 400, Loss: 2.5203531549777836e-05, Min w: 0.9473597407341003\n",
      "Iteration 410, Loss: 2.3338079699897207e-05, Min w: 0.9312756061553955\n",
      "Iteration 420, Loss: 2.256173684145324e-05, Min w: 0.9340808391571045\n",
      "Iteration 430, Loss: 7.812127478246111e-06, Min w: 0.9832435250282288\n",
      "Iteration 440, Loss: 3.368578109075315e-05, Min w: 0.8998831510543823\n",
      "Iteration 450, Loss: 2.5079198167077266e-05, Min w: 0.9376853704452515\n",
      "Iteration 460, Loss: 1.1548910151759628e-05, Min w: 0.9724902510643005\n",
      "Iteration 470, Loss: 1.05120916487067e-05, Min w: 0.9733132123947144\n",
      "Iteration 480, Loss: 2.6870891815633513e-05, Min w: 0.9126757979393005\n",
      "Iteration 490, Loss: 1.6355868865502998e-05, Min w: 0.9581862688064575\n",
      "Iteration 500, Loss: 1.3058718650427181e-05, Min w: 0.9598300457000732\n",
      "Iteration 510, Loss: 1.7632719391258433e-05, Min w: 0.9473346471786499\n",
      "Iteration 520, Loss: 3.355884473421611e-05, Min w: 0.9231008291244507\n",
      "Iteration 530, Loss: 3.0759485525777563e-05, Min w: 0.891848623752594\n",
      "Iteration 540, Loss: 1.4782428479520604e-05, Min w: 0.9598597884178162\n",
      "Iteration 550, Loss: 2.095511445077136e-05, Min w: 0.9263635277748108\n",
      "Iteration 560, Loss: 1.969429104065057e-05, Min w: 0.9458873867988586\n",
      "Iteration 570, Loss: 1.189831891679205e-05, Min w: 0.966530978679657\n",
      "Iteration 580, Loss: 1.8436743630445562e-05, Min w: 0.9420539736747742\n",
      "Iteration 590, Loss: 1.4923480193829164e-05, Min w: 0.9544287919998169\n",
      "Iteration 600, Loss: 1.3121134543325752e-05, Min w: 0.9663640856742859\n",
      "Iteration 610, Loss: 3.233501047361642e-05, Min w: 0.9332348704338074\n",
      "Iteration 620, Loss: 2.648223380674608e-05, Min w: 0.9253188371658325\n",
      "Iteration 630, Loss: 1.785126733011566e-05, Min w: 0.9414473176002502\n",
      "Iteration 640, Loss: 6.0966212913626805e-06, Min w: 0.986849844455719\n",
      "Iteration 650, Loss: 3.139978798571974e-05, Min w: 0.9001612067222595\n",
      "Iteration 660, Loss: 1.069491554517299e-05, Min w: 0.9774930477142334\n",
      "Iteration 670, Loss: 1.8081771486322396e-05, Min w: 0.9562979936599731\n",
      "Iteration 680, Loss: 8.423572580795735e-06, Min w: 0.9811118245124817\n",
      "Iteration 690, Loss: 2.7149881134391762e-05, Min w: 0.9180616736412048\n",
      "Iteration 700, Loss: 3.893958273692988e-05, Min w: 0.9110994338989258\n",
      "Iteration 710, Loss: 4.489673301577568e-05, Min w: 0.9006877541542053\n",
      "Iteration 720, Loss: 3.2902815291890875e-05, Min w: 0.9079927206039429\n",
      "Iteration 730, Loss: 1.4093143363425042e-05, Min w: 0.9604947566986084\n",
      "Iteration 740, Loss: 9.852429684542585e-06, Min w: 0.9781628847122192\n",
      "Iteration 750, Loss: 4.1541738028172404e-05, Min w: 0.8959306478500366\n",
      "Iteration 760, Loss: 2.2807522327639163e-05, Min w: 0.9463990926742554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP: 100%|██████████| 24/24 [19:29<00:00, 48.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 770, Loss: 5.0148369155067485e-06, Min w: 0.9893558025360107\n",
      "Iteration 780, Loss: 3.868332896672655e-06, Min w: 0.9911081790924072\n",
      "Early break at iteration 780 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 5781, 'ODE': 'Van der Pol Oscillator', 'ODE_dim': 2, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.006988707848306857, 'L2_avg': 0.011191254474987476, 'End_point_L1_avg': 0.0023477618157688646, 'End_point_L2_avg': 0.002827295452073066}\n",
      "Testing Simplified 15D Linear System\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.12122781574726105\n",
      "Iteration 10, Loss: 0.004071155562996864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   4%|▍         | 1/24 [00:00<00:06,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 0.0015384810976684093\n",
      "Stopping early at iteration 22\n",
      "{'Model': 'PINN base', 'Total_Iterations': 23, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.043607877441934964, 'L2_avg': 0.04708812745145431, 'End_point_L1_avg': 0.04743243821229722, 'End_point_L2_avg': 0.05780936791278956}\n",
      "Iteration 0, Loss: 0.1567479521036148\n",
      "Iteration 10, Loss: 0.005936402827501297\n",
      "Iteration 20, Loss: 0.0021684332750737667\n",
      "Iteration 30, Loss: 0.0006718360236845911\n",
      "Iteration 40, Loss: 0.0003336032968945801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:   8%|▊         | 2/24 [00:00<00:08,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, Loss: 0.00011622076999628916\n",
      "Stopping early at iteration 51\n",
      "{'Model': 'PINN base', 'Total_Iterations': 52, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013896987458680836, 'L2_avg': 0.0175914643312063, 'End_point_L1_avg': 0.011241919983288762, 'End_point_L2_avg': 0.013406645070972336}\n",
      "Iteration 0, Loss: 0.11555702984333038\n",
      "Iteration 10, Loss: 0.0053162723779678345\n",
      "Iteration 20, Loss: 0.0011780199129134417\n",
      "Stopping early at iteration 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  12%|█▎        | 3/24 [00:01<00:08,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 25, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04090677687024833, 'L2_avg': 0.04374229009764627, 'End_point_L1_avg': 0.040605866543201606, 'End_point_L2_avg': 0.04778472309108791}\n",
      "Iteration 0, Loss: 0.11310749500989914\n",
      "Iteration 10, Loss: 0.004287906922399998\n",
      "Iteration 20, Loss: 0.0006847225595265627\n",
      "Iteration 30, Loss: 0.0003457673010416329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  17%|█▋        | 4/24 [00:01<00:09,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, Loss: 0.0002348338603042066\n",
      "Stopping early at iteration 44\n",
      "{'Model': 'PINN base', 'Total_Iterations': 45, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.015216935556845047, 'L2_avg': 0.01757922629412524, 'End_point_L1_avg': 0.01454961591128583, 'End_point_L2_avg': 0.01834043159015162}\n",
      "Iteration 0, Loss: 0.13925780355930328\n",
      "Iteration 10, Loss: 0.028281990438699722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  21%|██        | 5/24 [00:02<00:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 0.0021507723722606897\n",
      "Iteration 30, Loss: 0.002564081223681569\n",
      "Stopping early at iteration 34\n",
      "{'Model': 'PINN base', 'Total_Iterations': 35, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.034671395050828904, 'L2_avg': 0.04117420259885011, 'End_point_L1_avg': 0.030601357446625007, 'End_point_L2_avg': 0.042323429436972544}\n",
      "Iteration 0, Loss: 0.10612636804580688\n",
      "Iteration 10, Loss: 0.01423501968383789\n",
      "Iteration 20, Loss: 0.0033667325042188168\n",
      "Iteration 30, Loss: 0.001497073215432465\n",
      "Iteration 40, Loss: 0.0005784088862128556\n",
      "Iteration 50, Loss: 0.00028871919494122267\n",
      "Iteration 60, Loss: 0.0002093582006637007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  25%|██▌       | 6/24 [00:02<00:09,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 0.00012794470239896327\n",
      "Stopping early at iteration 71\n",
      "{'Model': 'PINN base', 'Total_Iterations': 72, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.011754412671103038, 'L2_avg': 0.015904301968350236, 'End_point_L1_avg': 0.010373509994436614, 'End_point_L2_avg': 0.013101611087105934}\n",
      "Iteration 0, Loss: 0.14236465096473694\n",
      "Iteration 10, Loss: 0.025752248242497444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  29%|██▉       | 7/24 [00:03<00:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 0.0037333196960389614\n",
      "Iteration 30, Loss: 0.0025090279523283243\n",
      "Stopping early at iteration 34\n",
      "{'Model': 'PINN base', 'Total_Iterations': 35, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.045430513311519365, 'L2_avg': 0.05021570673079354, 'End_point_L1_avg': 0.04336712010711225, 'End_point_L2_avg': 0.05677682478195245}\n",
      "Iteration 0, Loss: 0.116356261074543\n",
      "Iteration 10, Loss: 0.027895456179976463\n",
      "Iteration 20, Loss: 0.0024383533746004105\n",
      "Iteration 30, Loss: 0.0024931340012699366\n",
      "Iteration 40, Loss: 0.0006321148248389363\n",
      "Iteration 50, Loss: 0.0004642911080736667\n",
      "Iteration 60, Loss: 0.0002165874175261706\n",
      "Iteration 70, Loss: 0.00012968905502930284\n",
      "Iteration 80, Loss: 0.00014338950859382749\n",
      "Iteration 90, Loss: 0.00015543712652288377\n",
      "Stopping early at iteration 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  33%|███▎      | 8/24 [00:08<00:31,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 100, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.008373508363754662, 'L2_avg': 0.011887974862907371, 'End_point_L1_avg': 0.00761745532418385, 'End_point_L2_avg': 0.009833692812482286}\n",
      "Iteration 0, Loss: 0.1351163387298584\n",
      "Iteration 10, Loss: 0.006153539288789034\n",
      "Iteration 20, Loss: 0.0011456343345344067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  38%|███▊      | 9/24 [00:08<00:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 24\n",
      "{'Model': 'PINN base', 'Total_Iterations': 25, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.027365674354454146, 'L2_avg': 0.03121189283595373, 'End_point_L1_avg': 0.024645341869797676, 'End_point_L2_avg': 0.0351000893202149}\n",
      "Iteration 0, Loss: 0.12825149297714233\n",
      "Iteration 10, Loss: 0.00470065139234066\n",
      "Iteration 20, Loss: 0.0012255171313881874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  42%|████▏     | 10/24 [00:09<00:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0005135913961566985\n",
      "Iteration 40, Loss: 0.0001321917079621926\n",
      "Stopping early at iteration 47\n",
      "{'Model': 'PINN base', 'Total_Iterations': 48, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.017251631807549798, 'L2_avg': 0.01917029394176223, 'End_point_L1_avg': 0.017784233941390396, 'End_point_L2_avg': 0.02133003798257143}\n",
      "Iteration 0, Loss: 0.14399582147598267\n",
      "Iteration 10, Loss: 0.0054070958867669106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  46%|████▌     | 11/24 [00:09<00:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 0.001276271534152329\n",
      "Stopping early at iteration 22\n",
      "{'Model': 'PINN base', 'Total_Iterations': 23, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.046365136456262175, 'L2_avg': 0.04951984475345732, 'End_point_L1_avg': 0.04473264889496078, 'End_point_L2_avg': 0.05372972093227503}\n",
      "Iteration 0, Loss: 0.1485263556241989\n",
      "Iteration 10, Loss: 0.004837966524064541\n",
      "Iteration 20, Loss: 0.002022666623815894\n",
      "Iteration 30, Loss: 0.000401100842282176\n",
      "Iteration 40, Loss: 0.00021595059661194682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  50%|█████     | 12/24 [00:10<00:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 46\n",
      "{'Model': 'PINN base', 'Total_Iterations': 47, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.019175637817216692, 'L2_avg': 0.020529676496019198, 'End_point_L1_avg': 0.02070962790323017, 'End_point_L2_avg': 0.027456265424493198}\n",
      "Iteration 0, Loss: 0.11697781831026077\n",
      "Iteration 10, Loss: 0.020472444593906403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  54%|█████▍    | 13/24 [00:10<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 0.0041710324585437775\n",
      "Iteration 30, Loss: 0.00176433683373034\n",
      "Stopping early at iteration 34\n",
      "{'Model': 'PINN base', 'Total_Iterations': 35, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.028095945525694808, 'L2_avg': 0.032117372463494824, 'End_point_L1_avg': 0.03037011330459342, 'End_point_L2_avg': 0.03850466370003817}\n",
      "Iteration 0, Loss: 0.09980212152004242\n",
      "Iteration 10, Loss: 0.011937933973968029\n",
      "Iteration 20, Loss: 0.004109903238713741\n",
      "Iteration 30, Loss: 0.0012116034049540758\n",
      "Iteration 40, Loss: 0.0006140990299172699\n",
      "Iteration 50, Loss: 0.0002760105999186635\n",
      "Iteration 60, Loss: 0.00015988998347893357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  58%|█████▊    | 14/24 [00:11<00:07,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 0.00010383682092651725\n",
      "Stopping early at iteration 74\n",
      "{'Model': 'PINN base', 'Total_Iterations': 75, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.011004644549106157, 'L2_avg': 0.015113097845642291, 'End_point_L1_avg': 0.008636607579955923, 'End_point_L2_avg': 0.014206077706116808}\n",
      "Iteration 0, Loss: 0.13952702283859253\n",
      "Iteration 10, Loss: 0.034334294497966766\n",
      "Iteration 20, Loss: 0.006175600923597813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  62%|██████▎   | 15/24 [00:12<00:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0015825438313186169\n",
      "Iteration 40, Loss: 0.0012239512288942933\n",
      "Stopping early at iteration 42\n",
      "{'Model': 'PINN base', 'Total_Iterations': 43, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.019890649233981577, 'L2_avg': 0.023572573388976892, 'End_point_L1_avg': 0.019477642996977865, 'End_point_L2_avg': 0.02479113109832488}\n",
      "Iteration 0, Loss: 0.12428022176027298\n",
      "Iteration 10, Loss: 0.03280961140990257\n",
      "Iteration 20, Loss: 0.005536099895834923\n",
      "Iteration 30, Loss: 0.0022071697749197483\n",
      "Iteration 40, Loss: 0.0008571669459342957\n",
      "Iteration 50, Loss: 0.0004597673541866243\n",
      "Iteration 60, Loss: 0.0002669179521035403\n",
      "Iteration 70, Loss: 0.00019357794371899217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  67%|██████▋   | 16/24 [00:13<00:06,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80, Loss: 0.00016594602493569255\n",
      "Stopping early at iteration 86\n",
      "{'Model': 'PINN base', 'Total_Iterations': 87, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.011552539995877052, 'L2_avg': 0.014627176431265354, 'End_point_L1_avg': 0.010696155753808716, 'End_point_L2_avg': 0.016525590981151504}\n",
      "Iteration 0, Loss: 0.12845750153064728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  71%|███████   | 17/24 [00:13<00:04,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: 0.005705644376575947\n",
      "Stopping early at iteration 19\n",
      "{'Model': 'PINN base', 'Total_Iterations': 20, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04591016660895129, 'L2_avg': 0.04817700621562869, 'End_point_L1_avg': 0.04432563928665866, 'End_point_L2_avg': 0.05244354274517901}\n",
      "Iteration 0, Loss: 0.11938419938087463\n",
      "Iteration 10, Loss: 0.004440948832780123\n",
      "Iteration 20, Loss: 0.0008030548342503607\n",
      "Iteration 30, Loss: 0.00037292411434464157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  75%|███████▌  | 18/24 [00:14<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, Loss: 0.0001316021371167153\n",
      "Stopping early at iteration 41\n",
      "{'Model': 'PINN base', 'Total_Iterations': 42, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.012544760311492086, 'L2_avg': 0.014633462656461493, 'End_point_L1_avg': 0.013007615376958704, 'End_point_L2_avg': 0.018556777113723787}\n",
      "Iteration 0, Loss: 0.1288052350282669\n",
      "Iteration 10, Loss: 0.00439019501209259\n",
      "Stopping early at iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  79%|███████▉  | 19/24 [00:14<00:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 20, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.03468132697708621, 'L2_avg': 0.039222689683315735, 'End_point_L1_avg': 0.03146255584283326, 'End_point_L2_avg': 0.044130727567427204}\n",
      "Iteration 0, Loss: 0.13263721764087677\n",
      "Iteration 10, Loss: 0.003764347406104207\n",
      "Iteration 20, Loss: 0.0007266548345796764\n",
      "Iteration 30, Loss: 0.00047396152513101697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  83%|████████▎ | 20/24 [00:15<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 35\n",
      "{'Model': 'PINN base', 'Total_Iterations': 36, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.01462405880911686, 'L2_avg': 0.01782380211530758, 'End_point_L1_avg': 0.013418304005376702, 'End_point_L2_avg': 0.016106013035593735}\n",
      "Iteration 0, Loss: 0.13180361688137054\n",
      "Iteration 10, Loss: 0.03982407972216606\n",
      "Iteration 20, Loss: 0.006084315478801727\n",
      "Iteration 30, Loss: 0.0032271251548081636\n",
      "Stopping early at iteration 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  88%|████████▊ | 21/24 [00:15<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN base', 'Total_Iterations': 38, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.02851883155951557, 'L2_avg': 0.03551675913554017, 'End_point_L1_avg': 0.024483013207455266, 'End_point_L2_avg': 0.04301657288590944}\n",
      "Iteration 0, Loss: 0.11636681109666824\n",
      "Iteration 10, Loss: 0.02926488034427166\n",
      "Iteration 20, Loss: 0.005037806462496519\n",
      "Iteration 30, Loss: 0.0017019996885210276\n",
      "Iteration 40, Loss: 0.0010948613053187728\n",
      "Iteration 50, Loss: 0.00046726956497877836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  92%|█████████▏| 22/24 [00:16<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60, Loss: 0.0002734466106630862\n",
      "Iteration 70, Loss: 0.00021834482322447002\n",
      "Stopping early at iteration 71\n",
      "{'Model': 'PINN base', 'Total_Iterations': 72, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.011294053444281424, 'L2_avg': 0.01590139593060478, 'End_point_L1_avg': 0.00843002027459915, 'End_point_L2_avg': 0.012786800310612821}\n",
      "Iteration 0, Loss: 0.1190638616681099\n",
      "Iteration 10, Loss: 0.023574065417051315\n",
      "Iteration 20, Loss: 0.005352159962058067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base:  96%|█████████▌| 23/24 [00:17<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0019925287924706936\n",
      "Stopping early at iteration 39\n",
      "{'Model': 'PINN base', 'Total_Iterations': 40, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.02835396418348848, 'L2_avg': 0.03432025438251343, 'End_point_L1_avg': 0.02310491311561039, 'End_point_L2_avg': 0.033363266166261056}\n",
      "Iteration 0, Loss: 0.15022854506969452\n",
      "Iteration 10, Loss: 0.04625476524233818\n",
      "Iteration 20, Loss: 0.0032841796055436134\n",
      "Iteration 30, Loss: 0.0029738880693912506\n",
      "Iteration 40, Loss: 0.001161239924840629\n",
      "Iteration 50, Loss: 0.0003893761895596981\n",
      "Iteration 60, Loss: 0.0003281750250607729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN base: 100%|██████████| 24/24 [00:18<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 0.00014774965529795736\n",
      "Iteration 80, Loss: 8.761039498494938e-05\n",
      "Stopping early at iteration 80\n",
      "{'Model': 'PINN base', 'Total_Iterations': 81, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014120491448622504, 'L2_avg': 0.017294511522109157, 'End_point_L1_avg': 0.014045049755291595, 'End_point_L2_avg': 0.025268025522995126}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.2010800838470459\n",
      "Iteration 10, Loss: 0.018370341509580612\n",
      "Iteration 20, Loss: 0.0039801690727472305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   4%|▍         | 1/24 [00:00<00:14,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0025858310982584953\n",
      "Stopping early at iteration 35\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 36, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.05828289676790403, 'L2_avg': 0.06170177304162519, 'End_point_L1_avg': 0.0546301166855725, 'End_point_L2_avg': 0.07946710257981021}\n",
      "Iteration 0, Loss: 0.23990070819854736\n",
      "Iteration 10, Loss: 0.016507305204868317\n",
      "Iteration 20, Loss: 0.006546946242451668\n",
      "Iteration 30, Loss: 0.002475544111803174\n",
      "Iteration 40, Loss: 0.0007992998580448329\n",
      "Iteration 50, Loss: 0.0005447769071906805\n",
      "Iteration 60, Loss: 0.00016429074457846582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:   8%|▊         | 2/24 [00:01<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 0.00011691769759636372\n",
      "Stopping early at iteration 71\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 72, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.012208651160529264, 'L2_avg': 0.014545057648706488, 'End_point_L1_avg': 0.011769702920232524, 'End_point_L2_avg': 0.014332254371317408}\n",
      "Iteration 0, Loss: 0.18058562278747559\n",
      "Iteration 10, Loss: 0.023147065192461014\n",
      "Iteration 20, Loss: 0.0052042799070477486\n",
      "Iteration 30, Loss: 0.0018058784771710634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  12%|█▎        | 3/24 [00:02<00:19,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, Loss: 0.0008673965348862112\n",
      "Stopping early at iteration 40\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 41, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04050442728679279, 'L2_avg': 0.043381835652656825, 'End_point_L1_avg': 0.041380697646490355, 'End_point_L2_avg': 0.05390068538742335}\n",
      "Iteration 0, Loss: 0.24315378069877625\n",
      "Iteration 10, Loss: 0.02629382722079754\n",
      "Iteration 20, Loss: 0.006303667090833187\n",
      "Iteration 30, Loss: 0.0020401026122272015\n",
      "Iteration 40, Loss: 0.0011526631424203515\n",
      "Iteration 50, Loss: 0.0004597513470798731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  17%|█▋        | 4/24 [00:04<00:22,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60, Loss: 0.0001617319940123707\n",
      "Stopping early at iteration 68\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 69, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.01647203981618982, 'L2_avg': 0.018445331626032093, 'End_point_L1_avg': 0.01703040290015623, 'End_point_L2_avg': 0.01994685159118686}\n",
      "Iteration 0, Loss: 0.17086204886436462\n",
      "Iteration 10, Loss: 0.07902970165014267\n",
      "Iteration 20, Loss: 0.030545078217983246\n",
      "Iteration 30, Loss: 0.010027165524661541\n",
      "Iteration 40, Loss: 0.003449423238635063\n",
      "Iteration 50, Loss: 0.0014212953392416239\n",
      "Stopping early at iteration 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  21%|██        | 5/24 [00:04<00:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 56, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.04610370809355367, 'L2_avg': 0.055123223684125686, 'End_point_L1_avg': 0.04236058552648672, 'End_point_L2_avg': 0.048994752843455044}\n",
      "Iteration 0, Loss: 0.1675916463136673\n",
      "Iteration 10, Loss: 0.07892495393753052\n",
      "Iteration 20, Loss: 0.03253060579299927\n",
      "Iteration 30, Loss: 0.011613147333264351\n",
      "Iteration 40, Loss: 0.004104420077055693\n",
      "Iteration 50, Loss: 0.0014439515070989728\n",
      "Iteration 60, Loss: 0.0009978617308661342\n",
      "Iteration 70, Loss: 0.000573968340177089\n",
      "Iteration 80, Loss: 0.000502549228258431\n",
      "Iteration 90, Loss: 0.00043929164530709386\n",
      "Iteration 100, Loss: 0.0004853874852415174\n",
      "Iteration 110, Loss: 0.0003723373229149729\n",
      "Iteration 120, Loss: 0.000302713131532073\n",
      "Iteration 130, Loss: 0.0004030765558127314\n",
      "Iteration 140, Loss: 0.00037418853025883436\n",
      "Iteration 150, Loss: 0.0003204877721145749\n",
      "Iteration 160, Loss: 0.000276278326055035\n",
      "Iteration 170, Loss: 0.00023368063557427377\n",
      "Iteration 180, Loss: 0.00018383775022812188\n",
      "Iteration 190, Loss: 0.00024228815163951367\n",
      "Iteration 200, Loss: 0.000215816282434389\n",
      "Iteration 210, Loss: 0.00018678870401345193\n",
      "Iteration 220, Loss: 0.0002214514242950827\n",
      "Iteration 230, Loss: 0.00017841240332927555\n",
      "Iteration 240, Loss: 0.00010020726767834276\n",
      "Iteration 250, Loss: 0.00023316117585636675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  25%|██▌       | 6/24 [00:08<00:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 258\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 259, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.011387703128707757, 'L2_avg': 0.016106570566862766, 'End_point_L1_avg': 0.00812210889920517, 'End_point_L2_avg': 0.010402511424440918}\n",
      "Iteration 0, Loss: 0.2373901605606079\n",
      "Iteration 10, Loss: 0.13452742993831635\n",
      "Iteration 20, Loss: 0.07568167895078659\n",
      "Iteration 30, Loss: 0.04265029355883598\n",
      "Iteration 40, Loss: 0.023847850039601326\n",
      "Iteration 50, Loss: 0.012700704857707024\n",
      "Iteration 60, Loss: 0.006460331380367279\n",
      "Iteration 70, Loss: 0.0031012624967843294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  29%|██▉       | 7/24 [00:10<00:33,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80, Loss: 0.0015599060570821166\n",
      "Stopping early at iteration 86\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 87, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.04010409973878971, 'L2_avg': 0.048150239310208086, 'End_point_L1_avg': 0.04127608228740811, 'End_point_L2_avg': 0.04930010429404813}\n",
      "Iteration 0, Loss: 0.20483432710170746\n",
      "Iteration 10, Loss: 0.10254842042922974\n",
      "Iteration 20, Loss: 0.045061953365802765\n",
      "Iteration 30, Loss: 0.017292294651269913\n",
      "Iteration 40, Loss: 0.0057991743087768555\n",
      "Iteration 50, Loss: 0.002170936670154333\n",
      "Iteration 60, Loss: 0.0011112986830994487\n",
      "Iteration 70, Loss: 0.0005805011605843902\n",
      "Iteration 80, Loss: 0.0006435606046579778\n",
      "Iteration 90, Loss: 0.0005359871429391205\n",
      "Iteration 100, Loss: 0.0005181902088224888\n",
      "Iteration 110, Loss: 0.0004647568566724658\n",
      "Iteration 120, Loss: 0.00028352698427625\n",
      "Iteration 130, Loss: 0.0003205432731192559\n",
      "Iteration 140, Loss: 0.00038684686296619475\n",
      "Iteration 150, Loss: 0.00029209713102318347\n",
      "Iteration 160, Loss: 0.0002810531295835972\n",
      "Iteration 170, Loss: 0.0002698478347156197\n",
      "Iteration 180, Loss: 0.00023194625100586563\n",
      "Iteration 190, Loss: 0.00022552837617695332\n",
      "Iteration 200, Loss: 0.00021325254056137055\n",
      "Iteration 210, Loss: 0.000173124935827218\n",
      "Iteration 220, Loss: 0.00017853584722615778\n",
      "Iteration 230, Loss: 0.0002007288276217878\n",
      "Iteration 240, Loss: 0.00016319943824782968\n",
      "Iteration 250, Loss: 0.0001859476324170828\n",
      "Iteration 260, Loss: 0.0001456099416827783\n",
      "Iteration 270, Loss: 0.00011834955512313172\n",
      "Iteration 280, Loss: 0.00012170214904472232\n",
      "Iteration 290, Loss: 0.00012274271284695715\n",
      "Iteration 300, Loss: 0.00011118770635221153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  33%|███▎      | 8/24 [00:17<00:54,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310, Loss: 0.00012270988372620195\n",
      "Stopping early at iteration 311\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 312, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014659296800131276, 'L2_avg': 0.018500803494906997, 'End_point_L1_avg': 0.01462312744290446, 'End_point_L2_avg': 0.019416343573615998}\n",
      "Iteration 0, Loss: 0.1651208996772766\n",
      "Iteration 10, Loss: 0.016083313152194023\n",
      "Iteration 20, Loss: 0.003732801415026188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  38%|███▊      | 9/24 [00:17<00:38,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0019686915911734104\n",
      "Stopping early at iteration 34\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 35, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.03339035707396336, 'L2_avg': 0.03645002648479285, 'End_point_L1_avg': 0.03543035433101858, 'End_point_L2_avg': 0.04673266634932017}\n",
      "Iteration 0, Loss: 0.18930548429489136\n",
      "Iteration 10, Loss: 0.0235377699136734\n",
      "Iteration 20, Loss: 0.005557303316891193\n",
      "Iteration 30, Loss: 0.0022062589414417744\n",
      "Iteration 40, Loss: 0.001151539385318756\n",
      "Iteration 50, Loss: 0.0004698280245065689\n",
      "Iteration 60, Loss: 0.00018520228331908584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  42%|████▏     | 10/24 [00:19<00:29,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 68\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 69, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.011835196111396868, 'L2_avg': 0.014469658737989503, 'End_point_L1_avg': 0.014533834239388043, 'End_point_L2_avg': 0.015463548962016151}\n",
      "Iteration 0, Loss: 0.1614147573709488\n",
      "Iteration 10, Loss: 0.013658866286277771\n",
      "Iteration 20, Loss: 0.0032400013878941536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  46%|████▌     | 11/24 [00:20<00:22,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0014752991264685988\n",
      "Stopping early at iteration 32\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 33, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0377391004013193, 'L2_avg': 0.0422340573144041, 'End_point_L1_avg': 0.03514759110784381, 'End_point_L2_avg': 0.044652815221089735}\n",
      "Iteration 0, Loss: 0.20305654406547546\n",
      "Iteration 10, Loss: 0.02605750598013401\n",
      "Iteration 20, Loss: 0.007168116047978401\n",
      "Iteration 30, Loss: 0.001832187408581376\n",
      "Iteration 40, Loss: 0.0007565349224023521\n",
      "Iteration 50, Loss: 0.00039902247954159975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  50%|█████     | 12/24 [00:21<00:21,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60, Loss: 0.00020772640709765255\n",
      "Stopping early at iteration 64\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 65, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.014226061745229784, 'L2_avg': 0.01608052928208325, 'End_point_L1_avg': 0.014452041597589423, 'End_point_L2_avg': 0.020607757274733293}\n",
      "Iteration 0, Loss: 0.2381000518798828\n",
      "Iteration 10, Loss: 0.12065018713474274\n",
      "Iteration 20, Loss: 0.05557328462600708\n",
      "Iteration 30, Loss: 0.023311350494623184\n",
      "Iteration 40, Loss: 0.008225343190133572\n",
      "Iteration 50, Loss: 0.0028358895797282457\n",
      "Iteration 60, Loss: 0.0011359344935044646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  54%|█████▍    | 13/24 [00:22<00:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 63\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 64, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0507084707310985, 'L2_avg': 0.06129570588064781, 'End_point_L1_avg': 0.061842850892933184, 'End_point_L2_avg': 0.08115805259909742}\n",
      "Iteration 0, Loss: 0.10103540122509003\n",
      "Iteration 10, Loss: 0.037669312208890915\n",
      "Iteration 20, Loss: 0.013696697540581226\n",
      "Iteration 30, Loss: 0.004593307618051767\n",
      "Iteration 40, Loss: 0.0012358746025711298\n",
      "Iteration 50, Loss: 0.0006162337376736104\n",
      "Iteration 60, Loss: 0.0006036703707650304\n",
      "Iteration 70, Loss: 0.0004900486674159765\n",
      "Iteration 80, Loss: 0.00029651448130607605\n",
      "Iteration 90, Loss: 0.0002988358901347965\n",
      "Iteration 100, Loss: 0.00029262283351272345\n",
      "Iteration 110, Loss: 0.0003179933992214501\n",
      "Iteration 120, Loss: 0.000309772469336167\n",
      "Iteration 130, Loss: 0.00014914281200617552\n",
      "Iteration 140, Loss: 0.00025096177705563605\n",
      "Iteration 150, Loss: 0.00014025976997800171\n",
      "Iteration 160, Loss: 0.0001576101203681901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  58%|█████▊    | 14/24 [00:25<00:19,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 166\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 167, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013042588896590993, 'L2_avg': 0.01798665328450094, 'End_point_L1_avg': 0.010354911640090112, 'End_point_L2_avg': 0.011813544710162915}\n",
      "Iteration 0, Loss: 0.14197257161140442\n",
      "Iteration 10, Loss: 0.06565553694963455\n",
      "Iteration 20, Loss: 0.02822687104344368\n",
      "Iteration 30, Loss: 0.011606864631175995\n",
      "Iteration 40, Loss: 0.004632839001715183\n",
      "Iteration 50, Loss: 0.002017296850681305\n",
      "Iteration 60, Loss: 0.0012936826096847653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  62%|██████▎   | 15/24 [00:27<00:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 0.0010722754523158073\n",
      "Stopping early at iteration 76\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 77, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.054346508581393324, 'L2_avg': 0.065513819477169, 'End_point_L1_avg': 0.06590508000690534, 'End_point_L2_avg': 0.08340763475685083}\n",
      "Iteration 0, Loss: 0.22034771740436554\n",
      "Iteration 10, Loss: 0.11034855991601944\n",
      "Iteration 20, Loss: 0.051659248769283295\n",
      "Iteration 30, Loss: 0.024307895451784134\n",
      "Iteration 40, Loss: 0.011459150351583958\n",
      "Iteration 50, Loss: 0.004728618543595076\n",
      "Iteration 60, Loss: 0.0020051663741469383\n",
      "Iteration 70, Loss: 0.0009052944369614124\n",
      "Iteration 80, Loss: 0.0005797880003228784\n",
      "Iteration 90, Loss: 0.0005109821795485914\n",
      "Iteration 100, Loss: 0.0005278585595078766\n",
      "Iteration 110, Loss: 0.0004813683044631034\n",
      "Iteration 120, Loss: 0.00041880810749717057\n",
      "Iteration 130, Loss: 0.0004018658946733922\n",
      "Iteration 140, Loss: 0.00031760489218868315\n",
      "Iteration 150, Loss: 0.00036125245969742537\n",
      "Iteration 160, Loss: 0.0002626243804115802\n",
      "Iteration 170, Loss: 0.0002770939317997545\n",
      "Iteration 180, Loss: 0.0002650611277204007\n",
      "Iteration 190, Loss: 0.00026560292462818325\n",
      "Iteration 200, Loss: 0.0002164706529583782\n",
      "Iteration 210, Loss: 0.0002147281338693574\n",
      "Iteration 220, Loss: 0.00020685610070358962\n",
      "Iteration 230, Loss: 0.00020719642634503543\n",
      "Iteration 240, Loss: 0.00018350830941926688\n",
      "Iteration 250, Loss: 0.0001667275937506929\n",
      "Iteration 260, Loss: 0.0001719636784400791\n",
      "Iteration 270, Loss: 0.00015996498405002058\n",
      "Iteration 280, Loss: 0.00015190757403615862\n",
      "Iteration 290, Loss: 0.0001310834486503154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  67%|██████▋   | 16/24 [00:35<00:30,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300, Loss: 0.00013319897698238492\n",
      "Stopping early at iteration 303\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 304, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.016857604395891165, 'L2_avg': 0.021266809863143315, 'End_point_L1_avg': 0.015764993687394813, 'End_point_L2_avg': 0.02026149042385278}\n",
      "Iteration 0, Loss: 0.12883511185646057\n",
      "Iteration 10, Loss: 0.012610205449163914\n",
      "Iteration 20, Loss: 0.005152249708771706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  71%|███████   | 17/24 [00:36<00:19,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0018827831372618675\n",
      "Stopping early at iteration 34\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 35, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.036743920763119754, 'L2_avg': 0.04126369591680881, 'End_point_L1_avg': 0.040060551727152074, 'End_point_L2_avg': 0.0518402686256947}\n",
      "Iteration 0, Loss: 0.15933459997177124\n",
      "Iteration 10, Loss: 0.020107077434659004\n",
      "Iteration 20, Loss: 0.0034018701408058405\n",
      "Iteration 30, Loss: 0.0012255116598680615\n",
      "Iteration 40, Loss: 0.0008380489889532328\n",
      "Iteration 50, Loss: 0.0003680985828395933\n",
      "Iteration 60, Loss: 0.00014208239736035466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  75%|███████▌  | 18/24 [00:37<00:14,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 67\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 68, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.013461847119515228, 'L2_avg': 0.015518076872258323, 'End_point_L1_avg': 0.012808184752510067, 'End_point_L2_avg': 0.01696202099278664}\n",
      "Iteration 0, Loss: 0.18019869923591614\n",
      "Iteration 10, Loss: 0.01856205239892006\n",
      "Iteration 20, Loss: 0.004524531774222851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  79%|███████▉  | 19/24 [00:38<00:09,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Loss: 0.0019599308725446463\n",
      "Stopping early at iteration 32\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 33, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.030050023124591325, 'L2_avg': 0.03691340614674483, 'End_point_L1_avg': 0.02475678357427608, 'End_point_L2_avg': 0.03614048794700187}\n",
      "Iteration 0, Loss: 0.20943063497543335\n",
      "Iteration 10, Loss: 0.02612965926527977\n",
      "Iteration 20, Loss: 0.007842794992029667\n",
      "Iteration 30, Loss: 0.00297927507199347\n",
      "Iteration 40, Loss: 0.0009778265375643969\n",
      "Iteration 50, Loss: 0.00031753137591294944\n",
      "Iteration 60, Loss: 0.00013274815864861012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  83%|████████▎ | 20/24 [00:41<00:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 9.478158608544618e-05\n",
      "Stopping early at iteration 70\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 71, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.009281443729817757, 'L2_avg': 0.011786167042133642, 'End_point_L1_avg': 0.007924570487334387, 'End_point_L2_avg': 0.01037734464784365}\n",
      "Iteration 0, Loss: 0.18420109152793884\n",
      "Iteration 10, Loss: 0.09092383086681366\n",
      "Iteration 20, Loss: 0.0411626473069191\n",
      "Iteration 30, Loss: 0.01818811520934105\n",
      "Iteration 40, Loss: 0.007651513442397118\n",
      "Iteration 50, Loss: 0.003245582804083824\n",
      "Iteration 60, Loss: 0.0016564757097512484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  88%|████████▊ | 21/24 [00:42<00:05,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at iteration 67\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 68, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.03900415879026169, 'L2_avg': 0.04701451176548736, 'End_point_L1_avg': 0.05602998823413995, 'End_point_L2_avg': 0.0641625199557645}\n",
      "Iteration 0, Loss: 0.16903583705425262\n",
      "Iteration 10, Loss: 0.07167509198188782\n",
      "Iteration 20, Loss: 0.02543744072318077\n",
      "Iteration 30, Loss: 0.008222736418247223\n",
      "Iteration 40, Loss: 0.0025644111447036266\n",
      "Iteration 50, Loss: 0.0008543181465938687\n",
      "Iteration 60, Loss: 0.00041183712892234325\n",
      "Iteration 70, Loss: 0.00036675797309726477\n",
      "Iteration 80, Loss: 0.00031952510471455753\n",
      "Iteration 90, Loss: 0.00029590772464871407\n",
      "Iteration 100, Loss: 0.0002490020706318319\n",
      "Iteration 110, Loss: 0.00024747283896431327\n",
      "Iteration 120, Loss: 0.00026786929811351\n",
      "Iteration 130, Loss: 0.00017619490972720087\n",
      "Iteration 140, Loss: 0.0001404978393111378\n",
      "Iteration 150, Loss: 0.0001859790791058913\n",
      "Iteration 160, Loss: 0.00020402426889631897\n",
      "Iteration 170, Loss: 0.00020763042266480625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  92%|█████████▏| 22/24 [00:46<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 180, Loss: 9.925926133291796e-05\n",
      "Stopping early at iteration 180\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 181, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.01485243943118206, 'L2_avg': 0.019398884277986802, 'End_point_L1_avg': 0.01360616520159371, 'End_point_L2_avg': 0.01853901985550592}\n",
      "Iteration 0, Loss: 0.21040524542331696\n",
      "Iteration 10, Loss: 0.10257828235626221\n",
      "Iteration 20, Loss: 0.044128723442554474\n",
      "Iteration 30, Loss: 0.017522457987070084\n",
      "Iteration 40, Loss: 0.006607905961573124\n",
      "Iteration 50, Loss: 0.002361558610573411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture:  96%|█████████▌| 23/24 [00:48<00:02,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60, Loss: 0.001214502495713532\n",
      "Stopping early at iteration 63\n",
      "{'Model': 'PINN new architecture', 'Total_Iterations': 64, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.03893482704660077, 'L2_avg': 0.04970285514359011, 'End_point_L1_avg': 0.04435972664109065, 'End_point_L2_avg': 0.053708078031532325}\n",
      "Iteration 0, Loss: 0.18438264727592468\n",
      "Iteration 10, Loss: 0.09918487817049026\n",
      "Iteration 20, Loss: 0.05221490189433098\n",
      "Iteration 30, Loss: 0.028279142454266548\n",
      "Iteration 40, Loss: 0.016600999981164932\n",
      "Iteration 50, Loss: 0.009623290970921516\n",
      "Iteration 60, Loss: 0.00549407210201025\n",
      "Iteration 70, Loss: 0.0033190231770277023\n",
      "Iteration 80, Loss: 0.0021526359487324953\n",
      "Iteration 90, Loss: 0.001554790185764432\n",
      "Iteration 100, Loss: 0.0010580396046862006\n",
      "Iteration 110, Loss: 0.0008962198626250029\n",
      "Iteration 120, Loss: 0.0007630654727108777\n",
      "Iteration 130, Loss: 0.0008219141745939851\n",
      "Iteration 140, Loss: 0.0006158180767670274\n",
      "Iteration 150, Loss: 0.0005965745076537132\n",
      "Iteration 160, Loss: 0.0005154908867552876\n",
      "Iteration 170, Loss: 0.0004761749296449125\n",
      "Iteration 180, Loss: 0.00040707606240175664\n",
      "Iteration 190, Loss: 0.0003515295102261007\n",
      "Iteration 200, Loss: 0.00037976045859977603\n",
      "Iteration 210, Loss: 0.0002918447135016322\n",
      "Iteration 220, Loss: 0.0002784187672659755\n",
      "Iteration 230, Loss: 0.0002898881211876869\n",
      "Iteration 240, Loss: 0.00023794958542566746\n",
      "Iteration 250, Loss: 0.00023342653003055602\n",
      "Iteration 260, Loss: 0.00023486347345169634\n",
      "Iteration 270, Loss: 0.00022270849149208516\n",
      "Iteration 280, Loss: 0.00018141882901545614\n",
      "Iteration 290, Loss: 0.0001529417495476082\n",
      "Iteration 300, Loss: 0.00015121842443477362\n",
      "Iteration 310, Loss: 0.00013934070011600852\n",
      "Iteration 320, Loss: 0.00016745369066484272\n",
      "Iteration 330, Loss: 0.00013192836195230484\n",
      "Iteration 340, Loss: 0.00013000269245821983\n",
      "Iteration 350, Loss: 0.00013787247007712722\n",
      "Stopping early at iteration 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture: 100%|██████████| 24/24 [00:59<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture', 'Total_Iterations': 356, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.009627733179339262, 'L2_avg': 0.013628930218222823, 'End_point_L1_avg': 0.0069310135932732775, 'End_point_L2_avg': 0.008379723618080702}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.001948520541191101, Min w: 1.4627253668881565e-32\n",
      "Iteration 10, Loss: 0.0009286115528084338, Min w: 3.147896179833687e-11\n",
      "Iteration 20, Loss: 0.0006160112679935992, Min w: 0.002131375949829817\n",
      "Iteration 30, Loss: 0.0003015024121850729, Min w: 0.327820360660553\n",
      "Iteration 40, Loss: 8.847460412653163e-05, Min w: 0.8089335560798645\n",
      "Iteration 50, Loss: 6.830918573541567e-05, Min w: 0.8099316358566284\n",
      "Iteration 60, Loss: 2.3608019546372816e-05, Min w: 0.9390395283699036\n",
      "Iteration 70, Loss: 1.4971882592362817e-05, Min w: 0.9686326384544373\n",
      "Iteration 80, Loss: 6.720827059325529e-06, Min w: 0.9858285188674927\n",
      "Iteration 90, Loss: 1.0357998689869419e-05, Min w: 0.9613848328590393\n",
      "Iteration 100, Loss: 8.457610420009587e-06, Min w: 0.9662212133407593\n",
      "Early break at iteration 107 --------------------------------\n",
      "Iteration 0, Loss: 3.1727472560305614e-06, Min w: 0.9950770139694214\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.054159035149496e-06, Min w: 0.9923672676086426\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.825874839298194e-06, Min w: 0.9901537299156189\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 6.23500000074273e-06, Min w: 0.9823606014251709\n",
      "Early break at iteration 9 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   4%|▍         | 1/24 [00:01<00:42,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 121, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.002386792670850892, 'L2_avg': 0.0031565169140486595, 'End_point_L1_avg': 0.002452644471603213, 'End_point_L2_avg': 0.0032551213711608826}\n",
      "Iteration 0, Loss: 0.0019942368380725384, Min w: 4.987586795510701e-31\n",
      "Iteration 10, Loss: 0.0007430406985804439, Min w: 3.6404377290466527e-09\n",
      "Iteration 20, Loss: 0.0003884189063683152, Min w: 0.021337492391467094\n",
      "Iteration 30, Loss: 0.0002614590630400926, Min w: 0.10661832243204117\n",
      "Iteration 40, Loss: 5.085063457954675e-05, Min w: 0.9093822240829468\n",
      "Iteration 50, Loss: 3.238683348172344e-05, Min w: 0.9517715573310852\n",
      "Iteration 60, Loss: 3.39313737640623e-05, Min w: 0.910063624382019\n",
      "Iteration 70, Loss: 1.7226502677658573e-05, Min w: 0.976331353187561\n",
      "Iteration 80, Loss: 1.0250993909721728e-05, Min w: 0.9847527146339417\n",
      "Iteration 90, Loss: 9.716206477605738e-06, Min w: 0.9850822687149048\n",
      "Early break at iteration 91 --------------------------------\n",
      "Iteration 0, Loss: 7.716543223068584e-06, Min w: 0.9866248965263367\n",
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 5.123686150909634e-06, Min w: 0.9923982620239258\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 6.392874183802633e-06, Min w: 0.988899827003479\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.1864689440699294e-05, Min w: 0.9740954637527466\n",
      "Early break at iteration 1 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:   8%|▊         | 2/24 [00:03<00:37,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 103, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.0033778187675288615, 'L2_avg': 0.004269257773383759, 'End_point_L1_avg': 0.002571482994247548, 'End_point_L2_avg': 0.0031689861911676537}\n",
      "Iteration 0, Loss: 0.000534410763066262, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0004224589210934937, Min w: 1.1453454002820921e-33\n",
      "Iteration 20, Loss: 0.00032095660571940243, Min w: 1.5580342132373827e-36\n",
      "Iteration 30, Loss: 0.00026789639377966523, Min w: 0.0\n",
      "Iteration 40, Loss: 0.00023443083046004176, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00017701434262562543, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0001755903649609536, Min w: 0.0\n",
      "Iteration 70, Loss: 0.0001462916552554816, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00012402811262290925, Min w: 0.0034555760212242603\n",
      "Iteration 90, Loss: 6.724640843458474e-05, Min w: 0.39363893866539\n",
      "Iteration 100, Loss: 9.19365556910634e-05, Min w: 0.0001365618227282539\n",
      "Iteration 110, Loss: 8.12630241853185e-05, Min w: 0.028222646564245224\n",
      "Iteration 120, Loss: 3.920348535757512e-05, Min w: 0.67281574010849\n",
      "Iteration 130, Loss: 2.4499708160874434e-05, Min w: 0.711812436580658\n",
      "Iteration 140, Loss: 1.795987736841198e-05, Min w: 0.7972396016120911\n",
      "Iteration 150, Loss: 1.4507064406643622e-05, Min w: 0.7939956188201904\n",
      "Iteration 160, Loss: 1.3319076970219612e-05, Min w: 0.8244897723197937\n",
      "Iteration 170, Loss: 1.8958000509883277e-05, Min w: 0.8534553647041321\n",
      "Iteration 180, Loss: 2.0898231014143676e-05, Min w: 0.8462436199188232\n",
      "Iteration 190, Loss: 1.2711569979728665e-05, Min w: 0.8164306879043579\n",
      "Iteration 200, Loss: 1.2943718502356205e-05, Min w: 0.8255553841590881\n",
      "Iteration 210, Loss: 1.539048389531672e-05, Min w: 0.8250908851623535\n",
      "Iteration 220, Loss: 1.4999352970335167e-05, Min w: 0.8260859847068787\n",
      "Iteration 230, Loss: 1.3093499546812382e-05, Min w: 0.8379749655723572\n",
      "Iteration 240, Loss: 1.49111865539453e-05, Min w: 0.8456621170043945\n",
      "Iteration 250, Loss: 1.4864264812786132e-05, Min w: 0.8226772546768188\n",
      "Iteration 260, Loss: 1.3542871784011368e-05, Min w: 0.8678432106971741\n",
      "Iteration 270, Loss: 1.5419302144437097e-05, Min w: 0.8299499750137329\n",
      "Iteration 280, Loss: 1.8868544430006295e-05, Min w: 0.832495927810669\n",
      "Iteration 290, Loss: 1.138826792157488e-05, Min w: 0.8556873202323914\n",
      "Iteration 300, Loss: 1.727062408463098e-05, Min w: 0.834213137626648\n",
      "Iteration 310, Loss: 1.8157523300033063e-05, Min w: 0.8523529767990112\n",
      "Iteration 320, Loss: 1.0798015864565969e-05, Min w: 0.8401068449020386\n",
      "Iteration 330, Loss: 2.1763091353932396e-05, Min w: 0.8684720993041992\n",
      "Iteration 340, Loss: 9.305647836299613e-06, Min w: 0.8453038334846497\n",
      "Iteration 350, Loss: 1.2161312952230219e-05, Min w: 0.8535371422767639\n",
      "Iteration 360, Loss: 1.5493042155867442e-05, Min w: 0.8598234057426453\n",
      "Iteration 370, Loss: 1.517251439508982e-05, Min w: 0.851532518863678\n",
      "Iteration 380, Loss: 1.966890886251349e-05, Min w: 0.83918696641922\n",
      "Iteration 390, Loss: 2.0599531126208603e-05, Min w: 0.8522126078605652\n",
      "Iteration 400, Loss: 1.8548258594819345e-05, Min w: 0.8640838861465454\n",
      "Iteration 410, Loss: 2.082790160784498e-05, Min w: 0.8649255633354187\n",
      "Iteration 420, Loss: 1.6669109754730016e-05, Min w: 0.8511102199554443\n",
      "Iteration 430, Loss: 2.082419814541936e-05, Min w: 0.8501893877983093\n",
      "Iteration 440, Loss: 1.1227585673623253e-05, Min w: 0.8560776114463806\n",
      "Iteration 450, Loss: 1.773142685124185e-05, Min w: 0.8383592367172241\n",
      "Iteration 460, Loss: 2.0288494852138683e-05, Min w: 0.8441465497016907\n",
      "Iteration 470, Loss: 1.7889837181428447e-05, Min w: 0.8574625253677368\n",
      "Iteration 480, Loss: 1.453426193620544e-05, Min w: 0.8547892570495605\n",
      "Iteration 490, Loss: 2.1826777810929343e-05, Min w: 0.8686563372612\n",
      "Iteration 500, Loss: 1.4080342225497589e-05, Min w: 0.8408176302909851\n",
      "Iteration 510, Loss: 1.663507464400027e-05, Min w: 0.8404730558395386\n",
      "Iteration 520, Loss: 1.9656235963338986e-05, Min w: 0.867607057094574\n",
      "Iteration 530, Loss: 1.6501355275977403e-05, Min w: 0.8592383861541748\n",
      "Iteration 540, Loss: 1.4999895029177424e-05, Min w: 0.8389749526977539\n",
      "Iteration 550, Loss: 1.843034624471329e-05, Min w: 0.848281979560852\n",
      "Iteration 560, Loss: 2.3853161110309884e-05, Min w: 0.8550685048103333\n",
      "Iteration 570, Loss: 1.4392982848221436e-05, Min w: 0.8403841257095337\n",
      "Iteration 580, Loss: 1.5975178030203097e-05, Min w: 0.8578095436096191\n",
      "Iteration 590, Loss: 1.99478781723883e-05, Min w: 0.8257901668548584\n",
      "Iteration 600, Loss: 1.825545223255176e-05, Min w: 0.8595876693725586\n",
      "Iteration 610, Loss: 1.8553928384790197e-05, Min w: 0.8432514667510986\n",
      "Iteration 620, Loss: 2.1444759113364853e-05, Min w: 0.8535153865814209\n",
      "Iteration 630, Loss: 1.7419966752640903e-05, Min w: 0.8561132550239563\n",
      "Iteration 640, Loss: 1.434718978998717e-05, Min w: 0.8606874942779541\n",
      "Iteration 650, Loss: 1.834918475651648e-05, Min w: 0.8593615889549255\n",
      "Iteration 660, Loss: 1.5630885172868147e-05, Min w: 0.8628973960876465\n",
      "Iteration 670, Loss: 1.4956326594983693e-05, Min w: 0.8515228033065796\n",
      "Iteration 680, Loss: 1.3959955140308011e-05, Min w: 0.8571244478225708\n",
      "Iteration 690, Loss: 1.629055623197928e-05, Min w: 0.8533493876457214\n",
      "Iteration 700, Loss: 1.750225965224672e-05, Min w: 0.8589352369308472\n",
      "Iteration 710, Loss: 1.6133089957293123e-05, Min w: 0.8570848107337952\n",
      "Iteration 720, Loss: 1.6365618648706004e-05, Min w: 0.8335385322570801\n",
      "Iteration 730, Loss: 2.4899507479858585e-05, Min w: 0.8642336130142212\n",
      "Iteration 740, Loss: 1.4113269571680576e-05, Min w: 0.8559855222702026\n",
      "Iteration 750, Loss: 2.218616646132432e-05, Min w: 0.8611717224121094\n",
      "Iteration 760, Loss: 1.5998466551536694e-05, Min w: 0.862594485282898\n",
      "Iteration 770, Loss: 1.796856122382451e-05, Min w: 0.8572255969047546\n",
      "Iteration 780, Loss: 1.5602598068653606e-05, Min w: 0.8691113591194153\n",
      "Iteration 790, Loss: 1.8066135453409515e-05, Min w: 0.8647122383117676\n",
      "Iteration 800, Loss: 1.776800309016835e-05, Min w: 0.8554993867874146\n",
      "Iteration 810, Loss: 1.6891670384211466e-05, Min w: 0.867285430431366\n",
      "Iteration 820, Loss: 1.6263200450339355e-05, Min w: 0.8465456962585449\n",
      "Iteration 830, Loss: 1.768047695804853e-05, Min w: 0.8642101287841797\n",
      "Iteration 840, Loss: 1.587793667567894e-05, Min w: 0.865661084651947\n",
      "Iteration 850, Loss: 1.7798871340346523e-05, Min w: 0.8733683824539185\n",
      "Iteration 860, Loss: 1.2479506949603092e-05, Min w: 0.8688316941261292\n",
      "Iteration 870, Loss: 2.124289130733814e-05, Min w: 0.864986777305603\n",
      "Iteration 880, Loss: 1.2586391676450148e-05, Min w: 0.8694380521774292\n",
      "Iteration 890, Loss: 1.9024355424335226e-05, Min w: 0.8735459446907043\n",
      "Iteration 900, Loss: 1.6152471289387904e-05, Min w: 0.878605842590332\n",
      "Iteration 910, Loss: 1.8187714886153117e-05, Min w: 0.8649907112121582\n",
      "Iteration 920, Loss: 1.6932206563069485e-05, Min w: 0.8697252869606018\n",
      "Iteration 930, Loss: 1.7825312170316465e-05, Min w: 0.8733318448066711\n",
      "Iteration 940, Loss: 1.7574546291143633e-05, Min w: 0.8701605796813965\n",
      "Iteration 950, Loss: 1.9102017176919617e-05, Min w: 0.863308846950531\n",
      "Iteration 960, Loss: 1.906339093693532e-05, Min w: 0.8660587668418884\n",
      "Iteration 970, Loss: 1.4189720786816906e-05, Min w: 0.8671621084213257\n",
      "Iteration 980, Loss: 2.793310886772815e-05, Min w: 0.8726028800010681\n",
      "Iteration 990, Loss: 1.5748877558507957e-05, Min w: 0.8604878783226013\n",
      "Iteration 1000, Loss: 1.7441447198507376e-05, Min w: 0.8622910380363464\n",
      "Iteration 1010, Loss: 1.6046687960624695e-05, Min w: 0.8732459545135498\n",
      "Iteration 1020, Loss: 1.856928429333493e-05, Min w: 0.8663162589073181\n",
      "Iteration 1030, Loss: 1.5901419828878716e-05, Min w: 0.8700931668281555\n",
      "Iteration 1040, Loss: 1.6848011000547558e-05, Min w: 0.8773231506347656\n",
      "Iteration 1050, Loss: 1.0890925295825582e-05, Min w: 0.8732582330703735\n",
      "Iteration 1060, Loss: 1.8786946384352632e-05, Min w: 0.8559818267822266\n",
      "Iteration 1070, Loss: 1.5306877685361542e-05, Min w: 0.8553381562232971\n",
      "Iteration 1080, Loss: 1.5110450476640835e-05, Min w: 0.8662107586860657\n",
      "Iteration 1090, Loss: 1.2877901099273004e-05, Min w: 0.8882672786712646\n",
      "Iteration 1100, Loss: 1.787157634680625e-05, Min w: 0.8715636134147644\n",
      "Iteration 1110, Loss: 1.652255559747573e-05, Min w: 0.8605439066886902\n",
      "Iteration 1120, Loss: 1.315718145633582e-05, Min w: 0.8653807044029236\n",
      "Iteration 1130, Loss: 1.9296054233564064e-05, Min w: 0.8808242082595825\n",
      "Iteration 1140, Loss: 1.4603447198169306e-05, Min w: 0.8738669157028198\n",
      "Iteration 1150, Loss: 2.030080577242188e-05, Min w: 0.8686352372169495\n",
      "Iteration 1160, Loss: 1.6878517271834426e-05, Min w: 0.877332329750061\n",
      "Iteration 1170, Loss: 1.8053182429866865e-05, Min w: 0.880342423915863\n",
      "Iteration 1180, Loss: 1.5849565897951834e-05, Min w: 0.8669934868812561\n",
      "Iteration 1190, Loss: 1.6618543668300845e-05, Min w: 0.8686141967773438\n",
      "Iteration 1200, Loss: 1.5276988051482476e-05, Min w: 0.884894847869873\n",
      "Iteration 1210, Loss: 1.969024378922768e-05, Min w: 0.8605191111564636\n",
      "Iteration 1220, Loss: 1.6032099665608257e-05, Min w: 0.8675476312637329\n",
      "Iteration 1230, Loss: 1.606006480869837e-05, Min w: 0.8733810186386108\n",
      "Iteration 1240, Loss: 1.9756689653149806e-05, Min w: 0.8691582679748535\n",
      "Iteration 0, Loss: 1.742417771311011e-05, Min w: 0.8732242584228516\n",
      "Iteration 10, Loss: 1.6094787497422658e-05, Min w: 0.8704014420509338\n",
      "Iteration 20, Loss: 2.040535764535889e-05, Min w: 0.8732243776321411\n",
      "Iteration 30, Loss: 1.4361572539201006e-05, Min w: 0.8791285157203674\n",
      "Iteration 40, Loss: 1.731855263642501e-05, Min w: 0.8800598382949829\n",
      "Iteration 50, Loss: 2.0499812308116816e-05, Min w: 0.8759987354278564\n",
      "Iteration 60, Loss: 1.5196914318948984e-05, Min w: 0.8799554109573364\n",
      "Iteration 70, Loss: 2.2345226170727983e-05, Min w: 0.8626826405525208\n",
      "Iteration 80, Loss: 1.6984875401249155e-05, Min w: 0.8727297782897949\n",
      "Iteration 90, Loss: 1.6822970792418346e-05, Min w: 0.8904597759246826\n",
      "Iteration 100, Loss: 1.532277929072734e-05, Min w: 0.856814444065094\n",
      "Iteration 110, Loss: 1.232943577633705e-05, Min w: 0.8983865976333618\n",
      "Iteration 120, Loss: 1.3698484508495312e-05, Min w: 0.8924331068992615\n",
      "Iteration 130, Loss: 2.1700439901906066e-05, Min w: 0.8599421381950378\n",
      "Iteration 140, Loss: 1.233168313774513e-05, Min w: 0.8741875290870667\n",
      "Iteration 150, Loss: 1.5327219443861395e-05, Min w: 0.877069354057312\n",
      "Iteration 160, Loss: 1.5881283616181463e-05, Min w: 0.8852200508117676\n",
      "Iteration 170, Loss: 1.6099627828225493e-05, Min w: 0.8814143538475037\n",
      "Iteration 180, Loss: 1.8511242160457186e-05, Min w: 0.8713257312774658\n",
      "Iteration 190, Loss: 1.3483813745551743e-05, Min w: 0.870962917804718\n",
      "Iteration 200, Loss: 1.5977808288880624e-05, Min w: 0.8888550996780396\n",
      "Iteration 210, Loss: 2.2207324946066365e-05, Min w: 0.8775139451026917\n",
      "Iteration 220, Loss: 1.652251921768766e-05, Min w: 0.8819775581359863\n",
      "Iteration 230, Loss: 2.1001003915444016e-05, Min w: 0.8789570927619934\n",
      "Iteration 240, Loss: 1.2450591384549625e-05, Min w: 0.8765069842338562\n",
      "Iteration 250, Loss: 2.025813955697231e-05, Min w: 0.8838509321212769\n",
      "Iteration 260, Loss: 1.9830391465802677e-05, Min w: 0.8190531134605408\n",
      "Iteration 270, Loss: 1.7540947737870738e-05, Min w: 0.875067412853241\n",
      "Iteration 280, Loss: 1.407218132953858e-05, Min w: 0.8829696774482727\n",
      "Iteration 290, Loss: 1.5587542293360457e-05, Min w: 0.8792223334312439\n",
      "Iteration 300, Loss: 1.683337177382782e-05, Min w: 0.8764103651046753\n",
      "Iteration 310, Loss: 1.5144823919399641e-05, Min w: 0.8719744086265564\n",
      "Iteration 320, Loss: 1.6972629964584485e-05, Min w: 0.8843410611152649\n",
      "Iteration 330, Loss: 1.8617671230458654e-05, Min w: 0.874443531036377\n",
      "Iteration 340, Loss: 1.4113917131908238e-05, Min w: 0.8848345875740051\n",
      "Iteration 350, Loss: 1.328996859228937e-05, Min w: 0.8930608034133911\n",
      "Iteration 360, Loss: 1.6084561138995923e-05, Min w: 0.8886036276817322\n",
      "Iteration 370, Loss: 2.107592263200786e-05, Min w: 0.8839234709739685\n",
      "Iteration 380, Loss: 1.341169081570115e-05, Min w: 0.8746057152748108\n",
      "Iteration 390, Loss: 1.8988213923876174e-05, Min w: 0.8893577456474304\n",
      "Iteration 400, Loss: 1.392880585626699e-05, Min w: 0.8768731355667114\n",
      "Iteration 410, Loss: 1.5378169337054715e-05, Min w: 0.8670940399169922\n",
      "Iteration 420, Loss: 1.5587329471600242e-05, Min w: 0.8893617391586304\n",
      "Iteration 430, Loss: 1.3925339771958534e-05, Min w: 0.8891346454620361\n",
      "Iteration 440, Loss: 1.650854574108962e-05, Min w: 0.8710026144981384\n",
      "Iteration 450, Loss: 2.0292834960855544e-05, Min w: 0.864945113658905\n",
      "Iteration 460, Loss: 1.9507098841131665e-05, Min w: 0.8835826516151428\n",
      "Iteration 470, Loss: 1.855720802268479e-05, Min w: 0.8983883261680603\n",
      "Iteration 480, Loss: 1.4800599274167325e-05, Min w: 0.8834117650985718\n",
      "Iteration 490, Loss: 1.3877595847588964e-05, Min w: 0.8864778876304626\n",
      "Iteration 500, Loss: 1.566624632687308e-05, Min w: 0.8882536292076111\n",
      "Iteration 510, Loss: 1.6637928638374433e-05, Min w: 0.8816622495651245\n",
      "Iteration 520, Loss: 1.591432919667568e-05, Min w: 0.8816865682601929\n",
      "Iteration 530, Loss: 1.3929627129982691e-05, Min w: 0.8777352571487427\n",
      "Iteration 540, Loss: 1.8551121684140526e-05, Min w: 0.8836252093315125\n",
      "Iteration 550, Loss: 1.7860296793514863e-05, Min w: 0.8976933360099792\n",
      "Iteration 560, Loss: 1.5435798559337854e-05, Min w: 0.9068902134895325\n",
      "Iteration 570, Loss: 1.26405384435202e-05, Min w: 0.8879690170288086\n",
      "Iteration 580, Loss: 1.4637784261140041e-05, Min w: 0.8875095248222351\n",
      "Iteration 590, Loss: 1.4571068277291488e-05, Min w: 0.8808405995368958\n",
      "Iteration 600, Loss: 1.4717049452883657e-05, Min w: 0.8878021836280823\n",
      "Iteration 610, Loss: 1.1088857718277723e-05, Min w: 0.8784947395324707\n",
      "Iteration 620, Loss: 2.33703940466512e-05, Min w: 0.8475300669670105\n",
      "Iteration 630, Loss: 1.277678347832989e-05, Min w: 0.8803275227546692\n",
      "Iteration 640, Loss: 1.8500673832022585e-05, Min w: 0.8927204608917236\n",
      "Iteration 650, Loss: 1.675777639320586e-05, Min w: 0.8899279832839966\n",
      "Iteration 660, Loss: 1.6601194147369824e-05, Min w: 0.8727890849113464\n",
      "Iteration 670, Loss: 2.6705936761572957e-05, Min w: 0.8665001392364502\n",
      "Iteration 680, Loss: 2.012162258324679e-05, Min w: 0.869431734085083\n",
      "Iteration 690, Loss: 1.4488671695289668e-05, Min w: 0.8913276195526123\n",
      "Iteration 700, Loss: 5.032014541939134e-06, Min w: 0.9181100130081177\n",
      "Iteration 710, Loss: 1.1848959729832131e-05, Min w: 0.9288906455039978\n",
      "Iteration 720, Loss: 1.0768807442218531e-05, Min w: 0.9365492463111877\n",
      "Iteration 730, Loss: 1.0077089427795727e-05, Min w: 0.9458547830581665\n",
      "Iteration 740, Loss: 9.430580576008651e-06, Min w: 0.9470098614692688\n",
      "Iteration 750, Loss: 7.575894414912909e-06, Min w: 0.9574261903762817\n",
      "Iteration 760, Loss: 1.5399424228235148e-05, Min w: 0.9198092222213745\n",
      "Iteration 770, Loss: 1.1718796486093197e-05, Min w: 0.9007963538169861\n",
      "Iteration 780, Loss: 1.2994365533813834e-05, Min w: 0.9131608605384827\n",
      "Iteration 790, Loss: 9.962440344679635e-06, Min w: 0.904778003692627\n",
      "Iteration 800, Loss: 6.817211669840617e-06, Min w: 0.9240493178367615\n",
      "Iteration 810, Loss: 8.605736184108537e-06, Min w: 0.951808512210846\n",
      "Iteration 820, Loss: 1.671608697506599e-05, Min w: 0.8989105224609375\n",
      "Iteration 830, Loss: 7.820930477464572e-06, Min w: 0.9306948781013489\n",
      "Iteration 840, Loss: 1.3424304597720038e-05, Min w: 0.9344493746757507\n",
      "Iteration 850, Loss: 9.8096543297288e-06, Min w: 0.9426624774932861\n",
      "Iteration 860, Loss: 8.547729521524161e-06, Min w: 0.9288410544395447\n",
      "Iteration 870, Loss: 8.514781256963033e-06, Min w: 0.9379397630691528\n",
      "Iteration 880, Loss: 1.3613478586194105e-05, Min w: 0.9073548316955566\n",
      "Iteration 890, Loss: 1.0479494449100457e-05, Min w: 0.9209558367729187\n",
      "Iteration 900, Loss: 1.364146464766236e-05, Min w: 0.9358024597167969\n",
      "Iteration 910, Loss: 1.0595495950838085e-05, Min w: 0.9258185029029846\n",
      "Iteration 920, Loss: 1.1144766176585108e-05, Min w: 0.9280244708061218\n",
      "Iteration 930, Loss: 1.2048791177221574e-05, Min w: 0.9317902326583862\n",
      "Iteration 940, Loss: 8.198317118512932e-06, Min w: 0.9429699182510376\n",
      "Iteration 950, Loss: 9.411941391590517e-06, Min w: 0.9395078420639038\n",
      "Iteration 960, Loss: 1.4567474863724783e-05, Min w: 0.927862823009491\n",
      "Iteration 970, Loss: 9.183607289742213e-06, Min w: 0.9369205236434937\n",
      "Iteration 980, Loss: 1.663554758124519e-05, Min w: 0.9232353568077087\n",
      "Iteration 990, Loss: 1.1114299923065118e-05, Min w: 0.920383870601654\n",
      "Iteration 1000, Loss: 1.5198593246168457e-05, Min w: 0.8509542346000671\n",
      "Iteration 1010, Loss: 1.2070350749127101e-05, Min w: 0.9099931716918945\n",
      "Iteration 1020, Loss: 7.804672350175679e-06, Min w: 0.9516763091087341\n",
      "Iteration 1030, Loss: 1.3491488061845303e-05, Min w: 0.9356656074523926\n",
      "Iteration 1040, Loss: 1.1786219147325028e-05, Min w: 0.9334089159965515\n",
      "Iteration 1050, Loss: 9.149433026323095e-06, Min w: 0.9251347184181213\n",
      "Iteration 1060, Loss: 1.5857431208132766e-05, Min w: 0.9037554264068604\n",
      "Iteration 1070, Loss: 1.3195557585277129e-05, Min w: 0.9180712699890137\n",
      "Iteration 1080, Loss: 9.27874498302117e-06, Min w: 0.9180691838264465\n",
      "Iteration 1090, Loss: 1.0102331543748733e-05, Min w: 0.9507202506065369\n",
      "Iteration 1100, Loss: 1.826071456889622e-05, Min w: 0.856464684009552\n",
      "Iteration 1110, Loss: 1.066662935045315e-05, Min w: 0.9092609882354736\n",
      "Iteration 1120, Loss: 2.7521748052095063e-05, Min w: 0.7575454115867615\n",
      "Iteration 1130, Loss: 4.3559815821936354e-05, Min w: 0.6657876968383789\n",
      "Iteration 1140, Loss: 2.64746522589121e-05, Min w: 0.7026994824409485\n",
      "Iteration 1150, Loss: 1.410283766745124e-05, Min w: 0.8948597311973572\n",
      "Iteration 1160, Loss: 1.8550719687482342e-05, Min w: 0.8905448317527771\n",
      "Iteration 1170, Loss: 4.656870714825345e-06, Min w: 0.9611011147499084\n",
      "Iteration 1180, Loss: 3.7707152387156384e-06, Min w: 0.9623510837554932\n",
      "Iteration 1190, Loss: 1.4309450307337102e-05, Min w: 0.8995800614356995\n",
      "Iteration 1200, Loss: 6.876912266307045e-06, Min w: 0.9545080065727234\n",
      "Iteration 1210, Loss: 1.3083754311082885e-05, Min w: 0.8830758929252625\n",
      "Iteration 1220, Loss: 4.696712494478561e-06, Min w: 0.9159043431282043\n",
      "Iteration 1230, Loss: 3.227553861506749e-06, Min w: 0.9788895845413208\n",
      "Iteration 1240, Loss: 4.647153673431603e-06, Min w: 0.9490758180618286\n",
      "Iteration 0, Loss: 5.598655206995318e-06, Min w: 0.9268660545349121\n",
      "Iteration 10, Loss: 4.639548023988027e-06, Min w: 0.9569975733757019\n",
      "Iteration 20, Loss: 6.408354238374159e-06, Min w: 0.918788492679596\n",
      "Iteration 30, Loss: 5.720241915696533e-06, Min w: 0.9536224603652954\n",
      "Iteration 40, Loss: 9.549315109325107e-06, Min w: 0.9206446409225464\n",
      "Iteration 50, Loss: 9.02971896721283e-06, Min w: 0.9329522848129272\n",
      "Iteration 60, Loss: 7.33304523237166e-06, Min w: 0.9532392024993896\n",
      "Iteration 70, Loss: 1.2310782949498389e-05, Min w: 0.9243517518043518\n",
      "Iteration 80, Loss: 7.16009571988252e-06, Min w: 0.9448940753936768\n",
      "Iteration 90, Loss: 1.2953595614817459e-05, Min w: 0.9287939071655273\n",
      "Iteration 100, Loss: 8.340500244230498e-06, Min w: 0.9380978345870972\n",
      "Iteration 110, Loss: 9.472376405028626e-06, Min w: 0.9436851143836975\n",
      "Iteration 120, Loss: 1.1027545951947104e-05, Min w: 0.929070234298706\n",
      "Iteration 130, Loss: 6.062530701456126e-06, Min w: 0.9600093960762024\n",
      "Iteration 140, Loss: 1.9432638509897515e-05, Min w: 0.8233792781829834\n",
      "Iteration 150, Loss: 1.100937879527919e-05, Min w: 0.8889269232749939\n",
      "Iteration 160, Loss: 1.048431840899866e-05, Min w: 0.9314809441566467\n",
      "Iteration 170, Loss: 1.2272354069864377e-05, Min w: 0.919522225856781\n",
      "Iteration 180, Loss: 8.985318345366977e-06, Min w: 0.9376015663146973\n",
      "Iteration 190, Loss: 1.143278586823726e-05, Min w: 0.9248008728027344\n",
      "Iteration 200, Loss: 1.229290046467213e-05, Min w: 0.9272658228874207\n",
      "Iteration 210, Loss: 1.3240021871752106e-05, Min w: 0.9204981327056885\n",
      "Iteration 220, Loss: 1.1633853318926413e-05, Min w: 0.9225931167602539\n",
      "Iteration 230, Loss: 1.0883218237722758e-05, Min w: 0.9259578585624695\n",
      "Iteration 240, Loss: 1.5784264178364538e-05, Min w: 0.8608659505844116\n",
      "Iteration 250, Loss: 1.1273538802925032e-05, Min w: 0.9261674880981445\n",
      "Iteration 260, Loss: 9.43615123105701e-06, Min w: 0.9282931685447693\n",
      "Iteration 270, Loss: 9.725771633384284e-06, Min w: 0.9100232124328613\n",
      "Iteration 280, Loss: 1.4853899301670026e-05, Min w: 0.9068687558174133\n",
      "Iteration 290, Loss: 8.282885573862586e-06, Min w: 0.9357580542564392\n",
      "Iteration 300, Loss: 9.824449989537243e-06, Min w: 0.9501992464065552\n",
      "Iteration 310, Loss: 2.085239793814253e-05, Min w: 0.9061477780342102\n",
      "Iteration 320, Loss: 9.862407750915736e-06, Min w: 0.8389687538146973\n",
      "Iteration 330, Loss: 7.231349172798218e-06, Min w: 0.9192975759506226\n",
      "Iteration 340, Loss: 2.8203903639223427e-05, Min w: 0.8085970282554626\n",
      "Iteration 350, Loss: 1.0380674211774021e-05, Min w: 0.8936933279037476\n",
      "Iteration 360, Loss: 5.26587973581627e-05, Min w: 0.6945163607597351\n",
      "Iteration 370, Loss: 2.139282696589362e-05, Min w: 0.8466951847076416\n",
      "Iteration 380, Loss: 1.4895717868057545e-05, Min w: 0.8227160573005676\n",
      "Iteration 390, Loss: 1.2279765542189125e-05, Min w: 0.873890221118927\n",
      "Iteration 400, Loss: 6.0665857745334506e-05, Min w: 0.6148988008499146\n",
      "Iteration 410, Loss: 1.429131498298375e-05, Min w: 0.8987382650375366\n",
      "Iteration 420, Loss: 8.636320671939757e-06, Min w: 0.8958305716514587\n",
      "Iteration 430, Loss: 1.3532072443922516e-05, Min w: 0.8699734210968018\n",
      "Iteration 440, Loss: 1.6752926967456006e-05, Min w: 0.8262664079666138\n",
      "Iteration 450, Loss: 7.381464456557296e-06, Min w: 0.9339708685874939\n",
      "Iteration 460, Loss: 1.4345854651764967e-05, Min w: 0.8418610692024231\n",
      "Iteration 470, Loss: 5.472074008139316e-06, Min w: 0.9294247031211853\n",
      "Iteration 480, Loss: 4.64634649688378e-06, Min w: 0.9566335678100586\n",
      "Iteration 490, Loss: 1.9082051494478947e-06, Min w: 0.9820877313613892\n",
      "Iteration 500, Loss: 2.5859587822196772e-06, Min w: 0.9757259488105774\n",
      "Iteration 510, Loss: 7.579772045573918e-06, Min w: 0.935987651348114\n",
      "Iteration 520, Loss: 3.5924651911045657e-06, Min w: 0.9606663584709167\n",
      "Iteration 530, Loss: 5.644024895445909e-06, Min w: 0.9499618411064148\n",
      "Iteration 540, Loss: 7.684978299948853e-06, Min w: 0.9339777231216431\n",
      "Iteration 550, Loss: 7.895104317867663e-06, Min w: 0.931407630443573\n",
      "Iteration 560, Loss: 7.5024277066404466e-06, Min w: 0.9364068508148193\n",
      "Iteration 570, Loss: 9.395274901180528e-06, Min w: 0.9437689781188965\n",
      "Iteration 580, Loss: 1.8917216948466375e-05, Min w: 0.8582301735877991\n",
      "Iteration 590, Loss: 8.958137186709791e-06, Min w: 0.922788143157959\n",
      "Iteration 600, Loss: 1.2234184396220371e-05, Min w: 0.9054415822029114\n",
      "Iteration 610, Loss: 9.061928722076118e-06, Min w: 0.9173108339309692\n",
      "Iteration 620, Loss: 1.6726349713280797e-05, Min w: 0.8730881810188293\n",
      "Iteration 630, Loss: 1.1336193892930169e-05, Min w: 0.9278849959373474\n",
      "Iteration 640, Loss: 5.415641498984769e-05, Min w: 0.7200939655303955\n",
      "Iteration 650, Loss: 3.98480478907004e-05, Min w: 0.7173925638198853\n",
      "Iteration 660, Loss: 3.210718932677992e-05, Min w: 0.8027819991111755\n",
      "Iteration 670, Loss: 1.7286709407926537e-05, Min w: 0.880257785320282\n",
      "Iteration 680, Loss: 1.246863030246459e-05, Min w: 0.8883318901062012\n",
      "Iteration 690, Loss: 1.0109733921126463e-05, Min w: 0.9315686821937561\n",
      "Iteration 700, Loss: 7.666353667445946e-06, Min w: 0.9351474046707153\n",
      "Iteration 710, Loss: 1.4071833902562503e-05, Min w: 0.8309701085090637\n",
      "Iteration 720, Loss: 5.3734811444883235e-06, Min w: 0.945004940032959\n",
      "Iteration 730, Loss: 4.481693395064212e-06, Min w: 0.9583237171173096\n",
      "Iteration 740, Loss: 5.552762104343856e-06, Min w: 0.9451847672462463\n",
      "Iteration 750, Loss: 1.0202165867667645e-05, Min w: 0.8891580104827881\n",
      "Early break at iteration 757 --------------------------------\n",
      "Iteration 0, Loss: 7.926437319838442e-07, Min w: 0.995638370513916\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 5.241054168436676e-07, Min w: 0.9968438744544983\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  12%|█▎        | 3/24 [01:13<11:30, 32.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 3260, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0017312533935658334, 'L2_avg': 0.0018591989696676418, 'End_point_L1_avg': 0.0019120867978367076, 'End_point_L2_avg': 0.0023627861601415987}\n",
      "Iteration 0, Loss: 0.0005676170694641769, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0003929981030523777, Min w: 2.7949658143455736e-09\n",
      "Iteration 20, Loss: 0.0002727487590163946, Min w: 2.8562837719031664e-17\n",
      "Iteration 30, Loss: 0.00020928018784616143, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000152186315972358, Min w: 0.0\n",
      "Iteration 50, Loss: 9.603010403225198e-05, Min w: 4.6193848192116745e-31\n",
      "Iteration 60, Loss: 0.0001027486432576552, Min w: 0.0\n",
      "Iteration 70, Loss: 8.944874571170658e-05, Min w: 7.478934478903798e-27\n",
      "Iteration 80, Loss: 7.512806041631848e-05, Min w: 0.008702658116817474\n",
      "Iteration 90, Loss: 3.465203189989552e-05, Min w: 0.6618587970733643\n",
      "Iteration 100, Loss: 7.860416371840984e-05, Min w: 1.898527342281131e-12\n",
      "Iteration 110, Loss: 7.077113696141168e-05, Min w: 1.5489715003907593e-39\n",
      "Iteration 120, Loss: 5.521434286492877e-05, Min w: 0.0\n",
      "Iteration 130, Loss: 5.656167195411399e-05, Min w: 0.00014868697326164693\n",
      "Iteration 140, Loss: 4.6671993914060295e-05, Min w: 0.0\n",
      "Iteration 150, Loss: 4.69688129669521e-05, Min w: 0.23905222117900848\n",
      "Iteration 160, Loss: 6.06915054959245e-05, Min w: 3.0261461214746157e-27\n",
      "Iteration 170, Loss: 4.478927803575061e-05, Min w: 0.0\n",
      "Iteration 180, Loss: 6.114097050158307e-05, Min w: 1.1152067970802114e-14\n",
      "Iteration 190, Loss: 5.190520823816769e-05, Min w: 9.02449226458657e-10\n",
      "Iteration 200, Loss: 4.942958548781462e-05, Min w: 1.0747218833556814e-33\n",
      "Iteration 210, Loss: 5.1052986236754805e-05, Min w: 0.0\n",
      "Iteration 220, Loss: 4.705749233835377e-05, Min w: 0.0\n",
      "Iteration 230, Loss: 4.895976235275157e-05, Min w: 4.038685074192472e-05\n",
      "Iteration 240, Loss: 3.858312629745342e-05, Min w: 0.4585297405719757\n",
      "Iteration 250, Loss: 3.7924357457086444e-05, Min w: 0.44060444831848145\n",
      "Iteration 260, Loss: 1.920756585604977e-05, Min w: 0.8723679780960083\n",
      "Iteration 270, Loss: 4.900182830169797e-05, Min w: 4.867270865863138e-14\n",
      "Iteration 280, Loss: 4.97648143209517e-05, Min w: 0.0\n",
      "Iteration 290, Loss: 5.291323395795189e-05, Min w: 9.139184698578748e-28\n",
      "Iteration 300, Loss: 4.0747476305114105e-05, Min w: 0.0454305037856102\n",
      "Iteration 310, Loss: 2.1785159333376214e-05, Min w: 0.6467902660369873\n",
      "Iteration 320, Loss: 4.638070095097646e-05, Min w: 0.7175681591033936\n",
      "Iteration 330, Loss: 4.5709599362453446e-05, Min w: 0.4550511837005615\n",
      "Iteration 340, Loss: 3.105720315943472e-05, Min w: 0.6603493690490723\n",
      "Iteration 350, Loss: 2.9351524062803946e-05, Min w: 0.7375293374061584\n",
      "Iteration 360, Loss: 2.2938642359804362e-05, Min w: 0.6958045363426208\n",
      "Iteration 370, Loss: 2.2801275918027386e-05, Min w: 0.788586437702179\n",
      "Iteration 380, Loss: 1.7673533875495195e-05, Min w: 0.8219732642173767\n",
      "Iteration 390, Loss: 1.8895008906838484e-05, Min w: 0.8386992812156677\n",
      "Iteration 400, Loss: 2.1721702069044113e-05, Min w: 0.8429498672485352\n",
      "Iteration 410, Loss: 1.8434651792631485e-05, Min w: 0.8782373070716858\n",
      "Iteration 420, Loss: 1.7961701814783737e-05, Min w: 0.8826385140419006\n",
      "Iteration 430, Loss: 1.76691755768843e-05, Min w: 0.8903435468673706\n",
      "Iteration 440, Loss: 1.9122735466226004e-05, Min w: 0.8746092915534973\n",
      "Iteration 450, Loss: 2.143039819202386e-05, Min w: 0.8749522566795349\n",
      "Iteration 460, Loss: 1.3874379874323495e-05, Min w: 0.9019366502761841\n",
      "Iteration 470, Loss: 2.2987531338003464e-05, Min w: 0.8950362801551819\n",
      "Iteration 480, Loss: 1.7979162294068374e-05, Min w: 0.8985633254051208\n",
      "Iteration 490, Loss: 1.6120688087539747e-05, Min w: 0.8925362229347229\n",
      "Iteration 500, Loss: 1.966810305020772e-05, Min w: 0.8880993127822876\n",
      "Iteration 510, Loss: 1.7324002328678034e-05, Min w: 0.9168096780776978\n",
      "Iteration 520, Loss: 1.8273285604664125e-05, Min w: 0.9212342500686646\n",
      "Iteration 530, Loss: 1.8796699805534445e-05, Min w: 0.9138064980506897\n",
      "Iteration 540, Loss: 1.8770706446957774e-05, Min w: 0.9134407639503479\n",
      "Iteration 550, Loss: 2.022481021413114e-05, Min w: 0.9066635966300964\n",
      "Iteration 560, Loss: 1.833713031373918e-05, Min w: 0.9149925112724304\n",
      "Iteration 570, Loss: 1.757026075210888e-05, Min w: 0.9254334568977356\n",
      "Iteration 580, Loss: 1.9363231331226416e-05, Min w: 0.9153574109077454\n",
      "Iteration 590, Loss: 1.6140769730554894e-05, Min w: 0.9231551885604858\n",
      "Iteration 600, Loss: 2.0305598809500225e-05, Min w: 0.9016022682189941\n",
      "Iteration 610, Loss: 1.674123268458061e-05, Min w: 0.9166150689125061\n",
      "Iteration 620, Loss: 1.8190705304732546e-05, Min w: 0.9153649210929871\n",
      "Iteration 630, Loss: 1.7319856851827353e-05, Min w: 0.9261217713356018\n",
      "Iteration 640, Loss: 1.9839459127979353e-05, Min w: 0.9179996252059937\n",
      "Iteration 650, Loss: 1.8025264580501243e-05, Min w: 0.917600154876709\n",
      "Iteration 660, Loss: 1.9284459995105863e-05, Min w: 0.9117076396942139\n",
      "Iteration 670, Loss: 1.6297679394483566e-05, Min w: 0.9173664450645447\n",
      "Iteration 680, Loss: 1.732326199999079e-05, Min w: 0.9068397879600525\n",
      "Iteration 690, Loss: 2.1701203877455555e-05, Min w: 0.9004130363464355\n",
      "Iteration 700, Loss: 1.7151043721241876e-05, Min w: 0.8997024893760681\n",
      "Iteration 710, Loss: 1.702746158116497e-05, Min w: 0.9109970331192017\n",
      "Iteration 720, Loss: 1.9973482267232612e-05, Min w: 0.9020084738731384\n",
      "Iteration 730, Loss: 1.69352406373946e-05, Min w: 0.8983979821205139\n",
      "Iteration 740, Loss: 1.7724565623211674e-05, Min w: 0.9049923419952393\n",
      "Iteration 750, Loss: 1.8257971532875672e-05, Min w: 0.9126505255699158\n",
      "Iteration 760, Loss: 1.8235317838843912e-05, Min w: 0.9037508964538574\n",
      "Iteration 770, Loss: 1.5638684999430552e-05, Min w: 0.9202075600624084\n",
      "Iteration 780, Loss: 1.8388704120297916e-05, Min w: 0.9181297421455383\n",
      "Iteration 790, Loss: 1.863780926214531e-05, Min w: 0.9157978296279907\n",
      "Iteration 800, Loss: 1.6078758562798612e-05, Min w: 0.9189795851707458\n",
      "Iteration 810, Loss: 1.852116474765353e-05, Min w: 0.9121092557907104\n",
      "Iteration 820, Loss: 1.64576467795996e-05, Min w: 0.9235103726387024\n",
      "Iteration 830, Loss: 1.6290845451294445e-05, Min w: 0.9235098361968994\n",
      "Iteration 840, Loss: 2.0349796614027582e-05, Min w: 0.9064465761184692\n",
      "Iteration 850, Loss: 1.5877407349762507e-05, Min w: 0.918570339679718\n",
      "Iteration 860, Loss: 1.7642025341046974e-05, Min w: 0.9102084636688232\n",
      "Iteration 870, Loss: 1.7923128325492144e-05, Min w: 0.907957911491394\n",
      "Iteration 880, Loss: 1.7347645552945323e-05, Min w: 0.9164138436317444\n",
      "Iteration 890, Loss: 1.868074650701601e-05, Min w: 0.9087717533111572\n",
      "Iteration 900, Loss: 1.7362199287163094e-05, Min w: 0.9159657955169678\n",
      "Iteration 910, Loss: 1.9232853446737863e-05, Min w: 0.9062075614929199\n",
      "Iteration 920, Loss: 1.6645399227854796e-05, Min w: 0.9177272915840149\n",
      "Iteration 930, Loss: 1.7258233128814027e-05, Min w: 0.9242621660232544\n",
      "Iteration 940, Loss: 1.9211205653846264e-05, Min w: 0.9180627465248108\n",
      "Iteration 950, Loss: 1.6456988305435516e-05, Min w: 0.9150827527046204\n",
      "Iteration 960, Loss: 2.2303294826997444e-05, Min w: 0.890338659286499\n",
      "Iteration 970, Loss: 1.5070142580952961e-05, Min w: 0.9210618734359741\n",
      "Iteration 980, Loss: 1.9314122255309485e-05, Min w: 0.9083813428878784\n",
      "Iteration 990, Loss: 1.7965630831895396e-05, Min w: 0.9137193560600281\n",
      "Iteration 1000, Loss: 1.6403091649408452e-05, Min w: 0.9140508770942688\n",
      "Iteration 1010, Loss: 1.9881870684912428e-05, Min w: 0.9171208739280701\n",
      "Iteration 1020, Loss: 1.582998265803326e-05, Min w: 0.9211142063140869\n",
      "Iteration 1030, Loss: 1.945685471582692e-05, Min w: 0.9085296988487244\n",
      "Iteration 1040, Loss: 1.8855582311516628e-05, Min w: 0.9004024863243103\n",
      "Iteration 1050, Loss: 1.68211518030148e-05, Min w: 0.9073082208633423\n",
      "Iteration 1060, Loss: 1.6629579477012157e-05, Min w: 0.9221369028091431\n",
      "Iteration 1070, Loss: 1.751248782966286e-05, Min w: 0.9244750142097473\n",
      "Iteration 1080, Loss: 1.8145978174288757e-05, Min w: 0.9155324101448059\n",
      "Iteration 1090, Loss: 1.8026685211225413e-05, Min w: 0.9101411700248718\n",
      "Iteration 1100, Loss: 1.7336356904706918e-05, Min w: 0.9229042530059814\n",
      "Iteration 1110, Loss: 1.586671896802727e-05, Min w: 0.9324317574501038\n",
      "Iteration 1120, Loss: 1.799706296878867e-05, Min w: 0.9200822710990906\n",
      "Iteration 1130, Loss: 1.6207721273531206e-05, Min w: 0.9188475608825684\n",
      "Iteration 1140, Loss: 1.8583117707748897e-05, Min w: 0.9088826775550842\n",
      "Iteration 1150, Loss: 1.6599615264567547e-05, Min w: 0.9122663140296936\n",
      "Iteration 1160, Loss: 1.8247939806315117e-05, Min w: 0.9069288372993469\n",
      "Iteration 1170, Loss: 1.7339742043986917e-05, Min w: 0.9106374382972717\n",
      "Iteration 1180, Loss: 1.537264688522555e-05, Min w: 0.9230654239654541\n",
      "Iteration 1190, Loss: 1.545538179925643e-05, Min w: 0.9229956269264221\n",
      "Iteration 1200, Loss: 2.0556040908559225e-05, Min w: 0.9117196202278137\n",
      "Iteration 1210, Loss: 1.5919891666271724e-05, Min w: 0.8924858570098877\n",
      "Iteration 1220, Loss: 1.6808837244752795e-05, Min w: 0.8838487267494202\n",
      "Iteration 1230, Loss: 1.5857220205361955e-05, Min w: 0.8823619484901428\n",
      "Iteration 1240, Loss: 2.0249872250133194e-05, Min w: 0.8912901282310486\n",
      "Iteration 0, Loss: 2.0419745851540938e-05, Min w: 0.8937817811965942\n",
      "Iteration 10, Loss: 1.8277416529599577e-05, Min w: 0.9034803509712219\n",
      "Iteration 20, Loss: 1.8628630641615018e-05, Min w: 0.9043920636177063\n",
      "Iteration 30, Loss: 1.7871019736048765e-05, Min w: 0.9138856530189514\n",
      "Iteration 40, Loss: 1.804857856768649e-05, Min w: 0.9133951663970947\n",
      "Iteration 50, Loss: 1.880395029729698e-05, Min w: 0.9142856597900391\n",
      "Iteration 60, Loss: 1.788312329153996e-05, Min w: 0.9116527438163757\n",
      "Iteration 70, Loss: 1.5498773791478015e-05, Min w: 0.9198243021965027\n",
      "Iteration 80, Loss: 1.8311666281078942e-05, Min w: 0.9167323708534241\n",
      "Iteration 90, Loss: 1.6615696949884295e-05, Min w: 0.9221270084381104\n",
      "Iteration 100, Loss: 1.7868946088128723e-05, Min w: 0.9169929027557373\n",
      "Iteration 110, Loss: 1.590707506693434e-05, Min w: 0.9273095726966858\n",
      "Iteration 120, Loss: 1.649534715397749e-05, Min w: 0.9178693890571594\n",
      "Iteration 130, Loss: 1.650016383791808e-05, Min w: 0.9162843823432922\n",
      "Iteration 140, Loss: 1.709471325739287e-05, Min w: 0.9190474152565002\n",
      "Iteration 150, Loss: 1.7564267182024196e-05, Min w: 0.9032366275787354\n",
      "Iteration 160, Loss: 1.532629357825499e-05, Min w: 0.9257394671440125\n",
      "Iteration 170, Loss: 1.7940021280082874e-05, Min w: 0.9199768304824829\n",
      "Iteration 180, Loss: 1.7997965187532827e-05, Min w: 0.9146773815155029\n",
      "Iteration 190, Loss: 1.7320182450930588e-05, Min w: 0.9170098304748535\n",
      "Iteration 200, Loss: 1.828235872380901e-05, Min w: 0.9100061058998108\n",
      "Iteration 210, Loss: 1.6657135347486474e-05, Min w: 0.9055654406547546\n",
      "Iteration 220, Loss: 1.6707166651031002e-05, Min w: 0.9106459617614746\n",
      "Iteration 230, Loss: 1.643884024815634e-05, Min w: 0.9054502844810486\n",
      "Iteration 240, Loss: 1.688012525846716e-05, Min w: 0.9148043990135193\n",
      "Iteration 250, Loss: 1.6290385246975347e-05, Min w: 0.9097175598144531\n",
      "Iteration 260, Loss: 1.797069671738427e-05, Min w: 0.9112303256988525\n",
      "Iteration 270, Loss: 1.6948970369412564e-05, Min w: 0.9080913662910461\n",
      "Iteration 280, Loss: 1.9498465917422436e-05, Min w: 0.9063019752502441\n",
      "Iteration 290, Loss: 1.9620252714958042e-05, Min w: 0.8927387595176697\n",
      "Iteration 300, Loss: 1.7508309611002915e-05, Min w: 0.895821750164032\n",
      "Iteration 310, Loss: 1.7473939806222916e-05, Min w: 0.9103066921234131\n",
      "Iteration 320, Loss: 1.8387832824373618e-05, Min w: 0.9046431183815002\n",
      "Iteration 330, Loss: 1.6924777810345404e-05, Min w: 0.9170044660568237\n",
      "Iteration 340, Loss: 1.7220916561200283e-05, Min w: 0.9124071598052979\n",
      "Iteration 350, Loss: 2.2281568817561492e-05, Min w: 0.9074828028678894\n",
      "Iteration 360, Loss: 1.6576250345679e-05, Min w: 0.9230253100395203\n",
      "Iteration 370, Loss: 1.550392153149005e-05, Min w: 0.9262821674346924\n",
      "Iteration 380, Loss: 1.666374555497896e-05, Min w: 0.9257311224937439\n",
      "Iteration 390, Loss: 1.6006839359761216e-05, Min w: 0.9197712540626526\n",
      "Iteration 400, Loss: 1.735620571707841e-05, Min w: 0.9167660474777222\n",
      "Iteration 410, Loss: 1.7148935512523167e-05, Min w: 0.9110923409461975\n",
      "Iteration 420, Loss: 1.655761298025027e-05, Min w: 0.9188615083694458\n",
      "Iteration 430, Loss: 1.6174699339899234e-05, Min w: 0.9259026050567627\n",
      "Iteration 440, Loss: 1.6141328160301782e-05, Min w: 0.932241678237915\n",
      "Iteration 450, Loss: 1.822752892621793e-05, Min w: 0.9141380190849304\n",
      "Iteration 460, Loss: 1.6771888112998568e-05, Min w: 0.9153559803962708\n",
      "Iteration 470, Loss: 1.926808909047395e-05, Min w: 0.9145931005477905\n",
      "Iteration 480, Loss: 1.5400726624648087e-05, Min w: 0.9216100573539734\n",
      "Iteration 490, Loss: 1.682251058809925e-05, Min w: 0.9196892380714417\n",
      "Iteration 500, Loss: 1.4073033526074141e-05, Min w: 0.9308564066886902\n",
      "Iteration 510, Loss: 1.577132752572652e-05, Min w: 0.92563396692276\n",
      "Iteration 520, Loss: 2.0073928681085818e-05, Min w: 0.9202778935432434\n",
      "Iteration 530, Loss: 1.5951820387272164e-05, Min w: 0.9202553033828735\n",
      "Iteration 540, Loss: 1.6715874153305776e-05, Min w: 0.9158124327659607\n",
      "Iteration 550, Loss: 1.7887428839458153e-05, Min w: 0.914120078086853\n",
      "Iteration 560, Loss: 1.762042120390106e-05, Min w: 0.9160284996032715\n",
      "Iteration 570, Loss: 1.855538721429184e-05, Min w: 0.9100940227508545\n",
      "Iteration 580, Loss: 1.7170239516417496e-05, Min w: 0.9076128005981445\n",
      "Iteration 590, Loss: 1.7865851987153292e-05, Min w: 0.9015554189682007\n",
      "Iteration 600, Loss: 1.7833761376095936e-05, Min w: 0.9068521857261658\n",
      "Iteration 610, Loss: 1.790836176951416e-05, Min w: 0.9114807844161987\n",
      "Iteration 620, Loss: 1.5614848962286487e-05, Min w: 0.91696697473526\n",
      "Iteration 630, Loss: 1.7161426512757316e-05, Min w: 0.9209390878677368\n",
      "Iteration 640, Loss: 1.601304393261671e-05, Min w: 0.9233362674713135\n",
      "Iteration 650, Loss: 1.8284668840351515e-05, Min w: 0.9138587713241577\n",
      "Iteration 660, Loss: 1.806665568437893e-05, Min w: 0.9114578366279602\n",
      "Iteration 670, Loss: 1.4851174455543514e-05, Min w: 0.9278011918067932\n",
      "Iteration 680, Loss: 1.7534994185552932e-05, Min w: 0.9177228212356567\n",
      "Iteration 690, Loss: 1.675181010796223e-05, Min w: 0.9051862955093384\n",
      "Iteration 700, Loss: 1.8392787751508877e-05, Min w: 0.9055593013763428\n",
      "Iteration 710, Loss: 1.6510324712726288e-05, Min w: 0.9090245366096497\n",
      "Iteration 720, Loss: 1.7001864762278274e-05, Min w: 0.9165194630622864\n",
      "Iteration 730, Loss: 1.8215563613921404e-05, Min w: 0.8885342478752136\n",
      "Iteration 740, Loss: 1.7516978914500214e-05, Min w: 0.9175567626953125\n",
      "Iteration 750, Loss: 1.5449337297468446e-05, Min w: 0.9200770854949951\n",
      "Iteration 760, Loss: 1.627800338610541e-05, Min w: 0.9123356342315674\n",
      "Iteration 770, Loss: 1.7462329196860082e-05, Min w: 0.9232379198074341\n",
      "Iteration 780, Loss: 1.591599175299052e-05, Min w: 0.9268462061882019\n",
      "Iteration 790, Loss: 1.8665252355276607e-05, Min w: 0.9132287502288818\n",
      "Iteration 800, Loss: 1.851919478212949e-05, Min w: 0.9022225141525269\n",
      "Iteration 810, Loss: 1.4470932001131587e-05, Min w: 0.902317225933075\n",
      "Iteration 820, Loss: 1.7563343135407194e-05, Min w: 0.9062079191207886\n",
      "Iteration 830, Loss: 2.128143205482047e-05, Min w: 0.8884686827659607\n",
      "Iteration 840, Loss: 2.8009642846882343e-05, Min w: 0.7745038270950317\n",
      "Iteration 850, Loss: 1.980056731554214e-05, Min w: 0.8949018716812134\n",
      "Iteration 860, Loss: 1.564303420309443e-05, Min w: 0.9174189567565918\n",
      "Iteration 870, Loss: 1.3989565559313633e-05, Min w: 0.93131023645401\n",
      "Iteration 880, Loss: 1.756861456669867e-05, Min w: 0.9108418226242065\n",
      "Iteration 890, Loss: 1.6322799638146535e-05, Min w: 0.8987074494361877\n",
      "Iteration 900, Loss: 1.609505488886498e-05, Min w: 0.9031311869621277\n",
      "Iteration 910, Loss: 1.7686737919575535e-05, Min w: 0.9031320810317993\n",
      "Iteration 920, Loss: 1.5587103916914202e-05, Min w: 0.9098993539810181\n",
      "Iteration 930, Loss: 1.683205846347846e-05, Min w: 0.9063758850097656\n",
      "Iteration 940, Loss: 1.4550292689818889e-05, Min w: 0.9083850979804993\n",
      "Iteration 950, Loss: 1.4519858268613461e-05, Min w: 0.91500324010849\n",
      "Iteration 960, Loss: 1.3677311471838038e-05, Min w: 0.9338652491569519\n",
      "Iteration 970, Loss: 1.4523861864290666e-05, Min w: 0.9306447505950928\n",
      "Iteration 980, Loss: 1.401949702994898e-05, Min w: 0.9308539628982544\n",
      "Iteration 990, Loss: 1.5084944607224315e-05, Min w: 0.9231298565864563\n",
      "Iteration 1000, Loss: 1.2773930393450428e-05, Min w: 0.9352580904960632\n",
      "Iteration 1010, Loss: 1.3704200682695955e-05, Min w: 0.9111910462379456\n",
      "Iteration 1020, Loss: 1.7619599020690657e-05, Min w: 0.881083607673645\n",
      "Iteration 1030, Loss: 2.3481130483560264e-05, Min w: 0.8319559693336487\n",
      "Iteration 1040, Loss: 2.4185830625356175e-05, Min w: 0.8291994333267212\n",
      "Iteration 1050, Loss: 2.0540461264317855e-05, Min w: 0.8713414669036865\n",
      "Iteration 1060, Loss: 1.813875678635668e-05, Min w: 0.9146129488945007\n",
      "Iteration 1070, Loss: 1.8719490981311537e-05, Min w: 0.9194785356521606\n",
      "Iteration 1080, Loss: 1.68933802342508e-05, Min w: 0.9249950647354126\n",
      "Iteration 1090, Loss: 1.7442453099647537e-05, Min w: 0.9264770150184631\n",
      "Iteration 1100, Loss: 1.7132651919382624e-05, Min w: 0.9148879647254944\n",
      "Iteration 1110, Loss: 1.4917480257281568e-05, Min w: 0.9289090633392334\n",
      "Iteration 1120, Loss: 1.690085446170997e-05, Min w: 0.9319568276405334\n",
      "Iteration 1130, Loss: 1.6395735656260513e-05, Min w: 0.9236515164375305\n",
      "Iteration 1140, Loss: 1.7668751752353273e-05, Min w: 0.9220907688140869\n",
      "Iteration 1150, Loss: 1.5138591152208392e-05, Min w: 0.9282410144805908\n",
      "Iteration 1160, Loss: 1.555763628857676e-05, Min w: 0.9231052994728088\n",
      "Iteration 1170, Loss: 1.6131612937897444e-05, Min w: 0.9287095665931702\n",
      "Iteration 1180, Loss: 1.4736712728335988e-05, Min w: 0.9260046482086182\n",
      "Iteration 1190, Loss: 1.6281708667520434e-05, Min w: 0.9256274104118347\n",
      "Iteration 1200, Loss: 1.5146412806643639e-05, Min w: 0.9232932925224304\n",
      "Iteration 1210, Loss: 1.573247391206678e-05, Min w: 0.9286726117134094\n",
      "Iteration 1220, Loss: 1.5819558029761538e-05, Min w: 0.9254084229469299\n",
      "Iteration 1230, Loss: 1.4930709767213557e-05, Min w: 0.9246252775192261\n",
      "Iteration 1240, Loss: 1.5880259525147267e-05, Min w: 0.916254460811615\n",
      "Iteration 0, Loss: 1.486219116486609e-05, Min w: 0.9242340326309204\n",
      "Iteration 10, Loss: 1.553506444906816e-05, Min w: 0.9238029718399048\n",
      "Iteration 20, Loss: 1.5125393474590965e-05, Min w: 0.9156844019889832\n",
      "Iteration 30, Loss: 1.6676300219842233e-05, Min w: 0.9150744080543518\n",
      "Iteration 40, Loss: 1.533106478746049e-05, Min w: 0.9211564660072327\n",
      "Iteration 50, Loss: 1.4623463357565925e-05, Min w: 0.9161230325698853\n",
      "Iteration 60, Loss: 1.5717829228378832e-05, Min w: 0.9217208027839661\n",
      "Iteration 70, Loss: 1.2802250239474233e-05, Min w: 0.9274293780326843\n",
      "Iteration 80, Loss: 1.5665387763874605e-05, Min w: 0.9303691983222961\n",
      "Iteration 90, Loss: 1.5238256310112774e-05, Min w: 0.9293684959411621\n",
      "Iteration 100, Loss: 1.3475700143317226e-05, Min w: 0.919028103351593\n",
      "Iteration 110, Loss: 1.4057167391001713e-05, Min w: 0.9020752906799316\n",
      "Iteration 120, Loss: 1.5123802768357564e-05, Min w: 0.9280502796173096\n",
      "Iteration 130, Loss: 1.794335366867017e-05, Min w: 0.9007807970046997\n",
      "Iteration 140, Loss: 1.7457656213082373e-05, Min w: 0.9226818084716797\n",
      "Iteration 150, Loss: 1.7188720448757522e-05, Min w: 0.9132696986198425\n",
      "Iteration 160, Loss: 1.2772887203027494e-05, Min w: 0.9330999851226807\n",
      "Iteration 170, Loss: 1.442979191779159e-05, Min w: 0.9380455613136292\n",
      "Iteration 180, Loss: 1.4169902897265274e-05, Min w: 0.9269622564315796\n",
      "Iteration 190, Loss: 1.73428106791107e-05, Min w: 0.9109706878662109\n",
      "Iteration 200, Loss: 1.5056782103783917e-05, Min w: 0.9129167199134827\n",
      "Iteration 210, Loss: 1.7861910237115808e-05, Min w: 0.9224613308906555\n",
      "Iteration 220, Loss: 1.4182221093506087e-05, Min w: 0.9206170439720154\n",
      "Iteration 230, Loss: 1.2309904377616476e-05, Min w: 0.9221198558807373\n",
      "Iteration 240, Loss: 1.839379001467023e-05, Min w: 0.9360899925231934\n",
      "Iteration 250, Loss: 1.1459474990260787e-05, Min w: 0.9414963126182556\n",
      "Iteration 260, Loss: 1.3174455489206593e-05, Min w: 0.9544300436973572\n",
      "Iteration 270, Loss: 1.4757563803868834e-05, Min w: 0.9325065016746521\n",
      "Iteration 280, Loss: 1.3187326658226084e-05, Min w: 0.9295007586479187\n",
      "Iteration 290, Loss: 1.3489913726516534e-05, Min w: 0.9366165399551392\n",
      "Iteration 300, Loss: 1.3404824130702764e-05, Min w: 0.9315930008888245\n",
      "Iteration 310, Loss: 1.2814512047043536e-05, Min w: 0.945163369178772\n",
      "Iteration 320, Loss: 1.5301679013646208e-05, Min w: 0.932725191116333\n",
      "Iteration 330, Loss: 1.9640614482341334e-05, Min w: 0.9242996573448181\n",
      "Iteration 340, Loss: 1.6737296391511336e-05, Min w: 0.8225452303886414\n",
      "Iteration 350, Loss: 1.6356410924345255e-05, Min w: 0.8809611201286316\n",
      "Iteration 360, Loss: 1.3267952454043552e-05, Min w: 0.930637776851654\n",
      "Iteration 370, Loss: 1.3233237950771581e-05, Min w: 0.9406747817993164\n",
      "Iteration 380, Loss: 1.3396221220318694e-05, Min w: 0.9353156089782715\n",
      "Iteration 390, Loss: 1.1956331945839338e-05, Min w: 0.9357688426971436\n",
      "Iteration 400, Loss: 1.3763724382442888e-05, Min w: 0.9258171916007996\n",
      "Iteration 410, Loss: 1.445957059331704e-05, Min w: 0.918047308921814\n",
      "Iteration 420, Loss: 1.7481419490650296e-05, Min w: 0.8687803745269775\n",
      "Iteration 430, Loss: 2.1837695385329425e-05, Min w: 0.8104915022850037\n",
      "Iteration 440, Loss: 1.60525905812392e-05, Min w: 0.879632830619812\n",
      "Iteration 450, Loss: 1.590537249285262e-05, Min w: 0.885301411151886\n",
      "Iteration 460, Loss: 1.1382831871742383e-05, Min w: 0.9102250337600708\n",
      "Iteration 470, Loss: 1.984034497581888e-05, Min w: 0.9104211330413818\n",
      "Iteration 480, Loss: 1.0405969987914432e-05, Min w: 0.9441811442375183\n",
      "Iteration 490, Loss: 1.72088693943806e-05, Min w: 0.9269805550575256\n",
      "Iteration 500, Loss: 1.4525672668241896e-05, Min w: 0.9239701628684998\n",
      "Iteration 510, Loss: 1.436690945411101e-05, Min w: 0.9249143004417419\n",
      "Iteration 520, Loss: 1.824971150199417e-05, Min w: 0.9087367057800293\n",
      "Iteration 530, Loss: 1.4405099136638455e-05, Min w: 0.9397650361061096\n",
      "Iteration 540, Loss: 1.5103392797755077e-05, Min w: 0.9345649480819702\n",
      "Iteration 550, Loss: 1.3612328984891064e-05, Min w: 0.937367856502533\n",
      "Iteration 560, Loss: 1.5931738744257018e-05, Min w: 0.9229077696800232\n",
      "Iteration 570, Loss: 1.4668918083771132e-05, Min w: 0.9399576783180237\n",
      "Iteration 580, Loss: 1.5600402548443526e-05, Min w: 0.9311578273773193\n",
      "Iteration 590, Loss: 1.4384359019459225e-05, Min w: 0.9208834767341614\n",
      "Iteration 600, Loss: 1.0488664884178434e-05, Min w: 0.9444469809532166\n",
      "Iteration 610, Loss: 1.8470373106538318e-05, Min w: 0.9083933234214783\n",
      "Iteration 620, Loss: 1.782041545084212e-05, Min w: 0.9089375734329224\n",
      "Iteration 630, Loss: 1.4566812751581892e-05, Min w: 0.9155368804931641\n",
      "Iteration 640, Loss: 1.8965110939461738e-05, Min w: 0.9100776314735413\n",
      "Iteration 650, Loss: 1.5822217392269522e-05, Min w: 0.9214113354682922\n",
      "Iteration 660, Loss: 1.9206276192562655e-05, Min w: 0.9164554476737976\n",
      "Iteration 670, Loss: 1.3632448826683685e-05, Min w: 0.9253393411636353\n",
      "Iteration 680, Loss: 1.684799644863233e-05, Min w: 0.9137685298919678\n",
      "Iteration 690, Loss: 1.3064657650829758e-05, Min w: 0.931569516658783\n",
      "Iteration 700, Loss: 1.7500517060398124e-05, Min w: 0.9018908739089966\n",
      "Iteration 710, Loss: 1.4751490198250394e-05, Min w: 0.9245104193687439\n",
      "Iteration 720, Loss: 1.1286770131846424e-05, Min w: 0.9330582022666931\n",
      "Iteration 730, Loss: 1.6611309547442943e-05, Min w: 0.9150387048721313\n",
      "Iteration 740, Loss: 1.3835362551617436e-05, Min w: 0.9289299845695496\n",
      "Iteration 750, Loss: 1.5515690392930992e-05, Min w: 0.9160019755363464\n",
      "Iteration 760, Loss: 1.208546837005997e-05, Min w: 0.9325731992721558\n",
      "Iteration 770, Loss: 1.3537998711399268e-05, Min w: 0.9336512684822083\n",
      "Iteration 780, Loss: 1.254068502021255e-05, Min w: 0.942588746547699\n",
      "Iteration 790, Loss: 1.4052316146262456e-05, Min w: 0.9355352520942688\n",
      "Iteration 800, Loss: 1.2062936548318248e-05, Min w: 0.9372561573982239\n",
      "Iteration 810, Loss: 1.4038380868441891e-05, Min w: 0.929573655128479\n",
      "Iteration 820, Loss: 1.4552204447682016e-05, Min w: 0.9263187050819397\n",
      "Iteration 830, Loss: 1.2819335097447038e-05, Min w: 0.9332188963890076\n",
      "Iteration 840, Loss: 1.4630623809352983e-05, Min w: 0.9162456393241882\n",
      "Iteration 850, Loss: 1.1567977708182298e-05, Min w: 0.9190356135368347\n",
      "Iteration 860, Loss: 3.103310154983774e-05, Min w: 0.7922751903533936\n",
      "Iteration 870, Loss: 1.827435517043341e-05, Min w: 0.88275545835495\n",
      "Iteration 880, Loss: 1.7139589544967748e-05, Min w: 0.8813118934631348\n",
      "Iteration 890, Loss: 1.717407394608017e-05, Min w: 0.906363844871521\n",
      "Iteration 900, Loss: 1.5987572623998858e-05, Min w: 0.9145200848579407\n",
      "Iteration 910, Loss: 2.124670209013857e-05, Min w: 0.8902268409729004\n",
      "Iteration 920, Loss: 1.8090857338393107e-05, Min w: 0.8907228708267212\n",
      "Iteration 930, Loss: 1.4344423107104376e-05, Min w: 0.9012612104415894\n",
      "Iteration 940, Loss: 1.643215728108771e-05, Min w: 0.9181171655654907\n",
      "Iteration 950, Loss: 1.5054194591357373e-05, Min w: 0.9185411930084229\n",
      "Iteration 960, Loss: 1.3308083907759283e-05, Min w: 0.9317001700401306\n",
      "Iteration 970, Loss: 1.4901284885127097e-05, Min w: 0.9289980530738831\n",
      "Iteration 980, Loss: 1.2932477147842292e-05, Min w: 0.9317681789398193\n",
      "Iteration 990, Loss: 1.6499139746883884e-05, Min w: 0.9261214137077332\n",
      "Iteration 1000, Loss: 1.4798685697314795e-05, Min w: 0.9188173413276672\n",
      "Iteration 1010, Loss: 1.1782317415054422e-05, Min w: 0.9336107969284058\n",
      "Iteration 1020, Loss: 1.4076014849706553e-05, Min w: 0.9350392818450928\n",
      "Iteration 1030, Loss: 1.5123268894967623e-05, Min w: 0.9144014120101929\n",
      "Iteration 1040, Loss: 1.325612174696289e-05, Min w: 0.9198918342590332\n",
      "Iteration 1050, Loss: 1.921069633681327e-05, Min w: 0.8901787996292114\n",
      "Iteration 1060, Loss: 2.2054111468605697e-05, Min w: 0.8843972682952881\n",
      "Iteration 1070, Loss: 1.462593354517594e-05, Min w: 0.9206146001815796\n",
      "Iteration 1080, Loss: 1.56336827785708e-05, Min w: 0.9291514158248901\n",
      "Iteration 1090, Loss: 1.7278835002798587e-05, Min w: 0.909824550151825\n",
      "Iteration 1100, Loss: 1.3286910871102009e-05, Min w: 0.9379420876502991\n",
      "Iteration 1110, Loss: 1.3361282071855385e-05, Min w: 0.9331269264221191\n",
      "Iteration 1120, Loss: 1.2773320122505538e-05, Min w: 0.9410591125488281\n",
      "Iteration 1130, Loss: 1.7860027583083138e-05, Min w: 0.9361918568611145\n",
      "Iteration 1140, Loss: 2.106318970618304e-05, Min w: 0.8272039294242859\n",
      "Iteration 1150, Loss: 2.4510409275535494e-05, Min w: 0.8650937676429749\n",
      "Iteration 1160, Loss: 1.5542453184025362e-05, Min w: 0.8748442530632019\n",
      "Iteration 1170, Loss: 2.0880554075120017e-05, Min w: 0.8799933791160583\n",
      "Iteration 1180, Loss: 1.4933094462321606e-05, Min w: 0.9012125134468079\n",
      "Iteration 1190, Loss: 1.665903619141318e-05, Min w: 0.9051305055618286\n",
      "Iteration 1200, Loss: 1.4757692042621784e-05, Min w: 0.9176183342933655\n",
      "Iteration 1210, Loss: 1.5450317732756957e-05, Min w: 0.923307478427887\n",
      "Iteration 1220, Loss: 1.4330384146887809e-05, Min w: 0.9273494482040405\n",
      "Iteration 1230, Loss: 1.600978612259496e-05, Min w: 0.9198343753814697\n",
      "Iteration 1240, Loss: 1.4832718079560436e-05, Min w: 0.9163450002670288\n",
      "Iteration 0, Loss: 1.4541672499035485e-05, Min w: 0.9159381985664368\n",
      "Iteration 10, Loss: 1.4871448001940735e-05, Min w: 0.9229856729507446\n",
      "Iteration 20, Loss: 1.5285499102901667e-05, Min w: 0.9188769459724426\n",
      "Iteration 30, Loss: 1.3337366908672266e-05, Min w: 0.9258533120155334\n",
      "Iteration 40, Loss: 1.54505451064324e-05, Min w: 0.9287852644920349\n",
      "Iteration 50, Loss: 1.6325400792993605e-05, Min w: 0.9093756675720215\n",
      "Iteration 60, Loss: 1.2336852705630008e-05, Min w: 0.9204636216163635\n",
      "Iteration 70, Loss: 1.5139111383177806e-05, Min w: 0.9252737164497375\n",
      "Iteration 80, Loss: 1.547525607747957e-05, Min w: 0.9334078431129456\n",
      "Iteration 90, Loss: 1.4710977666254621e-05, Min w: 0.9304776787757874\n",
      "Iteration 100, Loss: 1.4743097381142434e-05, Min w: 0.9304144978523254\n",
      "Iteration 110, Loss: 1.7406275219400413e-05, Min w: 0.928352952003479\n",
      "Iteration 120, Loss: 2.0073253836017102e-05, Min w: 0.9072352051734924\n",
      "Iteration 130, Loss: 1.510575930296909e-05, Min w: 0.9285454750061035\n",
      "Iteration 140, Loss: 1.4728435417055152e-05, Min w: 0.9346287846565247\n",
      "Iteration 150, Loss: 1.7183047020807862e-05, Min w: 0.9282359480857849\n",
      "Iteration 160, Loss: 1.402385805704398e-05, Min w: 0.9286423921585083\n",
      "Iteration 170, Loss: 1.3605302228825167e-05, Min w: 0.9342502355575562\n",
      "Iteration 180, Loss: 1.31237238747417e-05, Min w: 0.9401580095291138\n",
      "Iteration 190, Loss: 1.528571010567248e-05, Min w: 0.9268046021461487\n",
      "Iteration 200, Loss: 1.1591801012400538e-05, Min w: 0.9435151815414429\n",
      "Iteration 210, Loss: 1.2457189768610988e-05, Min w: 0.9410563707351685\n",
      "Iteration 220, Loss: 1.6313719243044034e-05, Min w: 0.9219803214073181\n",
      "Iteration 230, Loss: 1.6544954632990994e-05, Min w: 0.9128655791282654\n",
      "Iteration 240, Loss: 1.6633963241474703e-05, Min w: 0.9220085144042969\n",
      "Iteration 250, Loss: 1.1548724614840467e-05, Min w: 0.9211045503616333\n",
      "Iteration 260, Loss: 1.1458185326773673e-05, Min w: 0.9396429657936096\n",
      "Iteration 270, Loss: 1.2974968740309123e-05, Min w: 0.9174380302429199\n",
      "Iteration 280, Loss: 1.8314447515876964e-05, Min w: 0.9089372158050537\n",
      "Iteration 290, Loss: 2.0376432075863704e-05, Min w: 0.8266462683677673\n",
      "Iteration 300, Loss: 1.5771320249768905e-05, Min w: 0.8919842839241028\n",
      "Iteration 310, Loss: 1.7274935089517385e-05, Min w: 0.9058710336685181\n",
      "Iteration 320, Loss: 1.5454244930879213e-05, Min w: 0.925311267375946\n",
      "Iteration 330, Loss: 1.4750562513654586e-05, Min w: 0.9266926050186157\n",
      "Iteration 340, Loss: 1.275118029298028e-05, Min w: 0.9460480809211731\n",
      "Iteration 350, Loss: 1.630516635486856e-05, Min w: 0.9103452563285828\n",
      "Iteration 360, Loss: 1.2979675375390798e-05, Min w: 0.9368466138839722\n",
      "Iteration 370, Loss: 1.240225992660271e-05, Min w: 0.9131240844726562\n",
      "Iteration 380, Loss: 1.6035950466175564e-05, Min w: 0.9258261919021606\n",
      "Iteration 390, Loss: 8.199813237297349e-06, Min w: 0.9459643959999084\n",
      "Iteration 400, Loss: 1.562866964377463e-05, Min w: 0.9229368567466736\n",
      "Iteration 410, Loss: 1.8988701413036324e-05, Min w: 0.8734750151634216\n",
      "Iteration 420, Loss: 1.9270370103185996e-05, Min w: 0.8766433596611023\n",
      "Iteration 430, Loss: 1.958983739314135e-05, Min w: 0.8961371183395386\n",
      "Iteration 440, Loss: 2.011267679336015e-05, Min w: 0.8932823538780212\n",
      "Iteration 450, Loss: 1.8045384422293864e-05, Min w: 0.899176836013794\n",
      "Iteration 460, Loss: 1.757412974257022e-05, Min w: 0.9097587466239929\n",
      "Iteration 470, Loss: 1.414296366419876e-05, Min w: 0.924629807472229\n",
      "Iteration 480, Loss: 1.193886600958649e-05, Min w: 0.9410067200660706\n",
      "Iteration 490, Loss: 1.4248876141209621e-05, Min w: 0.9392142295837402\n",
      "Iteration 500, Loss: 1.210612572322134e-05, Min w: 0.9458009004592896\n",
      "Iteration 510, Loss: 1.3817380931868684e-05, Min w: 0.9356513023376465\n",
      "Iteration 520, Loss: 1.1020768397429492e-05, Min w: 0.9376333951950073\n",
      "Iteration 530, Loss: 1.4584205018763896e-05, Min w: 0.9194913506507874\n",
      "Iteration 540, Loss: 1.522686579846777e-05, Min w: 0.9177476167678833\n",
      "Iteration 550, Loss: 1.4579176422557794e-05, Min w: 0.8926708102226257\n",
      "Iteration 560, Loss: 2.1517987988772802e-05, Min w: 0.9227272272109985\n",
      "Iteration 570, Loss: 1.607779813639354e-05, Min w: 0.908791720867157\n",
      "Iteration 580, Loss: 1.514263294666307e-05, Min w: 0.9374047517776489\n",
      "Iteration 590, Loss: 1.5066651940287556e-05, Min w: 0.9377920627593994\n",
      "Iteration 600, Loss: 1.5420784620800987e-05, Min w: 0.9269591569900513\n",
      "Iteration 610, Loss: 1.2159589459770359e-05, Min w: 0.9387999176979065\n",
      "Iteration 620, Loss: 1.1126311619591434e-05, Min w: 0.9408308267593384\n",
      "Iteration 630, Loss: 1.554913615109399e-05, Min w: 0.9283415675163269\n",
      "Iteration 640, Loss: 1.2715995580947492e-05, Min w: 0.9166862964630127\n",
      "Iteration 650, Loss: 1.510987840447342e-05, Min w: 0.9118741154670715\n",
      "Iteration 660, Loss: 1.2451925613277126e-05, Min w: 0.9171105027198792\n",
      "Iteration 670, Loss: 1.170232553704409e-05, Min w: 0.9322206974029541\n",
      "Iteration 680, Loss: 1.0915446182480082e-05, Min w: 0.933282196521759\n",
      "Iteration 690, Loss: 1.5932357200654224e-05, Min w: 0.9065083861351013\n",
      "Iteration 700, Loss: 1.91888575500343e-05, Min w: 0.8812162280082703\n",
      "Iteration 710, Loss: 1.9234250430599786e-05, Min w: 0.8298738598823547\n",
      "Iteration 720, Loss: 1.8518345314078033e-05, Min w: 0.8718042373657227\n",
      "Iteration 730, Loss: 1.527731910755392e-05, Min w: 0.9005463719367981\n",
      "Iteration 740, Loss: 1.5195480045804288e-05, Min w: 0.9181375503540039\n",
      "Iteration 750, Loss: 1.4723948879691307e-05, Min w: 0.9182484745979309\n",
      "Iteration 760, Loss: 1.4191393347573467e-05, Min w: 0.922872006893158\n",
      "Iteration 770, Loss: 1.5176651686488185e-05, Min w: 0.9158977270126343\n",
      "Iteration 780, Loss: 1.2910421901324298e-05, Min w: 0.9159746766090393\n",
      "Iteration 790, Loss: 1.061594139173394e-05, Min w: 0.9468212723731995\n",
      "Iteration 800, Loss: 1.8470529539627023e-05, Min w: 0.9257190823554993\n",
      "Iteration 810, Loss: 9.048213541973382e-06, Min w: 0.9238392114639282\n",
      "Iteration 820, Loss: 1.843997961259447e-05, Min w: 0.9266043305397034\n",
      "Iteration 830, Loss: 1.6614400010439567e-05, Min w: 0.8929198980331421\n",
      "Iteration 840, Loss: 2.0372925064293668e-05, Min w: 0.8267592787742615\n",
      "Iteration 850, Loss: 1.5049489775265101e-05, Min w: 0.9086061716079712\n",
      "Iteration 860, Loss: 1.1882413673447445e-05, Min w: 0.927436113357544\n",
      "Iteration 870, Loss: 2.049405338766519e-05, Min w: 0.9122944474220276\n",
      "Iteration 880, Loss: 1.490802151238313e-05, Min w: 0.9178099036216736\n",
      "Iteration 890, Loss: 1.1766436728066765e-05, Min w: 0.9376043081283569\n",
      "Iteration 900, Loss: 1.3995328117744066e-05, Min w: 0.9294726848602295\n",
      "Iteration 910, Loss: 1.9050952687393874e-05, Min w: 0.9154106378555298\n",
      "Iteration 920, Loss: 7.8442863014061e-06, Min w: 0.9471984505653381\n",
      "Iteration 930, Loss: 1.6053751096478663e-05, Min w: 0.9304516315460205\n",
      "Iteration 940, Loss: 1.6590749510214664e-05, Min w: 0.9079939723014832\n",
      "Iteration 950, Loss: 1.3295914868649561e-05, Min w: 0.9291279911994934\n",
      "Iteration 960, Loss: 1.3712181498704012e-05, Min w: 0.9330185651779175\n",
      "Iteration 970, Loss: 9.363481694890652e-06, Min w: 0.9412405490875244\n",
      "Iteration 980, Loss: 1.2935847735207062e-05, Min w: 0.9439975023269653\n",
      "Iteration 990, Loss: 1.032818909152411e-05, Min w: 0.9420419931411743\n",
      "Iteration 1000, Loss: 1.944510586326942e-05, Min w: 0.8256774544715881\n",
      "Iteration 1010, Loss: 2.1398165699793026e-05, Min w: 0.8946746587753296\n",
      "Iteration 1020, Loss: 1.1555248420336284e-05, Min w: 0.923495352268219\n",
      "Iteration 1030, Loss: 1.3264445442473516e-05, Min w: 0.9322621822357178\n",
      "Iteration 1040, Loss: 1.2366138435027096e-05, Min w: 0.9251049160957336\n",
      "Iteration 1050, Loss: 1.3526905604521744e-05, Min w: 0.9317882657051086\n",
      "Iteration 1060, Loss: 8.210491614590865e-06, Min w: 0.9535447359085083\n",
      "Iteration 1070, Loss: 1.473198881285498e-05, Min w: 0.9240467548370361\n",
      "Iteration 1080, Loss: 1.3002547348150983e-05, Min w: 0.9384109973907471\n",
      "Iteration 1090, Loss: 1.738787796057295e-05, Min w: 0.8666045069694519\n",
      "Iteration 1100, Loss: 1.1537395948835183e-05, Min w: 0.9139106273651123\n",
      "Iteration 1110, Loss: 1.982969479286112e-05, Min w: 0.9030671715736389\n",
      "Iteration 1120, Loss: 1.1224331501580309e-05, Min w: 0.905575692653656\n",
      "Iteration 1130, Loss: 2.2485544832306914e-05, Min w: 0.9043989777565002\n",
      "Iteration 1140, Loss: 1.4145007298793644e-05, Min w: 0.9184507131576538\n",
      "Iteration 1150, Loss: 1.290559066546848e-05, Min w: 0.9345076680183411\n",
      "Iteration 1160, Loss: 1.2984271961613558e-05, Min w: 0.9276662468910217\n",
      "Iteration 1170, Loss: 9.911886081681587e-06, Min w: 0.935790479183197\n",
      "Iteration 1180, Loss: 1.538047581561841e-05, Min w: 0.85554039478302\n",
      "Iteration 1190, Loss: 1.595761932549067e-05, Min w: 0.8981035351753235\n",
      "Iteration 1200, Loss: 1.5564106433885172e-05, Min w: 0.9200237989425659\n",
      "Iteration 1210, Loss: 1.6503468941664323e-05, Min w: 0.8820300698280334\n",
      "Iteration 1220, Loss: 1.6110780052258633e-05, Min w: 0.906826376914978\n",
      "Iteration 1230, Loss: 1.4186945008987095e-05, Min w: 0.9193083047866821\n",
      "Iteration 1240, Loss: 1.2144816537329461e-05, Min w: 0.9268872737884521\n",
      "Iteration 0, Loss: 1.625953518669121e-05, Min w: 0.9301679730415344\n",
      "Iteration 10, Loss: 8.7817752500996e-06, Min w: 0.9602571129798889\n",
      "Iteration 20, Loss: 1.3075553397356998e-05, Min w: 0.9368163347244263\n",
      "Iteration 30, Loss: 8.041613909881562e-06, Min w: 0.9335195422172546\n",
      "Iteration 40, Loss: 1.639768379391171e-05, Min w: 0.9328992962837219\n",
      "Iteration 50, Loss: 1.013928067550296e-05, Min w: 0.9329599142074585\n",
      "Iteration 60, Loss: 2.082508035528008e-05, Min w: 0.895807683467865\n",
      "Iteration 70, Loss: 1.4177132470649667e-05, Min w: 0.9326621890068054\n",
      "Iteration 80, Loss: 1.293315381190041e-05, Min w: 0.9138718247413635\n",
      "Iteration 90, Loss: 1.6970085198408924e-05, Min w: 0.8807665109634399\n",
      "Iteration 100, Loss: 1.4578359696315601e-05, Min w: 0.8939773440361023\n",
      "Iteration 110, Loss: 1.0902283065661322e-05, Min w: 0.9307825565338135\n",
      "Iteration 120, Loss: 1.1526473826961592e-05, Min w: 0.9070776104927063\n",
      "Iteration 130, Loss: 1.6494544979650527e-05, Min w: 0.9061851501464844\n",
      "Iteration 140, Loss: 1.4356165593198966e-05, Min w: 0.922511637210846\n",
      "Iteration 150, Loss: 1.467019410483772e-05, Min w: 0.9177963137626648\n",
      "Iteration 160, Loss: 1.0845087672350928e-05, Min w: 0.9309549331665039\n",
      "Iteration 170, Loss: 1.010761934594484e-05, Min w: 0.9453117251396179\n",
      "Iteration 180, Loss: 1.7107304302044213e-05, Min w: 0.9265013337135315\n",
      "Iteration 190, Loss: 6.35612241239869e-06, Min w: 0.9387951493263245\n",
      "Iteration 200, Loss: 1.9868242816301063e-05, Min w: 0.9175024628639221\n",
      "Iteration 210, Loss: 7.739960892649833e-06, Min w: 0.933506190776825\n",
      "Iteration 220, Loss: 1.7949538232642226e-05, Min w: 0.8974197506904602\n",
      "Iteration 230, Loss: 2.273785139550455e-05, Min w: 0.8726787567138672\n",
      "Iteration 240, Loss: 9.075018169824034e-06, Min w: 0.9044311046600342\n",
      "Iteration 250, Loss: 1.4996511708886828e-05, Min w: 0.9045202136039734\n",
      "Iteration 260, Loss: 1.3675700756721199e-05, Min w: 0.9102278351783752\n",
      "Iteration 270, Loss: 1.3315986507222988e-05, Min w: 0.9346923232078552\n",
      "Iteration 280, Loss: 1.679827801126521e-05, Min w: 0.9099347591400146\n",
      "Iteration 290, Loss: 1.3636468793265522e-05, Min w: 0.918806254863739\n",
      "Iteration 300, Loss: 1.4683293557027355e-05, Min w: 0.8873266577720642\n",
      "Iteration 310, Loss: 9.337929441244341e-06, Min w: 0.9469589591026306\n",
      "Iteration 320, Loss: 1.0065172318718396e-05, Min w: 0.9420358538627625\n",
      "Iteration 330, Loss: 1.3040601515967865e-05, Min w: 0.9202053546905518\n",
      "Iteration 340, Loss: 2.3675682314205915e-05, Min w: 0.8629065155982971\n",
      "Iteration 350, Loss: 1.334761873295065e-05, Min w: 0.9240461587905884\n",
      "Iteration 360, Loss: 8.616846571385395e-06, Min w: 0.9441478252410889\n",
      "Iteration 370, Loss: 1.4515792827296536e-05, Min w: 0.9285609722137451\n",
      "Iteration 380, Loss: 9.033127753355075e-06, Min w: 0.9443973898887634\n",
      "Iteration 390, Loss: 1.0153339644602966e-05, Min w: 0.9602672457695007\n",
      "Iteration 400, Loss: 1.9454319044598378e-05, Min w: 0.9265895485877991\n",
      "Iteration 410, Loss: 9.356005648442078e-06, Min w: 0.9091193675994873\n",
      "Iteration 420, Loss: 1.5121801880013663e-05, Min w: 0.9158447980880737\n",
      "Iteration 430, Loss: 1.618633723410312e-05, Min w: 0.8908658623695374\n",
      "Iteration 440, Loss: 9.592333299224265e-06, Min w: 0.9572231769561768\n",
      "Iteration 450, Loss: 2.4578093871241435e-05, Min w: 0.8385594487190247\n",
      "Iteration 460, Loss: 1.0233497960143723e-05, Min w: 0.9265856146812439\n",
      "Iteration 470, Loss: 8.968064321379643e-06, Min w: 0.9196230173110962\n",
      "Iteration 480, Loss: 1.7513373677502386e-05, Min w: 0.841417670249939\n",
      "Iteration 490, Loss: 1.0416127224743832e-05, Min w: 0.9018651843070984\n",
      "Iteration 500, Loss: 1.4343258044391405e-05, Min w: 0.9228513836860657\n",
      "Iteration 510, Loss: 1.7342761566396803e-05, Min w: 0.8981218934059143\n",
      "Iteration 520, Loss: 1.3281620340421796e-05, Min w: 0.9351003170013428\n",
      "Iteration 530, Loss: 1.3633158232551068e-05, Min w: 0.8987412452697754\n",
      "Iteration 540, Loss: 9.69855045696022e-06, Min w: 0.9389714002609253\n",
      "Iteration 550, Loss: 1.1753846592910122e-05, Min w: 0.9018569588661194\n",
      "Iteration 560, Loss: 6.320934517134447e-06, Min w: 0.945098340511322\n",
      "Iteration 570, Loss: 2.119098644470796e-05, Min w: 0.9037507772445679\n",
      "Iteration 580, Loss: 1.282387074752478e-05, Min w: 0.9122453331947327\n",
      "Iteration 590, Loss: 9.75536386249587e-06, Min w: 0.9471762180328369\n",
      "Iteration 600, Loss: 8.938397513702512e-06, Min w: 0.9325238466262817\n",
      "Iteration 610, Loss: 1.6592359315836802e-05, Min w: 0.9310562610626221\n",
      "Iteration 620, Loss: 1.3325578947842587e-05, Min w: 0.9396823048591614\n",
      "Iteration 630, Loss: 9.730660167406313e-06, Min w: 0.9479283690452576\n",
      "Iteration 640, Loss: 1.165571575256763e-05, Min w: 0.949876070022583\n",
      "Iteration 650, Loss: 1.2272615094843786e-05, Min w: 0.9400917291641235\n",
      "Iteration 660, Loss: 7.769873263896443e-06, Min w: 0.9565300345420837\n",
      "Iteration 670, Loss: 1.895895547932014e-05, Min w: 0.8931097984313965\n",
      "Iteration 680, Loss: 1.0881483831326477e-05, Min w: 0.9165502190589905\n",
      "Iteration 690, Loss: 1.375466581521323e-05, Min w: 0.9450386166572571\n",
      "Iteration 700, Loss: 1.0688881957321428e-05, Min w: 0.9390116333961487\n",
      "Iteration 710, Loss: 1.440146934328368e-05, Min w: 0.9159942269325256\n",
      "Iteration 720, Loss: 1.0401271538285073e-05, Min w: 0.8995654582977295\n",
      "Iteration 730, Loss: 1.3565345398092177e-05, Min w: 0.9156603217124939\n",
      "Iteration 740, Loss: 1.09399761640816e-05, Min w: 0.916793942451477\n",
      "Iteration 750, Loss: 1.2761845027853269e-05, Min w: 0.921797513961792\n",
      "Iteration 760, Loss: 1.4502265912597068e-05, Min w: 0.9359896183013916\n",
      "Iteration 770, Loss: 7.5092448241775855e-06, Min w: 0.9619436264038086\n",
      "Iteration 780, Loss: 1.4834974535915535e-05, Min w: 0.927465558052063\n",
      "Iteration 790, Loss: 1.5974970665411092e-05, Min w: 0.8869419693946838\n",
      "Iteration 800, Loss: 1.5682140656281263e-05, Min w: 0.8999736309051514\n",
      "Iteration 810, Loss: 1.3126265002938453e-05, Min w: 0.933943510055542\n",
      "Iteration 820, Loss: 1.0294267667632084e-05, Min w: 0.9330326914787292\n",
      "Iteration 830, Loss: 9.25154654396465e-06, Min w: 0.9380027055740356\n",
      "Iteration 840, Loss: 8.59541160025401e-06, Min w: 0.944695770740509\n",
      "Iteration 850, Loss: 1.8451428331900388e-05, Min w: 0.9261357188224792\n",
      "Iteration 860, Loss: 1.0350696356908884e-05, Min w: 0.8774069547653198\n",
      "Iteration 870, Loss: 1.1766467650886625e-05, Min w: 0.9006704092025757\n",
      "Iteration 880, Loss: 2.650832902872935e-05, Min w: 0.8877400159835815\n",
      "Iteration 890, Loss: 8.622468158137053e-06, Min w: 0.9343762993812561\n",
      "Iteration 900, Loss: 1.1966670172114391e-05, Min w: 0.9435968995094299\n",
      "Iteration 910, Loss: 1.1380379874026403e-05, Min w: 0.9247921109199524\n",
      "Iteration 920, Loss: 9.115427928918507e-06, Min w: 0.9340055584907532\n",
      "Iteration 930, Loss: 1.0801528333104216e-05, Min w: 0.9400319457054138\n",
      "Iteration 940, Loss: 1.1685483514156658e-05, Min w: 0.9338517189025879\n",
      "Iteration 950, Loss: 9.641082215239294e-06, Min w: 0.9225836396217346\n",
      "Iteration 960, Loss: 1.1531545169418678e-05, Min w: 0.9373265504837036\n",
      "Iteration 970, Loss: 1.1591748261707835e-05, Min w: 0.9027149081230164\n",
      "Iteration 980, Loss: 1.732165583234746e-05, Min w: 0.883459210395813\n",
      "Iteration 990, Loss: 8.108072506729513e-06, Min w: 0.9350252151489258\n",
      "Iteration 1000, Loss: 1.3818876141158398e-05, Min w: 0.922267496585846\n",
      "Iteration 1010, Loss: 8.540031558368355e-06, Min w: 0.926255464553833\n",
      "Iteration 1020, Loss: 1.0271450264554005e-05, Min w: 0.9370251297950745\n",
      "Iteration 1030, Loss: 1.2984275599592365e-05, Min w: 0.8725652098655701\n",
      "Iteration 1040, Loss: 1.2663846973737236e-05, Min w: 0.933692991733551\n",
      "Iteration 1050, Loss: 9.715580745250918e-06, Min w: 0.9529864192008972\n",
      "Iteration 1060, Loss: 6.199315521371318e-06, Min w: 0.9457898736000061\n",
      "Iteration 1070, Loss: 1.6678435713401996e-05, Min w: 0.9240776896476746\n",
      "Iteration 1080, Loss: 6.515921086247545e-06, Min w: 0.9416313171386719\n",
      "Iteration 1090, Loss: 1.1736601663869806e-05, Min w: 0.9325339198112488\n",
      "Iteration 1100, Loss: 1.4496012227027677e-05, Min w: 0.9285960793495178\n",
      "Iteration 1110, Loss: 6.178035164339235e-06, Min w: 0.9512267708778381\n",
      "Iteration 1120, Loss: 1.3525476788345259e-05, Min w: 0.9004117846488953\n",
      "Iteration 1130, Loss: 1.688170050329063e-05, Min w: 0.8867473006248474\n",
      "Iteration 1140, Loss: 1.2408767361193895e-05, Min w: 0.9074074029922485\n",
      "Iteration 1150, Loss: 7.540215392509708e-06, Min w: 0.9344032406806946\n",
      "Iteration 1160, Loss: 1.09224838524824e-05, Min w: 0.9234883785247803\n",
      "Iteration 1170, Loss: 9.664548997534439e-06, Min w: 0.9169389605522156\n",
      "Iteration 1180, Loss: 1.0886201380344573e-05, Min w: 0.9162184596061707\n",
      "Iteration 1190, Loss: 1.9278375475551002e-05, Min w: 0.9006129503250122\n",
      "Iteration 1200, Loss: 6.841306458227336e-06, Min w: 0.9510800242424011\n",
      "Iteration 1210, Loss: 9.910727385431528e-06, Min w: 0.9449294209480286\n",
      "Iteration 1220, Loss: 1.8786686268867925e-05, Min w: 0.8572694659233093\n",
      "Iteration 1230, Loss: 2.032417251029983e-05, Min w: 0.8559926748275757\n",
      "Iteration 1240, Loss: 5.298358701111283e-06, Min w: 0.9318711161613464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  17%|█▋        | 4/24 [03:26<24:12, 72.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 6250, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.010076446312374905, 'L2_avg': 0.010370917673306551, 'End_point_L1_avg': 0.010755466239880388, 'End_point_L2_avg': 0.011873657910849954}\n",
      "Iteration 0, Loss: 0.0018238029442727566, Min w: 0.0\n",
      "Iteration 10, Loss: 0.001246267231181264, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0009633563458919525, Min w: 1.770334047249264e-20\n",
      "Iteration 30, Loss: 0.0006317635416053236, Min w: 0.28559428453445435\n",
      "Iteration 40, Loss: 0.0004687421314883977, Min w: 0.21257619559764862\n",
      "Iteration 50, Loss: 0.0002849344164133072, Min w: 0.6481924057006836\n",
      "Iteration 60, Loss: 0.00017421059601474553, Min w: 0.8130787014961243\n",
      "Iteration 70, Loss: 0.0001287348277401179, Min w: 0.8643264770507812\n",
      "Iteration 80, Loss: 0.00010664240835467353, Min w: 0.8719756007194519\n",
      "Iteration 90, Loss: 9.379915718454868e-05, Min w: 0.8747695088386536\n",
      "Iteration 100, Loss: 8.857557986630127e-05, Min w: 0.8659819960594177\n",
      "Iteration 110, Loss: 8.198111754609272e-05, Min w: 0.8839287161827087\n",
      "Iteration 120, Loss: 7.543174433521926e-05, Min w: 0.8941184878349304\n",
      "Iteration 130, Loss: 5.594127651420422e-05, Min w: 0.923639178276062\n",
      "Iteration 140, Loss: 6.933979602763429e-05, Min w: 0.9131861329078674\n",
      "Iteration 150, Loss: 4.020860797027126e-05, Min w: 0.9488211274147034\n",
      "Iteration 160, Loss: 4.4458905904321e-05, Min w: 0.9398428797721863\n",
      "Iteration 170, Loss: 7.188000745372847e-05, Min w: 0.9027856588363647\n",
      "Iteration 180, Loss: 3.565900624380447e-05, Min w: 0.9529876112937927\n",
      "Iteration 190, Loss: 2.352737465116661e-05, Min w: 0.9697731733322144\n",
      "Iteration 200, Loss: 2.1009571355534717e-05, Min w: 0.9693209528923035\n",
      "Iteration 210, Loss: 4.7168101446004584e-05, Min w: 0.9277855157852173\n",
      "Iteration 220, Loss: 2.607325222925283e-05, Min w: 0.9622951745986938\n",
      "Iteration 230, Loss: 2.433514964650385e-05, Min w: 0.9667624831199646\n",
      "Iteration 240, Loss: 2.4532631869078614e-05, Min w: 0.9640384316444397\n",
      "Iteration 250, Loss: 1.4701909094583243e-05, Min w: 0.9789021015167236\n",
      "Iteration 260, Loss: 1.377182525175158e-05, Min w: 0.9797571301460266\n",
      "Iteration 270, Loss: 1.2435436474333983e-05, Min w: 0.9810410737991333\n",
      "Iteration 280, Loss: 1.6408970623160712e-05, Min w: 0.97553950548172\n",
      "Iteration 290, Loss: 2.2884089048602618e-05, Min w: 0.9652876257896423\n",
      "Iteration 300, Loss: 1.2725716260320041e-05, Min w: 0.9791003465652466\n",
      "Iteration 310, Loss: 1.5576470104861073e-05, Min w: 0.9753674864768982\n",
      "Iteration 320, Loss: 1.3092367225908674e-05, Min w: 0.9779835343360901\n",
      "Iteration 330, Loss: 1.2773123671649955e-05, Min w: 0.9785309433937073\n",
      "Iteration 340, Loss: 1.5772966435179114e-05, Min w: 0.973310112953186\n",
      "Iteration 350, Loss: 1.7507463780930266e-05, Min w: 0.9703249335289001\n",
      "Iteration 360, Loss: 1.249437264050357e-05, Min w: 0.9785842895507812\n",
      "Iteration 370, Loss: 1.0542004929448012e-05, Min w: 0.9830631613731384\n",
      "Iteration 380, Loss: 1.2139103091612924e-05, Min w: 0.9782271385192871\n",
      "Iteration 390, Loss: 8.351301403308753e-06, Min w: 0.9853286147117615\n",
      "Early break at iteration 396 --------------------------------\n",
      "Iteration 0, Loss: 8.533344043826219e-06, Min w: 0.985490620136261\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 5.377703018893953e-06, Min w: 0.9922268390655518\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 8.072071068454534e-06, Min w: 0.9865573644638062\n",
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 1.1697416084643919e-05, Min w: 0.9799014329910278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  21%|██        | 5/24 [03:33<15:25, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 5 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 412, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0029945910937844776, 'L2_avg': 0.0044964098642575195, 'End_point_L1_avg': 0.002038611639150752, 'End_point_L2_avg': 0.003074097827530261}\n",
      "Iteration 0, Loss: 0.002028321148827672, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0015216509345918894, Min w: 4.567608644651403e-22\n",
      "Iteration 20, Loss: 0.0011069542961195111, Min w: 2.047299494734034e-05\n",
      "Iteration 30, Loss: 0.0007948334095999599, Min w: 0.11996861547231674\n",
      "Iteration 40, Loss: 0.0005967706092633307, Min w: 0.1878029853105545\n",
      "Iteration 50, Loss: 0.0005270492983981967, Min w: 0.17521193623542786\n",
      "Iteration 60, Loss: 0.0003865760227199644, Min w: 0.3200797140598297\n",
      "Iteration 70, Loss: 0.00030099545256234705, Min w: 0.49890637397766113\n",
      "Iteration 80, Loss: 0.00024595734430477023, Min w: 0.5794723629951477\n",
      "Iteration 90, Loss: 0.00020580900309141725, Min w: 0.6234144568443298\n",
      "Iteration 100, Loss: 0.00020980098634026945, Min w: 0.62428879737854\n",
      "Iteration 110, Loss: 0.00014727171219419688, Min w: 0.7151762247085571\n",
      "Iteration 120, Loss: 0.0001488367997808382, Min w: 0.6985346674919128\n",
      "Iteration 130, Loss: 0.00015079471631906927, Min w: 0.6688984632492065\n",
      "Iteration 140, Loss: 0.00010389470116933808, Min w: 0.7742370963096619\n",
      "Iteration 150, Loss: 9.29423185880296e-05, Min w: 0.7933084964752197\n",
      "Iteration 160, Loss: 0.00013111060252413154, Min w: 0.694503903388977\n",
      "Iteration 170, Loss: 9.177934407489374e-05, Min w: 0.7891332507133484\n",
      "Iteration 180, Loss: 0.00011285574873909354, Min w: 0.7424271702766418\n",
      "Iteration 190, Loss: 0.00011114477820228785, Min w: 0.7413349151611328\n",
      "Iteration 200, Loss: 5.906266233068891e-05, Min w: 0.8592621684074402\n",
      "Iteration 210, Loss: 8.917532250052318e-05, Min w: 0.7956652641296387\n",
      "Iteration 220, Loss: 8.228393562603742e-05, Min w: 0.8104374408721924\n",
      "Iteration 230, Loss: 3.7568901461781934e-05, Min w: 0.9094777703285217\n",
      "Iteration 240, Loss: 3.4055519790854305e-05, Min w: 0.9207239151000977\n",
      "Iteration 250, Loss: 3.9436821680283174e-05, Min w: 0.9080076217651367\n",
      "Iteration 260, Loss: 5.161763692740351e-05, Min w: 0.8792599439620972\n",
      "Iteration 270, Loss: 2.7482135919854045e-05, Min w: 0.9387194514274597\n",
      "Iteration 280, Loss: 3.693821054184809e-05, Min w: 0.9227651953697205\n",
      "Iteration 290, Loss: 3.072490653721616e-05, Min w: 0.9315609931945801\n",
      "Iteration 300, Loss: 3.854731403407641e-05, Min w: 0.9158535003662109\n",
      "Iteration 310, Loss: 3.3610962418606505e-05, Min w: 0.9244710803031921\n",
      "Iteration 320, Loss: 2.721198688959703e-05, Min w: 0.945443332195282\n",
      "Iteration 330, Loss: 2.566520925029181e-05, Min w: 0.9493849873542786\n",
      "Iteration 340, Loss: 1.932512896019034e-05, Min w: 0.9591044783592224\n",
      "Iteration 350, Loss: 2.3500197130488232e-05, Min w: 0.9489055871963501\n",
      "Iteration 360, Loss: 3.0223700377973728e-05, Min w: 0.9420069456100464\n",
      "Iteration 370, Loss: 2.647019391588401e-05, Min w: 0.950531005859375\n",
      "Iteration 380, Loss: 1.6124389730975963e-05, Min w: 0.9694763422012329\n",
      "Iteration 390, Loss: 1.6337029592250474e-05, Min w: 0.9695636630058289\n",
      "Iteration 400, Loss: 1.3719989510718733e-05, Min w: 0.9737614989280701\n",
      "Iteration 410, Loss: 1.5857312973821536e-05, Min w: 0.9736297130584717\n",
      "Iteration 420, Loss: 1.3371639397519175e-05, Min w: 0.9777688384056091\n",
      "Iteration 430, Loss: 1.559554584673606e-05, Min w: 0.9759259819984436\n",
      "Iteration 440, Loss: 1.8841565179172903e-05, Min w: 0.9673643708229065\n",
      "Iteration 450, Loss: 8.553754014428705e-06, Min w: 0.9874455332756042\n",
      "Iteration 460, Loss: 8.04541377874557e-06, Min w: 0.9873019456863403\n",
      "Iteration 470, Loss: 1.0337706953578163e-05, Min w: 0.9839174747467041\n",
      "Early break at iteration 476 --------------------------------\n",
      "Iteration 0, Loss: 9.976438377634622e-06, Min w: 0.9839924573898315\n",
      "Early break at iteration 6 --------------------------------\n",
      "Iteration 0, Loss: 1.2769932254741434e-05, Min w: 0.97960364818573\n",
      "Iteration 10, Loss: 1.4544663827109616e-05, Min w: 0.9777050018310547\n",
      "Early break at iteration 14 --------------------------------\n",
      "Iteration 0, Loss: 7.88968100096099e-06, Min w: 0.9882920980453491\n",
      "Early break at iteration 9 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  25%|██▌       | 6/24 [03:40<10:22, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 7.087362973834388e-06, Min w: 0.9904313087463379\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 510, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.0028531094010929054, 'L2_avg': 0.004443396331155353, 'End_point_L1_avg': 0.0025449349643411703, 'End_point_L2_avg': 0.0033331068400902905}\n",
      "Iteration 0, Loss: 0.0004671366768889129, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00029832081054337323, Min w: 0.0\n",
      "Iteration 20, Loss: 0.00023596305982209742, Min w: 2.932613596406952e-10\n",
      "Iteration 30, Loss: 0.00017849919095169753, Min w: 0.2327205091714859\n",
      "Iteration 40, Loss: 0.00012768096348736435, Min w: 0.38821157813072205\n",
      "Iteration 50, Loss: 0.00010117903730133548, Min w: 0.5476035475730896\n",
      "Iteration 60, Loss: 8.552266081096604e-05, Min w: 0.6078461408615112\n",
      "Iteration 70, Loss: 7.826533692423254e-05, Min w: 0.6441115736961365\n",
      "Iteration 80, Loss: 7.085705874487758e-05, Min w: 0.6687228679656982\n",
      "Iteration 90, Loss: 6.0804246459156275e-05, Min w: 0.7118073105812073\n",
      "Iteration 100, Loss: 5.753663936047815e-05, Min w: 0.7195548415184021\n",
      "Iteration 110, Loss: 5.2688526920974255e-05, Min w: 0.7402133941650391\n",
      "Iteration 120, Loss: 4.832354898098856e-05, Min w: 0.7568008303642273\n",
      "Iteration 130, Loss: 4.658592297346331e-05, Min w: 0.7656888365745544\n",
      "Iteration 140, Loss: 4.065281609655358e-05, Min w: 0.7950993776321411\n",
      "Iteration 150, Loss: 3.8637870602542534e-05, Min w: 0.8061317205429077\n",
      "Iteration 160, Loss: 3.343815842526965e-05, Min w: 0.8319674730300903\n",
      "Iteration 170, Loss: 3.167253089486621e-05, Min w: 0.8412669897079468\n",
      "Iteration 180, Loss: 2.949008012365084e-05, Min w: 0.8507516384124756\n",
      "Iteration 190, Loss: 2.6826422981685027e-05, Min w: 0.8610197901725769\n",
      "Iteration 200, Loss: 2.4448372641927563e-05, Min w: 0.8691781163215637\n",
      "Iteration 210, Loss: 2.2958296540309675e-05, Min w: 0.8818240165710449\n",
      "Iteration 220, Loss: 2.230425161542371e-05, Min w: 0.8858110308647156\n",
      "Iteration 230, Loss: 1.9499651898513548e-05, Min w: 0.8936585783958435\n",
      "Iteration 240, Loss: 1.8526226995163597e-05, Min w: 0.903103232383728\n",
      "Iteration 250, Loss: 1.6101761502795853e-05, Min w: 0.9152054786682129\n",
      "Iteration 260, Loss: 1.4537010429194197e-05, Min w: 0.9260355234146118\n",
      "Iteration 270, Loss: 1.2523416444309987e-05, Min w: 0.9357787370681763\n",
      "Iteration 280, Loss: 1.239395442098612e-05, Min w: 0.9351590275764465\n",
      "Iteration 290, Loss: 1.1117582289443817e-05, Min w: 0.9383010864257812\n",
      "Iteration 300, Loss: 1.0368630682933144e-05, Min w: 0.9418027400970459\n",
      "Iteration 310, Loss: 8.714718205737881e-06, Min w: 0.9500967264175415\n",
      "Iteration 320, Loss: 8.872213584254496e-06, Min w: 0.947488009929657\n",
      "Iteration 330, Loss: 7.875592018535826e-06, Min w: 0.9526323080062866\n",
      "Iteration 340, Loss: 7.432753136527026e-06, Min w: 0.9533636569976807\n",
      "Iteration 350, Loss: 7.388347512460314e-06, Min w: 0.9534787535667419\n",
      "Iteration 360, Loss: 6.649136594205629e-06, Min w: 0.9583364129066467\n",
      "Iteration 370, Loss: 5.909888386668172e-06, Min w: 0.963128387928009\n",
      "Iteration 380, Loss: 4.993198672309518e-06, Min w: 0.9667572975158691\n",
      "Iteration 390, Loss: 4.8728884394222405e-06, Min w: 0.9691107273101807\n",
      "Iteration 400, Loss: 5.205462912272196e-06, Min w: 0.9659372568130493\n",
      "Iteration 410, Loss: 4.275384981156094e-06, Min w: 0.9726513028144836\n",
      "Iteration 420, Loss: 4.03918193114805e-06, Min w: 0.9744055867195129\n",
      "Iteration 430, Loss: 3.874633421219187e-06, Min w: 0.9754096269607544\n",
      "Iteration 440, Loss: 4.4973335207032505e-06, Min w: 0.9682451486587524\n",
      "Iteration 450, Loss: 3.662629524114891e-06, Min w: 0.9764894843101501\n",
      "Iteration 460, Loss: 3.365203610883327e-06, Min w: 0.9788953065872192\n",
      "Iteration 470, Loss: 2.813645323840319e-06, Min w: 0.9830389618873596\n",
      "Iteration 480, Loss: 2.9476652798621217e-06, Min w: 0.9826046824455261\n",
      "Iteration 490, Loss: 2.629776645335369e-06, Min w: 0.9840832948684692\n",
      "Iteration 500, Loss: 2.541279172874056e-06, Min w: 0.9846557378768921\n",
      "Iteration 510, Loss: 3.3423070817661937e-06, Min w: 0.9800575971603394\n",
      "Iteration 520, Loss: 2.2317542516248068e-06, Min w: 0.9881030321121216\n",
      "Iteration 530, Loss: 2.194502030761214e-06, Min w: 0.9891277551651001\n",
      "Iteration 540, Loss: 2.027247774094576e-06, Min w: 0.9883795380592346\n",
      "Early break at iteration 543 --------------------------------\n",
      "Iteration 0, Loss: 1.6073026927188039e-06, Min w: 0.9910383224487305\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 2.2337194423016626e-06, Min w: 0.9855719208717346\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 1.971728806893225e-06, Min w: 0.9878498911857605\n",
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 2.18002082874591e-06, Min w: 0.9858489036560059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  29%|██▉       | 7/24 [03:52<07:42, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 8 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 565, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0024269716885371648, 'L2_avg': 0.004158863228969893, 'End_point_L1_avg': 0.0013192074559051832, 'End_point_L2_avg': 0.0015977798446320207}\n",
      "Iteration 0, Loss: 0.0004941032966598868, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0003624062519520521, Min w: 1.3034841740802146e-31\n",
      "Iteration 20, Loss: 0.0002680454635992646, Min w: 1.4673435089207487e-07\n",
      "Iteration 30, Loss: 0.00018974866543430835, Min w: 0.20304690301418304\n",
      "Iteration 40, Loss: 0.00014701494364999235, Min w: 0.5030409693717957\n",
      "Iteration 50, Loss: 0.00011073509813286364, Min w: 0.5849709510803223\n",
      "Iteration 60, Loss: 9.026281622936949e-05, Min w: 0.6367408633232117\n",
      "Iteration 70, Loss: 7.364036719081923e-05, Min w: 0.6635499000549316\n",
      "Iteration 80, Loss: 6.145515362732112e-05, Min w: 0.6913905143737793\n",
      "Iteration 90, Loss: 5.24659117218107e-05, Min w: 0.7241359353065491\n",
      "Iteration 100, Loss: 4.547430944512598e-05, Min w: 0.7522045373916626\n",
      "Iteration 110, Loss: 4.1243121813749894e-05, Min w: 0.7738790512084961\n",
      "Iteration 120, Loss: 3.6498091503744945e-05, Min w: 0.7969719767570496\n",
      "Iteration 130, Loss: 3.292905603302643e-05, Min w: 0.8148319721221924\n",
      "Iteration 140, Loss: 3.131306584691629e-05, Min w: 0.8254860639572144\n",
      "Iteration 150, Loss: 2.5854078558040783e-05, Min w: 0.8517399430274963\n",
      "Iteration 160, Loss: 2.5353945602546446e-05, Min w: 0.8563112020492554\n",
      "Iteration 170, Loss: 2.315595884283539e-05, Min w: 0.8684127926826477\n",
      "Iteration 180, Loss: 2.1602356355288066e-05, Min w: 0.8788231611251831\n",
      "Iteration 190, Loss: 1.8427403119858354e-05, Min w: 0.8918414115905762\n",
      "Iteration 200, Loss: 1.6254522051895037e-05, Min w: 0.9043293595314026\n",
      "Iteration 210, Loss: 1.4736896446265746e-05, Min w: 0.9161126017570496\n",
      "Iteration 220, Loss: 1.3722627045353875e-05, Min w: 0.9219394326210022\n",
      "Iteration 230, Loss: 1.240117217093939e-05, Min w: 0.9297741651535034\n",
      "Iteration 240, Loss: 1.1068262210756075e-05, Min w: 0.9393260478973389\n",
      "Iteration 250, Loss: 1.064724347088486e-05, Min w: 0.9411830306053162\n",
      "Iteration 260, Loss: 8.984849955595564e-06, Min w: 0.9503259062767029\n",
      "Iteration 270, Loss: 7.891331733844709e-06, Min w: 0.9554294347763062\n",
      "Iteration 280, Loss: 7.85386873758398e-06, Min w: 0.9560742378234863\n",
      "Iteration 290, Loss: 7.195745638455264e-06, Min w: 0.9601052403450012\n",
      "Iteration 300, Loss: 7.021034889476141e-06, Min w: 0.9618824124336243\n",
      "Iteration 310, Loss: 5.784441327705281e-06, Min w: 0.9672880172729492\n",
      "Iteration 320, Loss: 5.182120276003843e-06, Min w: 0.9712032079696655\n",
      "Iteration 330, Loss: 4.483945758693153e-06, Min w: 0.9746289253234863\n",
      "Iteration 340, Loss: 5.120731657370925e-06, Min w: 0.9723181128501892\n",
      "Iteration 350, Loss: 4.8397005230071954e-06, Min w: 0.9742880463600159\n",
      "Iteration 360, Loss: 3.926761564798653e-06, Min w: 0.9798102974891663\n",
      "Iteration 370, Loss: 3.707380301420926e-06, Min w: 0.9809162020683289\n",
      "Iteration 380, Loss: 3.5369810120755574e-06, Min w: 0.9828702211380005\n",
      "Iteration 390, Loss: 3.4621753002284095e-06, Min w: 0.9826986789703369\n",
      "Iteration 400, Loss: 2.8157198812550632e-06, Min w: 0.9858808517456055\n",
      "Iteration 410, Loss: 2.919748112617526e-06, Min w: 0.9851842522621155\n",
      "Iteration 420, Loss: 3.2640846256981604e-06, Min w: 0.9828000664710999\n",
      "Iteration 430, Loss: 2.834309498211951e-06, Min w: 0.9848297238349915\n",
      "Iteration 440, Loss: 2.852747456927318e-06, Min w: 0.9842932820320129\n",
      "Iteration 450, Loss: 3.493832764434046e-06, Min w: 0.9806461930274963\n",
      "Iteration 460, Loss: 2.88247611024417e-06, Min w: 0.9844969511032104\n",
      "Iteration 470, Loss: 2.4128657969413325e-06, Min w: 0.9866862893104553\n",
      "Iteration 480, Loss: 2.3641121060791193e-06, Min w: 0.986618161201477\n",
      "Early break at iteration 489 --------------------------------\n",
      "Iteration 0, Loss: 2.29644388127781e-06, Min w: 0.987514317035675\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 2.0987433799746213e-06, Min w: 0.9885541796684265\n",
      "Iteration 10, Loss: 1.977994088520063e-06, Min w: 0.9885624051094055\n",
      "Iteration 20, Loss: 1.85396174856578e-06, Min w: 0.9901494979858398\n",
      "Early break at iteration 20 --------------------------------\n",
      "Iteration 0, Loss: 2.6286309093848104e-06, Min w: 0.9854863286018372\n",
      "Iteration 10, Loss: 2.137524234058219e-06, Min w: 0.987941324710846\n",
      "Early break at iteration 16 --------------------------------\n",
      "Iteration 0, Loss: 2.1400792320491746e-06, Min w: 0.9884565472602844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  33%|███▎      | 8/24 [04:03<05:55, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 5 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 538, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0021649655530814865, 'L2_avg': 0.0033102083215912504, 'End_point_L1_avg': 0.0014598966723312129, 'End_point_L2_avg': 0.0019350918742644873}\n",
      "Iteration 0, Loss: 0.0020348720718175173, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0010468916734680533, Min w: 8.115258424368221e-06\n",
      "Iteration 20, Loss: 0.000588553084526211, Min w: 0.0013002598425373435\n",
      "Iteration 30, Loss: 0.00032850386924110353, Min w: 0.2815331220626831\n",
      "Iteration 40, Loss: 8.552351937396452e-05, Min w: 0.8790200352668762\n",
      "Iteration 50, Loss: 5.782900916528888e-05, Min w: 0.8885560035705566\n",
      "Iteration 60, Loss: 2.6649851861293428e-05, Min w: 0.9660495519638062\n",
      "Iteration 70, Loss: 1.3980815310787875e-05, Min w: 0.978914737701416\n",
      "Iteration 80, Loss: 8.038128726184368e-06, Min w: 0.9846962690353394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  38%|███▊      | 9/24 [04:05<03:56, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 88 --------------------------------\n",
      "Iteration 0, Loss: 6.082822437747382e-06, Min w: 0.9877812266349792\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 6.4397045207442716e-06, Min w: 0.9876841306686401\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 5.105394848214928e-06, Min w: 0.9904308319091797\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 5.183235771255568e-06, Min w: 0.9922640919685364\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 95, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.004093445778803637, 'L2_avg': 0.0055723927189980016, 'End_point_L1_avg': 0.003241475919220136, 'End_point_L2_avg': 0.004012059975553961}\n",
      "Iteration 0, Loss: 0.0018010339699685574, Min w: 4.138427339532569e-13\n",
      "Iteration 10, Loss: 0.0009562854538671672, Min w: 0.00036651839036494493\n",
      "Iteration 20, Loss: 0.0005217681755311787, Min w: 8.066783863114324e-08\n",
      "Iteration 30, Loss: 0.0002521528222132474, Min w: 0.4278630316257477\n",
      "Iteration 40, Loss: 0.0001969334261957556, Min w: 0.04449503496289253\n",
      "Iteration 50, Loss: 0.0001011393906082958, Min w: 0.5445128679275513\n",
      "Iteration 60, Loss: 5.4840627853991464e-05, Min w: 0.7242395281791687\n",
      "Iteration 70, Loss: 2.2182823158800602e-05, Min w: 0.9386223554611206\n",
      "Iteration 80, Loss: 1.7147127437056042e-05, Min w: 0.9512162208557129\n",
      "Early break at iteration 82 --------------------------------\n",
      "Iteration 0, Loss: 1.3575942830357235e-05, Min w: 0.961120069026947\n",
      "Iteration 10, Loss: 6.643480446655303e-06, Min w: 0.9880897998809814\n",
      "Early break at iteration 12 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  42%|████▏     | 10/24 [04:07<02:40, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.2512466128100641e-05, Min w: 0.9774819612503052\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 6.977662451390643e-06, Min w: 0.9891519546508789\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 8.165706276486162e-06, Min w: 0.982876718044281\n",
      "Early break at iteration 3 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 104, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.003158555928247225, 'L2_avg': 0.004132261680633539, 'End_point_L1_avg': 0.002455282890386747, 'End_point_L2_avg': 0.002850985079766997}\n",
      "Iteration 0, Loss: 0.0005315922317095101, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0004261898866388947, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0003379311237949878, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0002973973168991506, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000261781009612605, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0002227380027761683, Min w: 5.213029684879764e-30\n",
      "Iteration 60, Loss: 0.0002194033731939271, Min w: 0.0\n",
      "Iteration 70, Loss: 0.00021399823890533298, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00019274410442449152, Min w: 0.0\n",
      "Iteration 90, Loss: 0.00015478880959562957, Min w: 0.0\n",
      "Iteration 100, Loss: 0.00015818039537407458, Min w: 0.0\n",
      "Iteration 110, Loss: 0.00015856229583732784, Min w: 0.0\n",
      "Iteration 120, Loss: 0.00014883499534334987, Min w: 3.4235760452162165e-31\n",
      "Iteration 130, Loss: 0.00012744538253173232, Min w: 1.3950262882644893e-06\n",
      "Iteration 140, Loss: 9.37754666665569e-05, Min w: 3.1404331934936636e-07\n",
      "Iteration 150, Loss: 0.00013224327994976193, Min w: 0.0\n",
      "Iteration 160, Loss: 0.0001430429401807487, Min w: 2.3250513978136838e-23\n",
      "Iteration 170, Loss: 0.00013812897668685764, Min w: 3.358844876400606e-38\n",
      "Iteration 180, Loss: 0.00012643398076761514, Min w: 1.846975723735283e-20\n",
      "Iteration 190, Loss: 0.00010494405432837084, Min w: 2.0646870277415383e-24\n",
      "Iteration 200, Loss: 9.992643754230812e-05, Min w: 4.203895392974451e-45\n",
      "Iteration 210, Loss: 8.459688979201019e-05, Min w: 2.802596928649634e-45\n",
      "Iteration 220, Loss: 9.415047679794952e-05, Min w: 2.7465162714182948e-24\n",
      "Iteration 230, Loss: 7.891791756264865e-05, Min w: 5.673687672736176e-16\n",
      "Iteration 240, Loss: 5.6444117944920436e-05, Min w: 0.23086142539978027\n",
      "Iteration 250, Loss: 5.87741014896892e-05, Min w: 6.028119064215491e-25\n",
      "Iteration 260, Loss: 4.952427843818441e-05, Min w: 8.610615623183548e-06\n",
      "Iteration 270, Loss: 4.200173862045631e-05, Min w: 0.026421792805194855\n",
      "Iteration 280, Loss: 4.710013308795169e-05, Min w: 0.00010726775508373976\n",
      "Iteration 290, Loss: 4.586081558954902e-05, Min w: 2.762011641263811e-14\n",
      "Iteration 300, Loss: 4.7366582293761894e-05, Min w: 0.0\n",
      "Iteration 310, Loss: 4.7928046114975587e-05, Min w: 0.0008848645375110209\n",
      "Iteration 320, Loss: 3.846894469461404e-05, Min w: 2.58070973445379e-12\n",
      "Iteration 330, Loss: 3.2499312510481104e-05, Min w: 0.28202658891677856\n",
      "Iteration 340, Loss: 4.743771569337696e-05, Min w: 5.77460807498128e-17\n",
      "Iteration 350, Loss: 4.55190529464744e-05, Min w: 0.0\n",
      "Iteration 360, Loss: 4.557006832328625e-05, Min w: 2.9869863025599845e-15\n",
      "Iteration 370, Loss: 3.937229121220298e-05, Min w: 0.06993095576763153\n",
      "Iteration 380, Loss: 3.6419973184820265e-05, Min w: 0.1732427030801773\n",
      "Iteration 390, Loss: 2.7964193577645347e-05, Min w: 0.796245276927948\n",
      "Iteration 400, Loss: 1.8380475012236275e-05, Min w: 0.8348279595375061\n",
      "Iteration 410, Loss: 1.7494474377599545e-05, Min w: 0.8523623943328857\n",
      "Iteration 420, Loss: 1.844545840867795e-05, Min w: 0.8014994263648987\n",
      "Iteration 430, Loss: 1.2041213267366402e-05, Min w: 0.7776644825935364\n",
      "Iteration 440, Loss: 1.5221677131194156e-05, Min w: 0.8408900499343872\n",
      "Iteration 450, Loss: 1.237581545865396e-05, Min w: 0.8585124611854553\n",
      "Iteration 460, Loss: 9.364869583805557e-06, Min w: 0.8604030013084412\n",
      "Iteration 470, Loss: 1.4787788131798152e-05, Min w: 0.9065402746200562\n",
      "Iteration 480, Loss: 9.956966096069664e-06, Min w: 0.8846749067306519\n",
      "Iteration 490, Loss: 1.1547632311703637e-05, Min w: 0.8843228816986084\n",
      "Iteration 500, Loss: 1.556791175971739e-05, Min w: 0.9058833718299866\n",
      "Iteration 510, Loss: 1.1210448064957745e-05, Min w: 0.8976320028305054\n",
      "Iteration 520, Loss: 9.373259672429413e-06, Min w: 0.9127869009971619\n",
      "Iteration 530, Loss: 7.167239800764946e-06, Min w: 0.9429141879081726\n",
      "Iteration 540, Loss: 1.4607427146984264e-05, Min w: 0.9087161421775818\n",
      "Iteration 550, Loss: 1.487906320107868e-05, Min w: 0.8642228245735168\n",
      "Iteration 560, Loss: 1.3798196960124187e-05, Min w: 0.898167610168457\n",
      "Iteration 570, Loss: 1.1750126759579871e-05, Min w: 0.8928099274635315\n",
      "Iteration 580, Loss: 9.27270230022259e-06, Min w: 0.930762529373169\n",
      "Iteration 590, Loss: 6.570856385224033e-06, Min w: 0.9613969922065735\n",
      "Iteration 600, Loss: 2.2544478269992396e-05, Min w: 0.8191710710525513\n",
      "Iteration 610, Loss: 2.0793366275029257e-05, Min w: 0.8510743975639343\n",
      "Iteration 620, Loss: 9.604363185644615e-06, Min w: 0.8924373388290405\n",
      "Iteration 630, Loss: 1.0956481673929375e-05, Min w: 0.8848336338996887\n",
      "Iteration 640, Loss: 1.0303709132131189e-05, Min w: 0.9180124402046204\n",
      "Iteration 650, Loss: 1.2435935786925256e-05, Min w: 0.9037356376647949\n",
      "Iteration 660, Loss: 1.4038524568604771e-05, Min w: 0.9063268303871155\n",
      "Iteration 670, Loss: 4.045664354634937e-06, Min w: 0.932657778263092\n",
      "Iteration 680, Loss: 1.2169965884822886e-05, Min w: 0.9065536856651306\n",
      "Iteration 690, Loss: 1.0901842870225664e-05, Min w: 0.8501574993133545\n",
      "Iteration 700, Loss: 2.019227758864872e-05, Min w: 0.8140652775764465\n",
      "Iteration 710, Loss: 1.3098172530590091e-05, Min w: 0.9018973708152771\n",
      "Iteration 720, Loss: 1.2457871889637318e-05, Min w: 0.912769615650177\n",
      "Iteration 730, Loss: 9.445806426811032e-06, Min w: 0.9361392855644226\n",
      "Iteration 740, Loss: 1.752922253217548e-05, Min w: 0.9051620364189148\n",
      "Iteration 750, Loss: 2.2379570509656332e-05, Min w: 0.8232345581054688\n",
      "Iteration 760, Loss: 7.013668437139131e-06, Min w: 0.9361050128936768\n",
      "Iteration 770, Loss: 8.520454684912693e-06, Min w: 0.9067158699035645\n",
      "Iteration 780, Loss: 1.3255415979074314e-05, Min w: 0.9220479726791382\n",
      "Iteration 790, Loss: 1.752700518409256e-05, Min w: 0.8778079748153687\n",
      "Iteration 800, Loss: 1.038327445712639e-05, Min w: 0.9191778898239136\n",
      "Iteration 810, Loss: 8.63644072524039e-06, Min w: 0.9479148983955383\n",
      "Iteration 820, Loss: 2.5168646970996633e-05, Min w: 0.8912599086761475\n",
      "Iteration 830, Loss: 7.180299689935055e-06, Min w: 0.9217813611030579\n",
      "Iteration 840, Loss: 1.5047769011289347e-05, Min w: 0.9121454954147339\n",
      "Iteration 850, Loss: 1.0816250323841814e-05, Min w: 0.9347650408744812\n",
      "Iteration 860, Loss: 1.2151904229540378e-05, Min w: 0.9239367842674255\n",
      "Iteration 870, Loss: 7.795018063916359e-06, Min w: 0.9564347267150879\n",
      "Iteration 880, Loss: 9.373775355925318e-06, Min w: 0.9361227750778198\n",
      "Iteration 890, Loss: 1.1053082744183484e-05, Min w: 0.9290343523025513\n",
      "Iteration 900, Loss: 2.251480873383116e-05, Min w: 0.825572669506073\n",
      "Iteration 910, Loss: 1.4426806956180371e-05, Min w: 0.8880868554115295\n",
      "Iteration 920, Loss: 1.9794024410657585e-05, Min w: 0.9116389155387878\n",
      "Iteration 930, Loss: 8.449606866633985e-06, Min w: 0.9329138398170471\n",
      "Iteration 940, Loss: 1.1679318959068041e-05, Min w: 0.9267217516899109\n",
      "Iteration 950, Loss: 1.2875118045485578e-05, Min w: 0.9411119818687439\n",
      "Iteration 960, Loss: 8.102859283098951e-06, Min w: 0.9471237659454346\n",
      "Iteration 970, Loss: 7.036268016236136e-06, Min w: 0.951789379119873\n",
      "Iteration 980, Loss: 1.369635447190376e-05, Min w: 0.9302088618278503\n",
      "Iteration 990, Loss: 9.983020390791353e-06, Min w: 0.9312825202941895\n",
      "Iteration 1000, Loss: 1.75199984369101e-05, Min w: 0.8925231695175171\n",
      "Iteration 1010, Loss: 1.387277188769076e-05, Min w: 0.9025824069976807\n",
      "Iteration 1020, Loss: 1.4263583580031991e-05, Min w: 0.9111089110374451\n",
      "Iteration 1030, Loss: 1.1844415894302074e-05, Min w: 0.930365264415741\n",
      "Iteration 1040, Loss: 1.4228442523744889e-05, Min w: 0.9271280169487\n",
      "Iteration 1050, Loss: 7.777050996082835e-06, Min w: 0.9580029845237732\n",
      "Iteration 1060, Loss: 9.401736861036625e-06, Min w: 0.9341900944709778\n",
      "Iteration 1070, Loss: 1.8571090549812652e-05, Min w: 0.8743718266487122\n",
      "Iteration 1080, Loss: 8.243131560448091e-06, Min w: 0.9297601580619812\n",
      "Iteration 1090, Loss: 1.772196810634341e-05, Min w: 0.9123509526252747\n",
      "Iteration 1100, Loss: 7.814495802449528e-06, Min w: 0.948539674282074\n",
      "Iteration 1110, Loss: 1.2997948033444118e-05, Min w: 0.9357428550720215\n",
      "Iteration 1120, Loss: 1.6849826351972297e-05, Min w: 0.8707572817802429\n",
      "Iteration 1130, Loss: 1.4516919691232033e-05, Min w: 0.8723158836364746\n",
      "Iteration 1140, Loss: 1.954166145878844e-05, Min w: 0.8944157958030701\n",
      "Iteration 1150, Loss: 7.304843620659085e-06, Min w: 0.9292443990707397\n",
      "Iteration 1160, Loss: 1.1538263606780674e-05, Min w: 0.931016206741333\n",
      "Iteration 1170, Loss: 1.0225960068055429e-05, Min w: 0.9408825635910034\n",
      "Iteration 1180, Loss: 1.2371120647003409e-05, Min w: 0.8910709023475647\n",
      "Iteration 1190, Loss: 8.189228537958115e-06, Min w: 0.9538531303405762\n",
      "Iteration 1200, Loss: 8.772832188697066e-06, Min w: 0.9564380049705505\n",
      "Iteration 1210, Loss: 1.3314743227965664e-05, Min w: 0.9354453682899475\n",
      "Iteration 1220, Loss: 6.325266440398991e-06, Min w: 0.9544267058372498\n",
      "Iteration 1230, Loss: 1.8893142623710446e-05, Min w: 0.9179755449295044\n",
      "Iteration 1240, Loss: 1.1059049938921817e-05, Min w: 0.9013788104057312\n",
      "Iteration 0, Loss: 1.8233657101518475e-05, Min w: 0.9239745736122131\n",
      "Iteration 10, Loss: 1.066514232661575e-05, Min w: 0.9268133044242859\n",
      "Iteration 20, Loss: 7.0611458795610815e-06, Min w: 0.9434919357299805\n",
      "Iteration 30, Loss: 1.331045768893091e-05, Min w: 0.9292315244674683\n",
      "Iteration 40, Loss: 1.067885386873968e-05, Min w: 0.9237883687019348\n",
      "Iteration 50, Loss: 1.1038802767870948e-05, Min w: 0.8769871592521667\n",
      "Iteration 60, Loss: 1.1058417840104084e-05, Min w: 0.9324232935905457\n",
      "Iteration 70, Loss: 1.5244980204442982e-05, Min w: 0.9229382276535034\n",
      "Iteration 80, Loss: 9.954490451491438e-06, Min w: 0.9375293254852295\n",
      "Iteration 90, Loss: 1.2175453775853384e-05, Min w: 0.9451466798782349\n",
      "Iteration 100, Loss: 1.5951152818161063e-05, Min w: 0.90483558177948\n",
      "Iteration 110, Loss: 1.4319439287646674e-05, Min w: 0.9135949611663818\n",
      "Iteration 120, Loss: 9.005101674119942e-06, Min w: 0.9479700922966003\n",
      "Iteration 130, Loss: 7.564005045423983e-06, Min w: 0.9439542889595032\n",
      "Iteration 140, Loss: 1.5925428670016117e-05, Min w: 0.8816812634468079\n",
      "Iteration 150, Loss: 3.7050306218588958e-06, Min w: 0.9761468768119812\n",
      "Iteration 160, Loss: 1.74663400684949e-05, Min w: 0.9113172292709351\n",
      "Iteration 170, Loss: 1.054401491273893e-05, Min w: 0.9311729669570923\n",
      "Iteration 180, Loss: 7.815329809091054e-06, Min w: 0.93731689453125\n",
      "Iteration 190, Loss: 9.833785952650942e-06, Min w: 0.9087080359458923\n",
      "Iteration 200, Loss: 1.4720494618813973e-05, Min w: 0.8912954926490784\n",
      "Iteration 210, Loss: 1.1726434422598686e-05, Min w: 0.9095974564552307\n",
      "Iteration 220, Loss: 1.0939984349533916e-05, Min w: 0.9331847429275513\n",
      "Iteration 230, Loss: 6.64296067043324e-06, Min w: 0.9590714573860168\n",
      "Iteration 240, Loss: 1.4559813280357048e-05, Min w: 0.843895673751831\n",
      "Iteration 250, Loss: 1.3378264156926889e-05, Min w: 0.8685826063156128\n",
      "Iteration 260, Loss: 2.16750649997266e-05, Min w: 0.8624382615089417\n",
      "Iteration 270, Loss: 1.1125328455818817e-05, Min w: 0.9235751628875732\n",
      "Iteration 280, Loss: 1.2101793799956795e-05, Min w: 0.9396225810050964\n",
      "Iteration 290, Loss: 1.0791187378345057e-05, Min w: 0.8862523436546326\n",
      "Iteration 300, Loss: 9.595000847184565e-06, Min w: 0.9135817885398865\n",
      "Iteration 310, Loss: 1.4312651728687342e-05, Min w: 0.9057306051254272\n",
      "Iteration 320, Loss: 2.047383168246597e-05, Min w: 0.8071480393409729\n",
      "Iteration 330, Loss: 3.260033918195404e-05, Min w: 0.7637379765510559\n",
      "Iteration 340, Loss: 1.4984306289989036e-05, Min w: 0.8809233903884888\n",
      "Iteration 350, Loss: 2.4940860384958796e-05, Min w: 0.8517170548439026\n",
      "Iteration 360, Loss: 6.753244815627113e-05, Min w: 0.6017542481422424\n",
      "Iteration 370, Loss: 2.9570719561888836e-05, Min w: 0.7386155724525452\n",
      "Iteration 380, Loss: 1.0135840966540854e-05, Min w: 0.9238875508308411\n",
      "Iteration 390, Loss: 7.750330041744746e-06, Min w: 0.933955192565918\n",
      "Early break at iteration 398 --------------------------------\n",
      "Iteration 0, Loss: 1.1937357839997276e-06, Min w: 0.9865100383758545\n",
      "Early break at iteration 6 --------------------------------\n",
      "Iteration 0, Loss: 1.3122934205966885e-06, Min w: 0.9887589812278748\n",
      "Iteration 10, Loss: 4.422942311066436e-06, Min w: 0.9461398720741272\n",
      "Iteration 20, Loss: 1.2838977454521228e-06, Min w: 0.985644519329071\n",
      "Iteration 30, Loss: 4.38734286944964e-06, Min w: 0.9515945911407471\n",
      "Iteration 40, Loss: 2.061206714643049e-06, Min w: 0.9794516563415527\n",
      "Iteration 50, Loss: 3.6597273265215335e-06, Min w: 0.9710179567337036\n",
      "Iteration 60, Loss: 5.879575837752782e-06, Min w: 0.9525882601737976\n",
      "Iteration 70, Loss: 1.3528487215808127e-05, Min w: 0.8733813762664795\n",
      "Iteration 80, Loss: 3.84282429877203e-06, Min w: 0.9752435088157654\n",
      "Iteration 90, Loss: 1.0309755452908576e-05, Min w: 0.9405376315116882\n",
      "Iteration 100, Loss: 6.05182140134275e-06, Min w: 0.9526951313018799\n",
      "Iteration 110, Loss: 1.2193526345072314e-05, Min w: 0.9176936149597168\n",
      "Iteration 120, Loss: 5.465982667374192e-06, Min w: 0.968721866607666\n",
      "Iteration 130, Loss: 1.4143960470391903e-05, Min w: 0.9205622673034668\n",
      "Iteration 140, Loss: 8.044853530009277e-06, Min w: 0.9324625134468079\n",
      "Iteration 150, Loss: 1.2799616342817899e-05, Min w: 0.9200009107589722\n",
      "Iteration 160, Loss: 9.345819307782222e-06, Min w: 0.9279608130455017\n",
      "Iteration 170, Loss: 5.588139629253419e-06, Min w: 0.9573659896850586\n",
      "Iteration 180, Loss: 6.545185442519141e-06, Min w: 0.9455451965332031\n",
      "Iteration 190, Loss: 1.0706647117331158e-05, Min w: 0.9219526648521423\n",
      "Iteration 200, Loss: 1.1517913662828505e-05, Min w: 0.8902493119239807\n",
      "Iteration 210, Loss: 1.0285360986017622e-05, Min w: 0.9246090054512024\n",
      "Iteration 220, Loss: 9.533394404570572e-06, Min w: 0.8999603390693665\n",
      "Iteration 230, Loss: 1.167670234281104e-05, Min w: 0.9378045201301575\n",
      "Iteration 240, Loss: 6.3581278482161e-06, Min w: 0.9494161009788513\n",
      "Iteration 250, Loss: 1.1822895430668723e-05, Min w: 0.9229456782341003\n",
      "Iteration 260, Loss: 8.46455259306822e-06, Min w: 0.9394702315330505\n",
      "Iteration 270, Loss: 1.0931528777291533e-05, Min w: 0.9371426105499268\n",
      "Iteration 280, Loss: 9.404265256307553e-06, Min w: 0.9387436509132385\n",
      "Iteration 290, Loss: 1.1051289220631588e-05, Min w: 0.9326699376106262\n",
      "Iteration 300, Loss: 1.1458736480562948e-05, Min w: 0.9292141795158386\n",
      "Iteration 310, Loss: 1.2248276107129641e-05, Min w: 0.9091234803199768\n",
      "Iteration 320, Loss: 5.986120868328726e-06, Min w: 0.9511967301368713\n",
      "Iteration 330, Loss: 6.890769782330608e-06, Min w: 0.9459023475646973\n",
      "Iteration 340, Loss: 1.412411165802041e-05, Min w: 0.924837589263916\n",
      "Iteration 350, Loss: 6.561194823007099e-06, Min w: 0.955162525177002\n",
      "Iteration 360, Loss: 1.4136909157969058e-05, Min w: 0.9368694424629211\n",
      "Iteration 370, Loss: 1.0685612323868554e-05, Min w: 0.9225736260414124\n",
      "Iteration 380, Loss: 6.1031737459416036e-06, Min w: 0.967840313911438\n",
      "Iteration 390, Loss: 1.0752573871286586e-05, Min w: 0.9461075067520142\n",
      "Iteration 400, Loss: 7.191429631348001e-06, Min w: 0.9509465098381042\n",
      "Iteration 410, Loss: 1.2446914297470357e-05, Min w: 0.9300538897514343\n",
      "Iteration 420, Loss: 9.554356438457035e-06, Min w: 0.9415179491043091\n",
      "Iteration 430, Loss: 1.0003511306422297e-05, Min w: 0.9392938613891602\n",
      "Iteration 440, Loss: 5.106196567794541e-06, Min w: 0.9617226123809814\n",
      "Iteration 450, Loss: 1.8078411812894046e-05, Min w: 0.896796703338623\n",
      "Iteration 460, Loss: 8.211266504076775e-06, Min w: 0.9455555081367493\n",
      "Iteration 470, Loss: 1.216372493217932e-05, Min w: 0.9360354542732239\n",
      "Iteration 480, Loss: 1.2328502634773031e-05, Min w: 0.9345983266830444\n",
      "Iteration 490, Loss: 1.5033861927804537e-05, Min w: 0.9247919321060181\n",
      "Iteration 500, Loss: 5.38029689778341e-06, Min w: 0.9661835432052612\n",
      "Iteration 510, Loss: 1.4723895219503902e-05, Min w: 0.902466356754303\n",
      "Iteration 520, Loss: 6.075435521779582e-06, Min w: 0.9533637762069702\n",
      "Iteration 530, Loss: 1.8085765987052582e-05, Min w: 0.9258652329444885\n",
      "Iteration 540, Loss: 7.435907264152775e-06, Min w: 0.9472757577896118\n",
      "Iteration 550, Loss: 3.4959095955855446e-06, Min w: 0.9798026084899902\n",
      "Iteration 560, Loss: 2.8859962185379118e-05, Min w: 0.6624319553375244\n",
      "Iteration 570, Loss: 2.5001018002512865e-05, Min w: 0.7961786389350891\n",
      "Iteration 580, Loss: 1.3008970199734904e-05, Min w: 0.8849779367446899\n",
      "Iteration 590, Loss: 6.4878890952968504e-06, Min w: 0.8986427187919617\n",
      "Iteration 600, Loss: 1.9322587831993587e-05, Min w: 0.800639271736145\n",
      "Iteration 610, Loss: 1.1989310223725624e-05, Min w: 0.8793802261352539\n",
      "Iteration 620, Loss: 2.7629850592347793e-05, Min w: 0.7785022258758545\n",
      "Iteration 630, Loss: 6.767276772734476e-06, Min w: 0.9328101277351379\n",
      "Iteration 640, Loss: 3.4754100397549337e-06, Min w: 0.9725217223167419\n",
      "Iteration 650, Loss: 7.655026820430066e-06, Min w: 0.9603654742240906\n",
      "Iteration 660, Loss: 2.6641926069714827e-06, Min w: 0.978061854839325\n",
      "Early break at iteration 667 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  46%|████▌     | 11/24 [05:09<05:48, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 6.471134952334978e-07, Min w: 0.9939430356025696\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 2325, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0017559031384728827, 'L2_avg': 0.0018796900736971862, 'End_point_L1_avg': 0.0019348802460746482, 'End_point_L2_avg': 0.002436720166204034}\n",
      "Iteration 0, Loss: 0.0004867150273639709, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0003629798593465239, Min w: 1.888357383353033e-31\n",
      "Iteration 20, Loss: 0.00027848113677464426, Min w: 1.957803314594867e-27\n",
      "Iteration 30, Loss: 0.00019944441737607121, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0001746765337884426, Min w: 1.0080056124674085e-28\n",
      "Iteration 50, Loss: 0.00015851802891120315, Min w: 5.785392789633297e-16\n",
      "Iteration 60, Loss: 0.00013984317774884403, Min w: 6.481069633891442e-29\n",
      "Iteration 70, Loss: 0.00012516055721789598, Min w: 2.0957645847224634e-36\n",
      "Iteration 80, Loss: 0.0001059662681655027, Min w: 0.0\n",
      "Iteration 90, Loss: 8.624658221378922e-05, Min w: 0.0\n",
      "Iteration 100, Loss: 9.532269177725539e-05, Min w: 0.0\n",
      "Iteration 110, Loss: 9.322110417997465e-05, Min w: 1.0693992806503082e-22\n",
      "Iteration 120, Loss: 9.053396206581965e-05, Min w: 4.390163232947941e-11\n",
      "Iteration 130, Loss: 8.613206591689959e-05, Min w: 0.0008918067323975265\n",
      "Iteration 140, Loss: 9.34944036998786e-05, Min w: 0.0001252375659532845\n",
      "Iteration 150, Loss: 7.3376671934966e-05, Min w: 7.266909233294427e-05\n",
      "Iteration 160, Loss: 5.4417309002019465e-05, Min w: 8.513614119243229e-11\n",
      "Iteration 170, Loss: 6.127925735199824e-05, Min w: 0.0019303382141515613\n",
      "Iteration 180, Loss: 6.496316200355068e-05, Min w: 4.34028152085375e-06\n",
      "Iteration 190, Loss: 7.140642264857888e-05, Min w: 0.00013990819570608437\n",
      "Iteration 200, Loss: 5.908601087867282e-05, Min w: 0.02564537525177002\n",
      "Iteration 210, Loss: 5.6617631344124675e-05, Min w: 1.7483265529836443e-29\n",
      "Iteration 220, Loss: 5.825897824252024e-05, Min w: 1.1908228682376131e-15\n",
      "Iteration 230, Loss: 2.976152791234199e-05, Min w: 0.6603683829307556\n",
      "Iteration 240, Loss: 6.133855640655383e-05, Min w: 0.0013859084574505687\n",
      "Iteration 250, Loss: 5.5608190450584516e-05, Min w: 0.046815961599349976\n",
      "Iteration 260, Loss: 5.436511128209531e-05, Min w: 0.001333856605924666\n",
      "Iteration 270, Loss: 5.244150088401511e-05, Min w: 1.7180466601821442e-21\n",
      "Iteration 280, Loss: 5.2597049943869933e-05, Min w: 3.793986017861784e-20\n",
      "Iteration 290, Loss: 6.178059265948832e-05, Min w: 5.715660160703798e-30\n",
      "Iteration 300, Loss: 6.044054316589609e-05, Min w: 0.0\n",
      "Iteration 310, Loss: 5.134122329764068e-05, Min w: 3.635547375299697e-12\n",
      "Iteration 320, Loss: 6.031713564880192e-05, Min w: 1.4364813190023755e-25\n",
      "Iteration 330, Loss: 5.9385649365140125e-05, Min w: 0.0\n",
      "Iteration 340, Loss: 5.3600633691530675e-05, Min w: 0.0\n",
      "Iteration 350, Loss: 5.727402458433062e-05, Min w: 1.2434411833517345e-10\n",
      "Iteration 360, Loss: 5.481377957039513e-05, Min w: 0.025288265198469162\n",
      "Iteration 370, Loss: 4.438102405401878e-05, Min w: 0.5815203785896301\n",
      "Iteration 380, Loss: 4.341417661635205e-05, Min w: 0.5019903779029846\n",
      "Iteration 390, Loss: 2.5676061341073364e-05, Min w: 0.685732901096344\n",
      "Iteration 400, Loss: 2.291364762641024e-05, Min w: 0.6736677289009094\n",
      "Iteration 410, Loss: 2.9733106202911586e-05, Min w: 0.6768550872802734\n",
      "Iteration 420, Loss: 2.5804396500461735e-05, Min w: 0.6568610668182373\n",
      "Iteration 430, Loss: 2.7240548661211506e-05, Min w: 0.6866814494132996\n",
      "Iteration 440, Loss: 2.3511207473347895e-05, Min w: 0.6703792214393616\n",
      "Iteration 450, Loss: 2.760279312497005e-05, Min w: 0.6788077354431152\n",
      "Iteration 460, Loss: 2.6669273211155087e-05, Min w: 0.6604883074760437\n",
      "Iteration 470, Loss: 2.489160578988958e-05, Min w: 0.6840368509292603\n",
      "Iteration 480, Loss: 2.676224903552793e-05, Min w: 0.6676691174507141\n",
      "Iteration 490, Loss: 2.3641225197934546e-05, Min w: 0.680303692817688\n",
      "Iteration 500, Loss: 2.8251035473658703e-05, Min w: 0.6629679203033447\n",
      "Iteration 510, Loss: 2.712924833758734e-05, Min w: 0.6784054636955261\n",
      "Iteration 520, Loss: 2.4695933461771347e-05, Min w: 0.6678029894828796\n",
      "Iteration 530, Loss: 2.5962162908399478e-05, Min w: 0.6780616044998169\n",
      "Iteration 540, Loss: 2.4836444936227053e-05, Min w: 0.672832727432251\n",
      "Iteration 550, Loss: 2.654475247254595e-05, Min w: 0.679312527179718\n",
      "Iteration 560, Loss: 2.5744546292116866e-05, Min w: 0.6657779812812805\n",
      "Iteration 570, Loss: 2.7237014364800416e-05, Min w: 0.6786357760429382\n",
      "Iteration 580, Loss: 2.270519507874269e-05, Min w: 0.6783312559127808\n",
      "Iteration 590, Loss: 2.4074579414445907e-05, Min w: 0.6802874803543091\n",
      "Iteration 600, Loss: 2.556939762143884e-05, Min w: 0.6691144108772278\n",
      "Iteration 610, Loss: 2.550088356656488e-05, Min w: 0.6799869537353516\n",
      "Iteration 620, Loss: 2.2975737010710873e-05, Min w: 0.676626980304718\n",
      "Iteration 630, Loss: 2.6471636374481022e-05, Min w: 0.6802729368209839\n",
      "Iteration 640, Loss: 2.6066456484841183e-05, Min w: 0.6663432121276855\n",
      "Iteration 650, Loss: 2.383517858106643e-05, Min w: 0.68132483959198\n",
      "Iteration 660, Loss: 2.7500505893840455e-05, Min w: 0.6660920977592468\n",
      "Iteration 670, Loss: 2.5279801775468513e-05, Min w: 0.6826550960540771\n",
      "Iteration 680, Loss: 2.7882575523108244e-05, Min w: 0.6741104125976562\n",
      "Iteration 690, Loss: 2.850721102731768e-05, Min w: 0.6855093836784363\n",
      "Iteration 700, Loss: 2.312968899786938e-05, Min w: 0.6724117994308472\n",
      "Iteration 710, Loss: 2.6200521460850723e-05, Min w: 0.6815080046653748\n",
      "Iteration 720, Loss: 2.9382401407929137e-05, Min w: 0.6737160682678223\n",
      "Iteration 730, Loss: 2.584666981420014e-05, Min w: 0.6763083934783936\n",
      "Iteration 740, Loss: 2.656394281075336e-05, Min w: 0.6755317449569702\n",
      "Iteration 750, Loss: 2.6684796466724947e-05, Min w: 0.6823034286499023\n",
      "Iteration 760, Loss: 2.4270981157314964e-05, Min w: 0.6736431121826172\n",
      "Iteration 770, Loss: 2.1799665773869492e-05, Min w: 0.6806584000587463\n",
      "Iteration 780, Loss: 2.9410828574327752e-05, Min w: 0.6861600279808044\n",
      "Iteration 790, Loss: 2.6311952751711942e-05, Min w: 0.6743989586830139\n",
      "Iteration 800, Loss: 2.7347557988832705e-05, Min w: 0.6816228032112122\n",
      "Iteration 810, Loss: 2.67579252977157e-05, Min w: 0.6684502959251404\n",
      "Iteration 820, Loss: 2.6039006115752272e-05, Min w: 0.6744247674942017\n",
      "Iteration 830, Loss: 2.5257450033677742e-05, Min w: 0.6801635026931763\n",
      "Iteration 840, Loss: 2.4251959985122085e-05, Min w: 0.6734487414360046\n",
      "Iteration 850, Loss: 2.3899172447272576e-05, Min w: 0.6762104630470276\n",
      "Iteration 860, Loss: 2.462846168782562e-05, Min w: 0.6870467662811279\n",
      "Iteration 870, Loss: 2.2686848751618527e-05, Min w: 0.680474042892456\n",
      "Iteration 880, Loss: 2.475845394656062e-05, Min w: 0.6854519844055176\n",
      "Iteration 890, Loss: 2.500286245776806e-05, Min w: 0.6795917749404907\n",
      "Iteration 900, Loss: 2.672642222023569e-05, Min w: 0.6755498647689819\n",
      "Iteration 910, Loss: 2.2298037947621197e-05, Min w: 0.6799313426017761\n",
      "Iteration 920, Loss: 2.3083173800841905e-05, Min w: 0.687683641910553\n",
      "Iteration 930, Loss: 2.580006002972368e-05, Min w: 0.686388373374939\n",
      "Iteration 940, Loss: 2.4042075892793946e-05, Min w: 0.6824380159378052\n",
      "Iteration 950, Loss: 2.3529608370154165e-05, Min w: 0.6820467114448547\n",
      "Iteration 960, Loss: 2.416701136098709e-05, Min w: 0.6806633472442627\n",
      "Iteration 970, Loss: 2.3623757442692295e-05, Min w: 0.6786455512046814\n",
      "Iteration 980, Loss: 3.739020030479878e-05, Min w: 0.6906323432922363\n",
      "Iteration 990, Loss: 2.793890052998904e-05, Min w: 0.6793723106384277\n",
      "Iteration 1000, Loss: 2.2353882741299458e-05, Min w: 0.688075065612793\n",
      "Iteration 1010, Loss: 2.430540007480886e-05, Min w: 0.6779213547706604\n",
      "Iteration 1020, Loss: 2.292109638801776e-05, Min w: 0.677978515625\n",
      "Iteration 1030, Loss: 2.272966412419919e-05, Min w: 0.6866282820701599\n",
      "Iteration 1040, Loss: 2.8071530323359184e-05, Min w: 0.6806257963180542\n",
      "Iteration 1050, Loss: 2.7310828954796307e-05, Min w: 0.6800979375839233\n",
      "Iteration 1060, Loss: 2.639305603224784e-05, Min w: 0.6798313856124878\n",
      "Iteration 1070, Loss: 2.353781383135356e-05, Min w: 0.6908458471298218\n",
      "Iteration 1080, Loss: 2.4685750759090297e-05, Min w: 0.6740478873252869\n",
      "Iteration 1090, Loss: 2.3894679543445818e-05, Min w: 0.6870607137680054\n",
      "Iteration 1100, Loss: 2.2843007172923535e-05, Min w: 0.6809790134429932\n",
      "Iteration 1110, Loss: 2.294223668286577e-05, Min w: 0.6961175799369812\n",
      "Iteration 1120, Loss: 2.345636676182039e-05, Min w: 0.6830348372459412\n",
      "Iteration 1130, Loss: 2.240514186269138e-05, Min w: 0.6875019073486328\n",
      "Iteration 1140, Loss: 3.154041769448668e-05, Min w: 0.7038100957870483\n",
      "Iteration 1150, Loss: 2.700277036637999e-05, Min w: 0.6824663877487183\n",
      "Iteration 1160, Loss: 2.0406112525961362e-05, Min w: 0.6864508390426636\n",
      "Iteration 1170, Loss: 2.6472036552149802e-05, Min w: 0.6829065084457397\n",
      "Iteration 1180, Loss: 2.3749547835905105e-05, Min w: 0.6864216923713684\n",
      "Iteration 1190, Loss: 2.3684055122430436e-05, Min w: 0.6826192140579224\n",
      "Iteration 1200, Loss: 2.332650365133304e-05, Min w: 0.6913036108016968\n",
      "Iteration 1210, Loss: 2.4125234631355852e-05, Min w: 0.6845323443412781\n",
      "Iteration 1220, Loss: 2.4738519641687162e-05, Min w: 0.6853412985801697\n",
      "Iteration 1230, Loss: 2.3144470105762593e-05, Min w: 0.6833564043045044\n",
      "Iteration 1240, Loss: 2.4372759071411565e-05, Min w: 0.6889368891716003\n",
      "Iteration 0, Loss: 2.2104855815996416e-05, Min w: 0.6938866376876831\n",
      "Iteration 10, Loss: 2.3581698769703507e-05, Min w: 0.6943708062171936\n",
      "Iteration 20, Loss: 2.4437840693281032e-05, Min w: 0.6894776225090027\n",
      "Iteration 30, Loss: 2.689603752514813e-05, Min w: 0.6953162550926208\n",
      "Iteration 40, Loss: 2.619324004626833e-05, Min w: 0.6842588186264038\n",
      "Iteration 50, Loss: 2.4308510546688922e-05, Min w: 0.6934949159622192\n",
      "Iteration 60, Loss: 2.3677370336372405e-05, Min w: 0.682264506816864\n",
      "Iteration 70, Loss: 2.262684029119555e-05, Min w: 0.6913579702377319\n",
      "Iteration 80, Loss: 2.182077878387645e-05, Min w: 0.6966384053230286\n",
      "Iteration 90, Loss: 2.4486949769197963e-05, Min w: 0.696779727935791\n",
      "Iteration 100, Loss: 2.0829073037020862e-05, Min w: 0.6966202855110168\n",
      "Iteration 110, Loss: 2.2530226488015614e-05, Min w: 0.6996615529060364\n",
      "Iteration 120, Loss: 2.016680082306266e-05, Min w: 0.6997712254524231\n",
      "Iteration 130, Loss: 2.4578479496994987e-05, Min w: 0.696143388748169\n",
      "Iteration 140, Loss: 2.397397292952519e-05, Min w: 0.694842517375946\n",
      "Iteration 150, Loss: 2.2588545107282698e-05, Min w: 0.6990233659744263\n",
      "Iteration 160, Loss: 2.3192276785266586e-05, Min w: 0.6923639178276062\n",
      "Iteration 170, Loss: 2.174557448597625e-05, Min w: 0.6961708068847656\n",
      "Iteration 180, Loss: 2.196153945988044e-05, Min w: 0.6930012106895447\n",
      "Iteration 190, Loss: 2.2952755898586474e-05, Min w: 0.6972860097885132\n",
      "Iteration 200, Loss: 2.043443964794278e-05, Min w: 0.691498339176178\n",
      "Iteration 210, Loss: 2.421113822492771e-05, Min w: 0.7010084390640259\n",
      "Iteration 220, Loss: 2.473200947861187e-05, Min w: 0.6984524726867676\n",
      "Iteration 230, Loss: 2.448095619911328e-05, Min w: 0.6921321153640747\n",
      "Iteration 240, Loss: 2.5689907488413155e-05, Min w: 0.6954127550125122\n",
      "Iteration 250, Loss: 2.2167465431266464e-05, Min w: 0.6978604793548584\n",
      "Iteration 260, Loss: 2.4958302674349397e-05, Min w: 0.6998081803321838\n",
      "Iteration 270, Loss: 2.2012691260897554e-05, Min w: 0.7007739543914795\n",
      "Iteration 280, Loss: 2.3034048354020342e-05, Min w: 0.6947610974311829\n",
      "Iteration 290, Loss: 2.367249908274971e-05, Min w: 0.6934818625450134\n",
      "Iteration 300, Loss: 2.2396428903448395e-05, Min w: 0.6980003714561462\n",
      "Iteration 310, Loss: 2.180774936277885e-05, Min w: 0.6968399882316589\n",
      "Iteration 320, Loss: 2.086710992443841e-05, Min w: 0.7016552090644836\n",
      "Iteration 330, Loss: 2.5079933038796298e-05, Min w: 0.6969941258430481\n",
      "Iteration 340, Loss: 3.045685116376262e-05, Min w: 0.6990388035774231\n",
      "Iteration 350, Loss: 1.989156771742273e-05, Min w: 0.7114776968955994\n",
      "Iteration 360, Loss: 2.0899897208437324e-05, Min w: 0.7110768556594849\n",
      "Iteration 370, Loss: 2.768803278740961e-05, Min w: 0.7298016548156738\n",
      "Iteration 380, Loss: 1.896036701509729e-05, Min w: 0.7428787350654602\n",
      "Iteration 390, Loss: 1.48890767377452e-05, Min w: 0.7921077609062195\n",
      "Iteration 400, Loss: 1.2107549082429614e-05, Min w: 0.9335309267044067\n",
      "Iteration 410, Loss: 8.082152817223687e-06, Min w: 0.9463968873023987\n",
      "Iteration 420, Loss: 9.364483958052006e-06, Min w: 0.9281415939331055\n",
      "Iteration 430, Loss: 1.2927099305670708e-05, Min w: 0.9276694655418396\n",
      "Iteration 440, Loss: 9.914051588566508e-06, Min w: 0.9390600919723511\n",
      "Iteration 450, Loss: 1.3604255400423426e-05, Min w: 0.9245337247848511\n",
      "Iteration 460, Loss: 1.1261767212999985e-05, Min w: 0.9337752461433411\n",
      "Iteration 470, Loss: 1.3389946616371162e-05, Min w: 0.9111994504928589\n",
      "Iteration 480, Loss: 9.96573635347886e-06, Min w: 0.9413471221923828\n",
      "Iteration 490, Loss: 1.0590567399049178e-05, Min w: 0.9452475309371948\n",
      "Iteration 500, Loss: 5.886663075216347e-06, Min w: 0.945999264717102\n",
      "Iteration 510, Loss: 1.0617400221235584e-05, Min w: 0.9229480624198914\n",
      "Iteration 520, Loss: 1.521252761449432e-05, Min w: 0.930237889289856\n",
      "Iteration 530, Loss: 1.0065202332043555e-05, Min w: 0.9299749732017517\n",
      "Iteration 540, Loss: 1.529442124592606e-05, Min w: 0.9021053910255432\n",
      "Iteration 550, Loss: 1.5401270502479747e-05, Min w: 0.8840860724449158\n",
      "Iteration 560, Loss: 1.7255280909012072e-05, Min w: 0.8922861218452454\n",
      "Iteration 570, Loss: 1.279363550565904e-05, Min w: 0.8869161605834961\n",
      "Iteration 580, Loss: 5.836983291374054e-06, Min w: 0.9416173100471497\n",
      "Iteration 590, Loss: 1.7065507563529536e-05, Min w: 0.8884268999099731\n",
      "Iteration 600, Loss: 1.2886598597106058e-05, Min w: 0.9233037233352661\n",
      "Iteration 610, Loss: 1.1496666957100388e-05, Min w: 0.916654646396637\n",
      "Iteration 620, Loss: 1.1791151337092742e-05, Min w: 0.9240666627883911\n",
      "Iteration 630, Loss: 9.111548024520744e-06, Min w: 0.9257065057754517\n",
      "Iteration 640, Loss: 1.0458624274178874e-05, Min w: 0.9437342882156372\n",
      "Iteration 650, Loss: 9.449578101339284e-06, Min w: 0.9421070218086243\n",
      "Iteration 660, Loss: 2.0493265765253454e-05, Min w: 0.9051732420921326\n",
      "Iteration 670, Loss: 1.1140476090076845e-05, Min w: 0.9183963537216187\n",
      "Iteration 680, Loss: 1.9250321201980114e-05, Min w: 0.8621866106987\n",
      "Iteration 690, Loss: 1.417896055500023e-05, Min w: 0.8703891634941101\n",
      "Iteration 700, Loss: 8.747689207666554e-06, Min w: 0.9151065945625305\n",
      "Iteration 710, Loss: 1.0813578228408005e-05, Min w: 0.9313593506813049\n",
      "Iteration 720, Loss: 7.743332389509305e-06, Min w: 0.9306736588478088\n",
      "Iteration 730, Loss: 8.990768947114702e-06, Min w: 0.9345908761024475\n",
      "Iteration 740, Loss: 1.0788330655486789e-05, Min w: 0.924527645111084\n",
      "Iteration 750, Loss: 2.1888788978685625e-05, Min w: 0.87274569272995\n",
      "Iteration 760, Loss: 6.478625891759293e-06, Min w: 0.9481729865074158\n",
      "Iteration 770, Loss: 1.7174908862216398e-05, Min w: 0.9240612983703613\n",
      "Iteration 780, Loss: 1.0354097867093515e-05, Min w: 0.9352961182594299\n",
      "Iteration 790, Loss: 9.906984814733732e-06, Min w: 0.9493271112442017\n",
      "Iteration 800, Loss: 1.2174295989098027e-05, Min w: 0.9329335689544678\n",
      "Iteration 810, Loss: 9.923031029757112e-06, Min w: 0.9430856704711914\n",
      "Iteration 820, Loss: 9.780781510926317e-06, Min w: 0.9317518472671509\n",
      "Iteration 830, Loss: 1.2129629794799257e-05, Min w: 0.924430787563324\n",
      "Iteration 840, Loss: 6.8411459324124735e-06, Min w: 0.9390402436256409\n",
      "Iteration 850, Loss: 1.0034998922492377e-05, Min w: 0.93511962890625\n",
      "Iteration 860, Loss: 1.0549526450631674e-05, Min w: 0.9434780478477478\n",
      "Iteration 870, Loss: 1.0266455319651868e-05, Min w: 0.92988121509552\n",
      "Iteration 880, Loss: 8.606805749877822e-06, Min w: 0.9419992566108704\n",
      "Iteration 890, Loss: 1.6875321307452396e-05, Min w: 0.8887535333633423\n",
      "Iteration 900, Loss: 1.559156044095289e-05, Min w: 0.8888720273971558\n",
      "Iteration 910, Loss: 1.0970518815156538e-05, Min w: 0.9314906597137451\n",
      "Iteration 920, Loss: 9.41966300160857e-06, Min w: 0.9354658126831055\n",
      "Iteration 930, Loss: 1.0634435056999791e-05, Min w: 0.9324567317962646\n",
      "Iteration 940, Loss: 1.0902444955718238e-05, Min w: 0.9091131091117859\n",
      "Iteration 950, Loss: 1.3470704288920388e-05, Min w: 0.9306728839874268\n",
      "Iteration 960, Loss: 8.680645805725362e-06, Min w: 0.9523231387138367\n",
      "Iteration 970, Loss: 1.5732326573925093e-05, Min w: 0.9093497395515442\n",
      "Iteration 980, Loss: 1.3788007890980225e-05, Min w: 0.897028386592865\n",
      "Iteration 990, Loss: 9.790212970983703e-06, Min w: 0.9323158264160156\n",
      "Iteration 1000, Loss: 1.2516311471699737e-05, Min w: 0.9303106069564819\n",
      "Iteration 1010, Loss: 1.2956335922353901e-05, Min w: 0.9082274436950684\n",
      "Iteration 1020, Loss: 1.2781741133949254e-05, Min w: 0.9262784123420715\n",
      "Iteration 1030, Loss: 1.154157507698983e-05, Min w: 0.9176668524742126\n",
      "Iteration 1040, Loss: 1.1223274668736849e-05, Min w: 0.9204772114753723\n",
      "Iteration 1050, Loss: 1.1248987902945373e-05, Min w: 0.9211862087249756\n",
      "Iteration 1060, Loss: 1.0504572856007144e-05, Min w: 0.9235556125640869\n",
      "Iteration 1070, Loss: 9.066265192814171e-06, Min w: 0.9341791868209839\n",
      "Iteration 1080, Loss: 1.182025243906537e-05, Min w: 0.93113112449646\n",
      "Iteration 1090, Loss: 1.0249253136862535e-05, Min w: 0.9287936687469482\n",
      "Iteration 1100, Loss: 1.645094198465813e-05, Min w: 0.9150237441062927\n",
      "Iteration 1110, Loss: 1.33878629640094e-05, Min w: 0.932838499546051\n",
      "Iteration 1120, Loss: 1.5086353414517362e-05, Min w: 0.9291465878486633\n",
      "Iteration 1130, Loss: 1.1734263352991547e-05, Min w: 0.9292505383491516\n",
      "Iteration 1140, Loss: 1.1802323570009321e-05, Min w: 0.9428826570510864\n",
      "Iteration 1150, Loss: 9.09381196834147e-06, Min w: 0.9502848386764526\n",
      "Iteration 1160, Loss: 1.1119384907942731e-05, Min w: 0.9172376394271851\n",
      "Iteration 1170, Loss: 8.735696610528976e-06, Min w: 0.9600616693496704\n",
      "Iteration 1180, Loss: 1.0060067324957345e-05, Min w: 0.941791832447052\n",
      "Iteration 1190, Loss: 1.1042310688935686e-05, Min w: 0.9199336767196655\n",
      "Iteration 1200, Loss: 1.755405537551269e-05, Min w: 0.9037806987762451\n",
      "Iteration 1210, Loss: 1.526214327896014e-05, Min w: 0.9040718674659729\n",
      "Iteration 1220, Loss: 1.3850378309143707e-05, Min w: 0.915503978729248\n",
      "Iteration 1230, Loss: 1.0794027730298694e-05, Min w: 0.9241524338722229\n",
      "Iteration 1240, Loss: 1.101567340811016e-05, Min w: 0.937717854976654\n",
      "Iteration 0, Loss: 1.0583495168248191e-05, Min w: 0.922771155834198\n",
      "Iteration 10, Loss: 1.1081481716246344e-05, Min w: 0.9196155071258545\n",
      "Iteration 20, Loss: 1.0482041034265421e-05, Min w: 0.9318326115608215\n",
      "Iteration 30, Loss: 1.4903633200447075e-05, Min w: 0.9050984978675842\n",
      "Iteration 40, Loss: 1.143153895100113e-05, Min w: 0.909439206123352\n",
      "Iteration 50, Loss: 1.2835021152568515e-05, Min w: 0.9245933890342712\n",
      "Iteration 60, Loss: 1.4707233276567422e-05, Min w: 0.9091061949729919\n",
      "Iteration 70, Loss: 1.2783092643076088e-05, Min w: 0.8982983827590942\n",
      "Iteration 80, Loss: 1.553669608256314e-05, Min w: 0.8909741640090942\n",
      "Iteration 90, Loss: 1.1791757970058825e-05, Min w: 0.9056063294410706\n",
      "Iteration 100, Loss: 1.5093876754690427e-05, Min w: 0.9141013026237488\n",
      "Iteration 110, Loss: 1.6585754565312527e-05, Min w: 0.9079703092575073\n",
      "Iteration 120, Loss: 1.3516767467081081e-05, Min w: 0.9267295002937317\n",
      "Iteration 130, Loss: 1.259128657693509e-05, Min w: 0.9298452138900757\n",
      "Iteration 140, Loss: 1.3208723430579994e-05, Min w: 0.9324543476104736\n",
      "Iteration 150, Loss: 1.1461988833616488e-05, Min w: 0.9365921020507812\n",
      "Iteration 160, Loss: 1.1745894880732521e-05, Min w: 0.9331169724464417\n",
      "Iteration 170, Loss: 1.4353682672663126e-05, Min w: 0.9306765794754028\n",
      "Iteration 180, Loss: 1.0863748684641905e-05, Min w: 0.9322326183319092\n",
      "Iteration 190, Loss: 1.3430611033982132e-05, Min w: 0.9261035323143005\n",
      "Iteration 200, Loss: 1.5012408766779117e-05, Min w: 0.9195632338523865\n",
      "Iteration 210, Loss: 1.5308540241676383e-05, Min w: 0.8597202897071838\n",
      "Iteration 220, Loss: 1.5266228729160503e-05, Min w: 0.8812989592552185\n",
      "Iteration 230, Loss: 1.6693125871825032e-05, Min w: 0.9109644293785095\n",
      "Iteration 240, Loss: 1.3067066902294755e-05, Min w: 0.9081405997276306\n",
      "Iteration 250, Loss: 1.5506577256019227e-05, Min w: 0.9042587876319885\n",
      "Iteration 260, Loss: 1.3927551663073245e-05, Min w: 0.9125478267669678\n",
      "Iteration 270, Loss: 1.2184462320874445e-05, Min w: 0.9267579317092896\n",
      "Iteration 280, Loss: 1.3291813047544565e-05, Min w: 0.9336026906967163\n",
      "Iteration 290, Loss: 1.0467828360560816e-05, Min w: 0.942906379699707\n",
      "Iteration 300, Loss: 1.0906658644671552e-05, Min w: 0.9487778544425964\n",
      "Iteration 310, Loss: 1.2226933904457837e-05, Min w: 0.9409121870994568\n",
      "Iteration 320, Loss: 1.1643483048828784e-05, Min w: 0.93203204870224\n",
      "Iteration 330, Loss: 1.0585713425825816e-05, Min w: 0.9329712986946106\n",
      "Iteration 340, Loss: 1.2520112250058446e-05, Min w: 0.9335964918136597\n",
      "Iteration 350, Loss: 1.3054531336820219e-05, Min w: 0.9252260327339172\n",
      "Iteration 360, Loss: 9.41018333833199e-06, Min w: 0.942352831363678\n",
      "Iteration 370, Loss: 1.3266902897157706e-05, Min w: 0.9317763447761536\n",
      "Iteration 380, Loss: 1.6458105164929293e-05, Min w: 0.8770596981048584\n",
      "Iteration 390, Loss: 2.2850779714644887e-05, Min w: 0.8560388684272766\n",
      "Iteration 400, Loss: 1.4784152881475165e-05, Min w: 0.9009137153625488\n",
      "Iteration 410, Loss: 1.1918259588128421e-05, Min w: 0.9247836470603943\n",
      "Iteration 420, Loss: 1.715731923468411e-05, Min w: 0.9039526581764221\n",
      "Iteration 430, Loss: 1.1492019439174328e-05, Min w: 0.9234248399734497\n",
      "Iteration 440, Loss: 1.1276266377535649e-05, Min w: 0.9210190176963806\n",
      "Iteration 450, Loss: 1.8406046365271322e-05, Min w: 0.8898747563362122\n",
      "Iteration 460, Loss: 1.0186337931372691e-05, Min w: 0.9475830793380737\n",
      "Iteration 470, Loss: 1.2948301446158439e-05, Min w: 0.9271419048309326\n",
      "Iteration 480, Loss: 1.2646436516661197e-05, Min w: 0.9309895634651184\n",
      "Iteration 490, Loss: 1.5295849152607843e-05, Min w: 0.9290335774421692\n",
      "Iteration 500, Loss: 1.401595272909617e-05, Min w: 0.938721776008606\n",
      "Iteration 510, Loss: 1.7591859432286583e-05, Min w: 0.8942477703094482\n",
      "Iteration 520, Loss: 1.3920275705459062e-05, Min w: 0.9344861507415771\n",
      "Iteration 530, Loss: 1.1323481885483488e-05, Min w: 0.9403350949287415\n",
      "Iteration 540, Loss: 1.2106755093554966e-05, Min w: 0.941459596157074\n",
      "Iteration 550, Loss: 1.5942310710670426e-05, Min w: 0.9168761968612671\n",
      "Iteration 560, Loss: 1.3181177564547397e-05, Min w: 0.9272145628929138\n",
      "Iteration 570, Loss: 1.041716222971445e-05, Min w: 0.9483375549316406\n",
      "Iteration 580, Loss: 1.4363042282639071e-05, Min w: 0.9162552952766418\n",
      "Iteration 590, Loss: 1.1347811778250616e-05, Min w: 0.9199375510215759\n",
      "Iteration 600, Loss: 2.198662332375534e-05, Min w: 0.8555010557174683\n",
      "Iteration 610, Loss: 1.4163916603138205e-05, Min w: 0.9333586096763611\n",
      "Iteration 620, Loss: 1.3812466022500303e-05, Min w: 0.933784544467926\n",
      "Iteration 630, Loss: 1.1686491234286223e-05, Min w: 0.9463596343994141\n",
      "Iteration 640, Loss: 1.4509909306070767e-05, Min w: 0.927161693572998\n",
      "Iteration 650, Loss: 8.678529411554337e-06, Min w: 0.9362375140190125\n",
      "Iteration 660, Loss: 1.177376998384716e-05, Min w: 0.9480879306793213\n",
      "Iteration 670, Loss: 1.4053753147891257e-05, Min w: 0.9356011152267456\n",
      "Iteration 680, Loss: 1.1585171705519315e-05, Min w: 0.9350925087928772\n",
      "Iteration 690, Loss: 2.547895383031573e-05, Min w: 0.8117751479148865\n",
      "Iteration 700, Loss: 7.74801810621284e-06, Min w: 0.940651535987854\n",
      "Iteration 710, Loss: 1.615415749256499e-05, Min w: 0.9235765933990479\n",
      "Iteration 720, Loss: 1.1391825864848215e-05, Min w: 0.9344021677970886\n",
      "Iteration 730, Loss: 1.4047443983145058e-05, Min w: 0.9235918521881104\n",
      "Iteration 740, Loss: 1.1409708349674474e-05, Min w: 0.9170701503753662\n",
      "Iteration 750, Loss: 1.1879827980010305e-05, Min w: 0.9271712303161621\n",
      "Iteration 760, Loss: 1.5471943697775714e-05, Min w: 0.9166702628135681\n",
      "Iteration 770, Loss: 1.1404089491406921e-05, Min w: 0.9406062364578247\n",
      "Iteration 780, Loss: 1.1960460142290685e-05, Min w: 0.9345476627349854\n",
      "Iteration 790, Loss: 1.567659455758985e-05, Min w: 0.8952428102493286\n",
      "Iteration 800, Loss: 1.7943701095646247e-05, Min w: 0.8328388333320618\n",
      "Iteration 810, Loss: 1.4856726920697838e-05, Min w: 0.883958101272583\n",
      "Iteration 820, Loss: 1.2739174053422175e-05, Min w: 0.9002005457878113\n",
      "Iteration 830, Loss: 1.009053630696144e-05, Min w: 0.9257065653800964\n",
      "Iteration 840, Loss: 1.814875940908678e-05, Min w: 0.904528796672821\n",
      "Iteration 850, Loss: 1.0357995961385313e-05, Min w: 0.9110700488090515\n",
      "Iteration 860, Loss: 1.5988318409654312e-05, Min w: 0.9024398922920227\n",
      "Iteration 870, Loss: 9.06402783584781e-06, Min w: 0.9515555500984192\n",
      "Iteration 880, Loss: 1.3426335499389097e-05, Min w: 0.9202046394348145\n",
      "Iteration 890, Loss: 1.583786252012942e-05, Min w: 0.920160710811615\n",
      "Iteration 900, Loss: 1.252692163689062e-05, Min w: 0.929997444152832\n",
      "Iteration 910, Loss: 1.276747843803605e-05, Min w: 0.9393052458763123\n",
      "Iteration 920, Loss: 1.1214101505174767e-05, Min w: 0.9411821961402893\n",
      "Iteration 930, Loss: 9.530153874948155e-06, Min w: 0.9485510587692261\n",
      "Iteration 940, Loss: 1.338946822215803e-05, Min w: 0.9378718137741089\n",
      "Iteration 950, Loss: 8.599569810030516e-06, Min w: 0.9458981156349182\n",
      "Iteration 960, Loss: 1.0836062756425235e-05, Min w: 0.9570448994636536\n",
      "Iteration 970, Loss: 1.739976869430393e-05, Min w: 0.9278258085250854\n",
      "Iteration 980, Loss: 1.4097444363869727e-05, Min w: 0.9064972400665283\n",
      "Iteration 990, Loss: 2.4068269340205006e-05, Min w: 0.8621466159820557\n",
      "Iteration 1000, Loss: 1.0366680726292543e-05, Min w: 0.9318932294845581\n",
      "Iteration 1010, Loss: 1.2796679584425874e-05, Min w: 0.9430522918701172\n",
      "Iteration 1020, Loss: 1.326444726146292e-05, Min w: 0.9102246761322021\n",
      "Iteration 1030, Loss: 9.656914699007757e-06, Min w: 0.9359561204910278\n",
      "Iteration 1040, Loss: 1.573380177433137e-05, Min w: 0.9284660816192627\n",
      "Iteration 1050, Loss: 9.826162568060681e-06, Min w: 0.9400243163108826\n",
      "Iteration 1060, Loss: 1.2441947546903975e-05, Min w: 0.9401305317878723\n",
      "Iteration 1070, Loss: 1.0939984349533916e-05, Min w: 0.9204186797142029\n",
      "Iteration 1080, Loss: 1.3525360373023432e-05, Min w: 0.8935550451278687\n",
      "Iteration 1090, Loss: 1.2648781194002368e-05, Min w: 0.9146702289581299\n",
      "Iteration 1100, Loss: 1.446045371267246e-05, Min w: 0.9100578427314758\n",
      "Iteration 1110, Loss: 1.0056908649858087e-05, Min w: 0.9265214800834656\n",
      "Iteration 1120, Loss: 1.2164721738372464e-05, Min w: 0.9321846961975098\n",
      "Iteration 1130, Loss: 1.2319117558945436e-05, Min w: 0.9311132431030273\n",
      "Iteration 1140, Loss: 9.188671356241684e-06, Min w: 0.949920654296875\n",
      "Iteration 1150, Loss: 1.0872066013689619e-05, Min w: 0.94832843542099\n",
      "Iteration 1160, Loss: 1.1015838936145883e-05, Min w: 0.9432432651519775\n",
      "Iteration 1170, Loss: 9.18736077437643e-06, Min w: 0.9420959949493408\n",
      "Iteration 1180, Loss: 1.6411901015089825e-05, Min w: 0.8690345287322998\n",
      "Iteration 1190, Loss: 1.031114243232878e-05, Min w: 0.8892858028411865\n",
      "Iteration 1200, Loss: 1.0467795618751552e-05, Min w: 0.9219353795051575\n",
      "Iteration 1210, Loss: 1.674882514635101e-05, Min w: 0.912043571472168\n",
      "Iteration 1220, Loss: 1.545042141515296e-05, Min w: 0.9346635937690735\n",
      "Iteration 1230, Loss: 9.880076504487079e-06, Min w: 0.9425361752510071\n",
      "Iteration 1240, Loss: 1.083859388018027e-05, Min w: 0.9441026449203491\n",
      "Iteration 0, Loss: 7.2726188591332175e-06, Min w: 0.9491577744483948\n",
      "Iteration 10, Loss: 1.7333288269583136e-05, Min w: 0.9175148606300354\n",
      "Iteration 20, Loss: 7.903196092229337e-06, Min w: 0.9405099153518677\n",
      "Iteration 30, Loss: 9.860513273451943e-06, Min w: 0.9509808421134949\n",
      "Iteration 40, Loss: 1.5296725905500352e-05, Min w: 0.9110904335975647\n",
      "Iteration 50, Loss: 1.552622597955633e-05, Min w: 0.8751600384712219\n",
      "Iteration 60, Loss: 1.4412853488465771e-05, Min w: 0.8862342834472656\n",
      "Iteration 70, Loss: 1.3153466170479078e-05, Min w: 0.9079631567001343\n",
      "Iteration 80, Loss: 1.5605675798724405e-05, Min w: 0.8739591240882874\n",
      "Iteration 90, Loss: 1.720909494906664e-05, Min w: 0.911306619644165\n",
      "Iteration 100, Loss: 9.587068234395701e-06, Min w: 0.9422735571861267\n",
      "Iteration 110, Loss: 9.775680155144073e-06, Min w: 0.9507968425750732\n",
      "Iteration 120, Loss: 1.0814614142873324e-05, Min w: 0.9306171536445618\n",
      "Iteration 130, Loss: 9.7809261205839e-06, Min w: 0.9510918259620667\n",
      "Iteration 140, Loss: 2.4894330636016093e-05, Min w: 0.8470239043235779\n",
      "Iteration 150, Loss: 1.2880082067567855e-05, Min w: 0.9172636866569519\n",
      "Iteration 160, Loss: 1.2387412425596267e-05, Min w: 0.9185398817062378\n",
      "Iteration 170, Loss: 1.1501820154080633e-05, Min w: 0.9232129454612732\n",
      "Iteration 180, Loss: 1.4789800843573175e-05, Min w: 0.9457365870475769\n",
      "Iteration 190, Loss: 9.918606338032987e-06, Min w: 0.9139055013656616\n",
      "Iteration 200, Loss: 1.55239540617913e-05, Min w: 0.906588077545166\n",
      "Iteration 210, Loss: 6.8815757003903855e-06, Min w: 0.9599209427833557\n",
      "Iteration 220, Loss: 1.8005288438871503e-05, Min w: 0.8760808706283569\n",
      "Iteration 230, Loss: 1.9546152543625794e-05, Min w: 0.8866005539894104\n",
      "Iteration 240, Loss: 6.0165630202391185e-06, Min w: 0.9516708850860596\n",
      "Iteration 250, Loss: 1.236398020409979e-05, Min w: 0.9365225434303284\n",
      "Iteration 260, Loss: 1.4067914889892563e-05, Min w: 0.8994530439376831\n",
      "Iteration 270, Loss: 1.181863081001211e-05, Min w: 0.916372537612915\n",
      "Iteration 280, Loss: 9.121378752752207e-06, Min w: 0.9438603520393372\n",
      "Iteration 290, Loss: 1.1472879123175517e-05, Min w: 0.9196925759315491\n",
      "Iteration 300, Loss: 1.3332558410183992e-05, Min w: 0.9273598790168762\n",
      "Iteration 310, Loss: 1.2739533303829376e-05, Min w: 0.9169480204582214\n",
      "Iteration 320, Loss: 1.243951828655554e-05, Min w: 0.913864016532898\n",
      "Iteration 330, Loss: 8.210025953303557e-06, Min w: 0.9596683382987976\n",
      "Iteration 340, Loss: 1.4470709174929652e-05, Min w: 0.9052018523216248\n",
      "Iteration 350, Loss: 7.670386366953608e-06, Min w: 0.942297101020813\n",
      "Iteration 360, Loss: 1.1319545592414215e-05, Min w: 0.9258742928504944\n",
      "Iteration 370, Loss: 1.2566973055072594e-05, Min w: 0.9304657578468323\n",
      "Iteration 380, Loss: 1.6718149709049612e-05, Min w: 0.8995517492294312\n",
      "Iteration 390, Loss: 1.158723625849234e-05, Min w: 0.9362528324127197\n",
      "Iteration 400, Loss: 7.005225143075222e-06, Min w: 0.9378879070281982\n",
      "Iteration 410, Loss: 1.2282936950214207e-05, Min w: 0.9336665272712708\n",
      "Iteration 420, Loss: 1.025000983645441e-05, Min w: 0.9406399130821228\n",
      "Iteration 430, Loss: 1.1497497325763106e-05, Min w: 0.9353716969490051\n",
      "Iteration 440, Loss: 2.056067023659125e-05, Min w: 0.8855041265487671\n",
      "Iteration 450, Loss: 1.1726959201041609e-05, Min w: 0.9397384524345398\n",
      "Iteration 460, Loss: 1.3197770385886542e-05, Min w: 0.922884464263916\n",
      "Iteration 470, Loss: 1.1898798220499884e-05, Min w: 0.939415693283081\n",
      "Iteration 480, Loss: 1.1175604413438123e-05, Min w: 0.9355368614196777\n",
      "Iteration 490, Loss: 1.4374529200722463e-05, Min w: 0.9216666221618652\n",
      "Iteration 500, Loss: 7.144025403249543e-06, Min w: 0.9311597943305969\n",
      "Iteration 510, Loss: 1.096702635550173e-05, Min w: 0.9320464730262756\n",
      "Iteration 520, Loss: 8.887262993084732e-06, Min w: 0.9412740468978882\n",
      "Iteration 530, Loss: 1.1954431101912633e-05, Min w: 0.9359452128410339\n",
      "Iteration 540, Loss: 1.6938900444074534e-05, Min w: 0.8704031705856323\n",
      "Iteration 550, Loss: 1.1899938726855908e-05, Min w: 0.92131108045578\n",
      "Iteration 560, Loss: 1.6043153664213605e-05, Min w: 0.8623601794242859\n",
      "Iteration 570, Loss: 1.665687159402296e-05, Min w: 0.8915716409683228\n",
      "Iteration 580, Loss: 5.927952315687435e-06, Min w: 0.9604193568229675\n",
      "Iteration 590, Loss: 1.541106939839665e-05, Min w: 0.9123603105545044\n",
      "Iteration 600, Loss: 1.0354276128055062e-05, Min w: 0.9266751408576965\n",
      "Iteration 610, Loss: 1.2725538908853196e-05, Min w: 0.9230785965919495\n",
      "Iteration 620, Loss: 1.2021088878100272e-05, Min w: 0.9332567453384399\n",
      "Iteration 630, Loss: 1.5839244952076115e-05, Min w: 0.8950663208961487\n",
      "Iteration 640, Loss: 9.849891284829937e-06, Min w: 0.9264811277389526\n",
      "Iteration 650, Loss: 1.0123438187292777e-05, Min w: 0.9448174834251404\n",
      "Iteration 660, Loss: 1.3440886505122762e-05, Min w: 0.9026774168014526\n",
      "Iteration 670, Loss: 9.780268555914517e-06, Min w: 0.9480657577514648\n",
      "Iteration 680, Loss: 1.1471354810055345e-05, Min w: 0.9419662952423096\n",
      "Iteration 690, Loss: 1.1955489753745496e-05, Min w: 0.9346256256103516\n",
      "Iteration 700, Loss: 1.1708659258147236e-05, Min w: 0.9506485462188721\n",
      "Iteration 710, Loss: 1.5035509022709448e-05, Min w: 0.9152265191078186\n",
      "Iteration 720, Loss: 1.0982860658259597e-05, Min w: 0.9286393523216248\n",
      "Iteration 730, Loss: 1.1288871974102221e-05, Min w: 0.9033759832382202\n",
      "Iteration 740, Loss: 1.2832208994950633e-05, Min w: 0.911820650100708\n",
      "Iteration 750, Loss: 1.2520230484369677e-05, Min w: 0.9292698502540588\n",
      "Iteration 760, Loss: 1.4660756278317422e-05, Min w: 0.9133656620979309\n",
      "Iteration 770, Loss: 1.0033329090219922e-05, Min w: 0.94770348072052\n",
      "Iteration 780, Loss: 1.1250906027271412e-05, Min w: 0.9197357892990112\n",
      "Iteration 790, Loss: 1.1017642464139499e-05, Min w: 0.9415830373764038\n",
      "Iteration 800, Loss: 1.0343352187192068e-05, Min w: 0.9449751973152161\n",
      "Iteration 810, Loss: 1.0294878848071676e-05, Min w: 0.9380135536193848\n",
      "Iteration 820, Loss: 1.2915048500872217e-05, Min w: 0.9351903200149536\n",
      "Iteration 830, Loss: 2.1296109480317682e-05, Min w: 0.9012552499771118\n",
      "Iteration 840, Loss: 1.4174431271385401e-05, Min w: 0.8918634653091431\n",
      "Iteration 850, Loss: 9.56674830376869e-06, Min w: 0.9423611760139465\n",
      "Iteration 860, Loss: 1.550816887174733e-05, Min w: 0.9290668964385986\n",
      "Iteration 870, Loss: 1.118724776461022e-05, Min w: 0.9394197463989258\n",
      "Iteration 880, Loss: 1.6496402167831548e-05, Min w: 0.8451604843139648\n",
      "Iteration 890, Loss: 8.793685992714018e-06, Min w: 0.9178462028503418\n",
      "Iteration 900, Loss: 1.1344886843289714e-05, Min w: 0.9129738211631775\n",
      "Iteration 910, Loss: 9.275101547245868e-06, Min w: 0.9354138374328613\n",
      "Iteration 920, Loss: 1.194544256577501e-05, Min w: 0.9325599670410156\n",
      "Iteration 930, Loss: 7.333397661568597e-06, Min w: 0.9574649333953857\n",
      "Iteration 940, Loss: 9.763764865056146e-06, Min w: 0.9340113997459412\n",
      "Iteration 950, Loss: 1.4277091395342723e-05, Min w: 0.9287278056144714\n",
      "Iteration 960, Loss: 1.4489572095044423e-05, Min w: 0.9235613942146301\n",
      "Iteration 970, Loss: 1.1987922334810719e-05, Min w: 0.9314056634902954\n",
      "Iteration 980, Loss: 1.1494952559587546e-05, Min w: 0.9350041151046753\n",
      "Iteration 990, Loss: 1.0011558515543584e-05, Min w: 0.9315976500511169\n",
      "Iteration 1000, Loss: 1.3516652870748658e-05, Min w: 0.9253454208374023\n",
      "Iteration 1010, Loss: 9.536664038023446e-06, Min w: 0.9397469758987427\n",
      "Iteration 1020, Loss: 1.4550825653714128e-05, Min w: 0.9215673208236694\n",
      "Iteration 1030, Loss: 1.2732180948660243e-05, Min w: 0.8881765604019165\n",
      "Iteration 1040, Loss: 1.602716656634584e-05, Min w: 0.8944968581199646\n",
      "Iteration 1050, Loss: 1.1165736395923886e-05, Min w: 0.9339964985847473\n",
      "Iteration 1060, Loss: 1.1432357496232726e-05, Min w: 0.9356383681297302\n",
      "Iteration 1070, Loss: 1.1145739335916005e-05, Min w: 0.9400823712348938\n",
      "Iteration 1080, Loss: 1.1864741281897295e-05, Min w: 0.9286108613014221\n",
      "Iteration 1090, Loss: 1.6102865629363805e-05, Min w: 0.919751763343811\n",
      "Iteration 1100, Loss: 1.3456114174914546e-05, Min w: 0.9127299189567566\n",
      "Iteration 1110, Loss: 6.712072718073614e-06, Min w: 0.9340755939483643\n",
      "Iteration 1120, Loss: 1.0825248864421155e-05, Min w: 0.9424130320549011\n",
      "Iteration 1130, Loss: 1.5184743460849859e-05, Min w: 0.9125685095787048\n",
      "Iteration 1140, Loss: 1.2661811524594668e-05, Min w: 0.8594180345535278\n",
      "Iteration 1150, Loss: 9.253210919268895e-06, Min w: 0.9146270751953125\n",
      "Iteration 1160, Loss: 1.2751291251333896e-05, Min w: 0.917475700378418\n",
      "Iteration 1170, Loss: 1.2174865332781337e-05, Min w: 0.9356727600097656\n",
      "Iteration 1180, Loss: 1.091189551516436e-05, Min w: 0.9224773049354553\n",
      "Iteration 1190, Loss: 1.5831617929507047e-05, Min w: 0.9224511981010437\n",
      "Iteration 1200, Loss: 9.175189006782603e-06, Min w: 0.9470297694206238\n",
      "Iteration 1210, Loss: 1.4321277376438957e-05, Min w: 0.8887450098991394\n",
      "Iteration 1220, Loss: 1.0763598766061477e-05, Min w: 0.9214639663696289\n",
      "Iteration 1230, Loss: 1.1081324373662937e-05, Min w: 0.9050734639167786\n",
      "Iteration 1240, Loss: 7.718071174167562e-06, Min w: 0.9424057006835938\n",
      "Iteration 0, Loss: 1.2571780644066166e-05, Min w: 0.9245246648788452\n",
      "Iteration 10, Loss: 2.212898834841326e-05, Min w: 0.8883465528488159\n",
      "Iteration 20, Loss: 8.722277016204316e-06, Min w: 0.9458039402961731\n",
      "Iteration 30, Loss: 2.0404830138431862e-05, Min w: 0.8956843614578247\n",
      "Iteration 40, Loss: 9.964298442355357e-06, Min w: 0.9228370189666748\n",
      "Iteration 50, Loss: 8.927061571739614e-06, Min w: 0.9353904724121094\n",
      "Iteration 60, Loss: 1.3981129086459987e-05, Min w: 0.9217703342437744\n",
      "Iteration 70, Loss: 1.439598054275848e-05, Min w: 0.9274808764457703\n",
      "Iteration 80, Loss: 7.180140528362244e-06, Min w: 0.9514230489730835\n",
      "Iteration 90, Loss: 1.3184570889279712e-05, Min w: 0.9296577572822571\n",
      "Iteration 100, Loss: 1.0327645213692449e-05, Min w: 0.9403494596481323\n",
      "Iteration 110, Loss: 9.811617019295227e-06, Min w: 0.9537143111228943\n",
      "Iteration 120, Loss: 1.327926747762831e-05, Min w: 0.9170346260070801\n",
      "Iteration 130, Loss: 1.0529493010835722e-05, Min w: 0.9398017525672913\n",
      "Iteration 140, Loss: 1.4752722563571297e-05, Min w: 0.8937993049621582\n",
      "Iteration 150, Loss: 1.1474595339677762e-05, Min w: 0.9296682476997375\n",
      "Iteration 160, Loss: 1.0902536814683117e-05, Min w: 0.9502649903297424\n",
      "Iteration 170, Loss: 1.0783370271383319e-05, Min w: 0.9456326961517334\n",
      "Iteration 180, Loss: 7.280085810634773e-06, Min w: 0.9582070112228394\n",
      "Iteration 190, Loss: 8.595864528615493e-06, Min w: 0.9330082535743713\n",
      "Iteration 200, Loss: 1.1748081305995584e-05, Min w: 0.9298821687698364\n",
      "Iteration 210, Loss: 8.679577149450779e-06, Min w: 0.9405268430709839\n",
      "Iteration 220, Loss: 1.7261669199797325e-05, Min w: 0.9261115193367004\n",
      "Iteration 230, Loss: 1.2535109817690682e-05, Min w: 0.9145567417144775\n",
      "Iteration 240, Loss: 1.5713065295130946e-05, Min w: 0.927343487739563\n",
      "Iteration 250, Loss: 6.439998742280295e-06, Min w: 0.9171971678733826\n",
      "Iteration 260, Loss: 1.2723777217615861e-05, Min w: 0.8828762769699097\n",
      "Iteration 270, Loss: 1.6294437955366448e-05, Min w: 0.8490462303161621\n",
      "Iteration 280, Loss: 6.512572144856676e-05, Min w: 0.6651797294616699\n",
      "Iteration 290, Loss: 3.1949926778906956e-05, Min w: 0.75954270362854\n",
      "Iteration 300, Loss: 3.166004898957908e-05, Min w: 0.7854828834533691\n",
      "Iteration 310, Loss: 1.3849888091499452e-05, Min w: 0.9231738448143005\n",
      "Iteration 320, Loss: 2.501530798326712e-05, Min w: 0.8282819390296936\n",
      "Iteration 330, Loss: 1.7229709555977024e-05, Min w: 0.8547723889350891\n",
      "Iteration 340, Loss: 5.827557288284879e-06, Min w: 0.9458403587341309\n",
      "Iteration 350, Loss: 4.99129646414076e-06, Min w: 0.9450679421424866\n",
      "Iteration 360, Loss: 5.451968263514573e-06, Min w: 0.9348220229148865\n",
      "Iteration 370, Loss: 3.557952823030064e-06, Min w: 0.9592726826667786\n",
      "Iteration 380, Loss: 4.595932296069805e-06, Min w: 0.9602976441383362\n",
      "Iteration 390, Loss: 2.980714725708822e-06, Min w: 0.9657924771308899\n",
      "Iteration 400, Loss: 4.363302650745027e-06, Min w: 0.9489766955375671\n",
      "Iteration 410, Loss: 4.742965757031925e-06, Min w: 0.9606897830963135\n",
      "Iteration 420, Loss: 6.946382200112566e-06, Min w: 0.9382603168487549\n",
      "Iteration 430, Loss: 6.771441803721245e-06, Min w: 0.9589288234710693\n",
      "Iteration 440, Loss: 8.487698323733639e-06, Min w: 0.9568242430686951\n",
      "Iteration 450, Loss: 8.554084161005449e-06, Min w: 0.9110101461410522\n",
      "Iteration 460, Loss: 8.789669664110988e-06, Min w: 0.9397234916687012\n",
      "Iteration 470, Loss: 1.0137347999261692e-05, Min w: 0.9388329386711121\n",
      "Iteration 480, Loss: 7.738957719993778e-06, Min w: 0.9395537972450256\n",
      "Iteration 490, Loss: 8.39424228615826e-06, Min w: 0.9556950926780701\n",
      "Iteration 500, Loss: 1.2367963790893555e-05, Min w: 0.9445265531539917\n",
      "Iteration 510, Loss: 8.427810826105997e-06, Min w: 0.9470864534378052\n",
      "Iteration 520, Loss: 8.841225280775689e-06, Min w: 0.926156759262085\n",
      "Iteration 530, Loss: 1.2964263987669256e-05, Min w: 0.9357579946517944\n",
      "Iteration 540, Loss: 1.0163107617700007e-05, Min w: 0.943873405456543\n",
      "Iteration 550, Loss: 8.239982889790554e-06, Min w: 0.9485328793525696\n",
      "Iteration 560, Loss: 1.089195575332269e-05, Min w: 0.9438040852546692\n",
      "Iteration 570, Loss: 1.3541050975618418e-05, Min w: 0.863800048828125\n",
      "Iteration 580, Loss: 9.093031621887349e-06, Min w: 0.9198314547538757\n",
      "Iteration 590, Loss: 1.2498610885813832e-05, Min w: 0.9286049604415894\n",
      "Iteration 600, Loss: 8.997850272862706e-06, Min w: 0.9327828288078308\n",
      "Iteration 610, Loss: 8.151043402904179e-06, Min w: 0.9380723237991333\n",
      "Iteration 620, Loss: 1.0818234841281082e-05, Min w: 0.9274073839187622\n",
      "Iteration 630, Loss: 1.2300131857045926e-05, Min w: 0.9029809832572937\n",
      "Iteration 640, Loss: 9.813923497858923e-06, Min w: 0.9258257746696472\n",
      "Iteration 650, Loss: 1.0938820196315646e-05, Min w: 0.9485260844230652\n",
      "Iteration 660, Loss: 7.622031716891797e-06, Min w: 0.9522515535354614\n",
      "Iteration 670, Loss: 8.921670996642206e-06, Min w: 0.9483059048652649\n",
      "Iteration 680, Loss: 1.0341149391024373e-05, Min w: 0.943498969078064\n",
      "Iteration 690, Loss: 9.602088539395481e-06, Min w: 0.9401654005050659\n",
      "Iteration 700, Loss: 1.0650224794517271e-05, Min w: 0.9449154734611511\n",
      "Iteration 710, Loss: 1.1186743904545438e-05, Min w: 0.9506635665893555\n",
      "Iteration 720, Loss: 1.1628883839875925e-05, Min w: 0.9264007210731506\n",
      "Iteration 730, Loss: 1.0635249054757878e-05, Min w: 0.9270979762077332\n",
      "Iteration 740, Loss: 8.65627225721255e-06, Min w: 0.9009233117103577\n",
      "Iteration 750, Loss: 9.541568942950107e-06, Min w: 0.9168035984039307\n",
      "Iteration 760, Loss: 1.8954460756503977e-05, Min w: 0.8907169699668884\n",
      "Iteration 770, Loss: 9.794386642170139e-06, Min w: 0.9248996376991272\n",
      "Iteration 780, Loss: 7.92343507782789e-06, Min w: 0.945798933506012\n",
      "Iteration 790, Loss: 7.775721314828843e-06, Min w: 0.9366024732589722\n",
      "Iteration 800, Loss: 7.5732741606771015e-06, Min w: 0.9382826089859009\n",
      "Iteration 810, Loss: 1.5019866623333655e-05, Min w: 0.9122388958930969\n",
      "Iteration 820, Loss: 7.592128895339556e-06, Min w: 0.9234445095062256\n",
      "Iteration 830, Loss: 1.5366587831522338e-05, Min w: 0.9082692265510559\n",
      "Iteration 840, Loss: 9.082637006940786e-06, Min w: 0.9494704604148865\n",
      "Iteration 850, Loss: 1.212381357618142e-05, Min w: 0.8941866755485535\n",
      "Iteration 860, Loss: 1.4671391909359954e-05, Min w: 0.9195913076400757\n",
      "Iteration 870, Loss: 1.5679950593039393e-05, Min w: 0.9204806089401245\n",
      "Iteration 880, Loss: 1.8368482415098697e-05, Min w: 0.8802541494369507\n",
      "Iteration 890, Loss: 2.2252956114243716e-05, Min w: 0.8372030258178711\n",
      "Iteration 900, Loss: 7.860458572395146e-05, Min w: 0.6946216821670532\n",
      "Iteration 910, Loss: 3.5257511626696214e-05, Min w: 0.7510201930999756\n",
      "Iteration 920, Loss: 1.2212837646075059e-05, Min w: 0.7988576889038086\n",
      "Iteration 930, Loss: 1.1368561899871565e-05, Min w: 0.9073301553726196\n",
      "Iteration 940, Loss: 1.238741879205918e-05, Min w: 0.8923665285110474\n",
      "Iteration 950, Loss: 4.24799418397015e-06, Min w: 0.9764277338981628\n",
      "Iteration 960, Loss: 7.168650427047396e-06, Min w: 0.9411243796348572\n",
      "Iteration 970, Loss: 1.3570976989285555e-05, Min w: 0.9030706882476807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  50%|█████     | 12/24 [07:47<13:21, 66.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 978 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 5979, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.002030170267837664, 'L2_avg': 0.0021892077458051753, 'End_point_L1_avg': 0.002473035229545157, 'End_point_L2_avg': 0.0028313999599266122}\n",
      "Iteration 0, Loss: 0.0019368532812222838, Min w: 4.292860997587382e-18\n",
      "Iteration 10, Loss: 0.0012197704054415226, Min w: 8.575701940571889e-05\n",
      "Iteration 20, Loss: 0.0008474575006403029, Min w: 0.11857384443283081\n",
      "Iteration 30, Loss: 0.0005626516067422926, Min w: 0.2943981885910034\n",
      "Iteration 40, Loss: 0.00037908225203864276, Min w: 0.509922206401825\n",
      "Iteration 50, Loss: 0.00030687893740832806, Min w: 0.5863921642303467\n",
      "Iteration 60, Loss: 0.00022499803162645549, Min w: 0.6294820308685303\n",
      "Iteration 70, Loss: 0.00015972735127434134, Min w: 0.7189339995384216\n",
      "Iteration 80, Loss: 0.00013321831647772342, Min w: 0.7499799132347107\n",
      "Iteration 90, Loss: 0.00012677312770392746, Min w: 0.7661747932434082\n",
      "Iteration 100, Loss: 9.534651326248422e-05, Min w: 0.8178444504737854\n",
      "Iteration 110, Loss: 0.0001029928243951872, Min w: 0.8196161985397339\n",
      "Iteration 120, Loss: 6.817148096160963e-05, Min w: 0.8753980994224548\n",
      "Iteration 130, Loss: 5.926969606662169e-05, Min w: 0.8950380682945251\n",
      "Iteration 140, Loss: 6.179850606713444e-05, Min w: 0.8891327381134033\n",
      "Iteration 150, Loss: 4.5573578972835094e-05, Min w: 0.9135692715644836\n",
      "Iteration 160, Loss: 4.8298639740096405e-05, Min w: 0.9198944568634033\n",
      "Iteration 170, Loss: 4.724817335954867e-05, Min w: 0.9056763648986816\n",
      "Iteration 180, Loss: 3.656241824501194e-05, Min w: 0.9246440529823303\n",
      "Iteration 190, Loss: 3.1002746254671365e-05, Min w: 0.9388831257820129\n",
      "Iteration 200, Loss: 2.6165491362917237e-05, Min w: 0.9524999260902405\n",
      "Iteration 210, Loss: 1.9468634491204284e-05, Min w: 0.9632565975189209\n",
      "Iteration 220, Loss: 1.9891918782377616e-05, Min w: 0.9599176049232483\n",
      "Iteration 230, Loss: 1.6679927284712903e-05, Min w: 0.9677779674530029\n",
      "Iteration 240, Loss: 2.0412880985531956e-05, Min w: 0.9600360989570618\n",
      "Iteration 250, Loss: 2.1112200556672178e-05, Min w: 0.950286865234375\n",
      "Iteration 260, Loss: 1.7924559870152734e-05, Min w: 0.9654016494750977\n",
      "Iteration 270, Loss: 1.1630459994194098e-05, Min w: 0.97398442029953\n",
      "Iteration 280, Loss: 1.3131395462551154e-05, Min w: 0.9779535531997681\n",
      "Iteration 290, Loss: 1.105061255657347e-05, Min w: 0.9773924946784973\n",
      "Iteration 300, Loss: 6.725086677761283e-06, Min w: 0.9849802851676941\n",
      "Iteration 310, Loss: 1.6440413673990406e-05, Min w: 0.9607397317886353\n",
      "Iteration 320, Loss: 9.896863957692403e-06, Min w: 0.9817354679107666\n",
      "Iteration 330, Loss: 8.492843335261568e-06, Min w: 0.9854515194892883\n",
      "Iteration 340, Loss: 7.310783985303715e-06, Min w: 0.9853237867355347\n",
      "Iteration 350, Loss: 7.080855539243203e-06, Min w: 0.9865732789039612\n",
      "Early break at iteration 359 --------------------------------\n",
      "Iteration 0, Loss: 7.475174697901821e-06, Min w: 0.9862416982650757\n",
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 8.19913202576572e-06, Min w: 0.9857494235038757\n",
      "Iteration 10, Loss: 8.94062850420596e-06, Min w: 0.984609842300415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  54%|█████▍    | 13/24 [07:53<08:54, 48.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 11 --------------------------------\n",
      "Iteration 0, Loss: 7.1187864705279935e-06, Min w: 0.9871870875358582\n",
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 5.616809175990056e-06, Min w: 0.9918510913848877\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 385, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0028670150569810077, 'L2_avg': 0.0039161022726201394, 'End_point_L1_avg': 0.0021021522656618414, 'End_point_L2_avg': 0.0027400717831640112}\n",
      "Iteration 0, Loss: 0.00207653664983809, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0015933453105390072, Min w: 3.988318673213067e-22\n",
      "Iteration 20, Loss: 0.0010403338819742203, Min w: 0.03788517415523529\n",
      "Iteration 30, Loss: 0.0008526984602212906, Min w: 0.119194895029068\n",
      "Iteration 40, Loss: 0.0005793844466097653, Min w: 0.4428059160709381\n",
      "Iteration 50, Loss: 0.00039247420500032604, Min w: 0.5201348066329956\n",
      "Iteration 60, Loss: 0.0003031943633686751, Min w: 0.603795051574707\n",
      "Iteration 70, Loss: 0.00023006831179372966, Min w: 0.695618748664856\n",
      "Iteration 80, Loss: 0.00017959269462153316, Min w: 0.7294421792030334\n",
      "Iteration 90, Loss: 0.0001353338302578777, Min w: 0.8105002641677856\n",
      "Iteration 100, Loss: 8.990312198875472e-05, Min w: 0.8528498411178589\n",
      "Iteration 110, Loss: 7.750458462396637e-05, Min w: 0.8749060034751892\n",
      "Iteration 120, Loss: 6.660477083642036e-05, Min w: 0.8725268840789795\n",
      "Iteration 130, Loss: 5.7489858590997756e-05, Min w: 0.8877544403076172\n",
      "Iteration 140, Loss: 4.384189014672302e-05, Min w: 0.918077826499939\n",
      "Iteration 150, Loss: 4.327835631556809e-05, Min w: 0.906888484954834\n",
      "Iteration 160, Loss: 3.548637323547155e-05, Min w: 0.9255391359329224\n",
      "Iteration 170, Loss: 3.77662327082362e-05, Min w: 0.9117416739463806\n",
      "Iteration 180, Loss: 4.19974239775911e-05, Min w: 0.8952909111976624\n",
      "Iteration 190, Loss: 1.8308339349459857e-05, Min w: 0.9597575068473816\n",
      "Iteration 200, Loss: 1.1118800102849491e-05, Min w: 0.9795342683792114\n",
      "Iteration 210, Loss: 2.4256207325379364e-05, Min w: 0.940167248249054\n",
      "Iteration 220, Loss: 2.5957268007914536e-05, Min w: 0.9339666962623596\n",
      "Iteration 230, Loss: 7.0482487899425905e-06, Min w: 0.9882028102874756\n",
      "Iteration 240, Loss: 1.4742538951395545e-05, Min w: 0.9649876952171326\n",
      "Iteration 250, Loss: 7.976880624482874e-06, Min w: 0.9852681756019592\n",
      "Iteration 260, Loss: 1.9547467672964558e-05, Min w: 0.9497320652008057\n",
      "Iteration 270, Loss: 1.433342185919173e-05, Min w: 0.9656891822814941\n",
      "Iteration 280, Loss: 7.980622285685968e-06, Min w: 0.9847056269645691\n",
      "Iteration 290, Loss: 1.1936414921365213e-05, Min w: 0.9725185036659241\n",
      "Early break at iteration 297 --------------------------------\n",
      "Iteration 0, Loss: 9.816478268476203e-06, Min w: 0.9776434302330017\n",
      "Iteration 10, Loss: 6.695819593005581e-06, Min w: 0.9880030155181885\n",
      "Iteration 20, Loss: 7.639031537109986e-06, Min w: 0.9842807054519653\n",
      "Early break at iteration 26 --------------------------------\n",
      "Iteration 0, Loss: 1.5063286809890997e-05, Min w: 0.961747407913208\n",
      "Iteration 10, Loss: 7.80949540057918e-06, Min w: 0.9829673767089844\n",
      "Iteration 20, Loss: 9.195220627589151e-06, Min w: 0.9781177043914795\n",
      "Early break at iteration 25 --------------------------------\n",
      "Iteration 0, Loss: 5.10476502313395e-06, Min w: 0.9917908310890198\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 6.748319265170721e-06, Min w: 0.9856377243995667\n",
      "Early break at iteration 3 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  58%|█████▊    | 14/24 [08:00<05:58, 35.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 356, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.002499922983062999, 'L2_avg': 0.0038731223290628157, 'End_point_L1_avg': 0.0015102130964157279, 'End_point_L2_avg': 0.002513248044460324}\n",
      "Iteration 0, Loss: 0.0005441310349851847, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00048580850125290453, Min w: 3.2143156881653193e-29\n",
      "Iteration 20, Loss: 0.00040879673906601965, Min w: 0.0003754297213163227\n",
      "Iteration 30, Loss: 0.0003182445652782917, Min w: 5.7177119742846116e-05\n",
      "Iteration 40, Loss: 0.0002562758163549006, Min w: 0.020799707621335983\n",
      "Iteration 50, Loss: 0.00018862751312553883, Min w: 0.1834530532360077\n",
      "Iteration 60, Loss: 0.00015572439588140696, Min w: 0.3526681065559387\n",
      "Iteration 70, Loss: 0.00010308463970432058, Min w: 0.5357912182807922\n",
      "Iteration 80, Loss: 8.40367138152942e-05, Min w: 0.6017348170280457\n",
      "Iteration 90, Loss: 6.818230031058192e-05, Min w: 0.662233829498291\n",
      "Iteration 100, Loss: 5.6947468692669645e-05, Min w: 0.7118668556213379\n",
      "Iteration 110, Loss: 4.323841130826622e-05, Min w: 0.7631750106811523\n",
      "Iteration 120, Loss: 3.756207661353983e-05, Min w: 0.7779625058174133\n",
      "Iteration 130, Loss: 3.249385190429166e-05, Min w: 0.7975475192070007\n",
      "Iteration 140, Loss: 2.7677800972014666e-05, Min w: 0.8167351484298706\n",
      "Iteration 150, Loss: 2.1847334210178815e-05, Min w: 0.8436878323554993\n",
      "Iteration 160, Loss: 2.1709303837269545e-05, Min w: 0.8431894779205322\n",
      "Iteration 170, Loss: 2.224646959803067e-05, Min w: 0.8294366598129272\n",
      "Iteration 180, Loss: 1.6954501916188747e-05, Min w: 0.8676568269729614\n",
      "Iteration 190, Loss: 1.6027759556891397e-05, Min w: 0.8731094598770142\n",
      "Iteration 200, Loss: 1.5159472241066396e-05, Min w: 0.8760173320770264\n",
      "Iteration 210, Loss: 1.2853161933890078e-05, Min w: 0.892670750617981\n",
      "Iteration 220, Loss: 1.5851541320444085e-05, Min w: 0.864557147026062\n",
      "Iteration 230, Loss: 9.00963004824007e-06, Min w: 0.9268475770950317\n",
      "Iteration 240, Loss: 9.621819117455743e-06, Min w: 0.9174656271934509\n",
      "Iteration 250, Loss: 9.705042430141475e-06, Min w: 0.9153895378112793\n",
      "Iteration 260, Loss: 1.055634675140027e-05, Min w: 0.9090105891227722\n",
      "Iteration 270, Loss: 1.0829158782144077e-05, Min w: 0.9064444899559021\n",
      "Iteration 280, Loss: 9.888184649753384e-06, Min w: 0.9149035215377808\n",
      "Iteration 290, Loss: 7.869558430684265e-06, Min w: 0.9333680272102356\n",
      "Iteration 300, Loss: 7.470638138329377e-06, Min w: 0.9370728135108948\n",
      "Iteration 310, Loss: 6.968913112359587e-06, Min w: 0.9416329264640808\n",
      "Iteration 320, Loss: 6.166400453366805e-06, Min w: 0.9492789506912231\n",
      "Iteration 330, Loss: 6.0257361838012e-06, Min w: 0.9485151171684265\n",
      "Iteration 340, Loss: 7.565752639493439e-06, Min w: 0.935487687587738\n",
      "Iteration 350, Loss: 6.445866802096134e-06, Min w: 0.9455448985099792\n",
      "Iteration 360, Loss: 5.5534119383082725e-06, Min w: 0.9534494280815125\n",
      "Iteration 370, Loss: 7.223813554446679e-06, Min w: 0.9341046214103699\n",
      "Iteration 380, Loss: 5.232018793321913e-06, Min w: 0.9559571743011475\n",
      "Iteration 390, Loss: 5.5318155318673234e-06, Min w: 0.9518402218818665\n",
      "Iteration 400, Loss: 5.013795998820569e-06, Min w: 0.9578053951263428\n",
      "Iteration 410, Loss: 5.546854026761139e-06, Min w: 0.9509516358375549\n",
      "Iteration 420, Loss: 3.412639671296347e-06, Min w: 0.975389301776886\n",
      "Iteration 430, Loss: 5.304610112943919e-06, Min w: 0.9539346694946289\n",
      "Iteration 440, Loss: 3.917886260751402e-06, Min w: 0.9695168733596802\n",
      "Iteration 450, Loss: 4.562330104818102e-06, Min w: 0.959748387336731\n",
      "Iteration 460, Loss: 4.785301825904753e-06, Min w: 0.9590432047843933\n",
      "Iteration 470, Loss: 2.599419531179592e-06, Min w: 0.9828342795372009\n",
      "Iteration 480, Loss: 3.240002115489915e-06, Min w: 0.974628210067749\n",
      "Iteration 490, Loss: 5.0134308366978075e-06, Min w: 0.9559506773948669\n",
      "Iteration 500, Loss: 3.084913487327867e-06, Min w: 0.975230872631073\n",
      "Iteration 510, Loss: 2.88738806375477e-06, Min w: 0.9775753617286682\n",
      "Iteration 520, Loss: 2.6906463972409256e-06, Min w: 0.9813442230224609\n",
      "Iteration 530, Loss: 2.4476787530147703e-06, Min w: 0.9846723675727844\n",
      "Iteration 540, Loss: 2.128141204593703e-06, Min w: 0.985953688621521\n",
      "Early break at iteration 549 --------------------------------\n",
      "Iteration 0, Loss: 2.674088818821474e-06, Min w: 0.9790463447570801\n",
      "Iteration 10, Loss: 3.3294872991973534e-06, Min w: 0.9721840620040894\n",
      "Iteration 20, Loss: 2.4293044589285273e-06, Min w: 0.9808323979377747\n",
      "Iteration 30, Loss: 2.042299456661567e-06, Min w: 0.9871542453765869\n",
      "Iteration 40, Loss: 2.5830208869592752e-06, Min w: 0.9804274439811707\n",
      "Early break at iteration 42 --------------------------------\n",
      "Iteration 0, Loss: 2.355938477194286e-06, Min w: 0.982122004032135\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 3.887113962264266e-06, Min w: 0.965417742729187\n",
      "Iteration 10, Loss: 1.6751212115195813e-06, Min w: 0.9899260401725769\n",
      "Early break at iteration 16 --------------------------------\n",
      "Iteration 0, Loss: 2.2402446120395325e-06, Min w: 0.9845729470252991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  62%|██████▎   | 15/24 [08:17<04:30, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: 1.5666354329368914e-06, Min w: 0.99137282371521\n",
      "Early break at iteration 10 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 629, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0019318101773177312, 'L2_avg': 0.002902042413757037, 'End_point_L1_avg': 0.001214263872652972, 'End_point_L2_avg': 0.0021352645145031103}\n",
      "Iteration 0, Loss: 0.0004819350433535874, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0003776942612603307, Min w: 1.0310621708760768e-16\n",
      "Iteration 20, Loss: 0.0003029737272299826, Min w: 0.01061507873237133\n",
      "Iteration 30, Loss: 0.00020650670921895653, Min w: 0.2814251780509949\n",
      "Iteration 40, Loss: 0.00014132968499325216, Min w: 0.4971019923686981\n",
      "Iteration 50, Loss: 0.00012052235979354009, Min w: 0.5475043654441833\n",
      "Iteration 60, Loss: 0.0001008280596579425, Min w: 0.6053569912910461\n",
      "Iteration 70, Loss: 8.393207826884463e-05, Min w: 0.6263209581375122\n",
      "Iteration 80, Loss: 6.834888336015865e-05, Min w: 0.6796928644180298\n",
      "Iteration 90, Loss: 6.134097202448174e-05, Min w: 0.69240403175354\n",
      "Iteration 100, Loss: 5.133175363880582e-05, Min w: 0.7370678186416626\n",
      "Iteration 110, Loss: 4.34888424933888e-05, Min w: 0.7730550765991211\n",
      "Iteration 120, Loss: 3.8812646380392835e-05, Min w: 0.7914859056472778\n",
      "Iteration 130, Loss: 3.7757323298137635e-05, Min w: 0.7833647131919861\n",
      "Iteration 140, Loss: 3.5806206142297015e-05, Min w: 0.7857027053833008\n",
      "Iteration 150, Loss: 3.0282742955023423e-05, Min w: 0.8176721930503845\n",
      "Iteration 160, Loss: 2.7343845431460068e-05, Min w: 0.8345760107040405\n",
      "Iteration 170, Loss: 2.1958678189548664e-05, Min w: 0.8698027729988098\n",
      "Iteration 180, Loss: 2.249879798910115e-05, Min w: 0.8632912039756775\n",
      "Iteration 190, Loss: 1.9658220480778255e-05, Min w: 0.880226731300354\n",
      "Iteration 200, Loss: 1.8439470295561478e-05, Min w: 0.8913506865501404\n",
      "Iteration 210, Loss: 1.6201271137106232e-05, Min w: 0.8988230228424072\n",
      "Iteration 220, Loss: 1.3556219528254587e-05, Min w: 0.9242629408836365\n",
      "Iteration 230, Loss: 1.4007378922542557e-05, Min w: 0.9179672598838806\n",
      "Iteration 240, Loss: 1.2819480616599321e-05, Min w: 0.929662823677063\n",
      "Iteration 250, Loss: 1.016986516333418e-05, Min w: 0.9439005255699158\n",
      "Iteration 260, Loss: 9.177990250464063e-06, Min w: 0.9526650309562683\n",
      "Iteration 270, Loss: 9.312624570156913e-06, Min w: 0.9503215551376343\n",
      "Iteration 280, Loss: 8.386483386857435e-06, Min w: 0.9527079463005066\n",
      "Iteration 290, Loss: 6.505104465759359e-06, Min w: 0.9707552790641785\n",
      "Iteration 300, Loss: 8.532507308700588e-06, Min w: 0.950045108795166\n",
      "Iteration 310, Loss: 6.870798642921727e-06, Min w: 0.964095413684845\n",
      "Iteration 320, Loss: 6.2273666117107496e-06, Min w: 0.9714269042015076\n",
      "Iteration 330, Loss: 5.4770948736404534e-06, Min w: 0.9775089621543884\n",
      "Iteration 340, Loss: 5.002347734262003e-06, Min w: 0.9770103096961975\n",
      "Iteration 350, Loss: 4.221953986416338e-06, Min w: 0.9829171895980835\n",
      "Iteration 360, Loss: 5.012141627958044e-06, Min w: 0.9773480892181396\n",
      "Iteration 370, Loss: 5.5637178775214124e-06, Min w: 0.9708833694458008\n",
      "Iteration 380, Loss: 3.976075731770834e-06, Min w: 0.9816440343856812\n",
      "Iteration 390, Loss: 4.791808351001237e-06, Min w: 0.9761568307876587\n",
      "Iteration 400, Loss: 3.562139909263351e-06, Min w: 0.9853214025497437\n",
      "Iteration 410, Loss: 4.102703314856626e-06, Min w: 0.9807897806167603\n",
      "Iteration 420, Loss: 3.7280312881193822e-06, Min w: 0.9840648174285889\n",
      "Iteration 430, Loss: 2.496290562703507e-06, Min w: 0.9897865056991577\n",
      "Iteration 440, Loss: 3.4216907351947157e-06, Min w: 0.982479989528656\n",
      "Early break at iteration 449 --------------------------------\n",
      "Iteration 0, Loss: 3.216376853742986e-06, Min w: 0.9857867360115051\n",
      "Iteration 10, Loss: 3.025354317287565e-06, Min w: 0.9857141971588135\n",
      "Early break at iteration 13 --------------------------------\n",
      "Iteration 0, Loss: 2.672607934073312e-06, Min w: 0.9880527257919312\n",
      "Iteration 10, Loss: 2.4738906176935416e-06, Min w: 0.9892224669456482\n",
      "Early break at iteration 17 --------------------------------\n",
      "Iteration 0, Loss: 2.6824482119991444e-06, Min w: 0.9884082078933716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  67%|██████▋   | 16/24 [08:30<03:19, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 8 --------------------------------\n",
      "Iteration 0, Loss: 2.6148290999117307e-06, Min w: 0.9890590906143188\n",
      "Early break at iteration 2 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 494, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0031120926893905996, 'L2_avg': 0.00490120296498395, 'End_point_L1_avg': 0.0017158814411082917, 'End_point_L2_avg': 0.002064608813663579}\n",
      "Iteration 0, Loss: 0.002121137687936425, Min w: 3.9025714497529145e-33\n",
      "Iteration 10, Loss: 0.0009839128470048308, Min w: 1.903483468682592e-20\n",
      "Iteration 20, Loss: 0.0003823929582722485, Min w: 6.569138122358709e-07\n",
      "Iteration 30, Loss: 0.0002907301241066307, Min w: 9.48288970903377e-07\n",
      "Iteration 40, Loss: 0.00013702250726055354, Min w: 0.5228273272514343\n",
      "Iteration 50, Loss: 8.151262591127306e-05, Min w: 0.7047988176345825\n",
      "Iteration 60, Loss: 8.697083103470504e-05, Min w: 0.5404377579689026\n",
      "Iteration 70, Loss: 1.6240535842371173e-05, Min w: 0.9839475154876709\n",
      "Iteration 80, Loss: 1.074092597264098e-05, Min w: 0.986404299736023\n",
      "Early break at iteration 82 --------------------------------\n",
      "Iteration 0, Loss: 1.7596739780856296e-05, Min w: 0.9342172741889954\n",
      "Iteration 10, Loss: 1.387049451295752e-05, Min w: 0.977292537689209\n",
      "Early break at iteration 11 --------------------------------\n",
      "Iteration 0, Loss: 1.0312747690477408e-05, Min w: 0.9789530038833618\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.2882089322374668e-05, Min w: 0.9813516736030579\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 1.119667194870999e-05, Min w: 0.9873942136764526\n",
      "Early break at iteration 1 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  71%|███████   | 17/24 [08:32<02:06, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 103, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.004473821074276358, 'L2_avg': 0.005922509476824049, 'End_point_L1_avg': 0.003028558278555793, 'End_point_L2_avg': 0.0034321726999788616}\n",
      "Iteration 0, Loss: 0.0017918032826855779, Min w: 8.84118082564167e-15\n",
      "Iteration 10, Loss: 0.0009798314422369003, Min w: 9.509982007526003e-23\n",
      "Iteration 20, Loss: 0.0005112569197081029, Min w: 0.0025694689247757196\n",
      "Iteration 30, Loss: 0.0003038036811631173, Min w: 1.9732709688469185e-07\n",
      "Iteration 40, Loss: 0.000143741985084489, Min w: 0.4300163984298706\n",
      "Iteration 50, Loss: 0.00010377869330113754, Min w: 0.48613834381103516\n",
      "Iteration 60, Loss: 5.0800692406482995e-05, Min w: 0.7463746070861816\n",
      "Iteration 70, Loss: 2.8642767574638128e-05, Min w: 0.9000344276428223\n",
      "Iteration 80, Loss: 7.88416582508944e-06, Min w: 0.9848529100418091\n",
      "Early break at iteration 88 --------------------------------\n",
      "Iteration 0, Loss: 1.2284141121199355e-05, Min w: 0.974175751209259\n",
      "Iteration 10, Loss: 1.0900847883021925e-05, Min w: 0.9829745888710022\n",
      "Iteration 20, Loss: 7.738140084256884e-06, Min w: 0.9886478781700134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  75%|███████▌  | 18/24 [08:34<01:19, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 24 --------------------------------\n",
      "Iteration 0, Loss: 3.510472652124008e-06, Min w: 0.9947763085365295\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.3608483792922925e-06, Min w: 0.9924701452255249\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.822219696303364e-06, Min w: 0.9939839243888855\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 117, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.002855016614362391, 'L2_avg': 0.0035220505173880158, 'End_point_L1_avg': 0.00283423979549881, 'End_point_L2_avg': 0.0032896422722763605}\n",
      "Iteration 0, Loss: 0.0005084310541860759, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00036709316191263497, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0002870811440516263, Min w: 0.0\n",
      "Iteration 30, Loss: 0.00022581445227842778, Min w: 6.981906817546194e-21\n",
      "Iteration 40, Loss: 0.00021280208602547646, Min w: 0.0\n",
      "Iteration 50, Loss: 0.00016698417311999947, Min w: 0.0\n",
      "Iteration 60, Loss: 0.00011959951370954514, Min w: 0.0\n",
      "Iteration 70, Loss: 8.103158324956894e-05, Min w: 0.0\n",
      "Iteration 80, Loss: 6.152568676043302e-05, Min w: 3.0672868216695404e-13\n",
      "Iteration 90, Loss: 6.934973498573527e-05, Min w: 0.02148342877626419\n",
      "Iteration 100, Loss: 5.582457743003033e-05, Min w: 3.78916731325063e-10\n",
      "Iteration 110, Loss: 5.1009905291721225e-05, Min w: 0.0\n",
      "Iteration 120, Loss: 4.078423080500215e-05, Min w: 0.0\n",
      "Iteration 130, Loss: 4.5326862164074555e-05, Min w: 5.274996809978841e-32\n",
      "Iteration 140, Loss: 4.527144483290613e-05, Min w: 0.0\n",
      "Iteration 150, Loss: 5.397654604166746e-05, Min w: 0.0\n",
      "Iteration 160, Loss: 5.324893572833389e-05, Min w: 0.0\n",
      "Iteration 170, Loss: 4.318980427342467e-05, Min w: 0.0\n",
      "Iteration 180, Loss: 4.494314271141775e-05, Min w: 0.0\n",
      "Iteration 190, Loss: 4.783105032402091e-05, Min w: 9.484842461980675e-22\n",
      "Iteration 200, Loss: 3.9960435969987884e-05, Min w: 5.134454528210597e-10\n",
      "Iteration 210, Loss: 4.54964792879764e-05, Min w: 0.0\n",
      "Iteration 220, Loss: 6.668111018370837e-05, Min w: 9.82207928703801e-40\n",
      "Iteration 230, Loss: 4.912839358439669e-05, Min w: 4.736882692668587e-05\n",
      "Iteration 240, Loss: 4.321001688367687e-05, Min w: 1.0491451973848598e-07\n",
      "Iteration 250, Loss: 4.9882568418979645e-05, Min w: 6.397388459290303e-27\n",
      "Iteration 260, Loss: 4.6538796595996246e-05, Min w: 5.367595104696008e-26\n",
      "Iteration 270, Loss: 6.694027251796797e-05, Min w: 0.11818322539329529\n",
      "Iteration 280, Loss: 4.799997986992821e-05, Min w: 1.3284891723614712e-30\n",
      "Iteration 290, Loss: 4.5948974729981273e-05, Min w: 2.718519020790145e-42\n",
      "Iteration 300, Loss: 4.2448213207535446e-05, Min w: 1.156505042682494e-27\n",
      "Iteration 310, Loss: 4.3459531298140064e-05, Min w: 0.0\n",
      "Iteration 320, Loss: 5.9405287174740806e-05, Min w: 2.037537255526058e-31\n",
      "Iteration 330, Loss: 4.244632145855576e-05, Min w: 9.633908604200769e-08\n",
      "Iteration 340, Loss: 4.847355012316257e-05, Min w: 7.059677539850701e-37\n",
      "Iteration 350, Loss: 5.6875978771131486e-05, Min w: 2.5008444479775876e-14\n",
      "Iteration 360, Loss: 4.7817506128922105e-05, Min w: 0.3817209303379059\n",
      "Iteration 370, Loss: 4.738002098747529e-05, Min w: 2.1471483178574582e-16\n",
      "Iteration 380, Loss: 5.257950761006214e-05, Min w: 1.581699089353967e-23\n",
      "Iteration 390, Loss: 5.316239548847079e-05, Min w: 0.0\n",
      "Iteration 400, Loss: 4.2027622839668766e-05, Min w: 4.5652377878013795e-08\n",
      "Iteration 410, Loss: 4.651906056096777e-05, Min w: 0.0677885040640831\n",
      "Iteration 420, Loss: 5.947969475528225e-05, Min w: 2.7270062107438006e-30\n",
      "Iteration 430, Loss: 5.1924176659667864e-05, Min w: 0.016438134014606476\n",
      "Iteration 440, Loss: 6.065137858968228e-05, Min w: 9.716184644082905e-21\n",
      "Iteration 450, Loss: 6.373678479576483e-05, Min w: 0.0\n",
      "Iteration 460, Loss: 5.598656935035251e-05, Min w: 5.74532370373175e-44\n",
      "Iteration 470, Loss: 4.2253537685610354e-05, Min w: 2.6772469657876385e-11\n",
      "Iteration 480, Loss: 7.245085726026446e-05, Min w: 0.0487547442317009\n",
      "Iteration 490, Loss: 5.764780144090764e-05, Min w: 9.125238648266532e-06\n",
      "Iteration 500, Loss: 9.07138382899575e-06, Min w: 0.9547203183174133\n",
      "Iteration 510, Loss: 4.619625906343572e-05, Min w: 0.0\n",
      "Iteration 520, Loss: 4.7980061935959384e-05, Min w: 1.5799914274052668e-13\n",
      "Iteration 530, Loss: 4.558236105367541e-05, Min w: 0.30622610449790955\n",
      "Iteration 540, Loss: 2.9551594707299955e-05, Min w: 0.5066454410552979\n",
      "Iteration 550, Loss: 2.5956265744753182e-05, Min w: 0.7599727511405945\n",
      "Iteration 560, Loss: 3.1388284696731716e-05, Min w: 0.31787559390068054\n",
      "Iteration 570, Loss: 4.763299511978403e-05, Min w: 0.0011299487669020891\n",
      "Iteration 580, Loss: 5.5044183682184666e-05, Min w: 4.0255356020979527e-38\n",
      "Iteration 590, Loss: 5.331312422640622e-05, Min w: 9.85835550407189e-21\n",
      "Iteration 600, Loss: 5.313958172337152e-05, Min w: 3.5888663307779956e-29\n",
      "Iteration 610, Loss: 4.053064913023263e-05, Min w: 6.409362654252832e-18\n",
      "Iteration 620, Loss: 4.956664270139299e-05, Min w: 0.0\n",
      "Iteration 630, Loss: 7.96061140135862e-05, Min w: 1.2615698096426716e-38\n",
      "Iteration 640, Loss: 5.057140879216604e-05, Min w: 0.022064274176955223\n",
      "Iteration 650, Loss: 5.900087853660807e-05, Min w: 0.00024486627080477774\n",
      "Iteration 660, Loss: 3.9827915315981954e-05, Min w: 0.3060494363307953\n",
      "Iteration 670, Loss: 5.215979035710916e-05, Min w: 7.544935882393795e-25\n",
      "Iteration 680, Loss: 5.505008084583096e-05, Min w: 3.275580411354895e-07\n",
      "Iteration 690, Loss: 3.5258810385130346e-05, Min w: 0.2217286378145218\n",
      "Iteration 700, Loss: 1.586934013175778e-05, Min w: 0.885928213596344\n",
      "Iteration 710, Loss: 1.3947003935754765e-05, Min w: 0.8046731352806091\n",
      "Iteration 720, Loss: 1.9280951164546423e-05, Min w: 0.7448513507843018\n",
      "Iteration 730, Loss: 1.9168870494468138e-05, Min w: 0.8269506096839905\n",
      "Iteration 740, Loss: 2.153755303879734e-05, Min w: 0.7298974394798279\n",
      "Iteration 750, Loss: 1.4897580513206776e-05, Min w: 0.8648341298103333\n",
      "Iteration 760, Loss: 1.2919914297526702e-05, Min w: 0.8271995186805725\n",
      "Iteration 770, Loss: 1.0532774467719719e-05, Min w: 0.8708949685096741\n",
      "Iteration 780, Loss: 1.5024484127934556e-05, Min w: 0.8713414669036865\n",
      "Iteration 790, Loss: 1.1411622836021706e-05, Min w: 0.8806315660476685\n",
      "Iteration 800, Loss: 1.3170681995688938e-05, Min w: 0.8939534425735474\n",
      "Iteration 810, Loss: 1.8701586668612435e-05, Min w: 0.9015333652496338\n",
      "Iteration 820, Loss: 1.3873737771064043e-05, Min w: 0.8765479326248169\n",
      "Iteration 830, Loss: 1.3132594176568091e-05, Min w: 0.8890644311904907\n",
      "Iteration 840, Loss: 1.132855140895117e-05, Min w: 0.9057947397232056\n",
      "Iteration 850, Loss: 1.4592757906939369e-05, Min w: 0.9090933799743652\n",
      "Iteration 860, Loss: 1.8486203771317378e-05, Min w: 0.9011352062225342\n",
      "Iteration 870, Loss: 1.3528599083656445e-05, Min w: 0.9035916924476624\n",
      "Iteration 880, Loss: 1.0396621291874908e-05, Min w: 0.9262568950653076\n",
      "Iteration 890, Loss: 1.2177854841866065e-05, Min w: 0.9320463538169861\n",
      "Iteration 900, Loss: 1.4668433323095087e-05, Min w: 0.9021238684654236\n",
      "Iteration 910, Loss: 2.60942179011181e-05, Min w: 0.8138799071311951\n",
      "Iteration 920, Loss: 1.8819731849362142e-05, Min w: 0.842312216758728\n",
      "Iteration 930, Loss: 1.8598779206513427e-05, Min w: 0.8828513026237488\n",
      "Iteration 940, Loss: 1.469783910579281e-05, Min w: 0.8952564001083374\n",
      "Iteration 950, Loss: 1.7268574083573185e-05, Min w: 0.8693329691886902\n",
      "Iteration 960, Loss: 1.0178489901591092e-05, Min w: 0.9368515014648438\n",
      "Iteration 970, Loss: 1.6357302229152992e-05, Min w: 0.9270527362823486\n",
      "Iteration 980, Loss: 1.1264504792052321e-05, Min w: 0.9357366561889648\n",
      "Iteration 990, Loss: 2.3477046852349304e-05, Min w: 0.7878915071487427\n",
      "Iteration 1000, Loss: 8.74123907124158e-06, Min w: 0.9298668503761292\n",
      "Iteration 1010, Loss: 2.0914147171424702e-05, Min w: 0.903437077999115\n",
      "Iteration 1020, Loss: 9.436286745767575e-06, Min w: 0.9370031952857971\n",
      "Iteration 1030, Loss: 1.9516184693202376e-05, Min w: 0.9147141575813293\n",
      "Iteration 1040, Loss: 1.1004478437826037e-05, Min w: 0.9325606822967529\n",
      "Iteration 1050, Loss: 9.263787433155812e-06, Min w: 0.9442944526672363\n",
      "Iteration 1060, Loss: 1.8436912796460092e-05, Min w: 0.9224164485931396\n",
      "Iteration 1070, Loss: 1.048688773153117e-05, Min w: 0.920456051826477\n",
      "Iteration 1080, Loss: 1.4375973478308879e-05, Min w: 0.9275431036949158\n",
      "Iteration 1090, Loss: 1.925199649122078e-05, Min w: 0.8911299109458923\n",
      "Iteration 1100, Loss: 1.283566962229088e-05, Min w: 0.9130869507789612\n",
      "Iteration 1110, Loss: 2.0365012460388243e-05, Min w: 0.9172207117080688\n",
      "Iteration 1120, Loss: 1.2113962839066517e-05, Min w: 0.9266979694366455\n",
      "Iteration 1130, Loss: 1.3688276339962613e-05, Min w: 0.9387435913085938\n",
      "Iteration 1140, Loss: 1.2707893802144099e-05, Min w: 0.9310368895530701\n",
      "Iteration 1150, Loss: 1.4237029972719029e-05, Min w: 0.9220277667045593\n",
      "Iteration 1160, Loss: 1.0741802725533489e-05, Min w: 0.9211010336875916\n",
      "Iteration 1170, Loss: 2.275494989589788e-05, Min w: 0.8507643342018127\n",
      "Iteration 1180, Loss: 1.4698777704325039e-05, Min w: 0.8934021592140198\n",
      "Iteration 1190, Loss: 2.1766929421573877e-05, Min w: 0.850074827671051\n",
      "Iteration 1200, Loss: 1.1527701644808985e-05, Min w: 0.9294095039367676\n",
      "Iteration 1210, Loss: 2.4594719434389845e-05, Min w: 0.8948169946670532\n",
      "Iteration 1220, Loss: 1.4224317055777647e-05, Min w: 0.9189073443412781\n",
      "Iteration 1230, Loss: 1.1318612450850196e-05, Min w: 0.9263176321983337\n",
      "Iteration 1240, Loss: 1.548643376736436e-05, Min w: 0.927335798740387\n",
      "Iteration 0, Loss: 1.3918619515607134e-05, Min w: 0.9224685430526733\n",
      "Iteration 10, Loss: 1.7687429135548882e-05, Min w: 0.9188118577003479\n",
      "Iteration 20, Loss: 1.2267862075532321e-05, Min w: 0.9383389949798584\n",
      "Iteration 30, Loss: 1.2358476851659361e-05, Min w: 0.9416027665138245\n",
      "Iteration 40, Loss: 1.398341828462435e-05, Min w: 0.9292156100273132\n",
      "Iteration 50, Loss: 6.644789664278505e-06, Min w: 0.91866534948349\n",
      "Iteration 60, Loss: 2.078326724586077e-05, Min w: 0.8967899680137634\n",
      "Iteration 70, Loss: 1.1880438250955194e-05, Min w: 0.9208697080612183\n",
      "Iteration 80, Loss: 1.2702394087682478e-05, Min w: 0.933844268321991\n",
      "Iteration 90, Loss: 1.5917757991701365e-05, Min w: 0.926917314529419\n",
      "Iteration 100, Loss: 1.3650147593580186e-05, Min w: 0.943224310874939\n",
      "Iteration 110, Loss: 1.095350944524398e-05, Min w: 0.9081037640571594\n",
      "Iteration 120, Loss: 1.229715326189762e-05, Min w: 0.9263362884521484\n",
      "Iteration 130, Loss: 1.4995764104241971e-05, Min w: 0.8941155076026917\n",
      "Iteration 140, Loss: 9.543405212752987e-06, Min w: 0.9405748248100281\n",
      "Iteration 150, Loss: 1.2513179171946831e-05, Min w: 0.946967363357544\n",
      "Iteration 160, Loss: 1.423150570190046e-05, Min w: 0.9184702038764954\n",
      "Iteration 170, Loss: 1.0321969966753386e-05, Min w: 0.9309578537940979\n",
      "Iteration 180, Loss: 1.3658555872098077e-05, Min w: 0.9265785813331604\n",
      "Iteration 190, Loss: 1.039400649460731e-05, Min w: 0.9479082822799683\n",
      "Iteration 200, Loss: 1.2146807421231642e-05, Min w: 0.9389299750328064\n",
      "Iteration 210, Loss: 1.5136434740270488e-05, Min w: 0.8576586842536926\n",
      "Iteration 220, Loss: 7.398599791486049e-06, Min w: 0.9343504309654236\n",
      "Iteration 230, Loss: 2.6468096621101722e-05, Min w: 0.8960110545158386\n",
      "Iteration 240, Loss: 1.751794115989469e-05, Min w: 0.876566469669342\n",
      "Iteration 250, Loss: 1.611580046301242e-05, Min w: 0.9003524780273438\n",
      "Iteration 260, Loss: 1.2372390301607084e-05, Min w: 0.9205983281135559\n",
      "Iteration 270, Loss: 1.1989596714556683e-05, Min w: 0.9242832660675049\n",
      "Iteration 280, Loss: 1.5338408047682606e-05, Min w: 0.9118039011955261\n",
      "Iteration 290, Loss: 1.240475285158027e-05, Min w: 0.9174140691757202\n",
      "Iteration 300, Loss: 9.440900612389669e-06, Min w: 0.9305042624473572\n",
      "Iteration 310, Loss: 1.2553745364130009e-05, Min w: 0.920383632183075\n",
      "Iteration 320, Loss: 1.3769977158517577e-05, Min w: 0.9399522542953491\n",
      "Iteration 330, Loss: 1.5240529137372505e-05, Min w: 0.930690586566925\n",
      "Iteration 340, Loss: 1.2014265848847572e-05, Min w: 0.9187294244766235\n",
      "Iteration 350, Loss: 7.675987035327125e-06, Min w: 0.9459860920906067\n",
      "Iteration 360, Loss: 1.0389705494162627e-05, Min w: 0.933327317237854\n",
      "Iteration 370, Loss: 1.691070974629838e-05, Min w: 0.9120774865150452\n",
      "Iteration 380, Loss: 1.0099822247866541e-05, Min w: 0.8936560750007629\n",
      "Iteration 390, Loss: 8.86398265720345e-06, Min w: 0.9357275366783142\n",
      "Iteration 400, Loss: 1.416532450093655e-05, Min w: 0.8924727439880371\n",
      "Iteration 410, Loss: 1.3361915080167819e-05, Min w: 0.9266757965087891\n",
      "Iteration 420, Loss: 7.574557002953952e-06, Min w: 0.9504861831665039\n",
      "Iteration 430, Loss: 1.639487163629383e-05, Min w: 0.9166569113731384\n",
      "Iteration 440, Loss: 5.690134003089042e-06, Min w: 0.9634512662887573\n",
      "Iteration 450, Loss: 1.242691450897837e-05, Min w: 0.9319443106651306\n",
      "Iteration 460, Loss: 1.6055610103649087e-05, Min w: 0.9285489320755005\n",
      "Iteration 470, Loss: 6.737855073879473e-06, Min w: 0.9455236196517944\n",
      "Iteration 480, Loss: 1.0742277481767815e-05, Min w: 0.9404140710830688\n",
      "Iteration 490, Loss: 6.697834123770008e-06, Min w: 0.9452747106552124\n",
      "Iteration 500, Loss: 1.6673673599143513e-05, Min w: 0.9317505955696106\n",
      "Iteration 510, Loss: 1.0471596397110261e-05, Min w: 0.9329603910446167\n",
      "Iteration 520, Loss: 1.7703165212878957e-05, Min w: 0.8745986819267273\n",
      "Iteration 530, Loss: 1.193983007397037e-05, Min w: 0.8877789378166199\n",
      "Iteration 540, Loss: 1.2778730706486385e-05, Min w: 0.9385655522346497\n",
      "Iteration 550, Loss: 1.0976943485729862e-05, Min w: 0.9134853482246399\n",
      "Iteration 560, Loss: 1.3592239156423602e-05, Min w: 0.9067400693893433\n",
      "Iteration 570, Loss: 1.5424056982737966e-05, Min w: 0.9028195142745972\n",
      "Iteration 580, Loss: 1.3248491995909717e-05, Min w: 0.9289262294769287\n",
      "Iteration 590, Loss: 1.1495427315821871e-05, Min w: 0.923768162727356\n",
      "Iteration 600, Loss: 1.0063865374831948e-05, Min w: 0.9507284164428711\n",
      "Iteration 610, Loss: 1.014748886518646e-05, Min w: 0.9313005805015564\n",
      "Iteration 620, Loss: 9.405952368979342e-06, Min w: 0.9385215044021606\n",
      "Iteration 630, Loss: 1.3534217032429297e-05, Min w: 0.9126995801925659\n",
      "Iteration 640, Loss: 8.631590389995836e-06, Min w: 0.9356455206871033\n",
      "Iteration 650, Loss: 9.027132364280988e-06, Min w: 0.9439003467559814\n",
      "Iteration 660, Loss: 1.701475957816001e-05, Min w: 0.9035305380821228\n",
      "Iteration 670, Loss: 1.53777000377886e-05, Min w: 0.896300196647644\n",
      "Iteration 680, Loss: 9.839216545515228e-06, Min w: 0.9360131621360779\n",
      "Iteration 690, Loss: 1.3851602489012294e-05, Min w: 0.9251216053962708\n",
      "Iteration 700, Loss: 1.2751954272971489e-05, Min w: 0.9360969662666321\n",
      "Iteration 710, Loss: 1.2479151337174699e-05, Min w: 0.9166795611381531\n",
      "Iteration 720, Loss: 1.0148449291591533e-05, Min w: 0.9436150193214417\n",
      "Iteration 730, Loss: 6.422834758268436e-06, Min w: 0.9487380981445312\n",
      "Iteration 740, Loss: 1.2246006917848717e-05, Min w: 0.901729166507721\n",
      "Iteration 750, Loss: 1.1964502846240066e-05, Min w: 0.9121339321136475\n",
      "Iteration 760, Loss: 1.2867483746958897e-05, Min w: 0.9206483960151672\n",
      "Iteration 770, Loss: 1.5764224372105673e-05, Min w: 0.9142733216285706\n",
      "Iteration 780, Loss: 8.207524842873681e-06, Min w: 0.9354939460754395\n",
      "Iteration 790, Loss: 1.3386673344939481e-05, Min w: 0.927644670009613\n",
      "Iteration 800, Loss: 1.0454175935592502e-05, Min w: 0.917067289352417\n",
      "Iteration 810, Loss: 1.8436545360600576e-05, Min w: 0.9046357870101929\n",
      "Iteration 820, Loss: 8.58632120070979e-06, Min w: 0.9169039726257324\n",
      "Iteration 830, Loss: 7.3446226451778784e-06, Min w: 0.9388841390609741\n",
      "Iteration 840, Loss: 1.3424179087451193e-05, Min w: 0.9047024250030518\n",
      "Iteration 850, Loss: 8.558621630072594e-06, Min w: 0.9382039308547974\n",
      "Iteration 860, Loss: 1.342257655778667e-05, Min w: 0.9098498225212097\n",
      "Iteration 870, Loss: 1.4442672181758098e-05, Min w: 0.8976304531097412\n",
      "Iteration 880, Loss: 1.3220582331996411e-05, Min w: 0.9145966172218323\n",
      "Iteration 890, Loss: 8.761646313359961e-06, Min w: 0.950370728969574\n",
      "Iteration 900, Loss: 1.1877047654706985e-05, Min w: 0.9339823722839355\n",
      "Iteration 910, Loss: 1.812598384276498e-05, Min w: 0.8839383721351624\n",
      "Iteration 920, Loss: 9.829102054936811e-06, Min w: 0.9426974654197693\n",
      "Iteration 930, Loss: 1.2239134775882121e-05, Min w: 0.91401606798172\n",
      "Iteration 940, Loss: 7.253590865730075e-06, Min w: 0.9423806667327881\n",
      "Iteration 950, Loss: 2.2472304408438504e-05, Min w: 0.8776714205741882\n",
      "Iteration 960, Loss: 9.939418305293657e-06, Min w: 0.9352283477783203\n",
      "Iteration 970, Loss: 1.3419301467365585e-05, Min w: 0.911258339881897\n",
      "Iteration 980, Loss: 1.2680878171522636e-05, Min w: 0.8975858688354492\n",
      "Iteration 990, Loss: 9.379858965985477e-06, Min w: 0.9472232460975647\n",
      "Iteration 1000, Loss: 7.5803632171300706e-06, Min w: 0.9491474032402039\n",
      "Iteration 1010, Loss: 9.09378650248982e-06, Min w: 0.9565697908401489\n",
      "Iteration 1020, Loss: 1.315755071118474e-05, Min w: 0.9099177718162537\n",
      "Iteration 1030, Loss: 5.006921128369868e-06, Min w: 0.9643814563751221\n",
      "Iteration 1040, Loss: 1.8887472833739594e-05, Min w: 0.8878344893455505\n",
      "Iteration 1050, Loss: 7.754817488603294e-06, Min w: 0.9396710395812988\n",
      "Iteration 1060, Loss: 6.38851770418114e-06, Min w: 0.9424257278442383\n",
      "Iteration 1070, Loss: 1.193889147543814e-05, Min w: 0.9302409291267395\n",
      "Iteration 1080, Loss: 8.481621080136392e-06, Min w: 0.9344961643218994\n",
      "Iteration 1090, Loss: 5.080694973003119e-05, Min w: 0.6532571911811829\n",
      "Iteration 1100, Loss: 2.8832992029492743e-05, Min w: 0.6512462496757507\n",
      "Iteration 1110, Loss: 4.176298534730449e-05, Min w: 0.6486974954605103\n",
      "Iteration 1120, Loss: 1.6320713257300667e-05, Min w: 0.8446584343910217\n",
      "Iteration 1130, Loss: 8.167097803379875e-06, Min w: 0.9210883378982544\n",
      "Iteration 1140, Loss: 4.57572832601727e-06, Min w: 0.9532849192619324\n",
      "Iteration 1150, Loss: 7.508401267841691e-06, Min w: 0.9339398741722107\n",
      "Iteration 1160, Loss: 9.367594429932069e-06, Min w: 0.8928700089454651\n",
      "Iteration 1170, Loss: 4.625753717846237e-06, Min w: 0.9603031873703003\n",
      "Iteration 1180, Loss: 6.790058705519186e-06, Min w: 0.952571451663971\n",
      "Iteration 1190, Loss: 9.539402526570484e-06, Min w: 0.9254812598228455\n",
      "Iteration 1200, Loss: 2.6533643904258497e-06, Min w: 0.9748902916908264\n",
      "Iteration 1210, Loss: 4.927783720631851e-06, Min w: 0.9512225985527039\n",
      "Iteration 1220, Loss: 6.0992369981249794e-06, Min w: 0.9677489995956421\n",
      "Iteration 1230, Loss: 2.2499118585983524e-06, Min w: 0.9731248021125793\n",
      "Iteration 1240, Loss: 3.6061921946384246e-06, Min w: 0.9641655683517456\n",
      "Iteration 0, Loss: 5.600148142548278e-06, Min w: 0.9523412585258484\n",
      "Iteration 10, Loss: 6.098387984820874e-06, Min w: 0.9638598561286926\n",
      "Iteration 20, Loss: 7.893947440607008e-06, Min w: 0.9409352540969849\n",
      "Iteration 30, Loss: 6.419148576242151e-06, Min w: 0.9651610851287842\n",
      "Iteration 40, Loss: 5.873257578059565e-06, Min w: 0.9418562054634094\n",
      "Iteration 50, Loss: 9.293523362430278e-06, Min w: 0.9458459615707397\n",
      "Iteration 60, Loss: 1.5951560271787457e-05, Min w: 0.9190064668655396\n",
      "Iteration 70, Loss: 6.99085012456635e-06, Min w: 0.9494432210922241\n",
      "Iteration 80, Loss: 1.2281402632652316e-05, Min w: 0.9212265014648438\n",
      "Iteration 90, Loss: 6.068969923944678e-06, Min w: 0.9628852605819702\n",
      "Iteration 100, Loss: 1.0615493920340668e-05, Min w: 0.9411262273788452\n",
      "Iteration 110, Loss: 8.857630746206269e-06, Min w: 0.9447113871574402\n",
      "Iteration 120, Loss: 8.72664986673044e-06, Min w: 0.916347324848175\n",
      "Iteration 130, Loss: 1.0592493708827533e-05, Min w: 0.9258777499198914\n",
      "Iteration 140, Loss: 7.296251624211436e-06, Min w: 0.948373556137085\n",
      "Iteration 150, Loss: 1.137501294579124e-05, Min w: 0.9453091025352478\n",
      "Iteration 160, Loss: 5.529180725716287e-06, Min w: 0.9645184278488159\n",
      "Iteration 170, Loss: 1.1415982044127304e-05, Min w: 0.9244362115859985\n",
      "Iteration 180, Loss: 1.3509036762116011e-05, Min w: 0.924015998840332\n",
      "Iteration 190, Loss: 6.1492469285440166e-06, Min w: 0.9471482038497925\n",
      "Iteration 200, Loss: 1.4664532500319183e-05, Min w: 0.9062579870223999\n",
      "Iteration 210, Loss: 1.0443563041917514e-05, Min w: 0.9388617873191833\n",
      "Iteration 220, Loss: 1.2057819731126074e-05, Min w: 0.9356495141983032\n",
      "Iteration 230, Loss: 9.49063087318791e-06, Min w: 0.9358188509941101\n",
      "Iteration 240, Loss: 7.1025024226401e-06, Min w: 0.9557206034660339\n",
      "Iteration 250, Loss: 1.8308492144569755e-05, Min w: 0.9085757732391357\n",
      "Iteration 260, Loss: 5.488311217050068e-06, Min w: 0.9372556209564209\n",
      "Iteration 270, Loss: 1.2311726095504127e-05, Min w: 0.926016092300415\n",
      "Iteration 280, Loss: 7.4042773121618666e-06, Min w: 0.9375341534614563\n",
      "Iteration 290, Loss: 1.0796880815178156e-05, Min w: 0.8870871663093567\n",
      "Iteration 300, Loss: 1.072520262823673e-05, Min w: 0.9272263646125793\n",
      "Iteration 310, Loss: 1.3634760762215592e-05, Min w: 0.9195967316627502\n",
      "Iteration 320, Loss: 8.908870768209454e-06, Min w: 0.9532322883605957\n",
      "Iteration 330, Loss: 9.759074600879103e-06, Min w: 0.900995671749115\n",
      "Iteration 340, Loss: 1.425781738362275e-05, Min w: 0.9091836214065552\n",
      "Iteration 350, Loss: 1.2704464097623713e-05, Min w: 0.8471102118492126\n",
      "Iteration 360, Loss: 1.056902783602709e-05, Min w: 0.9004718065261841\n",
      "Iteration 370, Loss: 7.202586857602e-06, Min w: 0.9690853357315063\n",
      "Iteration 380, Loss: 9.758850865182467e-06, Min w: 0.9425130486488342\n",
      "Iteration 390, Loss: 9.743311238707975e-06, Min w: 0.9424683451652527\n",
      "Iteration 400, Loss: 7.1113126978161745e-06, Min w: 0.9576398134231567\n",
      "Iteration 410, Loss: 1.3753456187259872e-05, Min w: 0.9348657727241516\n",
      "Iteration 420, Loss: 9.638762094255071e-06, Min w: 0.9469670653343201\n",
      "Iteration 430, Loss: 1.0125625522050541e-05, Min w: 0.9307907819747925\n",
      "Iteration 440, Loss: 1.1422944226069376e-05, Min w: 0.9346774220466614\n",
      "Iteration 450, Loss: 8.284750947495922e-06, Min w: 0.9562355875968933\n",
      "Iteration 460, Loss: 1.0243694305245299e-05, Min w: 0.9277105927467346\n",
      "Iteration 470, Loss: 5.098048404761357e-06, Min w: 0.9616938233375549\n",
      "Iteration 480, Loss: 1.5664983948227018e-05, Min w: 0.8787464499473572\n",
      "Iteration 490, Loss: 6.438332547986647e-06, Min w: 0.9483356475830078\n",
      "Iteration 500, Loss: 1.418888132320717e-05, Min w: 0.9106327891349792\n",
      "Iteration 510, Loss: 9.84019243333023e-06, Min w: 0.8734145760536194\n",
      "Iteration 520, Loss: 1.2263063581485767e-05, Min w: 0.9309770464897156\n",
      "Iteration 530, Loss: 6.295461844274541e-06, Min w: 0.9628762602806091\n",
      "Iteration 540, Loss: 1.1610697583819274e-05, Min w: 0.9404525756835938\n",
      "Iteration 550, Loss: 9.843663974606898e-06, Min w: 0.9313860535621643\n",
      "Iteration 560, Loss: 1.0124792424903717e-05, Min w: 0.9316299557685852\n",
      "Iteration 570, Loss: 1.657884604355786e-05, Min w: 0.8979005813598633\n",
      "Iteration 580, Loss: 7.47179365134798e-06, Min w: 0.9344093203544617\n",
      "Iteration 590, Loss: 1.1957508831983432e-05, Min w: 0.9205799102783203\n",
      "Iteration 600, Loss: 4.694442395702936e-06, Min w: 0.9568291306495667\n",
      "Iteration 610, Loss: 1.364982108498225e-05, Min w: 0.9230767488479614\n",
      "Iteration 620, Loss: 1.1466113392089028e-05, Min w: 0.9426352977752686\n",
      "Iteration 630, Loss: 1.610743856872432e-05, Min w: 0.9255458116531372\n",
      "Iteration 640, Loss: 1.314281780651072e-05, Min w: 0.9147598743438721\n",
      "Iteration 650, Loss: 9.99111944111064e-06, Min w: 0.9438211917877197\n",
      "Iteration 660, Loss: 1.0449349247210193e-05, Min w: 0.9346540570259094\n",
      "Iteration 670, Loss: 6.457813469751272e-06, Min w: 0.965770959854126\n",
      "Iteration 680, Loss: 9.960220268112607e-06, Min w: 0.9472577571868896\n",
      "Iteration 690, Loss: 1.0905799172178376e-05, Min w: 0.947665274143219\n",
      "Iteration 700, Loss: 9.1680567493313e-06, Min w: 0.9259828925132751\n",
      "Iteration 710, Loss: 1.3284184205986094e-05, Min w: 0.9201948642730713\n",
      "Iteration 720, Loss: 6.5085559981525876e-06, Min w: 0.9389206171035767\n",
      "Iteration 730, Loss: 1.9034285287489183e-05, Min w: 0.899204671382904\n",
      "Iteration 740, Loss: 4.2201536416541785e-06, Min w: 0.9615183472633362\n",
      "Iteration 750, Loss: 9.581135600456037e-06, Min w: 0.9286747574806213\n",
      "Iteration 760, Loss: 1.5867295587668195e-05, Min w: 0.8925959467887878\n",
      "Iteration 770, Loss: 2.231224425486289e-05, Min w: 0.8757314085960388\n",
      "Iteration 780, Loss: 7.696998181927484e-06, Min w: 0.9508219361305237\n",
      "Iteration 790, Loss: 1.2663685993175022e-05, Min w: 0.9273989200592041\n",
      "Iteration 800, Loss: 5.268672794045415e-06, Min w: 0.9631193280220032\n",
      "Iteration 810, Loss: 1.5705174519098364e-05, Min w: 0.9329696893692017\n",
      "Iteration 820, Loss: 6.442674475692911e-06, Min w: 0.9536576867103577\n",
      "Iteration 830, Loss: 9.054903784999624e-06, Min w: 0.9437249898910522\n",
      "Iteration 840, Loss: 4.926712335873162e-06, Min w: 0.9537801146507263\n",
      "Iteration 850, Loss: 2.1778829250251874e-05, Min w: 0.8807035684585571\n",
      "Iteration 860, Loss: 1.0537746675254311e-05, Min w: 0.9357990622520447\n",
      "Iteration 870, Loss: 8.983692168840207e-06, Min w: 0.9390571713447571\n",
      "Iteration 880, Loss: 1.829617758630775e-05, Min w: 0.9131759405136108\n",
      "Iteration 890, Loss: 2.0021227101096883e-05, Min w: 0.8599743843078613\n",
      "Iteration 900, Loss: 4.35586616731598e-06, Min w: 0.9602589011192322\n",
      "Iteration 910, Loss: 1.1889010238519404e-05, Min w: 0.9302506446838379\n",
      "Iteration 920, Loss: 4.810895916307345e-06, Min w: 0.9484310150146484\n",
      "Iteration 930, Loss: 1.5341576727223583e-05, Min w: 0.9174622893333435\n",
      "Iteration 940, Loss: 1.0090397154272068e-05, Min w: 0.9215971827507019\n",
      "Iteration 950, Loss: 8.948298273026012e-06, Min w: 0.9400226473808289\n",
      "Iteration 960, Loss: 1.6019303075154312e-05, Min w: 0.9048840999603271\n",
      "Iteration 970, Loss: 3.567227167877718e-06, Min w: 0.9672199487686157\n",
      "Iteration 980, Loss: 1.5639672710676678e-05, Min w: 0.9014480113983154\n",
      "Iteration 990, Loss: 7.1558274612470996e-06, Min w: 0.9573129415512085\n",
      "Iteration 1000, Loss: 1.328041162196314e-05, Min w: 0.9039230942726135\n",
      "Iteration 1010, Loss: 7.605389782838756e-06, Min w: 0.9375818371772766\n",
      "Iteration 1020, Loss: 1.1509599971759599e-05, Min w: 0.9401870965957642\n",
      "Iteration 1030, Loss: 1.4247306353354361e-05, Min w: 0.9012199640274048\n",
      "Iteration 1040, Loss: 7.53168524170178e-06, Min w: 0.94594407081604\n",
      "Iteration 1050, Loss: 7.960554285091348e-06, Min w: 0.9143781065940857\n",
      "Iteration 1060, Loss: 9.244986358680762e-06, Min w: 0.930115818977356\n",
      "Iteration 1070, Loss: 1.2406232599460054e-05, Min w: 0.9174116253852844\n",
      "Iteration 1080, Loss: 8.943015018303413e-06, Min w: 0.9192943572998047\n",
      "Iteration 1090, Loss: 7.926243597466964e-06, Min w: 0.9369526505470276\n",
      "Iteration 1100, Loss: 5.20028879691381e-06, Min w: 0.9497815370559692\n",
      "Iteration 1110, Loss: 1.9485358279780485e-05, Min w: 0.831061840057373\n",
      "Iteration 1120, Loss: 0.00012344232527539134, Min w: 0.2600661814212799\n",
      "Iteration 1130, Loss: 7.810655370121822e-05, Min w: 0.009619230404496193\n",
      "Iteration 1140, Loss: 0.00011642433673841879, Min w: 0.03388817235827446\n",
      "Iteration 1150, Loss: 0.00010867487435461953, Min w: 0.03703976422548294\n",
      "Iteration 1160, Loss: 5.666983997798525e-05, Min w: 0.7206608057022095\n",
      "Iteration 1170, Loss: 5.983312803437002e-05, Min w: 0.07033588737249374\n",
      "Iteration 1180, Loss: 1.7978276446228847e-05, Min w: 0.7234911918640137\n",
      "Iteration 1190, Loss: 1.750349110807292e-05, Min w: 0.7601583003997803\n",
      "Iteration 1200, Loss: 6.385912001860561e-06, Min w: 0.9586268663406372\n",
      "Iteration 1210, Loss: 2.766075567706139e-06, Min w: 0.9552868604660034\n",
      "Early break at iteration 1214 --------------------------------\n",
      "Iteration 0, Loss: 1.7040664488376933e-06, Min w: 0.984868586063385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  79%|███████▉  | 19/24 [10:30<03:40, 44.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 9.36964170250576e-07, Min w: 0.9856671094894409\n",
      "Early break at iteration 1 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 3720, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0025978554319006876, 'L2_avg': 0.002806927156143693, 'End_point_L1_avg': 0.0023271197994935923, 'End_point_L2_avg': 0.0030594020042637397}\n",
      "Iteration 0, Loss: 0.0005384577671065927, Min w: 0.0\n",
      "Iteration 10, Loss: 0.0003596939495764673, Min w: 0.0\n",
      "Iteration 20, Loss: 0.00028876433498226106, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0002526644675526768, Min w: 0.0\n",
      "Iteration 40, Loss: 0.000176680157892406, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0001632619823794812, Min w: 0.0\n",
      "Iteration 60, Loss: 0.00015190111298579723, Min w: 0.0\n",
      "Iteration 70, Loss: 0.00013941571523901075, Min w: 0.0\n",
      "Iteration 80, Loss: 0.00012648258416447788, Min w: 0.0\n",
      "Iteration 90, Loss: 0.0001190482871606946, Min w: 0.0\n",
      "Iteration 100, Loss: 0.00010006391676142812, Min w: 0.0\n",
      "Iteration 110, Loss: 9.352679626317695e-05, Min w: 7.163804661134209e-35\n",
      "Iteration 120, Loss: 8.801306830719113e-05, Min w: 0.0\n",
      "Iteration 130, Loss: 8.456959039904177e-05, Min w: 0.0\n",
      "Iteration 140, Loss: 8.805898687569425e-05, Min w: 0.0\n",
      "Iteration 150, Loss: 8.062670531217009e-05, Min w: 6.885914061172116e-11\n",
      "Iteration 160, Loss: 7.742569869151339e-05, Min w: 2.5646394730127753e-12\n",
      "Iteration 170, Loss: 8.313007128890604e-05, Min w: 0.010440440848469734\n",
      "Iteration 180, Loss: 8.180002623703331e-05, Min w: 8.791500590141732e-24\n",
      "Iteration 190, Loss: 7.460701453965157e-05, Min w: 4.5992627585474365e-19\n",
      "Iteration 200, Loss: 8.24846065370366e-05, Min w: 0.0\n",
      "Iteration 210, Loss: 7.739365537418053e-05, Min w: 0.0\n",
      "Iteration 220, Loss: 8.255786815425381e-05, Min w: 7.851094210309384e-07\n",
      "Iteration 230, Loss: 7.360627205343917e-05, Min w: 2.4034112360704684e-21\n",
      "Iteration 240, Loss: 7.935473695397377e-05, Min w: 0.002015701262280345\n",
      "Iteration 250, Loss: 7.902486686361954e-05, Min w: 1.3778349341179167e-25\n",
      "Iteration 260, Loss: 7.866491068853065e-05, Min w: 0.0\n",
      "Iteration 270, Loss: 7.778398139635101e-05, Min w: 1.2863121234829578e-08\n",
      "Iteration 280, Loss: 3.952928091166541e-05, Min w: 0.5369112491607666\n",
      "Iteration 290, Loss: 4.8552221414865926e-05, Min w: 0.13671620190143585\n",
      "Iteration 300, Loss: 6.162959471112117e-05, Min w: 0.1381607949733734\n",
      "Iteration 310, Loss: 6.346371810650453e-05, Min w: 0.0001537439675303176\n",
      "Iteration 320, Loss: 4.0598552004667e-05, Min w: 0.43548595905303955\n",
      "Iteration 330, Loss: 2.6934156267088838e-05, Min w: 0.6822256445884705\n",
      "Iteration 340, Loss: 3.799648038693704e-05, Min w: 0.4614681899547577\n",
      "Iteration 350, Loss: 1.5440798961208202e-05, Min w: 0.8748875856399536\n",
      "Iteration 360, Loss: 3.034971814486198e-05, Min w: 0.6664764285087585\n",
      "Iteration 370, Loss: 2.217290057160426e-05, Min w: 0.7502191066741943\n",
      "Iteration 380, Loss: 1.7515327272121795e-05, Min w: 0.818177342414856\n",
      "Iteration 390, Loss: 1.180856634164229e-05, Min w: 0.8825225830078125\n",
      "Iteration 400, Loss: 1.6404672351200134e-05, Min w: 0.9144796133041382\n",
      "Iteration 410, Loss: 9.199865417031106e-06, Min w: 0.9078181385993958\n",
      "Iteration 420, Loss: 2.3319811589317396e-05, Min w: 0.8576334118843079\n",
      "Iteration 430, Loss: 1.7610504073672928e-05, Min w: 0.8782117366790771\n",
      "Iteration 440, Loss: 1.2764380699081812e-05, Min w: 0.8800520896911621\n",
      "Iteration 450, Loss: 1.3062315701972693e-05, Min w: 0.9139050841331482\n",
      "Iteration 460, Loss: 1.535941191832535e-05, Min w: 0.9211740493774414\n",
      "Iteration 470, Loss: 1.6063981092884205e-05, Min w: 0.9141932725906372\n",
      "Iteration 480, Loss: 1.220423564518569e-05, Min w: 0.9099704027175903\n",
      "Iteration 490, Loss: 1.7394533642800525e-05, Min w: 0.8563268780708313\n",
      "Iteration 500, Loss: 1.6984151443466544e-05, Min w: 0.9156493544578552\n",
      "Iteration 510, Loss: 1.4388356248673517e-05, Min w: 0.910164475440979\n",
      "Iteration 520, Loss: 1.6044483345467597e-05, Min w: 0.8940662741661072\n",
      "Iteration 530, Loss: 1.1890057976415846e-05, Min w: 0.9044889807701111\n",
      "Iteration 540, Loss: 1.6321337170666084e-05, Min w: 0.9051535129547119\n",
      "Iteration 550, Loss: 1.4403759450942744e-05, Min w: 0.9158483147621155\n",
      "Iteration 560, Loss: 1.6684774891473353e-05, Min w: 0.9204924702644348\n",
      "Iteration 570, Loss: 1.6649959434289485e-05, Min w: 0.9180735349655151\n",
      "Iteration 580, Loss: 1.653888466535136e-05, Min w: 0.8824819326400757\n",
      "Iteration 590, Loss: 1.0610297067614738e-05, Min w: 0.9165430068969727\n",
      "Iteration 600, Loss: 1.8882765289163217e-05, Min w: 0.8879581689834595\n",
      "Iteration 610, Loss: 1.5909410649328493e-05, Min w: 0.919988751411438\n",
      "Iteration 620, Loss: 1.587200677022338e-05, Min w: 0.9130953550338745\n",
      "Iteration 630, Loss: 1.7069129171431996e-05, Min w: 0.9200963973999023\n",
      "Iteration 640, Loss: 1.5322828403441235e-05, Min w: 0.8766371011734009\n",
      "Iteration 650, Loss: 1.6837228031363338e-05, Min w: 0.9282751083374023\n",
      "Iteration 660, Loss: 1.1833571988972835e-05, Min w: 0.9175941348075867\n",
      "Iteration 670, Loss: 2.1661082428181544e-05, Min w: 0.8925892114639282\n",
      "Iteration 680, Loss: 1.4070443285163492e-05, Min w: 0.93441241979599\n",
      "Iteration 690, Loss: 1.474356758990325e-05, Min w: 0.9328640103340149\n",
      "Iteration 700, Loss: 1.405840794177493e-05, Min w: 0.9414419531822205\n",
      "Iteration 710, Loss: 1.1955024092458189e-05, Min w: 0.9417733550071716\n",
      "Iteration 720, Loss: 1.2653115845751017e-05, Min w: 0.9324920177459717\n",
      "Iteration 730, Loss: 1.4407082744583022e-05, Min w: 0.9355826377868652\n",
      "Iteration 740, Loss: 1.3789286640530918e-05, Min w: 0.9402260184288025\n",
      "Iteration 750, Loss: 1.19640071716276e-05, Min w: 0.9499614834785461\n",
      "Iteration 760, Loss: 1.392405556543963e-05, Min w: 0.9261325597763062\n",
      "Iteration 770, Loss: 2.3531649276264943e-05, Min w: 0.831721305847168\n",
      "Iteration 780, Loss: 1.6059415429481305e-05, Min w: 0.9173715114593506\n",
      "Iteration 790, Loss: 1.4815610484220088e-05, Min w: 0.932380199432373\n",
      "Iteration 800, Loss: 1.434503064956516e-05, Min w: 0.9279000759124756\n",
      "Iteration 810, Loss: 1.2739808880724013e-05, Min w: 0.9404075145721436\n",
      "Iteration 820, Loss: 2.160548683605157e-05, Min w: 0.9033971428871155\n",
      "Iteration 830, Loss: 1.1988207916147076e-05, Min w: 0.9343774914741516\n",
      "Iteration 840, Loss: 1.8812146663549356e-05, Min w: 0.8864684700965881\n",
      "Iteration 850, Loss: 1.2014594176434912e-05, Min w: 0.9056424498558044\n",
      "Iteration 860, Loss: 1.6405600035795942e-05, Min w: 0.8956968188285828\n",
      "Iteration 870, Loss: 1.2864125892519951e-05, Min w: 0.9324761629104614\n",
      "Iteration 880, Loss: 1.6377623978769407e-05, Min w: 0.9166185855865479\n",
      "Iteration 890, Loss: 1.4548971194017213e-05, Min w: 0.9316995739936829\n",
      "Iteration 900, Loss: 1.2813711691705976e-05, Min w: 0.9401339888572693\n",
      "Iteration 910, Loss: 1.6483023500768468e-05, Min w: 0.9323205947875977\n",
      "Iteration 920, Loss: 1.4946966985007748e-05, Min w: 0.9183276891708374\n",
      "Iteration 930, Loss: 1.2939638509124052e-05, Min w: 0.9342840909957886\n",
      "Iteration 940, Loss: 1.5544554116786458e-05, Min w: 0.9251694679260254\n",
      "Iteration 950, Loss: 1.6844531273818575e-05, Min w: 0.9240648150444031\n",
      "Iteration 960, Loss: 1.1014593837899156e-05, Min w: 0.9367265701293945\n",
      "Iteration 970, Loss: 1.8578690287540667e-05, Min w: 0.9137948751449585\n",
      "Iteration 980, Loss: 1.7280233805649914e-05, Min w: 0.9087555408477783\n",
      "Iteration 990, Loss: 1.558326039230451e-05, Min w: 0.9406137466430664\n",
      "Iteration 1000, Loss: 1.6149295333889313e-05, Min w: 0.9321024417877197\n",
      "Iteration 1010, Loss: 1.4564674529538024e-05, Min w: 0.9269327521324158\n",
      "Iteration 1020, Loss: 1.472013900638558e-05, Min w: 0.9427912831306458\n",
      "Iteration 1030, Loss: 1.5263063687598333e-05, Min w: 0.9290540814399719\n",
      "Iteration 1040, Loss: 1.3680330084753223e-05, Min w: 0.9226884841918945\n",
      "Iteration 1050, Loss: 1.5348456145147793e-05, Min w: 0.9129735827445984\n",
      "Iteration 1060, Loss: 1.6910420526983216e-05, Min w: 0.9135972857475281\n",
      "Iteration 1070, Loss: 1.3323202438186854e-05, Min w: 0.9354878664016724\n",
      "Iteration 1080, Loss: 1.4577411093341652e-05, Min w: 0.9346607327461243\n",
      "Iteration 1090, Loss: 1.5148012607824057e-05, Min w: 0.9065195322036743\n",
      "Iteration 1100, Loss: 1.113178859668551e-05, Min w: 0.93666672706604\n",
      "Iteration 1110, Loss: 2.0108323951717466e-05, Min w: 0.9198381900787354\n",
      "Iteration 1120, Loss: 1.857775350799784e-05, Min w: 0.8519032597541809\n",
      "Iteration 1130, Loss: 1.821625482989475e-05, Min w: 0.9101848006248474\n",
      "Iteration 1140, Loss: 1.200018868985353e-05, Min w: 0.9272280931472778\n",
      "Iteration 1150, Loss: 1.5090899069036823e-05, Min w: 0.9363484382629395\n",
      "Iteration 1160, Loss: 1.5295228877221234e-05, Min w: 0.9179615378379822\n",
      "Iteration 1170, Loss: 1.3520226275431924e-05, Min w: 0.9290029406547546\n",
      "Iteration 1180, Loss: 1.5550440366496332e-05, Min w: 0.9262245297431946\n",
      "Iteration 1190, Loss: 1.3431576917355414e-05, Min w: 0.9313836693763733\n",
      "Iteration 1200, Loss: 1.4950062904972583e-05, Min w: 0.9308927655220032\n",
      "Iteration 1210, Loss: 1.5403034922201186e-05, Min w: 0.9282089471817017\n",
      "Iteration 1220, Loss: 1.4036274478712585e-05, Min w: 0.9401230812072754\n",
      "Iteration 1230, Loss: 1.233633065567119e-05, Min w: 0.94883793592453\n",
      "Iteration 1240, Loss: 1.2816277376259677e-05, Min w: 0.9431362152099609\n",
      "Iteration 0, Loss: 1.6726380636100657e-05, Min w: 0.9172564148902893\n",
      "Iteration 10, Loss: 1.2320624591666274e-05, Min w: 0.9351813793182373\n",
      "Iteration 20, Loss: 1.3681143173016608e-05, Min w: 0.899105429649353\n",
      "Iteration 30, Loss: 1.682242327660788e-05, Min w: 0.9123164415359497\n",
      "Iteration 40, Loss: 1.3690033483726438e-05, Min w: 0.9160001277923584\n",
      "Iteration 50, Loss: 1.4486324289464392e-05, Min w: 0.8998998999595642\n",
      "Iteration 60, Loss: 1.6766996850492433e-05, Min w: 0.9137433171272278\n",
      "Iteration 70, Loss: 1.525910192867741e-05, Min w: 0.9241592884063721\n",
      "Iteration 80, Loss: 1.3960411706648301e-05, Min w: 0.9133077263832092\n",
      "Iteration 90, Loss: 1.7763533833203837e-05, Min w: 0.908105194568634\n",
      "Iteration 100, Loss: 1.5331286704167724e-05, Min w: 0.912599503993988\n",
      "Iteration 110, Loss: 1.3519107596948743e-05, Min w: 0.9289168119430542\n",
      "Iteration 120, Loss: 1.4075059880269691e-05, Min w: 0.9259557127952576\n",
      "Iteration 130, Loss: 1.4539645235345233e-05, Min w: 0.911069929599762\n",
      "Iteration 140, Loss: 1.005467856884934e-05, Min w: 0.9392956495285034\n",
      "Iteration 150, Loss: 1.3347217645787168e-05, Min w: 0.9358496069908142\n",
      "Iteration 160, Loss: 1.0126762390427757e-05, Min w: 0.9316325783729553\n",
      "Iteration 170, Loss: 3.19138853228651e-05, Min w: 0.8200342655181885\n",
      "Iteration 180, Loss: 1.415994393028086e-05, Min w: 0.9128416180610657\n",
      "Iteration 190, Loss: 1.9554074242478237e-05, Min w: 0.8813477158546448\n",
      "Iteration 200, Loss: 1.3210349607106764e-05, Min w: 0.9222366213798523\n",
      "Iteration 210, Loss: 1.3716040484723635e-05, Min w: 0.9297054409980774\n",
      "Iteration 220, Loss: 1.2363258065306582e-05, Min w: 0.9277632832527161\n",
      "Iteration 230, Loss: 1.5431009160238318e-05, Min w: 0.9246821403503418\n",
      "Iteration 240, Loss: 1.4226024177332874e-05, Min w: 0.9189946055412292\n",
      "Iteration 250, Loss: 1.466809590056073e-05, Min w: 0.92201828956604\n",
      "Iteration 260, Loss: 9.156172382063232e-06, Min w: 0.9509403705596924\n",
      "Iteration 270, Loss: 1.3694944755116012e-05, Min w: 0.9447542428970337\n",
      "Iteration 280, Loss: 1.2296426575630903e-05, Min w: 0.9328904747962952\n",
      "Iteration 290, Loss: 2.0695208149845712e-05, Min w: 0.8651743531227112\n",
      "Iteration 300, Loss: 1.0499160453036893e-05, Min w: 0.9239290356636047\n",
      "Iteration 310, Loss: 1.327669269812759e-05, Min w: 0.9293959736824036\n",
      "Iteration 320, Loss: 2.389886685705278e-05, Min w: 0.8971969485282898\n",
      "Iteration 330, Loss: 1.3592588402389083e-05, Min w: 0.9259607791900635\n",
      "Iteration 340, Loss: 1.2812772183679044e-05, Min w: 0.9365445971488953\n",
      "Iteration 350, Loss: 1.1631328561634291e-05, Min w: 0.9499338269233704\n",
      "Iteration 360, Loss: 1.4119574188953266e-05, Min w: 0.9270570874214172\n",
      "Iteration 370, Loss: 1.132558099925518e-05, Min w: 0.9428244233131409\n",
      "Iteration 380, Loss: 1.4504255887004547e-05, Min w: 0.9365606904029846\n",
      "Iteration 390, Loss: 1.0203421879850794e-05, Min w: 0.9543424248695374\n",
      "Iteration 400, Loss: 1.4826196093054023e-05, Min w: 0.9288014769554138\n",
      "Iteration 410, Loss: 1.2284280273888726e-05, Min w: 0.9346319437026978\n",
      "Iteration 420, Loss: 1.393192451359937e-05, Min w: 0.9330222606658936\n",
      "Iteration 430, Loss: 1.53332748595858e-05, Min w: 0.9286325573921204\n",
      "Iteration 440, Loss: 1.2795993825420737e-05, Min w: 0.9408609867095947\n",
      "Iteration 450, Loss: 2.5476001610513777e-05, Min w: 0.8890085816383362\n",
      "Iteration 460, Loss: 1.5422148862853646e-05, Min w: 0.919120728969574\n",
      "Iteration 470, Loss: 1.4418669707083609e-05, Min w: 0.9217378497123718\n",
      "Iteration 480, Loss: 1.3139733709977008e-05, Min w: 0.9396908283233643\n",
      "Iteration 490, Loss: 1.3514476449927315e-05, Min w: 0.9253122806549072\n",
      "Iteration 500, Loss: 1.4186235603119712e-05, Min w: 0.9238390326499939\n",
      "Iteration 510, Loss: 1.3362719982978888e-05, Min w: 0.9236894249916077\n",
      "Iteration 520, Loss: 1.2168450666649733e-05, Min w: 0.9432113170623779\n",
      "Iteration 530, Loss: 1.4211282177711837e-05, Min w: 0.9462019801139832\n",
      "Iteration 540, Loss: 1.3753704479313456e-05, Min w: 0.9342514276504517\n",
      "Iteration 550, Loss: 1.2637159670703113e-05, Min w: 0.9319384694099426\n",
      "Iteration 560, Loss: 1.1747795724659227e-05, Min w: 0.9433615803718567\n",
      "Iteration 570, Loss: 1.4564633602276444e-05, Min w: 0.9341347217559814\n",
      "Iteration 580, Loss: 1.1504705071274657e-05, Min w: 0.9476935863494873\n",
      "Iteration 590, Loss: 1.3646657862409484e-05, Min w: 0.9323937296867371\n",
      "Iteration 600, Loss: 1.6103400412248448e-05, Min w: 0.908578634262085\n",
      "Iteration 610, Loss: 1.3253576071292628e-05, Min w: 0.936864972114563\n",
      "Iteration 620, Loss: 1.4839692994428333e-05, Min w: 0.9200071692466736\n",
      "Iteration 630, Loss: 1.261585384781938e-05, Min w: 0.9285286664962769\n",
      "Iteration 640, Loss: 1.4485893188975751e-05, Min w: 0.924558162689209\n",
      "Iteration 650, Loss: 1.1130005987070035e-05, Min w: 0.9452171921730042\n",
      "Iteration 660, Loss: 1.2983914530195761e-05, Min w: 0.9284345507621765\n",
      "Iteration 670, Loss: 2.0449344447115436e-05, Min w: 0.8030192852020264\n",
      "Iteration 680, Loss: 1.6490075722686015e-05, Min w: 0.8152700662612915\n",
      "Iteration 690, Loss: 1.896264984679874e-05, Min w: 0.8492431044578552\n",
      "Iteration 700, Loss: 1.9113133021164685e-05, Min w: 0.8673624396324158\n",
      "Iteration 710, Loss: 1.6590765881119296e-05, Min w: 0.8839643001556396\n",
      "Iteration 720, Loss: 1.5231439647322986e-05, Min w: 0.9120962619781494\n",
      "Iteration 730, Loss: 1.3449526704789605e-05, Min w: 0.9213612675666809\n",
      "Iteration 740, Loss: 1.4405905858438928e-05, Min w: 0.9251341223716736\n",
      "Iteration 750, Loss: 1.5582656487822533e-05, Min w: 0.9307286739349365\n",
      "Iteration 760, Loss: 1.3321680853550788e-05, Min w: 0.9282300472259521\n",
      "Iteration 770, Loss: 1.0714008567447308e-05, Min w: 0.9283276200294495\n",
      "Iteration 780, Loss: 1.086225347535219e-05, Min w: 0.940606415271759\n",
      "Iteration 790, Loss: 1.5229361451929435e-05, Min w: 0.9202371835708618\n",
      "Iteration 800, Loss: 1.658483233768493e-05, Min w: 0.9092005491256714\n",
      "Iteration 810, Loss: 1.3709062841371633e-05, Min w: 0.9175752401351929\n",
      "Iteration 820, Loss: 1.2884293028037064e-05, Min w: 0.9230363965034485\n",
      "Iteration 830, Loss: 1.1783379704866093e-05, Min w: 0.9192350506782532\n",
      "Iteration 840, Loss: 1.664917181187775e-05, Min w: 0.8767330646514893\n",
      "Iteration 850, Loss: 1.1937543604290113e-05, Min w: 0.9150897264480591\n",
      "Iteration 860, Loss: 1.4599174392060377e-05, Min w: 0.8857221603393555\n",
      "Iteration 870, Loss: 1.3490344827005174e-05, Min w: 0.9234485626220703\n",
      "Iteration 880, Loss: 1.4355697203427553e-05, Min w: 0.9252801537513733\n",
      "Iteration 890, Loss: 1.2968547707714606e-05, Min w: 0.9093629121780396\n",
      "Iteration 900, Loss: 9.52593927650014e-06, Min w: 0.9381490349769592\n",
      "Iteration 910, Loss: 1.7172915249830112e-05, Min w: 0.9190837740898132\n",
      "Iteration 920, Loss: 1.3889675756217912e-05, Min w: 0.9140737652778625\n",
      "Iteration 930, Loss: 1.4206970263330732e-05, Min w: 0.9337365031242371\n",
      "Iteration 940, Loss: 1.3108383427606896e-05, Min w: 0.935263991355896\n",
      "Iteration 950, Loss: 1.260885619558394e-05, Min w: 0.9286875128746033\n",
      "Iteration 960, Loss: 1.2537425391201396e-05, Min w: 0.9477145671844482\n",
      "Iteration 970, Loss: 1.4856022062303964e-05, Min w: 0.9293034672737122\n",
      "Iteration 980, Loss: 1.384239294566214e-05, Min w: 0.9177744388580322\n",
      "Iteration 990, Loss: 1.3742669580096845e-05, Min w: 0.9070870876312256\n",
      "Iteration 1000, Loss: 1.934148713189643e-05, Min w: 0.8837752938270569\n",
      "Iteration 1010, Loss: 1.565641832712572e-05, Min w: 0.9250914454460144\n",
      "Iteration 1020, Loss: 1.2947280083608348e-05, Min w: 0.9391232132911682\n",
      "Iteration 1030, Loss: 1.4189303328748792e-05, Min w: 0.937380313873291\n",
      "Iteration 1040, Loss: 1.353746574750403e-05, Min w: 0.9103290438652039\n",
      "Iteration 1050, Loss: 9.507865797786508e-06, Min w: 0.9418409466743469\n",
      "Iteration 1060, Loss: 1.0301951988367364e-05, Min w: 0.9408687353134155\n",
      "Iteration 1070, Loss: 1.3109149222145788e-05, Min w: 0.9481712579727173\n",
      "Iteration 1080, Loss: 1.0379041668784339e-05, Min w: 0.9552306532859802\n",
      "Iteration 1090, Loss: 1.1988382539129816e-05, Min w: 0.9236435890197754\n",
      "Iteration 1100, Loss: 9.724513802211732e-06, Min w: 0.9311679601669312\n",
      "Iteration 1110, Loss: 1.846571649366524e-05, Min w: 0.8919275403022766\n",
      "Iteration 1120, Loss: 2.1019021005486138e-05, Min w: 0.906623899936676\n",
      "Iteration 1130, Loss: 1.145483383879764e-05, Min w: 0.943442165851593\n",
      "Iteration 1140, Loss: 1.1353362424415536e-05, Min w: 0.936127781867981\n",
      "Iteration 1150, Loss: 1.2475682524382137e-05, Min w: 0.939083993434906\n",
      "Iteration 1160, Loss: 1.521395915915491e-05, Min w: 0.9087173342704773\n",
      "Iteration 1170, Loss: 1.4685567293781787e-05, Min w: 0.9380186796188354\n",
      "Iteration 1180, Loss: 1.381679976475425e-05, Min w: 0.9410141110420227\n",
      "Iteration 1190, Loss: 1.1486708899610676e-05, Min w: 0.9421483874320984\n",
      "Iteration 1200, Loss: 1.196178618556587e-05, Min w: 0.9361569881439209\n",
      "Iteration 1210, Loss: 1.0476286661287304e-05, Min w: 0.9365701079368591\n",
      "Iteration 1220, Loss: 1.4161618310026824e-05, Min w: 0.8999509215354919\n",
      "Iteration 1230, Loss: 7.2940529207699e-06, Min w: 0.9569600820541382\n",
      "Iteration 1240, Loss: 1.3646154002344701e-05, Min w: 0.9354944229125977\n",
      "Iteration 0, Loss: 1.2117850928916596e-05, Min w: 0.9363221526145935\n",
      "Iteration 10, Loss: 1.5257855920935981e-05, Min w: 0.9151549935340881\n",
      "Iteration 20, Loss: 1.2726939530693926e-05, Min w: 0.8936544060707092\n",
      "Iteration 30, Loss: 2.0807892724405974e-05, Min w: 0.8789580464363098\n",
      "Iteration 40, Loss: 8.10247911431361e-06, Min w: 0.9475633502006531\n",
      "Iteration 50, Loss: 1.5745676137157716e-05, Min w: 0.9192165732383728\n",
      "Iteration 60, Loss: 7.74820819060551e-06, Min w: 0.9393773674964905\n",
      "Iteration 70, Loss: 1.8395758161204867e-05, Min w: 0.8934823274612427\n",
      "Iteration 80, Loss: 1.3746383046964183e-05, Min w: 0.8449178338050842\n",
      "Iteration 90, Loss: 3.52048700733576e-05, Min w: 0.7749433517456055\n",
      "Iteration 100, Loss: 7.021056808298454e-05, Min w: 0.7050153613090515\n",
      "Iteration 110, Loss: 3.2906005799304694e-05, Min w: 0.7326343655586243\n",
      "Iteration 120, Loss: 1.2371764569252264e-05, Min w: 0.9051210284233093\n",
      "Iteration 130, Loss: 8.855567102727946e-06, Min w: 0.9512866139411926\n",
      "Iteration 140, Loss: 7.366629233729327e-06, Min w: 0.919895589351654\n",
      "Iteration 150, Loss: 3.3407602586521534e-06, Min w: 0.9661330580711365\n",
      "Iteration 160, Loss: 5.9867793424928095e-06, Min w: 0.957830011844635\n",
      "Iteration 170, Loss: 1.5653205309718032e-06, Min w: 0.9872444868087769\n",
      "Iteration 180, Loss: 1.2306000826356467e-05, Min w: 0.9051626324653625\n",
      "Iteration 190, Loss: 6.82180962030543e-06, Min w: 0.9270384907722473\n",
      "Iteration 200, Loss: 8.420258382102475e-06, Min w: 0.9192087054252625\n",
      "Iteration 210, Loss: 1.4855444533168338e-05, Min w: 0.8241063356399536\n",
      "Iteration 220, Loss: 1.6484656953252852e-05, Min w: 0.8889069557189941\n",
      "Iteration 230, Loss: 8.073014214460272e-06, Min w: 0.8667821288108826\n",
      "Iteration 240, Loss: 6.886984465381829e-06, Min w: 0.9278585314750671\n",
      "Iteration 250, Loss: 1.8677994376048446e-05, Min w: 0.8726586699485779\n",
      "Iteration 260, Loss: 1.1896045180037618e-05, Min w: 0.9032487869262695\n",
      "Iteration 270, Loss: 9.46541149460245e-06, Min w: 0.9436405301094055\n",
      "Iteration 280, Loss: 2.7570888050831854e-05, Min w: 0.8837961554527283\n",
      "Iteration 290, Loss: 3.058143556700088e-05, Min w: 0.7238432765007019\n",
      "Iteration 300, Loss: 1.1830033145088237e-05, Min w: 0.8751662969589233\n",
      "Iteration 310, Loss: 4.6326290430442896e-06, Min w: 0.94279545545578\n",
      "Iteration 320, Loss: 2.652279545145575e-05, Min w: 0.7971349954605103\n",
      "Iteration 330, Loss: 1.2500079719757196e-05, Min w: 0.8945145010948181\n",
      "Iteration 340, Loss: 8.902171430236194e-06, Min w: 0.9340885281562805\n",
      "Iteration 350, Loss: 2.8621034289244562e-05, Min w: 0.8289412260055542\n",
      "Iteration 360, Loss: 1.0130878763447981e-05, Min w: 0.8572980165481567\n",
      "Iteration 370, Loss: 1.0135970114788506e-05, Min w: 0.883619487285614\n",
      "Iteration 380, Loss: 4.534692834567977e-06, Min w: 0.9470291137695312\n",
      "Iteration 390, Loss: 1.71896845131414e-05, Min w: 0.9054601192474365\n",
      "Iteration 400, Loss: 6.657043741142843e-06, Min w: 0.9465033411979675\n",
      "Iteration 410, Loss: 1.5029371752461884e-05, Min w: 0.9342646598815918\n",
      "Iteration 420, Loss: 7.602142432006076e-06, Min w: 0.9231730699539185\n",
      "Iteration 430, Loss: 1.3832868717145175e-05, Min w: 0.9254140257835388\n",
      "Iteration 440, Loss: 2.19612611545017e-05, Min w: 0.8155524134635925\n",
      "Iteration 450, Loss: 1.4298478163254913e-05, Min w: 0.8987258076667786\n",
      "Iteration 460, Loss: 5.5790060287108645e-06, Min w: 0.9662322402000427\n",
      "Iteration 470, Loss: 1.1483574780868366e-05, Min w: 0.9259434342384338\n",
      "Iteration 480, Loss: 4.911335963697638e-06, Min w: 0.934647798538208\n",
      "Iteration 490, Loss: 7.084850949468091e-06, Min w: 0.9337189197540283\n",
      "Iteration 500, Loss: 9.084191333386116e-06, Min w: 0.9352547526359558\n",
      "Iteration 510, Loss: 1.4841980373603292e-05, Min w: 0.9098888039588928\n",
      "Iteration 520, Loss: 1.1689246093737893e-05, Min w: 0.9002269506454468\n",
      "Iteration 530, Loss: 9.572316230332945e-06, Min w: 0.9487290978431702\n",
      "Iteration 540, Loss: 9.772185876499861e-06, Min w: 0.9565063714981079\n",
      "Iteration 550, Loss: 1.1797708793892525e-05, Min w: 0.9423409104347229\n",
      "Iteration 560, Loss: 1.1147447366965935e-05, Min w: 0.9366509318351746\n",
      "Iteration 570, Loss: 6.965095053601544e-06, Min w: 0.9607936143875122\n",
      "Iteration 580, Loss: 1.2435801181709394e-05, Min w: 0.9440569281578064\n",
      "Iteration 590, Loss: 1.2029470781271812e-05, Min w: 0.9326965808868408\n",
      "Iteration 600, Loss: 1.4306286175269634e-05, Min w: 0.9037231802940369\n",
      "Iteration 610, Loss: 2.1436571842059493e-05, Min w: 0.8703508377075195\n",
      "Iteration 620, Loss: 1.369147048535524e-05, Min w: 0.9052876234054565\n",
      "Iteration 630, Loss: 1.4741434824827593e-05, Min w: 0.9285903573036194\n",
      "Iteration 640, Loss: 9.560209036862943e-06, Min w: 0.9411569833755493\n",
      "Iteration 650, Loss: 1.293291734327795e-05, Min w: 0.9301958680152893\n",
      "Iteration 660, Loss: 1.0998674042639323e-05, Min w: 0.9372162818908691\n",
      "Iteration 670, Loss: 1.3579054211732e-05, Min w: 0.9325230717658997\n",
      "Iteration 680, Loss: 1.1181278750882484e-05, Min w: 0.9325244426727295\n",
      "Iteration 690, Loss: 1.389058797940379e-05, Min w: 0.919032633304596\n",
      "Iteration 700, Loss: 1.28246510939789e-05, Min w: 0.931904137134552\n",
      "Iteration 710, Loss: 1.619354407011997e-05, Min w: 0.8958377242088318\n",
      "Iteration 720, Loss: 6.670227321592392e-06, Min w: 0.951312243938446\n",
      "Iteration 730, Loss: 1.8577982700662687e-05, Min w: 0.8945733308792114\n",
      "Iteration 740, Loss: 9.053103894984815e-06, Min w: 0.9154112339019775\n",
      "Iteration 750, Loss: 1.5707288184785284e-05, Min w: 0.7668949365615845\n",
      "Iteration 760, Loss: 6.1477649069274776e-06, Min w: 0.9362374544143677\n",
      "Iteration 770, Loss: 2.4571430913056247e-05, Min w: 0.8255369663238525\n",
      "Iteration 780, Loss: 1.6138117644004524e-05, Min w: 0.8872154355049133\n",
      "Iteration 790, Loss: 1.6028909158194438e-05, Min w: 0.8060235381126404\n",
      "Iteration 800, Loss: 4.263025402906351e-05, Min w: 0.7108361721038818\n",
      "Iteration 810, Loss: 1.4256317626859527e-05, Min w: 0.8802396655082703\n",
      "Iteration 820, Loss: 1.4214216207619756e-05, Min w: 0.8500239253044128\n",
      "Iteration 830, Loss: 1.3883215615351219e-05, Min w: 0.8185760378837585\n",
      "Iteration 840, Loss: 1.8547940271673724e-05, Min w: 0.8090554475784302\n",
      "Iteration 850, Loss: 1.1587931112444494e-05, Min w: 0.8492802977561951\n",
      "Iteration 860, Loss: 1.3344511899049394e-05, Min w: 0.8831295371055603\n",
      "Iteration 870, Loss: 7.713686500210315e-06, Min w: 0.8992845416069031\n",
      "Iteration 880, Loss: 2.2993317543296143e-05, Min w: 0.7955639362335205\n",
      "Iteration 890, Loss: 1.7765334632713348e-05, Min w: 0.8689018487930298\n",
      "Iteration 900, Loss: 4.563945822155802e-06, Min w: 0.9682612419128418\n",
      "Iteration 910, Loss: 1.1265279681538232e-05, Min w: 0.916999101638794\n",
      "Iteration 920, Loss: 5.753171080868924e-06, Min w: 0.9496392607688904\n",
      "Iteration 930, Loss: 5.073393822385697e-06, Min w: 0.9573831558227539\n",
      "Iteration 940, Loss: 7.80430855229497e-06, Min w: 0.9574310779571533\n",
      "Iteration 950, Loss: 5.053611403127434e-06, Min w: 0.9664223790168762\n",
      "Iteration 960, Loss: 5.0597723202372435e-06, Min w: 0.9523393511772156\n",
      "Iteration 970, Loss: 1.9641898688860238e-05, Min w: 0.8488668203353882\n",
      "Iteration 980, Loss: 2.9302214898052625e-05, Min w: 0.8233585953712463\n",
      "Iteration 990, Loss: 1.6944281014730223e-05, Min w: 0.8860118985176086\n",
      "Iteration 1000, Loss: 9.203461559081916e-06, Min w: 0.9338743090629578\n",
      "Iteration 1010, Loss: 6.160150405776221e-06, Min w: 0.9364293217658997\n",
      "Iteration 1020, Loss: 5.500592669704929e-05, Min w: 0.6537100076675415\n",
      "Iteration 1030, Loss: 2.1114139599376358e-05, Min w: 0.890231728553772\n",
      "Iteration 1040, Loss: 2.3018095816951245e-05, Min w: 0.8550334572792053\n",
      "Iteration 1050, Loss: 3.06344372802414e-05, Min w: 0.8677000999450684\n",
      "Iteration 1060, Loss: 2.1324291083146818e-05, Min w: 0.8857762217521667\n",
      "Iteration 1070, Loss: 8.167750638676807e-05, Min w: 0.5189603567123413\n",
      "Iteration 1080, Loss: 1.1679819181154016e-05, Min w: 0.9045929312705994\n",
      "Iteration 1090, Loss: 3.544398168742191e-06, Min w: 0.9710394144058228\n",
      "Iteration 1100, Loss: 1.1475115570647176e-05, Min w: 0.8898182511329651\n",
      "Iteration 1110, Loss: 1.8063994957628893e-06, Min w: 0.9672133922576904\n",
      "Iteration 1120, Loss: 6.934526936674956e-06, Min w: 0.9338974356651306\n",
      "Iteration 1130, Loss: 2.813152150338283e-06, Min w: 0.9605504870414734\n",
      "Iteration 1140, Loss: 1.4435485127251013e-06, Min w: 0.9769452810287476\n",
      "Iteration 1150, Loss: 4.660842478187988e-06, Min w: 0.9485200643539429\n",
      "Iteration 1160, Loss: 9.122572009800933e-06, Min w: 0.9387761354446411\n",
      "Iteration 1170, Loss: 4.987854026694549e-06, Min w: 0.9541848301887512\n",
      "Iteration 1180, Loss: 7.432497568515828e-06, Min w: 0.9495076537132263\n",
      "Iteration 1190, Loss: 7.72698058426613e-06, Min w: 0.9427597522735596\n",
      "Iteration 1200, Loss: 6.9270881795091555e-06, Min w: 0.9563514590263367\n",
      "Iteration 1210, Loss: 7.945091056171805e-06, Min w: 0.9586330056190491\n",
      "Iteration 1220, Loss: 8.05843410489615e-06, Min w: 0.9361532926559448\n",
      "Iteration 1230, Loss: 9.921717719407752e-06, Min w: 0.9236922264099121\n",
      "Iteration 1240, Loss: 8.217627510020975e-06, Min w: 0.9536301493644714\n",
      "Iteration 0, Loss: 1.0091353033203632e-05, Min w: 0.9275235533714294\n",
      "Iteration 10, Loss: 6.756991297152126e-06, Min w: 0.9525821208953857\n",
      "Iteration 20, Loss: 1.85177123057656e-05, Min w: 0.873643159866333\n",
      "Iteration 30, Loss: 1.1765730960178189e-05, Min w: 0.9169217348098755\n",
      "Iteration 40, Loss: 8.375941433769185e-06, Min w: 0.9553318619728088\n",
      "Iteration 50, Loss: 7.938694579934236e-06, Min w: 0.9493193626403809\n",
      "Iteration 60, Loss: 1.2344945389486384e-05, Min w: 0.9136083126068115\n",
      "Iteration 70, Loss: 8.414544936385937e-06, Min w: 0.9427154064178467\n",
      "Iteration 80, Loss: 9.679755748948082e-06, Min w: 0.9634315371513367\n",
      "Iteration 90, Loss: 1.1719169378920924e-05, Min w: 0.9161540865898132\n",
      "Iteration 100, Loss: 1.9177907233824953e-05, Min w: 0.8600447773933411\n",
      "Iteration 110, Loss: 1.6961717847152613e-05, Min w: 0.8625481128692627\n",
      "Iteration 120, Loss: 1.0062961337098386e-05, Min w: 0.9241306781768799\n",
      "Iteration 130, Loss: 1.1320824341964908e-05, Min w: 0.9292551875114441\n",
      "Iteration 140, Loss: 1.2361970220808871e-05, Min w: 0.9462976455688477\n",
      "Iteration 150, Loss: 1.341972983937012e-05, Min w: 0.9267525672912598\n",
      "Iteration 160, Loss: 1.290073214477161e-05, Min w: 0.9020123481750488\n",
      "Iteration 170, Loss: 1.6706266251276247e-05, Min w: 0.9175305366516113\n",
      "Iteration 180, Loss: 4.558032287604874e-06, Min w: 0.9594065546989441\n",
      "Iteration 190, Loss: 1.586543112352956e-05, Min w: 0.9276419878005981\n",
      "Iteration 200, Loss: 8.70412895892514e-06, Min w: 0.9505860209465027\n",
      "Iteration 210, Loss: 1.027736743708374e-05, Min w: 0.933705747127533\n",
      "Iteration 220, Loss: 1.2000899914710317e-05, Min w: 0.9348400831222534\n",
      "Iteration 230, Loss: 1.0795356502057984e-05, Min w: 0.9156687259674072\n",
      "Iteration 240, Loss: 1.2098079423594754e-05, Min w: 0.9307170510292053\n",
      "Iteration 250, Loss: 7.25233667253633e-06, Min w: 0.9402359127998352\n",
      "Iteration 260, Loss: 1.0484424819878768e-05, Min w: 0.9050353765487671\n",
      "Iteration 270, Loss: 6.688060693704756e-06, Min w: 0.9467145800590515\n",
      "Iteration 280, Loss: 1.3207502888690215e-05, Min w: 0.9485710859298706\n",
      "Iteration 290, Loss: 1.0265899618389085e-05, Min w: 0.9081950783729553\n",
      "Iteration 300, Loss: 1.4774195733480155e-05, Min w: 0.9071269631385803\n",
      "Iteration 310, Loss: 1.1038525371986907e-05, Min w: 0.9472890496253967\n",
      "Iteration 320, Loss: 5.961313036095817e-06, Min w: 0.9607560634613037\n",
      "Iteration 330, Loss: 1.1808789167844225e-05, Min w: 0.935989260673523\n",
      "Iteration 340, Loss: 9.12856739887502e-06, Min w: 0.9607893228530884\n",
      "Iteration 350, Loss: 1.3299503734742757e-05, Min w: 0.9220089912414551\n",
      "Iteration 360, Loss: 8.336109203810338e-06, Min w: 0.9415507912635803\n",
      "Iteration 370, Loss: 8.72746022650972e-06, Min w: 0.9095426201820374\n",
      "Iteration 380, Loss: 1.629592770768795e-05, Min w: 0.9112666845321655\n",
      "Iteration 390, Loss: 7.32524267732515e-06, Min w: 0.9266877770423889\n",
      "Iteration 400, Loss: 1.5489744328078814e-05, Min w: 0.9211462140083313\n",
      "Iteration 410, Loss: 1.4500998076982796e-05, Min w: 0.8954805135726929\n",
      "Iteration 420, Loss: 7.764890142425429e-06, Min w: 0.9275372624397278\n",
      "Iteration 430, Loss: 9.222304470313247e-06, Min w: 0.9412193894386292\n",
      "Iteration 440, Loss: 1.2730144590022974e-05, Min w: 0.9029097557067871\n",
      "Iteration 450, Loss: 1.0795162779686507e-05, Min w: 0.9258641004562378\n",
      "Iteration 460, Loss: 1.272344798053382e-05, Min w: 0.9247630834579468\n",
      "Iteration 470, Loss: 1.377074295305647e-05, Min w: 0.9160175919532776\n",
      "Iteration 480, Loss: 1.3602065337181557e-05, Min w: 0.8817170858383179\n",
      "Iteration 490, Loss: 7.807891961419955e-06, Min w: 0.9304918050765991\n",
      "Iteration 500, Loss: 1.0981681953126099e-05, Min w: 0.9104862809181213\n",
      "Iteration 510, Loss: 1.3381682947510853e-05, Min w: 0.9283967614173889\n",
      "Iteration 520, Loss: 1.2387646165734623e-05, Min w: 0.9256592988967896\n",
      "Iteration 530, Loss: 2.1009174815844744e-05, Min w: 0.9074786305427551\n",
      "Iteration 540, Loss: 1.87627174454974e-05, Min w: 0.882675051689148\n",
      "Iteration 550, Loss: 1.36340468088747e-05, Min w: 0.892022430896759\n",
      "Iteration 560, Loss: 2.5828030629782006e-05, Min w: 0.8086230158805847\n",
      "Iteration 570, Loss: 2.0399584172992036e-05, Min w: 0.8681945204734802\n",
      "Iteration 580, Loss: 5.3539490181719884e-05, Min w: 0.5793159008026123\n",
      "Iteration 590, Loss: 7.621367331012152e-06, Min w: 0.9522876739501953\n",
      "Iteration 600, Loss: 1.091288504539989e-05, Min w: 0.9034395813941956\n",
      "Iteration 610, Loss: 8.701719707460143e-06, Min w: 0.9024107456207275\n",
      "Iteration 620, Loss: 1.8597860616864637e-05, Min w: 0.8819289803504944\n",
      "Iteration 630, Loss: 1.0172408110520337e-05, Min w: 0.9211643934249878\n",
      "Iteration 640, Loss: 3.157690343869035e-06, Min w: 0.9763956069946289\n",
      "Iteration 650, Loss: 4.821296442969469e-06, Min w: 0.9656868577003479\n",
      "Iteration 660, Loss: 2.1400244349933928e-06, Min w: 0.9794238209724426\n",
      "Iteration 670, Loss: 1.2799765727322665e-06, Min w: 0.9868303537368774\n",
      "Iteration 680, Loss: 2.2422800611821003e-06, Min w: 0.9703555703163147\n",
      "Iteration 690, Loss: 1.1989978702331427e-05, Min w: 0.9210875630378723\n",
      "Iteration 700, Loss: 1.9904593955288874e-06, Min w: 0.9819756150245667\n",
      "Iteration 710, Loss: 8.077213351498358e-06, Min w: 0.916566789150238\n",
      "Iteration 720, Loss: 5.588033218373312e-06, Min w: 0.9475629329681396\n",
      "Iteration 730, Loss: 8.38946652947925e-06, Min w: 0.9418138265609741\n",
      "Iteration 740, Loss: 6.3262059484259225e-06, Min w: 0.9604584574699402\n",
      "Iteration 750, Loss: 3.851205747196218e-06, Min w: 0.9724224805831909\n",
      "Iteration 760, Loss: 1.4764312254555989e-05, Min w: 0.9252623319625854\n",
      "Iteration 770, Loss: 2.8409017431840766e-06, Min w: 0.9750810861587524\n",
      "Iteration 780, Loss: 1.6210909961955622e-05, Min w: 0.9133414030075073\n",
      "Iteration 790, Loss: 6.213634605956031e-06, Min w: 0.9669997692108154\n",
      "Iteration 800, Loss: 8.340013664565049e-06, Min w: 0.9463433027267456\n",
      "Iteration 810, Loss: 1.5230529243126512e-05, Min w: 0.9134266972541809\n",
      "Iteration 820, Loss: 5.905922535021091e-06, Min w: 0.9685879349708557\n",
      "Iteration 830, Loss: 1.0892680620600004e-05, Min w: 0.9160327911376953\n",
      "Iteration 840, Loss: 1.2130905815865844e-05, Min w: 0.9404598474502563\n",
      "Iteration 850, Loss: 1.1423593605286442e-05, Min w: 0.9033812284469604\n",
      "Iteration 860, Loss: 1.0741430742200464e-05, Min w: 0.9145762324333191\n",
      "Iteration 870, Loss: 3.844436832878273e-06, Min w: 0.9692880511283875\n",
      "Iteration 880, Loss: 8.029909622564446e-06, Min w: 0.9465452432632446\n",
      "Iteration 890, Loss: 8.70292387844529e-06, Min w: 0.9445161819458008\n",
      "Iteration 900, Loss: 1.1214638107048813e-05, Min w: 0.8802987933158875\n",
      "Iteration 910, Loss: 7.653210559510626e-06, Min w: 0.9457736611366272\n",
      "Iteration 920, Loss: 5.490415787789971e-06, Min w: 0.9663389921188354\n",
      "Iteration 930, Loss: 1.4729267604707275e-05, Min w: 0.9255691766738892\n",
      "Iteration 940, Loss: 1.5326291759265587e-05, Min w: 0.8393439054489136\n",
      "Iteration 950, Loss: 0.0001423284411430359, Min w: 0.288893461227417\n",
      "Iteration 960, Loss: 0.0002018320665229112, Min w: 1.2805626283807214e-05\n",
      "Iteration 970, Loss: 0.00023388017143588513, Min w: 8.121029182461825e-09\n",
      "Iteration 980, Loss: 0.00025782969896681607, Min w: 3.921915681104338e-09\n",
      "Iteration 990, Loss: 0.00026402552612125874, Min w: 0.0\n",
      "Iteration 1000, Loss: 0.00030108087230473757, Min w: 8.057720489046251e-32\n",
      "Iteration 1010, Loss: 0.0004009165277238935, Min w: 0.0\n",
      "Iteration 1020, Loss: 0.00035706491325981915, Min w: 5.3809861030072976e-43\n",
      "Iteration 1030, Loss: 0.00031868385849520564, Min w: 1.9411493983886196e-23\n",
      "Iteration 1040, Loss: 0.00035022853990085423, Min w: 0.0\n",
      "Iteration 1050, Loss: 0.00033466031891293824, Min w: 3.833392702314902e-22\n",
      "Iteration 1060, Loss: 0.0003052831452805549, Min w: 2.7148269784271202e-33\n",
      "Iteration 1070, Loss: 0.0003115838044323027, Min w: 0.0\n",
      "Iteration 1080, Loss: 0.00022356565750669688, Min w: 0.0\n",
      "Iteration 1090, Loss: 0.00030988347134552896, Min w: 9.667857198521138e-37\n",
      "Iteration 1100, Loss: 0.0003110664547421038, Min w: 8.926593323577211e-35\n",
      "Iteration 1110, Loss: 0.00025275841471739113, Min w: 0.0065641761757433414\n",
      "Iteration 1120, Loss: 0.00017524385475553572, Min w: 0.0\n",
      "Iteration 1130, Loss: 8.611098019173369e-05, Min w: 1.6603300423412293e-07\n",
      "Iteration 1140, Loss: 6.895472324686125e-05, Min w: 5.1348840547061665e-33\n",
      "Iteration 1150, Loss: 4.873623402090743e-05, Min w: 7.855603030293423e-07\n",
      "Iteration 1160, Loss: 1.7568605471751653e-05, Min w: 0.7749664187431335\n",
      "Iteration 1170, Loss: 1.0863912393688224e-05, Min w: 0.9125814437866211\n",
      "Iteration 1180, Loss: 1.7801950889406726e-05, Min w: 0.7097787261009216\n",
      "Iteration 1190, Loss: 5.256724762148224e-06, Min w: 0.9417861700057983\n",
      "Iteration 1200, Loss: 2.2201436422619736e-06, Min w: 0.9792980551719666\n",
      "Iteration 1210, Loss: 2.0254858554835664e-06, Min w: 0.9770209193229675\n",
      "Iteration 1220, Loss: 1.4079736274652532e-06, Min w: 0.983612060546875\n",
      "Iteration 1230, Loss: 8.714393402442511e-07, Min w: 0.9902763962745667\n",
      "Early break at iteration 1230 --------------------------------\n",
      "Iteration 0, Loss: 1.2159603102190886e-06, Min w: 0.9844399094581604\n",
      "Iteration 10, Loss: 9.224453378919861e-07, Min w: 0.9889957308769226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  83%|████████▎ | 20/24 [13:06<05:10, 77.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Loss: 8.583177759646787e-07, Min w: 0.9896674752235413\n",
      "Early break at iteration 21 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 5003, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.001245776708544134, 'L2_avg': 0.002296191721202757, 'End_point_L1_avg': 0.0010329202197986386, 'End_point_L2_avg': 0.0012855510006927894}\n",
      "Iteration 0, Loss: 0.0017423124518245459, Min w: 2.2420775429197073e-44\n",
      "Iteration 10, Loss: 0.0009706409182399511, Min w: 4.2967810892283317e-16\n",
      "Iteration 20, Loss: 0.0007560577942058444, Min w: 0.03904998302459717\n",
      "Iteration 30, Loss: 0.0004941155202686787, Min w: 0.36621788144111633\n",
      "Iteration 40, Loss: 0.00044293171958997846, Min w: 0.4859475791454315\n",
      "Iteration 50, Loss: 0.00032963522244244814, Min w: 0.6049907207489014\n",
      "Iteration 60, Loss: 0.00023692863760516047, Min w: 0.6702443361282349\n",
      "Iteration 70, Loss: 0.00019473896827548742, Min w: 0.7179564833641052\n",
      "Iteration 80, Loss: 0.00016926773241721094, Min w: 0.7408201098442078\n",
      "Iteration 90, Loss: 0.00012793607311323285, Min w: 0.7908697724342346\n",
      "Iteration 100, Loss: 0.00011668780643958598, Min w: 0.814602255821228\n",
      "Iteration 110, Loss: 0.00010950784053420648, Min w: 0.8314114809036255\n",
      "Iteration 120, Loss: 0.00010370856762165204, Min w: 0.8503912687301636\n",
      "Iteration 130, Loss: 9.425949247088283e-05, Min w: 0.8509882092475891\n",
      "Iteration 140, Loss: 7.27962251403369e-05, Min w: 0.8899003863334656\n",
      "Iteration 150, Loss: 5.559407145483419e-05, Min w: 0.9077368378639221\n",
      "Iteration 160, Loss: 4.940604412695393e-05, Min w: 0.9198625683784485\n",
      "Iteration 170, Loss: 4.289214120944962e-05, Min w: 0.9321936964988708\n",
      "Iteration 180, Loss: 4.3758682295447215e-05, Min w: 0.9181817173957825\n",
      "Iteration 190, Loss: 3.631604340625927e-05, Min w: 0.9382725358009338\n",
      "Iteration 200, Loss: 2.914705328294076e-05, Min w: 0.9486718773841858\n",
      "Iteration 210, Loss: 2.508487341401633e-05, Min w: 0.9600182771682739\n",
      "Iteration 220, Loss: 1.8582242773845792e-05, Min w: 0.9704090356826782\n",
      "Iteration 230, Loss: 2.6963152777170762e-05, Min w: 0.9427587389945984\n",
      "Iteration 240, Loss: 1.9520257410476916e-05, Min w: 0.9653204083442688\n",
      "Iteration 250, Loss: 1.6031199265853502e-05, Min w: 0.9683177471160889\n",
      "Iteration 260, Loss: 1.3736836081079673e-05, Min w: 0.975397527217865\n",
      "Iteration 270, Loss: 1.1429355254222173e-05, Min w: 0.9798208475112915\n",
      "Iteration 280, Loss: 1.084667928807903e-05, Min w: 0.9812041521072388\n",
      "Iteration 290, Loss: 1.3973134628031403e-05, Min w: 0.9708810448646545\n",
      "Iteration 300, Loss: 9.08381389308488e-06, Min w: 0.9845669865608215\n",
      "Iteration 310, Loss: 9.769037205842324e-06, Min w: 0.9812396168708801\n",
      "Iteration 320, Loss: 1.312796666752547e-05, Min w: 0.9733850359916687\n",
      "Early break at iteration 326 --------------------------------\n",
      "Iteration 0, Loss: 9.9874050647486e-06, Min w: 0.9787368178367615\n",
      "Iteration 10, Loss: 6.798876711400226e-06, Min w: 0.9877061247825623\n",
      "Iteration 20, Loss: 7.940595423860941e-06, Min w: 0.9878768920898438\n",
      "Early break at iteration 21 --------------------------------\n",
      "Iteration 0, Loss: 7.810718670953065e-06, Min w: 0.9853094816207886\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 7.5084517447976395e-06, Min w: 0.9863991737365723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  88%|████████▊ | 21/24 [13:12<02:49, 56.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 6.006660896673566e-06, Min w: 0.9897761940956116\n",
      "Early break at iteration 2 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 366, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0030709002679077282, 'L2_avg': 0.00452058514158179, 'End_point_L1_avg': 0.00236370347699745, 'End_point_L2_avg': 0.0037191901706881258}\n",
      "Iteration 0, Loss: 0.0018575069261714816, Min w: 4.020869838731137e-38\n",
      "Iteration 10, Loss: 0.001143518602475524, Min w: 1.1761857153925852e-16\n",
      "Iteration 20, Loss: 0.0008612714591436088, Min w: 0.001750124734826386\n",
      "Iteration 30, Loss: 0.0006489072693511844, Min w: 0.20436438918113708\n",
      "Iteration 40, Loss: 0.00045272306306287646, Min w: 0.5360522866249084\n",
      "Iteration 50, Loss: 0.000364254810847342, Min w: 0.6001728773117065\n",
      "Iteration 60, Loss: 0.0002465592115186155, Min w: 0.6806423664093018\n",
      "Iteration 70, Loss: 0.00023945499560795724, Min w: 0.6988447904586792\n",
      "Iteration 80, Loss: 0.00022464546782430261, Min w: 0.7028498649597168\n",
      "Iteration 90, Loss: 0.0001483109372202307, Min w: 0.7822615504264832\n",
      "Iteration 100, Loss: 0.00014884021948091686, Min w: 0.7883977890014648\n",
      "Iteration 110, Loss: 0.000151550309965387, Min w: 0.7810808420181274\n",
      "Iteration 120, Loss: 0.00011706002260325477, Min w: 0.8249282836914062\n",
      "Iteration 130, Loss: 0.00010442484199302271, Min w: 0.8345471620559692\n",
      "Iteration 140, Loss: 9.792151104193181e-05, Min w: 0.8377079367637634\n",
      "Iteration 150, Loss: 8.864595292834565e-05, Min w: 0.8522304892539978\n",
      "Iteration 160, Loss: 9.052263339981437e-05, Min w: 0.8447356820106506\n",
      "Iteration 170, Loss: 6.322174886008725e-05, Min w: 0.8915558457374573\n",
      "Iteration 180, Loss: 5.390262231230736e-05, Min w: 0.9056400060653687\n",
      "Iteration 190, Loss: 5.658162262989208e-05, Min w: 0.8989779353141785\n",
      "Iteration 200, Loss: 4.8529454943491146e-05, Min w: 0.9153146147727966\n",
      "Iteration 210, Loss: 4.906732283416204e-05, Min w: 0.9044496417045593\n",
      "Iteration 220, Loss: 5.095186861581169e-05, Min w: 0.9123528003692627\n",
      "Iteration 230, Loss: 4.878091931459494e-05, Min w: 0.9098657369613647\n",
      "Iteration 240, Loss: 4.496939800446853e-05, Min w: 0.9162850379943848\n",
      "Iteration 250, Loss: 2.3613534722244367e-05, Min w: 0.9551182389259338\n",
      "Iteration 260, Loss: 2.3687349312240258e-05, Min w: 0.9523158669471741\n",
      "Iteration 270, Loss: 2.3741620680084452e-05, Min w: 0.9577999114990234\n",
      "Iteration 280, Loss: 2.9469414585037157e-05, Min w: 0.9462043046951294\n",
      "Iteration 290, Loss: 3.815906893578358e-05, Min w: 0.9256224036216736\n",
      "Iteration 300, Loss: 4.1737028368515894e-05, Min w: 0.9209948778152466\n",
      "Iteration 310, Loss: 3.35452969011385e-05, Min w: 0.9376305937767029\n",
      "Iteration 320, Loss: 2.1470634237630293e-05, Min w: 0.9606410264968872\n",
      "Iteration 330, Loss: 9.919745934894308e-06, Min w: 0.9838240146636963\n",
      "Iteration 340, Loss: 2.3756712835165672e-05, Min w: 0.9577891826629639\n",
      "Iteration 350, Loss: 1.4267116966948379e-05, Min w: 0.9764048457145691\n",
      "Iteration 360, Loss: 1.767863614077214e-05, Min w: 0.9664231538772583\n",
      "Iteration 370, Loss: 1.2982869520783424e-05, Min w: 0.9785698056221008\n",
      "Iteration 380, Loss: 1.4628576536779292e-05, Min w: 0.9751289486885071\n",
      "Iteration 390, Loss: 2.0703371774288826e-05, Min w: 0.9657987952232361\n",
      "Iteration 400, Loss: 1.7750780898495577e-05, Min w: 0.971545934677124\n",
      "Iteration 410, Loss: 2.0542953279800713e-05, Min w: 0.965903103351593\n",
      "Iteration 420, Loss: 1.2863425581599586e-05, Min w: 0.9788517951965332\n",
      "Iteration 430, Loss: 2.0194365788483992e-05, Min w: 0.9675150513648987\n",
      "Early break at iteration 434 --------------------------------\n",
      "Iteration 0, Loss: 1.5098043149919249e-05, Min w: 0.9782346487045288\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.2813183275284246e-05, Min w: 0.9808967709541321\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 8.5650372056989e-06, Min w: 0.9882130026817322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  92%|█████████▏| 22/24 [13:21<01:24, 42.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: 1.4219629520084709e-05, Min w: 0.9775252938270569\n",
      "Early break at iteration 15 --------------------------------\n",
      "Iteration 0, Loss: 6.953995125513757e-06, Min w: 0.9913627505302429\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 456, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.0037177791165455597, 'L2_avg': 0.005431160346634921, 'End_point_L1_avg': 0.0025690126267511482, 'End_point_L2_avg': 0.0038098581514005147}\n",
      "Iteration 0, Loss: 0.0005859366501681507, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00044900045031681657, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0003659795329440385, Min w: 3.123493742468731e-34\n",
      "Iteration 30, Loss: 0.0002679808530956507, Min w: 0.08685271441936493\n",
      "Iteration 40, Loss: 0.00021006344468332827, Min w: 0.20543263852596283\n",
      "Iteration 50, Loss: 0.000165485791512765, Min w: 0.3355831801891327\n",
      "Iteration 60, Loss: 0.00012466996849980205, Min w: 0.4310314953327179\n",
      "Iteration 70, Loss: 0.00010368112998548895, Min w: 0.46373993158340454\n",
      "Iteration 80, Loss: 9.316672367276624e-05, Min w: 0.4824249744415283\n",
      "Iteration 90, Loss: 8.199927833629772e-05, Min w: 0.5252712965011597\n",
      "Iteration 100, Loss: 7.572778122266755e-05, Min w: 0.5121974945068359\n",
      "Iteration 110, Loss: 6.768511957488954e-05, Min w: 0.5270837545394897\n",
      "Iteration 120, Loss: 6.145338556962088e-05, Min w: 0.5522304773330688\n",
      "Iteration 130, Loss: 5.3374595154309645e-05, Min w: 0.5877882838249207\n",
      "Iteration 140, Loss: 4.8765152314445004e-05, Min w: 0.6199073195457458\n",
      "Iteration 150, Loss: 4.481566065805964e-05, Min w: 0.6241640448570251\n",
      "Iteration 160, Loss: 3.986981391790323e-05, Min w: 0.6640270352363586\n",
      "Iteration 170, Loss: 3.6494438973022625e-05, Min w: 0.6810781359672546\n",
      "Iteration 180, Loss: 2.9836606699973345e-05, Min w: 0.7546617984771729\n",
      "Iteration 190, Loss: 2.5351342628709972e-05, Min w: 0.7825969457626343\n",
      "Iteration 200, Loss: 2.4909628336899914e-05, Min w: 0.7704535722732544\n",
      "Iteration 210, Loss: 2.394982766418252e-05, Min w: 0.7758293747901917\n",
      "Iteration 220, Loss: 2.0730627511511557e-05, Min w: 0.8013445734977722\n",
      "Iteration 230, Loss: 1.8356455257162452e-05, Min w: 0.8299962878227234\n",
      "Iteration 240, Loss: 1.6974458048935048e-05, Min w: 0.8348550200462341\n",
      "Iteration 250, Loss: 1.4648567230324261e-05, Min w: 0.865947425365448\n",
      "Iteration 260, Loss: 1.468202390242368e-05, Min w: 0.8536340594291687\n",
      "Iteration 270, Loss: 1.2588230674737133e-05, Min w: 0.8809639811515808\n",
      "Iteration 280, Loss: 1.2810041880584322e-05, Min w: 0.8729135394096375\n",
      "Iteration 290, Loss: 1.0177341209782753e-05, Min w: 0.90556401014328\n",
      "Iteration 300, Loss: 1.006742604658939e-05, Min w: 0.903704047203064\n",
      "Iteration 310, Loss: 9.681968549557496e-06, Min w: 0.9060642123222351\n",
      "Iteration 320, Loss: 7.277330041688401e-06, Min w: 0.9414193630218506\n",
      "Iteration 330, Loss: 9.094955203181598e-06, Min w: 0.9110807776451111\n",
      "Iteration 340, Loss: 6.627782113355352e-06, Min w: 0.9454911947250366\n",
      "Iteration 350, Loss: 7.705649295530748e-06, Min w: 0.9225137829780579\n",
      "Iteration 360, Loss: 5.52716619495186e-06, Min w: 0.9557340145111084\n",
      "Iteration 370, Loss: 5.695210802514339e-06, Min w: 0.9505123496055603\n",
      "Iteration 380, Loss: 5.123740720591741e-06, Min w: 0.9591609239578247\n",
      "Iteration 390, Loss: 4.657572844735114e-06, Min w: 0.9652314782142639\n",
      "Iteration 400, Loss: 4.656287728721509e-06, Min w: 0.9643325805664062\n",
      "Iteration 410, Loss: 4.644422006094828e-06, Min w: 0.961663544178009\n",
      "Iteration 420, Loss: 4.539310339168878e-06, Min w: 0.9640535712242126\n",
      "Iteration 430, Loss: 4.094375526619842e-06, Min w: 0.9695284962654114\n",
      "Iteration 440, Loss: 3.745446747416281e-06, Min w: 0.9727957844734192\n",
      "Iteration 450, Loss: 3.6186941088089952e-06, Min w: 0.9751341938972473\n",
      "Iteration 460, Loss: 4.310459189582616e-06, Min w: 0.9660494923591614\n",
      "Iteration 470, Loss: 3.0014182357263053e-06, Min w: 0.9821072816848755\n",
      "Iteration 480, Loss: 3.1320907964982325e-06, Min w: 0.9791752099990845\n",
      "Iteration 490, Loss: 3.5200514503230806e-06, Min w: 0.9739667773246765\n",
      "Iteration 500, Loss: 2.4746329927438637e-06, Min w: 0.9872781038284302\n",
      "Iteration 510, Loss: 2.5938547878467944e-06, Min w: 0.9872732162475586\n",
      "Iteration 520, Loss: 3.1624140319763683e-06, Min w: 0.9770809412002563\n",
      "Iteration 530, Loss: 2.58367731476028e-06, Min w: 0.986601710319519\n",
      "Iteration 540, Loss: 2.4653406853758497e-06, Min w: 0.9872403144836426\n",
      "Iteration 550, Loss: 2.693669102882268e-06, Min w: 0.9826922416687012\n",
      "Iteration 560, Loss: 2.348408315810957e-06, Min w: 0.9877489805221558\n",
      "Iteration 570, Loss: 2.584204821687308e-06, Min w: 0.9851844310760498\n",
      "Iteration 580, Loss: 2.353034005864174e-06, Min w: 0.9864965081214905\n",
      "Iteration 590, Loss: 2.169428171328036e-06, Min w: 0.9887073040008545\n",
      "Iteration 600, Loss: 2.330685447304859e-06, Min w: 0.9882404804229736\n",
      "Early break at iteration 609 --------------------------------\n",
      "Iteration 0, Loss: 2.1015571292082313e-06, Min w: 0.9892336130142212\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 2.032221800618572e-06, Min w: 0.9905445575714111\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 2.3700408746663015e-06, Min w: 0.9837111830711365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP:  96%|█████████▌| 23/24 [13:41<00:35, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 1.923139961945708e-06, Min w: 0.9903202652931213\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 618, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.003108482060204492, 'L2_avg': 0.00432393338682803, 'End_point_L1_avg': 0.002011216963147446, 'End_point_L2_avg': 0.0029871815886230906}\n",
      "Iteration 0, Loss: 0.0005632039974443614, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00048749276902526617, Min w: 0.0\n",
      "Iteration 20, Loss: 0.00038699028664268553, Min w: 0.0\n",
      "Iteration 30, Loss: 0.0002877899678424001, Min w: 0.0\n",
      "Iteration 40, Loss: 0.00022050386178307235, Min w: 0.04081759601831436\n",
      "Iteration 50, Loss: 0.00016994259203784168, Min w: 0.1124168336391449\n",
      "Iteration 60, Loss: 0.00012936437269672751, Min w: 0.33084943890571594\n",
      "Iteration 70, Loss: 9.388558828504756e-05, Min w: 0.6052716374397278\n",
      "Iteration 80, Loss: 8.355698810191825e-05, Min w: 0.673309862613678\n",
      "Iteration 90, Loss: 7.127945718821138e-05, Min w: 0.7220624685287476\n",
      "Iteration 100, Loss: 6.115239375503734e-05, Min w: 0.755786657333374\n",
      "Iteration 110, Loss: 5.202878674026579e-05, Min w: 0.7905937433242798\n",
      "Iteration 120, Loss: 4.557957436190918e-05, Min w: 0.8091095685958862\n",
      "Iteration 130, Loss: 4.1743431211216375e-05, Min w: 0.8178867697715759\n",
      "Iteration 140, Loss: 3.6471836210694164e-05, Min w: 0.8379243016242981\n",
      "Iteration 150, Loss: 3.2026295230025426e-05, Min w: 0.8559865951538086\n",
      "Iteration 160, Loss: 2.9341263143578544e-05, Min w: 0.8654634356498718\n",
      "Iteration 170, Loss: 2.721107375691645e-05, Min w: 0.8679406642913818\n",
      "Iteration 180, Loss: 2.428001789667178e-05, Min w: 0.883476197719574\n",
      "Iteration 190, Loss: 1.9519857232808135e-05, Min w: 0.9134535789489746\n",
      "Iteration 200, Loss: 1.724673347780481e-05, Min w: 0.9241312146186829\n",
      "Iteration 210, Loss: 1.61083517014049e-05, Min w: 0.9278977513313293\n",
      "Iteration 220, Loss: 1.3992255844641477e-05, Min w: 0.9368324279785156\n",
      "Iteration 230, Loss: 1.233503735420527e-05, Min w: 0.9421550631523132\n",
      "Iteration 240, Loss: 1.1519940017024055e-05, Min w: 0.9440842866897583\n",
      "Iteration 250, Loss: 1.0021897651313338e-05, Min w: 0.9533360004425049\n",
      "Iteration 260, Loss: 9.73873829934746e-06, Min w: 0.9541005492210388\n",
      "Iteration 270, Loss: 8.350692951353267e-06, Min w: 0.9598245620727539\n",
      "Iteration 280, Loss: 7.5896277849096805e-06, Min w: 0.9627808332443237\n",
      "Iteration 290, Loss: 6.588231826754054e-06, Min w: 0.9673234224319458\n",
      "Iteration 300, Loss: 6.084311735321535e-06, Min w: 0.970442533493042\n",
      "Iteration 310, Loss: 5.5424216043320484e-06, Min w: 0.9739049077033997\n",
      "Iteration 320, Loss: 5.011122993892059e-06, Min w: 0.9755507111549377\n",
      "Iteration 330, Loss: 4.694799372373382e-06, Min w: 0.9783862233161926\n",
      "Iteration 340, Loss: 4.124029601371149e-06, Min w: 0.9782058000564575\n",
      "Iteration 350, Loss: 4.089372396265389e-06, Min w: 0.9810224175453186\n",
      "Iteration 360, Loss: 3.846891104331007e-06, Min w: 0.9824981689453125\n",
      "Iteration 370, Loss: 3.1820313779462595e-06, Min w: 0.983561635017395\n",
      "Iteration 380, Loss: 3.1865447454038076e-06, Min w: 0.9839761257171631\n",
      "Iteration 390, Loss: 3.158323352181469e-06, Min w: 0.9857496619224548\n",
      "Iteration 400, Loss: 2.9840853130735923e-06, Min w: 0.9860489964485168\n",
      "Iteration 410, Loss: 2.8853189633082366e-06, Min w: 0.987852931022644\n",
      "Iteration 420, Loss: 2.9396137506410014e-06, Min w: 0.9884989261627197\n",
      "Iteration 430, Loss: 2.397140860921354e-06, Min w: 0.9885260462760925\n",
      "Iteration 440, Loss: 2.3474970021197805e-06, Min w: 0.9889237880706787\n",
      "Early break at iteration 442 --------------------------------\n",
      "Iteration 0, Loss: 2.12573377211811e-06, Min w: 0.9896482825279236\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 2.4411767753917957e-06, Min w: 0.989251434803009\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 2.3476113710785285e-06, Min w: 0.9893340468406677\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.9663279999804217e-06, Min w: 0.9905309677124023\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN new architecture MLP: 100%|██████████| 24/24 [13:55<00:00, 34.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN new architecture MLP', 'Total_Iterations': 456, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0033049898031476416, 'L2_avg': 0.005077521127238872, 'End_point_L1_avg': 0.0019146281929851322, 'End_point_L2_avg': 0.0027361198241005863}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.0015041206497699022, Min w: 1.457775198332456e-07\n",
      "Iteration 10, Loss: 0.0007883452926762402, Min w: 2.8446017243111132e-12\n",
      "Iteration 20, Loss: 0.0005601323209702969, Min w: 0.008623297326266766\n",
      "Iteration 30, Loss: 0.0002755429013632238, Min w: 0.5407583117485046\n",
      "Iteration 40, Loss: 7.281739090103656e-05, Min w: 0.8447179198265076\n",
      "Iteration 50, Loss: 3.0032470021978952e-05, Min w: 0.9645656943321228\n",
      "Iteration 60, Loss: 1.897589572763536e-05, Min w: 0.972190260887146\n",
      "Early break at iteration 66 --------------------------------\n",
      "Iteration 0, Loss: 9.917541319737211e-06, Min w: 0.9862827658653259\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 8.526612873538397e-06, Min w: 0.9884355068206787\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 5.6407998272334225e-06, Min w: 0.993401825428009\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 5.465845788421575e-06, Min w: 0.9941467046737671\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   4%|▍         | 1/24 [00:00<00:16,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 75, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.006289263629205216, 'L2_avg': 0.007179218332699246, 'End_point_L1_avg': 0.007155530659105311, 'End_point_L2_avg': 0.010205482321616811}\n",
      "Iteration 0, Loss: 0.0015983761986717582, Min w: 2.5011203774738533e-07\n",
      "Iteration 10, Loss: 0.0007924357778392732, Min w: 0.020303618162870407\n",
      "Iteration 20, Loss: 0.0004995813360437751, Min w: 0.0015866790199652314\n",
      "Iteration 30, Loss: 0.000352242001099512, Min w: 0.4062754809856415\n",
      "Iteration 40, Loss: 0.00019775886903516948, Min w: 0.6602129936218262\n",
      "Iteration 50, Loss: 6.419089186238125e-05, Min w: 0.8508339524269104\n",
      "Iteration 60, Loss: 3.697261490742676e-05, Min w: 0.9419397711753845\n",
      "Iteration 70, Loss: 1.120640263252426e-05, Min w: 0.9853238463401794\n",
      "Iteration 80, Loss: 1.580444586579688e-05, Min w: 0.9563118815422058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:   8%|▊         | 2/24 [00:01<00:18,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 89 --------------------------------\n",
      "Iteration 0, Loss: 3.910704435838852e-06, Min w: 0.9938374757766724\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 8.281315786007326e-06, Min w: 0.9737253189086914\n",
      "Early break at iteration 6 --------------------------------\n",
      "Iteration 0, Loss: 3.033715529454639e-06, Min w: 0.9951657056808472\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.6051450226514135e-06, Min w: 0.989318311214447\n",
      "Early break at iteration 7 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 107, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.003769265355267756, 'L2_avg': 0.004472575343320733, 'End_point_L1_avg': 0.003131782511207719, 'End_point_L2_avg': 0.003695272333613024}\n",
      "Iteration 0, Loss: 0.00046733615454286337, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00044068231363780797, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0003998278989456594, Min w: 0.0\n",
      "Iteration 30, Loss: 0.000359206460416317, Min w: 0.0\n",
      "Iteration 40, Loss: 0.0003769107279367745, Min w: 0.0\n",
      "Iteration 50, Loss: 0.0003550434485077858, Min w: 0.0\n",
      "Iteration 60, Loss: 0.0003310574102215469, Min w: 0.0\n",
      "Iteration 70, Loss: 0.000277013867162168, Min w: 2.4498338290327504e-35\n",
      "Iteration 80, Loss: 0.0002465801371727139, Min w: 2.4609696004067206e-36\n",
      "Iteration 90, Loss: 0.00017991286586038768, Min w: 0.0281894002109766\n",
      "Iteration 100, Loss: 0.0001181360348709859, Min w: 0.11874686926603317\n",
      "Iteration 110, Loss: 0.00011876989447046071, Min w: 0.23675289750099182\n",
      "Iteration 120, Loss: 5.876427167095244e-05, Min w: 0.05183343216776848\n",
      "Iteration 130, Loss: 5.539776975638233e-05, Min w: 0.6859668493270874\n",
      "Iteration 140, Loss: 2.930468508566264e-05, Min w: 0.7781417369842529\n",
      "Iteration 150, Loss: 1.0655644473445136e-05, Min w: 0.9305747747421265\n",
      "Iteration 160, Loss: 1.1737800377886742e-05, Min w: 0.9307020306587219\n",
      "Iteration 170, Loss: 3.8074269923527027e-06, Min w: 0.9472062587738037\n",
      "Iteration 180, Loss: 3.2552675293118227e-06, Min w: 0.973861038684845\n",
      "Early break at iteration 187 --------------------------------\n",
      "Iteration 0, Loss: 1.7345030300930375e-06, Min w: 0.9859597086906433\n",
      "Iteration 10, Loss: 6.758890776836779e-06, Min w: 0.9228201508522034\n",
      "Early break at iteration 15 --------------------------------\n",
      "Iteration 0, Loss: 1.0465568038853235e-06, Min w: 0.9930216073989868\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.0263337344440515e-06, Min w: 0.9933849573135376\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 9.131563842856849e-07, Min w: 0.9942426681518555\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  12%|█▎        | 3/24 [00:03<00:29,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 207, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0026780629451458224, 'L2_avg': 0.0037326731030513515, 'End_point_L1_avg': 0.0020016837744930775, 'End_point_L2_avg': 0.0026854865884159756}\n",
      "Iteration 0, Loss: 0.00044055964099243283, Min w: 0.0\n",
      "Iteration 10, Loss: 0.00041856037569232285, Min w: 0.0\n",
      "Iteration 20, Loss: 0.0003247206623200327, Min w: 1.4113692263095872e-27\n",
      "Iteration 30, Loss: 0.00023299857275560498, Min w: 0.0\n",
      "Iteration 40, Loss: 0.00019109809363726526, Min w: 3.5032461608120427e-44\n",
      "Iteration 50, Loss: 0.00015437482215929776, Min w: 8.749965812397754e-27\n",
      "Iteration 60, Loss: 0.0001265965838683769, Min w: 5.017206349174549e-22\n",
      "Iteration 70, Loss: 0.00012883012823294848, Min w: 2.1053867877611834e-15\n",
      "Iteration 80, Loss: 0.00010837217268999666, Min w: 0.19271138310432434\n",
      "Iteration 90, Loss: 4.5057266106596217e-05, Min w: 0.4065917134284973\n",
      "Iteration 100, Loss: 0.00014731206465512514, Min w: 0.1657198667526245\n",
      "Iteration 110, Loss: 9.470318036619574e-05, Min w: 0.38342320919036865\n",
      "Iteration 120, Loss: 3.843650847557001e-05, Min w: 0.6967028975486755\n",
      "Iteration 130, Loss: 1.6972888261079788e-05, Min w: 0.8397988080978394\n",
      "Iteration 140, Loss: 7.845756044844165e-06, Min w: 0.9519787430763245\n",
      "Iteration 150, Loss: 7.067353180900682e-06, Min w: 0.9536743760108948\n",
      "Iteration 160, Loss: 9.66200514085358e-06, Min w: 0.8332290649414062\n",
      "Iteration 170, Loss: 4.584470843838062e-06, Min w: 0.928951621055603\n",
      "Iteration 180, Loss: 7.021411875030026e-06, Min w: 0.9013311862945557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  17%|█▋        | 4/24 [00:05<00:31,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 190, Loss: 1.2659294270633836e-06, Min w: 0.9875216484069824\n",
      "Early break at iteration 191 --------------------------------\n",
      "Iteration 0, Loss: 1.0398081258244929e-06, Min w: 0.9932224154472351\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 9.131385354521626e-07, Min w: 0.9944072365760803\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 9.718307865114184e-07, Min w: 0.9929477572441101\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.1199184655197314e-06, Min w: 0.9903920292854309\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 196, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0031212107787682987, 'L2_avg': 0.004086055641114545, 'End_point_L1_avg': 0.0022422072753103947, 'End_point_L2_avg': 0.0028302654852293305}\n",
      "Iteration 0, Loss: 0.0012153186835348606, Min w: 1.030155306016412e-21\n",
      "Iteration 10, Loss: 0.0005405962001532316, Min w: 0.06081752851605415\n",
      "Iteration 20, Loss: 0.0003277497598901391, Min w: 0.524228036403656\n",
      "Iteration 30, Loss: 0.0002053998177871108, Min w: 0.637107253074646\n",
      "Iteration 40, Loss: 0.00014765986998099834, Min w: 0.7443253993988037\n",
      "Iteration 50, Loss: 8.350668213097379e-05, Min w: 0.805357813835144\n",
      "Iteration 60, Loss: 5.693710772902705e-05, Min w: 0.8660025596618652\n",
      "Iteration 70, Loss: 3.691658275783993e-05, Min w: 0.9122706651687622\n",
      "Iteration 80, Loss: 2.059725738945417e-05, Min w: 0.9492727518081665\n",
      "Iteration 90, Loss: 1.2611161764652934e-05, Min w: 0.971950888633728\n",
      "Iteration 100, Loss: 8.395672011829447e-06, Min w: 0.9849691390991211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  21%|██        | 5/24 [00:06<00:26,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110, Loss: 8.26723135105567e-06, Min w: 0.9845268726348877\n",
      "Early break at iteration 111 --------------------------------\n",
      "Iteration 0, Loss: 4.9513805606693495e-06, Min w: 0.9915680289268494\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 6.405638941942016e-06, Min w: 0.9886150360107422\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 4.497700501815416e-06, Min w: 0.9925781488418579\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.934178494091611e-06, Min w: 0.9931296110153198\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 119, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.0028795089067048434, 'L2_avg': 0.004085565078740801, 'End_point_L1_avg': 0.002395986360327779, 'End_point_L2_avg': 0.0036991130054260983}\n",
      "Iteration 0, Loss: 0.0015875202370807528, Min w: 2.410084505299892e-07\n",
      "Iteration 10, Loss: 0.0006916947313584387, Min w: 0.3771454393863678\n",
      "Iteration 20, Loss: 0.0004033513250760734, Min w: 0.5220966935157776\n",
      "Iteration 30, Loss: 0.00026478266227059066, Min w: 0.619523286819458\n",
      "Iteration 40, Loss: 0.0001724816975183785, Min w: 0.7064949870109558\n",
      "Iteration 50, Loss: 0.00011492757039377466, Min w: 0.7745524644851685\n",
      "Iteration 60, Loss: 6.1974540585652e-05, Min w: 0.8748598694801331\n",
      "Iteration 70, Loss: 3.5327360819792375e-05, Min w: 0.9259403944015503\n",
      "Iteration 80, Loss: 3.451617885730229e-05, Min w: 0.9131116271018982\n",
      "Iteration 90, Loss: 1.3960384421807248e-05, Min w: 0.9734469652175903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  25%|██▌       | 6/24 [00:07<00:22,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Loss: 1.003903253149474e-05, Min w: 0.979722261428833\n",
      "Early break at iteration 101 --------------------------------\n",
      "Iteration 0, Loss: 8.798270755505655e-06, Min w: 0.9834268093109131\n",
      "Early break at iteration 4 --------------------------------\n",
      "Iteration 0, Loss: 6.080317234591348e-06, Min w: 0.989732563495636\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 2.90863863483537e-06, Min w: 0.9965617060661316\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.7830661767657148e-06, Min w: 0.994441568851471\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 111, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.002484544710898703, 'L2_avg': 0.004105237504338407, 'End_point_L1_avg': 0.0016360499524863121, 'End_point_L2_avg': 0.0022554942618693056}\n",
      "Iteration 0, Loss: 0.0004377966688480228, Min w: 1.1911036946760945e-42\n",
      "Iteration 10, Loss: 0.00026391271967440844, Min w: 6.1574152894483536e-12\n",
      "Iteration 20, Loss: 0.00014890021702740341, Min w: 0.19298213720321655\n",
      "Iteration 30, Loss: 8.985275053419173e-05, Min w: 0.5675773620605469\n",
      "Iteration 40, Loss: 6.59984361846e-05, Min w: 0.63397616147995\n",
      "Iteration 50, Loss: 5.055242945672944e-05, Min w: 0.7188480496406555\n",
      "Iteration 60, Loss: 4.064642416778952e-05, Min w: 0.7690100073814392\n",
      "Iteration 70, Loss: 3.329417450004257e-05, Min w: 0.7958827018737793\n",
      "Iteration 80, Loss: 2.832784412021283e-05, Min w: 0.8117550015449524\n",
      "Iteration 90, Loss: 2.202439100074116e-05, Min w: 0.8621289730072021\n",
      "Iteration 100, Loss: 1.887728285510093e-05, Min w: 0.8810447454452515\n",
      "Iteration 110, Loss: 1.2622742360690609e-05, Min w: 0.9153975248336792\n",
      "Iteration 120, Loss: 1.083090410247678e-05, Min w: 0.9294615983963013\n",
      "Iteration 130, Loss: 8.427489774476271e-06, Min w: 0.9439821243286133\n",
      "Iteration 140, Loss: 7.818363883416168e-06, Min w: 0.948104202747345\n",
      "Iteration 150, Loss: 5.493221124197589e-06, Min w: 0.9631705284118652\n",
      "Iteration 160, Loss: 4.346261448517907e-06, Min w: 0.9711258411407471\n",
      "Iteration 170, Loss: 3.5417308481555665e-06, Min w: 0.9756889343261719\n",
      "Iteration 180, Loss: 2.512992068659514e-06, Min w: 0.9837000370025635\n",
      "Iteration 190, Loss: 2.0927752757415874e-06, Min w: 0.9869417548179626\n",
      "Iteration 200, Loss: 4.685566182160983e-06, Min w: 0.9616038799285889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  29%|██▉       | 7/24 [00:09<00:26,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 205 --------------------------------\n",
      "Iteration 0, Loss: 3.3086246276070597e-06, Min w: 0.9791945219039917\n",
      "Early break at iteration 4 --------------------------------\n",
      "Iteration 0, Loss: 3.1141485123953316e-06, Min w: 0.9765997529029846\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 2.3980737751116976e-06, Min w: 0.9872945547103882\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 1.9937481283704983e-06, Min w: 0.9870674014091492\n",
      "Early break at iteration 3 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 223, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0031314174095122826, 'L2_avg': 0.004324377050587512, 'End_point_L1_avg': 0.00257264110224736, 'End_point_L2_avg': 0.003929247552220635}\n",
      "Iteration 0, Loss: 0.0004585729620885104, Min w: 9.471901209331599e-14\n",
      "Iteration 10, Loss: 0.00024711989681236446, Min w: 0.1189480796456337\n",
      "Iteration 20, Loss: 0.00010429969552205876, Min w: 0.49670788645744324\n",
      "Iteration 30, Loss: 9.312388283433393e-05, Min w: 0.5259467363357544\n",
      "Iteration 40, Loss: 6.352477066684514e-05, Min w: 0.5747270584106445\n",
      "Iteration 50, Loss: 5.022713594371453e-05, Min w: 0.6251316070556641\n",
      "Iteration 60, Loss: 3.983756687375717e-05, Min w: 0.6803100109100342\n",
      "Iteration 70, Loss: 3.147138704662211e-05, Min w: 0.7359172701835632\n",
      "Iteration 80, Loss: 2.3988313841982745e-05, Min w: 0.7866021394729614\n",
      "Iteration 90, Loss: 1.9912862626370043e-05, Min w: 0.8150134086608887\n",
      "Iteration 100, Loss: 1.5545168935204856e-05, Min w: 0.851678729057312\n",
      "Iteration 110, Loss: 1.0393348929937929e-05, Min w: 0.8976265788078308\n",
      "Iteration 120, Loss: 7.86099917604588e-06, Min w: 0.9237356781959534\n",
      "Iteration 130, Loss: 6.1798159549653064e-06, Min w: 0.9424535036087036\n",
      "Iteration 140, Loss: 4.394658844830701e-06, Min w: 0.9610480666160583\n",
      "Iteration 150, Loss: 2.992085228470387e-06, Min w: 0.9748321771621704\n",
      "Iteration 160, Loss: 2.486328867234988e-06, Min w: 0.9799590110778809\n",
      "Iteration 170, Loss: 1.937448814715026e-06, Min w: 0.9851731657981873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  33%|███▎      | 8/24 [00:11<00:27,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 180, Loss: 1.6407714156230213e-06, Min w: 0.9885447025299072\n",
      "Early break at iteration 184 --------------------------------\n",
      "Iteration 0, Loss: 1.3161596825739252e-06, Min w: 0.991035521030426\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.5646131714674993e-06, Min w: 0.9889437556266785\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.3025554608248058e-06, Min w: 0.9911571741104126\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.2289067399251508e-06, Min w: 0.9921064972877502\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 190, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (2, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0019642060682786644, 'L2_avg': 0.0036499009153292314, 'End_point_L1_avg': 0.0010181881847450107, 'End_point_L2_avg': 0.0012328769514777349}\n",
      "Iteration 0, Loss: 0.0015850025229156017, Min w: 2.7963551474385895e-05\n",
      "Iteration 10, Loss: 0.0006384632433764637, Min w: 0.002089994726702571\n",
      "Iteration 20, Loss: 0.00011730715777957812, Min w: 0.8132802844047546\n",
      "Iteration 30, Loss: 0.00011096699017798528, Min w: 0.8451883792877197\n",
      "Iteration 40, Loss: 4.209844701108523e-05, Min w: 0.9167348146438599\n",
      "Iteration 50, Loss: 2.2503714717458934e-05, Min w: 0.963654100894928\n",
      "Early break at iteration 55 --------------------------------\n",
      "Iteration 0, Loss: 1.0982352250721306e-05, Min w: 0.9757876396179199\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 6.325742106128018e-06, Min w: 0.989519476890564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  38%|███▊      | 9/24 [00:12<00:21,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 4 --------------------------------\n",
      "Iteration 0, Loss: 3.5083432976534823e-06, Min w: 0.9956048727035522\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 5.03185356137692e-06, Min w: 0.9921150207519531\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 67, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.006128224591952057, 'L2_avg': 0.006837717098432611, 'End_point_L1_avg': 0.006225071671634329, 'End_point_L2_avg': 0.0083698601310479}\n",
      "Iteration 0, Loss: 0.001385533600114286, Min w: 0.0013427254743874073\n",
      "Iteration 10, Loss: 0.0006749433814547956, Min w: 0.004916694480925798\n",
      "Iteration 20, Loss: 0.00028593113529495895, Min w: 0.18809561431407928\n",
      "Iteration 30, Loss: 9.602733189240098e-05, Min w: 0.8239546418190002\n",
      "Iteration 40, Loss: 4.574270133161917e-05, Min w: 0.9404060244560242\n",
      "Iteration 50, Loss: 5.143724047229625e-05, Min w: 0.8654009699821472\n",
      "Iteration 60, Loss: 1.5520667147939093e-05, Min w: 0.9708347916603088\n",
      "Iteration 70, Loss: 4.264611561666243e-06, Min w: 0.9950591921806335\n",
      "Early break at iteration 70 --------------------------------\n",
      "Iteration 0, Loss: 6.125461823103251e-06, Min w: 0.9901938438415527\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 9.764463356987108e-06, Min w: 0.9804500341415405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  42%|████▏     | 10/24 [00:13<00:17,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 5 --------------------------------\n",
      "Iteration 0, Loss: 3.410674935366842e-06, Min w: 0.9923868179321289\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 6.167224455566611e-06, Min w: 0.9866154193878174\n",
      "Early break at iteration 8 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 88, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.002760803596202744, 'L2_avg': 0.003382593715210383, 'End_point_L1_avg': 0.0022683324249532623, 'End_point_L2_avg': 0.0028243450238849776}\n",
      "Iteration 0, Loss: 0.00040299948886968195, Min w: 8.921119398763722e-11\n",
      "Iteration 10, Loss: 0.00035187360481359065, Min w: 7.006492321624085e-45\n",
      "Iteration 20, Loss: 0.00022133823949843645, Min w: 0.008037781342864037\n",
      "Iteration 30, Loss: 0.00012060139124514535, Min w: 0.0012199839111417532\n",
      "Iteration 40, Loss: 9.53072085394524e-05, Min w: 0.011470623314380646\n",
      "Iteration 50, Loss: 9.907381172524765e-05, Min w: 0.28354084491729736\n",
      "Iteration 60, Loss: 2.4158594897016883e-05, Min w: 0.8836953043937683\n",
      "Iteration 70, Loss: 1.0212350389338098e-05, Min w: 0.9363628029823303\n",
      "Iteration 80, Loss: 3.159506741212681e-05, Min w: 0.6737583875656128\n",
      "Iteration 90, Loss: 1.561091085022781e-05, Min w: 0.8630868792533875\n",
      "Iteration 100, Loss: 1.663399234530516e-05, Min w: 0.8142245411872864\n",
      "Iteration 110, Loss: 7.541772902186494e-06, Min w: 0.9097217321395874\n",
      "Iteration 120, Loss: 5.511910330824321e-06, Min w: 0.9327424764633179\n",
      "Iteration 130, Loss: 9.315343959315214e-06, Min w: 0.8851330280303955\n",
      "Early break at iteration 139 --------------------------------\n",
      "Iteration 0, Loss: 8.634979167254642e-07, Min w: 0.9921693801879883\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.1498023013700731e-06, Min w: 0.9881299734115601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  46%|████▌     | 11/24 [00:15<00:20,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: 9.616307579563e-06, Min w: 0.8974746465682983\n",
      "Early break at iteration 13 --------------------------------\n",
      "Iteration 0, Loss: 1.94893664229312e-06, Min w: 0.9822444319725037\n",
      "Early break at iteration 7 --------------------------------\n",
      "Iteration 0, Loss: 7.426865522575099e-07, Min w: 0.9940523505210876\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 164, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0020420683577746946, 'L2_avg': 0.0031217459891399227, 'End_point_L1_avg': 0.0013692038436321557, 'End_point_L2_avg': 0.0020578179791833568}\n",
      "Iteration 0, Loss: 0.00038009611307643354, Min w: 1.1796855331079093e-17\n",
      "Iteration 10, Loss: 0.0003601165080908686, Min w: 2.523171851868439e-25\n",
      "Iteration 20, Loss: 0.0001947300333995372, Min w: 1.9923608347168255e-21\n",
      "Iteration 30, Loss: 0.0001363997726002708, Min w: 1.658738267860992e-16\n",
      "Iteration 40, Loss: 8.838314533932135e-05, Min w: 0.49108415842056274\n",
      "Iteration 50, Loss: 0.00011115198867628351, Min w: 0.266215443611145\n",
      "Iteration 60, Loss: 5.947009049123153e-05, Min w: 0.5836231708526611\n",
      "Iteration 70, Loss: 9.80418553808704e-05, Min w: 0.377221018075943\n",
      "Iteration 80, Loss: 8.416324271820486e-05, Min w: 0.5844029188156128\n",
      "Iteration 90, Loss: 4.283604721422307e-05, Min w: 0.6875866651535034\n",
      "Iteration 100, Loss: 1.2344232345640194e-05, Min w: 0.889106810092926\n",
      "Iteration 110, Loss: 9.600516023056116e-06, Min w: 0.8924791216850281\n",
      "Iteration 120, Loss: 1.4524872312904336e-05, Min w: 0.8232589960098267\n",
      "Iteration 130, Loss: 1.7510257748654112e-05, Min w: 0.8037819862365723\n",
      "Iteration 140, Loss: 3.952197221224196e-05, Min w: 0.591178834438324\n",
      "Iteration 150, Loss: 6.8859976636304054e-06, Min w: 0.913220226764679\n",
      "Iteration 160, Loss: 1.3688814760826062e-05, Min w: 0.8565415143966675\n",
      "Iteration 170, Loss: 7.407917109958362e-06, Min w: 0.9162065982818604\n",
      "Iteration 180, Loss: 3.5683515307027847e-06, Min w: 0.9608290195465088\n",
      "Iteration 190, Loss: 8.748290383664425e-06, Min w: 0.892967164516449\n",
      "Iteration 200, Loss: 8.998785233416129e-06, Min w: 0.8978649973869324\n",
      "Iteration 210, Loss: 1.9854916899930686e-05, Min w: 0.7899087071418762\n",
      "Iteration 220, Loss: 4.010103111795615e-06, Min w: 0.9571723341941833\n",
      "Iteration 230, Loss: 1.7939863710125792e-06, Min w: 0.9791248440742493\n",
      "Iteration 240, Loss: 5.8424157032277435e-06, Min w: 0.9335774779319763\n",
      "Iteration 250, Loss: 4.66128994958126e-06, Min w: 0.9483177065849304\n",
      "Early break at iteration 252 --------------------------------\n",
      "Iteration 0, Loss: 6.595827812816424e-07, Min w: 0.9940176606178284\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.1544780136318877e-06, Min w: 0.9882441163063049\n",
      "Iteration 10, Loss: 3.1344945909950184e-06, Min w: 0.9639143943786621\n",
      "Early break at iteration 19 --------------------------------\n",
      "Iteration 0, Loss: 1.6478978750456008e-06, Min w: 0.9842159152030945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  50%|█████     | 12/24 [00:19<00:27,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: 5.4384554459829815e-06, Min w: 0.9440359473228455\n",
      "Early break at iteration 16 --------------------------------\n",
      "Iteration 0, Loss: 4.616460671513778e-07, Min w: 0.9959151744842529\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 292, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0015202931567832917, 'L2_avg': 0.0028080442975372075, 'End_point_L1_avg': 0.0007920513840562031, 'End_point_L2_avg': 0.0016357077008285967}\n",
      "Iteration 0, Loss: 0.0011118212714791298, Min w: 6.111273978604004e-05\n",
      "Iteration 10, Loss: 0.0004865054797846824, Min w: 0.05070077255368233\n",
      "Iteration 20, Loss: 0.0003205984248779714, Min w: 0.46479082107543945\n",
      "Iteration 30, Loss: 0.00019918209000024945, Min w: 0.6801486015319824\n",
      "Iteration 40, Loss: 9.81326520559378e-05, Min w: 0.8387587666511536\n",
      "Iteration 50, Loss: 4.258500848663971e-05, Min w: 0.9133180379867554\n",
      "Iteration 60, Loss: 1.8653723600436933e-05, Min w: 0.9595900177955627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  54%|█████▍    | 13/24 [00:20<00:20,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 1.002733642962994e-05, Min w: 0.9788190722465515\n",
      "Early break at iteration 78 --------------------------------\n",
      "Iteration 0, Loss: 5.3535222832579166e-06, Min w: 0.9898059964179993\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 5.353330834623193e-06, Min w: 0.9909037351608276\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.538753162501962e-06, Min w: 0.9938815832138062\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.919601451547351e-06, Min w: 0.9922246932983398\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 86, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.00372052936752808, 'L2_avg': 0.004845409442186854, 'End_point_L1_avg': 0.0026359587672700005, 'End_point_L2_avg': 0.004313540787590009}\n",
      "Iteration 0, Loss: 0.0012858499540016055, Min w: 1.1316362069635488e-08\n",
      "Iteration 10, Loss: 0.0004790940147358924, Min w: 0.2531658411026001\n",
      "Iteration 20, Loss: 0.00028206472052261233, Min w: 0.4997745454311371\n",
      "Iteration 30, Loss: 0.00017974400543607771, Min w: 0.6183418035507202\n",
      "Iteration 40, Loss: 0.00010313125676475465, Min w: 0.7182856202125549\n",
      "Iteration 50, Loss: 5.328014594851993e-05, Min w: 0.8224781155586243\n",
      "Iteration 60, Loss: 2.082377795886714e-05, Min w: 0.9192564487457275\n",
      "Iteration 70, Loss: 1.2835245797759853e-05, Min w: 0.948167085647583\n",
      "Iteration 80, Loss: 4.675072887039278e-06, Min w: 0.9853997230529785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  58%|█████▊    | 14/24 [00:21<00:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 85 --------------------------------\n",
      "Iteration 0, Loss: 2.3683192011958454e-06, Min w: 0.9932444095611572\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.81855488740257e-06, Min w: 0.9878761768341064\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 5.66364178666845e-06, Min w: 0.9815754890441895\n",
      "Early break at iteration 1 --------------------------------\n",
      "Iteration 0, Loss: 1.9082872313447297e-06, Min w: 0.995262861251831\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 92, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.0015851500771531415, 'L2_avg': 0.0024597307172403776, 'End_point_L1_avg': 0.000995575433414558, 'End_point_L2_avg': 0.0014198586794961447}\n",
      "Iteration 0, Loss: 0.00038324229535646737, Min w: 3.71530290976807e-07\n",
      "Iteration 10, Loss: 0.00017884197586681694, Min w: 0.40111565589904785\n",
      "Iteration 20, Loss: 0.00011577514669625089, Min w: 0.5305408239364624\n",
      "Iteration 30, Loss: 7.785380876157433e-05, Min w: 0.5970849394798279\n",
      "Iteration 40, Loss: 6.297305662883446e-05, Min w: 0.6344589591026306\n",
      "Iteration 50, Loss: 4.612134944181889e-05, Min w: 0.7297046184539795\n",
      "Iteration 60, Loss: 3.034806104551535e-05, Min w: 0.8004138469696045\n",
      "Iteration 70, Loss: 2.0547437088680454e-05, Min w: 0.863614559173584\n",
      "Iteration 80, Loss: 1.1798763807746582e-05, Min w: 0.9168384671211243\n",
      "Iteration 90, Loss: 7.168114279920701e-06, Min w: 0.9512808322906494\n",
      "Iteration 100, Loss: 5.615755071630701e-06, Min w: 0.9467597007751465\n",
      "Iteration 110, Loss: 3.426393504923908e-06, Min w: 0.9676175117492676\n",
      "Early break at iteration 118 --------------------------------\n",
      "Iteration 0, Loss: 1.8757018551696092e-06, Min w: 0.9884505867958069\n",
      "Early break at iteration 4 --------------------------------\n",
      "Iteration 0, Loss: 1.434986529602611e-06, Min w: 0.9921442866325378\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.4438015796258696e-06, Min w: 0.9908373355865479\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  62%|██████▎   | 15/24 [00:23<00:14,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.646171199354285e-06, Min w: 0.9864844083786011\n",
      "Early break at iteration 5 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 132, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.002399194089112938, 'L2_avg': 0.0043952713283659335, 'End_point_L1_avg': 0.001054944922514898, 'End_point_L2_avg': 0.002321481907023865}\n",
      "Iteration 0, Loss: 0.00038220526766963303, Min w: 1.3649517722485343e-15\n",
      "Iteration 10, Loss: 0.0001577752409502864, Min w: 0.21922732889652252\n",
      "Iteration 20, Loss: 0.00010121923696715385, Min w: 0.6185028553009033\n",
      "Iteration 30, Loss: 7.167294097598642e-05, Min w: 0.6587161421775818\n",
      "Iteration 40, Loss: 5.042890188633464e-05, Min w: 0.7310813069343567\n",
      "Iteration 50, Loss: 3.519711390254088e-05, Min w: 0.8173509240150452\n",
      "Iteration 60, Loss: 2.2995913241175003e-05, Min w: 0.8576127886772156\n",
      "Iteration 70, Loss: 1.4968510186008643e-05, Min w: 0.885549783706665\n",
      "Iteration 80, Loss: 9.312572728958912e-06, Min w: 0.9138338565826416\n",
      "Iteration 90, Loss: 5.70747715755715e-06, Min w: 0.9400657415390015\n",
      "Iteration 100, Loss: 7.910663043730892e-06, Min w: 0.9145192503929138\n",
      "Iteration 110, Loss: 3.30631382894353e-06, Min w: 0.97369384765625\n",
      "Iteration 120, Loss: 1.7490710888523608e-06, Min w: 0.9844425320625305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  67%|██████▋   | 16/24 [00:24<00:13,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130, Loss: 1.535619844617031e-06, Min w: 0.988089919090271\n",
      "Early break at iteration 132 --------------------------------\n",
      "Iteration 0, Loss: 1.3546859918278642e-06, Min w: 0.9905657172203064\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.0981078730765148e-06, Min w: 0.992293119430542\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.11123029000737e-06, Min w: 0.9925147294998169\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.286838028136117e-06, Min w: 0.9909526109695435\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 137, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (3, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.002510662985774041, 'L2_avg': 0.004001692275610974, 'End_point_L1_avg': 0.001697523204759903, 'End_point_L2_avg': 0.0023208169726051057}\n",
      "Iteration 0, Loss: 0.0009844991145655513, Min w: 0.04280270263552666\n",
      "Iteration 10, Loss: 0.0004138329823035747, Min w: 0.16182342171669006\n",
      "Iteration 20, Loss: 0.00016300252173095942, Min w: 0.8358514904975891\n",
      "Iteration 30, Loss: 8.801570947980508e-05, Min w: 0.806096613407135\n",
      "Iteration 40, Loss: 2.273094105476048e-05, Min w: 0.9408826231956482\n",
      "Early break at iteration 48 --------------------------------\n",
      "Iteration 0, Loss: 1.2896319276478607e-05, Min w: 0.9820534586906433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  71%|███████   | 17/24 [00:25<00:09,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 4.759504463436315e-06, Min w: 0.9906719326972961\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.0238276445306838e-05, Min w: 0.9805943369865417\n",
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 6.688456323900027e-06, Min w: 0.9881332516670227\n",
      "Early break at iteration 2 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 59, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.002853952789161913, 'L2_avg': 0.0037352117243861943, 'End_point_L1_avg': 0.002002010085879168, 'End_point_L2_avg': 0.00268823173076573}\n",
      "Iteration 0, Loss: 0.0011563810985535383, Min w: 1.1768603371820063e-06\n",
      "Iteration 10, Loss: 0.0005108311888761818, Min w: 0.0006647787522524595\n",
      "Iteration 20, Loss: 0.00018853350775316358, Min w: 0.6973423957824707\n",
      "Iteration 30, Loss: 0.0001031382562359795, Min w: 0.7564554810523987\n",
      "Iteration 40, Loss: 4.494914537644945e-05, Min w: 0.9207978248596191\n",
      "Iteration 50, Loss: 1.4673086297989357e-05, Min w: 0.9663550853729248\n",
      "Early break at iteration 58 --------------------------------\n",
      "Iteration 0, Loss: 5.600738404609729e-06, Min w: 0.9914326071739197\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 7.996162821655162e-06, Min w: 0.9798603057861328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  75%|███████▌  | 18/24 [00:26<00:07,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 9 --------------------------------\n",
      "Iteration 0, Loss: 1.5893736417638138e-05, Min w: 0.9575708508491516\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 1.2168127796030603e-05, Min w: 0.9655181765556335\n",
      "Early break at iteration 2 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 77, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.00444815875844301, 'L2_avg': 0.005221403664089552, 'End_point_L1_avg': 0.004638177627550742, 'End_point_L2_avg': 0.005908885727022035}\n",
      "Iteration 0, Loss: 0.00033710626303218305, Min w: 3.2996830157117074e-08\n",
      "Iteration 10, Loss: 0.0002696409064810723, Min w: 1.6727693686322594e-15\n",
      "Iteration 20, Loss: 0.00020546220184769481, Min w: 0.003302660072222352\n",
      "Iteration 30, Loss: 9.708535071695223e-05, Min w: 0.6004199981689453\n",
      "Iteration 40, Loss: 5.353810411179438e-05, Min w: 0.4578874409198761\n",
      "Iteration 50, Loss: 0.00014215693227015436, Min w: 0.26013317704200745\n",
      "Iteration 60, Loss: 4.7676756366854534e-05, Min w: 0.5140737295150757\n",
      "Iteration 70, Loss: 2.926808338088449e-05, Min w: 0.7267202734947205\n",
      "Iteration 80, Loss: 5.882958430447616e-05, Min w: 0.2533515691757202\n",
      "Iteration 90, Loss: 4.2361651139799505e-05, Min w: 0.5891385078430176\n",
      "Iteration 100, Loss: 1.4360551176650915e-05, Min w: 0.8547264337539673\n",
      "Iteration 110, Loss: 2.2363443349604495e-05, Min w: 0.7482741475105286\n",
      "Iteration 120, Loss: 3.6959654607926495e-06, Min w: 0.9538455605506897\n",
      "Iteration 130, Loss: 1.3159350601199549e-05, Min w: 0.8213829398155212\n",
      "Iteration 140, Loss: 8.572682418162003e-06, Min w: 0.9163936376571655\n",
      "Iteration 150, Loss: 3.7832810448890086e-06, Min w: 0.9662443995475769\n",
      "Early break at iteration 152 --------------------------------\n",
      "Iteration 0, Loss: 2.364226475037867e-06, Min w: 0.9727385640144348\n",
      "Iteration 10, Loss: 2.43473073169298e-06, Min w: 0.975532054901123\n",
      "Iteration 20, Loss: 6.139935976534616e-06, Min w: 0.9280099272727966\n",
      "Early break at iteration 24 --------------------------------\n",
      "Iteration 0, Loss: 1.6825398461151053e-06, Min w: 0.9871649742126465\n",
      "Iteration 10, Loss: 7.198295406851685e-06, Min w: 0.9154047966003418\n",
      "Iteration 20, Loss: 3.2588891372142825e-06, Min w: 0.9657544493675232\n",
      "Early break at iteration 29 --------------------------------\n",
      "Iteration 0, Loss: 1.7044224023265997e-06, Min w: 0.9828759431838989\n",
      "Iteration 10, Loss: 4.268379143468337e-06, Min w: 0.9440086483955383\n",
      "Early break at iteration 13 --------------------------------\n",
      "Iteration 0, Loss: 5.149021262695896e-07, Min w: 0.9952866435050964\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  79%|███████▉  | 19/24 [00:29<00:09,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 223, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.0019237452503031239, 'L2_avg': 0.003389346223913434, 'End_point_L1_avg': 0.0009643960146249417, 'End_point_L2_avg': 0.001747023276159428}\n",
      "Iteration 0, Loss: 0.00030920011340640485, Min w: 0.000562880712095648\n",
      "Iteration 10, Loss: 0.0002705299702938646, Min w: 8.99136830412317e-06\n",
      "Iteration 20, Loss: 0.00020911656611133367, Min w: 0.03796419873833656\n",
      "Iteration 30, Loss: 0.00017738122551236302, Min w: 0.2237836867570877\n",
      "Iteration 40, Loss: 6.169258267618716e-05, Min w: 0.6903195977210999\n",
      "Iteration 50, Loss: 0.000133347071823664, Min w: 0.20114092528820038\n",
      "Iteration 60, Loss: 2.6364479708718136e-05, Min w: 0.8002720475196838\n",
      "Iteration 70, Loss: 3.496294084470719e-05, Min w: 0.5761791467666626\n",
      "Iteration 80, Loss: 3.4008397051366046e-05, Min w: 0.6768376231193542\n",
      "Iteration 90, Loss: 1.9251059711677954e-05, Min w: 0.8302490711212158\n",
      "Iteration 100, Loss: 2.3310161850531586e-05, Min w: 0.6993961334228516\n",
      "Iteration 110, Loss: 5.171978955331724e-06, Min w: 0.9378260970115662\n",
      "Iteration 120, Loss: 2.7111150302516762e-06, Min w: 0.9684334993362427\n",
      "Iteration 130, Loss: 1.3799915905110538e-05, Min w: 0.7733912467956543\n",
      "Iteration 140, Loss: 7.957296475069597e-06, Min w: 0.9260929822921753\n",
      "Iteration 150, Loss: 1.3795006452710368e-05, Min w: 0.8522695899009705\n",
      "Iteration 160, Loss: 7.206411282822955e-06, Min w: 0.91454017162323\n",
      "Iteration 170, Loss: 4.087651541340165e-05, Min w: 0.5834236145019531\n",
      "Iteration 180, Loss: 4.0861759771360084e-06, Min w: 0.943572461605072\n",
      "Iteration 190, Loss: 2.582216438895557e-06, Min w: 0.968230664730072\n",
      "Iteration 200, Loss: 8.454911039734725e-06, Min w: 0.8712264895439148\n",
      "Early break at iteration 208 --------------------------------\n",
      "Iteration 0, Loss: 2.6352381610195152e-06, Min w: 0.9652146100997925\n",
      "Early break at iteration 8 --------------------------------\n",
      "Iteration 0, Loss: 1.0593234947009478e-06, Min w: 0.988420307636261\n",
      "Iteration 10, Loss: 5.183575012779329e-06, Min w: 0.9547416567802429\n",
      "Iteration 20, Loss: 1.9570622953324346e-06, Min w: 0.9728245139122009\n",
      "Early break at iteration 26 --------------------------------\n",
      "Iteration 0, Loss: 8.508698101650225e-07, Min w: 0.9930698871612549\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.4648866226707469e-06, Min w: 0.9836941957473755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  83%|████████▎ | 20/24 [00:33<00:09,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 9 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 256, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.01, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0030445124126057036, 'L2_avg': 0.004612525832906439, 'End_point_L1_avg': 0.0025663198431727556, 'End_point_L2_avg': 0.0032435269437217093}\n",
      "Iteration 0, Loss: 0.0010387263027951121, Min w: 9.835305263550254e-07\n",
      "Iteration 10, Loss: 0.0004502425726968795, Min w: 0.3892541229724884\n",
      "Iteration 20, Loss: 0.0002739804331213236, Min w: 0.5769198536872864\n",
      "Iteration 30, Loss: 0.00013262024731375277, Min w: 0.7964484095573425\n",
      "Iteration 40, Loss: 7.063738303259015e-05, Min w: 0.8522939085960388\n",
      "Iteration 50, Loss: 2.707501880649943e-05, Min w: 0.9189589023590088\n",
      "Iteration 60, Loss: 1.0968425158353057e-05, Min w: 0.9627847671508789\n",
      "Iteration 70, Loss: 7.93184335634578e-06, Min w: 0.980331540107727\n",
      "Early break at iteration 72 --------------------------------\n",
      "Iteration 0, Loss: 3.0003102438058704e-06, Min w: 0.9953409433364868\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 4.157031526119681e-06, Min w: 0.9889383316040039\n",
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 3.003037591042812e-06, Min w: 0.993664026260376\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 3.665054464363493e-06, Min w: 0.9907880425453186\n",
      "Early break at iteration 0 --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  88%|████████▊ | 21/24 [00:34<00:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PINN MLP', 'Total_Iterations': 79, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.001, 'L1_avg': 0.003235115175195744, 'L2_avg': 0.004138402034154013, 'End_point_L1_avg': 0.0025208229535978403, 'End_point_L2_avg': 0.003105211171537939}\n",
      "Iteration 0, Loss: 0.0010548249119892716, Min w: 0.002804657444357872\n",
      "Iteration 10, Loss: 0.0003899472940247506, Min w: 0.4675658047199249\n",
      "Iteration 20, Loss: 0.00025982558145187795, Min w: 0.563704252243042\n",
      "Iteration 30, Loss: 0.00015867999172769487, Min w: 0.6950205564498901\n",
      "Iteration 40, Loss: 9.883315215120092e-05, Min w: 0.7726277709007263\n",
      "Iteration 50, Loss: 3.8057612982811406e-05, Min w: 0.9206905364990234\n",
      "Iteration 60, Loss: 1.0871277481783181e-05, Min w: 0.9852321147918701\n",
      "Iteration 70, Loss: 8.056064871198032e-06, Min w: 0.9754435420036316\n",
      "Early break at iteration 72 --------------------------------\n",
      "Iteration 0, Loss: 6.3821885305515025e-06, Min w: 0.9860458970069885\n",
      "Early break at iteration 3 --------------------------------\n",
      "Iteration 0, Loss: 6.449816282838583e-06, Min w: 0.9799593091011047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  92%|█████████▏| 22/24 [00:35<00:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 5.7938914324040525e-06, Min w: 0.9819990992546082\n",
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 4.518195964919869e-06, Min w: 0.9871178269386292\n",
      "Early break at iteration 1 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 85, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 512, 'stopping_loss': 0.0001, 'L1_avg': 0.00322712285684039, 'L2_avg': 0.004022011535739582, 'End_point_L1_avg': 0.0025245865365836257, 'End_point_L2_avg': 0.0037774799278497565}\n",
      "Iteration 0, Loss: 0.0003424919268582016, Min w: 2.031936645607857e-07\n",
      "Iteration 10, Loss: 0.0001210451519000344, Min w: 0.432944655418396\n",
      "Iteration 20, Loss: 9.461972513236105e-05, Min w: 0.4943695068359375\n",
      "Iteration 30, Loss: 7.021093188086525e-05, Min w: 0.603954553604126\n",
      "Iteration 40, Loss: 4.956504562869668e-05, Min w: 0.6821798086166382\n",
      "Iteration 50, Loss: 2.9929356969660148e-05, Min w: 0.7661874294281006\n",
      "Iteration 60, Loss: 1.538215292384848e-05, Min w: 0.8597361445426941\n",
      "Iteration 70, Loss: 1.965259616554249e-05, Min w: 0.7907118797302246\n",
      "Iteration 80, Loss: 9.494311598245986e-06, Min w: 0.9027183055877686\n",
      "Iteration 90, Loss: 4.431721208675299e-06, Min w: 0.9601219892501831\n",
      "Iteration 100, Loss: 1.6942691445365199e-06, Min w: 0.9865837693214417\n",
      "Early break at iteration 101 --------------------------------\n",
      "Iteration 0, Loss: 1.861099462985294e-06, Min w: 0.9821546673774719\n",
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 1.3941840961706475e-06, Min w: 0.9897591471672058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP:  96%|█████████▌| 23/24 [00:36<00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 2 --------------------------------\n",
      "Iteration 0, Loss: 9.83568611445662e-07, Min w: 0.9938459396362305\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.0723298373704893e-06, Min w: 0.9918006658554077\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 110, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.001, 'L1_avg': 0.003097590144964412, 'L2_avg': 0.004364655723952474, 'End_point_L1_avg': 0.002116360077241299, 'End_point_L2_avg': 0.002695533486935169}\n",
      "Iteration 0, Loss: 0.000322541716741398, Min w: 5.20598053554977e-09\n",
      "Iteration 10, Loss: 0.00014579309208784252, Min w: 0.2159901112318039\n",
      "Iteration 20, Loss: 0.00010365420166635886, Min w: 0.48155415058135986\n",
      "Iteration 30, Loss: 7.776817074045539e-05, Min w: 0.5186334848403931\n",
      "Iteration 40, Loss: 5.591282024397515e-05, Min w: 0.631905734539032\n",
      "Iteration 50, Loss: 3.725789065356366e-05, Min w: 0.7189188003540039\n",
      "Iteration 60, Loss: 2.346660585317295e-05, Min w: 0.7950414419174194\n",
      "Iteration 70, Loss: 1.3574790500570089e-05, Min w: 0.8680254817008972\n",
      "Iteration 80, Loss: 9.907859748636838e-06, Min w: 0.8874496221542358\n",
      "Iteration 90, Loss: 4.9852214942802675e-06, Min w: 0.9452483654022217\n",
      "Iteration 100, Loss: 5.248308752925368e-06, Min w: 0.9369016289710999\n",
      "Iteration 110, Loss: 2.9155314678064315e-06, Min w: 0.9678593277931213\n",
      "Early break at iteration 118 --------------------------------\n",
      "Iteration 0, Loss: 1.5298390962925623e-06, Min w: 0.9857980012893677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PINN MLP: 100%|██████████| 24/24 [00:38<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early break at iteration 6 --------------------------------\n",
      "Iteration 0, Loss: 8.372008437618206e-07, Min w: 0.9957678914070129\n",
      "Early break at iteration 0 --------------------------------\n",
      "Iteration 0, Loss: 1.390174020343693e-06, Min w: 0.9877168536186218\n",
      "Early break at iteration 9 --------------------------------\n",
      "Iteration 0, Loss: 6.813503432567813e-07, Min w: 0.996734619140625\n",
      "Early break at iteration 0 --------------------------------\n",
      "{'Model': 'PINN MLP', 'Total_Iterations': 138, 'ODE': 'Simplified 15D Linear System', 'ODE_dim': 15, 'net_size': (4, 50), 'lr': 0.001, 'batch_size': 2048, 'stopping_loss': 0.0001, 'L1_avg': 0.0021690675632066734, 'L2_avg': 0.0029468481881019864, 'End_point_L1_avg': 0.0015532911939460646, 'End_point_L2_avg': 0.00241245452148337}\n",
      "Results saved to results/pinn_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_pinn_models(ODE_systems, PINNS, param_grid, compute_error_norms, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode = ODE_systems[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': <function PINN.pinn_base.pin_base_exe(net_size, lr, batch_size, ode, stopping_loss, device, max_iter=50000, wd=None)>,\n",
       "  'name': 'PINN base'},\n",
       " {'model': <function PINN.pinn_modified.pin_modified_exe(net_size, lr, batch_size, ode, stopping_loss, device, max_iter=50000, wd=None)>,\n",
       "  'name': 'PINN modified'},\n",
       " {'model': <function PINN.pinn_new_arc.pin_new_arc_exe(net_size, lr, batch_size, ode, stopping_loss, device, max_iter=50000, wd=None)>,\n",
       "  'name': 'PINN new architecture'},\n",
       " {'model': <function PINN.pinn_new_arc_MLP.pin_new_arc_MLP_exe(net_size, lr, batch_size, ode, stopping_loss, device, max_iter=50000, wd=None)>,\n",
       "  'name': 'PINN new architecture MLP'},\n",
       " {'model': <function PINN.pinn_MLP.pin_MLP_exe(net_size, lr, batch_size, ode, stopping_loss, device, max_iter=50000, wd=None)>,\n",
       "  'name': 'PINN MLP'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.1094589233398438\n",
      "Iteration 10, Loss: 0.1533796340227127\n",
      "Iteration 20, Loss: 0.029828239232301712\n",
      "Iteration 30, Loss: 0.01858656108379364\n",
      "Iteration 40, Loss: 0.006138352677226067\n",
      "Iteration 50, Loss: 0.003682161681354046\n",
      "Iteration 60, Loss: 0.0029010570142418146\n",
      "Iteration 70, Loss: 0.002080485923215747\n",
      "Iteration 80, Loss: 0.0017065138090401888\n",
      "Iteration 90, Loss: 0.0016464036889374256\n",
      "Iteration 100, Loss: 0.0013821168104186654\n",
      "Iteration 110, Loss: 0.0018588907551020384\n",
      "Iteration 120, Loss: 0.0017271514516323805\n",
      "Iteration 130, Loss: 0.0015019680140540004\n",
      "Iteration 140, Loss: 0.001349571393802762\n",
      "Iteration 150, Loss: 0.0010356982238590717\n",
      "Iteration 160, Loss: 0.0014165736502036452\n",
      "Iteration 170, Loss: 0.0011866420973092318\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, train_iter \u001b[38;5;241m=\u001b[39m \u001b[43mPINNS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/GitHub/master-thesis/code/PINN/pinn_base.py:64\u001b[0m, in \u001b[0;36mpin_base_exe\u001b[0;34m(net_size, lr, batch_size, ode, stopping_loss, device, max_iter, wd)\u001b[0m\n\u001b[1;32m     61\u001b[0m t\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     62\u001b[0m t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 64\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/mnt/d/Documents/GitHub/master-thesis/code/PINN/pinn_base.py:37\u001b[0m, in \u001b[0;36mpin_base_exe.<locals>.loss_fn\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(t: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# INTERIOR LOSS\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# NN grads\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     y \u001b[38;5;241m=\u001b[39m model(t)\n\u001b[0;32m---> 37\u001b[0m     jacobians \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_jacobian_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     dydt \u001b[38;5;241m=\u001b[39m jacobians\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# ODE actual grads\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m/mnt/d/Documents/GitHub/master-thesis/code/PINN/pinn_base.py:21\u001b[0m, in \u001b[0;36mpin_base_exe.<locals>.jacobian_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjacobian_fn\u001b[39m(x):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:524\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    523\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacrev\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 524\u001b[0m     vjp_out \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    526\u001b[0m         output, vjp_fn, aux \u001b[38;5;241m=\u001b[39m vjp_out\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:334\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    332\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    333\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 334\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Documents/GitHub/master-thesis/code/PINN/models.py:47\u001b[0m, in \u001b[0;36mLinearNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, train_iter = PINNS[0]['model'](net_size=(4,64), lr=1e-2, batch_size=512, ode=ode, stopping_loss=1e-4, device='cuda', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol, y_pred_np, t_np = solve(model, ode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(sol, y_pred_np, t_np, ode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_norms = compute_error_norms(sol.y.T, y_pred_np, t_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1': {'y_1': 0.016495777426448078, 'y_2': 0.011320865707932453},\n",
       " 'L2': {'y_1': 0.020917698390765186, 'y_2': 0.015568748881555539},\n",
       " 'L1_avg': 0.013908321567190265,\n",
       " 'L2_avg': 0.018243223636160363,\n",
       " 'End_point_L1': {'y_1': 0.012558190539294684, 'y_2': 0.0061826607914974505},\n",
       " 'End_point_L2': {'y_1': 0.012558190539294684, 'y_2': 0.0061826607914974505},\n",
       " 'End_point_L1_avg': 0.009370425665396066,\n",
       " 'End_point_L2_avg': 0.009897814003201676,\n",
       " 'End_point_time': array([15.], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_norms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
